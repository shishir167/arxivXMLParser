<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T04:08:15Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|99001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602062</id><created>2006-02-17</created><authors><author><keyname>Denis</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIF</affiliation></author><author><keyname>Esposito</keyname><forenames>Yann</forenames><affiliation>LIF</affiliation></author><author><keyname>Habrard</keyname><forenames>Amaury</forenames><affiliation>LIF</affiliation></author></authors><title>Learning rational stochastic languages</title><categories>cs.LG</categories><comments>15 pages</comments><proxy>ccsd ccsd-00019161</proxy><abstract>  Given a finite set of words w1,...,wn independently drawn according to a
fixed unknown distribution law P called a stochastic language, an usual goal in
Grammatical Inference is to infer an estimate of P in some class of
probabilistic models, such as Probabilistic Automata (PA). Here, we study the
class of rational stochastic languages, which consists in stochastic languages
that can be generated by Multiplicity Automata (MA) and which strictly includes
the class of stochastic languages generated by PA. Rational stochastic
languages have minimal normal representation which may be very concise, and
whose parameters can be efficiently estimated from stochastic samples. We
design an efficient inference algorithm DEES which aims at building a minimal
normal representation of the target. Despite the fact that no recursively
enumerable class of MA computes exactly the set of rational stochastic
languages over Q, we show that DEES strongly identifies tis set in the limit.
We study the intermediary MA output by DEES and show that they compute rational
series which converge absolutely to one and which can be used to provide
stochastic languages which closely estimate the target.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602063</id><created>2006-02-17</created><authors><author><keyname>Thomas</keyname><forenames>Tony</forenames></author><author><keyname>Lal</keyname><forenames>Arbind Kumar</forenames></author></authors><title>Group Signature Schemes Using Braid Groups</title><categories>cs.CR</categories><abstract>  Artin's braid groups have been recently suggested as a new source for
public-key cryptography. In this paper we propose the first group signature
schemes based on the conjugacy problem, decomposition problem and root problem
in the braid groups which are believed to be hard problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602064</id><created>2006-02-17</created><authors><author><keyname>Romero</keyname><forenames>A.</forenames></author><author><keyname>Rubio</keyname><forenames>J.</forenames></author><author><keyname>Sergeraert</keyname><forenames>F.</forenames></author></authors><title>Computing spectral sequences</title><categories>cs.SC</categories><abstract>  In this paper, a set of programs enhancing the Kenzo system is presented.
Kenzo is a Common Lisp program designed for computing in Algebraic Topology, in
particular it allows the user to calculate homology and homotopy groups of
complicated spaces. The new programs presented here entirely compute Serre and
Eilenberg-Moore spectral sequences, in particular the groups and differential
maps for arbitrary r. They also determine when the spectral sequence has
converged and describe the filtration of the target homology groups induced by
the spectral sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602065</id><created>2006-02-17</created><authors><author><keyname>Cilibrasi</keyname><forenames>Rudi</forenames><affiliation>CWI</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>Similarity of Objects and the Meaning of Words</title><categories>cs.CV cs.IR</categories><comments>LaTeX, 25 pages, 7 figures. Proc. 3rd Conf. Theory and Applications
  of Models of Computation (TAMC), 15-20 May, 2006, Beijing, China (Invited
  paper) This is an extended version of the 5-page abstract cs.IR/0504089</comments><acm-class>I.5; E.4; H.5; I.2.6; I.2.7; I.6</acm-class><abstract>  We survey the emerging area of compression-based, parameter-free, similarity
distance measures useful in data-mining, pattern recognition, learning and
automatic semantics extraction. Given a family of distances on a set of
objects, a distance is universal up to a certain precision for that family if
it minorizes every distance in the family between every two objects in the set,
up to the stated precision (we do not require the universal distance to be an
element of the family). We consider similarity distances for two types of
objects: literal objects that as such contain all of their meaning, like
genomes or books, and names for objects. The latter may have literal
embodyments like the first type, but may also be abstract like ``red'' or
``christianity.'' For the first type we consider a family of computable
distance measures corresponding to parameters expressing similarity according
to particular featuresdistances generated by web users corresponding to
particular semantic relations between the (names for) the designated objects.
For both families we give universal similarity distance measures, incorporating
all particular distance measures in the family. In the first case the universal
distance is based on compression and in the second case it is based on Google
page counts related to search terms. In both cases experiments on a massive
scale give evidence of the viability of the approaches. between pairs of
literal objects. For the second type we consider similarity
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602066</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602066</id><created>2006-02-17</created><authors><author><keyname>Mello</keyname><forenames>Louis</forenames></author></authors><title>Natural Economics</title><categories>cs.OH</categories><abstract>  A few considerations on the nature of Economics and its relationship to human
communities through the prism of Self-Organizing-Systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602067</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602067</id><created>2006-02-17</created><updated>2006-05-22</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Renyi to Renyi -- Source Coding under Siege</title><categories>cs.IT cs.DS math.IT</categories><comments>5 pages, 1 figure, accepted to ISIT 2006</comments><acm-class>E.4; H.1.1</acm-class><abstract>  A novel lossless source coding paradigm applies to problems of unreliable
lossless channels with low bit rates, in which a vital message needs to be
transmitted prior to termination of communications. This paradigm can be
applied to Alfred Renyi's secondhand account of an ancient siege in which a spy
was sent to scout the enemy but was captured. After escaping, the spy returned
to his base in no condition to speak and unable to write. His commander asked
him questions that he could answer by nodding or shaking his head, and the
fortress was defended with this information. Renyi told this story with
reference to prefix coding, but maximizing probability of survival in the siege
scenario is distinct from yet related to the traditional source coding
objective of minimizing expected codeword length. Rather than finding a code
minimizing expected codeword length $\sum_{i=1}^n p(i) l(i)$, the siege problem
involves maximizing $\sum_{i=1}^n p(i) \theta^{l(i)}$ for a known $\theta \in
(0,1)$. When there are no restrictions on codewords, this problem can be solve
using a known generalization of Huffman coding. The optimal solution has coding
bounds which are functions of Renyi entropy; in addition to known bounds, new
bounds are derived here. The alphabetically constrained version of this problem
has applications in search trees and diagnostic testing. A novel dynamic
programming algorithm -- based upon the oldest known algorithm for the
traditional alphabetic problem -- optimizes this problem in $O(n^3)$ time and
$O(n^2)$ space, whereas two novel approximation algorithms can find a
suboptimal solution faster: one in linear time, the other in $O(n \log n)$.
Coding bounds for the alphabetic version of this problem are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602068</id><created>2006-02-19</created><authors><author><keyname>Koehler</keyname><forenames>K. R.</forenames></author></authors><title>Parallel Symbolic Computation of Curvature Invariants in General
  Relativity</title><categories>cs.DC cs.SC gr-qc</categories><comments>9 pages, submitted to Journal of Computational Physics</comments><abstract>  We present a practical application of parallel symbolic computation in
General Relativity: the calculation of curvature invariants for large
dimension. We discuss the structure of the calculations, an implementation of
the technique and scaling of the computation with spacetime dimension for
various invariants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602069</id><created>2006-02-19</created><updated>2006-06-01</updated><authors><author><keyname>Choi</keyname><forenames>Vicky</forenames></author></authors><title>Faster Algorithms for Constructing a Concept (Galois) Lattice</title><categories>cs.DM cs.DS</categories><comments>15 pages, 3 figures</comments><abstract>  In this paper, we present a fast algorithm for constructing a concept
(Galois) lattice of a binary relation, including computing all concepts and
their lattice order. We also present two efficient variants of the algorithm,
one for computing all concepts only, and one for constructing a frequent closed
itemset lattice. The running time of our algorithms depends on the lattice
structure and is faster than all other existing algorithms for these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602070</id><created>2006-02-20</created><authors><author><keyname>Boeger</keyname><forenames>Nathan</forenames></author></authors><title>Methods for scaling a large member base</title><categories>cs.GL</categories><comments>12 pages</comments><abstract>  The technical challenges of scaling websites with large and growing member
bases, like social networking sites, are numerous. One of these challenges is
how to evenly distribute the growing member base across all available
resources. This paper will explore various methods that address this issue. The
techniques used in this paper can be generalized and applied to various other
problems that need to distribute data evenly amongst a finite amount of
resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602071</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602071</id><created>2006-02-19</created><authors><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Geographic Gossip: Efficient Aggregation for Sensor Networks</title><categories>cs.IT math.IT</categories><comments>8 pages total; to appear in Information Processing in Sensor Networks
  (IPSN) 2006</comments><abstract>  Gossip algorithms for aggregation have recently received significant
attention for sensor network applications because of their simplicity and
robustness in noisy and uncertain environments. However, gossip algorithms can
waste significant energy by essentially passing around redundant information
multiple times. For realistic sensor network model topologies like grids and
random geometric graphs, the inefficiency of gossip schemes is caused by slow
mixing times of random walks on those graphs. We propose and analyze an
alternative gossiping scheme that exploits geographic information. By utilizing
a simple resampling method, we can demonstrate substantial gains over
previously proposed gossip protocols. In particular, for random geometric
graphs, our algorithm computes the true average to accuracy $1/n^a$ using
$O(n^{1.5}\sqrt{\log n})$ radio transmissions, which reduces the energy
consumption by a $\sqrt{\frac{n}{\log n}}$ factor over standard gossip
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602072</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602072</id><created>2006-02-20</created><authors><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author><author><keyname>Ytrehus</keyname><forenames>&#xd8;yvind</forenames></author></authors><title>Turbo Decoding on the Binary Erasure Channel: Finite-Length Analysis and
  Turbo Stopping Sets</title><categories>cs.IT math.IT</categories><comments>28 pages, 5 figures, submitted to IEEE Transactions on Information
  Theory</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 53, no. 11, pp. 4059-4075, Nov. 2007</journal-ref><abstract>  This paper is devoted to the finite-length analysis of turbo decoding over
the binary erasure channel (BEC). The performance of iterative
belief-propagation (BP) decoding of low-density parity-check (LDPC) codes over
the BEC can be characterized in terms of stopping sets. We describe turbo
decoding on the BEC which is simpler than turbo decoding on other channels. We
then adapt the concept of stopping sets to turbo decoding and state an exact
condition for decoding failure. Apply turbo decoding until the transmitted
codeword has been recovered, or the decoder fails to progress further. Then the
set of erased positions that will remain when the decoder stops is equal to the
unique maximum-size turbo stopping set which is also a subset of the set of
erased positions. Furthermore, we present some improvements of the basic turbo
decoding algorithm on the BEC. The proposed improved turbo decoding algorithm
has substantially better error performance as illustrated by the given
simulation results. Finally, we give an expression for the turbo stopping set
size enumerating function under the uniform interleaver assumption, and an
efficient enumeration algorithm of small-size turbo stopping sets for a
particular interleaver. The solution is based on the algorithm proposed by
Garello et al. in 2001 to compute an exhaustive list of all low-weight
codewords in a turbo code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602073</id><created>2006-02-21</created><updated>2006-04-20</updated><authors><author><keyname>Ajwani</keyname><forenames>Deepak</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>Meyer</keyname><forenames>Ulrich</forenames></author></authors><title>An O(n^{2.75}) algorithm for online topological ordering</title><categories>cs.DS</categories><comments>20 pages, long version of SWAT'06 paper</comments><abstract>  We present a simple algorithm which maintains the topological order of a
directed acyclic graph with n nodes under an online edge insertion sequence in
O(n^{2.75}) time, independent of the number of edges m inserted. For dense
DAGs, this is an improvement over the previous best result of O(min(m^{3/2}
log(n), m^{3/2} + n^2 log(n)) by Katriel and Bodlaender. We also provide an
empirical comparison of our algorithm with other algorithms for online
topological sorting. Our implementation outperforms them on certain hard
instances while it is still competitive on random edge insertion sequences
leading to complete DAGs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602074</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602074</id><created>2006-02-21</created><updated>2009-01-30</updated><authors><author><keyname>Chigansky</keyname><forenames>Pavel</forenames></author></authors><title>The entropy rate of the binary symmetric channel in the rare transitions
  regime</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note has been withdrawn by the author as the more complete result was
recently proved by A.Quas and Y.Peres
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602075</id><created>2006-02-21</created><authors><author><keyname>Deineko</keyname><forenames>Vladimir</forenames></author><author><keyname>Jonsson</keyname><forenames>Peter</forenames></author><author><keyname>Klasson</keyname><forenames>Mikael</forenames></author><author><keyname>Krokhin</keyname><forenames>Andrei</forenames></author></authors><title>The approximability of MAX CSP with fixed-value constraints</title><categories>cs.CC</categories><abstract>  In the maximum constraint satisfaction problem (MAX CSP), one is given a
finite collection of (possibly weighted) constraints on overlapping sets of
variables, and the goal is to assign values from a given finite domain to the
variables so as to maximize the number (or the total weight, for the weighted
case) of satisfied constraints. This problem is NP-hard in general, and,
therefore, it is natural to study how restricting the allowed types of
constraints affects the approximability of the problem. In this paper, we show
that any MAX CSP problem with a finite set of allowed constraint types, which
includes all fixed-value constraints (i.e., constraints of the form x=a), is
either solvable exactly in polynomial-time or else is APX-complete, even if the
number of occurrences of variables in instances are bounded. Moreover, we
present a simple description of all polynomial-time solvable cases of our
problem. This description relies on the well-known algebraic combinatorial
property of supermodularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602076</id><created>2006-02-21</created><authors><author><keyname>Antonellis</keyname><forenames>Ioannis</forenames></author><author><keyname>Gallopoulos</keyname><forenames>Efstratios</forenames></author></authors><title>Exploring term-document matrices from matrix models in text mining</title><categories>cs.IR cs.DB cs.DL</categories><comments>SIAM Text Mining Workshop, SIAM Conference Data Mining, 2006</comments><report-no>03/02-06</report-no><abstract>  We explore a matrix-space model, that is a natural extension to the vector
space model for Information Retrieval. Each document can be represented by a
matrix that is based on document extracts (e.g. sentences, paragraphs,
sections). We focus on the performance of this model for the specific case in
which documents are originally represented as term-by-sentence matrices. We use
the singular value decomposition to approximate the term-by-sentence matrices
and assemble these results to form the pseudo-``term-document'' matrix that
forms the basis of a text mining method alternative to traditional VSM and LSI.
We investigate the singular values of this matrix and provide experimental
evidence suggesting that the method can be particularly effective in terms of
accuracy for text collections with multi-topic documents, such as web pages
with news.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602077</id><created>2006-02-21</created><authors><author><keyname>Schmitt</keyname><forenames>Vincent</forenames></author><author><keyname>Worytkiewicz</keyname><forenames>Krzysztof</forenames></author></authors><title>Bisimulations of enrichments</title><categories>cs.LO</categories><abstract>  In this paper we show that classical notions from automata theory such as
simulation and bisimulation can be lifted to the context of enriched
categories. The usual properties of bisimulation are nearly all preserved in
this new context. The class of enriched functors that correspond to functionnal
bisimulations surjective on objects is investigated and appears &quot;nearly&quot; open
in the sense of Joyal and Moerdijk. Seeing the change of base techniques as a
convenient means to define process refinement/abstractions, we give sufficient
conditions for the change of base categories to preserve bisimularity. We apply
these concepts to Betti's generalized automata, categorical transition systems,
and other exotic categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602078</id><created>2006-02-21</created><updated>2006-02-23</updated><authors><author><keyname>Burger</keyname><forenames>John Robert</forenames></author></authors><title>Associative Memory For Reversible Programming and Charge Recovery</title><categories>cs.AR cs.DC</categories><acm-class>C.1.2; C.5.4</acm-class><abstract>  Presented below is an interesting type of associative memory called toggle
memory based on the concept of T flip flops, as opposed to D flip flops. Toggle
memory supports both reversible programming and charge recovery. Circuits
designed using the principles delineated below permit matchlines to charge and
discharge with near zero energy dissipation. The resulting lethargy is
compensated by the massive parallelism of associative memory. Simulation
indicates over 33x reduction in energy dissipation using a sinusoidal power
supply at 2 MHz, assuming realistic 50 nm MOSFET models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602079</identifier>
 <datestamp>2012-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602079</id><created>2006-02-21</created><updated>2011-09-22</updated><authors><author><keyname>Ionescu</keyname><forenames>Dumitru Mihai</forenames></author><author><keyname>Zhu</keyname><forenames>Haidong</forenames></author></authors><title>SISO APP Searches in Lattices with Tanner Graphs</title><categories>cs.IT cs.DS math.IT</categories><comments>15 pages, 6 figures, 2 tables, uses IEEEtran.cls</comments><acm-class>E.4; H.1.1</acm-class><journal-ref>IEEE Trans. Inf. Theory, pp. 2672-2688, vol. 58, May 2012</journal-ref><doi>10.1109/TIT.2011.2178130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient, low-complexity, soft-output detector for general lattices is
presented, based on their Tanner graph (TG) representations. Closest-point
searches in lattices can be performed as non-binary belief propagation on
associated TGs; soft-information output is naturally generated in the process;
the algorithm requires no backtrack (cf. classic sphere decoding), and extracts
extrinsic information. A lattice's coding gain enables equivalence relations
between lattice points, which can be thereby partitioned in cosets. Total and
extrinsic a posteriori probabilities at the detector's output further enable
the use of soft detection information in iterative schemes. The algorithm is
illustrated via two scenarios that transmit a 32-point, uncoded
super-orthogonal (SO) constellation for multiple-input multiple-output (MIMO)
channels, carved from an 8-dimensional non-orthogonal lattice (a direct sum of
two 4-dimensional checkerboard lattice): it achieves maximum likelihood
performance in quasistatic fading; and, performs close to interference-free
transmission, and identically to list sphere decoding, in independent fading
with coordinate interleaving and iterative equalization and detection. Latter
scenario outperforms former despite the absence of forward error correction
coding---because the inherent lattice coding gain allows for the refining of
extrinsic information. The lattice constellation is the same as the one
employed in the SO space-time trellis codes first introduced for 2-by-2 MIMO by
Ionescu et al., then independently by Jafarkhani and Seshadri. Complexity is
log-linear in lattice dimensionality, vs. cubic in sphere decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602080</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602080</id><created>2006-02-22</created><authors><author><keyname>Poon</keyname><forenames>Sheung-Hung</forenames><affiliation>Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, The Netherlands</affiliation></author><author><keyname>Thite</keyname><forenames>Shripad</forenames><affiliation>Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, The Netherlands</affiliation></author></authors><title>Pants Decomposition of the Punctured Plane</title><categories>cs.CG</categories><comments>5 pages, 1 grayscale figure</comments><abstract>  A pants decomposition of an orientable surface S is a collection of simple
cycles that partition S into pants, i.e., surfaces of genus zero with three
boundary cycles. Given a set P of n points in the plane, we consider the
problem of computing a pants decomposition of the surface S which is the plane
minus P, of minimum total length. We give a polynomial-time approximation
scheme using Mitchell's guillotine rectilinear subdivisions. We give a
quartic-time algorithm to compute the shortest pants decomposition of S when
the cycles are restricted to be axis-aligned boxes, and a quadratic-time
algorithm when all the points lie on a line; both exact algorithms use dynamic
programming with Yao's speedup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602081</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602081</id><created>2006-02-23</created><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author><author><keyname>Yang</keyname><forenames>En-hui</forenames></author></authors><title>Low-Density Parity-Check Code with Fast Decoding Speed</title><categories>cs.IT math.IT</categories><comments>Will be submitted to IEEE Transactions on Information Theory</comments><abstract>  Low-Density Parity-Check (LDPC) codes received much attention recently due to
their capacity-approaching performance. The iterative message-passing algorithm
is a widely adopted decoding algorithm for LDPC codes \cite{Kschischang01}. An
important design issue for LDPC codes is designing codes with fast decoding
speed while maintaining capacity-approaching performance. In another words, it
is desirable that the code can be successfully decoded in few number of
decoding iterations, at the same time, achieves a significant portion of the
channel capacity. Despite of its importance, this design issue received little
attention so far. In this paper, we address this design issue for the case of
binary erasure channel.
  We prove that density-efficient capacity-approaching LDPC codes satisfy a so
called &quot;flatness condition&quot;. We show an asymptotic approximation to the number
of decoding iterations. Based on these facts, we propose an approximated
optimization approach to finding the codes with good decoding speed. We further
show that the optimal codes in the sense of decoding speed are
&quot;right-concentrated&quot;. That is, the degrees of check nodes concentrate around
the average right degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602082</id><created>2006-02-23</created><authors><author><keyname>Khan</keyname><forenames>Zaheer Abbas</forenames></author><author><keyname>Odeh</keyname><forenames>Mohammed</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author></authors><title>Digital Libraries: From Process Modelling to Grid-based Service Oriented
  Architecture</title><categories>cs.DL cs.SE</categories><comments>6 pages, 5 figures, 1 table. The 2nd international conference on
  Information and Communication Technologies from Theory to Application
  (ICTTA06</comments><acm-class>D.2.11</acm-class><abstract>  Graphical Business Process Modelling Languages (BPML) like Role Activity
Diagrams (RAD) provide ease and flexibility for modelling business behaviour.
However, these languages show limited applicability in terms of enactment over
distributed systems paradigms like Service Oriented Architecture (SOA) based
grid computing. This paper investigates RAD modelling of a Scientific
Publishing Process (SPP) for Digital Libraries (DL) and tries to determine the
suitability of Pi-Calculus based formal approaches to enact SOA based grid
computing. In order to achieve this purpose, the Pi-Calculus based formal
transformation from a RAD model of SPP for DL draws attention towards a number
of challenging issues including issues that require particular design
considerations for appropriate enactment in a SOA based grid system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602083</identifier>
 <datestamp>2011-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602083</id><created>2006-02-24</created><authors><author><keyname>Frailis</keyname><forenames>Marco</forenames></author><author><keyname>Mansutti</keyname><forenames>Oriana</forenames></author><author><keyname>Boinee</keyname><forenames>Praveen</forenames></author><author><keyname>Cabras</keyname><forenames>Giuseppe</forenames></author><author><keyname>De Angelis</keyname><forenames>Alessandro</forenames></author><author><keyname>De Lotto</keyname><forenames>Barbara</forenames></author><author><keyname>Forti</keyname><forenames>Alberto</forenames></author><author><keyname>Dell'Orso</keyname><forenames>Mauro</forenames></author><author><keyname>Paoletti</keyname><forenames>Riccardo</forenames></author><author><keyname>Scribano</keyname><forenames>Angelo</forenames></author><author><keyname>Turini</keyname><forenames>Nicola</forenames></author><author><keyname>Mariotti</keyname><forenames>Mose'</forenames></author><author><keyname>Peruzzo</keyname><forenames>Luigi</forenames></author><author><keyname>Saggion</keyname><forenames>Antonio</forenames></author></authors><title>A third level trigger programmable on FPGA for the gamma/hadron
  separation in a Cherenkov telescope using pseudo-Zernike moments and the SVM
  classifier</title><categories>cs.CV cs.AI</categories><acm-class>I.5.2; C.3</acm-class><journal-ref>Proceedings of the Third Workshop on Science with the New
  Generation of High Energy Gamma Experiments, p.201 (2006)</journal-ref><abstract>  We studied the application of the Pseudo-Zernike features as image parameters
(instead of the Hillas parameters) for the discrimination between the images
produced by atmospheric electromagnetic showers caused by gamma-rays and the
ones produced by atmospheric electromagnetic showers caused by hadrons in the
MAGIC Experiment. We used a Support Vector Machine as classification algorithm
with the computed Pseudo-Zernike features as classification parameters. We
implemented on a FPGA board a kernel function of the SVM and the Pseudo-Zernike
features to build a third level trigger for the gamma-hadron separation task of
the MAGIC Experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602084</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602084</id><created>2006-02-25</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Astola</keyname><forenames>Jaakko</forenames></author></authors><title>Universal Codes as a Basis for Time Series Testing</title><categories>cs.IT math.IT</categories><comments>accepted for &quot;Statistical Methodology&quot; (Elsevier)</comments><abstract>  We suggest a new approach to hypothesis testing for ergodic and stationary
processes. In contrast to standard methods, the suggested approach gives a
possibility to make tests, based on any lossless data compression method even
if the distribution law of the codeword lengths is not known. We apply this
approach to the following four problems: goodness-of-fit testing (or identity
testing), testing for independence, testing of serial independence and
homogeneity testing and suggest nonparametric statistical tests for these
problems. It is important to note that practically used so-called archivers can
be used for suggested testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602085</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602085</id><created>2006-02-25</created><updated>2007-06-20</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Twenty (or so) Questions: $D$-ary Length-Bounded Prefix Coding</title><categories>cs.IT cs.DS math.IT</categories><comments>12 pages, 4 figures, extended version of cs/0701012 (accepted to ISIT
  2007), formerly &quot;Twenty (or so) Questions: $D$-ary Bounded-Length Huffman
  Coding&quot;</comments><acm-class>G.2.2; F.2; E.4; H.1.1</acm-class><abstract>  Efficient optimal prefix coding has long been accomplished via the Huffman
algorithm. However, there is still room for improvement and exploration
regarding variants of the Huffman problem. Length-limited Huffman coding,
useful for many practical applications, is one such variant, for which codes
are restricted to the set of codes in which none of the $n$ codewords is longer
than a given length, $l_{\max}$. Binary length-limited coding can be done in
$O(n l_{\max})$ time and O(n) space via the widely used Package-Merge algorithm
and with even smaller asymptotic complexity using a lesser-known algorithm. In
this paper these algorithms are generalized without increasing complexity in
order to introduce a minimum codeword length constraint $l_{\min}$, to allow
for objective functions other than the minimization of expected codeword
length, and to be applicable to both binary and nonbinary codes; nonbinary
codes were previously addressed using a slower dynamic programming approach.
These extensions have various applications -- including fast decompression and
a modified version of the game ``Twenty Questions'' -- and can be used to solve
the problem of finding an optimal code with limited fringe, that is, finding
the best code among codes with a maximum difference between the longest and
shortest codewords. The previously proposed method for solving this problem was
nonpolynomial time, whereas solving this using the novel linear-space algorithm
requires only $O(n (l_{\max}- l_{\min})^2)$ time, or even less if $l_{\max}-
l_{\min}$ is not $O(\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602086</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602086</id><created>2006-02-25</created><authors><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>On the Block Error Probability of LP Decoding of LDPC Codes</title><categories>cs.IT math.IT</categories><journal-ref>Proc. Inaugural Workshop of the Center for Information Theory and
  its Applications, UC San Diego, San Diego, CA, USA, Feb. 6-10, 2006</journal-ref><abstract>  In his thesis, Wiberg showed the existence of thresholds for families of
regular low-density parity-check codes under min-sum algorithm decoding. He
also derived analytic bounds on these thresholds. In this paper, we formulate
similar results for linear programming decoding of regular low-density
parity-check codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602087</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602087</id><created>2006-02-25</created><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author></authors><title>Bounds on the Threshold of Linear Programming Decoding</title><categories>cs.IT math.IT</categories><journal-ref>Proc. IEEE Information Theory Workshop (ITW 2006), Punta del Este,
  Uruguay, March 13-17, 2006</journal-ref><abstract>  Whereas many results are known about thresholds for ensembles of low-density
parity-check codes under message-passing iterative decoding, this is not the
case for linear programming decoding. Towards closing this knowledge gap, this
paper presents some bounds on the thresholds of low-density parity-check code
ensembles under linear programming decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602088</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602088</id><created>2006-02-25</created><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author></authors><title>Towards Low-Complexity Linear-Programming Decoding</title><categories>cs.IT math.IT</categories><journal-ref>Proc. 4th Int. Symposium on Turbo Codes and Related Topics,
  Munich, Germany, April 3-7, 2006</journal-ref><abstract>  We consider linear-programming (LP) decoding of low-density parity-check
(LDPC) codes. While it is clear that one can use any general-purpose LP solver
to solve the LP that appears in the decoding problem, we argue in this paper
that the LP at hand is equipped with a lot of structure that one should take
advantage of. Towards this goal, we study the dual LP and show how
coordinate-ascent methods lead to very simple update rules that are tightly
connected to the min-sum algorithm. Moreover, replacing minima in the formula
of the dual LP with soft-minima one obtains update rules that are tightly
connected to the sum-product algorithm. This shows that LP solvers with
complexity similar to the min-sum algorithm and the sum-product algorithm are
feasible. Finally, we also discuss some sub-gradient-based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602089</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602089</id><created>2006-02-25</created><authors><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Pseudo-Codeword Analysis of Tanner Graphs from Projective and Euclidean
  Planes</title><categories>cs.IT cs.DM math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, February 25,
  2006</comments><abstract>  In order to understand the performance of a code under maximum-likelihood
(ML) decoding, one studies the codewords, in particular the minimal codewords,
and their Hamming weights. In the context of linear programming (LP) decoding,
one's attention needs to be shifted to the pseudo-codewords, in particular to
the minimal pseudo-codewords, and their pseudo-weights. In this paper we
investigate some families of codes that have good properties under LP decoding,
namely certain families of low-density parity-check (LDPC) codes that are
derived from projective and Euclidean planes: we study the structure of their
minimal pseudo-codewords and give lower bounds on their pseudo-weight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602090</id><created>2006-02-26</created><authors><author><keyname>Huang</keyname><forenames>Li-Sha</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>On the Approximation and Smoothed Complexity of Leontief Market
  Equilibria</title><categories>cs.GT cs.CC</categories><acm-class>F.1.2; F.1.3; F.2; F.2.3</acm-class><abstract>  We show that the problem of finding an \epsilon-approximate Nash equilibrium
of an n by n two-person games can be reduced to the computation of an
(\epsilon/n)^2-approximate market equilibrium of a Leontief economy. Together
with a recent result of Chen, Deng and Teng, this polynomial reduction implies
that the Leontief market exchange problem does not have a fully polynomial-time
approximation scheme, that is, there is no algorithm that can compute an
\epsilon-approximate market equilibrium in time polynomial in m, n, and
1/\epsilon, unless PPAD is not in P, We also extend the analysis of our
reduction to show, unless PPAD is not in RP, that the smoothed complexity of
the Scarf's general fixed-point approximation algorithm (when applying to solve
the approximate Leontief market exchange problem) or of any algorithm for
computing an approximate market equilibrium of Leontief economies is not
polynomial in n and 1/\sigma, under Gaussian or uniform perturbations with
magnitude \sigma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602091</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602091</id><created>2006-02-26</created><authors><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>Feedback Capacity of Stationary Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>64 pages, submitted to IEEE Trans. Inform. Theory</comments><abstract>  The feedback capacity of additive stationary Gaussian noise channels is
characterized as the solution to a variational problem. Toward this end, it is
proved that the optimal feedback coding scheme is stationary. When specialized
to the first-order autoregressive moving average noise spectrum, this
variational characterization yields a closed-form expression for the feedback
capacity. In particular, this result shows that the celebrated
Schalkwijk-Kailath coding scheme achieves the feedback capacity for the
first-order autoregressive moving average Gaussian channel, positively
answering a long-standing open problem studied by Butman, Schalkwijk-Tiernan,
Wolfowitz, Ozarow, Ordentlich, Yang-Kavcic-Tatikonda, and others. More
generally, it is shown that a k-dimensional generalization of the
Schalkwijk-Kailath coding scheme achieves the feedback capacity for any
autoregressive moving average noise spectrum of order k. Simply put, the
optimal transmitter iteratively refines the receiver's knowledge of the
intended message.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602092</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602092</id><created>2006-02-27</created><authors><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Inconsistent parameter estimation in Markov random fields: Benefits in
  the computation-limited setting</title><categories>cs.LG cs.IT math.IT math.ST stat.TH</categories><comments>UC Berkeley, Department of Statistics; Technical Report 690</comments><abstract>  Consider the problem of joint parameter estimation and prediction in a Markov
random field: i.e., the model parameters are estimated on the basis of an
initial set of data, and then the fitted model is used to perform prediction
(e.g., smoothing, denoising, interpolation) on a new noisy observation. Working
under the restriction of limited computation, we analyze a joint method in
which the \emph{same convex variational relaxation} is used to construct an
M-estimator for fitting parameters, and to perform approximate marginalization
for the prediction step. The key result of this paper is that in the
computation-limited setting, using an inconsistent parameter estimator (i.e.,
an estimator that returns the ``wrong'' model even in the infinite data limit)
can be provably beneficial, since the resulting errors can partially compensate
for errors made by using an approximate prediction technique. En route to this
result, we analyze the asymptotic properties of M-estimators based on convex
variational relaxations, and establish a Lipschitz stability property that
holds for a broad class of variational methods. We show that joint
estimation/prediction based on the reweighted sum-product algorithm
substantially outperforms a commonly used heuristic based on ordinary
sum-product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602093</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602093</id><created>2006-02-27</created><authors><author><keyname>Denis</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIF</affiliation></author><author><keyname>Esposito</keyname><forenames>Yann</forenames><affiliation>LIF</affiliation></author></authors><title>Rational stochastic languages</title><categories>cs.LG cs.CL</categories><comments>35 pages</comments><proxy>ccsd ccsd-00019728</proxy><abstract>  The goal of the present paper is to provide a systematic and comprehensive
study of rational stochastic languages over a semiring K \in {Q, Q +, R, R+}. A
rational stochastic language is a probability distribution over a free monoid
\Sigma^* which is rational over K, that is which can be generated by a
multiplicity automata with parameters in K. We study the relations between the
classes of rational stochastic languages S rat K (\Sigma). We define the notion
of residual of a stochastic language and we use it to investigate properties of
several subclasses of rational stochastic languages. Lastly, we study the
representation of rational stochastic languages by means of multiplicity
automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602094</id><created>2006-02-27</created><updated>2006-03-26</updated><authors><author><keyname>Altaher</keyname><forenames>Altyeb</forenames></author></authors><title>Effect of CSMA/CD on Self-Similarity of Network Traffic</title><categories>cs.NI</categories><comments>4 pages, 2 figures</comments><acm-class>C.2.5</acm-class><abstract>  It is now well known that Internet traffic exhibits self-similarity, which
cannot be described by traditional Markovian models such as the Poisson
process. The causes of self-similarity of network traffic must be identified
because understanding the nature of network traffic is critical in order to
properly design and implement computer networks and network services like the
World Wide Web. While some researchers have argued self similarity is generated
by the typical applications or caused by Transport layer Protocols, it is also
possible that the CSMA/CD protocol may cause or at least contribute to this
phenomenon. In this paper, we use NS simulator to study the effect of CSMA/CD
Exponential Backoff retransmission algorithm on Traffic Self similarity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602095</id><created>2006-02-27</created><updated>2006-03-22</updated><authors><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Flatland</keyname><forenames>Robin</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Epsilon-Unfolding Orthogonal Polyhedra</title><categories>cs.CG</categories><comments>23 pages, 20 figures, 7 references. Revised version improves language
  and figures, updates references, and sharpens the conclusion</comments><acm-class>F.2.2</acm-class><abstract>  An unfolding of a polyhedron is produced by cutting the surface and
flattening to a single, connected, planar piece without overlap (except
possibly at boundary points). It is a long unsolved problem to determine
whether every polyhedron may be unfolded. Here we prove, via an algorithm, that
every orthogonal polyhedron (one whose faces meet at right angles) of genus
zero may be unfolded. Our cuts are not necessarily along edges of the
polyhedron, but they are always parallel to polyhedron edges. For a polyhedron
of n vertices, portions of the unfolding will be rectangular strips which, in
the worst case, may need to be as thin as epsilon = 1/2^{Omega(n)}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602096</id><created>2006-02-27</created><authors><author><keyname>Ponnath</keyname><forenames>Abhilash</forenames></author></authors><title>Difficulties in the Implementation of Quantum Computers</title><categories>cs.AR</categories><comments>6 pages</comments><abstract>  This paper reviews various engineering hurdles facing the field of quantum
computing. Specifically, problems related to decoherence, state preparation,
error correction, and implementability of gates are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602097</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602097</id><created>2006-02-27</created><updated>2006-06-09</updated><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>The Cubic Public-Key Transformation</title><categories>cs.CR</categories><comments>9 pages; typographical errors corrected</comments><journal-ref>Circuits Systems and Signal Processing, vol 26, pp. 353-359, 2007</journal-ref><abstract>  We propose the use of the cubic transformation for public-key applications
and digital signatures. Transformations modulo a prime p or a composite n=pq,
where p and q are primes, are used in such a fashion that each transformed
value has only 3 roots that makes it a more efficient transformation than the
squaring transformation of Rabin, which has 4 roots. Such a transformation,
together with additional tag information, makes it possible to uniquely invert
each transformed value. The method may be used for other exponents as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602098</id><created>2006-02-28</created><updated>2006-05-07</updated><authors><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author></authors><title>Compositional Semantics for the Procedural Interpretation of Logic</title><categories>cs.PL</categories><comments>17 pages; no figures</comments><report-no>DCS-307-IR</report-no><acm-class>D.1.6; F.3.2</acm-class><abstract>  Semantics of logic programs has been given by proof theory, model theory and
by fixpoint of the immediate-consequence operator. If clausal logic is a
programming language, then it should also have a compositional semantics.
Compositional semantics for programming languages follows the abstract syntax
of programs, composing the meaning of a unit by a mathematical operation on the
meanings of its constituent units. The procedural interpretation of logic has
only yielded an incomplete abstract syntax for logic programs. We complete it
and use the result as basis of a compositional semantics. We present for
comparison Tarski's algebraization of first-order predicate logic, which is in
substance the compositional semantics for his choice of syntax. We characterize
our semantics by equivalence with the immediate-consequence operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0602099</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0602099</id><created>2006-02-28</created><authors><author><keyname>Ibrahim</keyname><forenames>H.</forenames></author><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author></authors><title>Towards Applicative Relational Programming</title><categories>cs.PL</categories><comments>10 pages; no figures</comments><acm-class>D.1.6; F.3.2</acm-class><abstract>  Functional programming comes in two flavours: one where ``functions are
first-class citizens'' (we call this applicative) and one which is based on
equations (we call this declarative). In relational programming clauses play
the role of equations. Hence Prolog is declarative. The purpose of this paper
is to provide in relational programming a mathematical basis for the relational
analog of applicative functional programming. We use the cylindric semantics of
first-order logic due to Tarski and provide a new notation for the required
cylinders that we call tables. We define the Table/Relation Algebra with
operators sufficient to translate Horn clauses into algebraic form. We
establish basic mathematical properties of these operators. We show how
relations can be first-class citizens, and devise mechanisms for modularity,
for local scoping of predicates, and for exporting/importing relations between
programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603001</id><created>2006-03-01</created><authors><author><keyname>Schl&#xf6;gl</keyname><forenames>Alois</forenames></author></authors><title>BioSig - An application of Octave</title><categories>cs.MS</categories><comments>6 pages, submission for the Octave 2006 meeting</comments><report-no>Octave2006/16</report-no><acm-class>J.2; J.3; J.4</acm-class><abstract>  BioSig is an open source software library for biomedical signal processing.
Most users in the field are using Matlab; however, significant effort was
undertaken to provide compatibility to Octave, too. This effort has been widely
successful, only some non-critical components relying on a graphical user
interface are missing. Now, installing BioSig on Octave is as easy as on
Matlab. Moreover, a benchmark test based on BioSig has been developed and the
benchmark results of several platforms are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603002</id><created>2006-02-28</created><authors><author><keyname>Cheng</keyname><forenames>Qi</forenames></author></authors><title>On comparing sums of square roots of small integers</title><categories>cs.CG</categories><acm-class>F.2.1</acm-class><abstract>  Let $k$ and $n$ be positive integers, $n&gt;k$. Define $r(n,k)$ to be the
minimum positive value of $$ |\sqrt{a_1} + ... + \sqrt{a_k} - \sqrt{b_1} - &gt;...
-\sqrt{b_k} | $$ where $ a_1, a_2, ..., a_k, b_1, b_2, ..., b_k $ are positive
integers no larger than $n$. It is an important problem in computational
geometry to determine a good upper bound of $-\log r(n,k)$. In this paper we
prove an upper bound of $ 2^{O(n/\log n)} \log n$, which is better than the
best known result $O(2^{2k} \log n)$ whenever $ n \leq ck\log k$ for some
constant $c$. In particular, our result implies a {\em subexponential}
algorithm to compare two sums of square roots of integers of size $o(k\log k)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603003</id><created>2006-03-01</created><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>LIX, INRIA Futurs</affiliation></author></authors><title>Analyse non standard du bruit</title><categories>cs.CE math.LO math.OC math.PR quant-ph</categories><proxy>ccsd inria-00001134</proxy><abstract>  Thanks to the nonstandard formalization of fast oscillating functions, due to
P. Cartier and Y. Perrin, an appropriate mathematical framework is derived for
new non-asymptotic estimation techniques, which do not necessitate any
statistical analysis of the noises corrupting any sensor. Various applications
are deduced for multiplicative noises, for the length of the parametric
estimation windows, and for burst errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603004</id><created>2006-03-01</created><authors><author><keyname>Castillo</keyname><forenames>P. A.</forenames></author><author><keyname>Arenas</keyname><forenames>M. G.</forenames></author><author><keyname>Castellano</keyname><forenames>J. G.</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author><author><keyname>Prieto</keyname><forenames>A.</forenames></author><author><keyname>Rivas</keyname><forenames>V.</forenames></author><author><keyname>Romero</keyname><forenames>G.</forenames></author></authors><title>Lamarckian Evolution and the Baldwin Effect in Evolutionary Neural
  Networks</title><categories>cs.NE</categories><comments>Presented in a Spanish conference, MAEB</comments><acm-class>C.1.3</acm-class><abstract>  Hybrid neuro-evolutionary algorithms may be inspired on Darwinian or
Lamarckian evolu- tion. In the case of Darwinian evolution, the Baldwin effect,
that is, the progressive incorporation of learned characteristics to the
genotypes, can be observed and leveraged to improve the search. The purpose of
this paper is to carry out an exper- imental study into how learning can
improve G-Prop genetic search. Two ways of combining learning and genetic
search are explored: one exploits the Baldwin effect, while the other uses a
Lamarckian strategy. Our experiments show that using a Lamarckian op- erator
makes the algorithm find networks with a low error rate, and the smallest size,
while using the Bald- win effect obtains MLPs with the smallest error rate, and
a larger size, taking longer to reach a solution. Both approaches obtain a
lower average error than other BP-based algorithms like RPROP, other evolu-
tionary methods and fuzzy logic based methods
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603005</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603005</id><created>2006-03-01</created><updated>2008-10-20</updated><authors><author><keyname>Maiti</keyname><forenames>Santanu K.</forenames></author></authors><title>A Basic Introduction on Math-Link in Mathematica</title><categories>cs.MS cs.PL</categories><comments>14 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting from the basic ideas of mathematica, we give a detailed description
about the way of linking of external programs with mathematica through proper
mathlink commands. This article may be quite helpful for the beginners to start
with and write programs in mathematica.
  In the first part, we illustrate how to use a mathemtica notebook and write a
complete program in the notebook. Following with this, we also mention
elaborately about the utility of the local and global variables those are very
essential for writing a program in mathematica. All the commands needed for
doing different mathematical operations can be found with some proper examples
in the mathematica book written by Stephen Wolfram \cite{wolfram}.
  In the rest of this article, we concentrate our study on the most significant
issue which is the process of linking of {\em external programs} with
mathematica, so-called the mathlink operation. By using proper mathlink
commands one can run very tedious jobs efficiently and the operations become
extremely fast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603006</id><created>2006-03-01</created><updated>2007-04-08</updated><authors><author><keyname>Ben-Naim</keyname><forenames>Jonathan</forenames><affiliation>LIF</affiliation></author></authors><title>Pivotal and Pivotal-discriminative Consequence Relations</title><categories>cs.LO</categories><journal-ref>Journal of Logic and Computation Volume 15, number 5 (2005)
  679-700</journal-ref><doi>10.1093/logcom/exi030</doi><abstract>  In the present paper, we investigate consequence relations that are both
paraconsistent and plausible (but still monotonic). More precisely, we put the
focus on pivotal consequence relations, i.e. those relations that can be
defined by a pivot (in the style of e.g. D. Makinson). A pivot is a fixed
subset of valuations which are considered to be the important ones in the
absolute sense. We worked with a general notion of valuation that covers e.g.
the classical valuations as well as certain kinds of many-valued valuations. In
the many-valued cases, pivotal consequence relations are paraconsistant (in
addition to be plausible), i.e. they are capable of drawing reasonable
conclusions which contain contradictions. We will provide in our general
framework syntactic characterizations of several families of pivotal relations.
In addition, we will provide, again in our general framework, characterizations
of several families of pivotal discriminative consequence relations. The latter
are defined exactly as the plain version, but contradictory conclusions are
rejected. We will also answer negatively a representation problem that was left
open by Makinson. Finally, we will put in evidence a connexion with X-logics
from Forget, Risch, and Siegel. The motivations and the framework of the
present paper are very close to those of a previous paper of the author which
is about preferential consequence relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603007</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603007</id><created>2006-03-02</created><authors><author><keyname>Abdel-Ghaffar</keyname><forenames>Khaled A. S.</forenames></author><author><keyname>Weber</keyname><forenames>Jos H.</forenames></author></authors><title>Complete Enumeration of Stopping Sets of Full-Rank Parity-Check Matrices
  of Hamming Codes</title><categories>cs.IT math.IT</categories><comments>7 pages, submitted to the IEEE Transactions on Information Theory</comments><abstract>  Stopping sets, and in particular their numbers and sizes, play an important
role in determining the performance of iterative decoders of linear codes over
binary erasure channels. In the 2004 Shannon Lecture, McEliece presented an
expression for the number of stopping sets of size three for a full-rank
parity-check matrix of the Hamming code. In this correspondence, we derive an
expression for the number of stopping sets of any given size for the same
parity-check matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603008</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603008</id><created>2006-03-01</created><updated>2006-03-10</updated><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author></authors><title>Linear Secret Sharing from Algebraic-Geometric Codes</title><categories>cs.CR cs.IT math.IT</categories><comments>11 pages, note added in the new version</comments><abstract>  It is well-known that the linear secret-sharing scheme (LSSS) can be
constructed from linear error-correcting codes (Brickell [1], R.J. McEliece and
D.V.Sarwate [2],Cramer, el.,[3]). The theory of linear codes from
algebraic-geometric curves (algebraic-geometric (AG) codes or geometric Goppa
code) has been well-developed since the work of V.Goppa and Tsfasman, Vladut,
and Zink(see [17], [18] and [19]). In this paper the linear secret-sharing
scheme from algebraic-geometric codes, which are non-threshold scheme for
curves of genus greater than 0, are presented . We analysis the minimal access
structure, $d_{min}$ and $d_{cheat}$([8]), (strongly) multiplicativity and the
applications in verifiable secret-sharing (VSS) scheme and secure multi-party
computation (MPC) of this construction([3] and [10-11]). Our construction also
offers many examples of the self-dually $GF(q)$-representable matroids and many
examples of new ideal linear secret-sharing schemes addressing to the problem
of the characterization of the access structures for ideal secret-sharing
schemes([3] and [9]). The access structures of the linear secret-sharing
schemes from the codes on elliptic curves are given explicitly. From the work
in this paper we can see that the algebraic-geometric structure of the
underlying algebraic curves is an important resource for secret-sharing,
matroid theory, verifiable secret-sharing and secure multi-party computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603009</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603009</id><created>2006-03-01</created><updated>2006-11-01</updated><authors><author><keyname>Dabora</keyname><forenames>Ron</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Servetto</keyname><forenames>Sergio D.</forenames><affiliation>Cornell University</affiliation></author></authors><title>An Achievability Result for the General Relay Channel</title><categories>cs.IT math.IT</categories><comments>This correspondence article has been folded into the revision of
  another paper of ours, cs.IT/0605135. This replacement paper explains why</comments><abstract>  See cs.IT/0605135: R. Dabora, S. D. Servetto; On the Role of
Estimate-and-Forward with Time-Sharing in Cooperative Communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603010</id><created>2006-03-02</created><authors><author><keyname>Savla</keyname><forenames>Ketan</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Asymptotic constant-factor approximation algorithm for the Traveling
  Salesperson Problem for Dubins' vehicle</title><categories>cs.RO</categories><abstract>  This article proposes the first known algorithm that achieves a
constant-factor approximation of the minimum length tour for a Dubins' vehicle
through $n$ points on the plane. By Dubins' vehicle, we mean a vehicle
constrained to move at constant speed along paths with bounded curvature
without reversing direction. For this version of the classic Traveling
Salesperson Problem, our algorithm closes the gap between previously
established lower and upper bounds; the achievable performance is of order
$n^{2/3}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603011</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603011</id><created>2006-03-02</created><authors><author><keyname>Wiesmaier</keyname><forenames>A.</forenames></author><author><keyname>Rauchschwalbe</keyname><forenames>U.</forenames></author><author><keyname>Ludwig</keyname><forenames>C.</forenames></author><author><keyname>Henhapl</keyname><forenames>B.</forenames></author><author><keyname>Ruppert</keyname><forenames>M.</forenames></author><author><keyname>Buchmann</keyname><forenames>J.</forenames></author></authors><title>Intrinsically Legal-For-Trade Objects by Digital Signatures</title><categories>cs.CR</categories><comments>4 pages, 0 figures</comments><journal-ref>Sicherheit 2006: Sicherheit -- Schutz und Zuverlaessigkeit</journal-ref><abstract>  The established techniques for legal-for-trade registration of weight values
meet the legal requirements, but in praxis they show serious disadvantages. We
report on the first implementation of intrinsically legal-for-trade objects,
namely weight values signed by the scale, that is accepted by the approval
authority. The strict requirements from both the approval- and the
verification-authority as well as the limitations due to the hardware of the
scale were a special challenge. The presented solution fulfills all legal
requirements and eliminates the existing practical disadvantages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603012</id><created>2006-03-02</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Hebbinghaus</keyname><forenames>Nils</forenames></author><author><keyname>Werth</keyname><forenames>S&#xf6;ren</forenames></author></authors><title>Improved Bounds and Schemes for the Declustering Problem</title><categories>cs.DM cs.DS</categories><comments>19 pages, 1 figure</comments><acm-class>G.2.2; E.1</acm-class><abstract>  The declustering problem is to allocate given data on parallel working
storage devices in such a manner that typical requests find their data evenly
distributed on the devices. Using deep results from discrepancy theory, we
improve previous work of several authors concerning range queries to
higher-dimensional data. We give a declustering scheme with an additive error
of $O_d(\log^{d-1} M)$ independent of the data size, where $d$ is the
dimension, $M$ the number of storage devices and $d-1$ does not exceed the
smallest prime power in the canonical decomposition of $M$ into prime powers.
In particular, our schemes work for arbitrary $M$ in dimensions two and three.
For general $d$, they work for all $M\geq d-1$ that are powers of two.
Concerning lower bounds, we show that a recent proof of a
$\Omega_d(\log^{\frac{d-1}{2}} M)$ bound contains an error. We close the gap in
the proof and thus establish the bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603013</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603013</id><created>2006-03-02</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Schneider</keyname><forenames>Gert</forenames></author></authors><title>On the MacWilliams Identity for Convolutional Codes</title><categories>cs.IT math.IT math.OC</categories><abstract>  The adjacency matrix associated with a convolutional code collects in a
detailed manner information about the weight distribution of the code. A
MacWilliams Identity Conjecture, stating that the adjacency matrix of a code
fully determines the adjacency matrix of the dual code, will be formulated, and
an explicit formula for the transformation will be stated. The formula involves
the MacWilliams matrix known from complete weight enumerators of block codes.
The conjecture will be proven for the class of convolutional codes where either
the code itself or its dual does not have Forney indices bigger than one. For
the general case the conjecture is backed up by many examples, and a weaker
version will be established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603014</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603014</id><created>2006-03-02</created><authors><author><keyname>Carvalho</keyname><forenames>C.</forenames></author><author><keyname>Munuera</keyname><forenames>C.</forenames></author><author><keyname>Silva</keyname><forenames>E.</forenames></author><author><keyname>Torres</keyname><forenames>F.</forenames></author></authors><title>Near orders and codes</title><categories>cs.IT math.IT</categories><comments>15 pages</comments><abstract>  Hoholdt, van Lint and Pellikaan used order functions to construct codes by
means of Linear Algebra and Semigroup Theory only. However, Geometric Goppa
codes that can be represented by this method are mainly those based on just one
point. In this paper we introduce the concept of near order function with the
aim of generalize this approach in such a way that a of wider family of
Geometric Goppa codes can be studied on a more elementary setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603015</id><created>2006-03-02</created><authors><author><keyname>Rajagopal</keyname><forenames>Pritam</forenames></author></authors><title>The Basic Kak Neural Network with Complex Inputs</title><categories>cs.NE</categories><comments>17 pages, 9 figures, 7 tables</comments><abstract>  The Kak family of neural networks is able to learn patterns quickly, and this
speed of learning can be a decisive advantage over other competing models in
many applications. Amongst the implementations of these networks are those
using reconfigurable networks, FPGAs and optical networks. In some
applications, it is useful to use complex data, and it is with that in mind
that this introduction to the basic Kak network with complex inputs is being
presented. The training algorithm is prescriptive and the network weights are
assigned simply upon examining the inputs. The input is mapped using quaternary
encoding for purpose of efficienty. This network family is part of a larger
hierarchy of learning schemes that include quantum models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603016</id><created>2006-03-03</created><updated>2006-11-09</updated><authors><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author><author><keyname>Somosan</keyname><forenames>S. C.</forenames></author></authors><title>Object-Oriented Modeling of Programming Paradigms</title><categories>cs.SE cs.PL</categories><comments>Re-written introduction and abstract, new title, some references
  deleted; 10 pages; 4 figures</comments><report-no>DCS-310-IR</report-no><acm-class>D.1.5; D.2.2; D.2.3; D.3.3</acm-class><abstract>  For the right application, the use of programming paradigms such as
functional or logic programming can enormously increase productivity in
software development. But these powerful paradigms are tied to exotic
programming languages, while the management of software development dictates
standardization on a single language.
  This dilemma can be resolved by using object-oriented programming in a new
way. It is conventional to analyze an application by object-oriented modeling.
In the new approach, the analysis identifies the paradigm that is ideal for the
application; development starts with object-oriented modeling of the paradigm.
In this paper we illustrate the new approach by giving examples of
object-oriented modeling of dataflow and constraint programming. These examples
suggest that it is no longer necessary to embody a programming paradigm in a
language dedicated to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603017</id><created>2006-03-03</created><updated>2006-07-20</updated><authors><author><keyname>De Naurois</keyname><forenames>Paulin Jacob&#xe9;</forenames><affiliation>LIPN</affiliation></author></authors><title>A Measure of Space for Computing over the Reals</title><categories>cs.CC</categories><proxy>ccsd ccsd-00020024</proxy><journal-ref>Logical Approaches to Computational Barriers Second Conference on
  Computability in Europe, CiE 2006, Royaume-Uni (2006) 231-240</journal-ref><abstract>  We propose a new complexity measure of space for the BSS model of
computation. We define LOGSPACE\_W and PSPACE\_W complexity classes over the
reals. We prove that LOGSPACE\_W is included in NC^2\_R and in P\_W, i.e. is
small enough for being relevant. We prove that the Real Circuit Decision
Problem is P\_R-complete under LOGSPACE\_W reductions, i.e. that LOGSPACE\_W is
large enough for containing natural algorithms. We also prove that PSPACE\_W is
included in PAR\_R.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603018</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603018</id><created>2006-03-03</created><authors><author><keyname>Ray</keyname><forenames>Siddharth</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Zheng</keyname><forenames>Lizhong</forenames></author></authors><title>On Non-coherent MIMO Channels in the Wideband Regime: Capacity and
  Reliability</title><categories>cs.IT math.IT</categories><abstract>  We consider a multiple-input, multiple-output (MIMO) wideband Rayleigh block
fading channel where the channel state is unknown to both the transmitter and
the receiver and there is only an average power constraint on the input. We
compute the capacity and analyze its dependence on coherence length, number of
antennas and receive signal-to-noise ratio (SNR) per degree of freedom. We
establish conditions on the coherence length and number of antennas for the
non-coherent channel to have a &quot;near coherent&quot; performance in the wideband
regime. We also propose a signaling scheme that is near-capacity achieving in
this regime.
  We compute the error probability for this wideband non-coherent MIMO channel
and study its dependence on SNR, number of transmit and receive antennas and
coherence length. We show that error probability decays inversely with
coherence length and exponentially with the product of the number of transmit
and receive antennas. Moreover, channel outage dominates error probability in
the wideband regime. We also show that the critical as well as cut-off rates
are much smaller than channel capacity in this regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603019</id><created>2006-03-05</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Rego</keyname><forenames>Leandro Chaves</forenames></author></authors><title>Characterizing the NP-PSPACE Gap in the Satisfiability Problem for Modal
  Logic</title><categories>cs.LO cs.CC</categories><comments>6 pages</comments><abstract>  There has been a great of work on characterizing the complexity of the
satisfiability and validity problem for modal logics. In particular, Ladner
showed that the validity problem for all logics between K, T, and S4 is {\sl
PSPACE}-complete, while for S5 it is {\sl NP}-complete. We show that, in a
precise sense, it is \emph{negative introspection}, the axiom $\neg K p \rimp K
\neg K p$, that causes the gap. In a precise sense, if we require this axiom,
then the satisfiability problem is {\sl NP}-complete; without it, it is {\sl
PSPACE}-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603020</id><created>2006-03-05</created><authors><author><keyname>halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Rego</keyname><forenames>Leandro Chaves</forenames></author></authors><title>Reasoning About Knowledge of Unawareness</title><categories>cs.LO cs.MA</categories><comments>32 pages</comments><abstract>  Awareness has been shown to be a useful addition to standard epistemic logic
for many applications. However, standard propositional logics for knowledge and
awareness cannot express the fact that an agent knows that there are facts of
which he is unaware without there being an explicit fact that the agent knows
he is unaware of. We propose a logic for reasoning about knowledge of
unawareness, by extending Fagin and Halpern's \emph{Logic of General
Awareness}. The logic allows quantification over variables, so that there is a
formula in the language that can express the fact that ``an agent explicitly
knows that there exists a fact of which he is unaware''. Moreover, that formula
can be true without the agent explicitly knowing that he is unaware of any
particular formula. We provide a sound and complete axiomatization of the
logic, using standard axioms from the literature to capture the quantification
operator. Finally, we show that the validity problem for the logic is
recursively enumerable, but not decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603021</id><created>2006-03-05</created><authors><author><keyname>Mukherjee</keyname><forenames>Joy</forenames></author><author><keyname>Varadarajan</keyname><forenames>Srinidhi</forenames></author></authors><title>Language Support for Optional Functionality</title><categories>cs.PL cs.OS cs.SE</categories><comments>6 pages, 8 figures</comments><abstract>  We recommend a programming construct - availability check - for programs that
need to automatically adjust to presence or absence of segments of code. The
idea is to check the existence of a valid definition before a function call is
invoked. The syntax is that of a simple 'if' statement. The vision is to enable
customization of application functionality through addition or removal of
optional components, but without requiring complete re-building. Focus is on
C-like compiled procedural languages and UNIX-based systems. Essentially, our
approach attempts to combine the flexibility of dynamic libraries with the
usability of utility (dependency) libraries. We outline the benefits over
prevalent strategies mainly in terms of development complexity, crudely
measured as lesser lines of code. We also allude to performance and flexibility
facets. A Preliminary implementation and figures from early experimental
evaluation are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603022</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603022</id><created>2006-03-06</created><authors><author><keyname>Ray</keyname><forenames>Siddharth</forenames></author><author><keyname>Effros</keyname><forenames>Michelle</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author><author><keyname>Karger</keyname><forenames>David</forenames></author><author><keyname>Abounadi</keyname><forenames>Jinane</forenames></author></authors><title>On Separation, Randomness and Linearity for Network Codes over Finite
  Fields</title><categories>cs.IT math.IT</categories><report-no>MIT LIDS Technical Report 2687</report-no><abstract>  We examine the issue of separation and code design for networks that operate
over finite fields. We demonstrate that source-channel (or source-network)
separation holds for several canonical network examples like the noisy multiple
access channel and the erasure degraded broadcast channel, when the whole
network operates over a common finite field. This robustness of separation is
predicated on the fact that noise and inputs are independent, and we examine
the failure of separation when noise is dependent on inputs in multiple access
channels.
  Our approach is based on the sufficiency of linear codes. Using a simple and
unifying framework, we not only re-establish with economy the optimality of
linear codes for single-transmitter, single-receiver channels and for
Slepian-Wolf source coding, but also establish the optimality of linear codes
for multiple access and for erasure degraded broadcast channels. The linearity
allows us to obtain simple optimal code constructions and to study capacity
regions of the noisy multiple access and the degraded broadcast channel. The
linearity of both source and network coding blurs the delineation between
source and network codes. While our results point to the fact that separation
of source coding and channel coding is optimal in some canonical networks, we
show that decomposing networks into canonical subnetworks may not be effective.
Thus, we argue that it may be the lack of decomposability of a network into
canonical network modules, rather than the lack of separation between source
and channel coding, that presents major challenges for coding over networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603023</id><created>2006-03-07</created><authors><author><keyname>Zhumatiy</keyname><forenames>Viktor</forenames></author><author><keyname>Gomez</keyname><forenames>Faustino</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Metric State Space Reinforcement Learning for a Vision-Capable Mobile
  Robot</title><categories>cs.RO cs.LG</categories><comments>14 pages, 8 figures</comments><report-no>IDSIA-05-06</report-no><journal-ref>Proc. 9th International Conf. on Intelligent Autonomous Systems
  (IAS 2006) pages 272-281</journal-ref><abstract>  We address the problem of autonomously learning controllers for
vision-capable mobile robots. We extend McCallum's (1995) Nearest-Sequence
Memory algorithm to allow for general metrics over state-action trajectories.
We demonstrate the feasibility of our approach by successfully running our
algorithm on a real mobile robot. The algorithm is novel and unique in that it
(a) explores the environment and learns directly on a mobile robot without
using a hand-made computer model as an intermediate step, (b) does not require
manual discretization of the sensor input space, (c) works in piecewise
continuous perceptual spaces, and (d) copes with partial observability.
Together this allows learning from much less experience compared to previous
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603024</id><created>2006-03-07</created><authors><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author><author><keyname>Krafft</keyname><forenames>Dean</forenames></author><author><keyname>Cornwell</keyname><forenames>Tim</forenames></author><author><keyname>Eckstrom</keyname><forenames>Dean</forenames></author><author><keyname>Jesuroga</keyname><forenames>Susan</forenames></author><author><keyname>Wilper</keyname><forenames>Chris</forenames></author></authors><title>Representing Contextualized Information in the NSDL</title><categories>cs.DL</categories><acm-class>H.3.7</acm-class><abstract>  The NSDL (National Science Digital Library) is funded by the National Science
Foundation to advance science and match education. The inital product was a
metadata-based digital library providing search and access to distributed
resources. Our recent work recognizes the importance of context - relations,
metadata, annotations - for the pedagogical value of a digital library. This
new architecture uses Fedora, a tool for representing complex content, data,
metadata, web-based services, and semantic relationships, as the basis of an
information network overlay (INO). The INO provides an extensible knowl-edge
base for an expanding suite of digital library services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603025</id><created>2006-03-07</created><updated>2007-02-25</updated><authors><author><keyname>Heymans</keyname><forenames>Stijn</forenames></author><author><keyname>Van Nieuwenborgh</keyname><forenames>Davy</forenames></author><author><keyname>Vermeir</keyname><forenames>Dirk</forenames></author></authors><title>Open Answer Set Programming with Guarded Programs</title><categories>cs.AI</categories><comments>51 pages, 1 figure, accepted for publication in ACM's TOCL</comments><acm-class>I.2.3; I.2.4</acm-class><abstract>  Open answer set programming (OASP) is an extension of answer set programming
where one may ground a program with an arbitrary superset of the program's
constants. We define a fixed point logic (FPL) extension of Clark's completion
such that open answer sets correspond to models of FPL formulas and identify a
syntactic subclass of programs, called (loosely) guarded programs. Whereas
reasoning with general programs in OASP is undecidable, the FPL translation of
(loosely) guarded programs falls in the decidable (loosely) guarded fixed point
logic (mu(L)GF). Moreover, we reduce normal closed ASP to loosely guarded OASP,
enabling for the first time, a characterization of an answer set semantics by
muLGF formulas. We further extend the open answer set semantics for programs
with generalized literals. Such generalized programs (gPs) have interesting
properties, e.g., the ability to express infinity axioms. We restrict the
syntax of gPs such that both rules and generalized literals are guarded. Via a
translation to guarded fixed point logic, we deduce 2-exptime-completeness of
satisfiability checking in such guarded gPs (GgPs). Bound GgPs are restricted
GgPs with exptime-complete satisfiability checking, but still sufficiently
expressive to optimally simulate computation tree logic (CTL). We translate
Datalog lite programs to GgPs, establishing equivalence of GgPs under an open
answer set semantics, alternation-free muGF, and Datalog lite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603026</id><created>2006-03-07</created><authors><author><keyname>Arkin</keyname><forenames>Esther M.</forenames><affiliation>Department of Applied Mathematics and Statistics, Stony Brook University</affiliation></author><author><keyname>Bender</keyname><forenames>Michael A.</forenames><affiliation>Department of Computer Science, Stony Brook University</affiliation></author><author><keyname>Mitchell</keyname><forenames>Joseph S. B.</forenames><affiliation>Department of Applied Mathematics and Statistics, Stony Brook University</affiliation></author><author><keyname>Polishchuk</keyname><forenames>Valentin</forenames><affiliation>Department of Applied Mathematics and Statistics, Stony Brook University</affiliation></author></authors><title>The Snowblower Problem</title><categories>cs.DS cs.CC cs.RO</categories><comments>19 pages, 10 figures, 1 table. Submitted to WAFR 2006</comments><acm-class>F.2.2; I.3.5</acm-class><abstract>  We introduce the snowblower problem (SBP), a new optimization problem that is
closely related to milling problems and to some material-handling problems. The
objective in the SBP is to compute a short tour for the snowblower to follow to
remove all the snow from a domain (driveway, sidewalk, etc.). When a snowblower
passes over each region along the tour, it displaces snow into a nearby region.
The constraint is that if the snow is piled too high, then the snowblower
cannot clear the pile.
  We give an algorithmic study of the SBP. We show that in general, the problem
is NP-complete, and we present polynomial-time approximation algorithms for
removing snow under various assumptions about the operation of the snowblower.
Most commercially-available snowblowers allow the user to control the direction
in which the snow is thrown. We differentiate between the cases in which the
snow can be thrown in any direction, in any direction except backwards, and
only to the right. For all cases, we give constant-factor approximation
algorithms; the constants increase as the throw direction becomes more
restricted.
  Our results are also applicable to robotic vacuuming (or lawnmowing) with
bounded capacity dust bin and to some versions of material-handling problems,
in which the goal is to rearrange cartons on the floor of a warehouse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603027</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603027</id><created>2006-03-07</created><authors><author><keyname>Wang</keyname><forenames>Shuangquan</forenames></author><author><keyname>Abdi</keyname><forenames>Ali</forenames></author></authors><title>On the Second-Order Statistics of the Instantaneous Mutual Information
  in Rayleigh Fading Channels</title><categories>cs.IT math.IT</categories><comments>11 pages, 6 figures, submitted to IEEE Trans. Inform. Theory, Dec.
  2005</comments><abstract>  In this paper, the second-order statistics of the instantaneous mutual
information are studied, in time-varying Rayleigh fading channels, assuming
general non-isotropic scattering environments. Specifically, first the
autocorrelation function, correlation coefficient, level crossing rate, and the
average outage duration of the instantaneous mutual information are
investigated in single-input single-output (SISO) systems. Closed-form exact
expressions are derived, as well as accurate approximations in low- and
high-SNR regimes. Then, the results are extended to multiple-input
single-output and single-input multiple-output systems, as well as
multiple-input multiple-output systems with orthogonal space-time block code
transmission. Monte Carlo simulations are provided to verify the accuracy of
the analytical results. The results shed more light on the dynamic behavior of
the instantaneous mutual information in mobile fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603028</id><created>2006-03-08</created><authors><author><keyname>Janssen</keyname><forenames>Wim</forenames></author><author><keyname>Korlyukov</keyname><forenames>Alexandr</forenames></author><author><keyname>Bussche</keyname><forenames>Jan Van den</forenames></author></authors><title>On the tree-transformation power of XSLT</title><categories>cs.PL cs.DB</categories><acm-class>D.3.1; H.2.3; F.1.1</acm-class><journal-ref>Acta Informatica, Volume 43, Number 6 / January, 2007</journal-ref><doi>10.1007/s00236-006-0026-8</doi><abstract>  XSLT is a standard rule-based programming language for expressing
transformations of XML data. The language is currently in transition from
version 1.0 to 2.0. In order to understand the computational consequences of
this transition, we restrict XSLT to its pure tree-transformation capabilities.
Under this focus, we observe that XSLT~1.0 was not yet a computationally
complete tree-transformation language: every 1.0 program can be implemented in
exponential time. A crucial new feature of version~2.0, however, which allows
nodesets over temporary trees, yields completeness. We provide a formal
operational semantics for XSLT programs, and establish confluence for this
semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603029</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603029</id><created>2006-03-08</created><updated>2006-09-02</updated><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author></authors><title>A d-Sequence based Recursive Random Number Generator</title><categories>cs.CR</categories><comments>7 pages</comments><report-no>2006/310 Cryptology ePrint Archive</report-no><journal-ref>Proceedings of International Symposium on System and Information
  Security -- Sao Jose dos Campos: CTA/ITA/IEC, 2006. 542p</journal-ref><abstract>  This paper proposes a new recursive technique using d-sequences to generate
random numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603030</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603030</id><created>2006-03-08</created><authors><author><keyname>Adams</keyname><forenames>Jonathan K.</forenames></author></authors><title>A Service-Centric Approach to a Parameterized RBAC Service</title><categories>cs.CR</categories><acm-class>D.4.6</acm-class><journal-ref>In Proceedings of the 5th WSEAS International Conference on
  Applied Computer Science (ACOS 2006)</journal-ref><abstract>  Significant research has been done in the area of Role Based Access Control
[RBAC]. Within this research there has been a thread of work focusing on adding
parameters to the role and permissions within RBAC. The primary benefit of
parameter support in RBAC comes in the form of a significant increase in
specificity in how permissions may be granted. This paper focuses on
implementing a parameterized implementation based heavily upon existing
standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603031</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603031</id><created>2006-03-08</created><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>Youjian</forenames></author><author><keyname>Rider</keyname><forenames>Brian</forenames></author></authors><title>Performance Analysis of CDMA Signature Optimization with Finite Rate
  Feedback</title><categories>cs.IT cs.DM math.IT</categories><comments>6 pages, 3 figures, conference paper for CISS 2006</comments><abstract>  We analyze the performance of CDMA signature optimization with finite rate
feedback. For a particular user, the receiver selects a signature vector from a
signature codebook to avoid the interference from other users, and feeds the
corresponding index back to this user through a finite rate and error-free
feedback link. We assume the codebook is randomly constructed where the entries
are independent and isotropically distributed. It has been shown that the
randomly constructed codebook is asymptotically optimal. In this paper, we
consider two types of signature selection criteria. One is to select the
signature vector that minimizes the interference from other users. The other
one is to select the signature vector to match the weakest interference
directions. By letting the processing gain, number of users and feedback bits
approach infinity with fixed ratios, we derive the exact asymptotic formulas to
calculate the average interference for both criteria. Our simulations
demonstrate the theoretical formulas. The analysis can be extended to evaluate
the signal-to-interference plus noise ratio performance for both match filter
and linear minimum mean-square error receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603032</id><created>2006-03-09</created><updated>2006-04-08</updated><authors><author><keyname>Lahiri</keyname><forenames>Somdeb</forenames></author></authors><title>Market Equilibrium for Bundle Auctions and the Matching Core of
  Nonnegative TU Games</title><categories>cs.GT</categories><comments>17 pages</comments><abstract>  We discuss bundle auctions within the framework of an integer allocation
problem. We show that for multi-unit auctions, of which bundle auctions are a
special case, market equilibrium and constrained market equilibrium are
equivalent concepts. This equivalence, allows us to obtain a computable
necessary and sufficient condition for the existence of constrained market
equilibrium for bundle auctions. We use this result to obtain a necessary and
sufficient condition for the existence of market equilibrium for multi-unit
auctions. After obtaining the induced bundle auction of a nonnegative TU game,
we show that the existence of market equilibrium implies the existence of a
possibly different market equilibrium as well, which corresponds very naturally
to an outcome in the matching core of the TU game. Consequently we show that
the matching core of the nonnegative TU game is non-empty if and only if the
induced market game has a market equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603033</id><created>2006-03-09</created><authors><author><keyname>Petrosyan</keyname><forenames>Vaghinak</forenames></author></authors><title>Inter-component communication methods in object-oriented frameworks</title><categories>cs.SE</categories><abstract>  Modern frameworks for development of graphical interfaces are using the
native controls of the operating system. Because of that they are using
operating system events model for inter-component communication. We consider a
method to increase inter-component communication speed by sending messages from
one component to the other passing over the operating system. Besides the
messages subscription helps to avoid receiving of unnecessary messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603034</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603034</id><created>2006-03-09</created><authors><author><keyname>Herzig</keyname><forenames>Andreas</forenames></author><author><keyname>Varzinczak</keyname><forenames>Ivan</forenames></author></authors><title>Metatheory of actions: beyond consistency</title><categories>cs.AI</categories><abstract>  Consistency check has been the only criterion for theory evaluation in
logic-based approaches to reasoning about actions. This work goes beyond that
and contributes to the metatheory of actions by investigating what other
properties a good domain description in reasoning about actions should have. We
state some metatheoretical postulates concerning this sore spot. When all
postulates are satisfied together we have a modular action theory. Besides
being easier to understand and more elaboration tolerant in McCarthy's sense,
modular theories have interesting properties. We point out the problems that
arise when the postulates about modularity are violated and propose algorithmic
checks that can help the designer of an action theory to overcome them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603035</id><created>2006-03-09</created><updated>2006-03-11</updated><authors><author><keyname>Del Frate</keyname><forenames>Chiara</forenames></author><author><keyname>Galvez</keyname><forenames>Jose</forenames></author><author><keyname>Hauer</keyname><forenames>Tamas</forenames></author><author><keyname>Manset</keyname><forenames>David</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Odeh</keyname><forenames>Mohammed</forenames></author><author><keyname>Rogulin</keyname><forenames>Dmitry</forenames></author><author><keyname>Solomonides</keyname><forenames>Tony</forenames></author><author><keyname>Warren</keyname><forenames>Ruth</forenames></author></authors><title>Final Results from and Exploitation Plans for MammoGrid</title><categories>cs.DC</categories><comments>11 pages, 3 figures, 2 tables. Accepted at the 4th International
  HealthGrid conference, Valencia Spain June 2006</comments><acm-class>H.2.4; J.3</acm-class><abstract>  The MammoGrid project has delivered the first deployed instance of a
healthgrid for clinical mammography that spans national boundaries. During the
last year, the final MammoGrid prototype has undergone a series of rigorous
tests undertaken by radiologists in the UK and Italy and this paper draws
conclusions from those tests for the benefit of the Healthgrid community. In
addition, lessons learned during the lifetime of the project are detailed and
recommendations drawn for future health applications using grids. Following the
completion of the project, plans have been put in place for the
commercialisation of the MammoGrid system and this is also reported in this
article. Particular emphasis is placed on the issues surrounding the transition
from collaborative research project to a marketable product. This paper
concludes by highlighting some of the potential areas of future development and
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603036</id><created>2006-03-09</created><updated>2006-03-11</updated><authors><author><keyname>Freund</keyname><forenames>Joerg</forenames><affiliation>Sean</affiliation></author><author><keyname>Comaniciu</keyname><forenames>Dorin</forenames><affiliation>Sean</affiliation></author><author><keyname>Ioannis</keyname><forenames>Yannis</forenames><affiliation>Sean</affiliation></author><author><keyname>Liu</keyname><forenames>Peiya</forenames><affiliation>Sean</affiliation></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames><affiliation>Sean</affiliation></author><author><keyname>Morley-Fletcher</keyname><forenames>Edwin</forenames><affiliation>Sean</affiliation></author><author><keyname>Pennec</keyname><forenames>Xavier</forenames><affiliation>Sean</affiliation></author><author><keyname>Pongiglione</keyname><forenames>Giacomo</forenames><affiliation>Sean</affiliation></author><author><keyname>Xiang</keyname><affiliation>Sean</affiliation></author><author><keyname>ZHOU</keyname></author></authors><title>Health-e-Child : An Integrated Biomedical Platform for Grid-Based
  Paediatric Applications</title><categories>cs.DC</categories><comments>12 pages, 2 figures. Accepted at the 4th International HealthGrid
  conference, Valencia, Spain June 2006</comments><acm-class>H.2.4; J.2</acm-class><abstract>  There is a compelling demand for the integration and exploitation of
heterogeneous biomedical information for improved clinical practice, medical
research, and personalised healthcare across the EU. The Health-e-Child project
aims at developing an integrated healthcare platform for European Paediatrics,
providing seamless integration of traditional and emerging sources of
biomedical information. The long-term goal of the project is to provide
uninhibited access to universal biomedical knowledge repositories for
personalised and preventive healthcare, large-scale information-based
biomedical research and training, and informed policy making. The project focus
will be on individualised disease prevention, screening, early diagnosis,
therapy and follow-up of paediatric heart diseases, inflammatory diseases, and
brain tumours. The project will build a Grid-enabled European network of
leading clinical centres that will share and annotate biomedical data, validate
systems clinically, and diffuse clinical excellence across Europe by setting up
new technologies, clinical workflows, and standards. This paper outlines the
design approach being adopted in Health-e-Child to enable the delivery of an
integrated biomedical information platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603037</id><created>2006-03-09</created><authors><author><keyname>El-Ghalayini</keyname><forenames>Haya</forenames></author><author><keyname>Odeh</keyname><forenames>Mohammed</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author></authors><title>Deriving Conceptual Data Models from Domain Ontologies for
  Bioinformatics</title><categories>cs.SE</categories><comments>6 pages, 1 figure. The 2nd international conference on Information
  and Communication Technologies from Theory to Application (ICTTA06)</comments><acm-class>D.2.11</acm-class><abstract>  This paper studies the role that ontologies can play in establishing
conceptual data models during the process of information systems development. A
mapping algorithm has been proposed and embedded in a special purpose
Transformation-Engine to generate a conceptual data model from a given domain
ontology. In addition, this paper focuses on applying the proposed approach to
a bioinformatics context as the nature of biological data is considered a
barrier in representing biological conceptual data models. Both quantitative
and qualitative methods have been adopted to critically evaluate this new
approach. The results of this evaluation indicate that the quality of the
generated conceptual data models can reflect the problem domain entities and
the associations between them. The results are encouraging and support the
potential role that this approach can play in providing a suitable starting
point for conceptual data model development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603038</id><created>2006-03-09</created><updated>2006-05-22</updated><authors><author><keyname>Hoyer</keyname><forenames>Patrik O.</forenames></author><author><keyname>Shimizu</keyname><forenames>Shohei</forenames></author><author><keyname>Kerminen</keyname><forenames>Antti J.</forenames></author></authors><title>Estimation of linear, non-gaussian causal models in the presence of
  confounding latent variables</title><categories>cs.AI</categories><comments>8 pages, 4 figures, pdflatex</comments><abstract>  The estimation of linear causal models (also known as structural equation
models) from data is a well-known problem which has received much attention in
the past. Most previous work has, however, made an explicit or implicit
assumption of gaussianity, limiting the identifiability of the models. We have
recently shown (Shimizu et al, 2005; Hoyer et al, 2006) that for non-gaussian
distributions the full causal model can be estimated in the no hidden variables
case. In this contribution, we discuss the estimation of the model when
confounding latent variables are present. Although in this case uniqueness is
no longer guaranteed, there is at most a finite set of models which can fit the
data. We develop an algorithm for estimating this set, and describe numerical
simulations which confirm the theoretical arguments and demonstrate the
practical viability of the approach. Full Matlab code is provided for all
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603039</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603039</id><created>2006-03-09</created><updated>2006-05-15</updated><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>Youjian</forenames></author><author><keyname>Rider</keyname><forenames>Brian</forenames></author></authors><title>Quantization Bounds on Grassmann Manifolds and Applications to MIMO
  Communications</title><categories>cs.IT math.IT</categories><comments>26 pages, 7 figures, submitted to IEEE Transactions on Information
  Theory in Aug, 2005</comments><abstract>  This paper considers the quantization problem on the Grassmann manifold
\mathcal{G}_{n,p}, the set of all p-dimensional planes (through the origin) in
the n-dimensional Euclidean space. The chief result is a closed-form formula
for the volume of a metric ball in the Grassmann manifold when the radius is
sufficiently small. This volume formula holds for Grassmann manifolds with
arbitrary dimension n and p, while previous results pertained only to p=1, or a
fixed p with asymptotically large n. Based on this result, several quantization
bounds are derived for sphere packing and rate distortion tradeoff. We
establish asymptotically equivalent lower and upper bounds for the rate
distortion tradeoff. Since the upper bound is derived by constructing random
codes, this result implies that the random codes are asymptotically optimal.
The above results are also extended to the more general case, in which
\mathcal{G}_{n,q} is quantized through a code in \mathcal{G}_{n,p}, where p and
q are not necessarily the same. Finally, we discuss some applications of the
derived results to multi-antenna communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603040</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603040</id><created>2006-03-09</created><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>Youjian</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Rider</keyname><forenames>Brian</forenames></author></authors><title>On the Information Rate of MIMO Systems with Finite Rate Channel State
  Feedback Using Beamforming and Power On/Off Strategy</title><categories>cs.IT math.IT</categories><comments>44 pages, 8 figures, submitted to IEEE Transactions on Information
  Theory in 2005</comments><abstract>  It is well known that Multiple-Input Multiple-Output (MIMO) systems have high
spectral efficiency, especially when channel state information at the
transmitter (CSIT) is available. When CSIT is obtained by feedback, it is
practical to assume that the channel state feedback rate is finite and the CSIT
is not perfect. For such a system, we consider beamforming and power on/off
strategy for its simplicity and near optimality, where power on/off means that
a beamforming vector (beam) is either turned on with a constant power or turned
off. The main contribution of this paper is to accurately evaluate the
information rate as a function of the channel state feedback rate. Name a beam
turned on as an on-beam and the minimum number of the transmit and receive
antennas as the dimension of a MIMO system. We prove that the ratio of the
optimal number of on-beams and the system dimension converges to a constant for
a given signal-to-noise ratio (SNR) when the numbers of transmit and receive
antennas approach infinity simultaneously and when beamforming is perfect.
Asymptotic formulas are derived to evaluate this ratio and the corresponding
information rate per dimension. The asymptotic results can be accurately
applied to finite dimensional systems and suggest a power on/off strategy with
a constant number of on-beams. For this suboptimal strategy, we take a novel
approach to introduce power efficiency factor, which is a function of the
feedback rate, to quantify the effect of imperfect beamforming. By combining
power efficiency factor and the asymptotic formulas for perfect beamforming
case, the information rate of the power on/off strategy with a constant number
of on-beams is accurately characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603041</id><created>2006-03-09</created><authors><author><keyname>Hemachander</keyname><forenames>S.</forenames></author><author><keyname>Verma</keyname><forenames>Amit</forenames></author><author><keyname>Arora</keyname><forenames>Siddharth</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author></authors><title>Locally Adaptive Block Thresholding Method with Continuity Constraint</title><categories>cs.CV</categories><comments>12 Pages, 4 figures, 1 Table</comments><abstract>  We present an algorithm that enables one to perform locally adaptive block
thresholding, while maintaining image continuity. Images are divided into
sub-images based some standard image attributes and thresholding technique is
employed over the sub-images. The present algorithm makes use of the thresholds
of neighboring sub-images to calculate a range of values. The image continuity
is taken care by choosing the threshold of the sub-image under consideration to
lie within the above range. After examining the average range values for
various sub-image sizes of a variety of images, it was found that the range of
acceptable threshold values is substantially high, justifying our assumption of
exploiting the freedom of range for bringing out local details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603042</id><created>2006-03-09</created><authors><author><keyname>Scott</keyname><forenames>Willie L.</forenames><suffix>II</suffix></author></authors><title>The NoN Approach to Autonomic Face Recognition</title><categories>cs.NE</categories><comments>15 pages, 6 figures, 6 tables</comments><abstract>  A method of autonomic face recognition based on the biologically plausible
network of networks (NoN) model of information processing is presented. The NoN
model is based on locally parallel and globally coordinated transformations in
which the neurons or computational units form distributed networks, which
themselves link to form larger networks. This models the structures in the
cerebral cortex described by Mountcastle and the architecture based on that
proposed for information processing by Sutton. In the proposed implementation,
face images are processed by a nested family of locally operating networks
along with a hierarchically superior network that classifies the information
from each of the local networks. The results of the experiments yielded a
maximum of 98.5% recognition accuracy and an average of 97.4% recognition
accuracy on a benchmark database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603043</id><created>2006-03-10</created><authors><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>Time-Space Trade-Offs for Predecessor Search</title><categories>cs.CC cs.DS</categories><comments>29 pages. Full version (preliminary) of a paper appearing in STOC'06</comments><acm-class>F.2.3; E.2</acm-class><abstract>  We develop a new technique for proving cell-probe lower bounds for static
data structures. Previous lower bounds used a reduction to communication games,
which was known not to be tight by counting arguments. We give the first lower
bound for an explicit problem which breaks this communication complexity
barrier. In addition, our bounds give the first separation between polynomial
and near linear space. Such a separation is inherently impossible by
communication complexity.
  Using our lower bound technique and new upper bound constructions, we obtain
tight bounds for searching predecessors among a static set of integers. Given a
set Y of n integers of l bits each, the goal is to efficiently find
predecessor(x) = max{y in Y | y &lt;= x}, by representing Y on a RAM using space
S.
  In external memory, it follows that the optimal strategy is to use either
standard B-trees, or a RAM algorithm ignoring the larger block size. In the
important case of l = c*lg n, for c&gt;1 (i.e. polynomial universes), and near
linear space (such as S = n*poly(lg n)), the optimal search time is Theta(lg
l). Thus, our lower bound implies the surprising conclusion that van Emde Boas'
classic data structure from [FOCS'75] is optimal in this case. Note that for
space n^{1+eps}, a running time of O(lg l / lglg l) was given by Beame and Fich
[STOC'99].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603044</id><created>2006-03-10</created><updated>2006-03-14</updated><authors><author><keyname>Spight</keyname><forenames>Marshall</forenames></author><author><keyname>Tropashko</keyname><forenames>Vadim</forenames></author></authors><title>First Steps in Relational Lattice</title><categories>cs.DB</categories><comments>11 pages, 3 figures</comments><abstract>  Relational lattice reduces the set of six classic relational algebra
operators to two binary lattice operations: natural join and inner union. We
give an introduction to this theory with emphasis on formal algebraic laws. New
results include Spight distributivity criteria and its applications to query
transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603045</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603045</id><created>2006-03-10</created><authors><author><keyname>Nedurumalli</keyname><forenames>Balaji</forenames></author></authors><title>Information and Errors in Quantum Teleportation</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><abstract>  This article considers the question of the teleportation protocol from an
engineering perspective. The protocol ideally requires an authority that
ensures that the two communicating parties have a perfectly entangled pair of
particles available to them. But this cannot be unconditionally established to
the satisfaction of the parties due to the fact that an unknown quantum state
cannot be copied. This supports the view that quantum information cannot be
treated on the same basis as classical information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603046</id><created>2006-03-10</created><authors><author><keyname>Perkins</keyname><forenames>William</forenames></author></authors><title>Trusted Certificates in Quantum Cryptography</title><categories>cs.CR</categories><comments>4 pages, 2 figures</comments><abstract>  This paper analyzes the performance of Kak's three stage quantum
cryptographic protocol based on public key cryptography against a
man-in-the-middle attack. A method for protecting against such an attack is
presented using certificates distributed by a trusted third party.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603047</id><created>2006-03-12</created><updated>2006-03-31</updated><authors><author><keyname>Mancini</keyname><forenames>Stefano</forenames></author><author><keyname>Severini</keyname><forenames>Simone</forenames></author></authors><title>The Quantum Separability Problem for Gaussian States</title><categories>cs.CC quant-ph</categories><comments>8 pages</comments><journal-ref>Electronic Notes in Theoretical Computer Science, Volume 169 ,
  March 2007, pp. 121-131</journal-ref><doi>10.1016/j.entcs.2006.07.034</doi><abstract>  Determining whether a quantum state is separable or entangled is a problem of
fundamental importance in quantum information science. This is a brief review
in which we consider the problem for states in infinite dimensional Hilbert
spaces. We show how the problem becomes tractable for a class of Gaussian
states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603048</id><created>2006-03-13</created><authors><author><keyname>Xuan</keyname><forenames>Binh Minh Bui</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Habib</keyname><forenames>Michel</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Limouzy</keyname><forenames>Vincent</forenames><affiliation>LIAFA</affiliation></author><author><keyname>De Montgolfier</keyname><forenames>Fabien</forenames><affiliation>LIAFA</affiliation></author></authors><title>Homogeneity vs. Adjacency: generalising some graph decomposition
  algorithms</title><categories>cs.DS</categories><comments>soumis \`{a} WG 2006</comments><proxy>ccsd ccsd-00020188</proxy><acm-class>G.2.2</acm-class><journal-ref>Graph-Theoretic Concepts in Computer Science Springer (Ed.)
  (22/06/2006) 278-288</journal-ref><doi>10.1007/11917496\_25</doi><abstract>  In this paper, a new general decomposition theory inspired from modular graph
decomposition is presented. Our main result shows that, within this general
theory, most of the nice algorithmic tools developed for modular decomposition
are still efficient. This theory not only unifies the usual modular
decomposition generalisations such as modular decomposition of directed graphs
or decomposition of 2-structures, but also star cutsets and bimodular
decomposition. Our general framework provides a decomposition algorithm which
improves the best known algorithms for bimodular decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603049</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603049</id><created>2006-03-13</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Schneider</keyname><forenames>Gert</forenames></author></authors><title>State Space Realizations and Monomial Equivalence for Convolutional
  Codes</title><categories>cs.IT math.IT math.OC</categories><abstract>  We will study convolutional codes with the help of state space realizations.
It will be shown that two such minimal realizations belong to the same code if
and only if they are equivalent under the full state feedback group. This
result will be used in order to prove that two codes with positive Forney
indices are monomially equivalent if and only if they share the same adjacency
matrix. The adjacency matrix counts in a detailed way the weights of all
possible outputs and thus contains full information about the weights of the
codewords in the given code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603050</id><created>2006-03-13</created><authors><author><keyname>Cegielski</keyname><forenames>Patrick</forenames><affiliation>LACL</affiliation></author><author><keyname>Guessarian</keyname><forenames>Irene</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Matiyasevich</keyname><forenames>Yuri</forenames><affiliation>PDMI</affiliation></author></authors><title>Multiple serial episode matching</title><categories>cs.DS</categories><comments>12</comments><proxy>ccsd ccsd-00020564</proxy><acm-class>F.2.2</acm-class><journal-ref>CSIT05 (2005) 26-38</journal-ref><abstract>  In a previous paper we generalized the Knuth-Morris-Pratt (KMP) pattern
matching algorithm and defined a non-conventional kind of RAM, the MP--RAMs
(RAMS equipped with extra operations), and designed an O(n) on-line algorithm
for solving the serial episode matching problem on MP--RAMs when there is only
one single episode. We here give two extensions of this algorithm to the case
when we search for several patterns simultaneously and compare them. More
preciseley, given $q+1$ strings (a text $t$ of length $n$ and $q$ patterns
$m\_1,...,m\_q$) and a natural number $w$, the {\em multiple serial episode
matching problem} consists in finding the number of size $w$ windows of text
$t$ which contain patterns $m\_1,...,m\_q$ as subsequences, i.e. for each
$m\_i$, if $m\_i=p\_1,..., p\_k$, the letters $p\_1,..., p\_k$ occur in the
window, in the same order as in $m\_i$, but not necessarily consecutively (they
may be interleaved with other letters).} The main contribution is an algorithm
solving this problem on-line in time $O(nq)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603051</id><created>2006-03-13</created><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Transitive trust in mobile scenarios</title><categories>cs.CR</categories><comments>Pre-refereed version. To appear in Proceedings of the International
  Conference on Emerging Trends in Information and Communication Security
  (ETRICS 2006), Freiburg im Breisgau, Germany 6th-9th June 2006. Lecture Notes
  in Computer Science, Springer-Verlag</comments><abstract>  Horizontal integration of access technologies to networks and services should
be accompanied by some kind of convergence of authentication technologies. The
missing link for the federation of user identities across the technological
boundaries separating authentication methods can be provided by trusted
computing platforms. The concept of establishing transitive trust by trusted
computing enables the desired crossdomain authentication functionality. The
focus of target application scenarios lies in the realm of mobile networks and
devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603052</id><created>2006-03-13</created><updated>2006-03-14</updated><authors><author><keyname>Petrov</keyname><forenames>Evgueni</forenames></author></authors><title>Evaluation of interval extension of the power function by graph
  decomposition</title><categories>cs.MS</categories><comments>submitted to the INTERVAL 2006 workshop to be held in St. Petersburg
  June 2006, Russia; extended abstract</comments><abstract>  The subject of our talk is the correct evaluation of interval extension of
the function specified by the expression x^y without any constraints on the
values of x and y. The core of our approach is a decomposition of the graph of
x^y into a small number of parts which can be transformed into subsets of the
graph of x^y for non-negative bases x. Because of this fact, evaluation of
interval extension of x^y, without any constraints on x and y, is not much
harder than evaluation of interval extension of x^y for non-negative bases x.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603053</id><created>2006-03-14</created><authors><author><keyname>-Bouziad</keyname><forenames>A. Ai T</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Guessarian</keyname><forenames>Irene</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Vieille</keyname><forenames>L.</forenames><affiliation>NCM</affiliation></author></authors><title>Automatic generation of simplified weakest preconditions for integrity
  constraint verification</title><categories>cs.DS cs.DB</categories><proxy>ccsd ccsd-00020682</proxy><abstract>  Given a constraint $c$ assumed to hold on a database $B$ and an update $u$ to
be performed on $B$, we address the following question: will $c$ still hold
after $u$ is performed? When $B$ is a relational database, we define a
confluent terminating rewriting system which, starting from $c$ and $u$,
automatically derives a simplified weakest precondition $wp(c,u)$ such that,
whenever $B$ satisfies $wp(c,u)$, then the updated database $u(B)$ will satisfy
$c$, and moreover $wp(c,u)$ is simplified in the sense that its computation
depends only upon the instances of $c$ that may be modified by the update. We
then extend the definition of a simplified $wp(c,u)$ to the case of deductive
databases; we prove it using fixpoint induction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603054</id><created>2006-03-14</created><authors><author><keyname>Grohe</keyname><forenames>Martin</forenames></author><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>Testing Graph Isomorphism in Parallel by Playing a Game</title><categories>cs.CC cs.LO</categories><comments>21 pages</comments><abstract>  Our starting point is the observation that if graphs in a class C have low
descriptive complexity in first order logic, then the isomorphism problem for C
is solvable by a fast parallel algorithm (essentially, by a simple
combinatorial algorithm known as the multidimensional Weisfeiler-Lehman
algorithm). Using this approach, we prove that isomorphism of graphs of bounded
treewidth is testable in TC1, answering an open question posed by
Chandrasekharan. Furthermore, we obtain an AC1 algorithm for testing
isomorphism of rotation systems (combinatorial specifications of graph
embeddings). The AC1 upper bound was known before, but the fact that this bound
can be achieved by the simple Weisfeiler-Lehman algorithm is new. Combined with
other known results, it also yields a new AC1 isomorphism algorithm for planar
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603055</id><created>2006-03-14</created><authors><author><keyname>Shaik</keyname><forenames>Ashfaq N</forenames></author></authors><title>Improved Watermarking Scheme Using Decimal Sequences</title><categories>cs.CR</categories><comments>7 pages, 10 figures</comments><abstract>  This paper presents watermarking algorithms using d-sequences so that the
peak signal to noise ratio (PSNR) is maximized and the distortion introduced in
the image due to the embedding is minimized. By exploiting the cross
correlation property of decimal sequences, the concept of embedding more than
one watermark in the same cover image is investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603056</id><created>2006-03-14</created><updated>2007-02-06</updated><authors><author><keyname>Davis</keyname><forenames>Philip M.</forenames></author><author><keyname>Fromerth</keyname><forenames>Michael J.</forenames></author></authors><title>Does the arXiv lead to higher citations and reduced publisher downloads
  for mathematics articles?</title><categories>cs.DL cs.IR math.HO</categories><comments>Last updated May 02, 2006</comments><journal-ref>Scientometrics Vol. 71, No. 2. (May, 2007)</journal-ref><doi>10.1007/s11192-007-1661-8</doi><abstract>  An analysis of 2,765 articles published in four math journals from 1997 to
2005 indicate that articles deposited in the arXiv received 35% more citations
on average than non-deposited articles (an advantage of about 1.1 citations per
article), and that this difference was most pronounced for highly-cited
articles. Open Access, Early View, and Quality Differential were examined as
three non-exclusive postulates for explaining the citation advantage. There was
little support for a universal Open Access explanation, and no empirical
support for Early View. There was some inferential support for a Quality
Differential brought about by more highly-citable articles being deposited in
the arXiv. In spite of their citation advantage, arXiv-deposited articles
received 23% fewer downloads from the publisher's website (about 10 fewer
downloads per article) in all but the most recent two years after publication.
The data suggest that arXiv and the publisher's website may be fulfilling
distinct functional needs of the reader.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603057</id><created>2006-03-14</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Sitchinava</keyname><forenames>Nodari</forenames></author></authors><title>Guard Placement For Wireless Localization</title><categories>cs.CG</categories><acm-class>I.3.5</acm-class><abstract>  Motivated by secure wireless networking, we consider the problem of placing
fixed localizers that enable mobile communication devices to prove they belong
to a secure region that is defined by the interior of a polygon. Each localizer
views an infinite wedge of the plane, and a device can prove membership in the
secure region if it is inside the wedges for a set of localizers whose common
intersection contains no points outside the polygon. This model leads to a
broad class of new art gallery type problems, for which we provide upper and
lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603058</identifier>
 <datestamp>2008-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603058</id><created>2006-03-14</created><updated>2008-12-23</updated><authors><author><keyname>Moallemi</keyname><forenames>Ciamac C.</forenames></author><author><keyname>Van Roy</keyname><forenames>Benjamin</forenames></author></authors><title>Convergence of Min-Sum Message Passing for Quadratic Optimization</title><categories>cs.IT cs.AI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish the convergence of the min-sum message passing algorithm for
minimization of a broad class of quadratic objective functions: those that
admit a convex decomposition. Our results also apply to the equivalent problem
of the convergence of Gaussian belief propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603059</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603059</id><created>2006-03-14</created><updated>2006-04-03</updated><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author><author><keyname>Marcus</keyname><forenames>Brian</forenames></author></authors><title>Derivatives of Entropy Rate in Special Families of Hidden Markov Chains</title><categories>cs.IT math.IT math.PR</categories><comments>The relaxed condtions for entropy rate and examples are taken out (to
  be part of another paper). The section about general principle and an example
  to determine the domain of analyticity is taken out (to be part of another
  paper). A section about binary Markov chains corrupted by binary symmetric
  noise is added</comments><abstract>  Consider a hidden Markov chain obtained as the observation process of an
ordinary Markov chain corrupted by noise. Zuk, et. al. [13], [14] showed how,
in principle, one can explicitly compute the derivatives of the entropy rate of
at extreme values of the noise. Namely, they showed that the derivatives of
standard upper approximations to the entropy rate actually stabilize at an
explicit finite time. We generalize this result to a natural class of hidden
Markov chains called ``Black Holes.'' We also discuss in depth special cases of
binary Markov chains observed in binary symmetric noise, and give an abstract
formula for the first derivative in terms of a measure on the simplex due to
Blackwell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603060</id><created>2006-03-16</created><authors><author><keyname>Riege</keyname><forenames>Tobias</forenames></author><author><keyname>Rothe</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Spakowski</keyname><forenames>Holger</forenames></author><author><keyname>Yamamoto</keyname><forenames>Masaki</forenames></author></authors><title>An Improved Exact Algorithm for the Domatic Number Problem</title><categories>cs.CC</categories><comments>9 pages, a two-page abstract of this paper is to appear in the
  Proceedings of the Second IEEE International Conference on Information &amp;
  Communication Technologies: From Theory to Applications, April 2006</comments><acm-class>F.2.2</acm-class><abstract>  The 3-domatic number problem asks whether a given graph can be partitioned
intothree dominating sets. We prove that this problem can be solved by a
deterministic algorithm in time 2.695^n (up to polynomial factors). This result
improves the previous bound of 2.8805^n, which is due to Fomin, Grandoni,
Pyatkin, and Stepanov. To prove our result, we combine an algorithm by Fomin et
al. with Yamamoto's algorithm for the satisfiability problem. In addition, we
show that the 3-domatic number problem can be solved for graphs G with bounded
maximum degree Delta(G) by a randomized algorithm, whose running time is better
than the previous bound due to Riege and Rothe whenever Delta(G) &gt;= 5. Our new
randomized algorithm employs Schoening's approach to constraint satisfaction
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603061</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603061</id><created>2006-03-16</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Tjhung</keyname><forenames>Tjeng Thiang</forenames></author></authors><title>Quasi-Orthogonal STBC With Minimum Decoding Complexity</title><categories>cs.IT math.IT</categories><comments>IEEE Trans. on Wirless Communications</comments><abstract>  In this paper, we consider a quasi-orthogonal (QO) space-time block code
(STBC) with minimum decoding complexity (MDC-QO-STBC). We formulate its
algebraic structure and propose a systematic method for its construction. We
show that a maximum-likelihood (ML) decoder for this MDC-QOSTBC, for any number
of transmit antennas, only requires the joint detection of two real symbols.
Assuming the use of a square or rectangular quadratic-amplitude modulation
(QAM) or multiple phase-shift keying (MPSK) modulation for this MDC-QOSTBC, we
also obtain the optimum constellation rotation angle, in order to achieve full
diversity and optimum coding gain. We show that the maximum achievable code
rate of these MDC-QOSTBC is 1 for three and four antennas and 3/4 for five to
eight antennas. We also show that the proposed MDC-QOSTBC has several desirable
properties, such as a more even power distribution among antennas and better
scalability in adjusting the number of transmit antennas, compared with the
coordinate interleaved orthogonal design (CIOD) and asymmetric CIOD (ACIOD)
codes. For the case of an odd number of transmit antennas, MDC-QO-STBC also has
better decoding performance than CIOD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603062</id><created>2006-03-16</created><updated>2006-03-21</updated><authors><author><keyname>Donnet</keyname><forenames>Benoit</forenames></author><author><keyname>Huffaker</keyname><forenames>Bradley</forenames></author><author><keyname>Friedman</keyname><forenames>Timur</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author></authors><title>Implementation and Deployment of a Distributed Network Topology
  Discovery Algorithm</title><categories>cs.NI</categories><abstract>  In the past few years, the network measurement community has been interested
in the problem of internet topology discovery using a large number (hundreds or
thousands) of measurement monitors. The standard way to obtain information
about the internet topology is to use the traceroute tool from a small number
of monitors. Recent papers have made the case that increasing the number of
monitors will give a more accurate view of the topology. However, scaling up
the number of monitors is not a trivial process. Duplication of effort close to
the monitors wastes time by reexploring well-known parts of the network, and
close to destinations might appear to be a distributed denial-of-service (DDoS)
attack as the probes converge from a set of sources towards a given
destination. In prior work, authors of this report proposed Doubletree, an
algorithm for cooperative topology discovery, that reduces the load on the
network, i.e., router IP interfaces and end-hosts, while discovering almost as
many nodes and links as standard approaches based on traceroute. This report
presents our open-source and freely downloadable implementation of Doubletree
in a tool we call traceroute@home. We describe the deployment and validation of
traceroute@home on the PlanetLab testbed and we report on the lessons learned
from this experience. We discuss how traceroute@home can be developed further
and discuss ideas for future improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603063</identifier>
 <datestamp>2014-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603063</id><created>2006-03-16</created><updated>2007-12-21</updated><authors><author><keyname>Severin</keyname><forenames>Daniel E.</forenames></author></authors><title>Unary Primitive Recursive Functions</title><categories>cs.SC cs.LO</categories><journal-ref>Journal of Symbolic Logic. Volume 73, Issue 4 (2008), p.
  1122--1138</journal-ref><doi>10.2178/jsl/1230396909</doi><abstract>  In this article, we study some new characterizations of primitive recursive
functions based on restricted forms of primitive recursion, improving the
pioneering work of R. M. Robinson and M. D. Gladstone in this area. We reduce
certain recursion schemes (mixed/pure iteration without parameters) and we
characterize one-argument primitive recursive functions as the closure under
substitution and iteration of certain optimal sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603064</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603064</id><created>2006-03-16</created><updated>2006-09-08</updated><authors><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Guessing under source uncertainty</title><categories>cs.IT math.IT</categories><comments>27 pages, submitted to IEEE Transactions on Information Theory, March
  2006, revised September 2006, contains minor modifications and restructuring
  based on reviewers' comments</comments><doi>10.1109/TIT.2006.887466</doi><abstract>  This paper considers the problem of guessing the realization of a finite
alphabet source when some side information is provided. The only knowledge the
guesser has about the source and the correlated side information is that the
joint source is one among a family. A notion of redundancy is first defined and
a new divergence quantity that measures this redundancy is identified. This
divergence quantity shares the Pythagorean property with the Kullback-Leibler
divergence. Good guessing strategies that minimize the supremum redundancy
(over the family) are then identified. The min-sup value measures the richness
of the uncertainty set. The min-sup redundancies for two examples - the
families of discrete memoryless sources and finite-state arbitrarily varying
sources - are then determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603065</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603065</id><created>2006-03-16</created><authors><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>MIMO Broadcast Channels with Finite Rate Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Information Theory, 34 pages</comments><journal-ref>IEEE Trans. Information Theory, Vol. 52, No. 11, pp. 5045-5059,
  Nov. 2006</journal-ref><abstract>  Multiple transmit antennas in a downlink channel can provide tremendous
capacity (i.e. multiplexing) gains, even when receivers have only single
antennas. However, receiver and transmitter channel state information is
generally required. In this paper, a system where each receiver has perfect
channel knowledge, but the transmitter only receives quantized information
regarding the channel instantiation is analyzed. The well known zero forcing
transmission technique is considered, and simple expressions for the throughput
degradation due to finite rate feedback are derived. A key finding is that the
feedback rate per mobile must be increased linearly with the SNR (in dB) in
order to achieve the full multiplexing gain, which is in sharp contrast to
point-to-point MIMO systems in which it is not necessary to increase the
feedback rate as a function of the SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603066</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603066</id><created>2006-03-16</created><authors><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>A Feedback Reduction Technique for MIMO Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to Int. Symposium on Information Theory, January 2006</comments><abstract>  A multiple antenna broadcast channel with perfect channel state information
at the receivers is considered. If each receiver quantizes its channel
knowledge to a finite number of bits which are fed back to the transmitter, the
large capacity benefits of the downlink channel can be realized. However, the
required number of feedback bits per mobile must be scaled with both the number
of transmit antennas and the system SNR, and thus can be quite large in even
moderately sized systems. It is shown that a small number of antennas can be
used at each receiver to improve the quality of the channel estimate provided
to the transmitter. As a result, the required feedback rate per mobile can be
significantly decreased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603067</id><created>2006-03-16</created><authors><author><keyname>Sivakumar</keyname><forenames>Priya</forenames></author></authors><title>Implementing the Three-Stage Quantum Cryptography Protocol</title><categories>cs.CR</categories><comments>4 pages, 1 figure</comments><abstract>  We present simple implementations of Kak's three-stage quantum cryptography
protocol. The case where the transformation is applied to more than one qubit
at the same time is also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603068</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603068</id><created>2006-03-16</created><authors><author><keyname>Shamir</keyname><forenames>Gil I.</forenames></author></authors><title>Universal Lossless Compression with Unknown Alphabets - The Average Case</title><categories>cs.IT math.IT</categories><comments>Revised for IEEE Transactions on Information Theory</comments><acm-class>G.3</acm-class><abstract>  Universal compression of patterns of sequences generated by independently
identically distributed (i.i.d.) sources with unknown, possibly large,
alphabets is investigated. A pattern is a sequence of indices that contains all
consecutive indices in increasing order of first occurrence. If the alphabet of
a source that generated a sequence is unknown, the inevitable cost of coding
the unknown alphabet symbols can be exploited to create the pattern of the
sequence. This pattern can in turn be compressed by itself. It is shown that if
the alphabet size $k$ is essentially small, then the average minimax and
maximin redundancies as well as the redundancy of every code for almost every
source, when compressing a pattern, consist of at least 0.5 log(n/k^3) bits per
each unknown probability parameter, and if all alphabet letters are likely to
occur, there exist codes whose redundancy is at most 0.5 log(n/k^2) bits per
each unknown probability parameter, where n is the length of the data
sequences. Otherwise, if the alphabet is large, these redundancies are
essentially at least O(n^{-2/3}) bits per symbol, and there exist codes that
achieve redundancy of essentially O(n^{-1/2}) bits per symbol. Two sub-optimal
low-complexity sequential algorithms for compression of patterns are presented
and their description lengths analyzed, also pointing out that the pattern
average universal description length can decrease below the underlying i.i.d.\
entropy for large enough alphabets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603069</id><created>2006-03-17</created><authors><author><keyname>Li</keyname><forenames>Fengwei</forenames></author><author><keyname>Li</keyname><forenames>Xueliang</forenames></author></authors><title>The neighbor-scattering number can be computed in polynomial time for
  interval graphs</title><categories>cs.DM math.CO</categories><comments>13 pages</comments><acm-class>G.2.2; F.2.2</acm-class><abstract>  Neighbor-scattering number is a useful measure for graph vulnerability. For
some special kinds of graphs, explicit formulas are given for this number.
However, for general graphs it is shown that to compute this number is
NP-complete. In this paper, we prove that for interval graphs this number can
be computed in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603070</id><created>2006-03-17</created><authors><author><keyname>Stefanov</keyname><forenames>S. Z.</forenames></author></authors><title>Predicting the Path of an Open System</title><categories>cs.RO</categories><comments>18 pages</comments><abstract>  The expected path of an open system,which is a big Poincare system,has been
found in this paper.This path has been obtained from the actual and from the
expected droop of the open system.The actual droop has been reconstructed from
the variations in the power and in the frequency of the open system.The
expected droop has been found as a function of rotation from the expected
potential energy of the open system under synchronization of that system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603071</id><created>2006-03-17</created><authors><author><keyname>Meer</keyname><forenames>Klaus</forenames></author><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>An Explicit Solution to Post's Problem over the Reals</title><categories>cs.LO cs.SC</categories><comments>submitted to Journal of Complexity</comments><acm-class>F.1.1; F.4.1</acm-class><abstract>  In the BCSS model of real number computations we prove a concrete and
explicit semi-decidable language to be undecidable yet not reducible from (and
thus strictly easier than) the real Halting Language. This solution to Post's
Problem over the reals significantly differs from its classical, discrete
variant where advanced diagonalization techniques are only known to yield the
existence of such intermediate Turing degrees. Strengthening the above result,
we construct (that is, obtain again explicitly) as well an uncountable number
of incomparable semi-decidable Turing degrees below the real Halting problem in
the BCSS model. Finally we show the same to hold for the linear BCSS model,
that is over (R,+,-,&lt;) rather than (R,+,-,*,/,&lt;).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603072</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603072</id><created>2006-03-17</created><authors><author><keyname>Mudumbai</keyname><forenames>R.</forenames></author><author><keyname>Hespanha</keyname><forenames>J.</forenames></author><author><keyname>Madhow</keyname><forenames>U.</forenames></author><author><keyname>Barriac</keyname><forenames>G.</forenames></author></authors><title>Distributed Transmit Beamforming using Feedback Control</title><categories>cs.IT math.IT</categories><acm-class>C.2.1</acm-class><abstract>  A simple feedback control algorithm is presented for distributed beamforming
in a wireless network. A network of wireless sensors that seek to cooperatively
transmit a common message signal to a Base Station (BS) is considered. In this
case, it is well-known that substantial energy efficiencies are possible by
using distributed beamforming. The feedback algorithm is shown to achieve the
carrier phase coherence required for beamforming in a scalable and distributed
manner. In the proposed algorithm, each sensor independently makes a random
adjustment to its carrier phase. Assuming that the BS is able to broadcast one
bit of feedback each timeslot about the change in received signal to noise
ratio (SNR), the sensors are able to keep the favorable phase adjustments and
discard the unfavorable ones, asymptotically achieving perfect phase coherence.
A novel analytical model is derived that accurately predicts the convergence
rate. The analytical model is used to optimize the algorithm for fast
convergence and to establish the scalability of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603073</id><created>2006-03-18</created><authors><author><keyname>Ford</keyname><forenames>Bryan</forenames></author></authors><title>VXA: A Virtual Architecture for Durable Compressed Archives</title><categories>cs.DL cs.IR</categories><comments>14 pages, 7 figures, 2 tables</comments><acm-class>H.3.7; H.1.1; D.4.5; E.5</acm-class><journal-ref>4th USENIX Conference on File and Storage Technologies, December
  2005 (FAST '05), San Francisco, CA</journal-ref><abstract>  Data compression algorithms change frequently, and obsolete decoders do not
always run on new hardware and operating systems, threatening the long-term
usability of content archived using those algorithms. Re-encoding content into
new formats is cumbersome, and highly undesirable when lossy compression is
involved. Processor architectures, in contrast, have remained comparatively
stable over recent decades. VXA, an archival storage system designed around
this observation, archives executable decoders along with the encoded content
it stores. VXA decoders run in a specialized virtual machine that implements an
OS-independent execution environment based on the standard x86 architecture.
The VXA virtual machine strictly limits access to host system services, making
decoders safe to run even if an archive contains malicious code. VXA's adoption
of a &quot;native&quot; processor architecture instead of type-safe language technology
allows reuse of existing &quot;hand-optimized&quot; decoders in C and assembly language,
and permits decoders access to performance-enhancing architecture features such
as vector processing instructions. The performance cost of VXA's virtualization
is typically less than 15% compared with the same decoders running natively.
The storage cost of archived decoders, typically 30-130KB each, can be
amortized across many archived files sharing the same compression method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603074</id><created>2006-03-18</created><authors><author><keyname>Ford</keyname><forenames>Bryan</forenames></author><author><keyname>Srisuresh</keyname><forenames>Pyda</forenames></author><author><keyname>Kegel</keyname><forenames>Dan</forenames></author></authors><title>Peer-to-Peer Communication Across Network Address Translators</title><categories>cs.NI cs.CR</categories><comments>8 figures, 1 table</comments><acm-class>C.2.0</acm-class><journal-ref>USENIX Annual Technical Conference, April 2005 (USENIX '05),
  Anaheim, CA</journal-ref><abstract>  Network Address Translation (NAT) causes well-known difficulties for
peer-to-peer (P2P) communication, since the peers involved may not be reachable
at any globally valid IP address. Several NAT traversal techniques are known,
but their documentation is slim, and data about their robustness or relative
merits is slimmer. This paper documents and analyzes one of the simplest but
most robust and practical NAT traversal techniques, commonly known as &quot;hole
punching.&quot; Hole punching is moderately well-understood for UDP communication,
but we show how it can be reliably used to set up peer-to-peer TCP streams as
well. After gathering data on the reliability of this technique on a wide
variety of deployed NATs, we find that about 82% of the NATs tested support
hole punching for UDP, and about 64% support hole punching for TCP streams. As
NAT vendors become increasingly conscious of the needs of important P2P
applications such as Voice over IP and online gaming protocols, support for
hole punching is likely to increase in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603075</id><created>2006-03-18</created><authors><author><keyname>Ford</keyname><forenames>Bryan</forenames></author></authors><title>Unmanaged Internet Protocol: Taming the Edge Network Management Crisis</title><categories>cs.NI cs.OS</categories><comments>7 pages, 3 figures</comments><acm-class>C.2.1; C.2.2</acm-class><journal-ref>Second Workshop on Hot Topics in Networks (HotNets-II), November
  2003, Cambridge, MA</journal-ref><abstract>  Though appropriate for core Internet infrastructure, the Internet Protocol is
unsuited to routing within and between emerging ad-hoc edge networks due to its
dependence on hierarchical, administratively assigned addresses. Existing
ad-hoc routing protocols address the management problem but do not scale to
Internet-wide networks. The promise of ubiquitous network computing cannot be
fulfilled until we develop an Unmanaged Internet Protocol (UIP), a scalable
routing protocol that manages itself automatically. UIP must route within and
between constantly changing edge networks potentially containing millions or
billions of nodes, and must still function within edge networks disconnected
from the main Internet, all without imposing the administrative burden of
hierarchical address assignment. Such a protocol appears challenging but
feasible. We propose an architecture based on self-certifying, cryptographic
node identities and a routing algorithm adapted from distributed hash tables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603076</id><created>2006-03-18</created><authors><author><keyname>Ford</keyname><forenames>Bryan</forenames></author><author><keyname>Strauss</keyname><forenames>Jacob</forenames></author><author><keyname>Lesniewski-Laas</keyname><forenames>Chris</forenames></author><author><keyname>Rhea</keyname><forenames>Sean</forenames></author><author><keyname>Kaashoek</keyname><forenames>Frans</forenames></author><author><keyname>Morris</keyname><forenames>Robert</forenames></author></authors><title>User-Relative Names for Globally Connected Personal Devices</title><categories>cs.NI cs.DC cs.OS</categories><comments>7 pages, 1 figure, 1 table</comments><acm-class>C.2.1; C.2.2</acm-class><journal-ref>5th International Workshop on Peer-to-Peer Systems, February 2006
  (IPTPS 2006), Santa Barbara, CA</journal-ref><abstract>  Nontechnical users who own increasingly ubiquitous network-enabled personal
devices such as laptops, digital cameras, and smart phones need a simple,
intuitive, and secure way to share information and services between their
devices. User Information Architecture, or UIA, is a novel naming and
peer-to-peer connectivity architecture addressing this need. Users assign UIA
names by &quot;introducing&quot; devices to each other on a common local-area network,
but these names remain securely bound to their target as devices migrate.
Multiple devices owned by the same user, once introduced, automatically merge
their namespaces to form a distributed &quot;personal cluster&quot; that the owner can
access or modify from any of his devices. Instead of requiring users to
allocate globally unique names from a central authority, UIA enables users to
assign their own &quot;user-relative&quot; names both to their own devices and to other
users. With UIA, for example, Alice can always access her iPod from any of her
own personal devices at any location via the name &quot;ipod&quot;, and her friend Bob
can access her iPod via a relative name like &quot;ipod.Alice&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603077</id><created>2006-03-18</created><authors><author><keyname>Ford</keyname><forenames>Bryan</forenames></author></authors><title>Packrat Parsing: Simple, Powerful, Lazy, Linear Time</title><categories>cs.DS cs.CC cs.PL</categories><comments>12 pages, 5 figures</comments><acm-class>D.3.4; D.1.1; F.4.2</acm-class><journal-ref>International Conference on Functional Programming (ICFP '02),
  October 2002, Pittsburgh, PA</journal-ref><abstract>  Packrat parsing is a novel technique for implementing parsers in a lazy
functional programming language. A packrat parser provides the power and
flexibility of top-down parsing with backtracking and unlimited lookahead, but
nevertheless guarantees linear parse time. Any language defined by an LL(k) or
LR(k) grammar can be recognized by a packrat parser, in addition to many
languages that conventional linear-time algorithms do not support. This
additional power simplifies the handling of common syntactic idioms such as the
widespread but troublesome longest-match rule, enables the use of sophisticated
disambiguation strategies such as syntactic and semantic predicates, provides
better grammar composition properties, and allows lexical analysis to be
integrated seamlessly into parsing. Yet despite its power, packrat parsing
shares the same simplicity and elegance as recursive descent parsing; in fact
converting a backtracking recursive descent parser into a linear-time packrat
parser often involves only a fairly straightforward structural change. This
paper describes packrat parsing informally with emphasis on its use in
practical applications, and explores its advantages and disadvantages with
respect to the more conventional alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603078</id><created>2006-03-19</created><updated>2007-05-29</updated><authors><author><keyname>Moallemi</keyname><forenames>Ciamac C.</forenames></author><author><keyname>Van Roy</keyname><forenames>Benjamin</forenames></author></authors><title>Consensus Propagation</title><categories>cs.IT cs.AI cs.NI math.IT</categories><comments>journal version</comments><journal-ref>IEEE Transactions on Information Theory, 2006, 52(11): 4753-4766</journal-ref><doi>10.1109/TIT.2006.883539</doi><abstract>  We propose consensus propagation, an asynchronous distributed protocol for
averaging numbers across a network. We establish convergence, characterize the
convergence rate for regular graphs, and demonstrate that the protocol exhibits
better scaling properties than pairwise averaging, an alternative that has
received much recent attention. Consensus propagation can be viewed as a
special case of belief propagation, and our results contribute to the belief
propagation literature. In particular, beyond singly-connected graphs, there
are very few classes of relevant problems for which belief propagation is known
to converge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603079</id><created>2006-03-20</created><authors><author><keyname>Gabbrielli</keyname><forenames>Maurizio</forenames></author><author><keyname>Meo</keyname><forenames>Maria Chiara</forenames></author></authors><title>A compositional Semantics for CHR</title><categories>cs.PL</categories><abstract>  Constraint Handling Rules (CHR) are a committed-choice declarative language
which has been designed for writing constraint solvers. A CHR program consists
of multi-headed guarded rules which allow one to rewrite constraints into
simpler ones until a solved form is reached.
  CHR has received a considerable attention, both from the practical and from
the theoretical side. Nevertheless, due the use of multi-headed clauses, there
are several aspects of the CHR semantics which have not been clarified yet. In
particular, no compositional semantics for CHR has been defined so far.
  In this paper we introduce a fix-point semantics which characterizes the
input/output behavior of a CHR program and which is and-compositional, that is,
which allows to retrieve the semantics of a conjunctive query from the
semantics of its components. Such a semantics can be used as a basis to define
incremental and modular analysis and verification tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603080</id><created>2006-03-20</created><authors><author><keyname>Suciu</keyname><forenames>Alin</forenames></author></authors><title>Yet Another Efficient Unification Algorithm</title><categories>cs.LO cs.AI</categories><abstract>  The unification algorithm is at the core of the logic programming paradigm,
the first unification algorithm being developed by Robinson [5]. More efficient
algorithms were developed later [3] and I introduce here yet another efficient
unification algorithm centered on a specific data structure, called the
Unification Table.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603081</id><created>2006-03-20</created><authors><author><keyname>Sakhanenko</keyname><forenames>Nikita A.</forenames><affiliation>CS Dept. University of New Mexico</affiliation><affiliation>Physics Div. Los Alamos National Laboratory</affiliation></author><author><keyname>Luger</keyname><forenames>George F.</forenames><affiliation>CS Dept. University of New Mexico</affiliation></author><author><keyname>Makaruk</keyname><forenames>Hanna E.</forenames><affiliation>Physics Div. Los Alamos National Laboratory</affiliation></author><author><keyname>Holtkamp</keyname><forenames>David B.</forenames><affiliation>Physics Div. Los Alamos National Laboratory</affiliation></author></authors><title>Application of Support Vector Regression to Interpolation of Sparse
  Shock Physics Data Sets</title><categories>cs.AI</categories><comments>13 pages, 7 figures</comments><report-no>LA-UR-06-1739</report-no><acm-class>I.2; J.2</acm-class><abstract>  Shock physics experiments are often complicated and expensive. As a result,
researchers are unable to conduct as many experiments as they would like -
leading to sparse data sets. In this paper, Support Vector Machines for
regression are applied to velocimetry data sets for shock damaged and melted
tin metal. Some success at interpolating between data sets is achieved.
Implications for future work are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603082</id><created>2006-03-21</created><authors><author><keyname>Eberly</keyname><forenames>Wayne</forenames><affiliation>SCG</affiliation></author><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames><affiliation>SCG</affiliation></author><author><keyname>Giorgi</keyname><forenames>Pascal</forenames><affiliation>LP2A, SCG</affiliation></author><author><keyname>Storjohann</keyname><forenames>Arne</forenames><affiliation>SCG</affiliation></author><author><keyname>Villard</keyname><forenames>Gilles</forenames><affiliation>LIP</affiliation></author></authors><title>Solving Sparse Integer Linear Systems</title><categories>cs.SC</categories><proxy>ccsd ccsd-00021456</proxy><acm-class>I.1.2</acm-class><abstract>  We propose a new algorithm to solve sparse linear systems of equations over
the integers. This algorithm is based on a $p$-adic lifting technique combined
with the use of block matrices with structured blocks. It achieves a sub-cubic
complexity in terms of machine operations subject to a conjecture on the
effectiveness of certain sparse projections. A LinBox-based implementation of
this algorithm is demonstrated, and emphasizes the practical benefits of this
new method over the previous state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603083</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603083</id><created>2006-03-22</created><authors><author><keyname>Gore</keyname><forenames>Ashutosh Deepak</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author></authors><title>Entropy-optimal Generalized Token Bucket Regulator</title><categories>cs.IT math.IT</categories><comments>6 pages (2 column, 10-point), 3 figures, 1 table</comments><abstract>  We derive the maximum entropy of a flow (information utility) which conforms
to traffic constraints imposed by a generalized token bucket regulator, by
taking into account the covert information present in the randomness of packet
lengths. Under equality constraints of aggregate tokens and aggregate bucket
depth, a generalized token bucket regulator can achieve higher information
utility than a standard token bucket regulator. The optimal generalized token
bucket regulator has a near-uniform bucket depth sequence and a decreasing
token increment sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603084</id><created>2006-03-22</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Ofek</keyname><forenames>Eran</forenames></author></authors><title>Random 3CNF formulas elude the Lovasz theta function</title><categories>cs.CC cs.DS cs.LO</categories><comments>14 pages</comments><abstract>  Let $\phi$ be a 3CNF formula with n variables and m clauses. A simple
nonconstructive argument shows that when m is sufficiently large compared to n,
most 3CNF formulas are not satisfiable. It is an open question whether there is
an efficient refutation algorithm that for most such formulas proves that they
are not satisfiable. A possible approach to refute a formula $\phi$ is: first,
translate it into a graph $G_{\phi}$ using a generic reduction from 3-SAT to
max-IS, then bound the maximum independent set of $G_{\phi}$ using the Lovasz
$\vartheta$ function. If the $\vartheta$ function returns a value $&lt; m$, this
is a certificate for the unsatisfiability of $\phi$. We show that for random
formulas with $m &lt; n^{3/2 -o(1)}$ clauses, the above approach fails, i.e. the
$\vartheta$ function is likely to return a value of m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603085</id><created>2006-03-22</created><updated>2006-03-22</updated><authors><author><keyname>Adams</keyname><forenames>Jonathan K.</forenames></author><author><keyname>Bristow</keyname><forenames>Basheer N.</forenames></author></authors><title>Access Control for Hierarchical Joint-Tenancy</title><categories>cs.CR</categories><comments>To appear in WSEAS Transactions on Computers, will probably be edited
  further before final revision replaced due to typographical errors</comments><acm-class>D.4.6</acm-class><journal-ref>WSEAS Transactions on Computers, June 2006, Issue 6, Volume 5, p.
  1313-1318</journal-ref><abstract>  Basic role based access control [RBAC] provides a mechanism for segregating
access privileges based upon a user's hierarchical roles within an
organization. This model doesn't scale well when there is tight integration of
multiple hierarchies. In a case where there is joint-tenancy and a requirement
for different levels of disclosure based upon a user's hierarchy, or in our
case, organization or company, basic RBAC requires these hierarchies to be
effectively merged. Specific roles that effectively represent both the user's
organizations and roles must be translated to fit within the merged hierarchy
to be used to control access. Essentially, users from multiple organizations
are served from a single role base with roles designed to constrain their
access as needed.
  Our work proposes, through parameterized roles and privileges, a means for
accurately representing both users' roles within their respective hierarchies
for providing access to controlled objects. Using this method will reduce the
amount of complexity required in terms of the number of roles and privileges.
The resulting set of roles, privileges, and objects will make modeling and
visualizing the access role hierarchy significantly simplified. This paper will
give some background on role based access control, parameterized roles and
privileges, and then focus on how RBAC with parameterized roles and privileges
can be leveraged as an access control solution for the problems presented by
joint tenancy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603086</id><created>2006-03-22</created><authors><author><keyname>Roux</keyname><forenames>Joel Le</forenames><affiliation>University of Nice</affiliation></author><author><keyname>Chaurand</keyname><forenames>Philippe</forenames><affiliation>University of Nice</affiliation></author><author><keyname>Urrutia</keyname><forenames>Mickael</forenames><affiliation>University of Nice</affiliation></author></authors><title>Matching Edges in Images ; Application to Face Recognition</title><categories>cs.CV</categories><comments>11 Pages, 6 figures</comments><acm-class>I.5.1; I.5.2</acm-class><abstract>  This communication describes a representation of images as a set of edges
characterized by their position and orientation. This representation allows the
comparison of two images and the computation of their similarity. The first
step in this computation of similarity is the seach of a geometrical basis of
the two dimensional space where the two images are represented simultaneously
after transformation of one of them. Presently, this simultaneous
representation takes into account a shift and a scaling ; it may be extended to
rotations or other global geometrical transformations. An elementary
probabilistic computation shows that a sufficient but not excessive number of
trials (a few tens) ensures that the exhibition of this common basis is
guaranteed in spite of possible errors in the detection of edges. When this
first step is performed, the search of similarity between the two images
reduces to counting the coincidence of edges in the two images. The approach
may be applied to many problems of pattern matching ; it was checked on face
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603087</id><created>2006-03-22</created><authors><author><keyname>Ganguly</keyname><forenames>Arijit</forenames></author><author><keyname>Agrawal</keyname><forenames>Abhishek</forenames></author><author><keyname>Boykin</keyname><forenames>P. Oscar</forenames></author><author><keyname>Figueiredo</keyname><forenames>Renato</forenames></author></authors><title>IP over P2P: Enabling Self-configuring Virtual IP Networks for Grid
  Computing</title><categories>cs.DC cs.NI</categories><comments>To appear in IPDPS 2006</comments><abstract>  Peer-to-peer (P2P) networks have mostly focused on task oriented networking,
where networks are constructed for single applications, i.e. file-sharing, DNS
caching, etc. In this work, we introduce IPOP, a system for creating virtual IP
networks on top of a P2P overlay. IPOP enables seamless access to Grid
resources spanning multiple domains by aggregating them into a virtual IP
network that is completely isolated from the physical network. The virtual IP
network provided by IPOP supports deployment of existing IP-based protocols
over a robust, self-configuring P2P overlay. We present implementation details
as well as experimental measurement results taken from LAN, WAN, and Planet-Lab
tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603088</id><created>2006-03-22</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Kotiyal</keyname><forenames>Saurabh</forenames></author><author><keyname>Srinivas</keyname><forenames>M. B</forenames></author></authors><title>Novel BCD Adders and Their Reversible Logic Implementation for IEEE 754r
  Format</title><categories>cs.AR</categories><comments>6 Pages: This paper is a corrected version of our recent publication
  published in 19th International Conference on VLSI Design and 5th
  International Conference on Embedded Systems (VLSI Design 2006), Hyderabad,
  India, Jan 4-7, 2006</comments><abstract>  IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and
a major enhancement to the standard is the addition of decimal format. This
paper proposes two novel BCD adders called carry skip and carry look-ahead BCD
adders respectively. Furthermore, in the recent years, reversible logic has
emerged as a promising technology having its applications in low power CMOS,
quantum computing, nanotechnology, and optical computing. It is not possible to
realize quantum computing without reversible logic. Thus, this paper also paper
provides the reversible logic implementation of the conventional BCD adder as
the well as the proposed Carry Skip BCD adder using a recently proposed TSG
gate. Furthermore, a new reversible gate called TS-3 is also being proposed and
it has been shown that the proposed reversible logic implementation of the BCD
Adders is much better compared to recently proposed one, in terms of number of
reversible gates used and garbage outputs produced. The reversible BCD circuits
designed and proposed here form the basis of the decimal ALU of a primitive
quantum CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603089</id><created>2006-03-22</created><authors><author><keyname>Ioannou</keyname><forenames>Lawrence M.</forenames></author><author><keyname>Travaglione</keyname><forenames>Benjamin C.</forenames></author><author><keyname>Cheung</keyname><forenames>Donny</forenames></author></authors><title>Convex Separation from Optimization via Heuristics</title><categories>cs.DS math.OC</categories><abstract>  Let $K$ be a full-dimensional convex subset of $\mathbb{R}^n$. We describe a
new polynomial-time Turing reduction from the weak separation problem for $K$
to the weak optimization problem for $K$ that is based on a geometric
heuristic. We compare our reduction, which relies on analytic centers, with the
standard, more general reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603090</id><created>2006-03-22</created><updated>2006-07-28</updated><authors><author><keyname>Gorban</keyname><forenames>A. N.</forenames></author><author><keyname>Sumner</keyname><forenames>N. R.</forenames></author><author><keyname>Zinovyev</keyname><forenames>A. Y.</forenames></author></authors><title>Topological Grammars for Data Approximation</title><categories>cs.NE cs.LG</categories><comments>Corrected Journal version, Appl. Math. Lett., in press. 7 pgs., 2
  figs</comments><journal-ref>Applied Mathematics Letters 20 (2007) 382--386</journal-ref><doi>10.1016/j.aml.2006.04.022</doi><abstract>  A method of {\it topological grammars} is proposed for multidimensional data
approximation. For data with complex topology we define a {\it principal cubic
complex} of low dimension and given complexity that gives the best
approximation for the dataset. This complex is a generalization of linear and
non-linear principal manifolds and includes them as particular cases. The
problem of optimal principal complex construction is transformed into a series
of minimization problems for quadratic functionals. These quadratic functionals
have a physically transparent interpretation in terms of elastic energy. For
the energy computation, the whole complex is represented as a system of nodes
and springs. Topologically, the principal complex is a product of
one-dimensional continuums (represented by graphs), and the grammars describe
how these continuums transform during the process of optimal complex
construction. This factorization of the whole process onto one-dimensional
transformations using minimization of quadratic energy functionals allow us to
construct efficient algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603091</id><created>2006-03-23</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Srinivas</keyname><forenames>M. B</forenames></author></authors><title>A New Reversible TSG Gate and Its Application For Designing Efficient
  Adder Circuits</title><categories>cs.AR</categories><comments>5 Pages: Published in 7th International Symposium on Representations
  and Methodology of Future Computing Technologies(RM 2005), Tokyo, Japan,
  September 5-6, 2005</comments><abstract>  In the recent years, reversible logic has emerged as a promising technology
having its applications in low power CMOS, quantum computing, nanotechnology,
and optical computing. The classical set of gates such as AND, OR, and EXOR are
not reversible. This paper proposes a new 4 * 4 reversible gate called TSG
gate. The proposed gate is used to design efficient adder units. The most
significant aspect of the proposed gate is that it can work singly as a
reversible full adder i.e reversible full adder can now be implemented with a
single gate only. The proposed gate is then used to design reversible ripple
carry and carry skip adders. It is demonstrated that the adder architectures
designed using the proposed gate are much better and optimized, compared to
their existing counterparts in literature; in terms of number of reversible
gates and garbage outputs. Thus, this paper provides the initial threshold to
building of more complex system which can execute more complicated operations
using reversible logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603092</id><created>2006-03-23</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Srinivas</keyname><forenames>M. B</forenames></author></authors><title>An Extension to DNA Based Fredkin Gate Circuits: Design of Reversible
  Sequential Circuits using Fredkin Gates</title><categories>cs.AR</categories><comments>7 Pages: Deals with design of reversible sequential circuits.
  Published: Proceedings of SPIE Volume: 6050, pp.196-202.Optomechatronic
  Micro/Nano Devices and Components, Sapporo, Japan, December 5-7, 2005;
  Editor(s): Yoshitada Katagiri</comments><abstract>  In recent years, reversible logic has emerged as a promising computing
paradigm having its applications in low power computing, quantum computing,
nanotechnology, optical computing and DNA computing. The classical set of gates
such as AND, OR, and EXOR are not reversible. Recently, it has been shown how
to encode information in DNA and use DNA amplification to implement Fredkin
gates. Furthermore, in the past Fredkin gates have been constructed using DNA,
whose outputs are used as inputs for other Fredkin gates. Thus, it can be
concluded that arbitrary circuits of Fredkin gates can be constructed using
DNA. This paper provides the initial threshold to building of more complex
system having reversible sequential circuits and which can execute more
complicated operations. The novelty of the paper is the reversible designs of
sequential circuits using Fredkin gate. Since, Fredkin gate has already been
realized using DNA, it is expected that this work will initiate the building of
complex systems using DNA. The reversible circuits designed here are highly
optimized in terms of number of gates and garbage outputs. The modularization
approach that is synthesizing small circuits and thereafter using them to
construct bigger circuits is used for designing the optimal reversible
sequential circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603093</identifier>
 <datestamp>2009-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603093</id><created>2006-03-23</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>About the domino problem in the hyperbolic plane from an algorithmic
  point of view</title><categories>cs.CG cs.DM</categories><comments>11 pages, 6 figures</comments><acm-class>F.1.1; F.2.2</acm-class><journal-ref>About the domino problem in the hyperbolic plane from an
  algorithmic point of view, Theoretical Informatics and Applications, 42(1),
  (2008), 21-36</journal-ref><doi>10.1051/ita:2007045</doi><abstract>  In this paper, we prove that the general problem of tiling the hyperbolic
plane with \`a la Wang tiles is undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603094</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603094</id><created>2006-03-23</created><updated>2006-08-25</updated><authors><author><keyname>Dumont</keyname><forenames>Julien</forenames></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author></authors><title>On the Capacity Achieving Transmit Covariance Matrices of MIMO
  Correlated Rician Channels: A Large System Approach</title><categories>cs.IT math.IT</categories><comments>Paper submitted to Globecom2006</comments><abstract>  We determine the capacity-achieving input covariance matrices for coherent
block-fading correlated MIMO Rician channels. In contrast with the Rayleigh and
uncorrelated Rician cases, no closed-form expressions for the eigenvectors of
the optimum input covariance matrix are available. Both the eigenvectors and
eigenvalues have to be evaluated by using numerical techniques. As the
corresponding optimization algorithms are not very attractive, we evaluate the
limit of the average mutual information when the number of transmit and receive
antennas converge to infinity at the same rate. If the channel is
semi-correlated, we propose an attractive optimization algorithm of the large
system approximant, and establish some convergence results. Simulation results
show that our approach provide reliable results even for a quite moderate
number of transmit and receive antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603095</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603095</id><created>2006-03-23</created><authors><author><keyname>Zheng</keyname><forenames>Yan-Xiu</forenames></author><author><keyname>Su</keyname><forenames>Yu T.</forenames></author></authors><title>A Turbo Coding System for High Speed Communications</title><categories>cs.IT math.IT</categories><comments>11 figures</comments><abstract>  Conventional turbo codes (CTCs) usually employ a block-oriented interleaving
so that each block is separately encoded and decoded. As interleaving and
de-interleaving are performed within a block, the message-passing process
associated with an iterative decoder is limited to proceed within the
corresponding range. This paper presents a new turbo coding scheme that uses a
special interleaver structure and a multiple-round early termination test
involving both sign check and a CRC code. The new interleaver structure is
naturally suited for high speed parallel processing and the resulting coding
system offers new design options and tradeoffs that are not available to CTCs.
In particular, it becomes possible for the decoder to employ an efficient
inter-block collaborative decoding algorithm, passing the information obtained
from termination test proved blocks to other unproved blocks. It also becomes
important to have a proper decoding schedule. The combined effect is improved
performance and reduction in the average decoding delay (whence the required
computing power). A memory (storage) management mechanism is included as a
critical part of the decoder so as to provide additional design tradeoff
between performance and memory size. It is shown that the latter has a
modular-like effect in that additional memory units render enhanced performance
due not only to less forced early terminations but to possible increases of the
interleaving depth. Depending on the decoding schedule, the degree of
parallelism and other decoding resources available, the proposed scheme admits
a variety of decoder architectures that meet a large range of throughput and
performance demands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603096</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603096</id><created>2006-03-24</created><authors><author><keyname>Siti</keyname><forenames>Massimiliano</forenames></author><author><keyname>Fitz</keyname><forenames>Michael P.</forenames></author></authors><title>On Reduced Complexity Soft-Output MIMO ML detection</title><categories>cs.IT math.IT</categories><comments>43 pages, 10 figures Submitted to the IEEE Transactions on
  Information Theory, March 2006</comments><abstract>  In multiple-input multiple-output (MIMO) fading channels maximum likelihood
(ML) detection is desirable to achieve high performance, but its complexity
grows exponentially with the spectral efficiency. The current state of the art
in MIMO detection is list decoding and lattice decoding. This paper proposes a
new class of lattice detectors that combines some of the principles of both
list and lattice decoding, thus resulting in an efficient parallelizable
implementation and near optimal soft-ouput ML performance. The novel detector
is called layered orthogonal lattice detector (LORD), because it adopts a new
lattice formulation and relies on a channel orthogonalization process. It
should be noted that the algorithm achieves optimal hard-output ML performance
in case of two transmit antennas. For two transmit antennas max-log bit
soft-output information can be generated and for greater than two antennas
approximate max-log detection is achieved. Simulation results show that LORD,
in MIMO system employing orthogonal frequency division multiplexing (OFDM) and
bit interleaved coded modulation (BICM) is able to achieve very high
signal-to-noise ratio (SNR) gains compared to practical soft-output detectors
such as minimum-mean square error (MMSE), in either linear or nonlinear
iterative scheme. Besides, the performance comparison with hard-output decoded
algebraic space time codes shows the fundamental importance of soft-output
generation capability for practical wireless applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603097</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603097</id><created>2006-03-24</created><updated>2006-04-18</updated><authors><author><keyname>Gilardoni</keyname><forenames>Gustavo L.</forenames></author></authors><title>On Pinsker's Type Inequalities and Csiszar's f-divergences. Part I:
  Second and Fourth-Order Inequalities</title><categories>cs.IT math.IT</categories><comments>15 pages</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 56(11), pp.
  5377-5386, 2010</journal-ref><doi>10.1109/TIT.2010.2068710</doi><abstract>  We study conditions on $f$ under which an $f$-divergence $D_f$ will satisfy
$D_f \geq c_f V^2$ or $D_f \geq c_{2,f} V^2 + c_{4,f} V^4$, where $V$ denotes
variational distance and the coefficients $c_f$, $c_{2,f}$ and $c_{4,f}$ are
{\em best possible}. As a consequence, we obtain lower bounds in terms of $V$
for many well known distance and divergence measures. For instance, let
$D_{(\alpha)} (P,Q) = [\alpha (\alpha-1)]^{-1} [\int q^{\alpha} p^{1-\alpha} d
\mu -1]$ and ${\cal I}_\alpha (P,Q) = (\alpha -1)^{-1} \log [\int p^\alpha
q^{1-\alpha} d \mu]$ be respectively the {\em relative information of type}
($1-\alpha$) and {\em R\'{e}nyi's information gain of order} $\alpha$. We show
that $D_{(\alpha)} \geq {1/2} V^2 + {1/72} (\alpha+1)(2-\alpha) V^4$ whenever
$-1 \leq \alpha \leq 2$, $\alpha \not= 0,1$ and that ${\cal I}_{\alpha} =
\frac{\alpha}{2} V^2 + {1/36} \alpha (1 + 5 \alpha - 5 \alpha^2) V^4$ for $0 &lt;
\alpha &lt; 1$. Pinsker's inequality $D \geq {1/2}
  V^2$ and its extension $D \geq {1/2} V^2 + {1/36} V^4$ are special cases of
each one of these.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603098</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603098</id><created>2006-03-24</created><authors><author><keyname>Ray</keyname><forenames>Siddharth</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Zheng</keyname><forenames>Lizhong</forenames></author></authors><title>A SIMO Fiber Aided Wireless Network Architecture</title><categories>cs.IT math.IT</categories><abstract>  The concept of a fiber aided wireless network architecture (FAWNA) is
introduced in [Ray et al., Allerton Conference 2005], which allows high-speed
mobile connectivity by leveraging the speed of optical networks. In this paper,
we consider a single-input, multiple-output (SIMO) FAWNA, which consists of a
SIMO wireless channel and an optical fiber channel, connected through
wireless-optical interfaces. We propose a scheme where the received wireless
signal at each interface is quantized and sent over the fiber. Though our
architecture is similar to that of the classical CEO problem, our problem is
different from it. We show that the capacity of our scheme approaches the
capacity of the architecture, exponentially with fiber capacity. We also show
that for a given fiber capacity, there is an optimal operating wireless
bandwidth and an optimal number of wireless-optical interfaces. The
wireless-optical interfaces of our scheme have low complexity and do not
require knowledge of the transmitter code book. They are also extendable to
FAWNAs with large number of transmitters and interfaces and, offer adaptability
to variable rates, changing channel conditions and node positions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603099</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603099</id><created>2006-03-26</created><authors><author><keyname>Suciu</keyname><forenames>Alin</forenames></author><author><keyname>Potolea</keyname><forenames>Rodica</forenames></author><author><keyname>Muresan</keyname><forenames>Tudor</forenames></author></authors><title>Benchmark Problems for Constraint Solving</title><categories>cs.PF cs.SC</categories><abstract>  Constraint Programming is roughly a new software technology introduced by
Jaffar and Lassez in 1987 for description and effective solving of large,
particularly combinatorial, problems especially in areas of planning and
scheduling. In the following we define three problems for constraint solving
from the domain of electrical networks; based on them we define 43 related
problems. For the defined set of problems we benchmarked five systems: ILOG
OPL, AMPL, GAMS, Mathematica and UniCalc. As expected some of the systems
performed very well for some problems while others performed very well on
others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603100</id><created>2006-03-26</created><authors><author><keyname>Suciu</keyname><forenames>Alin</forenames></author><author><keyname>Pusztai</keyname><forenames>Kalman</forenames></author></authors><title>Efficient Compression of Prolog Programs</title><categories>cs.PL</categories><abstract>  We propose a special-purpose class of compression algorithms for efficient
compression of Prolog programs. It is a dictionary-based compression method,
specially designed for the compression of Prolog code, and therefore we name it
PCA (Prolog Compression Algorithm). According to the experimental results this
method provides better compression than state-of-the-art general-purpose
compression algorithms. Since the algorithm works with Prolog syntactic
entities (e.g. atoms, terms, etc.) the implementation of a Prolog prototype is
straightforward and very easy to use in any Prolog application that needs
compression. Although the algorithm is designed for Prolog programs, the idea
can be easily applied for the compression of programs written in other (logic)
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603101</id><created>2006-03-26</created><authors><author><keyname>Suciu</keyname><forenames>Alin</forenames></author><author><keyname>Pusztai</keyname><forenames>Kalman</forenames></author><author><keyname>Vancea</keyname><forenames>Andrei</forenames></author></authors><title>Prolog Server Pages</title><categories>cs.NI cs.PL</categories><abstract>  Prolog Server Pages (PSP) is a scripting language, based on Prolog, than can
be embedded in HTML documents. To run PSP applications one needs a web server,
a web browser and a PSP interpreter. The code is executed, by the interpreter,
on the server-side (web server) and the output (together with the html code in
witch the PSP code is embedded) is sent to the client-side (browser). The
current implementation supports Apache Web Server. We implemented an Apache web
server module that handles PSP files, and sends the result (an html document)
to the client. PSP supports both GET and POST http requests. It also provides
methods for working with http cookies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603102</id><created>2006-03-26</created><authors><author><keyname>Suciu</keyname><forenames>Alin</forenames></author><author><keyname>Pusztai</keyname><forenames>Kalman</forenames></author><author><keyname>Diaconu</keyname><forenames>Andrei</forenames></author></authors><title>Enhanced Prolog Remote Predicate Call Protocol</title><categories>cs.NI cs.PL</categories><abstract>  Following the ideas of the Remote Procedure Call model, we have developed a
logic programming counterpart, naturally called Prolog Remote Predicate Call
(Prolog RPC). The Prolog RPC protocol facilitates the integration of Prolog
code in multi-language applications as well as the development of distributed
intelligent applications. One use of the protocol's most important uses could
be the development of distributed applications that use Prolog at least
partially to achieve their goals. Most notably the Distributed Artificial
Intelligence (DAI) applications that are suitable for logic programming can
profit from the use of the protocol. After proving its usefulness, we went
further, developing a new version of the protocol, making it more reliable and
extending its functionality. Because it has a new syntax and the new set of
commands, we call this version Enhanced Prolog Remote Procedure Call. This
paper describes the new features and modifications this second version
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603103</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603103</id><created>2006-03-26</created><authors><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Zehavi</keyname><forenames>Ephraim</forenames></author></authors><title>Bargaining over the interference channel</title><categories>cs.IT math.IT</categories><abstract>  In this paper we analyze the interference channel as a conflict situation.
This viewpoint implies that certain points in the rate region are unreasonable
to one of the players. Therefore these points cannot be considered achievable
based on game theoretic considerations. We then propose to use Nash bargaining
solution as a tool that provides preferred points on the boundary of the game
theoretic rate region. We provide analysis for the 2x2 intereference channel
using the FDM achievable rate region. We also outline how to generalize our
results to other achievable rate regions for the interference channel as well
as the multiple access channel.
  Keywords: Spectrum optimization, distributed coordination, game theory,
interference channel, multiple access channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603104</id><created>2006-03-27</created><authors><author><keyname>Atassi</keyname><forenames>Vincent</forenames><affiliation>LIPN</affiliation></author><author><keyname>Baillot</keyname><forenames>Patrick</forenames><affiliation>LIPN</affiliation></author><author><keyname>Terui</keyname><forenames>Kazushige</forenames><affiliation>NII</affiliation></author></authors><title>Verification of Ptime reducibility for system F terms via Dual Light
  Affine Logic</title><categories>cs.LO</categories><comments>21 pages</comments><proxy>ccsd ccsd-00021834</proxy><journal-ref>A para\^{i}tre dans Proceedings Computer Science Logic 2006
  (CSL'06), LNCS, Springer. (2006)</journal-ref><abstract>  In a previous work we introduced Dual Light Affine Logic (DLAL)
([BaillotTerui04]) as a variant of Light Linear Logic suitable for guaranteeing
complexity properties on lambda-calculus terms: all typable terms can be
evaluated in polynomial time and all Ptime functions can be represented. In the
present work we address the problem of typing lambda-terms in second-order
DLAL. For that we give a procedure which, starting with a term typed in system
F, finds all possible ways to decorate it into a DLAL typed term. We show that
our procedure can be run in time polynomial in the size of the original Church
typed system F term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603105</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603105</id><created>2006-03-27</created><authors><author><keyname>Kucherov</keyname><forenames>Gregory</forenames><affiliation>LIFL</affiliation></author><author><keyname>Noe</keyname><forenames>Laurent</forenames><affiliation>LIFL</affiliation></author><author><keyname>Roytberg</keyname><forenames>Mikhail</forenames><affiliation>LIFL</affiliation></author></authors><title>A unifying framework for seed sensitivity and its application to subset
  seeds (Extended abstract)</title><categories>cs.OH</categories><proxy>ccsd inria-00001164</proxy><journal-ref>Algorithms in Bioinformatics, LNBI 3692 : 251-263, 2005</journal-ref><doi>10.1007/11557067_21</doi><abstract>  We propose a general approach to compute the seed sensitivity, that can be
applied to different definitions of seeds. It treats separately three
components of the seed sensitivity problem - a set of target alignments, an
associated probability distribution, and a seed model - that are specified by
distinct finite automata. The approach is then applied to a new concept of
subset seeds for which we propose an efficient automaton construction.
Experimental results confirm that sensitive subset seeds can be efficiently
designed using our approach, and can then be used in similarity search
producing better results than ordinary spaced seeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603106</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603106</id><created>2006-03-27</created><authors><author><keyname>Kucherov</keyname><forenames>Gregory</forenames><affiliation>LIFL</affiliation></author><author><keyname>Noe</keyname><forenames>Laurent</forenames><affiliation>LIFL</affiliation></author><author><keyname>Ponty</keyname><forenames>Yann</forenames><affiliation>LRI</affiliation></author></authors><title>Estimating seed sensitivity on homogeneous alignments</title><categories>cs.OH</categories><proxy>ccsd inria-00001163</proxy><journal-ref>Proceedings of the Fourth IEEE Symposium on Bioinformatics and
  Bioengineering (BIBE), 387-394, 2004</journal-ref><doi>10.1109/BIBE.2004.1317369</doi><abstract>  We address the problem of estimating the sensitivity of seed-based similarity
search algorithms. In contrast to approaches based on Markov models [18, 6, 3,
4, 10], we study the estimation based on homogeneous alignments. We describe an
algorithm for counting and random generation of those alignments and an
algorithm for exact computation of the sensitivity for a broad class of seed
strategies. We provide experimental results demonstrating a bias introduced by
ignoring the homogeneousness condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603107</id><created>2006-03-28</created><updated>2006-03-28</updated><authors><author><keyname>Ayuso</keyname><forenames>Pedro Fortuny</forenames></author></authors><title>Towards an information-theoretically safe cryptographic protocol</title><categories>cs.CR</categories><comments>2 pages</comments><abstract>  We introduce what --if some kind of group action exists-- is a truly
(information theoretically) safe cryptographic communication system: a protocol
which provides \emph{zero} information to any passive adversary having full
access to the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603108</id><created>2006-03-28</created><authors><author><keyname>Brinkmeier</keyname><forenames>Michael</forenames></author></authors><title>Minimizing Symmetric Set Functions Faster</title><categories>cs.DM math.CO</categories><comments>9 pages</comments><acm-class>G.2.1; G.1.6; F.2.2</acm-class><abstract>  We describe a combinatorial algorithm which, given a monotone and consistent
symmetric set function d on a finite set V in the sense of Rizzi, constructs a
non trivial set S minimizing d(S,V-S). This includes the possibility for the
minimization of symmetric submodular functions. The presented algorithm
requires at most as much time as the one described by Rizzi, but depending on
the function d, it may allow several improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603109</identifier>
 <datestamp>2011-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603109</id><created>2006-03-28</created><updated>2011-09-01</updated><authors><author><keyname>Vijayakumaran</keyname><forenames>Saravanan</forenames></author></authors><title>Encoding of Functions of Correlated Sources</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><abstract>  This submission is being withdrawn due to serious errors in the achievability
proofs. The reviewers of the journal I had submitted to had found errors back
in 2006. I had forgotten about this paper until I saw the CFP for a JSAC issue
on in-network computation.
http://www.jsac.ucsd.edu/Calls/in-networkcomputationcfp.pdf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603110</id><created>2006-03-28</created><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Asymptotic Learnability of Reinforcement Problems with Arbitrary
  Dependence</title><categories>cs.LG cs.AI</categories><comments>15 pages</comments><report-no>IDSIA-09-06</report-no><journal-ref>Proc. 17th International Conf. on Algorithmic Learning Theory (ALT
  2006) pages 334-347</journal-ref><abstract>  We address the problem of reinforcement learning in which observations may
exhibit an arbitrary form of stochastic dependence on past observations and
actions. The task for an agent is to attain the best possible asymptotic reward
where the true generating environment is unknown but belongs to a known
countable family of environments. We find some sufficient conditions on the
class of environments under which an agent exists which attains the best
asymptotic reward for any environment in the class. We analyze how tight these
conditions are and how they relate to different probabilistic assumptions known
in reinforcement learning and related fields, such as Markov Decision Processes
and mixing conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603111</id><created>2006-03-28</created><authors><author><keyname>Blachowicz</keyname><forenames>T.</forenames></author><author><keyname>Wieja</keyname><forenames>M.</forenames></author></authors><title>Remote-control and clustering of physical computations using the XML-RPC
  protocol and the open-Mosix system</title><categories>cs.DC cs.NI</categories><comments>18 pages, 2 figures</comments><abstract>  The applications of the remote control of physical simulations performed in
clustered computers running under an open-Mosix system are presented. Results
from the simulation of a 2-dimensional ferromagnetic system of spins in the
Ising scheme are provided. Basic parameters of a simulated hysteresis loop like
coercivity and exchange bias due to pinning of ferromagnetic spins are given.
The paper describes in physicists terminology a cost effective solution which
utilizes an XML-RPC protocol (Extensible Markup Language - Remote Procedure
Calling) and standard C++ and Python languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603112</id><created>2006-03-28</created><authors><author><keyname>Kong</keyname><forenames>Joseph S.</forenames></author><author><keyname>Bridgewater</keyname><forenames>Jesse S. A.</forenames></author><author><keyname>Roychowdhury</keyname><forenames>Vwani P.</forenames></author></authors><title>A General Framework for Scalability and Performance Analysis of DHT
  Routing Systems</title><categories>cs.DC</categories><comments>11 pages, 8 figures; to be published in IEEE DSN 2006</comments><abstract>  In recent years, many DHT-based P2P systems have been proposed, analyzed, and
certain deployments have reached a global scale with nearly one million nodes.
One is thus faced with the question of which particular DHT system to choose,
and whether some are inherently more robust and scalable.
 Toward developing such a comparative framework, we present the reachable
component method (RCM) for analyzing the performance of different DHT routing
systems subject to random failures. We apply RCM to five DHT systems and obtain
analytical expressions that characterize their routability as a continuous
function of system size and node failure probability. An important consequence
is that in the large-network limit, the routability of certain DHT systems go
to zero for any non-zero probability of node failure. These DHT routing
algorithms are therefore unscalable, while some others, including Kademlia,
which powers the popular eDonkey P2P system, are found to be scalable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603113</identifier>
 <datestamp>2009-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603113</id><created>2006-03-28</created><authors><author><keyname>Gornev</keyname><forenames>Serge</forenames></author></authors><title>Mathematical Modeling of Aerodynamic Space -to - Surface Flight with
  Trajectory for Avoid Intercepting Process</title><categories>cs.OH</categories><abstract>  Modeling has been created for a Space-to-Surface system defined for an
optimal trajectory for targeting in terminal phase with avoids an intercepting
process. The modeling includes models for simulation atmosphere, speed of
sound, aerodynamic flight and navigation by an infrared system. The modeling
and simulation includes statistical analysis of the modeling results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603114</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603114</id><created>2006-03-29</created><authors><author><keyname>Pluta</keyname><forenames>Gregory A.</forenames></author><author><keyname>Brumbaugh</keyname><forenames>Larry</forenames></author><author><keyname>Yurcik</keyname><forenames>William</forenames></author></authors><title>Using SMART for Customized Monitoring of Windows Services</title><categories>cs.NI cs.CR</categories><comments>15 pages, 10 figures, 2 tables</comments><abstract>  We focus on examining and working with an important category of computer
software called Services, which are provided as a part of newer Microsoft
Windows operating systems. A typical Windows user transparently utilizes many
of these services but is frequently unaware of their existence. Since some
services have the potential to create significant problems when they are
executing, it is important for a system administrator to identify which
services are running on the network, the types of processing done by each
service, and any interrelationships among the various services. This
information can then be used to improve the overall integrity of both the
individual computer where a questionable service is running and in aggregate an
entire network of computers.
  NCSA has developed an application called SMART (Services Monitoring And
Reporting Tool) that can be used to identify and display all services currently
running in the network. A commercial program called Hyena remotely monitors the
services on all computers attached to the network and exports this information
to SMART. SMART produces various outputs that the system administrator can
analyze and then determine appropriate actions to take. In particular, SMART
provides a color coordinated user interface to quickly identify and classify
both potentially hazardous services and also unknown services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603115</id><created>2006-03-29</created><authors><author><keyname>Da Gra&#xe7;ca</keyname><forenames>Guillaume</forenames><affiliation>LP2A</affiliation></author><author><keyname>Defour</keyname><forenames>David</forenames><affiliation>LP2A</affiliation></author></authors><title>Implementation of float-float operators on graphics hardware</title><categories>cs.AR cs.GR</categories><proxy>ccsd ccsd-00021443</proxy><abstract>  The Graphic Processing Unit (GPU) has evolved into a powerful and flexible
processor. The latest graphic processors provide fully programmable vertex and
pixel processing units that support vector operations up to single
floating-point precision. This computational power is now being used for
general-purpose computations. However, some applications require higher
precision than single precision. This paper describes the emulation of a 44-bit
floating-point number format and its corresponding operations. An
implementation is presented along with performance and accuracy results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603116</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603116</id><created>2006-03-29</created><updated>2006-04-03</updated><authors><author><keyname>Giraldi</keyname><forenames>G. A.</forenames></author><author><keyname>Moutinho</keyname><forenames>B. F.</forenames></author><author><keyname>de Carvalho</keyname><forenames>D. M. L.</forenames></author><author><keyname>de Oliveira</keyname><forenames>J. C.</forenames></author></authors><title>Fourier Analysis and Holographic Representations of 1D and 2D Signals</title><categories>cs.CV</categories><comments>13 pages</comments><acm-class>I.4.10</acm-class><abstract>  In this paper, we focus on Fourier analysis and holographic transforms for
signal representation. For instance, in the case of image processing, the
holographic representation has the property that an arbitrary portion of the
transformed image enables reconstruction of the whole image with details
missing. We focus on holographic representation defined through the Fourier
Transforms. Thus, We firstly review some results in Fourier transform and
Fourier series. Next, we review the Discrete Holographic Fourier Transform
(DHFT) for image representation. Then, we describe the contributions of our
work. We show a simple scheme for progressive transmission based on the DHFT.
Next, we propose the Continuous Holographic Fourier Transform (CHFT) and
discuss some theoretical aspects of it for 1D signals. Finally, some testes are
presented in the experimental results
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603117</id><created>2006-03-29</created><updated>2006-05-01</updated><authors><author><keyname>Bertot</keyname><forenames>Yves</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Affine functions and series with co-inductive real numbers</title><categories>cs.LO</categories><proxy>ccsd inria-00001171</proxy><journal-ref>Mathematical Structures in Computer Science 17, 1 (2006)</journal-ref><abstract>  We extend the work of A. Ciaffaglione and P. Di Gianantonio on mechanical
verification of algorithms for exact computation on real numbers, using
infinite streams of digits implemented as co-inductive types. Four aspects are
studied: the first aspect concerns the proof that digit streams can be related
to the axiomatized real numbers that are already axiomatized in the proof
system (axiomatized, but with no fixed representation). The second aspect
re-visits the definition of an addition function, looking at techniques to let
the proof search mechanism perform the effective construction of an algorithm
that is correct by construction. The third aspect concerns the definition of a
function to compute affine formulas with positive rational coefficients. This
should be understood as a testbed to describe a technique to combine
co-recursion and recursion to obtain a model for an algorithm that appears at
first sight to be outside the expressive power allowed by the proof system. The
fourth aspect concerns the definition of a function to compute series, with an
application on the series that is used to compute Euler's number e. All these
experiments should be reproducible in any proof system that supports
co-inductive types, co-recursion and general forms of terminating recursion,
but we performed with the Coq system [12, 3, 14].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603118</identifier>
 <datestamp>2008-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603118</id><created>2006-03-29</created><updated>2008-11-07</updated><authors><author><keyname>Bertot</keyname><forenames>Yves</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Coq in a Hurry</title><categories>cs.LO</categories><proxy>ccsd inria-00001173</proxy><journal-ref>Cours (2008) 22 pages</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These notes provide a quick introduction to the Coq system and show how it
can be used to define logical concepts and functions and reason about them. It
is designed as a tutorial, so that readers can quickly start their own
experiments, learning only a few of the capabilities of the system. A much more
comprehensive study is provided in [1], which also provides an extensive
collection of exercises to train on.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603119</id><created>2006-03-29</created><authors><author><keyname>Bertot</keyname><forenames>Yves</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>CoInduction in Coq</title><categories>cs.LO</categories><proxy>ccsd inria-00001174</proxy><abstract>  We describe the basic notions of co-induction as they are available in the
coq system. As an application, we describe arithmetic properties for simple
representations of real numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603120</id><created>2006-03-29</created><authors><author><keyname>He</keyname><forenames>Zengyou</forenames></author></authors><title>Approximation Algorithms for K-Modes Clustering</title><categories>cs.AI</categories><comments>7 pages</comments><report-no>Tr-06-0330</report-no><abstract>  In this paper, we study clustering with respect to the k-modes objective
function, a natural formulation of clustering for categorical data. One of the
main contributions of this paper is to establish the connection between k-modes
and k-median, i.e., the optimum of k-median is at most twice the optimum of
k-modes for the same categorical data clustering problem. Based on this
observation, we derive a deterministic algorithm that achieves an approximation
factor of 2. Furthermore, we prove that the distance measure in k-modes defines
a metric. Hence, we are able to extend existing approximation algorithms for
metric k-median to k-modes. Empirical results verify the superiority of our
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603121</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603121</id><created>2006-03-30</created><authors><author><keyname>Turner</keyname><forenames>Scott</forenames></author><author><keyname>Perez-Quinones</keyname><forenames>Manuel A.</forenames></author><author><keyname>Edwards</keyname><forenames>Stephen H.</forenames></author></authors><title>minimUML: A Minimalist Approach to UML Diagraming for Early Computer
  Science Education</title><categories>cs.HC cs.SE</categories><comments>38 pages, 15 figures</comments><acm-class>K.3.2; H.5.2; D.2.2</acm-class><abstract>  The Unified Modeling Language (UML) is commonly used in introductory Computer
Science to teach basic object-oriented design. However, there appears to be a
lack of suitable software to support this task. Many of the available programs
that support UML focus on developing code and not on enhancing learning. Those
that were designed for educational use sometimes have poor interfaces or are
missing common and important features, such as multiple selection and
undo/redo. There is a need for software that is tailored to an instructional
environment and has all the useful and needed functionality for that specific
task. This is the purpose of minimUML. minimUML provides a minimum amount of
UML, just what is commonly used in beginning programming classes, while
providing a simple, usable interface. In particular, minimUML was designed to
support abstract design while supplying features for exploratory learning and
error avoidance. In addition, it allows for the annotation of diagrams, through
text or freeform drawings, so students can receive feedback on their work.
minimUML was developed with the goal of supporting ease of use, supporting
novice students, and a requirement of no prior-training for its use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603122</id><created>2006-03-30</created><authors><author><keyname>Foustoucos</keyname><forenames>Eug&#xe9;nie</forenames><affiliation>MPLA</affiliation></author><author><keyname>Guessarian</keyname><forenames>Irene</forenames><affiliation>LIAFA</affiliation></author></authors><title>Complexity of Monadic inf-datalog. Application to temporal logic</title><categories>cs.DS</categories><proxy>ccsd ccsd-00021966</proxy><journal-ref>Proc. 4th Panhellenic Logic Symposium (2003) 95-99</journal-ref><abstract>  In [11] we defined Inf-Datalog and characterized the fragments of Monadic
inf-Datalog that have the same expressive power as Modal Logic (resp. $CTL$,
alternation-free Modal $\mu$-calculus and Modal $\mu$-calculus). We study here
the time and space complexity of evaluation of Monadic inf-Datalog programs on
finite models. We deduce a new unified proof that model checking has 1. linear
data and program complexities (both in time and space) for $CTL$ and
alternation-free Modal $\mu$-calculus, and 2. linear-space (data and program)
complexities, linear-time program complexity and polynomial-time data
complexity for $L\mu\_k$ (Modal $\mu$-calculus with fixed alternation-depth at
most $k$).}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603123</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603123</id><created>2006-03-30</created><updated>2006-11-30</updated><authors><author><keyname>Yang</keyname><forenames>Sheng</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Towards the Optimal Amplify-and-Forward Cooperative Diversity Scheme</title><categories>cs.IT math.IT</categories><comments>30 pages, 11 figures, submitted to IEEE trans. IT, revised version</comments><acm-class>H.1.1</acm-class><abstract>  In a slow fading channel, how to find a cooperative diversity scheme that
achieves the transmit diversity bound is still an open problem. In fact, all
previously proposed amplify-and-forward (AF) and decode-and-forward (DF)
schemes do not improve with the number of relays in terms of the diversity
multiplexing tradeoff (DMT) for multiplexing gains r higher than 0.5. In this
work, we study the class of slotted amplify-and-forward (SAF) schemes. We first
establish an upper bound on the DMT for any SAF scheme with an arbitrary number
of relays N and number of slots M. Then, we propose a sequential SAF scheme
that can exploit the potential diversity gain in the high multiplexing gain
regime. More precisely, in certain conditions, the sequential SAF scheme
achieves the proposed DMT upper bound which tends to the transmit diversity
bound when M goes to infinity. In particular, for the two-relay case, the
three-slot sequential SAF scheme achieves the proposed upper bound and
outperforms the two-relay non-orthorgonal amplify-and-forward (NAF) scheme of
Azarian et al. for multiplexing gains r &lt; 2/3. Numerical results reveal a
significant gain of our scheme over the previously proposed AF schemes,
especially in high spectral efficiency and large network size regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603124</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603124</id><created>2006-03-30</created><updated>2006-03-31</updated><authors><author><keyname>Yang</keyname><forenames>Sheng</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Diversity-Multiplexing Tradeoff of Double Scattering MIMO Channels</title><categories>cs.IT math.IT</categories><comments>17 pages, 1 figure, submitted to IEEE trans. IT</comments><acm-class>H.1.1</acm-class><abstract>  It is well known that the presence of double scattering degrades the
performance of a MIMO channel, in terms of both the multiplexing gain and the
diversity gain. In this paper, a closed-form expression of the
diversity-multiplexing tradeoff (DMT) of double scattering MIMO channels is
obtained. It is shown that, for a channel with nT transmit antennas, nR receive
antennas and nS scatterers, the DMT only depends on the ordered version of the
triple (nT,nS,nR), for arbitrary nT, nS and nR. The condition under which the
double scattering channel has the same DMT as the single scattering channel is
also established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603125</id><created>2006-03-30</created><updated>2006-06-06</updated><authors><author><keyname>Abbott</keyname><forenames>Russ</forenames></author></authors><title>If a tree casts a shadow is it telling the time?</title><categories>cs.MA cs.GL</categories><comments>12 pages. Submitted for conference presentation</comments><abstract>  Physical processes are computations only when we use them to externalize
thought. Computation is the performance of one or more fixed processes within a
contingent environment. We reformulate the Church-Turing thesis so that it
applies to programs rather than to computability. When suitably formulated
agent-based computing in an open, multi-scalar environment represents the
current consensus view of how we interact with the world. But we don't know how
to formulate multi-scalar environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603126</id><created>2006-03-30</created><authors><author><keyname>Abbott</keyname><forenames>Russ</forenames></author></authors><title>Open at the Top; Open at the Bottom; and Continually (but Slowly)
  Evolving</title><categories>cs.MA</categories><comments>6 pages. To be presented at the IEEE Conference on Systems of Systems
  Engineering, April, 2006</comments><abstract>  Systems of systems differ from traditional systems in that they are open at
the top, open at the bottom, and continually (but slowly) evolving. &quot;Open at
the top&quot; means that there is no pre-defined top level application. New
applications may be created at any time. &quot;Open at the bottom&quot; means that the
system primitives are defined functionally rather than concretely. This allows
the implementation of these primitives to be modified as technology changes.
&quot;Continually (but slowly) evolving&quot; means that the system's functionality is
stable enough to be useful but is understood to be subject to modification.
Systems with these properties tend to be environments within which other
systems operate--and hence are systems of systems. It is also important to
understand the larger environment within which a system of systems exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603127</id><created>2006-03-30</created><authors><author><keyname>Abbott</keyname><forenames>Russ</forenames></author></authors><title>Complex Systems + Systems Engineering = Complex Systems Engineeri</title><categories>cs.MA</categories><comments>10 pages. Position paper to be presented at Conference on Systems
  Engineering Research</comments><abstract>  One may define a complex system as a system in which phenomena emerge as a
consequence of multiscale interaction among the system's components and their
environments. The field of Complex Systems is the study of such
systems--usually naturally occurring, either bio-logical or social. Systems
Engineering may be understood to include the conceptualising and building of
systems that consist of a large number of concurrently operating and
interacting components--usually including both human and non-human elements. It
has become increasingly apparent that the kinds of systems that systems
engineers build have many of the same multiscale characteristics as those of
naturally occurring complex systems. In other words, systems engineering is the
engineering of complex systems. This paper and the associated panel will
explore some of the connections between the fields of complex systems and
systems engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603128</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603128</id><created>2006-03-31</created><updated>2006-11-30</updated><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author></authors><title>On Cosets of the Generalized First-Order Reed-Muller Code with Low PMEPR</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Trans. Inf. Theory, vol. 52, no. 7, pp. 3220-3232, July 2006</journal-ref><abstract>  Golay sequences are well suited for the use as codewords in orthogonal
frequency-division multiplexing (OFDM), since their peak-to-mean envelope power
ratio (PMEPR) in q-ary phase-shift keying (PSK) modulation is at most 2. It is
known that a family of polyphase Golay sequences of length 2^m organizes in
m!/2 cosets of a q-ary generalization of the first-order Reed-Muller code,
RM_q(1,m). In this paper a more general construction technique for cosets of
RM_q(1,m) with low PMEPR is established. These cosets contain so-called
near-complementary sequences. The application of this theory is then
illustrated by providing some construction examples. First, it is shown that
the m!/2 cosets of RM_q(1,m) comprised of Golay sequences just arise as a
special case. Second, further families of cosets of RM_q(1,m) with maximum
PMEPR between 2 and 4 are presented, showing that some previously unexplained
phenomena can now be understood within a unified framework. A lower bound on
the PMEPR of cosets of RM_q(1,m) is proved as well, and it is demonstrated that
the upper bound on the PMEPR is tight in many cases. Finally it is shown that
all upper bounds on the PMEPR of cosets of RM_q(1,m) also hold for the
peak-to-average power ratio (PAPR) under the Walsh-Hadamard transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603129</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603129</id><created>2006-03-31</created><authors><author><keyname>Su</keyname><forenames>Xiamoneg</forenames></author><author><keyname>Bolzoni</keyname><forenames>Damiano</forenames></author><author><keyname>van Eck</keyname><forenames>Pascal</forenames></author></authors><title>A Business Goal Driven Approach for Understanding and Specifying
  Information Security Requirements</title><categories>cs.CR</categories><report-no>TR-CTIT-06-08</report-no><abstract>  In this paper we present an approach for specifying and prioritizing
information security requirements in organizations. It is important to
prioritize security requirements since hundred per cent security is not
achievable and the limited resources available should be directed to satisfy
the most important ones. We propose to link explicitly security requirements
with the organization's business vision, i.e. to provide business rationale for
security requirements. The rationale is then used as a basis for comparing the
importance of different security requirements. A conceptual framework is
presented, where the relationships between business vision, critical impact
factors and valuable assets (together with their security requirements) are
shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603130</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603130</id><created>2006-03-31</created><authors><author><keyname>Agarwal</keyname><forenames>Rashmi</forenames></author><author><keyname>Santhanam</keyname><forenames>M. S.</forenames></author></authors><title>Digital watermarking in the singular vector domain</title><categories>cs.MM</categories><comments>11 pages, 21 figures, Elsevier class</comments><journal-ref>International Journal of Image and Graphics, volume 8, page 351
  (2008)</journal-ref><doi>10.1142/S0219467808003131</doi><abstract>  Many current watermarking algorithms insert data in the spatial or transform
domains like the discrete cosine, the discrete Fourier, and the discrete
wavelet transforms. In this paper, we present a data-hiding algorithm that
exploits the singular value decomposition (SVD) representation of the data. We
compute the SVD of the host image and the watermark and embed the watermark in
the singular vectors of the host image. The proposed method leads to an
imperceptible scheme for digital images, both in grey scale and color and is
quite robust against attacks like noise and JPEG compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603131</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603131</id><created>2006-03-31</created><authors><author><keyname>Snow</keyname><forenames>C.</forenames></author><author><keyname>Lampe</keyname><forenames>L.</forenames></author><author><keyname>Schober</keyname><forenames>R.</forenames></author></authors><title>Error Rate Analysis for Coded Multicarrier Systems over Quasi-Static
  Fading Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, 2 tables. Submitted to Globecom 2006</comments><abstract>  This paper presents two methods for approximating the performance of coded
multicarrier systems operating over frequency-selective, quasi-static fading
channels with non-ideal interleaving. The first method is based on
approximating the performance of the system over each realization of the
channel, and is suitable for obtaining the outage performance of this type of
system. The second method is based on knowledge of the correlation matrix of
the frequency-domain channel gains and can be used to directly obtain the
average performance. Both of the methods are applicable for
convolutionally-coded interleaved systems employing Quadrature Amplitude
Modulation (QAM). As examples, both methods are used to study the performance
of the Multiband Orthogonal Frequency Division Multiplexing (OFDM) proposal for
high data-rate Ultra-Wideband (UWB) communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0603132</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0603132</id><created>2006-03-31</created><authors><author><keyname>McGuigan</keyname><forenames>Michael</forenames></author></authors><title>Graphics Turing Test</title><categories>cs.GR</categories><comments>6 pages</comments><acm-class>I.3.7</acm-class><abstract>  We define a Graphics Turing Test to measure graphics performance in a similar
manner to the definition of the traditional Turing Test. To pass the test one
needs to reach a computational scale, the Graphics Turing Scale, for which
Computer Generated Imagery becomes comparatively indistinguishable from real
images while also being interactive. We derive an estimate for this
computational scale which, although large, is within reach of todays
supercomputers. We consider advantages and disadvantages of various computer
systems designed to pass the Graphics Turing Test. Finally we discuss
commercial applications from the creation of such a system, in particular
Interactive Cinema.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604001</id><created>2006-04-01</created><authors><author><keyname>Rossi</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Conan-Guez</keyname><forenames>Brieuc</forenames><affiliation>LITA</affiliation></author></authors><title>Theoretical Properties of Projection Based Multilayer Perceptrons with
  Functional Inputs</title><categories>cs.NE</categories><proxy>ccsd inria-00001191</proxy><doi>10.1007/s11063-005-3100-2</doi><abstract>  Many real world data are sampled functions. As shown by Functional Data
Analysis (FDA) methods, spectra, time series, images, gesture recognition data,
etc. can be processed more efficiently if their functional nature is taken into
account during the data analysis process. This is done by extending standard
data analysis methods so that they can apply to functional inputs. A general
way to achieve this goal is to compute projections of the functional data onto
a finite dimensional sub-space of the functional space. The coordinates of the
data on a basis of this sub-space provide standard vector representations of
the functions. The obtained vectors can be processed by any standard method. In
our previous work, this general approach has been used to define projection
based Multilayer Perceptrons (MLPs) with functional inputs. We study in this
paper important theoretical properties of the proposed model. We show in
particular that MLPs with functional inputs are universal approximators: they
can approximate to arbitrary accuracy any continuous mapping from a compact
sub-space of a functional space to R. Moreover, we provide a consistency result
that shows that any mapping from a functional space to R can be learned thanks
to examples by a projection based MLP: the generalization mean square error of
the MLP decreases to the smallest possible mean square error on the data when
the number of examples goes to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604002</id><created>2006-04-01</created><authors><author><keyname>Lopatenko</keyname><forenames>Andrei</forenames></author><author><keyname>Bertossi</keyname><forenames>Leopoldo</forenames></author></authors><title>Complexity of Consistent Query Answering in Databases under
  Cardinality-Based and Incremental Repair Semantics</title><categories>cs.DB cs.CC</categories><comments>26 pages, 2 figures</comments><abstract>  Consistent Query Answering (CQA) is the problem of computing from a database
the answers to a query that are consistent with respect to certain integrity
constraints that the database, as a whole, may fail to satisfy. Consistent
answers have been characterized as those that are invariant under certain
minimal forms of restoration of the database consistency. We investigate
algorithmic and complexity theoretic issues of CQA under database repairs that
minimally depart -wrt the cardinality of the symmetric difference- from the
original database. We obtain first tight complexity bounds.
  We also address the problem of incremental complexity of CQA, that naturally
occurs when an originally consistent database becomes inconsistent after the
execution of a sequence of update operations. Tight bounds on incremental
complexity are provided for various semantics under denial constraints. Fixed
parameter tractability is also investigated in this dynamic context, where the
size of the update sequence becomes the relevant parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604003</id><created>2006-04-02</created><authors><author><keyname>Potgieter</keyname><forenames>Petrus H.</forenames></author></authors><title>Hypercomputing the Mandelbrot Set?</title><categories>cs.CC</categories><comments>11 pages, 2 figures</comments><acm-class>F.1.1</acm-class><abstract>  The Mandelbrot set is an extremely well-known mathematical object that can be
described in a quite simple way but has very interesting and non-trivial
properties. This paper surveys some results that are known concerning the
(non-)computability of the set. It considers two models of decidability over
the reals (which have been treated much more thoroughly and technically by
Hertling (2005), Blum, Shub and Smale, Brattka (2003) and Weihrauch (1999 and
2003) among others), two over the computable reals (the Russian school and
hypercomputation) and a model over the rationals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604004</id><created>2006-04-02</created><authors><author><keyname>Evako</keyname><forenames>Alexander V.</forenames></author></authors><title>The Poincare conjecture for digital spaces. Properties of digital
  n-dimensional disks and spheres</title><categories>cs.DM cs.CV math.AT</categories><abstract>  Motivated by the Poincare conjecture, we study properties of digital
n-dimensional spheres and disks, which are digital models of their continuous
counterparts. We introduce homeomorphic transformations of digital manifolds,
which retain the connectedness, the dimension, the Euler characteristics and
the homology groups of manifolds. We find conditions where an n-dimensional
digital manifold is the n-dimensional digital sphere and discuss the link
between continuous closed n-manifolds and their digital models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604005</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604005</id><created>2006-04-03</created><updated>2006-11-15</updated><authors><author><keyname>Servetto</keyname><forenames>Sergio D.</forenames><affiliation>Cornell University</affiliation></author></authors><title>Multiterminal Source Coding with Two Encoders--I: A Computable Outer
  Bound</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory; Revised,
  November 2006. Substantial revision after the first round of reviews</comments><abstract>  In this first part, a computable outer bound is proved for the multiterminal
source coding problem, for a setup with two encoders, discrete memoryless
sources, and bounded distortion measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604006</id><created>2006-04-03</created><authors><author><keyname>Bateman</keyname><forenames>David</forenames></author><author><keyname>Adler</keyname><forenames>Andy</forenames></author></authors><title>Sparse Matrix Implementation in Octave</title><categories>cs.MS</categories><report-no>Octave2006/04</report-no><abstract>  There are many classes of mathematical problems which give rise to matrices,
where a large number of the elements are zero. In this case it makes sense to
have a special matrix type to handle this class of problems where only the
non-zero elements of the matrix are stored. Not only does this reduce the
amount of memory to store the matrix, but it also means that operations on this
type of matrix can take advantage of the a-priori knowledge of the positions of
the non-zero elements to accelerate their calculations. A matrix type that
stores only the non-zero elements is generally called sparse.
  Until recently Octave has lacked a full implementation of sparse matrices.
This article address the implementation of sparse matrices within Octave,
including their storage, creation, fundamental algorithms used, their
implementations and the basic operations and functions implemented for sparse
matrices. Mathematical issues such as the return types of sparse operations,
matrix fill-in and reordering for sparse matrix factorization is discussed in
the context of a real example.
  Benchmarking of Octave's implementation of sparse operations compared to
their equivalent in Matlab are given and their implications discussed. Results
are presented for multiplication and linear algebra operations for various
matrix orders and densities. Furthermore, the use of Octave's sparse matrix
implementation is demonstrated using a real example of a finite element model
(FEM) problem. Finally, the method of using sparse matrices with Octave's
oct-files is discussed. The means of creating, using and returning sparse
matrices within oct-files is discussed as well as the differences between
Octave's Sparse and Array classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604007</id><created>2006-04-04</created><updated>2006-10-02</updated><authors><author><keyname>Boyer</keyname><forenames>Laurent</forenames><affiliation>LIP</affiliation></author><author><keyname>Poupet</keyname><forenames>Victor</forenames><affiliation>LIP</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LM-Savoie</affiliation></author></authors><title>On the Complexity of Limit Sets of Cellular Automata Associated with
  Probability Measures</title><categories>cs.DM cs.CC math.DS</categories><proxy>ccsd ccsd-00022186</proxy><journal-ref>Mathematical Foundations of Computer Science 2006Springer (Ed.)
  (28/08/2006) 190-201</journal-ref><abstract>  We study the notion of limit sets of cellular automata associated with
probability measures (mu-limit sets). This notion was introduced by P. Kurka
and A. Maass. It is a refinement of the classical notion of omega-limit sets
dealing with the typical long term behavior of cellular automata. It focuses on
the words whose probability of appearance does not tend to 0 as time tends to
infinity (the persistent words). In this paper, we give a characterisation of
the persistent language for non sensible cellular automata associated with
Bernouilli measures. We also study the computational complexity of these
languages. We show that the persistent language can be non-recursive. But our
main result is that the set of quasi-nilpotent cellular automata (those with a
single configuration in their mu-limit set) is neither recursively enumerable
nor co-recursively enumerable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604008</id><created>2006-04-04</created><authors><author><keyname>Arkin</keyname><forenames>Esther M.</forenames></author><author><keyname>Broennimann</keyname><forenames>Herve</forenames></author><author><keyname>Erickson</keyname><forenames>Jeff</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>Lenchner</keyname><forenames>Jonathan</forenames></author><author><keyname>Mitchell</keyname><forenames>Joseph S. B.</forenames></author><author><keyname>Whittlesey</keyname><forenames>Kim</forenames></author></authors><title>Minimum-Cost Coverage of Point Sets by Disks</title><categories>cs.DS cs.CG</categories><comments>10 pages, 4 figures, Latex, to appear in ACM Symposium on
  Computational Geometry 2006</comments><acm-class>F.2.2</acm-class><abstract>  We consider a class of geometric facility location problems in which the goal
is to determine a set X of disks given by their centers (t_j) and radii (r_j)
that cover a given set of demand points Y in the plane at the smallest possible
cost. We consider cost functions of the form sum_j f(r_j), where f(r)=r^alpha
is the cost of transmission to radius r. Special cases arise for alpha=1 (sum
of radii) and alpha=2 (total area); power consumption models in wireless
network design often use an exponent alpha&gt;2. Different scenarios arise
according to possible restrictions on the transmission centers t_j, which may
be constrained to belong to a given discrete set or to lie on a line, etc. We
obtain several new results, including (a) exact and approximation algorithms
for selecting transmission points t_j on a given line in order to cover demand
points Y in the plane; (b) approximation algorithms (and an algebraic
intractability result) for selecting an optimal line on which to place
transmission points to cover Y; (c) a proof of NP-hardness for a discrete set
of transmission points in the plane and any fixed alpha&gt;1; and (d) a
polynomial-time approximation scheme for the problem of computing a minimum
cost covering tour (MCCT), in which the total cost is a linear combination of
the transmission cost for the set of disks and the length of a tour/path that
connects the centers of the disks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604009</id><created>2006-04-05</created><authors><author><keyname>Melkikh</keyname><forenames>Alexey V.</forenames></author></authors><title>Can an Organism Adapt Itself to Unforeseen Circumstances?</title><categories>cs.AI</categories><abstract>  A model of an organism as an autonomous intelligent system has been proposed.
This model was used to analyze learning of an organism in various environmental
conditions. Processes of learning were divided into two types: strong and weak
processes taking place in the absence and the presence of aprioristic
information about an object respectively. Weak learning is synonymous to
adaptation when aprioristic programs already available in a system (an
organism) are started. It was shown that strong learning is impossible for both
an organism and any autonomous intelligent system. It was shown also that the
knowledge base of an organism cannot be updated. Therefore, all behavior
programs of an organism are congenital. A model of a conditioned reflex as a
series of consecutive measurements of environmental parameters has been
advanced. Repeated measurements are necessary in this case to reduce the error
during decision making.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604010</id><created>2006-04-05</created><authors><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author></authors><title>Nearly optimal exploration-exploitation decision thresholds</title><categories>cs.AI cs.LG</categories><comments>10 pages, 2 figures; IDIAP Research Report</comments><report-no>IDIAP-RR-06-12</report-no><abstract>  While in general trading off exploration and exploitation in reinforcement
learning is hard, under some formulations relatively simple solutions exist.
Optimal decision thresholds for the multi-armed bandit problem, one for the
infinite horizon discounted reward case and one for the finite horizon
undiscounted reward case are derived, which make the link between the reward
horizon, uncertainty and the need for exploration explicit. From this result
follow two practical approximate algorithms, which are illustrated
experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604011</id><created>2006-04-05</created><updated>2006-04-06</updated><authors><author><keyname>Getz</keyname><forenames>Gad</forenames></author><author><keyname>Shental</keyname><forenames>Noam</forenames></author><author><keyname>Domany</keyname><forenames>Eytan</forenames></author></authors><title>Semi-Supervised Learning -- A Statistical Physics Approach</title><categories>cs.LG cond-mat.stat-mech cs.CV</categories><comments>9 pages. Appeared in in the Proceedings of &quot;Learning with Partially
  Classified Training Data&quot;, ICML 2005 workshop</comments><abstract>  We present a novel approach to semi-supervised learning which is based on
statistical physics. Most of the former work in the field of semi-supervised
learning classifies the points by minimizing a certain energy function, which
corresponds to a minimal k-way cut solution. In contrast to these methods, we
estimate the distribution of classifications, instead of the sole minimal k-way
cut, which yields more accurate and robust results. Our approach may be applied
to all energy functions used for semi-supervised learning. The method is based
on sampling using a Multicanonical Markov chain Monte-Carlo algorithm, and has
a straightforward probabilistic interpretation, which allows for soft
assignments of points to classes, and also to cope with yet unseen class types.
The suggested approach is demonstrated on a toy data set and on two real-life
data sets of gene expression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604012</id><created>2006-04-05</created><authors><author><keyname>Vuppala</keyname><forenames>Sreeram</forenames></author></authors><title>The Aryabhata Algorithm Using Least Absolute Remainders</title><categories>cs.CR</categories><comments>9 pages</comments><abstract>  This paper presents an introduction to the Aryabhata algorithm for finding
multiplicative inverses and solving linear congruences, both of which have
applications in cryptography. We do so by the use of the least absolute
remainders. The exposition of the Aryabhata algorithm provided here can have
performance that could exceed what was described recently by Rao and Yang.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604013</id><created>2006-04-06</created><updated>2006-04-07</updated><authors><author><keyname>Thite</keyname><forenames>Shripad</forenames></author></authors><title>On Covering a Graph Optimally with Induced Subgraphs</title><categories>cs.DM</categories><comments>9 pages</comments><abstract>  We consider the problem of covering a graph with a given number of induced
subgraphs so that the maximum number of vertices in each subgraph is minimized.
We prove NP-completeness of the problem, prove lower bounds, and give
approximation algorithms for certain graph classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604014</id><created>2006-04-05</created><updated>2006-04-07</updated><authors><author><keyname>Habibi</keyname><forenames>O.</forenames></author><author><keyname>Patihnedj</keyname><forenames>U. R.</forenames></author><author><keyname>Dhar</keyname><forenames>M. O.</forenames></author></authors><title>Towards Analog Reverse Time Computation</title><categories>cs.CC</categories><abstract>  We report the consequences of a destabilization process on a simulated
General Purpose Analog Computer. This new technology overcomes problems linked
with serial ambiguity, and provides an analog bias to encode algorithms whose
complexity is over polynomial. We also implicitly demonstrate how
countermesures of the Stochastic Aperture Degeneracy could efficiently reach
higher computational classes, and would open a road towards Analog Reverse Time
Computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604015</id><created>2006-04-05</created><authors><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Riley</keyname><forenames>George</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author></authors><title>Revealing the Autonomous System Taxonomy: The Machine Learning Approach</title><categories>cs.NI cs.LG</categories><journal-ref>PAM 2006, best paper award</journal-ref><abstract>  Although the Internet AS-level topology has been extensively studied over the
past few years, little is known about the details of the AS taxonomy. An AS
&quot;node&quot; can represent a wide variety of organizations, e.g., large ISP, or small
private business, university, with vastly different network characteristics,
external connectivity patterns, network growth tendencies, and other properties
that we can hardly neglect while working on veracious Internet representations
in simulation environments. In this paper, we introduce a radically new
approach based on machine learning techniques to map all the ASes in the
Internet into a natural AS taxonomy. We successfully classify 95.3% of ASes
with expected accuracy of 78.1%. We release to the community the AS-level
topology dataset augmented with: 1) the AS taxonomy information and 2) the set
of AS attributes we used to classify ASes. We believe that this dataset will
serve as an invaluable addition to further understanding of the structure and
evolution of the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604016</id><created>2006-04-05</created><updated>2006-05-23</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>On Conditional Branches in Optimal Search Trees</title><categories>cs.PF cs.DS cs.IR</categories><comments>8 pages, 5 figures (with 10 illustrations total), 1 table;
  reformatted with some additional notes</comments><acm-class>B.1.4; C.0; C.1.1; D.3.4; E.1; F.2.2; G.3; H.3.3; I.2.8</acm-class><abstract>  Algorithms for efficiently finding optimal alphabetic decision trees -- such
as the Hu-Tucker algorithm -- are well established and commonly used. However,
such algorithms generally assume that the cost per decision is uniform and thus
independent of the outcome of the decision. The few algorithms without this
assumption instead use one cost if the decision outcome is ``less than'' and
another cost otherwise. In practice, neither assumption is accurate for
software optimized for today's microprocessors. Such software generally has one
cost for the more likely decision outcome and a greater cost -- often far
greater -- for the less likely decision outcome. This problem and
generalizations thereof are thus applicable to hard coding static decision tree
instances in software, e.g., for optimizing program bottlenecks or for
compiling switch statements. An O(n^3)-time O(n^2)-space dynamic programming
algorithm can solve this optimal binary decision tree problem, and this
approach has many generalizations that optimize for the behavior of processors
with predictive branch capabilities, both static and dynamic. Solutions to this
formulation are often faster in practice than ``optimal'' decision trees as
formulated in the literature. Different search paradigms can sometimes yield
even better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604017</identifier>
 <datestamp>2008-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604017</id><created>2006-04-05</created><updated>2006-12-07</updated><authors><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Fomenkov</keyname><forenames>Marina</forenames></author><author><keyname>Huffaker</keyname><forenames>Bradley</forenames></author><author><keyname>Hyun</keyname><forenames>Young</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author><author><keyname>Riley</keyname><forenames>George</forenames></author></authors><title>AS Relationships: Inference and Validation</title><categories>cs.NI</categories><comments>Final journal version</comments><acm-class>C.2.5; C.2.1</acm-class><journal-ref>ACM SIGCOMM Computer Communication Review (CCR), v.37, n.1,
  p.29-40, 2007</journal-ref><doi>10.1145/1198255.1198259</doi><abstract>  Research on performance, robustness, and evolution of the global Internet is
fundamentally handicapped without accurate and thorough knowledge of the nature
and structure of the contractual relationships between Autonomous Systems
(ASs). In this work we introduce novel heuristics for inferring AS
relationships. Our heuristics improve upon previous works in several technical
aspects, which we outline in detail and demonstrate with several examples.
Seeking to increase the value and reliability of our inference results, we then
focus on validation of inferred AS relationships. We perform a survey with ASs'
network administrators to collect information on the actual connectivity and
policies of the surveyed ASs. Based on the survey results, we find that our new
AS relationship inference techniques achieve high levels of accuracy: we
correctly infer 96.5% customer to provider (c2p), 82.8% peer to peer (p2p), and
90.3% sibling to sibling (s2s) relationships. We then cross-compare the
reported AS connectivity with the AS connectivity data contained in BGP tables.
We find that BGP tables miss up to 86.2% of the true adjacencies of the
surveyed ASs. The majority of the missing links are of the p2p type, which
highlights the limitations of present measuring techniques to capture links of
this type. Finally, to make our results easily accessible and practically
useful for the community, we open an AS relationship repository where we
archive, on a weekly basis, and make publicly available the complete Internet
AS-level topology annotated with AS relationship information for every pair of
AS neighbors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604018</id><created>2006-04-06</created><updated>2006-08-16</updated><authors><author><keyname>Suneel</keyname><forenames>Madhekar</forenames></author></authors><title>Cryptographic Pseudo-Random Sequences from the Chaotic Henon Map</title><categories>cs.CR nlin.CD</categories><comments>Submitted to the Indian Academy of Sciences for possible publication
  in Sadhana (Academy Proceedings in Engineering Sciences). Results of
  statistical tests included. Introduction revised</comments><abstract>  A scheme for pseudo-random binary sequence generation based on the
two-dimensional discrete-time Henon map is proposed. Properties of the proposed
sequences pertaining to linear complexity, linear complexity profile,
correlation and auto-correlation are investigated. All these properties of the
sequences suggest a strong resemblance to random sequences. Results of
statistical testing of the sequences are found encouraging. An attempt is made
to estimate the keyspace size if the proposed scheme is used for cryptographic
applications. The keyspace size is found to be large and is dependent on the
precision of the computing platform used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604019</id><created>2006-04-06</created><authors><author><keyname>Prasad</keyname><forenames>K. Venkatesh</forenames></author><author><keyname>Giuli</keyname><forenames>TJ</forenames></author><author><keyname>Watson</keyname><forenames>David</forenames></author></authors><title>The Case for Modeling Security, Privacy, Usability and Reliability
  (SPUR) in Automotive Software</title><categories>cs.SE cs.CR cs.HC</categories><comments>12 pages, 3 figures, presented at the 2006 Automotive Software
  Workshop, San Diego, CA</comments><acm-class>D.2.4; K.4.1; H.5.2; K.6.5</acm-class><abstract>  Over the past five years, there has been considerable growth and established
value in the practice of modeling automotive software requirements. Much of
this growth has been centered on requirements of software associated with the
established functional areas of an automobile, such as those associated with
powertrain, chassis, body, safety and infotainment. This paper makes a case for
modeling four additional attributes that are increasingly important as vehicles
become information conduits: security, privacy, usability, and reliability.
These four attributes are important in creating specifications for embedded
in-vehicle automotive software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604020</id><created>2006-04-06</created><updated>2006-12-15</updated><authors><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author></authors><title>Approximation Algorithms for Restricted Cycle Covers Based on Cycle
  Decompositions</title><categories>cs.DS cs.CC cs.DM</categories><comments>This paper has been joint with &quot;On Approximating Restricted Cycle
  Covers&quot; (cs.CC/0504038). Please refer to that paper. The paper &quot;Approximation
  Algorithms for Restricted Cycle Covers Based on Cycle Decompositions&quot; is now
  obsolete</comments><acm-class>F.2.2; G.2.1; G.2.2</acm-class><abstract>  A cycle cover of a graph is a set of cycles such that every vertex is part of
exactly one cycle. An L-cycle cover is a cycle cover in which the length of
every cycle is in the set L. The weight of a cycle cover of an edge-weighted
graph is the sum of the weights of its edges.
  We come close to settling the complexity and approximability of computing
L-cycle covers. On the one hand, we show that for almost all L, computing
L-cycle covers of maximum weight in directed and undirected graphs is APX-hard
and NP-hard. Most of our hardness results hold even if the edge weights are
restricted to zero and one.
  On the other hand, we show that the problem of computing L-cycle covers of
maximum weight can be approximated within a factor of 2 for undirected graphs
and within a factor of 8/3 in the case of directed graphs. This holds for
arbitrary sets L.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604021</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604021</id><created>2006-04-06</created><authors><author><keyname>Sarshar</keyname><forenames>Nima</forenames></author><author><keyname>Rezaei</keyname><forenames>Behnam A.</forenames></author><author><keyname>Roychowdhury</keyname><forenames>Vwani P.</forenames></author></authors><title>Low Latency Wireless Ad-Hoc Networking: Power and Bandwidth Challenges
  and a Hierarchical Solution</title><categories>cs.IT math.IT</categories><abstract>  This paper is concerned with the scaling of the number of hops in a large
scale wireless ad-hoc network (WANET), a quantity we call network latency. A
large network latency affects all aspects of data communication in a WANET,
including an increase in delay, packet loss, required processing power and
memory. We consider network management and data routing challenges in WANETs
with scalable network latency. On the physical side, reducing network latency
imposes a significantly higher power and bandwidth demand on nodes, as is
reflected in a set of new bounds. On the protocol front, designing distributed
routing protocols that can guarantee the delivery of data packets within
scalable number of hops is a challenging task. To solve this, we introduce
multi-resolution randomized hierarchy (MRRH), a novel power and bandwidth
efficient WANET protocol with scalable network latency. MRRH uses a randomized
algorithm for building and maintaining a random hierarchical network topology,
which together with the proposed routing algorithm can guarantee efficient
delivery of data packets in the wireless network. For a network of size $N$,
MRRH can provide an average latency of only $O(\log^{3} N)$. The power and
bandwidth consumption of MRRH are shown to be \emph{nearly} optimal for the
latency it provides. Therefore, MRRH, is a provably efficient candidate for
truly large scale wireless ad-hoc networking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604022</identifier>
 <datestamp>2015-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604022</id><created>2006-04-06</created><updated>2010-05-17</updated><authors><author><keyname>Connelly</keyname><forenames>Robert</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Mitchell</keyname><forenames>Joseph S. B.</forenames></author><author><keyname>Ribo</keyname><forenames>Ares</forenames></author><author><keyname>Rote</keyname><forenames>Guenter</forenames></author></authors><title>Locked and Unlocked Chains of Planar Shapes</title><categories>cs.CG</categories><comments>23 pages, 25 figures, Latex; full journal version with all proof
  details. (Fixed crash-induced bugs in the abstract.)</comments><acm-class>F.2.2</acm-class><journal-ref>Discrete and Computational Geometry 44 (2010), 439-462</journal-ref><doi>10.1007/s00454-010-9262-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend linkage unfolding results from the well-studied case of polygonal
linkages to the more general case of linkages of polygons. More precisely, we
consider chains of nonoverlapping rigid planar shapes (Jordan regions) that are
hinged together sequentially at rotatable joints. Our goal is to characterize
the families of planar shapes that admit locked chains, where some
configurations cannot be reached by continuous reconfiguration without
self-intersection, and which families of planar shapes guarantee universal
foldability, where every chain is guaranteed to have a connected configuration
space. Previously, only obtuse triangles were known to admit locked shapes, and
only line segments were known to guarantee universal foldability. We show that
a surprisingly general family of planar shapes, called slender adornments,
guarantees universal foldability: roughly, the distance from each edge along
the path along the boundary of the slender adornment to each hinge should be
monotone. In contrast, we show that isosceles triangles with any desired apex
angle less than 90 degrees admit locked chains, which is precisely the
threshold beyond which the inward-normal property no longer holds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604023</id><created>2006-04-06</created><authors><author><keyname>Sreenivasan</keyname><forenames>Sameet</forenames></author><author><keyname>Cohen</keyname><forenames>Reuven</forenames></author><author><keyname>L&#xf3;pez</keyname><forenames>Eduardo</forenames></author><author><keyname>Toroczkai</keyname><forenames>Zolt&#xe1;n</forenames></author><author><keyname>Stanley</keyname><forenames>H. Eugene</forenames></author></authors><title>Communication Bottlenecks in Scale-Free Networks</title><categories>cs.NI cond-mat.stat-mech</categories><comments>5 pages, 3 figures</comments><acm-class>C.2.0; G.2.2</acm-class><journal-ref>Phys. Rev. E 75, 036105 (2007)</journal-ref><doi>10.1103/PhysRevE.75.036105</doi><abstract>  We consider the effects of network topology on the optimality of packet
routing quantified by $\gamma_c$, the rate of packet insertion beyond which
congestion and queue growth occurs. The key result of this paper is to show
that for any network, there exists an absolute upper bound, expressed in terms
of vertex separators, for the scaling of $\gamma_c$ with network size $N$,
irrespective of the routing algorithm used. We then derive an estimate to this
upper bound for scale-free networks, and introduce a novel static routing
protocol which is superior to shortest path routing under intense packet
insertion rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604024</id><created>2006-04-06</created><authors><author><keyname>Friedman</keyname><forenames>Joel</forenames></author></authors><title>Cohomology in Grothendieck Topologies and Lower Bounds in Boolean
  Complexity II: A Simple Example</title><categories>cs.CC math.AG</categories><comments>8 pages</comments><abstract>  In a previous paper we have suggested a number of ideas to attack circuit
size complexity with cohomology. As a simple example, we take circuits that can
only compute the AND of two inputs, which essentially reduces to SET COVER. We
show a very special case of the cohomological approach (one particular free
category, using injective and superskyscraper sheaves) gives the linear
programming bound coming from the relaxation of the standard integer
programming reformulation of SET COVER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604025</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604025</id><created>2006-04-07</created><updated>2006-11-07</updated><authors><author><keyname>Liu</keyname><forenames>Tie</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>An Extremal Inequality Motivated by Multiterminal Information Theoretic
  Problems</title><categories>cs.IT math.IT</categories><comments>32 pages, 1 figure</comments><abstract>  We prove a new extremal inequality, motivated by the vector Gaussian
broadcast channel and the distributed source coding with a single quadratic
distortion constraint problems. As a corollary, this inequality yields a
generalization of the classical entropy-power inequality (EPI). As another
corollary, this inequality sheds insight into maximizing the differential
entropy of the sum of two dependent random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604026</id><created>2006-04-07</created><authors><author><keyname>Bolzoni</keyname><forenames>Damiano</forenames></author><author><keyname>Etalle</keyname><forenames>Sandro</forenames></author></authors><title>APHRODITE: an Anomaly-based Architecture for False Positive Reduction</title><categories>cs.CR</categories><report-no>TR-CTIT-06-13</report-no><abstract>  We present APHRODITE, an architecture designed to reduce false positives in
network intrusion detection systems. APHRODITE works by detecting anomalies in
the output traffic, and by correlating them with the alerts raised by the NIDS
working on the input traffic. Benchmarks show a substantial reduction of false
positives and that APHRODITE is effective also after a &quot;quick setup&quot;, i.e. in
the realistic case in which it has not been &quot;trained&quot; and set up optimally
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604027</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604027</id><created>2006-04-07</created><authors><author><keyname>Khayari</keyname><forenames>Majid</forenames><affiliation>INIST</affiliation></author><author><keyname>Schneider</keyname><forenames>St&#xe9;phane</forenames><affiliation>INIST</affiliation></author><author><keyname>Kramer</keyname><forenames>Isabelle</forenames><affiliation>LORIA</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>LORIA</affiliation></author><author><keyname>Collaboration</keyname><forenames>the termsciences</forenames></author></authors><title>Unification of multi-lingual scientific terminological resources using
  the ISO 16642 standard. The TermSciences initiative</title><categories>cs.CL</categories><comments>6p</comments><proxy>ccsd ccsd-00022424</proxy><abstract>  This paper presents the TermSciences portal, which deals with the
implementation of a conceptual model that uses the recent ISO 16642 standard
(Terminological Markup Framework). This standard turns out to be suitable for
concept modeling since it allowed for organizing the original resources by
concepts and to associate the various terms for a given concept. Additional
structuring is produced by sharing conceptual relationships, that is,
cross-linking of resource results through the introduction of semantic
relations which may have initially be missing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604028</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604028</id><created>2006-04-07</created><authors><author><keyname>Liu</keyname><forenames>Tie</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Two Proofs of the Fisher Information Inequality via Data Processing
  Arguments</title><categories>cs.IT math.IT</categories><comments>6 pages, 0 figure</comments><abstract>  Two new proofs of the Fisher information inequality (FII) using data
processing inequalities for mutual information and conditional variance are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604029</identifier>
 <datestamp>2016-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604029</id><created>2006-04-07</created><updated>2007-11-11</updated><authors><author><keyname>Barton</keyname><forenames>Richard J.</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author></authors><title>Order-Optimal Data Aggregation in Wireless Sensor Networks - Part I:
  Regular Networks</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, vol. 56, no. 11, pp.
  5811-5821, November 2010</journal-ref><abstract>  The predominate traffic patterns in a wireless sensor network are many-to-one
and one-to-many communication. Hence, the performance of wireless sensor
networks is characterized by the rate at which data can be disseminated from or
aggregated to a data sink. In this paper, we consider the data aggregation
problem. We demonstrate that a data aggregation rate of O(log(n)/n) is optimal
and that this rate can be achieved in wireless sensor networks using a
generalization of cooperative beamforming called cooperative time-reversal
communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604030</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604030</id><created>2006-04-07</created><authors><author><keyname>Barton</keyname><forenames>Richard J.</forenames></author></authors><title>The Influence of Adaptive Multicoding on Mutual Information and Channel
  Capacity for Uncertain Wideband CDMA Rayleigh Fading Channels</title><categories>cs.IT math.IT</categories><abstract>  We consider the problem of adaptive modulation for wideband DS-CDMA Rayleigh
fading channels with imperfect channel state information (CSI). We assume a
multidimensional signal subspace spanned by a collection of random spreading
codes (multicoding) and study the effects of both the subspace dimension and
the probability distribution of the transmitted symbols on the mutual
information between the channel input and output in the presence of uncertainty
regarding the true state of the channel. We develop approximations for the
mutual information as well as both upper and lower bounds on the mutual
information that are stated explicitly in terms of the dimension of the signal
constellation, the number of resolvable fading paths on the channel, the
current estimate of channel state, and the mean-squared-error of the channel
estimate. We analyze these approximations and bounds in order to quantify the
impact of signal dimension and symbol distribution on system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604031</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604031</id><created>2006-04-07</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Wang</keyname><forenames>Ligong</forenames></author></authors><title>On the Low SNR Capacity of Peak-Limited Non-Coherent Fading Channels
  with Memory</title><categories>cs.IT math.IT</categories><abstract>  The capacity of non-coherent stationary Gaussian fading channels with memory
under a peak-power constraint is studied in the asymptotic weak-signal regime.
It is assumed that the fading law is known to both transmitter and receiver but
that neither is cognizant of the fading realization. A connection is
demonstrated between the asymptotic behavior of channel capacity in this regime
and the asymptotic behavior of the prediction error incurred in predicting the
fading process from very noisy observations of its past. This connection can be
viewed as the low signal-to-noise ratio (SNR) analog of recent results by
Lapidoth &amp; Moser and by Lapidoth demonstrating connections between the high SNR
capacity growth and the noiseless or almost-noiseless prediction error. We
distinguish between two families of fading laws: the ``slowly forgetting'' and
the ``quickly forgetting''. For channels in the former category the low SNR
capacity is achieved by IID inputs, whereas in the latter such inputs are
typically sub-optimal. Instead, the asymptotic capacity can be approached by
inputs with IID phase but block-constant magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604032</id><created>2006-04-07</created><updated>2006-06-07</updated><authors><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author><author><keyname>Meer</keyname><forenames>Klaus</forenames></author></authors><title>Real Computational Universality: The Word Problem for a class of groups
  with infinite presentation</title><categories>cs.LO cs.SC</categories><comments>corrected Section 4.5</comments><acm-class>F.1.1; F.4.1; F.4.2</acm-class><abstract>  The word problem for discrete groups is well-known to be undecidable by a
Turing Machine; more precisely, it is reducible both to and from and thus
equivalent to the discrete Halting Problem.
  The present work introduces and studies a real extension of the word problem
for a certain class of groups which are presented as quotient groups of a free
group and a normal subgroup. Most important, the free group will be generated
by an uncountable set of generators with index running over certain sets of
real numbers. This allows to include many mathematically important groups which
are not captured in the framework of the classical word problem.
  Our contribution extends computational group theory from the discrete to the
Blum-Shub-Smale (BSS) model of real number computation. We believe this to be
an interesting step towards applying BSS theory, in addition to semi-algebraic
geometry, also to further areas of mathematics.
  The main result establishes the word problem for such groups to be not only
semi-decidable (and thus reducible FROM) but also reducible TO the Halting
Problem for such machines. It thus provides the first non-trivial example of a
problem COMPLETE, that is, computationally universal for this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604033</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604033</id><created>2006-04-08</created><authors><author><keyname>Wang</keyname><forenames>Shuangquan</forenames></author><author><keyname>Abdi</keyname><forenames>Ali</forenames></author></authors><title>Statistical Properties of Eigen-Modes and Instantaneous Mutual
  Information in MIMO Time-Varying Rayleigh Channels</title><categories>cs.IT math.IT</categories><comments>25 pages, 7 figures, 1 table, submitted to IEEE Trans. Inform.
  Theory, Apr., 2006</comments><abstract>  In this paper, we study two important metrics in multiple-input
multiple-output (MIMO) time-varying Rayleigh flat fading channels. One is the
eigen-mode, and the other is the instantaneous mutual information (IMI). Their
second-order statistics, such as the correlation coefficient, level crossing
rate (LCR), and average fade/outage duration, are investigated, assuming a
general nonisotropic scattering environment. Exact closed-form expressions are
derived and Monte Carlo simulations are provided to verify the accuracy of the
analytical results. For the eigen-modes, we found they tend to be
spatio-temporally uncorrelated in large MIMO systems. For the IMI, the results
show that its correlation coefficient can be well approximated by the squared
amplitude of the correlation coefficient of the channel, under certain
conditions. Moreover, we also found the LCR of IMI is much more sensitive to
the scattering environment than that of each eigen-mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604034</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604034</id><created>2006-04-08</created><updated>2008-02-24</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Squarepants in a Tree: Sum of Subtree Clustering and Hyperbolic Pants
  Decomposition</title><categories>cs.CG</categories><comments>22 pages, 14 figures. This version replaces the proof of what is now
  Lemma 5.2, as the previous proof was erroneous</comments><acm-class>F.2.2</acm-class><journal-ref>ACM Trans. Algorithms 5(3): 29, 2009</journal-ref><doi>10.1145/1541885.1541890</doi><abstract>  We provide efficient constant factor approximation algorithms for the
problems of finding a hierarchical clustering of a point set in any metric
space, minimizing the sum of minimimum spanning tree lengths within each
cluster, and in the hyperbolic or Euclidean planes, minimizing the sum of
cluster perimeters. Our algorithms for the hyperbolic and Euclidean planes can
also be used to provide a pants decomposition, that is, a set of disjoint
simple closed curves partitioning the plane minus the input points into subsets
with exactly three boundary components, with approximately minimum total
length. In the Euclidean case, these curves are squares; in the hyperbolic
case, they combine our Euclidean square pants decomposition with our tree
clustering method for general metric spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604035</id><created>2006-04-09</created><authors><author><keyname>Mohan</keyname><forenames>R. N.</forenames></author><author><keyname>Kageyama</keyname><forenames>Sanpei</forenames></author><author><keyname>Lee</keyname><forenames>Moon Ho</forenames></author><author><keyname>Yang</keyname><forenames>Gao</forenames></author></authors><title>Certain new M-matrices and their properties and applications</title><categories>cs.DM</categories><comments>21 pages,3 figures</comments><abstract>  The Mn-matrix was defined by Mohan [20] in which he has shown a method of
constructing (1,-1)-matrices and studied some of their properties. The
(1,-1)-matrices were constructed and studied by Cohn [5],Wang [33], Ehrlich [8]
and Ehrlich and Zeller[9]. But in this paper, while giving some resemblances of
this matrix with Hadamard matrix, and by naming it as M-matrix, we show how to
construct partially balanced incomplete block (PBIB) designs and some regular
bipartite graphs by it. We have considered two types of these M- matrices. Also
we will make a mention of certain applications of these M-matrices in signal
and communication processing, and network systems and end with some open
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604036</id><created>2006-04-10</created><updated>2006-04-26</updated><authors><author><keyname>Voss</keyname><forenames>Jakob</forenames></author></authors><title>Collaborative thesaurus tagging the Wikipedia way</title><categories>cs.IR cs.DL</categories><comments>7 pages, 7 figures, 7 tables; v2 with added appendix and fixed
  references</comments><acm-class>H.3.1</acm-class><abstract>  This paper explores the system of categories that is used to classify
articles in Wikipedia. It is compared to collaborative tagging systems like
del.icio.us and to hierarchical classification like the Dewey Decimal
Classification (DDC). Specifics and commonalitiess of these systems of subject
indexing are exposed. Analysis of structural and statistical properties
(descriptors per record, records per descriptor, descriptor levels) shows that
the category system of Wikimedia is a thesaurus that combines collaborative
tagging and hierarchical subject indexing in a special way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604037</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604037</id><created>2006-04-09</created><updated>2006-04-19</updated><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Mozes</keyname><forenames>Shay</forenames></author><author><keyname>Rossman</keyname><forenames>Benjamin</forenames></author><author><keyname>Weimann</keyname><forenames>Oren</forenames></author></authors><title>An O(n^3)-Time Algorithm for Tree Edit Distance</title><categories>cs.DS</categories><comments>10 pages, 5 figures, 5 .tex files where TED.tex is the main one</comments><journal-ref>ACM Transactions on Algorithms 6(1): (2009)</journal-ref><doi>10.1145/1644015.1644017</doi><abstract>  The {\em edit distance} between two ordered trees with vertex labels is the
minimum cost of transforming one tree into the other by a sequence of
elementary operations consisting of deleting and relabeling existing nodes, as
well as inserting new nodes. In this paper, we present a worst-case
$O(n^3)$-time algorithm for this problem, improving the previous best
$O(n^3\log n)$-time algorithm~\cite{Klein}. Our result requires a novel
adaptive strategy for deciding how a dynamic program divides into subproblems
(which is interesting in its own right), together with a deeper understanding
of the previous algorithms for the problem. We also prove the optimality of our
algorithm among the family of \emph{decomposition strategy} algorithms--which
also includes the previous fastest algorithms--by tightening the known lower
bound of $\Omega(n^2\log^2 n)$~\cite{Touzet} to $\Omega(n^3)$, matching our
algorithm's running time. Furthermore, we obtain matching upper and lower
bounds of $\Theta(n m^2 (1 + \log \frac{n}{m}))$ when the two trees have
different sizes $m$ and~$n$, where $m &lt; n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604038</id><created>2006-04-10</created><authors><author><keyname>Petrov</keyname><forenames>E.</forenames></author><author><keyname>Kostov</keyname><forenames>Yu.</forenames></author><author><keyname>Botoeva</keyname><forenames>E.</forenames></author></authors><title>UniCalc.LIN: a linear constraint solver for the UniCalc system</title><categories>cs.MS cs.AI</categories><comments>rejected by the programm committee of the conforence on Perspective
  of System Informatics held in Novosibirsk, Russian Federation July 2006</comments><abstract>  In this short paper we present a linear constraint solver for the UniCalc
system, an environment for reliable solution of mathematical modeling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604039</id><created>2006-04-10</created><authors><author><keyname>Bateman</keyname><forenames>David</forenames></author><author><keyname>Mazet</keyname><forenames>Laurent</forenames></author><author><keyname>Buzenac-Settineri</keyname><forenames>Veronique</forenames></author><author><keyname>Muck</keyname><forenames>Markus</forenames></author></authors><title>A Fixed-Point Type for Octave</title><categories>cs.MS</categories><comments>5 pages, 1 figure</comments><report-no>octave2006/12</report-no><abstract>  This paper announces the availability of a fixed point toolbox for the Matlab
compatible software package Octave. This toolbox is released under the GNU
Public License, and can be used to model the losses in algorithms implemented
in hardware. Furthermore, this paper presents as an example of the use of this
toolbox, the effects of a fixed point implementation on the precision of an
OFDM modulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604040</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604040</id><created>2006-04-10</created><authors><author><keyname>Liu</keyname><forenames>Nan</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Optimal Distortion-Power Tradeoffs in Sensor Networks: Gauss-Markov
  Random Processes</title><categories>cs.IT math.IT</categories><comments>6 pages, 0 figure, to appear in ICC 2006</comments><abstract>  We investigate the optimal performance of dense sensor networks by studying
the joint source-channel coding problem. The overall goal of the sensor network
is to take measurements from an underlying random process, code and transmit
those measurement samples to a collector node in a cooperative multiple access
channel with feedback, and reconstruct the entire random process at the
collector node. We provide lower and upper bounds for the minimum achievable
expected distortion when the underlying random process is stationary and
Gaussian. In the case where the random process is also Markovian, we evaluate
the lower and upper bounds explicitly and show that they are of the same order
for a wide range of sum power constraints. Thus, for a Gauss-Markov random
process, under these sum power constraints, we determine the achievability
scheme that is order-optimal, and express the minimum achievable expected
distortion as a function of the sum power constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604041</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604041</id><created>2006-04-10</created><updated>2006-06-05</updated><authors><author><keyname>Mohan</keyname><forenames>R. N.</forenames></author><author><keyname>Lee</keyname><forenames>Moon Ho</forenames></author><author><keyname>Pokreal</keyname><forenames>Subash</forenames></author></authors><title>On Orthogonality of Latin Squares</title><categories>cs.DM</categories><comments>29 pages</comments><abstract>  An arrangement of s elements in s rows and s columns, such that no element
repeats more than once in each row and each column is called a Latin square of
order s. If two Latin squares of the same order superimposed one on the other
and in the resultant array if each ordered pair occurs once and only once then
they are called othogonal Latin Squares. A frequency square is an nxn matrix,
such that each element from the list of n elements, occurs t times in each row
and in each column. These two concepts lead to a new third concept called as t
orthogonal latin squares, where from a set of m orthogonal Latin squares, if t
orthogonal Latin squares are superimposed and each ordered t tuple in the
resultant array occurs once and only once then it is t othogonal Latin square.
In this paper it is proposed to construct such t othogonal latin squares
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604042</id><created>2006-04-11</created><authors><author><keyname>Florea</keyname><forenames>M. C.</forenames></author><author><keyname>Dezert</keyname><forenames>J.</forenames></author><author><keyname>Valin</keyname><forenames>P.</forenames></author><author><keyname>Smarandache</keyname><forenames>F.</forenames></author><author><keyname>Jousselme</keyname><forenames>Anne-Laure</forenames></author></authors><title>Adaptative combination rule and proportional conflict redistribution
  rule for information fusion</title><categories>cs.AI</categories><comments>Presented at Cogis '06 Conference, Paris, March 2006</comments><acm-class>I.4.8</acm-class><abstract>  This paper presents two new promising rules of combination for the fusion of
uncertain and potentially highly conflicting sources of evidences in the
framework of the theory of belief functions in order to palliate the well-know
limitations of Dempster's rule and to work beyond the limits of applicability
of the Dempster-Shafer theory. We present both a new class of adaptive
combination rules (ACR) and a new efficient Proportional Conflict
Redistribution (PCR) rule allowing to deal with highly conflicting sources for
static and dynamic fusion applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604043</id><created>2006-04-11</created><authors><author><keyname>Way</keyname><forenames>Thomas P.</forenames></author><author><keyname>Pollock</keyname><forenames>Lori L.</forenames></author></authors><title>Demand-driven Inlining in a Region-based Optimizer for ILP Architectures</title><categories>cs.DC cs.PL</categories><comments>23 pages</comments><acm-class>D.3.4</acm-class><abstract>  Region-based compilation repartitions a program into more desirable
compilation units using profiling information and procedure inlining to enable
region formation analysis. Heuristics play a key role in determining when it is
most beneficial to inline procedures during region formation. An ILP optimizing
compiler using a region-based approach restructures a program to better reflect
dynamic behavior and increase interprocedural optimization and scheduling
opportunities. This paper presents an interprocedural compilation technique
which performs procedure inlining on-demand, rather than as a separate phase,
to improve the ability of a region-based optimizer to control code growth,
compilation time and memory usage while improving performance. The
interprocedural region formation algorithm utilizes a demand-driven,
heuristics-guided approach to inlining, restructuring an input program into
interprocedural regions. Experimental results are presented to demonstrate the
impact of the algorithm and several inlining heuristics upon a number of
traditional and novel compilation characteristics within a region-based ILP
compiler and simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604044</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604044</id><created>2006-04-11</created><authors><author><keyname>Mohan</keyname><forenames>R. N.</forenames></author><author><keyname>Lee</keyname><forenames>Moon Ho</forenames></author><author><keyname>Paudal</keyname><forenames>Ram</forenames></author></authors><title>A new M-matrix of Type III, its properties and applications</title><categories>cs.DM</categories><comments>12 pages, one figure</comments><abstract>  Some binary matrices like (1,-1) and (1,0) were studied by many authors like
Cohn, Wang, Ehlich and Ehlich and Zeller, and Mohan, Kageyama, Lee, and Gao. In
this recent paper by Mohan et al considered the M-matrices of Type I and II by
studying some of their properties and applications. In the present paper they
discussed the M-matrices of Type III, and studied their properties and
applications. They gave some constructions of SPBIB designs and some
corresponding M-graphs, which are being constructed by it. This is the
continuation of our earlier research work in this direction, and these papers
establish the importance of non-orthogonal matrices as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604045</id><created>2006-04-11</created><authors><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Schepers</keyname><forenames>Joerg</forenames></author><author><keyname>van der Veen</keyname><forenames>Jan C.</forenames></author></authors><title>An exact algorithm for higher-dimensional orthogonal packing</title><categories>cs.DS</categories><comments>31 pages, 6 figures, 9 tables, to appear in Operations Research; full
  and updated journal version of sketches that appeared as parts of an extended
  abstract in ESA'97</comments><acm-class>F.2.2</acm-class><abstract>  Higher-dimensional orthogonal packing problems have a wide range of practical
applications, including packing, cutting, and scheduling. Combining the use of
our data structure for characterizing feasible packings with our new classes of
lower bounds, and other heuristics, we develop a two-level tree search
algorithm for solving higher-dimensional packing problems to optimality.
Computational results are reported, including optimal solutions for all
two--dimensional test problems from recent literature.
  This is the third in a series of articles describing new approaches to
higher-dimensional packing; see cs.DS/0310032 and cs.DS/0402044.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604046</id><created>2006-04-11</created><authors><author><keyname>Lepetz</keyname><forenames>Dominique</forenames></author><author><keyname>Nemoz-Gaillard</keyname><forenames>Max</forenames></author><author><keyname>Aupetit</keyname><forenames>Michael</forenames></author></authors><title>Concerning the differentiability of the energy function in vector
  quantization algorithms</title><categories>cs.LG cs.NE</categories><comments>Under submission to a peer-reviewed international journal</comments><abstract>  The adaptation rule for Vector Quantization algorithms, and consequently the
convergence of the generated sequence, depends on the existence and properties
of a function called the energy function, defined on a topological manifold.
Our aim is to investigate the conditions of existence of such a function for a
class of algorithms examplified by the initial ''K-means'' and Kohonen
algorithms. The results presented here supplement previous studies and show
that the energy function is not always a potential but at least the uniform
limit of a series of potential functions which we call a pseudo-potential. Our
work also shows that a large number of existing vector quantization algorithms
developped by the Artificial Neural Networks community fall into this category.
The framework we define opens the way to study the convergence of all the
corresponding adaptation rules at once, and a theorem gives promising insights
in that direction. We also demonstrate that the ''K-means'' energy function is
a pseudo-potential but not a potential in general. Consequently, the energy
function associated to the ''Neural-Gas'' is not a potential in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604047</id><created>2006-04-11</created><authors><author><keyname>Jungers</keyname><forenames>Rapha&#xeb;l</forenames></author><author><keyname>Protasov</keyname><forenames>Vladimir</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author></authors><title>Efficient algorithms for deciding the type of growth of products of
  integer matrices</title><categories>cs.CC</categories><comments>20 pages, 4 figures, submitted to LAA</comments><abstract>  For a given finite set $\Sigma$ of matrices with nonnegative integer entries
we study the growth of $$ \max_t(\Sigma) = \max\{\|A_{1}... A_{t}\|: A_i \in
\Sigma\}.$$ We show how to determine in polynomial time whether the growth with
$t$ is bounded, polynomial, or exponential, and we characterize precisely all
possible behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604048</id><created>2006-04-11</created><authors><author><keyname>Hinze-Hoare</keyname><forenames>Vita</forenames></author></authors><title>Will the Butterfly Cipher keep your Network Data secure? Developments in
  Computer Encryption</title><categories>cs.CR</categories><abstract>  This paper explains the recent developments in security and encryption. The
Butterfly cipher and quantum cryptography are reviewed and compared. Examples
of their relative uses are discussed and suggestions for future developments
considered. In addition application to network security together with a
substantial review of classification of encryption systems and a summary of
security weaknesses are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604049</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604049</id><created>2006-04-11</created><updated>2006-04-12</updated><authors><author><keyname>Sethuraman</keyname><forenames>Vignesh</forenames></author><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author></authors><title>Low SNR Capacity of Fading Channels with Peak and Average Power
  Constraints</title><categories>cs.IT math.IT</categories><comments>13 pages, version without proofs submitted to ISIT 2006</comments><abstract>  Flat-fading channels that are correlated in time are considered under peak
and average power constraints. For discrete-time channels, a new upper bound on
the capacity per unit time is derived. A low SNR analysis of a full-scattering
vector channel is used to derive a complimentary lower bound. Together, these
bounds allow us to identify the exact scaling of channel capacity for a fixed
peak to average ratio, as the average power converges to zero. The upper bound
is also asymptotically tight as the average power converges to zero for a fixed
peak power.
  For a continuous time infinite bandwidth channel, Viterbi identified the
capacity for M-FSK modulation. Recently, Zhang and Laneman showed that the
capacity can be achieved with non-bursty signaling (QPSK). An additional
contribution of this paper is to obtain similar results under peak and average
power constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604050</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604050</id><created>2006-04-11</created><authors><author><keyname>Mohan</keyname><forenames>R. N.</forenames></author></authors><title>On Hadamard Conjecture</title><categories>cs.DM</categories><abstract>  In this note, while giving an overview of the state of art of the well known
Hadamard conjecture, which is more than a century old and now it has been
established by using the methods given in the two papers by Mohan et al [6,7].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604051</id><created>2006-04-12</created><authors><author><keyname>Brinkmeier</keyname><forenames>Michael</forenames></author></authors><title>Structural Alignments of pseudo-knotted RNA-molecules in polynomial time</title><categories>cs.DS cs.CC cs.DM</categories><comments>16 pages</comments><acm-class>F.2.2</acm-class><abstract>  An RNA molecule is structured on several layers. The primary and most obvious
structure is its sequence of bases, i.e. a word over the alphabet {A,C,G,U}.
The higher structure is a set of one-to-one base-pairings resulting in a
two-dimensional folding of the one-dimensional sequence. One speaks of a
secondary structure if these pairings do not cross and of a tertiary structure
otherwise.
  Since the folding of the molecule is important for its function, the search
for related RNA molecules should not only be restricted to the primary
structure. It seems sensible to incorporate the higher structures in the
search. Based on this assumption and certain edit-operations a distance between
two arbitrary structures can be defined. It is known that the general
calculation of this measure is NP-complete \cite{zhang02similarity}. But for
some special cases polynomial algorithms are known. Using a new formal
description of secondary and tertiary structures, we extend the class of
structures for which the distance can be calculated in polynomial time. In
addition the presented algorithm may be used to approximate the edit-distance
between two arbitrary structures with a constant ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604052</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604052</id><created>2006-04-12</created><updated>2006-04-21</updated><authors><author><keyname>Tentyukov</keyname><forenames>M.</forenames></author><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author></authors><title>Extension of the functionality of the symbolic program FORM by external
  software</title><categories>cs.SC hep-ph</categories><comments>36 pages, 2 Encapsulated postscript figures, LaTeX2e, uses elsart.cls
  (included)</comments><report-no>SFB/CPP-06-15, TTP06-12, NIKHEF 06-002</report-no><acm-class>I.1; I.1.3; I.1.4</acm-class><journal-ref>Comput.Phys.Commun.176:385-405,2007</journal-ref><doi>10.1016/j.cpc.2006.11.007</doi><abstract>  We describe the implementation of facilities for the communication with
external resources in the Symbolic Manipulation System FORM. This is done
according to the POSIX standards defined for the UNIX operating system. We
present a number of examples that illustrate the increased power due to these
new capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604053</id><created>2006-04-12</created><authors><author><keyname>Kurant</keyname><forenames>Maciej</forenames></author><author><keyname>Thiran</keyname><forenames>Patrick</forenames></author></authors><title>Survivable Routing in IP-over-WDM Networks in the Presence of Multiple
  Failures</title><categories>cs.NI</categories><comments>8 pages, 6 figures</comments><abstract>  Failure restoration at the IP layer in IP-over-WDM networks requires to map
the IP topology on the WDM topology in such a way that a failure at the WDM
layer leaves the IP topology connected. Such a mapping is called $survivable$.
As finding a survivable mapping is known to be NP-complete, in practice it
requires a heuristic approach. We have introduced in [1] a novel algorithm
called ``SMART'', that is more effective and scalable than the heuristics known
to date. Moreover, the formal analysis of SMART [2] has led to new
applications: the formal verification of the existence of a survivable mapping,
and a tool tracing and repairing the vulnerable areas of the network. In this
paper we extend the theoretical analysis in [2] by considering $multiple
failures$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604054</identifier>
 <datestamp>2015-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604054</id><created>2006-04-12</created><updated>2008-05-31</updated><authors><author><keyname>Armando</keyname><forenames>Alessandro</forenames></author><author><keyname>Bonacina</keyname><forenames>Maria Paola</forenames></author><author><keyname>Ranise</keyname><forenames>Silvio</forenames></author><author><keyname>Schulz</keyname><forenames>Stephan</forenames></author></authors><title>New results on rewrite-based satisfiability procedures</title><categories>cs.AI cs.LO</categories><comments>To appear in the ACM Transactions on Computational Logic, 49 pages</comments><report-no>RR 36/2005</report-no><journal-ref>ACM Transactions on Computational Logic, 10(1):129-179, January
  2009</journal-ref><doi>10.1145/1459010.1459014</doi><abstract>  Program analysis and verification require decision procedures to reason on
theories of data structures. Many problems can be reduced to the satisfiability
of sets of ground literals in theory T. If a sound and complete inference
system for first-order logic is guaranteed to terminate on T-satisfiability
problems, any theorem-proving strategy with that system and a fair search plan
is a T-satisfiability procedure. We prove termination of a rewrite-based
first-order engine on the theories of records, integer offsets, integer offsets
modulo and lists. We give a modularity theorem stating sufficient conditions
for termination on a combinations of theories, given termination on each. The
above theories, as well as others, satisfy these conditions. We introduce
several sets of benchmarks on these theories and their combinations, including
both parametric synthetic benchmarks to test scalability, and real-world
problems to test performances on huge sets of literals. We compare the
rewrite-based theorem prover E with the validity checkers CVC and CVC Lite.
Contrary to the folklore that a general-purpose prover cannot compete with
reasoners with built-in theories, the experiments are overall favorable to the
theorem prover, showing that not only the rewriting approach is elegant and
conceptually simple, but has important practical implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604055</identifier>
 <datestamp>2008-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604055</id><created>2006-04-12</created><updated>2008-04-30</updated><authors><author><keyname>Vershynin</keyname><forenames>Roman</forenames></author></authors><title>Beyond Hirsch Conjecture: walks on random polytopes and smoothed
  complexity of the simplex method</title><categories>cs.DS math.FA</categories><comments>39 pages, 3 figures. Final version. Parts of the argument are
  reorganized to make the paper more transparent. Figures added. Small mistakes
  and typos corrected</comments><acm-class>G.1.6</acm-class><abstract>  The smoothed analysis of algorithms is concerned with the expected running
time of an algorithm under slight random perturbations of arbitrary inputs.
Spielman and Teng proved that the shadow-vertex simplex method has polynomial
smoothed complexity. On a slight random perturbation of an arbitrary linear
program, the simplex method finds the solution after a walk on polytope(s) with
expected length polynomial in the number of constraints n, the number of
variables d and the inverse standard deviation of the perturbation 1/sigma.
  We show that the length of walk in the simplex method is actually
polylogarithmic in the number of constraints n. Spielman-Teng's bound on the
walk was O(n^{86} d^{55} sigma^{-30}), up to logarithmic factors. We improve
this to O(log^7 n (d^9 + d^3 \s^{-4})). This shows that the tight Hirsch
conjecture n-d on the length of walk on polytopes is not a limitation for the
smoothed Linear Programming. Random perturbations create short paths between
vertices.
  We propose a randomized phase-I for solving arbitrary linear programs, which
is of independent interest. Instead of finding a vertex of a feasible set, we
add a vertex at random to the feasible set. This does not affect the solution
of the linear program with constant probability. This overcomes one of the
major difficulties of smoothed analysis of the simplex method -- one can now
statistically decouple the walk from the smoothed linear program. This yields a
much better reduction of the smoothed complexity to a geometric quantity -- the
size of planar sections of random polytopes. We also improve upon the known
estimates for that size, showing that it is polylogarithmic in the number of
vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604056</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604056</id><created>2006-04-12</created><authors><author><keyname>Ham</keyname><forenames>Woonchul</forenames></author><author><keyname>Zhou</keyname><forenames>Kemin</forenames></author></authors><title>A Short Note on The Volume of Hypersphere</title><categories>cs.IT math.IT</categories><abstract>  In this note, a new method for deriving the volume of hypersphere is proposed
by using probability theory. The explicit expression of the multiple times
convolution of the probability density functions we should use is very
complicated. But in here, we don't need its whole explicit expression. We just
need the only a part of information and this fact make it possible to derive
the general expression of the voulume of hypersphere. We also comments about
the paradox in the hypersphere which was introduced by R.W.Hamming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604057</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604057</id><created>2006-04-12</created><authors><author><keyname>Mohan</keyname><forenames>R. N.</forenames></author><author><keyname>Kulkarni</keyname><forenames>P. T.</forenames></author></authors><title>A New Fault-Tolerant M-network and its Analysis</title><categories>cs.IT math.IT</categories><abstract>  This paper introduces a new class of efficient inter connection networks
called as M-graphs for large multi-processor systems.The concept of M-matrix
and M-graph is an extension of Mn-matrices and Mn-graphs.We analyze these
M-graphs regarding their suitability for large multi-processor systems. An(p,N)
M-graph consists of N nodes, where p is the degree of each node.The topology is
found to be having many attractive features prominent among them is the
capability of maximal fault-tolerance, high density and constant diameter.It is
found that these combinatorial structures exibit some properties like
symmetry,and an inter-relation with the nodes, and degree of the concerned
graph, which can be utilized for the purposes of inter connected networks.But
many of the properties of these mathematical and graphical structures still
remained unexplored and the present aim of the paper is to study and analyze
some of the properties of these M-graphs and explore their application in
networks and multi-processor systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604058</id><created>2006-04-13</created><authors><author><keyname>Lifshits</keyname><forenames>Yury</forenames></author></authors><title>Solving Classical String Problems on Compressed Texts</title><categories>cs.DS cs.CC</categories><comments>10 pages, 6 figures, submitted</comments><acm-class>E.4; F.2.2; I.7</acm-class><abstract>  Here we study the complexity of string problems as a function of the size of
a program that generates input. We consider straight-line programs (SLP), since
all algorithms on SLP-generated strings could be applied to processing
LZ-compressed texts.
  The main result is a new algorithm for pattern matching when both a text T
and a pattern P are presented by SLPs (so-called fully compressed pattern
matching problem). We show how to find a first occurrence, count all
occurrences, check whether any given position is an occurrence or not in time
O(n^2m). Here m,n are the sizes of straight-line programs generating
correspondingly P and T.
  Then we present polynomial algorithms for computing fingerprint table and
compressed representation of all covers (for the first time) and for finding
periods of a given compressed string (our algorithm is faster than previously
known). On the other hand, we show that computing the Hamming distance between
two SLP-generated strings is NP- and coNP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604059</id><created>2006-04-13</created><authors><author><keyname>Devillers</keyname><forenames>Olivier</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Guigue</keyname><forenames>Philippe</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Inner and Outer Rounding of Boolean Operations on Lattice Polygonal
  Regions</title><categories>cs.CG</categories><proxy>ccsd inria-00001250</proxy><abstract>  Robustness problems due to the substitution of the exact computation on real
numbers by the rounded floating point arithmetic are often an obstacle to
obtain practical implementation of geometric algorithms. If the adoption of the
--exact computation paradigm--[Yap et Dube] gives a satisfactory solution to
this kind of problems for purely combinatorial algorithms, this solution does
not allow to solve in practice the case of algorithms that cascade the
construction of new geometric objects. In this report, we consider the problem
of rounding the intersection of two polygonal regions onto the integer lattice
with inclusion properties. Namely, given two polygonal regions A and B having
their vertices on the integer lattice, the inner and outer rounding modes
construct two polygonal regions with integer vertices which respectively is
included and contains the true intersection. We also prove interesting results
on the Hausdorff distance, the size and the convexity of these polygonal
regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604060</id><created>2006-04-13</created><authors><author><keyname>Hubert</keyname><forenames>&#xc9;velyne</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Sedoglavic</keyname><forenames>Alexandre</forenames><affiliation>INRIA Futurs, LIFL</affiliation></author></authors><title>Polynomial Time Nondimensionalisation of Ordinary Differential Equations
  via their Lie Point Symmetries</title><categories>cs.SC</categories><proxy>ccsd inria-00001251</proxy><abstract>  Lie group theory states that knowledge of a $m$-parameters solvable group of
symmetries of a system of ordinary differential equations allows to reduce by
$m$ the number of equation. We apply this principle by finding dilatations and
translations that are Lie point symmetries of considered ordinary differential
system. By rewriting original problem in an invariant coordinates set for these
symmetries, one can reduce the involved number of parameters. This process is
classically call nondimensionalisation in dimensional analysis. We present an
algorithm based on this standpoint and show that its arithmetic complexity is
polynomial in input's size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604061</id><created>2006-04-13</created><updated>2006-06-05</updated><authors><author><keyname>Henneken</keyname><forenames>Edwin A.</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Eichhorn</keyname><forenames>Guenther</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn</forenames></author><author><keyname>Thompson</keyname><forenames>Donna</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Effect of E-printing on Citation Rates in Astronomy and Physics</title><categories>cs.DL astro-ph</categories><comments>Submitted to the Journal of Electronic Publishing. 11 pages with 5
  figures</comments><abstract>  In this report we examine the change in citation behavior since the
introduction of the arXiv e-print repository (Ginsparg, 2001). It has been
observed that papers that initially appear as arXiv e-prints get cited more
than papers that do not (Lawrence, 2001; Brody et al., 2004; Schwarz &amp;
Kennicutt, 2004; Kurtz et al., 2005a, Metcalfe, 2005). Using the citation
statistics from the NASA-Smithsonian Astrophysics Data System (ADS; Kurtz et
al., 1993, 2000), we confirm the findings from other studies, we examine the
average citation rate to e-printed papers in the Astrophysical Journal, and we
show that for a number of major astronomy and physics journals the most
important papers are submitted to the arXiv e-print repository first.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604062</id><created>2006-04-14</created><authors><author><keyname>Wu</keyname><forenames>Liang</forenames></author></authors><title>Biologically Inspired Hierarchical Model for Feature Extraction and
  Localization</title><categories>cs.CV</categories><comments>4 pages, 4 figures</comments><abstract>  Feature extraction and matching are among central problems of computer
vision. It is inefficent to search features over all locations and scales.
Neurophysiological evidence shows that to locate objects in a digital image the
human visual system employs visual attention to a specific object while
ignoring others. The brain also has a mechanism to search from coarse to fine.
In this paper, we present a feature extractor and an associated hierarchical
searching model to simulate such processes. With the hierarchical
representation of the object, coarse scanning is done through the matching of
the larger scale and precise localization is conducted through the matching of
the smaller scale. Experimental results justify the proposed model in its
effectiveness and efficiency to localize features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604063</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604063</id><created>2006-04-16</created><updated>2007-01-10</updated><authors><author><keyname>Hong</keyname><forenames>Yi</forenames></author><author><keyname>Viterbo</keyname><forenames>Emanuele</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Golden Space-Time Trellis Coded Modulation</title><categories>cs.IT math.IT</categories><comments>33 pages, 13 figures</comments><acm-class>H.1.1</acm-class><abstract>  In this paper, we present a concatenated coding scheme for a high rate
$2\times 2$ multiple-input multiple-output (MIMO) system over slow fading
channels. The inner code is the Golden code \cite{Golden05} and the outer code
is a trellis code. Set partitioning of the Golden code is designed specifically
to increase the minimum determinant. The branches of the outer trellis code are
labeled with these partitions. Viterbi algorithm is applied for trellis
decoding. In order to compute the branch metrics a lattice sphere decoder is
used. The general framework for code optimization is given. The performance of
the proposed concatenated scheme is evaluated by simulation. It is shown that
the proposed scheme achieves significant performance gains over uncoded Golden
code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604064</id><created>2006-04-16</created><authors><author><keyname>Mannucci</keyname><forenames>Mirco A.</forenames></author></authors><title>Quantum Fuzzy Sets: Blending Fuzzy Set Theory and Quantum Computation</title><categories>cs.LO cs.AI</categories><comments>12 pages</comments><abstract>  In this article we investigate a way in which quantum computing can be used
to extend the class of fuzzy sets. The core idea is to see states of a quantum
register as characteristic functions of quantum fuzzy subsets of a given set.
As the real unit interval is embedded in the Bloch sphere, every fuzzy set is
automatically a quantum fuzzy set. However, a generic quantum fuzzy set can be
seen as a (possibly entangled) superposition of many fuzzy sets at once,
offering new opportunities for modeling uncertainty. After introducing the main
framework of quantum fuzzy set theory, we analyze the standard operations of
fuzzification and defuzzification from our viewpoint. We conclude this
preliminary paper with a list of possible applications of quantum fuzzy sets to
pattern recognition, as well as future directions of pure research in quantum
fuzzy set theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604065</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604065</id><created>2006-04-16</created><updated>2007-06-26</updated><authors><author><keyname>Bui-Xuan</keyname><forenames>Binh-Minh</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Habib</keyname><forenames>Michel</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Limouzy</keyname><forenames>Vincent</forenames><affiliation>LIAFA</affiliation></author><author><keyname>De Montgolfier</keyname><forenames>Fabien</forenames><affiliation>LIAFA</affiliation></author></authors><title>Unifying two Graph Decompositions with Modular Decomposition</title><categories>cs.DS</categories><comments>Soumis \`a ISAAC 2007</comments><journal-ref>Dans Lecture Notes in Computer Science - International Symposium
  on Algorithms and Computation (ISAAC, Sendai : Japon (2007)</journal-ref><doi>10.1007/978-3-540-77120-3</doi><abstract>  We introduces the umodules, a generalisation of the notion of graph module.
The theory we develop captures among others undirected graphs, tournaments,
digraphs, and $2-$structures. We show that, under some axioms, a unique
decomposition tree exists for umodules. Polynomial-time algorithms are provided
for: non-trivial umodule test, maximal umodule computation, and decomposition
tree computation when the tree exists. Our results unify many known
decomposition like modular and bi-join decomposition of graphs, and a new
decomposition of tournaments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604066</id><created>2006-04-17</created><authors><author><keyname>Tsigaridas</keyname><forenames>Elias P.</forenames></author><author><keyname>Emiris</keyname><forenames>Ioannis Z.</forenames></author></authors><title>Univariate polynomial real root isolation: Continued Fractions revisited</title><categories>cs.SC cs.CC cs.MS</categories><comments>12 pages</comments><abstract>  We present algorithmic, complexity and implementation results concerning real
root isolation of integer univariate polynomials using the continued fraction
expansion of real algebraic numbers. One motivation is to explain the method's
good performance in practice. We improve the previously known bound by a factor
of $d \tau$, where $d$ is the polynomial degree and $\tau$ bounds the
coefficient bitsize, thus matching the current record complexity for real root
isolation by exact methods. Namely, the complexity bound is $\sOB(d^4 \tau^2)$
using the standard bound on the expected bitsize of the integers in the
continued fraction expansion. We show how to compute the multiplicities within
the same complexity and extend the algorithm to non square-free polynomials.
Finally, we present an efficient open-source \texttt{C++} implementation in the
algebraic library \synaps, and illustrate its efficiency as compared to other
available software. We use polynomials with coefficient bitsize up to 8000 and
degree up to 1000.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604067</id><created>2006-04-18</created><updated>2006-05-10</updated><authors><author><keyname>Mohan</keyname><forenames>R. N.</forenames></author><author><keyname>Lee</keyname><forenames>Moon Ho</forenames></author><author><keyname>Pokrel</keyname><forenames>Subhash</forenames></author></authors><title>Certain t-partite graphs</title><categories>cs.DM</categories><abstract>  By making use of the generalized concept of orthogonality in Latin squares,
certain t-partite graphs have been constructed and a suggestion for a net work
system and some applications have been made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604068</id><created>2006-04-18</created><updated>2006-04-20</updated><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>Klein</keyname><forenames>Christian</forenames></author><author><keyname>Osbild</keyname><forenames>Ralf</forenames></author></authors><title>Unbiased Matrix Rounding</title><categories>cs.DS cs.DM</categories><comments>10th Scandinavian Workshop on Algorithm Theory (SWAT), 2006, to
  appear</comments><abstract>  We show several ways to round a real matrix to an integer one such that the
rounding errors in all rows and columns as well as the whole matrix are less
than one. This is a classical problem with applications in many fields, in
particular, statistics.
  We improve earlier solutions of different authors in two ways. For rounding
matrices of size $m \times n$, we reduce the runtime from $O((m n)^2 Second,
our roundings also have a rounding error of less than one in all initial
intervals of rows and columns. Consequently, arbitrary intervals have an error
of at most two. This is particularly useful in the statistics application of
controlled rounding.
  The same result can be obtained via (dependent) randomized rounding. This has
the additional advantage that the rounding is unbiased, that is, for all
entries $y_{ij}$ of our rounding, we have $E(y_{ij}) = x_{ij}$, where $x_{ij}$
is the corresponding entry of the input matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604069</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604069</id><created>2006-04-18</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Universal decoding with an erasure option</title><categories>cs.IT math.IT</categories><comments>23 pages. submitted to the IEEE Transactions on Information Theory</comments><abstract>  Motivated by applications of rateless coding, decision feedback, and ARQ, we
study the problem of universal decoding for unknown channels, in the presence
of an erasure option. Specifically, we harness the competitive minimax
methodology developed in earlier studies, in order to derive a universal
version of Forney's classical erasure/list decoder, which in the erasure case,
optimally trades off between the probability of erasure and the probability of
undetected error. The proposed universal erasure decoder guarantees universal
achievability of a certain fraction $\xi$ of the optimum error exponents of
these probabilities (in a sense to be made precise in the sequel). A
single--letter expression for $\xi$, which depends solely on the coding rate
and the threshold, is provided. The example of the binary symmetric channel is
studied in full detail, and some conclusions are drawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604070</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604070</id><created>2006-04-19</created><updated>2006-11-27</updated><authors><author><keyname>Cao</keyname><forenames>Yongzhi</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author><author><keyname>Chen</keyname><forenames>Guoqing</forenames></author></authors><title>Retraction and Generalized Extension of Computing with Words</title><categories>cs.AI</categories><comments>13 double column pages; 3 figures; to be published in the IEEE
  Transactions on Fuzzy Systems</comments><journal-ref>IEEE Transactions on Fuzzy Systems, vol. 15(6): 1238-1250, Dec.
  2007</journal-ref><doi>10.1109/TED.2007.893191</doi><abstract>  Fuzzy automata, whose input alphabet is a set of numbers or symbols, are a
formal model of computing with values. Motivated by Zadeh's paradigm of
computing with words rather than numbers, Ying proposed a kind of fuzzy
automata, whose input alphabet consists of all fuzzy subsets of a set of
symbols, as a formal model of computing with all words. In this paper, we
introduce a somewhat general formal model of computing with (some special)
words. The new features of the model are that the input alphabet only comprises
some (not necessarily all) fuzzy subsets of a set of symbols and the fuzzy
transition function can be specified arbitrarily. By employing the methodology
of fuzzy control, we establish a retraction principle from computing with words
to computing with values for handling crisp inputs and a generalized extension
principle from computing with words to computing with all words for handling
fuzzy inputs. These principles show that computing with values and computing
with all words can be respectively implemented by computing with words. Some
algebraic properties of retractions and generalized extensions are addressed as
well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604071</id><created>2006-04-19</created><authors><author><keyname>Santos</keyname><forenames>Nuno</forenames></author><author><keyname>Koblitz</keyname><forenames>Birger</forenames></author></authors><title>Distributed Metadata with the AMGA Metadata Catalog</title><categories>cs.DC cs.DB</categories><comments>6 pages, 3 figures, to appear in Workshop on Next-Generation
  Distributed Data Management - HPDC-15</comments><acm-class>C.2.4</acm-class><abstract>  Catalog Services play a vital role on Data Grids by allowing users and
applications to discover and locate the data needed. On large Data Grids, with
hundreds of geographically distributed sites, centralized Catalog Services do
not provide the required scalability, performance or fault-tolerance. In this
article, we start by presenting and discussing the general requirements on Grid
Catalogs of applications being developed by the EGEE user community. This
provides the motivation for the second part of the article, where we present
the replication and distribution mechanisms we have designed and implemented
into the AMGA Metadata Catalog, which is part of the gLite software stack being
developed for the EGEE project. Implementing these mechanisms in the catalog
itself has the advantages of not requiring any special support from the
relational database back-end, of being database independent, and of allowing
tailoring the mechanisms to the specific requirements and characteristics of
Metadata Catalogs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604072</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604072</id><created>2006-04-19</created><authors><author><keyname>Heylighen</keyname><forenames>Francis</forenames></author><author><keyname>Cilliers</keyname><forenames>Paul</forenames></author><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author></authors><title>Complexity and Philosophy</title><categories>cs.CC cond-mat.other</categories><comments>21 pages</comments><journal-ref>In Bogg, J. and R. Geyer (eds.) Complexity, Science and Society.
  Radcliffe Publishing, Oxford. 2007.</journal-ref><abstract>  The science of complexity is based on a new way of thinking that stands in
sharp contrast to the philosophy underlying Newtonian science, which is based
on reductionism, determinism, and objective knowledge. This paper reviews the
historical development of this new world view, focusing on its philosophical
foundations. Determinism was challenged by quantum mechanics and chaos theory.
Systems theory replaced reductionism by a scientifically based holism.
Cybernetics and postmodern social science showed that knowledge is
intrinsically subjective. These developments are being integrated under the
header of &quot;complexity science&quot;. Its central paradigm is the multi-agent system.
Agents are intrinsically subjective and uncertain about their environment and
future, but out of their local interactions, a global organization emerges.
Although different philosophers, and in particular the postmodernists, have
voiced similar ideas, the paradigm of complexity still needs to be fully
assimilated by philosophy. This will throw a new light on old philosophical
issues such as relativism, ethics and the role of the subject.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604073</id><created>2006-04-19</created><updated>2006-04-28</updated><authors><author><keyname>Annamalai</keyname><forenames>Muthiah</forenames></author><author><keyname>Kumar</keyname><forenames>Hemant</forenames></author><author><keyname>Velusamy</keyname><forenames>Leela</forenames></author></authors><title>Octave-GTK: A GTK binding for GNU Octave</title><categories>cs.SE</categories><comments>Comments: Presented at Octave2006 Conference, Washington D.C</comments><report-no>Octave2006/02</report-no><abstract>  This paper discusses the problems faced with interoperability between two
programming languages, with respect to GNU Octave, and GTK API written in C, to
provide the GTK API on Octave.Octave-GTK is the fusion of two different API's:
one exported by GNU Octave [scientific computing tool] and the other GTK [GUI
toolkit]; this enables one to use GTK primitives within GNU Octave, to build
graphical front ends,at the same time using octave engine for number crunching
power. This paper illustrates our implementation of binding logic, and shows
results extended to various other libraries using the same base code generator.
Also shown, are methods of code generation, binding automation, and the niche
we plan to fill in the absence of GUI in Octave. Canonical discussion of
advantages, feasibility and problems faced in the process are elucidated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604074</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604074</id><created>2006-04-19</created><updated>2009-05-19</updated><authors><author><keyname>de Miguel</keyname><forenames>Rodrigo</forenames></author><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Muller</keyname><forenames>Ralf R.</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author></authors><title>Information and multiaccess interference in a complexity-constrained
  vector channel</title><categories>cs.IT math.IT</categories><comments>The author has withdrawn this submission [arXiv admin]</comments><doi>10.1088/1751-8113/40/20/002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rodrigo de Miguel et al 2007 J. Phys. A: Math. Theor. 40 5241-5260: A noisy
vector channel operating under a strict complexity constraint at the receiver
is introduced. According to this constraint, detected bits, obtained by
performing hard decisions directly on the channel's matched filter output, must
be the same as the transmitted binary inputs. An asymptotic analysis is carried
out using mathematical tools imported from the study of neural networks, and it
is shown that, under a bounded noise assumption, such complexity-constrained
channel exhibits a non-trivial Shannon-theoretic capacity. It is found that
performance relies on rigorous interference-based multiuser cooperation at the
transmitter and that this cooperation is best served when all transmitters use
the same amplitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604075</id><created>2006-04-19</created><updated>2007-05-07</updated><authors><author><keyname>Lu</keyname><forenames>Qiming</forenames></author><author><keyname>Korniss</keyname><forenames>G.</forenames></author><author><keyname>Szymanski</keyname><forenames>Boleslaw K.</forenames></author></authors><title>Naming Games in Spatially-Embedded Random Networks</title><categories>cs.MA cond-mat.stat-mech cs.AI</categories><comments>We have found a programming error in our code used to generate the
  results of the earlier version. We have corrected the error, reran all
  simulations, and regenerated all data plots. While the qualitative behavior
  of the model has not changed, the numerical values of some of the scaling
  exponents did. 7 figures</comments><journal-ref>Proceedings of the 2006 American Association for Artificial
  Intelligence Fall Symposium Series, Interaction and Emergent Phenomena in
  Societies of Agents (AAAI Press, Menlo Park, CA 2006) pp. 148-155</journal-ref><abstract>  We investigate a prototypical agent-based model, the Naming Game, on random
geometric networks. The Naming Game is a minimal model, employing local
communications that captures the emergence of shared communication schemes
(languages) in a population of autonomous semiotic agents. Implementing the
Naming Games on random geometric graphs, local communications being local
broadcasts, serves as a model for agreement dynamics in large-scale,
autonomously operating wireless sensor networks. Further, it captures essential
features of the scaling properties of the agreement process for
spatially-embedded autonomous agents. We also present results for the case when
a small density of long-range communication links are added on top of the
random geometric graph, resulting in a &quot;small-world&quot;-like network and yielding
a significantly reduced time to reach global agreement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604076</id><created>2006-04-19</created><authors><author><keyname>Bravo</keyname><forenames>Loreto</forenames></author><author><keyname>Bertossi</keyname><forenames>Leopoldo</forenames></author></authors><title>Semantically Correct Query Answers in the Presence of Null Values</title><categories>cs.DB</categories><comments>20 pages. To appear in Proc. of International Workshop on
  Inconsistency and Incompleteness in Databases (IIDB 2006)</comments><abstract>  For several reasons a database may not satisfy a given set of integrity
constraints(ICs), but most likely most of the information in it is still
consistent with those ICs; and could be retrieved when queries are answered.
Consistent answers to queries wrt a set of ICs have been characterized as
answers that can be obtained from every possible minimally repaired consistent
version of the original database. In this paper we consider databases that
contain null values and are also repaired, if necessary, using null values. For
this purpose, we propose first a precise semantics for IC satisfaction in a
database with null values that is compatible with the way null values are
treated in commercial database management systems. Next, a precise notion of
repair is introduced that privileges the introduction of null values when
repairing foreign key constraints, in such a way that these new values do not
create an infinite cycle of new inconsistencies. Finally, we analyze how to
specify this kind of repairs of a database that contains null values using
disjunctive logic programs with stable model semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604077</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604077</id><created>2006-04-19</created><authors><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>Berger</keyname><forenames>Toby</forenames></author></authors><title>Successive Wyner-Ziv Coding Scheme and its Application to the Quadratic
  Gaussian CEO Problem</title><categories>cs.IT math.IT</categories><comments>28 pages, submitted to the IEEE Transactions on Information Theory</comments><abstract>  We introduce a distributed source coding scheme called successive Wyner-Ziv
coding. We show that any point in the rate region of the quadratic Gaussian CEO
problem can be achieved via the successive Wyner-Ziv coding. The concept of
successive refinement in the single source coding is generalized to the
distributed source coding scenario, which we refer to as distributed successive
refinement. For the quadratic Gaussian CEO problem, we establish a necessary
and sufficient condition for distributed successive refinement, where the
successive Wyner-Ziv coding scheme plays an important role.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604078</id><created>2006-04-20</created><authors><author><keyname>Chli</keyname><forenames>Maria</forenames></author><author><keyname>De Wilde</keyname><forenames>Philippe</forenames></author></authors><title>The emergence of knowledge exchange: an agent-based model of a software
  market</title><categories>cs.MA cs.CE</categories><comments>fixed legend problem</comments><abstract>  We investigate knowledge exchange among commercial organisations, the
rationale behind it and its effects on the market. Knowledge exchange is known
to be beneficial for industry, but in order to explain it, authors have used
high level concepts like network effects, reputation and trust. We attempt to
formalise a plausible and elegant explanation of how and why companies adopt
information exchange and why it benefits the market as a whole when this
happens. This explanation is based on a multi-agent model that simulates a
market of software providers. Even though the model does not include any
high-level concepts, information exchange naturally emerges during simulations
as a successful profitable behaviour. The conclusions reached by this
agent-based analysis are twofold: (1) A straightforward set of assumptions is
enough to give rise to exchange in a software market. (2) Knowledge exchange is
shown to increase the efficiency of the market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604079</identifier>
 <datestamp>2010-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604079</id><created>2006-04-20</created><updated>2009-04-01</updated><authors><author><keyname>Scott</keyname><forenames>Alexander D.</forenames></author><author><keyname>Sorkin</keyname><forenames>Gregory B.</forenames></author></authors><title>Polynomial Constraint Satisfaction, Graph Bisection, and the Ising
  Partition Function</title><categories>cs.DM</categories><comments>Another algorithm, some applications, and a general revamping</comments><journal-ref>ACM Transactions on Algorithms, 5(4):45:1-27, October 2009.</journal-ref><doi>10.1145/1597036.1597049</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a problem class we call Polynomial Constraint Satisfaction
Problems, or PCSP. Where the usual CSPs from computer science and optimization
have real-valued score functions, and partition functions from physics have
monomials, PCSP has scores that are arbitrary multivariate formal polynomials,
or indeed take values in an arbitrary ring.
  Although PCSP is much more general than CSP, remarkably, all (exact,
exponential-time) algorithms we know of for 2-CSP (where each score depends on
at most 2 variables) extend to 2-PCSP, at the expense of just a polynomial
factor in running time. Specifically, we extend the reduction-based algorithm
of Scott and Sorkin; the specialization of that approach to sparse random
instances, where the algorithm runs in polynomial expected time;
dynamic-programming algorithms based on tree decompositions; and the
split-and-list matrix-multiplication algorithm of Williams.
  This gives the first polynomial-space exact algorithm more efficient than
exhaustive enumeration for the well-studied problems of finding a minimum
bisection of a graph, and calculating the partition function of an Ising model,
and the most efficient algorithm known for certain instances of Maximum
Independent Set. Furthermore, PCSP solves both optimization and counting
versions of a wide range of problems, including all CSPs, and thus enables
samplers including uniform sampling of optimal solutions and Gibbs sampling of
all solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604080</identifier>
 <datestamp>2008-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604080</id><created>2006-04-20</created><updated>2008-03-26</updated><authors><author><keyname>Scott</keyname><forenames>Alexander D.</forenames></author><author><keyname>Sorkin</keyname><forenames>Gregory B.</forenames></author></authors><title>Linear-programming design and analysis of fast algorithms for Max 2-Sat
  and Max 2-CSP</title><categories>cs.DM</categories><comments>Updated per published version</comments><journal-ref>Discrete Optimization, 4(3-4): 260-287, 2007</journal-ref><abstract>  The class $(r,2)$-CSP, or simply Max 2-CSP, consists of constraint
satisfaction problems with at most two $r$-valued variables per clause. For
instances with $n$ variables and $m$ binary clauses, we present an $O(n
r^{5+19m/100})$-time algorithm which is the fastest polynomial-space algorithm
for many problems in the class, including Max Cut. The method also proves a
treewidth bound $\tw(G) \leq (13/75+o(1))m$, which gives a faster Max 2-CSP
algorithm that uses exponential space: running in time
$\Ostar{2^{(13/75+o(1))m}}$, this is fastest for most problems in Max 2-CSP.
Parametrizing in terms of $n$ rather than $m$, for graphs of average degree $d$
we show a simple algorithm running time $\Ostar{2^{(1-\frac{2}{d+1})n}}$, the
fastest polynomial-space algorithm known.
  In combination with ``Polynomial CSPs'' introduced in a companion paper,
these algorithms also allow (with an additional polynomial-factor overhead in
space and time) counting and sampling, and the solution of problems like Max
Bisection that escape the usual CSP framework.
  Linear programming is key to the design as well as the analysis of the
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604081</id><created>2006-04-21</created><authors><author><keyname>M&#xe9;ry</keyname><forenames>Dominique</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Merz</keyname><forenames>Stephan</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Event Systems and Access Control</title><categories>cs.LO cs.CR</categories><proxy>ccsd inria-00001262</proxy><abstract>  We consider the interpretations of notions of access control (permissions,
interdictions, obligations, and user rights) as run-time properties of
information systems specified as event systems with fairness. We give proof
rules for verifying that an access control policy is enforced in a system, and
consider preservation of access control by refinement of event systems. In
particular, refinement of user rights is non-trivial; we propose to combine
low-level user rights and system obligations to implement high-level user
rights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604082</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604082</id><created>2006-04-21</created><updated>2006-05-05</updated><authors><author><keyname>Meshkati</keyname><forenames>Farhad</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Schwartz</keyname><forenames>Stuart C.</forenames></author><author><keyname>Balan</keyname><forenames>Radu V.</forenames></author></authors><title>Energy-Efficient Power and Rate Control with QoS Constraints: A
  Game-Theoretic Approach</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of the 2006 International Wireless
  Communications and Mobile Computing Conference (IWCMC'06), Vancouver, BC,
  Canada, July 2006</comments><acm-class>C.2.1</acm-class><abstract>  A game-theoretic model is proposed to study the cross-layer problem of joint
power and rate control with quality of service (QoS) constraints in
multiple-access networks. In the proposed game, each user seeks to choose its
transmit power and rate in a distributed manner in order to maximize its own
utility and at the same time satisfy its QoS requirements. The user's QoS
constraints are specified in terms of the average source rate and average
delay. The utility function considered here measures energy efficiency and the
delay includes both transmission and queueing delays. The Nash equilibrium
solution for the proposed non-cooperative game is derived and a closed-form
expression for the utility achieved at equilibrium is obtained. It is shown
that the QoS requirements of a user translate into a &quot;size&quot; for the user which
is an indication of the amount of network resources consumed by the user. Using
this framework, the tradeoffs among throughput, delay, network capacity and
energy efficiency are also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604083</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604083</id><created>2006-04-21</created><authors><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author></authors><title>Optimum Asymptotic Multiuser Efficiency of Pseudo-Orthogonal Randomly
  Spread CDMA</title><categories>cs.IT math.IT</categories><comments>WIC 27th Symposium on Information Theory in the Benelux, 2006</comments><abstract>  A $K$-user pseudo-orthogonal (PO) randomly spread CDMA system, equivalent to
transmission over a subset of $K'\leq K$ single-user Gaussian channels, is
introduced. The high signal-to-noise ratio performance of the PO-CDMA is
analyzed by rigorously deriving its asymptotic multiuser efficiency (AME) in
the large system limit. Interestingly, the $K'$-optimized PO-CDMA transceiver
scheme yields an AME which is practically equal to 1 for system loads smaller
than 0.1 and lower bounded by 1/4 for increasing loads. As opposed to the
vanishing efficiency of linear multiuser detectors, the derived efficiency is
comparable to the ultimate CDMA efficiency achieved for the intractable optimal
multiuser detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604084</id><created>2006-04-21</created><authors><author><keyname>Li</keyname><forenames>Ziming</forenames></author><author><keyname>Singer</keyname><forenames>Michael F.</forenames></author><author><keyname>Wu</keyname><forenames>Min</forenames></author><author><keyname>Zheng</keyname><forenames>Dabin</forenames></author></authors><title>A Recursive Method for Determining the One-Dimensional Submodules of
  Laurent-Ore Modules</title><categories>cs.SC math.CA</categories><comments>To appear in the Proceedings of ISSAC 2006</comments><abstract>  We present a method for determining the one-dimensional submodules of a
Laurent-Ore module. The method is based on a correspondence between
hyperexponential solutions of associated systems and one-dimensional
submodules. The hyperexponential solutions are computed recursively by solving
a sequence of first-order ordinary matrix equations. As the recursion proceeds,
the matrix equations will have constant coefficients with respect to the
operators that have been considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604085</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604085</id><created>2006-04-21</created><authors><author><keyname>Krishnan</keyname><forenames>Gayathre</forenames></author></authors><title>Information in Quantum Description and Gate Implementation</title><categories>cs.IT math.IT</categories><comments>4 pages</comments><abstract>  This note considers Kak's observer-reference model of quantum information,
where it is shown that qubits carry information that is sqrt n / ln n times
classical information, where n is the number of components in the measurement
system, to analyze information processing in quantum gates. The obverse side of
this exponential nature of quantum information is that the computational
complexity of implementing unconditionally reliable quantum gates is also
exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604086</id><created>2006-04-21</created><authors><author><keyname>Eiter</keyname><forenames>Thomas</forenames></author><author><keyname>Fink</keyname><forenames>Michael</forenames></author><author><keyname>Tompits</keyname><forenames>Hans</forenames></author></authors><title>A Knowledge-Based Approach for Selecting Information Sources</title><categories>cs.AI</categories><comments>53 pages, 2 Figures; to appear in Theory and Practice of Logic
  Programming (TPLP)</comments><acm-class>I.2.4; H.3.3</acm-class><abstract>  Through the Internet and the World-Wide Web, a vast number of information
sources has become available, which offer information on various subjects by
different providers, often in heterogeneous formats. This calls for tools and
methods for building an advanced information-processing infrastructure. One
issue in this area is the selection of suitable information sources in query
answering. In this paper, we present a knowledge-based approach to this
problem, in the setting where one among a set of information sources
(prototypically, data repositories) should be selected for evaluating a user
query. We use extended logic programs (ELPs) to represent rich descriptions of
the information sources, an underlying domain theory, and user queries in a
formal query language (here, XML-QL, but other languages can be handled as
well). Moreover, we use ELPs for declarative query analysis and generation of a
query description. Central to our approach are declarative source-selection
programs, for which we define syntax and semantics. Due to the structured
nature of the considered data items, the semantics of such programs must
carefully respect implicit context information in source-selection rules, and
furthermore combine it with possible user preferences. A prototype
implementation of our approach has been realized exploiting the DLV KR system
and its plp front-end for prioritized ELPs. We describe a representative
example involving specific movie databases, and report about experimental
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604087</id><created>2006-04-22</created><authors><author><keyname>Cao</keyname><forenames>Yongzhi</forenames></author><author><keyname>Xia</keyname><forenames>Lirong</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Probabilistic Automata for Computing with Words</title><categories>cs.AI cs.CL</categories><comments>35 pages; 3 figures</comments><abstract>  Usually, probabilistic automata and probabilistic grammars have crisp symbols
as inputs, which can be viewed as the formal models of computing with values.
In this paper, we first introduce probabilistic automata and probabilistic
grammars for computing with (some special) words in a probabilistic framework,
where the words are interpreted as probabilistic distributions or possibility
distributions over a set of crisp symbols. By probabilistic conditioning, we
then establish a retraction principle from computing with words to computing
with values for handling crisp inputs and a generalized extension principle
from computing with words to computing with all words for handling arbitrary
inputs. These principles show that computing with values and computing with all
words can be respectively implemented by computing with some special words. To
compare the transition probabilities of two near inputs, we also examine some
analytical properties of the transition probability functions of generalized
extensions. Moreover, the retractions and the generalized extensions are shown
to be equivalence-preserving. Finally, we clarify some relationships among the
retractions, the generalized extensions, and the extensions studied recently by
Qiu and Wang.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604088</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604088</id><created>2006-04-23</created><updated>2008-10-17</updated><authors><author><keyname>Maiti</keyname><forenames>Santanu K.</forenames></author></authors><title>How to Run Mathematica Batch-files in Background ?</title><categories>cs.MS</categories><comments>7 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematica is a versatile equipment for doing numeric and symbolic
computations and it has wide spread applications in all branches of science.
Mathematica has a complete consistency to design it at every stage that gives
it multilevel capability and helps advanced usage evolve naturally. Mathematica
functions work for any precision of number and it can be easily computed with
symbols, represented graphically to get the best answer. Mathematica is a
robust software development that can be used in any popular operating systems
and it can be communicated with external programs by using proper mathlink
commands.
  Sometimes it is quite desirable to run jobs in background of a computer which
can take considerable amount of time to finish, and this allows us to do work
on other tasks, while keeping the jobs running. Most of us are very familiar to
run jobs in background for the programs written in the languages like C, C++,
F77, F90, F95, etc. But the way of running jobs, written in a mathematica
notebook, in background is quite different from the conventional method. In
this article, we explore how to create a mathematica batch-file from a
mathematica notebook and run it in background. Here we concentrate our study
only for the Unix version, but one can run mathematica programs in background
for the Windows version as well by using proper mathematica batch-file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604089</id><created>2006-04-23</created><authors><author><keyname>Tucci</keyname><forenames>Michele</forenames></author></authors><title>Evolutionary Socioeconomics: a Schumpeterian Computer Simulation</title><categories>cs.GT cs.CY</categories><comments>PDF, 15 pages, 5 graphs</comments><acm-class>K.4.0; J.4; I.6.3</acm-class><abstract>  The following note contains a computer simulation concerning the struggle
between two companies: the first one is &quot;the biggest zaibatsu of all&quot;, while
the second one is &quot;small, fast, ruthless&quot;. The model is based on a
neo-Schumpeterian framework operating in a Darwinian evolutionary environment.
After running the program a large number of times, two characteristics stand
out: -- There is always a winner which takes it all, while the loser
disappears. -- The key to success is the ability to employ efficiently the
technological innovations. The topic of the present paper is strictly related
with the content of the following notes: Michele Tucci, Evolution and
Gravitation: a Computer Simulation of a Non-Walrasian Equilibrium Model;
Michele Tucci, Oligopolistic Competition in an Evolutionary Environment: a
Computer Simulation. The texts can be downloaded respectively at the following
addresses: http://arxiv.org/abs/cs.CY/0209017
http://arxiv.org/abs/cs.CY/0501037 These references include some preliminary
considerations regarding the comparison between the evolutionary and the
gravitational paradigms and the evaluation of approaches belonging to rival
schools of economic thought.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604090</id><created>2006-04-23</created><authors><author><keyname>Mannucci</keyname><forenames>Mirco A.</forenames></author><author><keyname>Sparks</keyname><forenames>Lisa</forenames></author><author><keyname>Struppa</keyname><forenames>Daniele C.</forenames></author></authors><title>Simplicial models of social aggregation I</title><categories>cs.CE</categories><comments>31 pages</comments><abstract>  This paper presents the foundational ideas for a new way of modeling social
aggregation. Traditional approaches have been using network theory, and the
theory of random networks. Under that paradigm, every social agent is
represented by a node, and every social interaction is represented by a segment
connecting two nodes. Early work in family interactions, as well as more recent
work in the study of terrorist organizations, shows that network modeling may
be insufficient to describe the complexity of human social structures.
Specifically, network theory does not seem to have enough flexibility to
represent higher order aggregations, where several agents interact as a group,
rather than as a collection of pairs. The model we present here uses a well
established mathematical theory, the theory of simplicial complexes, to address
this complex issue prevalent in interpersonal and intergroup communication. The
theory enables us to provide a richer graphical representation of social
interactions, and to determine quantitative mechanisms to describe the
robustness of a social structure. We also propose a methodology to create
random simplicial complexes, with the purpose of providing a new method to
simulate computationally the creation and disgregation of social structures.
Finally, we propose several measures which could be taken and observed in order
to describe and study an actual social aggregation occurring in interpersonal
and intergroup contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604091</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604091</id><created>2006-04-23</created><authors><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>Berger</keyname><forenames>Toby</forenames></author></authors><title>Robust Distributed Source Coding</title><categories>cs.IT math.IT</categories><comments>40 pages, submitted to the IEEE Transactions on Information Theory</comments><abstract>  We consider a distributed source coding system in which several observations
are communicated to the decoder using limited transmission rate. The
observations must be separately coded. We introduce a robust distributed coding
scheme which flexibly trades off between system robustness and compression
efficiency. The optimality of this coding scheme is proved for various special
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604092</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604092</id><created>2006-04-23</created><authors><author><keyname>Gezici</keyname><forenames>Sinan</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hisashi</forenames></author></authors><title>Optimal and Suboptimal Finger Selection Algorithms for MMSE Rake
  Receivers in Impulse Radio UWB Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to the EURASIP Journal on Wireless Communications and
  Networking - Special Issue on Ultra-Wideband (UWB) Communication Systems -
  Technology and Applications</comments><abstract>  The problem of choosing the optimal multipath components to be employed at a
minimum mean square error (MMSE) selective Rake receiver is considered for an
impulse radio ultra-wideband system. First, the optimal finger selection
problem is formulated as an integer programming problem with a non-convex
objective function. Then, the objective function is approximated by a convex
function and the integer programming problem is solved by means of constraint
relaxation techniques. The proposed algorithms are suboptimal due to the
approximate objective function and the constraint relaxation steps. However,
they perform better than the conventional finger selection algorithm, which is
suboptimal since it ignores the correlation between multipath components, and
they can get quite close to the optimal scheme that cannot be implemented in
practice due to its complexity. In addition to the convex relaxation
techniques, a genetic algorithm (GA) based approach is proposed, which does not
need any approximations or integer relaxations. This iterative algorithm is
based on the direct evaluation of the objective function, and can achieve
near-optimal performance with a reasonable number of iterations. Simulation
results are presented to compare the performance of the proposed finger
selection algorithms with that of the conventional and the optimal schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604093</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604093</id><created>2006-04-24</created><authors><author><keyname>Oggier</keyname><forenames>F.</forenames></author><author><keyname>Othman</keyname><forenames>G. Rekaya-Ben</forenames></author><author><keyname>Belfiore</keyname><forenames>J. -C.</forenames></author><author><keyname>Viterbo</keyname><forenames>E.</forenames></author></authors><title>Perfect Space Time Block Codes</title><categories>cs.IT math.IT</categories><comments>39 pages, 7 figures, submitted to IEEE Trans. on Inform. Theory Sep.
  2004, revised version</comments><acm-class>H.1.1</acm-class><abstract>  In this paper, we introduce the notion of perfect space-time block codes
(STBC). These codes have full rate, full diversity, non-vanishing constant
minimum determinant for increasing spectral efficiency, uniform average
transmitted energy per antenna and good shaping. We present algebraic
constructions of perfect STBCs for 2, 3, 4 and 6 antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604094</identifier>
 <datestamp>2007-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604094</id><created>2006-04-24</created><authors><author><keyname>Costa</keyname><forenames>Luciano da Fontoura</forenames></author><author><keyname>Bollt</keyname><forenames>Erik</forenames></author></authors><title>A Fast and Accurate Nonlinear Spectral Method for Image Recognition and
  Registration</title><categories>cs.DC cond-mat.stat-mech cs.CG cs.CV</categories><comments>4 pages, 3 figures</comments><journal-ref>Appl. Phys. Lett. 89, 174102 (2006)</journal-ref><doi>10.1063/1.2358325</doi><abstract>  This article addresses the problem of two- and higher dimensional pattern
matching, i.e. the identification of instances of a template within a larger
signal space, which is a form of registration. Unlike traditional correlation,
we aim at obtaining more selective matchings by considering more strict
comparisons of gray-level intensity. In order to achieve fast matching, a
nonlinear thresholded version of the fast Fourier transform is applied to a
gray-level decomposition of the original 2D image. The potential of the method
is substantiated with respect to real data involving the selective
identification of neuronal cell bodies in gray-level images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604095</id><created>2006-04-24</created><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>Fixed-Parameter Complexity of Minimum Profile Problems</title><categories>cs.DS cs.DM</categories><abstract>  Let $G=(V,E)$ be a graph. An ordering of $G$ is a bijection $\alpha: V\dom
\{1,2,..., |V|\}.$ For a vertex $v$ in $G$, its closed neighborhood is
$N[v]=\{u\in V: uv\in E\}\cup \{v\}.$ The profile of an ordering $\alpha$ of
$G$ is $\prf_{\alpha}(G)=\sum_{v\in V}(\alpha(v)-\min\{\alpha(u): u\in
N[v]\}).$ The profile $\prf(G)$ of $G$ is the minimum of $\prf_{\alpha}(G)$
over all orderings $\alpha$ of $G$. It is well-known that $\prf(G)$ is the
minimum number of edges in an interval graph $H$ that contains $G$ is a
subgraph. Since $|V|-1$ is a tight lower bound for the profile of connected
graphs $G=(V,E)$, the parametrization above the guaranteed value $|V|-1$ is of
particular interest. We show that deciding whether the profile of a connected
graph $G=(V,E)$ is at most $|V|-1+k$ is fixed-parameter tractable with respect
to the parameter $k$. We achieve this result by reduction to a problem kernel
of linear size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604096</id><created>2006-04-24</created><authors><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>Polynomial-time algorithms for coding across multiple unicasts</title><categories>cs.NI</categories><abstract>  We consider the problem of network coding across multiple unicasts. We give,
for wired and wireless networks, efficient polynomial time algorithms for
finding optimal network codes within the class of network codes restricted to
XOR coding between pairs of flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604097</identifier>
 <datestamp>2007-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604097</id><created>2006-04-24</created><updated>2007-07-22</updated><authors><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>Harb</keyname><forenames>Boulos</forenames></author></authors><title>Approximation algorithms for wavelet transform coding of data streams</title><categories>cs.DS</categories><comments>Added a universal representation that provides a provable
  approximation guarantee under all p-norms simultaneously</comments><acm-class>G.1.2</acm-class><abstract>  This paper addresses the problem of finding a B-term wavelet representation
of a given discrete function $f \in \real^n$ whose distance from f is
minimized. The problem is well understood when we seek to minimize the
Euclidean distance between f and its representation. The first known algorithms
for finding provably approximate representations minimizing general $\ell_p$
distances (including $\ell_\infty$) under a wide variety of compactly supported
wavelet bases are presented in this paper. For the Haar basis, a polynomial
time approximation scheme is demonstrated. These algorithms are applicable in
the one-pass sublinear-space data stream model of computation. They generalize
naturally to multiple dimensions and weighted norms. A universal representation
that provides a provable approximation guarantee under all p-norms
simultaneously; and the first approximation algorithms for bit-budget versions
of the problem, known as adaptive quantization, are also presented. Further, it
is shown that the algorithms presented here can be used to select a basis from
a tree-structured dictionary of bases and find a B-term representation of the
given function that provably approximates its best dictionary-basis
representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604098</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604098</id><created>2006-04-25</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Achievable Rates for the Multiple Access Channel with Feedback and
  Correlated Sources</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 43rd Annual Allerton Conference on Communication,
  Control, and Computing, Allerton House, the University of Illinois, Sept
  28-30 2005</comments><journal-ref>Proceedings of the 43rd Annual Allerton Conference on
  Communication, Control, and Computing, Allerton House, the University of
  Illinois, Sept 28-30 2005.</journal-ref><abstract>  In this paper, we investigate achievable rates on the multiple access channel
with feedback and correlated sources (MACFCS). The motivation for studying the
MACFCS stems from the fact that in a sensor network, sensors collect and
transmit correlated data to a common sink. We derive two achievable rate
regions for the three-node MACFCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604099</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604099</id><created>2006-04-25</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Myopic Coding in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 39th Conference on Information Sciences and
  Systems (CISS 2005), John Hopkins University, Baltimore, MD, March 16-18 2005</comments><journal-ref>Proceedings of the 39th Conference on Information Sciences and
  Systems (CISS 2005), John Hopkins University, Baltimore, MD, March 16-18
  2005.</journal-ref><abstract>  We investigate the achievable rate of data transmission from sources to sinks
through a multiple-relay network. We study achievable rates for omniscient
coding, in which all nodes are considered in the coding design at each node. We
find that, when maximizing the achievable rate, not all nodes need to
``cooperate'' with all other nodes in terms of coding and decoding. This leads
us to suggest a constrained network, whereby each node only considers a few
neighboring nodes during encoding and decoding. We term this myopic coding and
calculate achievable rates for myopic coding. We show by examples that, when
nodes transmit at low SNR, these rates are close to that achievable by
omniscient coding, when the network is unconstrained . This suggests that a
myopic view of the network might be as good as a global view. In addition,
myopic coding has the practical advantage of being more robust to topology
changes. It also mitigates the high computational complexity and large
buffer/memory requirements of omniscient coding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604100</id><created>2006-04-25</created><updated>2007-04-01</updated><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author></authors><title>Protocols for Kak's Cubic Cipher and Diffie-Hellman Based Asymmetric
  Oblivious Key Exchange</title><categories>cs.CR</categories><comments>7 pages, with minor typographical corrections.</comments><abstract>  This paper presents protocols for Kak's cubic transformation and proposes a
modification to Diffie-Hellman key exchange protocol in order to achieve
asymmetric oblivious exchange of keys.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604101</identifier>
 <datestamp>2008-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604101</id><created>2006-04-25</created><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Chyzak</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Ollivier</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIX</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Schost</keyname><forenames>&#xc9;ric</forenames><affiliation>LIX</affiliation></author><author><keyname>Sedoglavic</keyname><forenames>Alexandre</forenames><affiliation>LIFL</affiliation></author></authors><title>Fast computation of power series solutions of systems of differential
  equations</title><categories>cs.SC</categories><proxy>ccsd inria-00001264</proxy><journal-ref>Dans 2007 ACM-SIAM Symposium on Discrete Algorithms (2007)
  1012--1021</journal-ref><abstract>  We propose new algorithms for the computation of the first N terms of a
vector (resp. a basis) of power series solutions of a linear system of
differential equations at an ordinary point, using a number of arithmetic
operations which is quasi-linear with respect to N. Similar results are also
given in the non-linear case. This extends previous results obtained by Brent
and Kung for scalar differential equations of order one and two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604102</id><created>2006-04-25</created><authors><author><keyname>Hinze-Hoare</keyname><forenames>Vita</forenames></author></authors><title>HCI and Educational Metrics as Tools for VLE Evaluation</title><categories>cs.HC cs.LG</categories><abstract>  The general set of HCI and Educational principles are considered and a
classification system constructed. A frequency analysis of principles is used
to obtain the most significant set. Metrics are devised to provide objective
measures of these principles and a consistent testing regime devised. These
principles are used to analyse Blackboard and Moodle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604103</id><created>2006-04-25</created><authors><author><keyname>Hinze-Hoare</keyname><forenames>Vita</forenames></author></authors><title>Further Evaluationh of VLEs using HCI and Educational Metrics</title><categories>cs.HC</categories><abstract>  Under consideration are the general set of Human computer Interaction (HCI)
and Educational principles from prominent authors in the field and the
construction of a system for evaluating Virtual Learning Environments (VLEs)
with respect to the application of these HCI and Educational Principles. A
frequency analysis of principles is used to obtain the most significant set.
Metrics are devised to provide objective measures of these principles and a
consistent testing regime is introduced. These principles are used to analyse
the University VLE Blackboard. An open source VLE is also constructed with
similar content to Blackboard courses so that a systematic comparison can be
made. HCI and Educational metrics are determined for each VLE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604104</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604104</id><created>2006-04-26</created><authors><author><keyname>Manada</keyname><forenames>Akiko</forenames></author><author><keyname>Kashyap</keyname><forenames>Navin</forenames></author></authors><title>On the Shannon Covers of Certain Irreducible Constrained Systems of
  Finite Type</title><categories>cs.IT cs.DM math.IT</categories><comments>5 pages, 9 figures; to appear in the Proceedings of the 2006
  International Symposium on Information Theory, July 2006</comments><abstract>  A construction of Crochemore, Mignosi and Restivo in the automata theory
literature gives a presentation of a finite-type constrained system (FTCS) that
is deterministic and has a relatively small number of states. This construction
is thus a good starting point for determining the minimal deterministic
presentation, known as the Shannon cover, of an FTCS. We analyze in detail the
Crochemore-Mignosi-Restivo (CMR) construction in the case when the list of
forbidden words defining the FTCS is of size at most two. We show that if the
FTCS is irreducible, then an irreducible presentation for the system can be
easily obtained by deleting a prescribed few states from the CMR presentation.
By studying the follower sets of the states in this irreducible presentation,
we are able to explicitly determine the Shannon cover in some cases. In
particular, our results show that the CMR construction directly yields the
Shannon cover in the case of an irreducible FTCS with exactly one forbidden
word, but this is not in general the case for FTCS's with two forbidden words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604105</id><created>2006-04-26</created><authors><author><keyname>Benbadis</keyname><forenames>Farid</forenames></author><author><keyname>Puig</keyname><forenames>Jean-Jacques</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author><author><keyname>Chaudet</keyname><forenames>Claude</forenames></author><author><keyname>Friedman</keyname><forenames>Timur</forenames></author><author><keyname>Simplot-Ryl</keyname><forenames>David</forenames></author></authors><title>Jumps: Enhancing hop-count positioning in sensor networks using multiple
  coordinates</title><categories>cs.NI</categories><abstract>  Positioning systems in self-organizing networks generally rely on
measurements such as delay and received signal strength, which may be difficult
to obtain and often require dedicated equipment. An alternative to such
approaches is to use simple connectivity information, that is, the presence or
absence of a link between any pair of nodes, and to extend it to hop-counts, in
order to obtain an approximate coordinate system. Such an approximation is
sufficient for a large number of applications, such as routing. In this paper,
we propose Jumps, a positioning system for those self-organizing networks in
which other types of (exact) positioning systems cannot be used or are deemed
to be too costly. Jumps builds a multiple coordinate system based solely on
nodes neighborhood knowledge. Jumps is interesting in the context of wireless
sensor networks, as it neither requires additional embedded equipment nor
relies on any nodes capabilities. While other approaches use only three
hop-count measurements to infer the position of a node, Jumps uses an arbitrary
number. We observe that an increase in the number of measurements leads to an
improvement in the localization process, without requiring a high dense
environment. We show through simulations that Jumps, when compared with
existing approaches, reduces the number of nodes sharing the same coordinates,
which paves the way for functions such as position-based routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604106</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604106</id><created>2006-04-26</created><authors><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Bounded expected delay in arithmetic coding</title><categories>cs.IT math.IT</categories><abstract>  We address the problem of delay in an arithmetic coding system. Due to the
nature of the arithmetic coding process, source sequences causing arbitrarily
large encoding or decoding delays exist. This phenomena raises the question of
just how large is the expected input to output delay in these systems, i.e.,
once a source sequence has been encoded, what is the expected number of source
letters that should be further encoded to allow full decoding of that sequence.
In this paper, we derive several new upper bounds on the expected delay for a
memoryless source, which improve upon a known bound due to Gallager. The bounds
provided are uniform in the sense of being independent of the sequence's
history. In addition, we give a sufficient condition for a source to admit a
bounded expected delay, which holds for a stationary ergodic Markov source of
any order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604107</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604107</id><created>2006-04-27</created><updated>2006-05-09</updated><authors><author><keyname>Jovicic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Cognitive Radio: An Information-Theoretic Perspective</title><categories>cs.IT math.IT</categories><comments>34 pages, Sections 5 and A.2 updated</comments><abstract>  Cognitive radios have been proposed as a means to implement efficient reuse
of the licensed spectrum. The key feature of a cognitive radio is its ability
to recognize the primary (licensed) user and adapt its communication strategy
to minimize the interference that it generates. We consider a communication
scenario in which the primary and the cognitive user wish to communicate to
different receivers, subject to mutual interference. Modeling the cognitive
radio as a transmitter with side-information about the primary transmission, we
characterize the largest rate at which the cognitive radio can reliably
communicate under the constraint that (i) no interference is created for the
primary user, and (ii) the primary encoder-decoder pair is oblivious to the
presence of the cognitive radio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604108</id><created>2006-04-27</created><authors><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author><author><keyname>Valiente</keyname><forenames>Gabriel</forenames></author></authors><title>An Algebraic View of the Relation between Largest Common Subtrees and
  Smallest Common Supertrees</title><categories>cs.DS cs.DM math.CT</categories><comments>32 pages</comments><acm-class>G.2.3</acm-class><abstract>  The relationship between two important problems in tree pattern matching, the
largest common subtree and the smallest common supertree problems, is
established by means of simple constructions, which allow one to obtain a
largest common subtree of two trees from a smallest common supertree of them,
and vice versa. These constructions are the same for isomorphic, homeomorphic,
topological, and minor embeddings, they take only time linear in the size of
the trees, and they turn out to have a clear algebraic meaning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604109</id><created>2006-04-27</created><authors><author><keyname>Rabbertz</keyname><forenames>K.</forenames><affiliation>University of Karlsruhe</affiliation></author><author><keyname>Thomas</keyname><forenames>M.</forenames><affiliation>CALTECH</affiliation></author><author><keyname>Ashby</keyname><forenames>S.</forenames><affiliation>CERN</affiliation></author><author><keyname>Corvo</keyname><forenames>M.</forenames><affiliation>CERN</affiliation><affiliation>INFN Padova</affiliation></author><author><keyname>Argir&#xf2;</keyname><forenames>S.</forenames><affiliation>CERN</affiliation><affiliation>INFN-CNAF</affiliation></author><author><keyname>Darmenov</keyname><forenames>N.</forenames><affiliation>CERN</affiliation><affiliation>INRNE Sofia</affiliation></author><author><keyname>Darwish</keyname><forenames>R.</forenames><affiliation>FERMILAB</affiliation></author><author><keyname>Evans</keyname><forenames>D.</forenames><affiliation>FERMILAB</affiliation></author><author><keyname>Holzman</keyname><forenames>B.</forenames><affiliation>FERMILAB</affiliation></author><author><keyname>Ratnikova</keyname><forenames>N.</forenames><affiliation>FERMILAB</affiliation></author><author><keyname>Muzaffar</keyname><forenames>S.</forenames><affiliation>Northeastern University</affiliation></author><author><keyname>Nowack</keyname><forenames>A.</forenames><affiliation>RWTH Aachen</affiliation></author><author><keyname>Wildish</keyname><forenames>T.</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Kim</keyname><forenames>B.</forenames><affiliation>University of Florida</affiliation></author><author><keyname>Weng</keyname><forenames>J.</forenames><affiliation>University of Karlsruhe</affiliation><affiliation>CERN</affiliation></author><author><keyname>B&#xfc;ge</keyname><forenames>V.</forenames><affiliation>University of Karlsruhe</affiliation><affiliation>FZ Karlsruhe</affiliation></author><author><keyname>Collaboration</keyname><forenames>for the CMS</forenames></author></authors><title>CMS Software Distribution on the LCG and OSG Grids</title><categories>cs.DC</categories><comments>4 pages, 1 figure, latex with hyperrefs</comments><abstract>  The efficient exploitation of worldwide distributed storage and computing
resources available in the grids require a robust, transparent and fast
deployment of experiment specific software. The approach followed by the CMS
experiment at CERN in order to enable Monte-Carlo simulations, data analysis
and software development in an international collaboration is presented. The
current status and future improvement plans are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604110</id><created>2006-04-27</created><authors><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author><author><keyname>Hogg</keyname><forenames>Tad</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Modeling and Mathematical Analysis of Swarms of Microscopic Robots</title><categories>cs.MA cs.RO</categories><comments>2005 IEEE Swarm Intelligence Symposium, Pasadena, CA June 2005</comments><abstract>  The biologically-inspired swarm paradigm is being used to design
self-organizing systems of locally interacting artificial agents. A major
difficulty in designing swarms with desired characteristics is understanding
the causal relation between individual agent and collective behaviors.
Mathematical analysis of swarm dynamics can address this difficulty to gain
insight into system design. This paper proposes a framework for mathematical
modeling of swarms of microscopic robots that may one day be useful in medical
applications. While such devices do not yet exist, the modeling approach can be
helpful in identifying various design trade-offs for the robots and be a useful
guide for their eventual fabrication. Specifically, we examine microscopic
robots that reside in a fluid, for example, a bloodstream, and are able to
detect and respond to different chemicals. We present the general mathematical
model of a scenario in which robots locate a chemical source. We solve the
scenario in one-dimension and show how results can be used to evaluate certain
design decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604111</id><created>2006-04-27</created><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Jones</keyname><forenames>Chris</forenames></author><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author><author><keyname>Mataric</keyname><forenames>Maja J</forenames></author></authors><title>Analysis of Dynamic Task Allocation in Multi-Robot Systems</title><categories>cs.RO cs.MA</categories><comments>Preprint version of the paper published in International Journal of
  Robotics, March 2006, Volume 25, pp. 225-242</comments><abstract>  Dynamic task allocation is an essential requirement for multi-robot systems
operating in unknown dynamic environments. It allows robots to change their
behavior in response to environmental changes or actions of other robots in
order to improve overall system performance. Emergent coordination algorithms
for task allocation that use only local sensing and no direct communication
between robots are attractive because they are robust and scalable. However, a
lack of formal analysis tools makes emergent coordination algorithms difficult
to design. In this paper we present a mathematical model of a general dynamic
task allocation mechanism. Robots using this mechanism have to choose between
two types of task, and the goal is to achieve a desired task division in the
absence of explicit communication and global knowledge. Robots estimate the
state of the environment from repeated local observations and decide which task
to choose based on these observations. We model the robots and observations as
stochastic processes and study the dynamics of the collective behavior.
Specifically, we analyze the effect that the number of observations and the
choice of the decision function have on the performance of the system. The
mathematical models are validated in a multi-robot multi-foraging scenario. The
model's predictions agree very closely with experimental results from
sensor-based simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604112</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604112</id><created>2006-04-27</created><authors><author><keyname>Becla</keyname><forenames>Jacek</forenames></author><author><keyname>Hanushevsky</keyname><forenames>Andrew</forenames></author><author><keyname>Nikolaev</keyname><forenames>Sergei</forenames></author><author><keyname>Abdulla</keyname><forenames>Ghaleb</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author><author><keyname>Nieto-Santisteban</keyname><forenames>Maria</forenames></author><author><keyname>Thakar</keyname><forenames>Ani</forenames></author><author><keyname>Gray</keyname><forenames>Jim</forenames></author></authors><title>Designing a Multi-petabyte Database for LSST</title><categories>cs.DB cs.DL</categories><comments>8 pages. to appear in SPIE</comments><doi>10.1117/12.671721</doi><abstract>  The 3.2 giga-pixel LSST camera will produce approximately half a petabyte of
archive images every month. These data need to be reduced in under a minute to
produce real-time transient alerts, and then added to the cumulative catalog
for further analysis. The catalog is expected to grow about three hundred
terabytes per year. The data volume, the real-time transient alerting
requirements of the LSST, and its spatio-temporal aspects require innovative
techniques to build an efficient data access system at reasonable cost. As
currently envisioned, the system will rely on a database for catalogs and
metadata. Several database systems are being evaluated to understand how they
perform at these data rates, data volumes, and access patterns. This paper
describes the LSST requirements, the challenges they impose, the data access
philosophy, results to date from evaluating available database technologies
against LSST requirements, and the proposed database architecture to meet the
data challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0604113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0604113</id><created>2006-04-28</created><authors><author><keyname>Caracciolo</keyname><forenames>Sergio</forenames></author><author><keyname>Fichera</keyname><forenames>Davide</forenames></author><author><keyname>Sportiello</keyname><forenames>Andrea</forenames></author></authors><title>One-in-Two-Matching Problem is NP-complete</title><categories>cs.CC</categories><comments>30 pages</comments><acm-class>F.2.2</acm-class><abstract>  2-dimensional Matching Problem, which requires to find a matching of left- to
right-vertices in a balanced $2n$-vertex bipartite graph, is a well-known
polynomial problem, while various variants, like the 3-dimensional analogoue
(3DM, with triangles on a tripartite graph), or the Hamiltonian Circuit Problem
(HC, a restriction to ``unicyclic'' matchings) are among the main examples of
NP-hard problems, since the first Karp reduction series of 1972. The same holds
for the weighted variants of these problems, the Linear Assignment Problem
being polynomial, and the Numerical 3-Dimensional Matching and Travelling
Salesman Problem being NP-complete.
  In this paper we show that a small modification of the 2-dimensional Matching
and Assignment Problems in which for each $i \leq n/2$ it is required that
either $\pi(2i-1)=2i-1$ or $\pi(2i)=2i$, is a NP-complete problem. The proof is
by linear reduction from SAT (or NAE-SAT), with the size $n$ of the Matching
Problem being four times the number of edges in the factor graph representation
of the boolean problem. As a corollary, in combination with the simple linear
reduction of One-in-Two Matching to 3-Dimensional Matching, we show that SAT
can be linearly reduced to 3DM, while the original Karp reduction was only
cubic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605001</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605001</id><created>2006-05-01</created><updated>2006-05-02</updated><authors><author><keyname>Tian</keyname><forenames>Chao</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>On Multistage Successive Refinement for Wyner-Ziv Source Coding with
  Degraded Side Informations</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Information Theory Apr. 2006</comments><abstract>  We provide a complete characterization of the rate-distortion region for the
multistage successive refinement of the Wyner-Ziv source coding problem with
degraded side informations at the decoder. Necessary and sufficient conditions
for a source to be successively refinable along a distortion vector are
subsequently derived. A source-channel separation theorem is provided when the
descriptions are sent over independent channels for the multistage case.
Furthermore, we introduce the notion of generalized successive refinability
with multiple degraded side informations. This notion captures whether
progressive encoding to satisfy multiple distortion constraints for different
side informations is as good as encoding without progressive requirement.
Necessary and sufficient conditions for generalized successive refinability are
given. It is shown that the following two sources are generalized successively
refinable: (1) the Gaussian source with degraded Gaussian side informations,
(2) the doubly symmetric binary source when the worse side information is a
constant. Thus for both cases, the failure of being successively refinable is
only due to the inherent uncertainty on which side information will occur at
the decoder, but not the progressive encoding requirement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605002</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605002</id><created>2006-04-30</created><updated>2006-06-20</updated><authors><author><keyname>Pang</keyname><forenames>Chao-Yang</forenames></author><author><keyname>Zhou</keyname><forenames>Zheng-Wei</forenames></author><author><keyname>Guo</keyname><forenames>Guang-Can</forenames></author></authors><title>A Hybrid Quantum Encoding Algorithm of Vector Quantization for Image
  Compression</title><categories>cs.MM cs.DS</categories><comments>Modify on June 21. 10pages, 3 figures</comments><acm-class>H.5.1; F.2.1; F.2.2; F.1.2</acm-class><doi>10.1088/1009-1963/15/12/044</doi><abstract>  Many classical encoding algorithms of Vector Quantization (VQ) of image
compression that can obtain global optimal solution have computational
complexity O(N). A pure quantum VQ encoding algorithm with probability of
success near 100% has been proposed, that performs operations 45sqrt(N) times
approximately. In this paper, a hybrid quantum VQ encoding algorithm between
classical method and quantum algorithm is presented. The number of its
operations is less than sqrt(N) for most images, and it is more efficient than
the pure quantum algorithm.
  Key Words: Vector Quantization, Grover's Algorithm, Image Compression,
Quantum Algorithm
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605003</id><created>2006-04-30</created><updated>2006-05-03</updated><authors><author><keyname>Saxena</keyname><forenames>Amitabh</forenames></author><author><keyname>Soh</keyname><forenames>Ben</forenames></author></authors><title>A New Cryptosystem Based On Hidden Order Groups</title><categories>cs.CR cs.CC</categories><comments>removed examples for multiparty key agreement and join protocols,
  since they are redundant</comments><abstract>  Let $G_1$ be a cyclic multiplicative group of order $n$. It is known that the
Diffie-Hellman problem is random self-reducible in $G_1$ with respect to a
fixed generator $g$ if $\phi(n)$ is known. That is, given $g, g^x\in G_1$ and
having oracle access to a `Diffie-Hellman Problem' solver with fixed generator
$g$, it is possible to compute $g^{1/x} \in G_1$ in polynomial time (see
theorem 3.2). On the other hand, it is not known if such a reduction exists
when $\phi(n)$ is unknown (see conjuncture 3.1). We exploit this ``gap'' to
construct a cryptosystem based on hidden order groups and present a practical
implementation of a novel cryptographic primitive called an \emph{Oracle Strong
Associative One-Way Function} (O-SAOWF). O-SAOWFs have applications in
multiparty protocols. We demonstrate this by presenting a key agreement
protocol for dynamic ad-hoc groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605004</id><created>2006-05-01</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Srinivas</keyname><forenames>M. B</forenames></author></authors><title>Novel Reversible Multiplier Architecture Using Reversible TSG Gate</title><categories>cs.AR</categories><comments>4 Pages; Published in Proceedings of the 4th ACS/IEEE International
  Conference on Computer Systems and Applications (AICCSA-06), Dubai, March
  2006. pp. 100-103. Contains the missing reference</comments><abstract>  In the recent years, reversible logic has emerged as a promising technology
having its applications in low power CMOS, quantum computing, nanotechnology,
and optical computing. The classical set of gates such as AND, OR, and EXOR are
not reversible. Recently a 4 * 4 reversible gate called TSG is proposed. The
most significant aspect of the proposed gate is that it can work singly as a
reversible full adder, that is reversible full adder can now be implemented
with a single gate only. This paper proposes a NXN reversible multiplier using
TSG gate. It is based on two concepts. The partial products can be generated in
parallel with a delay of d using Fredkin gates and thereafter the addition can
be reduced to log2N steps by using reversible parallel adder designed from TSG
gates. Similar multiplier architecture in conventional arithmetic (using
conventional logic) has been reported in existing literature, but the proposed
one in this paper is totally based on reversible logic and reversible cells as
its building block. A 4x4 architecture of the proposed reversible multiplier is
also designed. It is demonstrated that the proposed multiplier architecture
using the TSG gate is much better and optimized, compared to its existing
counterparts in literature; in terms of number of reversible gates and garbage
outputs. Thus, this paper provides the initial threshold to building of more
complex system which can execute more complicated operations using reversible
logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605005</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605005</id><created>2006-05-01</created><updated>2007-02-17</updated><authors><author><keyname>Liu</keyname><forenames>Ruoheng</forenames></author><author><keyname>Maric</keyname><forenames>Ivana</forenames></author><author><keyname>Yates</keyname><forenames>Roy D.</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author></authors><title>The Discrete Memoryless Multiple Access Channel with Confidential
  Messages</title><categories>cs.IT math.IT</categories><comments>1 figure, accepted by ISIT 2006 conference</comments><abstract>  A multiple-access channel is considered in which messages from one encoder
are confidential. Confidential messages are to be transmitted with perfect
secrecy, as measured by equivocation at the other encoder. The upper bounds and
the achievable rates for this communication situation are determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605006</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605006</id><created>2006-05-01</created><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>An Information-Spectrum Approach to Multiterminal Rate-Distortion Theory</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory (Apr. 2006)</comments><abstract>  An information-spectrum approach is applied to solve the multiterminal source
coding problem for correlated general sources, where sources may be
nonstationary and/or nonergodic, and the distortion measure is arbitrary and
may be nonadditive. A general formula for the rate-distortion region of the
multiterminal source coding problem with the maximum distortion criterion under
fixed-length coding is shown in this correspondence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605007</identifier>
 <datestamp>2008-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605007</id><created>2006-05-02</created><updated>2006-07-29</updated><authors><author><keyname>Mahadevan</keyname><forenames>Priya</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Fall</keyname><forenames>Kevin</forenames></author><author><keyname>Vahdat</keyname><forenames>Amin</forenames></author></authors><title>Systematic Topology Analysis and Generation Using Degree Correlations</title><categories>cs.NI cond-mat.stat-mech physics.soc-ph</categories><comments>Final version</comments><acm-class>C.2.1; G.3; G.2.2</acm-class><journal-ref>SIGCOMM 2006 (ACM SIGCOMM Computer Communication Review (CCR),
  v.36, n.4, p.135-146, 2006)</journal-ref><doi>10.1145/1151659.1159930</doi><abstract>  We present a new, systematic approach for analyzing network topologies. We
first introduce the dK-series of probability distributions specifying all
degree correlations within d-sized subgraphs of a given graph G. Increasing
values of d capture progressively more properties of G at the cost of more
complex representation of the probability distribution. Using this series, we
can quantitatively measure the distance between two graphs and construct random
graphs that accurately reproduce virtually all metrics proposed in the
literature. The nature of the dK-series implies that it will also capture any
future metrics that may be proposed. Using our approach, we construct graphs
for d=0,1,2,3 and demonstrate that these graphs reproduce, with increasing
accuracy, important properties of measured and modeled Internet topologies. We
find that the d=2 case is sufficient for most practical purposes, while d=3
essentially reconstructs the Internet AS- and router-level topologies exactly.
We hope that a systematic method to analyze and synthesize topologies offers a
significant improvement to the set of tools available to network topology and
protocol researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605008</id><created>2006-05-02</created><authors><author><keyname>Durand</keyname><forenames>Arnaud</forenames><affiliation>ELM</affiliation></author><author><keyname>Grandjean</keyname><forenames>Etienne</forenames><affiliation>GREYC</affiliation></author></authors><title>The complexity of acyclic conjunctive queries revisited</title><categories>cs.LO</categories><comments>30 pages</comments><proxy>ccsd ccsd-00023582</proxy><abstract>  In this paper, we consider first-order logic over unary functions and study
the complexity of the evaluation problem for conjunctive queries described by
such kind of formulas. A natural notion of query acyclicity for this language
is introduced and we study the complexity of a large number of variants or
generalizations of acyclic query problems in that context (Boolean or not
Boolean, with or without inequalities, comparisons, etc...). Our main results
show that all those problems are \textit{fixed-parameter linear} i.e. they can
be evaluated in time $f(|Q|).|\textbf{db}|.|Q(\textbf{db})|$ where $|Q|$ is the
size of the query $Q$, $|\textbf{db}|$ the database size, $|Q(\textbf{db})|$ is
the size of the output and $f$ is some function whose value depends on the
specific variant of the query problem (in some cases, $f$ is the identity
function). Our results have two kinds of consequences. First, they can be
easily translated in the relational (i.e., classical) setting. Previously known
bounds for some query problems are improved and new tractable cases are then
exhibited. Among others, as an immediate corollary, we improve a result of
\~\cite{PapadimitriouY-99} by showing that any (relational) acyclic conjunctive
query with inequalities can be evaluated in time
$f(|Q|).|\textbf{db}|.|Q(\textbf{db})|$. A second consequence of our method is
that it provides a very natural descriptive approach to the complexity of
well-known algorithmic problems. A number of examples (such as acyclic subgraph
problems, multidimensional matching, etc...) are considered for which new
insights of their complexity are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605009</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605009</id><created>2006-05-03</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>On the Foundations of Universal Sequence Prediction</title><categories>cs.LG cs.IT math.IT math.ST stat.TH</categories><comments>14 pages</comments><report-no>IDSIA-03-06</report-no><journal-ref>Proc. 3rd Annual Conference on Theory and Applications of Models
  of Computation (TAMC 2006) pages 408-420</journal-ref><abstract>  Solomonoff completed the Bayesian framework by providing a rigorous, unique,
formal, and universal choice for the model class and the prior. We discuss in
breadth how and in which sense universal (non-i.i.d.) sequence prediction
solves various (philosophical) problems of traditional Bayesian sequence
prediction. We show that Solomonoff's model possesses many desirable
properties: Fast convergence and strong bounds, and in contrast to most
classical continuous prior densities has no zero p(oste)rior problem, i.e. can
confirm universal hypotheses, is reparametrization and regrouping invariant,
and avoids the old-evidence and updating problem. It even performs well
(actually better) in non-computable environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605010</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605010</id><created>2006-05-03</created><authors><author><keyname>Wu</keyname><forenames>Di</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author></authors><title>Complementary Set Matrices Satisfying a Column Correlation Constraint</title><categories>cs.IT math.IT</categories><abstract>  Motivated by the problem of reducing the peak to average power ratio (PAPR)
of transmitted signals, we consider a design of complementary set matrices
whose column sequences satisfy a correlation constraint. The design algorithm
recursively builds a collection of $2^{t+1}$ mutually orthogonal (MO)
complementary set matrices starting from a companion pair of sequences. We
relate correlation properties of column sequences to that of the companion pair
and illustrate how to select an appropriate companion pair to ensure that a
given column correlation constraint is satisfied. For $t=0$, companion pair
properties directly determine matrix column correlation properties. For $t\geq
1$, reducing correlation merits of the companion pair may lead to improved
column correlation properties. However, further decrease of the maximum
out-off-phase aperiodic autocorrelation of column sequences is not possible
once the companion pair correlation merit is less than a threshold determined
by $t$. We also reveal a design of the companion pair which leads to
complementary set matrices with Golay column sequences. Exhaustive search for
companion pairs satisfying a column correlation constraint is infeasible for
medium and long sequences. We instead search for two shorter length sequences
by minimizing a cost function in terms of their autocorrelation and
crosscorrelation merits. Furthermore, an improved cost function which helps in
reducing the maximum out-off-phase column correlation is derived based on the
properties of the companion pair. By exploiting the well-known Welch bound,
sufficient conditions for the existence of companion pairs which satisfy a set
of column correlation constraints are also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605011</identifier>
 <datestamp>2012-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605011</id><created>2006-05-03</created><updated>2006-06-28</updated><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Krizanc</keyname><forenames>Danny</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author><author><keyname>Wuhrer</keyname><forenames>Stefanie</forenames></author></authors><title>A Characterization of the Degree Sequences of 2-Trees</title><categories>cs.DM math.CO</categories><comments>17 pages, 5 figures</comments><acm-class>G.2.2</acm-class><journal-ref>The Journal of Graph Theory, 58(3):191-209, 2008</journal-ref><doi>10.1002/jgt.20302</doi><abstract>  A graph G is a 2-tree if G=K_3, or G has a vertex v of degree 2, whose
neighbours are adjacent, and G\v{i}s a 2-tree. A characterization of the degree
sequences of 2-trees is given. This characterization yields a linear-time
algorithm for recognizing and realizing degree sequences of 2-trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605012</identifier>
 <datestamp>2008-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605012</id><created>2006-05-04</created><updated>2008-02-13</updated><authors><author><keyname>Steels</keyname><forenames>L.</forenames></author><author><keyname>Loetzsch</keyname><forenames>M.</forenames></author></authors><title>Perspective alignment in spatial language</title><categories>cs.AI</categories><comments>to appear in: K. Coventry, J. Bateman, and T. Tenbrink (eds.) Spatial
  Language in Dialogue. Oxford University Press, 2008</comments><abstract>  It is well known that perspective alignment plays a major role in the
planning and interpretation of spatial language. In order to understand the
role of perspective alignment and the cognitive processes involved, we have
made precise complete cognitive models of situated embodied agents that
self-organise a communication system for dialoging about the position and
movement of real world objects in their immediate surroundings. We show in a
series of robotic experiments which cognitive mechanisms are necessary and
sufficient to achieve successful spatial language and why and how perspective
alignment can take place, either implicitly or based on explicit marking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605013</identifier>
 <datestamp>2007-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605013</id><created>2006-05-04</created><updated>2007-07-31</updated><authors><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Francis</keyname><forenames>Mathew C</forenames></author><author><keyname>Sivadasan</keyname><forenames>Naveen</forenames></author></authors><title>Geometric representation of graphs in low dimension</title><categories>cs.DM cs.DS</categories><comments>preliminary version appeared in Cocoon 2006</comments><abstract>  We give an efficient randomized algorithm to construct a box representation
of any graph G on n vertices in $1.5 (\Delta + 2) \ln n$ dimensions, where
$\Delta$ is the maximum degree of G. We also show that $\boxi(G) \le (\Delta +
2) \ln n$ for any graph G. Our bound is tight up to a factor of $\ln n$. We
also show that our randomized algorithm can be derandomized to get a polynomial
time deterministic algorithm. Though our general upper bound is in terms of
maximum degree $\Delta$, we show that for almost all graphs on n vertices, its
boxicity is upper bound by $c\cdot(d_{av} + 1) \ln n$ where d_{av} is the
average degree and c is a small constant. Also, we show that for any graph G,
$\boxi(G) \le \sqrt{8 n d_{av} \ln n}$, which is tight up to a factor of $b
\sqrt{\ln n}$ for a constant b.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605014</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605014</id><created>2006-05-04</created><authors><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Generalized Multiple Access Channels with Confidential Messages</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, April 2006</comments><abstract>  A discrete memoryless generalized multiple access channel (GMAC) with
confidential messages is studied, where two users attempt to transmit common
information to a destination and each user also has private (confidential)
information intended for the destination. The two users are allowed to receive
channel outputs, and hence may obtain the confidential information sent by each
other from channel outputs they receive. However, each user views the other
user as a wire-tapper, and wishes to keep its confidential information as
secret as possible from the other user. The level of secrecy of the
confidential information is measured by the equivocation rate, i.e., the
entropy rate of the confidential information conditioned on channel outputs at
the wire-tapper. The performance measure of interest for the GMAC with
confidential messages is the rate-equivocation tuple that includes the common
rate, two private rates and two equivocation rates as components. The set that
includes all these achievable rate-equivocation tuples is referred to as the
capacity-equivocation region. The GMAC with one confidential message set is
first studied, where only one user (user 1) has private (confidential)
information for the destination. Inner and outer bounds on the
capacity-equivocation region are derived, and the capacity-equivocation are
established for some classes of channels including the Gaussian GMAC.
Furthermore, the secrecy capacity region is established, which is the set of
all achievable rates with user 2 being perfectly ignorant of confidential
messages of user 1. For the GMAC with two confidential message sets, where both
users have confidential messages for the destination, an inner bound on the
capacity-equivocation region is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605015</id><created>2006-05-04</created><authors><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author><author><keyname>Pietronero</keyname><forenames>Luciano</forenames></author></authors><title>Collaborative Tagging and Semiotic Dynamics</title><categories>cs.CY cs.DL physics.data-an physics.soc-ph</categories><comments>8 pages, 7 figures</comments><journal-ref>PNAS 104, 1461 (2007)</journal-ref><doi>10.1073/pnas.0610487104</doi><abstract>  Collaborative tagging has been quickly gaining ground because of its ability
to recruit the activity of web users into effectively organizing and sharing
vast amounts of information. Here we collect data from a popular system and
investigate the statistical properties of tag co-occurrence. We introduce a
stochastic model of user behavior embodying two main aspects of collaborative
tagging: (i) a frequency-bias mechanism related to the idea that users are
exposed to each other's tagging activity; (ii) a notion of memory - or aging of
resources - in the form of a heavy-tailed access to the past state of the
system. Remarkably, our simple modeling is able to account quantitatively for
the observed experimental features, with a surprisingly high accuracy. This
points in the direction of a universal behavior of users, who - despite the
complexity of their own cognitive processes and the uncoordinated and selfish
nature of their tagging activity - appear to follow simple activity patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605016</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605016</id><created>2006-05-04</created><authors><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Cooperative Relay Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, July 2005</comments><abstract>  The capacity regions are investigated for two relay broadcast channels
(RBCs), where relay links are incorporated into standard two-user broadcast
channels to support user cooperation. In the first channel, the Partially
Cooperative Relay Broadcast Channel, only one user in the system can act as a
relay and transmit to the other user through a relay link. An achievable rate
region is derived based on the relay using the decode-and-forward scheme. An
outer bound on the capacity region is derived and is shown to be tighter than
the cut-set bound. For the special case where the Partially Cooperative RBC is
degraded, the achievable rate region is shown to be tight and provides the
capacity region. Gaussian Partially Cooperative RBCs and Partially Cooperative
RBCs with feedback are further studied. In the second channel model being
studied in the paper, the Fully Cooperative Relay Broadcast Channel, both users
can act as relay nodes and transmit to each other through relay links. This is
a more general model than the Partially Cooperative RBC. All the results for
Partially Cooperative RBCs are correspondingly generalized to the Fully
Cooperative RBCs. It is further shown that the AWGN Fully Cooperative RBC has a
larger achievable rate region than the AWGN Partially Cooperative RBC. The
results illustrate that relaying and user cooperation are powerful techniques
in improving the capacity of broadcast channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605017</id><created>2006-05-04</created><authors><author><keyname>Tu</keyname><forenames>Phan Huy</forenames></author><author><keyname>Son</keyname><forenames>Tran Cao</forenames></author><author><keyname>Baral</keyname><forenames>Chitta</forenames></author></authors><title>Reasoning and Planning with Sensing Actions, Incomplete Information, and
  Static Causal Laws using Answer Set Programming</title><categories>cs.AI</categories><comments>72 pages, 3 figures, a preliminary version of this paper appeared in
  the proceedings of the 7th International Conference on Logic Programming and
  Non-Monotonic Reasoning, 2004. To appear in Theory and Practice of Logic
  Programming</comments><acm-class>I.2.3; I.2.4; I.2.8</acm-class><abstract>  We extend the 0-approximation of sensing actions and incomplete information
in [Son and Baral 2000] to action theories with static causal laws and prove
its soundness with respect to the possible world semantics. We also show that
the conditional planning problem with respect to this approximation is
NP-complete. We then present an answer set programming based conditional
planner, called ASCP, that is capable of generating both conformant plans and
conditional plans in the presence of sensing actions, incomplete information
about the initial state, and static causal laws. We prove the correctness of
our implementation and argue that our planner is sound and complete with
respect to the proposed approximation. Finally, we present experimental results
comparing ASCP to other planners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605018</id><created>2006-05-04</created><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Sukanto</forenames></author><author><keyname>Khoshnevisan</keyname><forenames>Mohammad</forenames></author><author><keyname>Singh</keyname><forenames>Housila P.</forenames></author><author><keyname>Singh</keyname><forenames>Rajesh</forenames></author><author><keyname>Kaymram</keyname><forenames>F.</forenames></author><author><keyname>Malakar</keyname><forenames>S.</forenames></author><author><keyname>Salmeron</keyname><forenames>Jose L.</forenames></author></authors><title>Computational Modeling in Applied Problems: collected papers on
  econometrics, operations research, game theory and simulation</title><categories>cs.OH</categories><comments>108 pages, many figures</comments><acm-class>I.2.0; I.2.1; C.2.3</acm-class><journal-ref>Hexis, 2006.</journal-ref><abstract>  Computational models pervade all branches of the exact sciences and have in
recent times also started to prove to be of immense utility in some of the
traditionally 'soft' sciences like ecology, sociology and politics. This volume
is a collection of a few cutting-edge research papers on the application of
variety of computational models and tools in the analysis, interpretation and
solution of vexing real-world problems and issues in economics, management,
ecology and global politics by some prolific researchers in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605019</id><created>2006-05-05</created><authors><author><keyname>Chyzak</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Drmota</keyname><forenames>Michael</forenames></author><author><keyname>Klausner</keyname><forenames>Thomas</forenames></author><author><keyname>Kok</keyname><forenames>Gerard</forenames></author></authors><title>The Distribution of Patterns in Random Trees</title><categories>cs.DM math.CO</categories><proxy>ccsd inria-00001281</proxy><abstract>  Let $T\_n$ denote the set of unrooted labeled trees of size $n$ and let
$T\_n$ be a particular (finite, unlabeled) tree. Assuming that every tree of
$T\_n$ is equally likely, it is shown that the limiting distribution as $n$
goes to infinity of the number of occurrences of $M$ as an induced subtree is
asymptotically normal with mean value and variance asymptotically equivalent to
$\mu n$ and $\sigma^2n$, respectively, where the constants $\mu&gt;0$ and
$\sigma\ge 0$ are computable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605020</id><created>2006-05-05</created><authors><author><keyname>Alpaev</keyname><forenames>Sergey</forenames></author></authors><title>Applied MVC Patterns. A pattern language</title><categories>cs.SE</categories><acm-class>D.2.11</acm-class><abstract>  How to get advantages of MVC model without making applications unnecessarily
complex? The full-featured MVC implementation is on the top end of ladder of
complexity. The other end is meant for simple cases that do not call for such
complex designs, however still in need of the advantages of MVC patterns, such
as ability to change the look-and-feel. This paper presents patterns of MVC
implementation that help to benefit from the paradigm and keep the right
balance between flexibility and implementation complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605021</id><created>2006-05-05</created><authors><author><keyname>Zankl</keyname><forenames>Harald</forenames></author></authors><title>SAT Techniques for Lexicographic Path Orders</title><categories>cs.SC</categories><comments>29 pages, Seminar Report</comments><abstract>  This seminar report is concerned with expressing LPO-termination of term
rewrite systems as a satisfiability problem in propositional logic. After
relevant algorithms are explained, experimental results are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605022</id><created>2006-05-05</created><authors><author><keyname>Kurth</keyname><forenames>Martin</forenames></author><author><keyname>LeBlanc</keyname><forenames>Jim</forenames></author></authors><title>Toward a Collection-based Metadata Maintenance Model</title><categories>cs.DL</categories><comments>10 pages, 4 figures; submitted to DC 2006</comments><abstract>  In this paper, the authors identify key entities and relationships in the
operational management of metadata catalogs that describe digital collections,
and they draft a data model to support the administration of metadata
maintenance for collections. Further, they consider this proposed model in
light of other data schemes to which it relates and discuss the implications of
the model for library metadata maintenance operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605023</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605023</id><created>2006-05-06</created><authors><author><keyname>Tekin</keyname><forenames>Ender</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>The Gaussian Multiple Access Wire-Tap Channel with Collective Secrecy
  Constraints</title><categories>cs.IT cs.CR math.IT</categories><comments>International Symposium on Information Theory, 2006. 5 pages</comments><abstract>  We consider the Gaussian Multiple Access Wire-Tap Channel (GMAC-WT). In this
scenario, multiple users communicate with an intended receiver in the presence
of an intelligent and informed wire-tapper who receives a degraded version of
the signal at the receiver. We define a suitable security measure for this
multi-access environment. We derive an outer bound for the rate region such
that secrecy to some pre-determined degree can be maintained. We also find,
using Gaussian codebooks, an achievable such secrecy region. Gaussian codewords
are shown to achieve the sum capacity outer bound, and the achievable region
concides with the outer bound for Gaussian codewords, giving the capacity
region when inputs are constrained to be Gaussian. We present numerical results
showing the new rate region and compare it with that of the Gaussian
Multiple-Access Channel (GMAC) with no secrecy constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605024</id><created>2006-05-06</created><authors><author><keyname>Legg</keyname><forenames>Shane</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>A Formal Measure of Machine Intelligence</title><categories>cs.AI cs.LG</categories><comments>8 two-column pages</comments><report-no>IDSIA-10-06</report-no><journal-ref>Proc. 15th Annual Machine Learning Conference of {B}elgium and The
  Netherlands (Benelearn 2006) pages 73-80</journal-ref><abstract>  A fundamental problem in artificial intelligence is that nobody really knows
what intelligence is. The problem is especially acute when we need to consider
artificial systems which are significantly different to humans. In this paper
we approach this problem in the following way: We take a number of well known
informal definitions of human intelligence that have been given by experts, and
extract their essential features. These are then mathematically formalised to
produce a general measure of intelligence for arbitrary machines. We believe
that this measure formally captures the concept of machine intelligence in the
broadest reasonable sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605025</id><created>2006-05-07</created><authors><author><keyname>Perlibakas</keyname><forenames>Vytautas</forenames></author></authors><title>Face Recognition using Principal Component Analysis and Log-Gabor
  Filters</title><categories>cs.CV</categories><comments>Unpublished manuscript. March 2005. 23 pages, 7 figures, 5 tables</comments><abstract>  In this article we propose a novel face recognition method based on Principal
Component Analysis (PCA) and Log-Gabor filters. The main advantages of the
proposed method are its simple implementation, training, and very high
recognition accuracy. For recognition experiments we used 5151 face images of
1311 persons from different sets of the FERET and AR databases that allow to
analyze how recognition accuracy is affected by the change of facial
expressions, illumination, and aging. Recognition experiments with the FERET
database (containing photographs of 1196 persons) showed that our method can
achieve maximal 97-98% first one recognition rate and 0.3-0.4% Equal Error
Rate. The experiments also showed that the accuracy of our method is less
affected by eye location errors and used image normalization method than of
traditional PCA -based recognition method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605026</id><created>2006-05-07</created><authors><author><keyname>Pritykin</keyname><forenames>Yuri</forenames></author></authors><title>Strongly Almost Periodic Sequences under Finite Automata Mappings</title><categories>cs.DM</categories><comments>7 pages</comments><acm-class>G.2.1; F.1.1</acm-class><abstract>  The notion of almost periodicity nontrivially generalizes the notion of
periodicity. Strongly almost periodic sequences (=uniformly recurrent infinite
words) first appeared in the field of symbolic dynamics, but then turned out to
be interesting in connection with computer science. The paper studies the class
of eventually strongly almost periodic sequences (i. e., becoming strongly
almost periodic after deleting some prefix). We prove that the property of
eventual strong almost periodicity is preserved under the mappings done by
finite automata and finite transducers. The class of almost periodic sequences
includes the class of eventually strongly almost periodic sequences. We prove
this inclusion to be strict.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605027</id><created>2006-05-07</created><authors><author><keyname>Perlibakas</keyname><forenames>Vytautas</forenames></author></authors><title>Recognition of expression variant faces using masked log-Gabor features
  and Principal Component Analysis</title><categories>cs.CV</categories><comments>Unpublished manuscript. June 2005. 20 pages, 8 figures, 5 tables</comments><abstract>  In this article we propose a method for the recognition of faces with
different facial expressions. For recognition we extract feature vectors by
using log-Gabor filters of multiple orientations and scales. Using sliding
window algorithm and variances -based masking these features are extracted at
image regions that are less affected by the changes of facial expressions.
Extracted features are passed to the Principal Component Analysis (PCA) -based
recognition method. The results of face recognition experiments using
expression variant faces showed that the proposed method could achieve higher
recognition accuracy than many other methods. For development and testing we
used facial images from the AR and FERET databases. Using facial photographs of
more than one thousand persons from the FERET database the proposed method
achieved 96.6-98.9% first one recognition rate and 0.2-0.6% Equal Error Rate
(EER).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605028</identifier>
 <datestamp>2008-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605028</id><created>2006-05-07</created><updated>2008-03-31</updated><authors><author><keyname>Tekin</keyname><forenames>Ender</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>The Gaussian Multiple Access Wire-Tap Channel</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  We consider the Gaussian Multiple Access Wire-Tap Channel (GMAC-WT). In this
scenario, multiple users communicate with an intended receiver in the presence
of an intelligent and informed wire-tapper who receives a degraded version of
the signal at the receiver. We define suitable security measures for this
multi-access environment. Using codebooks generated randomly according to a
Gaussian distribution, achievable secrecy rate regions are identified using
superposition coding and TDMA coding schemes. An upper bound for the secrecy
sum-rate is derived, and our coding schemes are shown to achieve the sum
capacity. Numerical results showing the new rate region are presented and
compared with the capacity region of the Gaussian Multiple-Access Channel
(GMAC) with no secrecy constraints, quantifying the price paid for secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605029</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605029</id><created>2006-05-07</created><authors><author><keyname>Furer</keyname><forenames>Martin</forenames></author><author><keyname>Kasiviswanathan</keyname><forenames>Shiva Prasad</forenames></author></authors><title>Spanners for Geometric Intersection Graphs</title><categories>cs.CG</categories><comments>16 pages, 5 figures, Latex</comments><acm-class>F.2.2</acm-class><journal-ref>Journal of Computational Geometry 3(1) (2012) 31-64</journal-ref><abstract>  Efficient algorithms are presented for constructing spanners in geometric
intersection graphs. For a unit ball graph in R^k, a (1+\epsilon)-spanner is
obtained using efficient partitioning of the space into hypercubes and solving
bichromatic closest pair problems. The spanner construction has almost
equivalent complexity to the construction of Euclidean minimum spanning trees.
The results are extended to arbitrary ball graphs with a sub-quadratic running
time.
  For unit ball graphs, the spanners have a small separator decomposition which
can be used to obtain efficient algorithms for approximating proximity problems
like diameter and distance queries. The results on compressed quadtrees,
geometric graph separators, and diameter approximation might be of independent
interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605030</id><created>2006-05-08</created><authors><author><keyname>Cogill</keyname><forenames>Randy</forenames></author><author><keyname>Lall</keyname><forenames>Sanjay</forenames></author></authors><title>A Delay Analysis of Maximal Matching Switching with Speedup</title><categories>cs.NI cs.PF</categories><comments>11 pages, 2 figures. Submitted to the 2006 IEEE Conference on
  Decision and Control</comments><abstract>  In this paper we analyze the average queue backlog in a combined input-output
queued switch using a maximal size matching scheduling algorithm. We compare
this average backlog to the average backlog achieved by an optimal switch. We
model the cell arrival process as independent and identically distributed
between time slots and uniformly distributed among input and output ports. For
switches with many input and output ports, the backlog associated with maximal
size matching with speedup 3 is no more than 10/3 times the backlog associated
with an optimal switch. Moreover, this performance ratio rapidly approaches 2
as speedup increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605031</id><created>2006-05-08</created><authors><author><keyname>Dinsoreanu</keyname><forenames>Mihaela</forenames></author><author><keyname>Salomie</keyname><forenames>Ioan</forenames></author><author><keyname>Pusztai</keyname><forenames>Kalman</forenames></author></authors><title>On the Design of Agent-Based Systems using UML and Extensions</title><categories>cs.AI cs.MA cs.SE</categories><abstract>  The Unified Software Development Process (USDP) and UML have been now
generally accepted as the standard methodology and modeling language for
developing Object-Oriented Systems. Although Agent-based Systems introduces new
issues, we consider that USDP and UML can be used in an extended manner for
modeling Agent-based Systems. The paper presents a methodology for designing
agent-based systems and the specific models expressed in an UML-based notation
corresponding to each phase of the software development process. UML was
extended using the provided mechanism: stereotypes. Therefore, this approach
can be managed with any CASE tool supporting UML. A Case Study, the development
of a specific agent-based Student Evaluation System (SAS), is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605032</id><created>2006-05-08</created><authors><author><keyname>Marian</keyname><forenames>Tudor</forenames></author><author><keyname>Dumitriu</keyname><forenames>Bogdan</forenames></author><author><keyname>Dinsoreanu</keyname><forenames>Mihaela</forenames></author><author><keyname>Salomie</keyname><forenames>Ioan</forenames></author></authors><title>A framework of reusable structures for mobile agent development</title><categories>cs.MA cs.AI cs.SE</categories><abstract>  Mobile agents research is clearly aiming towards imposing agent based
development as the next generation of tools for writing software. This paper
comes with its own contribution to this global goal by introducing a novel
unifying framework meant to bring simplicity and interoperability to and among
agent platforms as we know them today. In addition to this, we also introduce a
set of agent behaviors which, although tailored for and from the area of
virtual learning environments, are none the less generic enough to be used for
rapid, simple, useful and reliable agent deployment. The paper also presents an
illustrative case study brought forward to prove the feasibility of our design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605033</id><created>2006-05-08</created><authors><author><keyname>Dinsoreanu</keyname><forenames>Mihaela</forenames></author><author><keyname>Godja</keyname><forenames>Cristian</forenames></author><author><keyname>Anghel</keyname><forenames>Claudiu</forenames></author><author><keyname>Salomie</keyname><forenames>Ioan</forenames></author><author><keyname>Coffey</keyname><forenames>Tom</forenames></author></authors><title>Mobile Agent Based Solutions for Knowledge Assessment in elearning
  Environments</title><categories>cs.MA cs.AI cs.SE</categories><abstract>  E-learning is nowadays one of the most interesting of the &quot;e- &quot; domains
available through the Internet. The main problem to create a Web-based, virtual
environment is to model the traditional domain and to implement the model using
the most suitable technologies. We analyzed the distance learning domain and
investigated the possibility to implement some e-learning services using mobile
agent technologies. This paper presents a model of the Student Assessment
Service (SAS) and an agent-based framework developed to be used for
implementing specific applications. A specific Student Assessment application
that relies on the framework was developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605034</id><created>2006-05-08</created><authors><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Peer to Peer Networks for Defense Against Internet Worms</title><categories>cs.CR cs.AR cs.NI</categories><comments>11 Pages</comments><abstract>  Internet worms, which spread in computer networks without human mediation,
pose a severe threat to computer systems today. The rate of propagation of
worms has been measured to be extremely high and they can infect a large
fraction of their potential hosts in a short time. We study two different
methods of patch dissemination to combat the spread of worms. We first show
that using a fixed number of patch servers performs woefully inadequately
against Internet worms. We then show that by exploiting the exponential data
dissemination capability of P2P systems, the spread of worms can be halted very
effectively. We compare the two methods by using fluid models to compute two
quantities of interest: the time taken to effectively combat the progress of
the worm and the maximum number of infected hosts. We validate our models using
Internet measurements and simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605035</id><created>2006-05-08</created><authors><author><keyname>Radlinski</keyname><forenames>Filip</forenames></author><author><keyname>Joachims</keyname><forenames>Thorsten</forenames></author></authors><title>Query Chains: Learning to Rank from Implicit Feedback</title><categories>cs.LG cs.IR</categories><comments>10 pages</comments><acm-class>H.3.3</acm-class><journal-ref>Proceedings of the ACM Conference on Knowledge Discovery and Data
  Mining (KDD), ACM, 2005</journal-ref><abstract>  This paper presents a novel approach for using clickthrough data to learn
ranked retrieval functions for web search results. We observe that users
searching the web often perform a sequence, or chain, of queries with a similar
information need. Using query chains, we generate new types of preference
judgments from search engine logs, thus taking advantage of user intelligence
in reformulating queries. To validate our method we perform a controlled user
study comparing generated preference judgments to explicit relevance judgments.
We also implemented a real-world search engine to test our approach, using a
modified ranking SVM to learn an improved ranking function from preference
data. Our results demonstrate significant improvements in the ranking given by
the search engine. The learned rankings outperform both a static ranking
function, as well as one trained without considering query chains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605036</id><created>2006-05-08</created><authors><author><keyname>Radlinski</keyname><forenames>Filip</forenames></author><author><keyname>Joachims</keyname><forenames>Thorsten</forenames></author></authors><title>Evaluating the Robustness of Learning from Implicit Feedback</title><categories>cs.LG cs.IR</categories><comments>8 pages, Presented at ICML Workshop on Learning In Web Search, 2005</comments><acm-class>H.3.3</acm-class><abstract>  This paper evaluates the robustness of learning from implicit feedback in web
search. In particular, we create a model of user behavior by drawing upon user
studies in laboratory and real-world settings. The model is used to understand
the effect of user behavior on the performance of a learning algorithm for
ranked retrieval. We explore a wide range of possible user behaviors and find
that learning from implicit feedback can be surprisingly robust. This
complements previous results that demonstrated our algorithm's effectiveness in
a real-world search engine application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605037</id><created>2006-05-08</created><authors><author><keyname>Radlinski</keyname><forenames>Filip</forenames></author><author><keyname>Joachims</keyname><forenames>Thorsten</forenames></author></authors><title>Minimally Invasive Randomization for Collecting Unbiased Preferences
  from Clickthrough Logs</title><categories>cs.IR cs.LG</categories><comments>7 pages. Proceedings of the 21st National Conference on Artificial
  Intelligence (AAAI), 2006</comments><acm-class>H.3.3</acm-class><abstract>  Clickthrough data is a particularly inexpensive and plentiful resource to
obtain implicit relevance feedback for improving and personalizing search
engines. However, it is well known that the probability of a user clicking on a
result is strongly biased toward documents presented higher in the result set
irrespective of relevance. We introduce a simple method to modify the
presentation of search results that provably gives relevance judgments that are
unaffected by presentation bias under reasonable assumptions. We validate this
property of the training data in interactive real world experiments. Finally,
we show that using these unbiased relevance judgments learning methods can be
guaranteed to converge to an ideal ranking given sufficient data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605038</id><created>2006-05-09</created><authors><author><keyname>Son</keyname><forenames>Tran Cao</forenames></author><author><keyname>Pontelli</keyname><forenames>Enrico</forenames></author><author><keyname>Elkabani</keyname><forenames>Islam</forenames></author></authors><title>An Unfolding-Based Semantics for Logic Programming with Aggregates</title><categories>cs.SE cs.AI</categories><abstract>  The paper presents two equivalent definitions of answer sets for logic
programs with aggregates. These definitions build on the notion of unfolding of
aggregates, and they are aimed at creating methodologies to translate logic
programs with aggregates to normal logic programs or positive programs, whose
answer set semantics can be used to defined the semantics of the original
programs. The first definition provides an alternative view of the semantics
for logic programming with aggregates described by Pelov et al.
  The second definition is similar to the traditional answer set definition for
normal logic programs, in that, given a logic program with aggregates and an
interpretation, the unfolding process produces a positive program. The paper
shows how this definition can be extended to consider aggregates in the head of
the rules.
  The proposed views of logic programming with aggregates are simple and
coincide with the ultimate stable model semantics, and with other semantic
characterizations for large classes of program (e.g., programs with monotone
aggregates and programs that are aggregate-stratified).
  Moreover, it can be directly employed to support an implementation using
available answer set solvers. The paper describes a system, called ASP^A, that
is capable of computing answer sets of programs with arbitrary (e.g.,
recursively defined) aggregates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605039</id><created>2006-05-09</created><updated>2006-05-29</updated><authors><author><keyname>Roy</keyname><forenames>Amitabha</forenames></author><author><keyname>Zeisset</keyname><forenames>Stephan</forenames></author><author><keyname>Fleckenstein</keyname><forenames>Charles J.</forenames></author><author><keyname>Huang</keyname><forenames>John C.</forenames></author></authors><title>Fast and Generalized Polynomial Time Memory Consistency Verification</title><categories>cs.AR cs.LO cs.PF</categories><comments>To appear in the proceedings of Computer Aided Verification (CAV)
  2006</comments><abstract>  The problem of verifying multi-threaded execution against the memory
consistency model of a processor is known to be an NP hard problem. However
polynomial time algorithms exist that detect almost all failures in such
execution. These are often used in practice for microprocessor verification. We
present a low complexity and fully parallelized algorithm to check program
execution against the processor consistency model. In addition our algorithm is
general enough to support a number of consistency models without any
degradation in performance. An implementation of this algorithm is currently
used in practice to verify processors in the post silicon stage for multiple
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605040</id><created>2006-05-09</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>General Discounting versus Average Reward</title><categories>cs.LG</categories><comments>17 pages, 1 table</comments><report-no>IDSIA-11-06</report-no><journal-ref>Proc. 17th International Conf. on Algorithmic Learning Theory (ALT
  2006) pages 244-258</journal-ref><abstract>  Consider an agent interacting with an environment in cycles. In every
interaction cycle the agent is rewarded for its performance. We compare the
average reward U from cycle 1 to m (average value) with the future discounted
reward V from cycle k to infinity (discounted value). We consider essentially
arbitrary (non-geometric) discount sequences and arbitrary reward sequences
(non-MDP environments). We show that asymptotically U for m-&gt;infinity and V for
k-&gt;infinity are equal, provided both limits exist. Further, if the effective
horizon grows linearly with k or faster, then existence of the limit of U
implies that the limit of V exists. Conversely, if the effective horizon grows
linearly with k or slower, then existence of the limit of V implies that the
limit of U exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605041</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605041</id><created>2006-05-09</created><updated>2006-10-03</updated><authors><author><keyname>Cao</keyname><forenames>Jian</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>Asymptotically Optimal Multiple-access Communication via Distributed
  Rate Splitting</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory. 15 Pages</comments><abstract>  We consider the multiple-access communication problem in a distributed
setting for both the additive white Gaussian noise channel and the discrete
memoryless channel. We propose a scheme called Distributed Rate Splitting to
achieve the optimal rates allowed by information theory in a distributed
manner. In this scheme, each real user creates a number of virtual users via a
power/rate splitting mechanism in the M-user Gaussian channel or via a random
switching mechanism in the M-user discrete memoryless channel. At the receiver,
all virtual users are successively decoded. Compared with other multiple-access
techniques, Distributed Rate Splitting can be implemented with lower complexity
and less coordination. Furthermore, in a symmetric setting, we show that the
rate tuple achieved by this scheme converges to the maximum equal rate point
allowed by the information-theoretic bound as the number of virtual users per
real user tends to infinity. When the capacity regions are asymmetric, we show
that a point on the dominant face can be achieved asymptotically. Finally, when
there is an unequal number of virtual users per real user, we show that
differential user rate requirements can be accommodated in a distributed
fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605042</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605042</id><created>2006-05-09</created><updated>2006-05-11</updated><authors><author><keyname>Authors</keyname></author><author><keyname>:</keyname></author><author><keyname>Xi</keyname><forenames>Yufang</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>Throughput Optimal Distributed Control of Stochastic Wireless Networks</title><categories>cs.NI</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn by the author due to the need for further
revision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605043</id><created>2006-05-09</created><authors><author><keyname>Guerrini</keyname><forenames>Stefano</forenames></author><author><keyname>Masini</keyname><forenames>Andrea</forenames></author></authors><title>Continuations, proofs and tests</title><categories>cs.LO cs.PL</categories><comments>32 pages, uses xy-pic</comments><abstract>  Continuation Passing Style (CPS) is one of the most important issues in the
field of functional programming languages, and the quest for a primitive notion
of types for continuation is still open. Starting from the notion of ``test''
proposed by Girard, we develop a notion of test for intuitionistic logic. We
give a complete deductive system for tests and we show that it is good to deal
with ``continuations''. In particular, in the proposed system it is possible to
work with Call by Value and Call by Name translations in a uniform way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605044</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605044</id><created>2006-05-09</created><authors><author><keyname>Schmidt</keyname><forenames>Georg</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir R.</forenames></author></authors><title>Linear Shift-Register Synthesis for Multiple Sequences of Varying Length</title><categories>cs.IT math.IT</categories><abstract>  The problem of finding the shortest linear shift-register capable of
generating t finite length sequences over some field F is considered. A similar
problem was already addressed by Feng and Tzeng. They presented an iterative
algorithm for solving this multi-sequence shift-register synthesis problem,
which can be considered as generalization of the well known Berlekamp-Massey
algorithm. The Feng-Tzeng algorithm works indeed, if all t sequences have the
same length. This paper focuses on multi-sequence shift-register synthesis for
generating sequences of varying length. It is exposed, that the Feng-Tzeng
algorithm does not always give the correct solution in this case. A modified
algorithm is proposed and formally proved, which overcomes this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605045</id><created>2006-05-09</created><authors><author><keyname>Mohan</keyname><forenames>R. N.</forenames></author></authors><title>On Orthogonalities in Matrices</title><categories>cs.DM</categories><abstract>  In this paper we have discussed different possible orthogonalities in
matrices, namely orthogonal, quasi-orthogonal, semi-orthogonal and
non-orthogonal matrices including completely positive matrices, while giving
some of their constructions besides studying some of their properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605046</identifier>
 <datestamp>2007-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605046</id><created>2006-05-10</created><updated>2007-11-13</updated><authors><author><keyname>Shamir</keyname><forenames>Gil I.</forenames></author></authors><title>Patterns of i.i.d. Sequences and Their Entropy - Part I: General Bounds</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  Tight bounds on the block entropy of patterns of sequences generated by
independent and identically distributed (i.i.d.) sources are derived. A pattern
of a sequence is a sequence of integer indices with each index representing the
order of first occurrence of the respective symbol in the original sequence.
Since a pattern is the result of data processing on the original sequence, its
entropy cannot be larger. Bounds derived here describe the pattern entropy as
function of the original i.i.d. source entropy, the alphabet size, the symbol
probabilities, and their arrangement in the probability space. Matching upper
and lower bounds derived provide a useful tool for very accurate approximations
of pattern block entropies for various distributions, and for assessing the
decrease of the pattern entropy from that of the original i.i.d. sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605047</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605047</id><created>2006-05-10</created><updated>2007-07-02</updated><authors><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author><author><keyname>Barron</keyname><forenames>Andrew</forenames></author></authors><title>Generalized Entropy Power Inequalities and Monotonicity Properties of
  Information</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>13 pages. Many minor modifications from first version, plus a section
  on refined results. This is almost but not exactly identical to the published
  version</comments><acm-class>E.4; G.3</acm-class><journal-ref>IEEE Transactions on Information Theory, Vol. 53(7), pp.
  2317-2329, July 2007</journal-ref><abstract>  New families of Fisher information and entropy power inequalities for sums of
independent random variables are presented. These inequalities relate the
information in the sum of $n$ independent random variables to the information
contained in sums over subsets of the random variables, for an arbitrary
collection of subsets. As a consequence, a simple proof of the monotonicity of
information in central limit theorems is obtained, both in the setting of
i.i.d. summands as well as in the more general setting of independent summands
with variance-standardized sums.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605048</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605048</id><created>2006-05-10</created><authors><author><keyname>Roch</keyname><forenames>S.</forenames></author></authors><title>On Learning Thresholds of Parities and Unions of Rectangles in Random
  Walk Models</title><categories>cs.LG cs.CC math.PR</categories><abstract>  In a recent breakthrough, [Bshouty et al., 2005] obtained the first
passive-learning algorithm for DNFs under the uniform distribution. They showed
that DNFs are learnable in the Random Walk and Noise Sensitivity models. We
extend their results in several directions. We first show that thresholds of
parities, a natural class encompassing DNFs, cannot be learned efficiently in
the Noise Sensitivity model using only statistical queries. In contrast, we
show that a cyclic version of the Random Walk model allows to learn efficiently
polynomially weighted thresholds of parities. We also extend the algorithm of
Bshouty et al. to the case of Unions of Rectangles, a natural generalization of
DNFs to $\{0,...,b-1\}^n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605049</id><created>2006-05-11</created><authors><author><keyname>Siddlenikov</keyname><forenames>V. M.</forenames></author><author><keyname>Mohan</keyname><forenames>R. N.</forenames></author><author><keyname>Lee</keyname><forenames>Moon Ho</forenames></author></authors><title>On fractionally linear functions over a finite field</title><categories>cs.DM</categories><abstract>  Abstrct: In this note, by considering fractionally linear functions over a
finite field and consequently developing an abstract sequence, we study some of
its properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605050</id><created>2006-05-11</created><authors><author><keyname>Arvind</keyname><forenames>V.</forenames></author><author><keyname>Kurur</keyname><forenames>Piyush P</forenames></author></authors><title>A Polynomial Time Nilpotence Test for Galois Groups and Related Results</title><categories>cs.CC cs.DS</categories><comments>12 pages</comments><abstract>  We give a deterministic polynomial-time algorithm to check whether the Galois
group $\Gal{f}$ of an input polynomial $f(X) \in \Q[X]$ is nilpotent: the
running time is polynomial in $\size{f}$. Also, we generalize the Landau-Miller
solvability test to an algorithm that tests if $\Gal{f}$ is in $\Gamma_d$: this
algorithm runs in time polynomial in $\size{f}$ and $n^d$ and, moreover, if
$\Gal{f}\in\Gamma_d$ it computes all the prime factors of $# \Gal{f}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605051</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605051</id><created>2006-05-11</created><authors><author><keyname>Cole</keyname><forenames>Chad A.</forenames></author><author><keyname>Wilson</keyname><forenames>Stephen G.</forenames></author><author><keyname>Hall</keyname><forenames>Eric. K.</forenames></author><author><keyname>Giallorenzi</keyname><forenames>Thomas R.</forenames></author></authors><title>A General Method for Finding Low Error Rates of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Submitted Trans. Inf. Theory</comments><abstract>  This paper outlines a three-step procedure for determining the low bit error
rate performance curve of a wide class of LDPC codes of moderate length. The
traditional method to estimate code performance in the higher SNR region is to
use a sum of the contributions of the most dominant error events to the
probability of error. These dominant error events will be both code and decoder
dependent, consisting of low-weight codewords as well as non-codeword events if
ML decoding is not used. For even moderate length codes, it is not feasible to
find all of these dominant error events with a brute force search. The proposed
method provides a convenient way to evaluate very low bit error rate
performance of an LDPC code without requiring knowledge of the complete error
event weight spectrum or resorting to a Monte Carlo simulation. This new method
can be applied to various types of decoding such as the full belief propagation
version of the message passing algorithm or the commonly used min-sum
approximation to belief propagation. The proposed method allows one to
efficiently see error performance at bit error rates that were previously out
of reach of Monte Carlo methods. This result will provide a solid foundation
for the analysis and design of LDPC codes and decoders that are required to
provide a guaranteed very low bit error rate performance at certain SNRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605052</identifier>
 <datestamp>2007-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605052</id><created>2006-05-11</created><updated>2007-09-18</updated><authors><author><keyname>Xi</keyname><forenames>Yufang</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>Node-Based Optimal Power Control, Routing, and Congestion Control in
  Wireless Networks</title><categories>cs.NI</categories><comments>Full paper with 8 figures. Submitted to IEEE Transactions on
  Information Theory</comments><abstract>  We present a unified analytical framework within which power control, rate
allocation, routing, and congestion control for wireless networks can be
optimized in a coherent and integrated manner. We consider a multi-commodity
flow model with an interference-limited physical-layer scheme in which power
control and routing variables are chosen to minimize the sum of convex link
costs reflecting, for instance, queuing delay. Distributed network algorithms
where joint power control and routing are performed on a node-by-node basis are
presented. We show that with appropriately chosen parameters, these algorithms
iteratively converge to the global optimum from any initial point with finite
cost. Next, we study refinements of the algorithms for more accurate link
capacity models, and extend the results to wireless networks where the
physical-layer achievable rate region is given by an arbitrary convex set, and
the link costs are strictly quasiconvex. Finally, we demonstrate that
congestion control can be seamlessly incorporated into our framework, so that
algorithms developed for power control and routing can naturally be extended to
optimize user input rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605053</id><created>2006-05-12</created><authors><author><keyname>Gibbins</keyname><forenames>Hussein</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Gridscape II: A Customisable and Pluggable Grid Monitoring Portal and
  its Integration with Google Maps</title><categories>cs.DC</categories><comments>12 pages</comments><report-no>Technical Report, GRIDS-TR-2006-8, Grid Computing and Distributed
  Systems Laboratory, The University of Melbourne, Australia, May 12, 2006</report-no><acm-class>H.4.3</acm-class><abstract>  Grid computing has emerged as an effective means of facilitating the sharing
of distributed heterogeneous resources, enabling collaboration in large scale
environments. However, the nature of Grid systems, coupled with the
overabundance and fragmentation of information, makes it difficult to monitor
resources, services, and computations in order to plan and make decisions. In
this paper we present Gridscape II, a customisable portal component that can be
used on its own or plugged in to compliment existing Grid portals. Gridscape II
manages the gathering of information from arbitrary, heterogeneous and
distributed sources and presents them together seamlessly within a single
interface. It also leverages the Google Maps API in order to provide a highly
interactive user interface. Gridscape II is simple and easy to use, providing a
solution to those users who do not wish to invest heavily in developing their
own monitoring portal from scratch, and also for those users who want something
that is easy to customise and extend for their specific needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605054</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605054</id><created>2006-05-12</created><updated>2006-10-05</updated><authors><author><keyname>Lamarche</keyname><forenames>Francois</forenames></author><author><keyname>Strassburger</keyname><forenames>Lutz</forenames></author></authors><title>From Proof Nets to the Free *-Autonomous Category</title><categories>cs.LO</categories><comments>LaTeX, 44 pages, final version for LMCS; v2: updated bibliography</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 4 (October 5,
  2006) lmcs:911</journal-ref><doi>10.2168/LMCS-2(4:3)2006</doi><abstract>  In the first part of this paper we present a theory of proof nets for full
multiplicative linear logic, including the two units. It naturally extends the
well-known theory of unit-free multiplicative proof nets. A linking is no
longer a set of axiom links but a tree in which the axiom links are subtrees.
These trees will be identified according to an equivalence relation based on a
simple form of graph rewriting. We show the standard results of
sequentialization and strong normalization of cut elimination. In the second
part of the paper we show that the identifications enforced on proofs are such
that the class of two-conclusion proof nets defines the free *-autonomous
category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605055</id><created>2006-05-12</created><authors><author><keyname>Bellot</keyname><forenames>David</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / Gravir-Imag</affiliation></author><author><keyname>Bessiere</keyname><forenames>Pierre</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / Gravir-Imag</affiliation></author></authors><title>Approximate Discrete Probability Distribution Representation using a
  Multi-Resolution Binary Tree</title><categories>cs.AI</categories><proxy>ccsd ccsd-00068631</proxy><journal-ref>International Conference on Tools for Artificial Intelligence -
  ITCAI 2003, Sacramento, (2003) --</journal-ref><abstract>  Computing and storing probabilities is a hard problem as soon as one has to
deal with complex distributions over multiple random variables. The problem of
efficient representation of probability distributions is central in term of
computational efficiency in the field of probabilistic reasoning. The main
problem arises when dealing with joint probability distributions over a set of
random variables: they are always represented using huge probability arrays. In
this paper, a new method based on binary-tree representation is introduced in
order to store efficiently very large joint distributions. Our approach
approximates any multidimensional joint distributions using an adaptive
discretization of the space. We make the assumption that the lower is the
probability mass of a particular region of feature space, the larger is the
discretization step. This assumption leads to a very optimized representation
in term of time and memory. The other advantages of our approach are the
ability to refine dynamically the distribution every time it is needed leading
to a more accurate representation of the probability distribution and to an
anytime representation of the distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605056</id><created>2006-05-12</created><authors><author><keyname>Yeo</keyname><forenames>Chee Shin</forenames></author><author><keyname>de Assuncao</keyname><forenames>Marcos Dias</forenames></author><author><keyname>Yu</keyname><forenames>Jia</forenames></author><author><keyname>Sulistio</keyname><forenames>Anthony</forenames></author><author><keyname>Venugopal</keyname><forenames>Srikumar</forenames></author><author><keyname>Placek</keyname><forenames>Martin</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Utility Computing and Global Grids</title><categories>cs.DC</categories><comments>23 pages</comments><report-no>Technical Report, GRIDS-TR-2006-7, Grid Computing and Distributed
  Systems Laboratory, The University of Melbourne, Australia, April 13, 2006</report-no><acm-class>C.2.4</acm-class><abstract>  This chapter focuses on the use of Grid technologies to achieve utility
computing. An overview of how Grids can support utility computing is first
presented through the architecture of Utility Grids. Then, utility-based
resource allocation is described in detail at each level of the architecture.
Finally, some industrial solutions for utility computing are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605057</id><created>2006-05-15</created><authors><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>Harwood</keyname><forenames>Aaron</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>SLA-Based Coordinated Superscheduling Scheme and Performance for
  Computational Grids</title><categories>cs.DC</categories><journal-ref>In Proceedings of the 8th IEEE International Conference on Cluster
  Computing (Cluster 2006), IEEE Computer Society Press, September 27 - 30,
  2006, Barcelona, Spain.</journal-ref><abstract>  The Service Level Agreement~(SLA) based grid superscheduling approach
promotes coordinated resource sharing. Superscheduling is facilitated between
administratively and topologically distributed grid sites by grid schedulers
such as Resource brokers. In this work, we present a market-based SLA
coordination mechanism. We based our SLA model on a well known \emph{contract
net protocol}.
  The key advantages of our approach are that it allows:~(i) resource owners to
have finer degree of control over the resource allocation that was previously
not possible through traditional mechanism; and (ii) superschedulers to bid for
SLA contracts in the contract net with focus on completing the job within the
user specified deadline. In this work, we use simulation to show the
effectiveness of our proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605058</identifier>
 <datestamp>2008-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605058</id><created>2006-05-14</created><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>A Monadic, Functional Implementation of Real Numbers</title><categories>cs.NA cs.MS</categories><comments>This paper is to appear in an upcoming issue of Mathematical
  Structures in Computer Science published by Cambridge University Press. For
  more information and the latest source code for Few Digits, see
  &lt;http://r6.ca/FewDigits/&gt;</comments><journal-ref>Russell O'Connor: A monadic, functional implementation of real
  numbers. Mathematical Structures in Computer Science 17(1): 129-159 (2007)</journal-ref><doi>10.1017/S0960129506005871</doi><abstract>  Large scale real number computation is an essential ingredient in several
modern mathematical proofs. Because such lengthy computations cannot be
verified by hand, some mathematicians want to use software proof assistants to
verify the correctness of these proofs. This paper develops a new
implementation of the constructive real numbers and elementary functions for
such proofs by using the monad properties of the completion operation on metric
spaces. Bishop and Bridges's notion of regular sequences is generalized to,
what I call, regular functions which form the completion of any metric space.
Using the monad operations, continuous functions on length spaces (a common
subclass of metric spaces) are created by lifting continuous functions on the
original space. A prototype Haskell implementation has been created. I believe
that this approach yields a real number library that is reasonably efficient
for computation, and still simple enough to easily verify its correctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605059</id><created>2006-05-14</created><authors><author><keyname>Rosengard</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Ursu</keyname><forenames>Marian</forenames></author></authors><title>Ontological Representations of Software Patterns</title><categories>cs.SE cs.AI</categories><comments>7 pages</comments><journal-ref>Proceedings of KES'04, Lecture Notes in Computer Science, vol.
  3215, pp. 31-37, Springer-Verlag, 2004</journal-ref><doi>10.1007/b100916</doi><abstract>  This paper is based on and advocates the trend in software engineering of
extending the use of software patterns as means of structuring solutions to
software development problems (be they motivated by best practice or by company
interests and policies). The paper argues that, on the one hand, this
development requires tools for automatic organisation, retrieval and
explanation of software patterns. On the other hand, that the existence of such
tools itself will facilitate the further development and employment of patterns
in the software development process. The paper analyses existing pattern
representations and concludes that they are inadequate for the kind of
automation intended here. Adopting a standpoint similar to that taken in the
semantic web, the paper proposes that feasible solutions can be built on the
basis of ontological representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605060</identifier>
 <datestamp>2014-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605060</id><created>2006-05-15</created><authors><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>Harwood</keyname><forenames>Aaron</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>A Case for Cooperative and Incentive-Based Coupling of Distributed
  Clusters</title><categories>cs.DC</categories><comments>22 pages, extended version of the conference paper published at IEEE
  Cluster'05, Boston, MA</comments><journal-ref>In Proceedings of the 7th IEEE International Conference on Cluster
  Computing (Cluster 2005), IEEE Computer Society Press, September 27 - 30,
  2005, Boston, Massachusetts, USA.</journal-ref><abstract>  Research interest in Grid computing has grown significantly over the past
five years. Management of distributed resources is one of the key issues in
Grid computing. Central to management of resources is the effectiveness of
resource allocation as it determines the overall utility of the system. The
current approaches to superscheduling in a grid environment are non-coordinated
since application level schedulers or brokers make scheduling decisions
independently of the others in the system. Clearly, this can exacerbate the
load sharing and utilization problems of distributed resources due to
suboptimal schedules that are likely to occur. To overcome these limitations,
we propose a mechanism for coordinated sharing of distributed clusters based on
computational economy. The resulting environment, called
\emph{Grid-Federation}, allows the transparent use of resources from the
federation when local resources are insufficient to meet its users'
requirements. The use of computational economy methodology in coordinating
resource allocation not only facilitates the QoS based scheduling, but also
enhances utility delivered by resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605061</id><created>2006-05-15</created><authors><author><keyname>Pathan</keyname><forenames>Al-Mukaddim Khan</forenames></author><author><keyname>Mottalib</keyname><forenames>Md. Abdul</forenames></author><author><keyname>Zibran</keyname><forenames>Minhaz Fahim</forenames></author></authors><title>An Internet Framework to Bring Coherence between WAP and HTTP Ensuring
  Better Mobile Internet Security</title><categories>cs.NI</categories><comments>8th International Conference on Advanced Communication Technology
  (ICACT 2006)</comments><abstract>  To bring coherence between Wireless Access Protocol (WAP) and Hyper Text
Transfer Protocol (HTTP), in this paper, we have proposed an enhanced Internet
framework, which incorporates a new markup language and a browser compatible
with both of the access control protocols. This Markup Language and the browser
enables co-existence of both Hyper Text Markup Language (HTML) and Wireless
Markup Language (WML) contents in a single source file, whereas the browser
incorporates the ability to hold contents compliant with both HTTP and WAP. The
proposed framework also bridges the security gap that is present in the
existing mobile Internet framework.
  Keywords: WAP, WML, HTTP, HTML, browser, parser, wireless devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605062</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605062</id><created>2006-05-15</created><authors><author><keyname>Pathan</keyname><forenames>Al-Mukaddim Khan</forenames></author><author><keyname>Talukder</keyname><forenames>Md. Golam Shagadul Amin</forenames></author></authors><title>QoSIP: A QoS Aware IP Routing Ptotocol for Multimedia Data</title><categories>cs.NI</categories><comments>8th International Conference of Advanced Communication Technology
  (ICACT 2006)</comments><abstract>  Conventional IP routing protocols are not suitable for multimedia
applications which have very stringent Quality-of-Service (QoS) demands and
they require a connection oriented service. For multimedia applications it is
expected that the router should be able to forward the packet according to the
demand of the packet and it is necessary to find a path that satisfies the
specific demands of a particular application. In order to address these issues,
in this paper, we have presented a QoS aware IP routing protocol where a router
stores information about the QoS parameters and routes the packet accordingly.
  Keywords: IP Routing Protocol, Quality of Service (QoS) parameter, QoSIP,
Selective Flooding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605063</id><created>2006-05-15</created><authors><author><keyname>Anik</keyname><forenames>Asif Ahmed</forenames></author><author><keyname>Pathan</keyname><forenames>Al-Mukaddim Khan</forenames></author></authors><title>An Electronic Payment System to Ensure Cost Effectiveness with Easy
  Security Incorporation for the Developing Countries</title><categories>cs.OH</categories><comments>International Conference on Intelligent Agents, Web Technology and
  Internet Commerce (IAWTIC 2004)</comments><abstract>  With the rapid growth of Information and Communication Technology, Electronic
commerce is now acting as a new means of carrying out business transactions
through electronic means such as Internet environment. To avoid the
complexities associated with the digital cash and electronic cash, consumers
and vendors are looking for credit card payments on the Internet as one
possible time-tested alternative. This gave rise of the on-line payment
processing using a third-party verification; which is not suitable for the
developing countries in most of the cases because of the excessive costs
associated with it for maintenance and establishment of an online third-party
processor. As a remedy of this problem, in this paper, we have proposed a
framework for easy security incorporation in credit card based electronic
payment system without the use of an on-line third- party processor; which
tends to be low cost and effective for the developing countries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605064</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605064</id><created>2006-05-15</created><updated>2006-06-22</updated><authors><author><keyname>Lutz</keyname><forenames>Carsten</forenames></author><author><keyname>Wolter</keyname><forenames>Frank</forenames></author></authors><title>Modal Logics of Topological Relations</title><categories>cs.LO cs.AI cs.CC</categories><acm-class>F.4.1; H.2.8; I.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 2 (June 22,
  2006) lmcs:1228</journal-ref><doi>10.2168/LMCS-2(2:5)2006</doi><abstract>  Logical formalisms for reasoning about relations between spatial regions play
a fundamental role in geographical information systems, spatial and constraint
databases, and spatial reasoning in AI. In analogy with Halpern and Shoham's
modal logic of time intervals based on the Allen relations, we introduce a
family of modal logics equipped with eight modal operators that are interpreted
by the Egenhofer-Franzosa (or RCC8) relations between regions in topological
spaces such as the real plane. We investigate the expressive power and
computational complexity of logics obtained in this way. It turns out that our
modal logics have the same expressive power as the two-variable fragment of
first-order logic, but are exponentially less succinct. The complexity ranges
from (undecidable and) recursively enumerable to highly undecidable, where the
recursively enumerable logics are obtained by considering substructures of
structures induced by topological spaces. As our undecidability results also
capture logics based on the real line, they improve upon undecidability results
for interval temporal logics by Halpern and Shoham. We also analyze modal
logics based on the five RCC5 relations, with similar results regarding the
expressive power, but weaker results regarding the complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605065</id><created>2006-05-15</created><updated>2007-04-08</updated><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author><author><keyname>Hernandez-Quiroz</keyname><forenames>Francisco</forenames></author></authors><title>On the possible Computational Power of the Human Mind</title><categories>cs.NE cs.AI cs.CC</categories><comments>Complexity, Science and Society Conference, 2005, University of
  Liverpool, UK. 23 pages</comments><journal-ref>WORLDVIEWS, SCIENCE AND US, edited by Carlos Gershenson, Diederik
  Aerts and Bruce Edmonds, World Scientific, 2007</journal-ref><abstract>  The aim of this paper is to address the question: Can an artificial neural
network (ANN) model be used as a possible characterization of the power of the
human mind? We will discuss what might be the relationship between such a model
and its natural counterpart. A possible characterization of the different power
capabilities of the mind is suggested in terms of the information contained (in
its computational complexity) or achievable by it. Such characterization takes
advantage of recent results based on natural neural networks (NNN) and the
computational power of arbitrary artificial neural networks (ANN). The possible
acceptance of neural networks as the model of the human mind's operation makes
the aforementioned quite relevant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605066</id><created>2006-05-15</created><updated>2006-05-30</updated><authors><author><keyname>Zhang</keyname><forenames>Xiaowen</forenames></author><author><keyname>Tang</keyname><forenames>Ke</forenames></author><author><keyname>Shu</keyname><forenames>Li</forenames></author></authors><title>A Chaotic Cipher Mmohocc and Its Randomness Evaluation</title><categories>cs.CR</categories><comments>8 pages, 4 figures, and 3 tables, submitted to ICCS06</comments><abstract>  After a brief introduction to a new chaotic stream cipher Mmohocc which
utilizes the fundamental chaos characteristics of mixing, unpredictability, and
sensitivity to initial conditions, we conducted the randomness statistical
tests against the keystreams generated by the cipher. Two batteries of most
stringent randomness tests, namely the NIST Suite and the Diehard Suite, were
performed. The results showed that the keystreams have successfully passed all
the statistical tests. We conclude that Mmohocc can generate high-quality
pseudorandom numbers from a statistical point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605067</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605067</id><created>2006-05-15</created><authors><author><keyname>Lun</keyname><forenames>Desmond S.</forenames></author></authors><title>Efficient Operation of Coded Packet Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>136 pages, 25 figures</comments><journal-ref>Ph.D. dissertation, Massachusetts Institute of Technology, June
  2006</journal-ref><abstract>  A fundamental problem faced in the design of almost all packet networks is
that of efficient operation--of reliably communicating given messages among
nodes at minimum cost in resource usage. We present a solution to the efficient
operation problem for coded packet networks, i.e., packet networks where the
contents of outgoing packets are arbitrary, causal functions of the contents of
received packets. Such networks are in contrast to conventional, routed packet
networks, where outgoing packets are restricted to being copies of received
packets and where reliability is provided by the use of retransmissions.
  This thesis introduces four considerations to coded packet networks: 1.
efficiency, 2. the lack of synchronization in packet networks, 3. the
possibility of broadcast links, and 4. packet loss. We take these
considerations and give a prescription for operation that is novel and general,
yet simple, useful, and extensible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605068</identifier>
 <datestamp>2008-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605068</id><created>2006-05-16</created><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Chyzak</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Cluzeau</keyname><forenames>Thomas</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Low Complexity Algorithms for Linear Recurrences</title><categories>cs.SC</categories><comments>This is the author's version of the work. It is posted here by
  permission of ACM for your personal use. Not for redistribution</comments><proxy>ccsd inria-00068922</proxy><journal-ref>ISSAC'06, pages 31--38, ACM Press, 2006</journal-ref><doi>10.1145/1145768.1145781</doi><abstract>  We consider two kinds of problems: the computation of polynomial and rational
solutions of linear recurrences with coefficients that are polynomials with
integer coefficients; indefinite and definite summation of sequences that are
hypergeometric over the rational numbers. The algorithms for these tasks all
involve as an intermediate quantity an integer $N$ (dispersion or root of an
indicial polynomial) that is potentially exponential in the bit size of their
input. Previous algorithms have a bit complexity that is at least quadratic in
$N$. We revisit them and propose variants that exploit the structure of
solutions and avoid expanding polynomials of degree $N$. We give two
algorithms: a probabilistic one that detects the existence or absence of
nonzero polynomial and rational solutions in $O(\sqrt{N}\log^{2}N)$ bit
operations; a deterministic one that computes a compact representation of the
solution in $O(N\log^{3}N)$ bit operations. Similar speed-ups are obtained in
indefinite and definite hypergeometric summation. We describe the results of an
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605069</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605069</id><created>2006-05-16</created><authors><author><keyname>Yacov</keyname><forenames>Nadav</forenames></author><author><keyname>Efraim</keyname><forenames>Hadar</forenames></author><author><keyname>Kfir</keyname><forenames>Haggai</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author><author><keyname>Shental</keyname><forenames>Ori</forenames></author></authors><title>Parallel vs. Sequential Belief Propagation Decoding of LDPC Codes over
  GF(q) and Markov Sources</title><categories>cs.IT math.IT</categories><doi>10.1016/j.physa.2006.12.009</doi><abstract>  A sequential updating scheme (SUS) for belief propagation (BP) decoding of
LDPC codes over Galois fields, $GF(q)$, and correlated Markov sources is
proposed, and compared with the standard parallel updating scheme (PUS). A
thorough experimental study of various transmission settings indicates that the
convergence rate, in iterations, of the BP algorithm (and subsequently its
complexity) for the SUS is about one half of that for the PUS, independent of
the finite field size $q$. Moreover, this 1/2 factor appears regardless of the
correlations of the source and the channel's noise model, while the error
correction performance remains unchanged. These results may imply on the
'universality' of the one half convergence speed-up of SUS decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605070</id><created>2006-05-16</created><authors><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Broucke</keyname><forenames>Mireille E.</forenames></author><author><keyname>Francis</keyname><forenames>Bruce A.</forenames></author></authors><title>Curve Shortening and the Rendezvous Problem for Mobile Autonomous Robots</title><categories>cs.RO cs.MA</categories><comments>15 pages, 18 figures</comments><acm-class>I.2.9</acm-class><abstract>  If a smooth, closed, and embedded curve is deformed along its normal vector
field at a rate proportional to its curvature, it shrinks to a circular point.
This curve evolution is called Euclidean curve shortening and the result is
known as the Gage-Hamilton-Grayson Theorem. Motivated by the rendezvous problem
for mobile autonomous robots, we address the problem of creating a polygon
shortening flow. A linear scheme is proposed that exhibits several analogues to
Euclidean curve shortening: The polygon shrinks to an elliptical point, convex
polygons remain convex, and the perimeter of the polygon is monotonically
decreasing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605071</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605071</id><created>2006-05-17</created><authors><author><keyname>Wu</keyname><forenames>Wei</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Arapostathis</keyname><forenames>Ari</forenames></author></authors><title>On the Capacity of Interference Channels with Degraded Message sets</title><categories>cs.IT math.IT</categories><abstract>  This paper is motivated by a sensor network on a correlated field where
nearby sensors share information, and can thus assist rather than interfere
with one another. A special class of two-user Gaussian interference channels
(IFCs) is considered where one of the two transmitters knows both the messages
to be conveyed to the two receivers (called the IFC with degraded message
sets). Both achievability and converse arguments are provided for this scenario
for a class of discrete memoryless channels with weak interference. For the
case of the Gaussian weak interference channel with degraded message sets,
optimality of Gaussian inputs is also shown, resulting in the capacity region
of this channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605072</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605072</id><created>2006-05-17</created><authors><author><keyname>Wu</keyname><forenames>Wei</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Arapostathis</keyname><forenames>Ari</forenames></author></authors><title>On the Capacity of Gaussian Weak Interference Channels with Degraded
  Message sets</title><categories>cs.IT math.IT</categories><comments>This paper appears in CISS 2006, Princeton, NJ</comments><abstract>  This paper is motivated by a sensor network on a correlated field where
nearby sensors share information, and can thus assist rather than interfere
with one another. We consider a special class of two-user Gaussian interference
channels (IFCs) where one of the two transmitters knows both the messages to be
conveyed to the two receivers. Both achievability and converse arguments are
provided for a channel with Gaussian inputs and Gaussian noise when the
interference is weaker than the direct link (a so called weak IFC). In general,
this region serves as an outer bound on the capacity of weak IFCs with no
shared knowledge between transmitters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605073</identifier>
 <datestamp>2012-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605073</id><created>2006-05-17</created><authors><author><keyname>Hristopulos</keyname><forenames>Dionissios T.</forenames></author><author><keyname>Elogne</keyname><forenames>Samuel</forenames></author></authors><title>Analytic Properties and Covariance Functions of a New Class of
  Generalized Gibbs Random Fields</title><categories>cs.IT cs.CE math.IT</categories><comments>24 pages; 4 figures Submitted for publication to IEEE Transactions on
  Information Theory</comments><acm-class>J.2; J.3; G.3; I.4.4</acm-class><journal-ref>Information Theory, IEEE Transactions on Volume: 53 , Issue: 12 ,
  4667 - 4679 (2007)</journal-ref><doi>10.1109/TIT.2007.909163</doi><abstract>  Spartan Spatial Random Fields (SSRFs) are generalized Gibbs random fields,
equipped with a coarse-graining kernel that acts as a low-pass filter for the
fluctuations. SSRFs are defined by means of physically motivated spatial
interactions and a small set of free parameters (interaction couplings). This
paper focuses on the FGC-SSRF model, which is defined on the Euclidean space
$\mathbb{R}^{d}$ by means of interactions proportional to the squares of the
field realizations, as well as their gradient and curvature. The permissibility
criteria of FGC-SSRFs are extended by considering the impact of a
finite-bandwidth kernel. It is proved that the FGC-SSRFs are almost surely
differentiable in the case of finite bandwidth. Asymptotic explicit expressions
for the Spartan covariance function are derived for $d=1$ and $d=3$; both known
and new covariance functions are obtained depending on the value of the
FGC-SSRF shape parameter. Nonlinear dependence of the covariance integral scale
on the FGC-SSRF characteristic length is established, and it is shown that the
relation becomes linear asymptotically. The results presented in this paper are
useful in random field parameter inference, as well as in spatial interpolation
of irregularly-spaced samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605074</id><created>2006-05-17</created><authors><author><keyname>Codish</keyname><forenames>Michael</forenames><affiliation>Department of Computer Science, Ben-Gurion University, Israel</affiliation></author><author><keyname>Schneider-Kamp</keyname><forenames>Peter</forenames><affiliation>LuFG Informatik 2, RWTH Aachen, Germany</affiliation></author><author><keyname>Lagoon</keyname><forenames>Vitaly</forenames><affiliation>Department of Computer Science and Software Engineering, University of Melbourne, Australia</affiliation></author><author><keyname>Thiemann</keyname><forenames>Ren&#xe9;</forenames><affiliation>LuFG Informatik 2, RWTH Aachen, Germany</affiliation></author><author><keyname>Giesl</keyname><forenames>J&#xfc;rgen</forenames><affiliation>LuFG Informatik 2, RWTH Aachen, Germany</affiliation></author></authors><title>SAT Solving for Argument Filterings</title><categories>cs.LO</categories><abstract>  This paper introduces a propositional encoding for lexicographic path orders
in connection with dependency pairs. This facilitates the application of SAT
solvers for termination analysis of term rewrite systems based on the
dependency pair method. We address two main inter-related issues and encode
them as satisfiability problems of propositional formulas that can be
efficiently handled by SAT solving: (1) the combined search for a lexicographic
path order together with an \emph{argument filtering} to orient a set of
inequalities; and (2) how the choice of the argument filtering influences the
set of inequalities that have to be oriented. We have implemented our
contributions in the termination prover AProVE. Extensive experiments show that
by our encoding and the application of SAT solvers one obtains speedups in
orders of magnitude as well as increased termination proving power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605075</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605075</id><created>2006-05-17</created><authors><author><keyname>de Ryhove</keyname><forenames>Sebastien de la Kethulle</forenames></author><author><keyname>Marina</keyname><forenames>Ninoslav</forenames></author><author><keyname>Oien</keyname><forenames>Geir E.</forenames></author></authors><title>On the Capacity and Mutual Information of Memoryless Noncoherent
  Rayleigh-Fading Channels</title><categories>cs.IT math.IT</categories><comments>20 pages, 3 figures. Submitted to IEEE Transactions on Information
  Theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  The memoryless noncoherent single-input single-output (SISO) Rayleigh-fading
channel is considered. Closed-form expressions for the mutual information
between the output and the input of this channel when the input magnitude
distribution is discrete and restricted to having two mass points are derived,
and it is subsequently shown how these expressions can be used to obtain
closed-form expressions for the capacity of this channel for signal to noise
ratio (SNR) values of up to approximately 0 dB, and a tight capacity lower
bound for SNR values between 0 dB and 10 dB. The expressions for the channel
capacity and its lower bound are given as functions of a parameter which can be
obtained via numerical root-finding algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605076</id><created>2006-05-17</created><authors><author><keyname>Laros</keyname><forenames>J. F. J.</forenames></author></authors><title>Numeration-automatic sequences</title><categories>cs.CL cs.DM</categories><comments>25 pages, 22 figures</comments><abstract>  We present a base class of automata that induce a numeration system and we
give an algorithm to give the n-th word in the language of the automaton when
the expansion of n in the induced numeration system is feeded to the automaton.
Furthermore we give some algorithms for reverse reading of this expansion and a
way to combine automata to other automata having the same properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605077</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605077</id><created>2006-05-17</created><authors><author><keyname>Moon</keyname><forenames>Taesup</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Universal Filtering via Hidden Markov Modeling</title><categories>cs.IT math.IT</categories><comments>29 pages</comments><abstract>  The problem of discrete universal filtering, in which the components of a
discrete signal emitted by an unknown source and corrupted by a known DMC are
to be causally estimated, is considered. A family of filters are derived, and
are shown to be universally asymptotically optimal in the sense of achieving
the optimum filtering performance when the clean signal is stationary, ergodic,
and satisfies an additional mild positivity condition. Our schemes are
comprised of approximating the noisy signal using a hidden Markov process (HMP)
via maximum-likelihood (ML) estimation, followed by the use of the forward
recursions for HMP state estimation. It is shown that as the data length
increases, and as the number of states in the HMP approximation increases, our
family of filters attain the performance of the optimal distribution-dependent
filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605078</id><created>2006-05-17</created><authors><author><keyname>Baptiste</keyname><forenames>Philippe</forenames></author><author><keyname>Brucker</keyname><forenames>Peter</forenames></author><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Kravchenko</keyname><forenames>Svetlana A.</forenames></author><author><keyname>Sourd</keyname><forenames>Francis</forenames></author></authors><title>The Complexity of Mean Flow Time Scheduling Problems with Release Times</title><categories>cs.DS</categories><comments>Subsumes and replaces cs.DS/0412094 and &quot;Complexity of mean flow time
  scheduling problems with release dates&quot; by P.B, S.K</comments><acm-class>F.2.2</acm-class><abstract>  We study the problem of preemptive scheduling n jobs with given release times
on m identical parallel machines. The objective is to minimize the average flow
time. We show that when all jobs have equal processing times then the problem
can be solved in polynomial time using linear programming. Our algorithm can
also be applied to the open-shop problem with release times and unit processing
times. For the general case (when processing times are arbitrary), we show that
the problem is unary NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605079</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605079</id><created>2006-05-17</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames></author><author><keyname>Wigger</keyname><forenames>Michele</forenames></author></authors><title>On the Capacity of Fading MIMO Broadcast Channels with Imperfect
  Transmitter Side-Information</title><categories>cs.IT math.IT</categories><comments>Extended version of a paper of the same title that appeared in the
  Proceedings of the 43rd Annual Allerton Conference on Communication, Control,
  and Computing, Sept. 28-30, 2005</comments><abstract>  A fading broadcast channel is considered where the transmitter employs two
antennas and each of the two receivers employs a single receive antenna. It is
demonstrated that even if the realization of the fading is precisely known to
the receivers, the high signal-to-noise (SNR) throughput is greatly reduced if,
rather than knowing the fading realization \emph{precisely}, the trasmitter
only knows the fading realization \emph{approximately}. The results are general
and are not limited to memoryless Gaussian fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605080</id><created>2006-05-18</created><authors><author><keyname>Kaafar</keyname><forenames>Mohamed Ali Dali</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Turletti</keyname><forenames>Thierry</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>A Locating-First Approach for Scalable Overlay Multicast</title><categories>cs.NI</categories><proxy>ccsd inria-00069194</proxy><journal-ref>Dans IEEE IWQoS 2006</journal-ref><abstract>  Recent proposals in multicast overlay construction have demonstrated the
importance of exploiting underlying network topology. However, these
topology-aware proposals often rely on incremental and periodic refinements to
improve the system performance. These approaches are therefore neither
scalable, as they induce high communication cost due to refinement overhead,
nor efficient because long convergence time is necessary to obtain a stabilized
structure. In this paper, we propose a highly scalable locating algorithm that
gradually directs newcomers to their a set of their closest nodes without
inducing high overhead. On the basis of this locating process, we build a
robust and scalable topology-aware clustered hierarchical overlay scheme,
called LCC. We conducted both simulations and PlanetLab experiments to evaluate
the performance of LCC. Results show that the locating process entails modest
resources in terms of time and bandwidth. Moreover, LCC demonstrates promising
performance to support large scale multicast applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605081</id><created>2006-05-18</created><authors><author><keyname>Daumas</keyname><forenames>Marc</forenames><affiliation>LP2A, LIRMM</affiliation></author><author><keyname>Da Gra&#xe7;a</keyname><forenames>Guillaume</forenames><affiliation>LP2A</affiliation></author><author><keyname>Defour</keyname><forenames>David</forenames><affiliation>LP2A</affiliation></author></authors><title>Caract\'{e}ristiques arithm\'{e}tiques des processeurs graphiques</title><categories>cs.MS</categories><proxy>ccsd ccsd-00069622</proxy><abstract>  Les unit\'{e}s graphiques (Graphic Processing Units- GPU) sont d\'{e}sormais
des processeurs puissants et flexibles. Les derni\`{e}res g\'{e}n\'{e}rations
de GPU contiennent des unit\'{e}s programmables de traitement des sommets
(vertex shader) et des pixels (pixel shader) supportant des op\'{e}rations en
virgule flottante sur 8, 16 ou 32 bits. La repr\'{e}sentation flottante sur 32
bits correspond \`{a} la simple pr\'{e}cision de la norme IEEE sur
l'arithm\'{e}tique en virgule flottante (IEEE-754). Les GPU sont bien
adapt\'{e}s aux applications avec un fort parall\'{e}lisme de donn\'{e}es.
Cependant ils ne sont que peu utilis\'{e}s en dehors des calculs graphiques
(General Purpose computation on GPU -- GPGPU). Une des raisons de cet \'{e}tat
de faits est la pauvret\'{e} des documentations techniques fournies par les
fabricants (ATI et Nvidia), particuli\`{e}rement en ce qui concerne
l'implantation des diff\'{e}rents op\'{e}rateurs arithm\'{e}tiques
embarqu\'{e}s dans les diff\'{e}rentes unit\'{e}s de traitement. Or ces
informations sont essentielles pour estimer et contr\^{o}ler les erreurs
d'arrondi ou pour mettre en oeuvre des techniques de r\'{e}duction ou de
compensation afin de travailler en pr\'{e}cision double, quadruple ou
arbitrairement \'{e}tendue. Nous proposons dans cet article un ensemble de
programmes qui permettent de d\'{e}couvrir les caract\'{e}ristiques principales
des GPU en ce qui concerne l'arithm\'{e}tique \`{a} virgule flottante. Nous
donnons les r\'{e}sultats obtenus sur deux cartes graphiques r\'{e}centes: la
Nvidia 7800GTX et l'ATI RX1800XL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605082</id><created>2006-05-18</created><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author></authors><title>Efficient algorithm for computing the Euler-Poincar\'e characteristic of
  a semi-algebraic set defined by few quadratic inequalities</title><categories>cs.SC cs.CG</categories><comments>17 pages, accepted for publication in Computational Complexity</comments><abstract>  We present an algorithm which takes as input a closed semi-algebraic set, $S
\subset \R^k$, defined by \[ P_1 \leq 0, ..., P_\ell \leq 0, P_i \in
\R[X_1,...,X_k], \deg(P_i) \leq 2, \] and computes the Euler-Poincar\'e
characteristic of $S$. The complexity of the algorithm is $k^{O(\ell)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605083</id><created>2006-05-18</created><authors><author><keyname>Basuchowdhuri</keyname><forenames>Partha</forenames></author></authors><title>Classical Authentication Aided Three-Stage Quantum Protocol</title><categories>cs.CR</categories><comments>7 pages, 3 figures</comments><abstract>  This paper modifies Kak's three-stage protocol so that it can guarantee
secure transmission of information. Although avoiding man-in-the-middle attack
is our primary objective in the introduction of classical authentication inside
the three-stage protocol, we also benefit from the inherent advantages of the
chosen classical authentication protocol. We have tried to implement ideas like
key distribution center, session key, time-stamp, and nonce, within the quantum
cryptography protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605084</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605084</id><created>2006-05-19</created><authors><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>The Generalized Multiple Access Channel with Confidential Messages</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the 2006 IEEE International Symposium
  on Information Theory, Seattle, WA, July 9 - 14, 2006</comments><abstract>  A discrete memoryless generalized multiple access channel (GMAC) with
confidential messages is studied, where two users attempt to transmit common
information to a destination and each user also has private (confidential)
information intended for the destination. This channel generalizes the multiple
access channel (MAC) in that the two users also receive channel outputs. It is
assumed that each user views the other user as a wire-tapper, and wishes to
keep its confidential information as secret as possible from the other user.
The level of secrecy of the confidential information is measured by the
equivocation rate. The performance measure of interest is the rate-equivocation
tuple that includes the common rate, two private rates and two equivocation
rates as components. The set that includes all achievable rate-equivocation
tuples is referred to as the capacity-equivocation region. For the GMAC with
one confidential message set, where only one user (user 1) has private
(confidential) information for the destination, inner and outer bounds on the
capacity-equivocation region are derived. The secrecy capacity region is
established, which is the set of all achievable rates with user 2 being
perfectly ignorant of confidential messages of user 1. Furthermore, the
capacity-equivocation region and the secrecy capacity region are established
for the degraded GMAC with one confidential message set. For the GMAC with two
confidential message sets, where both users have confidential messages for the
destination, inner bounds on the capacity-equivocation region and the secrecy
capacity region are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605085</id><created>2006-05-19</created><updated>2006-05-28</updated><authors><author><keyname>Dershowitz</keyname><forenames>Nachum</forenames></author><author><keyname>Hanna</keyname><forenames>Ziyad</forenames></author><author><keyname>Nadel</keyname><forenames>Alexander</forenames></author></authors><title>A Scalable Algorithm for Minimal Unsatisfiable Core Extraction</title><categories>cs.LO</categories><abstract>  We propose a new algorithm for minimal unsatisfiable core extraction, based
on a deeper exploration of resolution-refutation properties. We provide
experimental results on formal verification benchmarks confirming that our
algorithm finds smaller cores than suboptimal algorithms; and that it runs
faster than those algorithms that guarantee minimality of the core.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605086</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605086</id><created>2006-05-19</created><authors><author><keyname>Wang</keyname><forenames>Chih-Chun</forenames><affiliation>Purdue University</affiliation></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Princeton University</affiliation></author></authors><title>Upper Bounding the Performance of Arbitrary Finite LDPC Codes on Binary
  Erasure Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the 2006 IEEE International Symposium
  on Information Theory, Seattle, WA, July 9 - 14, 2006</comments><abstract>  Assuming iterative decoding for binary erasure channels (BECs), a novel
tree-based technique for upper bounding the bit error rates (BERs) of
arbitrary, finite low-density parity-check (LDPC) codes is provided and the
resulting bound can be evaluated for all operating erasure probabilities,
including both the waterfall and the error floor regions. This upper bound can
also be viewed as a narrowing search of stopping sets, which is an approach
different from the stopping set enumeration used for lower bounding the error
floor. When combined with optimal leaf-finding modules, this upper bound is
guaranteed to be tight in terms of the asymptotic order. The Boolean framework
proposed herein further admits a composite search for even tighter results. For
comparison, a refinement of the algorithm is capable of exhausting all stopping
sets of size &lt;14 for irregular LDPC codes of length n=500, which requires
approximately 1.67*10^25 trials if a brute force approach is taken. These
experiments indicate that this upper bound can be used both as an analytical
tool and as a deterministic worst-performance (error floor) guarantee, the
latter of which is crucial to optimizing LDPC codes for extremely low BER
applications, e.g., optical/satellite communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605087</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605087</id><created>2006-05-19</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Error Exponents and Cutoff Rate for Noncoherent Rician Fading Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE International Conference on Communications,
  2006</comments><abstract>  In this paper, random coding error exponents and cutoff rate are studied for
noncoherent Rician fading channels, where neither the receiver nor the
transmitter has channel side information. First, it is assumed that the input
is subject only to an average power constraint. In this case, a lower bound to
the random coding error exponent is considered and the optimal input achieving
this lower bound is shown to have a discrete amplitude and uniform phase. If
the input is subject to both average and peak power constraints, it is proven
that the optimal input achieving the random coding error exponent has again a
discrete nature. Finally, the cutoff rate is analyzed, and the optimality of
the single-mass input amplitude distribution in the low-power regime is
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605088</id><created>2006-05-19</created><authors><author><keyname>Liu</keyname><forenames>Ke</forenames></author><author><keyname>Majeed</keyname><forenames>Adnan</forenames></author><author><keyname>Abu-Ghazaleh</keyname><forenames>Nael B.</forenames></author></authors><title>TARMAC: Traffic-Analysis Reslient MAC Protocol for Multi-Hop Wireless
  Networks</title><categories>cs.NI cs.CR</categories><abstract>  Traffic analysis in Multi-hop Wireless Networks can expose the structure of
the network allowing attackers to focus their efforts on critical nodes. For
example, jamming the only data sink in a sensor network can cripple the
network. We propose a new communication protocol that is part of the MAC layer,
but resides conceptually between the routing layer and MAC, that is resilient
to traffic analysis. Each node broadcasts the data that it has to transmit
according to a fixed transmission schedule that is independent of the traffic
being generated, making the network immune to time correlation analysis. The
transmission pattern is identical, with the exception of a possible time shift,
at all nodes, removing spatial correlation of transmissions to network
strucutre. Data for all neighbors resides in the same encrypted packet. Each
neighbor then decides which subset of the data in a packet to forward onwards
using a routing protocol whose details are orthogonal to the proposed scheme.
We analyze the basic scheme, exploring the tradeoffs in terms of frequency of
transmission and packet size. We also explore adaptive and time changing
patterns and analyze their performance under a number of representative
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605089</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605089</id><created>2006-05-20</created><authors><author><keyname>Liu</keyname><forenames>Ke</forenames></author><author><keyname>Abu-Ghazaleh</keyname><forenames>Nael</forenames></author></authors><title>Aligned Virtual Coordinates for Greedy Routing in WSNs</title><categories>cs.NI</categories><journal-ref>MASS 2006</journal-ref><abstract>  Geographic routing provides relatively good performance at a much lower
overhead than conventional routing protocols such as AODV. However, the
performance of these protocols is impacted by physical voids, and localization
errors. Accordingly, virtual coordinate systems (VCS) were proposed as an
alternative approach that is resilient to localization errors and that
naturally routes around physical voids. However, we show that VCS is vulnerable
to different forms of the void problem and the performance of greedy routing on
VCS is worse than that of geographic forwarding. We show that these anomalies
are due to the integral nature of VCS, which causes quantization noise in the
estimate of connectivity and node location. We propose an aligned virtual
coordinate system (AVCS) on which the greedy routing success can be
significantly improved. With our approach, and for the first time, we show that
greedy routing on VCS out-performs that on physical coordinate systems even in
the absence of localization errors. We compare AVCS against some of the most
popular geographical routing protocols both on physical coordinate system and
the virtual coordinate systems and show that AVCS significantly improves
performance over the best known solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605090</identifier>
 <datestamp>2015-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605090</id><created>2006-05-20</created><updated>2015-10-28</updated><authors><author><keyname>Maiti</keyname><forenames>Santanu K.</forenames></author></authors><title>Mathematica: A System of Computer Programs</title><categories>cs.MS cs.PL</categories><comments>17 pages, 4 figures. arXiv admin note: substantial text overlap with
  arXiv:cs/0603005, arXiv:cs/0604088</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting from the basic level of mathematica here we illustrate how to use a
mathematica notebook and write a program in the notebook. Next, we investigate
elaborately the way of linking of external programs with mathematica, so-called
the mathlink operation. Using this technique we can run very tedious jobs quite
efficiently, and the operations become extremely fast. Sometimes it is quite
desirable to run jobs in background of a computer which can take considerable
amount of time to finish, and this allows us to do work on other tasks, while
keeping the jobs running. The way of running jobs, written in a mathematica
notebook, in background is quite different from the conventional methods i.e.,
the techniques for the programs written in other languages like C, C++, F77,
F90, F95, etc. To illustrate it, in the present article we study how to create
a mathematica batch-file from a mathematica notebook and run it in the
background. Finally, we explore the most significant issue of this article.
Here we describe the basic ideas for parallelizing a mathematica program by
sharing its independent parts into all other remote computers available in the
network. Doing the parallelization, we can perform large computational
operations within a very short period of time, and therefore, the efficiency of
the numerical works can be achieved. Parallel computation supports any version
of mathematica and it also works significantly well even if different versions
of mathematica are installed in different computers. All the operations studied
in this article run under any supported operating system like Unix, Windows,
Macintosh, etc. For the sake of our illustrations, here we concentrate all the
discussions only for the Unix based operating system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605091</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605091</id><created>2006-05-21</created><authors><author><keyname>Martinian</keyname><forenames>Emin</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Low-density constructions can achieve the Wyner-Ziv and Gelfand-Pinsker
  bounds</title><categories>cs.IT math.IT</categories><comments>To appear at International Symposium on Information Theory, Seattle,
  WA. July 2006</comments><abstract>  We describe and analyze sparse graphical code constructions for the problems
of source coding with decoder side information (the Wyner-Ziv problem), and
channel coding with encoder side information (the Gelfand-Pinsker problem). Our
approach relies on a combination of low-density parity check (LDPC) codes and
low-density generator matrix (LDGM) codes, and produces sparse constructions
that are simultaneously good as both source and channel codes. In particular,
we prove that under maximum likelihood encoding/decoding, there exist
low-density codes (i.e., with finite degrees) from our constructions that can
saturate both the Wyner-Ziv and Gelfand-Pinsker bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605092</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605092</id><created>2006-05-22</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>The Multiple Access Channel with Feedback and Correlated Sources</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2006 IEEE International Symposium on Information
  Theory (ISIT 2006), The Westin Seattle, Seattle, Washington, July 9-14 2006</comments><journal-ref>Proceedings of the 2006 IEEE International Symposium on
  Information Theory (ISIT 2006), The Westin Seattle, Seattle, WA, pp.
  2129-2133, Jul. 9-14 2006.</journal-ref><doi>10.1109/ISIT.2006.261927</doi><abstract>  In this paper, we investigate communication strategies for the multiple
access channel with feedback and correlated sources (MACFCS). The MACFCS models
a wireless sensor network scenario in which sensors distributed throughout an
arbitrary random field collect correlated measurements and transmit them to a
common sink. We derive achievable rate regions for the three-node MACFCS.
First, we study the strategy when source coding and channel coding are
combined, which we term full decoding at sources. Second, we look at several
strategies when source coding and channel coding are separated, which we term
full decoding at destination. From numerical computations on Gaussian channels,
we see that different strategies perform better under certain source
correlations and channel setups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605093</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605093</id><created>2006-05-22</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>The Capacity of the Single Source Multiple Relay Single Destination Mesh
  Network</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2006 IEEE International Symposium on Information
  Theory (ISIT 2006), The Westin Seattle, Seattle, Washington, July 9-14 2006</comments><journal-ref>Proceedings of the 2006 IEEE International Symposium on
  Information Theory (ISIT 2006), The Westin Seattle, Seattle, WA, pp.
  1673-1677, Jul. 9-14 2006.</journal-ref><doi>10.1109/ISIT.2006.261639</doi><abstract>  In this paper, we derive the capacity of a special class of mesh networks. A
mesh network is defined as a heterogeneous wireless network in which the
transmission among power limited nodes is assisted by powerful relays, which
use the same wireless medium. We find the capacity of the mesh network when
there is one source, one destination, and multiple relays. We call this channel
the single source multiple relay single destination (SSMRSD) mesh network. Our
approach is as follows. We first look at an upper bound on the information
theoretic capacity of these networks in the Gaussian setting. We then show that
the bound is achievable asymptotically using the compress-forward strategy for
the multiple relay channel. Theoretically, the results indicate the value of
cooperation and the utility of carefully deployed relays in wireless ad-hoc and
sensor networks. The capacity characterization quantifies how the relays can be
used to either conserve node energy or to increase transmission rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605094</id><created>2006-05-22</created><authors><author><keyname>Bova</keyname><forenames>S.</forenames><affiliation>University of Siena, Italy</affiliation></author><author><keyname>Montagna</keyname><forenames>F.</forenames><affiliation>University of Siena, Italy</affiliation></author></authors><title>Proof Search in Hajek's Basic Logic</title><categories>cs.LO cs.CC</categories><comments>26 pages</comments><acm-class>F.4.1</acm-class><abstract>  We introduce a proof system for Hajek's logic BL based on a relational
hypersequents framework. We prove that the rules of our logical calculus,
called RHBL, are sound and invertible with respect to any valuation of BL into
a suitable algebra, called omega[0,1]. Refining the notion of reduction tree
that arises naturally from RHBL, we obtain a decision algorithm for BL
provability whose running time upper bound is 2^O(n), where n is the number of
connectives of the input formula. Moreover, if a formula is unprovable, we
exploit the constructiveness of a polynomial time algorithm for leaves validity
for providing a procedure to build countermodels in omega[0,1]. Finally, since
the size of the reduction tree branches is O(n^3), we can describe a polynomial
time verification algorithm for BL unprovability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605095</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605095</id><created>2006-05-22</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Tjhung</keyname><forenames>Tjeng Thiang</forenames></author></authors><title>Single-Symbol-Decodable Differential Space-Time Modulation Based on
  QO-STBC</title><categories>cs.IT math.IT</categories><comments>Accepted for IEEE Trans Wireless Comms</comments><abstract>  We present a novel differential space-time modulation (DSTM) scheme that is
single-symbol decodable and can provide full transmit diversity. It is the
first known singlesymbol- decodable DSTM scheme not based on Orthogonal STBC
(O-STBC), and it is constructed based on the recently proposed
Minimum-Decoding-Complexity Quasi-Orthogonal Space-Time Block Code
(MDC-QOSTBC). We derive the code design criteria and present systematic
methodology to find the solution sets. The proposed DSTM scheme can provide
higher code rate than DSTM schemes based on O-STBC. Its decoding complexity is
also considerably lower than DSTM schemes based on Sp(2) and
double-symbol-decodable QOSTBC, with negligible or slight trade-off in decoding
error probability performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605096</id><created>2006-05-22</created><authors><author><keyname>Dieudonn&#xe9;</keyname><forenames>Yoann</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LaRIA</affiliation></author></authors><title>Circle Formation of Weak Robots and Lyndon Words</title><categories>cs.DC cs.RO</categories><comments>13 pages</comments><proxy>ccsd ccsd-00069724</proxy><report-no>LaRIA-2006-05</report-no><acm-class>C.2.4</acm-class><abstract>  A Lyndon word is a non-empty word strictly smaller in the lexicographic order
than any of its suffixes, except itself and the empty word. In this paper, we
show how Lyndon words can be used in the distributed control of a set of n weak
mobile robots. By weak, we mean that the robots are anonymous, memoryless,
without any common sense of direction, and unable to communicate in an other
way than observation. An efficient and simple deterministic protocol to form a
regular n-gon is presented and proven for n prime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605097</id><created>2006-05-22</created><authors><author><keyname>van Dijk</keyname><forenames>Marten</forenames></author><author><keyname>Torlak</keyname><forenames>Emina</forenames></author><author><keyname>Gassend</keyname><forenames>Blaise</forenames></author><author><keyname>Devadas</keyname><forenames>Srinivas</forenames></author></authors><title>A Generalized Two-Phase Analysis of Knowledge Flows in Security
  Protocols</title><categories>cs.CR</categories><comments>16 pages</comments><abstract>  We introduce knowledge flow analysis, a simple and flexible formalism for
checking cryptographic protocols. Knowledge flows provide a uniform language
for expressing the actions of principals, assump- tions about intruders, and
the properties of cryptographic primitives. Our approach enables a generalized
two-phase analysis: we extend the two-phase theory by identifying the necessary
and sufficient proper- ties of a broad class of cryptographic primitives for
which the theory holds. We also contribute a library of standard primitives and
show that they satisfy our criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605098</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605098</id><created>2006-05-22</created><authors><author><keyname>Betz</keyname><forenames>Sharon</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Energy Efficiency in Multi-hop CDMA Networks: A Game Theoretic Analysis</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the Workshop on Multi-Layer Modelling
  and Design of Multi-Hop Wireless Networks (MLMD 06), Minneapolis, MN, July 12
  - 15, 2006</comments><abstract>  A game-theoretic analysis is used to study the effects of receiver choice on
the energy efficiency of multi-hop networks in which the nodes communicate
using Direct-Sequence Code Division Multiple Access (DS-CDMA). A Nash
equilibrium of the game in which the network nodes can choose their receivers
as well as their transmit powers to maximize the total number of bits they
transmit per unit of energy is derived. The energy efficiencies resulting from
the use of different linear multiuser receivers in this context are compared,
looking at both the non-cooperative game and the Pareto optimal solution. For
analytical ease, particular attention is paid to asymptotically large networks.
Significant gains in energy efficiency are observed when multiuser receivers,
particularly the linear minimum mean-square error (MMSE) receiver, are used
instead of conventional matched filter receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605099</identifier>
 <datestamp>2009-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605099</id><created>2006-05-23</created><updated>2009-03-27</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Alphabetic Coding with Exponential Costs</title><categories>cs.IT cs.DS math.IT</categories><comments>7 pages, submitted to Elsevier</comments><acm-class>E.4; H.1.1; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An alphabetic binary tree formulation applies to problems in which an outcome
needs to be determined via alphabetically ordered search prior to the
termination of some window of opportunity. Rather than finding a decision tree
minimizing $\sum_{i=1}^n w(i) l(i)$, this variant involves minimizing $\log_a
\sum_{i=1}^n w(i) a^{l(i)}$ for a given $a \in (0,1)$. This note introduces a
dynamic programming algorithm that finds the optimal solution in polynomial
time and space, and shows that methods traditionally used to improve the speed
of optimizations in related problems, such as the Hu-Tucker procedure, fail for
this problem. This note thus also introduces two approximation algorithms which
can find a suboptimal solution in linear time (for one) or $\order(n \log n)$
time (for the other), with associated coding redundancy bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605100</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605100</id><created>2006-05-23</created><authors><author><keyname>Rabbat</keyname><forenames>Michael</forenames></author><author><keyname>Figueiredo</keyname><forenames>Mario</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>Network Inference from Co-Occurrences</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. An extended
  version is available as University of Wisconsin Technical Report ECE-06-2</comments><abstract>  The recovery of network structure from experimental data is a basic and
fundamental problem. Unfortunately, experimental data often do not directly
reveal structure due to inherent limitations such as imprecision in timing or
other observation mechanisms. We consider the problem of inferring network
structure in the form of a directed graph from co-occurrence observations. Each
observation arises from a transmission made over the network and indicates
which vertices carry the transmission without explicitly conveying their order
in the path. Without order information, there are an exponential number of
feasible graphs which agree with the observed data equally well. Yet, the basic
physical principles underlying most networks strongly suggest that all feasible
graphs are not equally likely. In particular, vertices that co-occur in many
observations are probably closely connected. Previous approaches to this
problem are based on ad hoc heuristics. We model the experimental observations
as independent realizations of a random walk on the underlying graph, subjected
to a random permutation which accounts for the lack of order information.
Treating the permutations as missing data, we derive an exact
expectation-maximization (EM) algorithm for estimating the random walk
parameters. For long transmission paths the exact E-step may be computationally
intractable, so we also describe an efficient Monte Carlo EM (MCEM) algorithm
and derive conditions which ensure convergence of the MCEM algorithm with high
probability. Simulations and experiments with Internet measurements demonstrate
the promise of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605101</id><created>2006-05-23</created><authors><author><keyname>Kryssanov</keyname><forenames>Victor V.</forenames></author><author><keyname>Rinaldo</keyname><forenames>Frank J.</forenames></author><author><keyname>Kuleshov</keyname><forenames>Evgeny L.</forenames></author><author><keyname>Ogawa</keyname><forenames>Hitoshi</forenames></author></authors><title>Modeling the Dynamics of Social Networks</title><categories>cs.CY cs.CE cs.CL cs.HC cs.NI physics.data-an</categories><comments>8 pages, 3 figures. Preprint (as of May 24, 2006)</comments><abstract>  Modeling human dynamics responsible for the formation and evolution of the
so-called social networks - structures comprised of individuals or
organizations and indicating connectivities existing in a community - is a
topic recently attracting a significant research interest. It has been claimed
that these dynamics are scale-free in many practically important cases, such as
impersonal and personal communication, auctioning in a market, accessing sites
on the WWW, etc., and that human response times thus conform to the power law.
While a certain amount of progress has recently been achieved in predicting the
general response rate of a human population, existing formal theories of human
behavior can hardly be found satisfactory to accommodate and comprehensively
explain the scaling observed in social networks. In the presented study, a
novel system-theoretic modeling approach is proposed and successfully applied
to determine important characteristics of a communication network and to
analyze consumer behavior on the WWW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605102</id><created>2006-05-23</created><authors><author><keyname>Buchsbaum</keyname><forenames>Adam L.</forenames></author><author><keyname>Efrat</keyname><forenames>Alon</forenames></author><author><keyname>Jain</keyname><forenames>Shaili</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author><author><keyname>Yi</keyname><forenames>Ke</forenames></author></authors><title>Restricted Strip Covering and the Sensor Cover Problem</title><categories>cs.DS cs.CG</categories><comments>14 pages, 6 figures</comments><abstract>  Given a set of objects with durations (jobs) that cover a base region, can we
schedule the jobs to maximize the duration the original region remains covered?
We call this problem the sensor cover problem. This problem arises in the
context of covering a region with sensors. For example, suppose you wish to
monitor activity along a fence by sensors placed at various fixed locations.
Each sensor has a range and limited battery life. The problem is to schedule
when to turn on the sensors so that the fence is fully monitored for as long as
possible. This one dimensional problem involves intervals on the real line.
Associating a duration to each yields a set of rectangles in space and time,
each specified by a pair of fixed horizontal endpoints and a height. The
objective is to assign a position to each rectangle to maximize the height at
which the spanning interval is fully covered. We call this one dimensional
problem restricted strip covering. If we replace the covering constraint by a
packing constraint, the problem is identical to dynamic storage allocation, a
scheduling problem that is a restricted case of the strip packing problem. We
show that the restricted strip covering problem is NP-hard and present an O(log
log n)-approximation algorithm. We present better approximations or exact
algorithms for some special cases. For the uniform-duration case of restricted
strip covering we give a polynomial-time, exact algorithm but prove that the
uniform-duration case for higher-dimensional regions is NP-hard. Finally, we
consider regions that are arbitrary sets, and we present an O(log
n)-approximation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605103</id><created>2006-05-24</created><updated>2007-04-28</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>A Better Alternative to Piecewise Linear Time Series Segmentation</title><categories>cs.DB cs.CV</categories><comments>to appear in SIAM Data Mining 2007</comments><acm-class>H.2.8</acm-class><abstract>  Time series are difficult to monitor, summarize and predict. Segmentation
organizes time series into few intervals having uniform characteristics
(flatness, linearity, modality, monotonicity and so on). For scalability, we
require fast linear time algorithms. The popular piecewise linear model can
determine where the data goes up or down and at what rate. Unfortunately, when
the data does not follow a linear model, the computation of the local slope
creates overfitting. We propose an adaptive time series model where the
polynomial degree of each interval vary (constant, linear and so on). Given a
number of regressors, the cost of each interval is its polynomial degree:
constant intervals cost 1 regressor, linear intervals cost 2 regressors, and so
on. Our goal is to minimize the Euclidean (l_2) error for a given model
complexity. Experimentally, we investigate the model where intervals can be
either constant or linear. Over synthetic random walks, historical stock market
prices, and electrocardiograms, the adaptive model provides a more accurate
segmentation than the piecewise linear model without increasing the
cross-validation error or the running time, while providing a richer vocabulary
to applications. Implementation issues, such as numerical stability and
real-world performance, are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605104</id><created>2006-05-24</created><updated>2006-07-26</updated><authors><author><keyname>Hegerle</keyname><forenames>Blake</forenames></author></authors><title>Parsing Transformative LR(1) Languages</title><categories>cs.PL</categories><comments>68 pages, 4 figures. Numerous stylistic and grammatical fixes; new
  material in Sections 2.2 and 4.2</comments><acm-class>D.3.2; D.3.4; F.4.2; F.4.3</acm-class><abstract>  We consider, as a means of making programming languages more flexible and
powerful, a parsing algorithm in which the parser may freely modify the grammar
while parsing. We are particularly interested in a modification of the
canonical LR(1) parsing algorithm in which, after the reduction of certain
productions, we examine the source sentence seen so far to determine the
grammar to use to continue parsing. A naive modification of the canonical LR(1)
parsing algorithm along these lines cannot be guaranteed to halt; as a result,
we develop a test which examines the grammar as it changes, stopping the parse
if the grammar changes in a way that would invalidate earlier assumptions made
by the parser. With this test in hand, we can develop our parsing algorithm and
prove that it is correct. That being done, we turn to earlier, related work;
the idea of programming languages which can be extended to include new
syntactic constructs has existed almost as long as the idea of high-level
programming languages. Early efforts to construct such a programming language
were hampered by an immature theory of formal languages. More recent efforts to
construct transformative languages relied either on an inefficient chain of
source-to-source translators; or they have a defect, present in our naive
parsing algorithm, in that they cannot be known to halt. The present algorithm
does not have these undesirable properties, and as such, it should prove a
useful foundation for a new kind of programming language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605105</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605105</id><created>2006-05-24</created><updated>2006-10-05</updated><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>An outer bound to the capacity region of the broadcast channel</title><categories>cs.IT math.IT</categories><comments>12 pages, 1 figure ISIT 2006</comments><abstract>  An outer bound to the capacity region of the two-receiver discrete memoryless
broadcast channel is given. The outer bound is tight for all cases where the
capacity region is known. When specialized to the case of no common
information, this outer bound is contained in the Korner-Marton outer bound.
This containment is shown to be strict for the binary skew-symmetric broadcast
channel. Thus, this outer bound is in general tighter than all other known
outer bounds on the discrete memoryless broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605106</id><created>2006-05-24</created><authors><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author></authors><title>Supervisory Control of Fuzzy Discrete Event Systems: A Formal Approach</title><categories>cs.LO cs.AI</categories><acm-class>F.1.2; F.4.3; J.7</acm-class><journal-ref>IEEE Trans. SMC-Part B, VOL.35, NO. 1, February 2005, pp. 72-88</journal-ref><abstract>  Fuzzy {\it discrete event systems} (DESs) were proposed recently by Lin and
Ying [19], which may better cope with the real-world problems with fuzziness,
impreciseness, and subjectivity such as those in biomedicine. As a continuation
of [19], in this paper we further develop fuzzy DESs by dealing with
supervisory control of fuzzy DESs. More specifically, (i) we reformulate the
parallel composition of crisp DESs, and then define the parallel composition of
fuzzy DESs that is equivalent to that in [19]; {\it max-product} and {\it
max-min} automata for modeling fuzzy DESs are considered; (ii) we deal with a
number of fundamental problems regarding supervisory control of fuzzy DESs,
particularly demonstrate controllability theorem and nonblocking
controllability theorem of fuzzy DESs, and thus present the conditions for the
existence of supervisors in fuzzy DESs; (iii) we analyze the complexity for
presenting a uniform criterion to test the fuzzy controllability condition of
fuzzy DESs modeled by max-product automata; in particular, we present in detail
a general computing method for checking whether or not the fuzzy
controllability condition holds, if max-min automata are used to model fuzzy
DESs, and by means of this method we can search for all possible fuzzy states
reachable from initial fuzzy state in max-min automata; also, we introduce the
fuzzy $n$-controllability condition for some practical problems; (iv) a number
of examples serving to illustrate the applications of the derived results and
methods are described; some basic properties related to supervisory control of
fuzzy DESs are investigated. To conclude, some related issues are raised for
further consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605107</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605107</id><created>2006-05-24</created><updated>2007-10-06</updated><authors><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Liu</keyname><forenames>Fuchun</forenames></author></authors><title>Fuzzy Discrete Event Systems under Fuzzy Observability and a
  test-algorithm</title><categories>cs.LO</categories><comments>A further revised version to appear in IEEE Trans. Fuzzy Systems</comments><acm-class>F.1.2; F.4.3; J.7</acm-class><journal-ref>IEEE Transactions on Fuzzy Systems, 2009, 17 (3): 578-589.</journal-ref><abstract>  In order to more effectively cope with the real-world problems of vagueness,
impreciseness, and subjectivity, fuzzy discrete event systems (FDESs) were
proposed recently. Notably, FDESs have been applied to biomedical control for
HIV/AIDS treatment planning and sensory information processing for robotic
control. Qiu, Cao and Ying independently developed supervisory control theory
of FDESs. We note that the controllability of events in Qiu's work is fuzzy but
the observability of events is crisp, and, the observability of events in Cao
and Ying's work is also crisp although the controllability is not completely
crisp since the controllable events can be disabled with any degrees. Motivated
by the necessity to consider the situation that the events may be observed or
controlled with some membership degrees, in this paper, we establish the
supervisory control theory of FDESs with partial observations, in which both
the observability and controllability of events are fuzzy instead. We formalize
the notions of fuzzy controllability condition and fuzzy observability
condition. And Controllability and Observability Theorem of FDESs is set up in
a more generic framework. In particular, we present a detailed computing flow
to verify whether the controllability and observability conditions hold. Thus,
this result can decide the existence of supervisors. Also, we use this
computing method to check the existence of supervisors in the Controllability
and Observability Theorem of classical discrete event systems (DESs), which is
a new method and different from classical case. A number of examples are
elaborated on to illustrate the presented results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605108</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605108</id><created>2006-05-24</created><updated>2006-12-17</updated><authors><author><keyname>Liu</keyname><forenames>Fuchun</forenames></author><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Xing</keyname><forenames>Hongyan</forenames></author><author><keyname>Fan</keyname><forenames>Zhujun</forenames></author></authors><title>Diagnosability of Fuzzy Discrete Event Systems</title><categories>cs.AI</categories><comments>14 pages; revisions have been made</comments><acm-class>F.1.2; F.4.3; J.7</acm-class><doi>10.1007/978-3-540-74205-0_73</doi><abstract>  In order to more effectively cope with the real-world problems of vagueness,
{\it fuzzy discrete event systems} (FDESs) were proposed recently, and the
supervisory control theory of FDESs was developed. In view of the importance of
failure diagnosis, in this paper, we present an approach of the failure
diagnosis in the framework of FDESs. More specifically: (1) We formalize the
definition of diagnosability for FDESs, in which the observable set and failure
set of events are {\it fuzzy}, that is, each event has certain degree to be
observable and unobservable, and, also, each event may possess different
possibility of failure occurring. (2) Through the construction of
observability-based diagnosers of FDESs, we investigate its some basic
properties. In particular, we present a necessary and sufficient condition for
diagnosability of FDESs. (3) Some examples serving to illuminate the
applications of the diagnosability of FDESs are described. To conclude, some
related issues are raised for further consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605109</id><created>2006-05-24</created><authors><author><keyname>Torlak</keyname><forenames>Emina</forenames></author><author><keyname>van Dijk</keyname><forenames>Marten</forenames></author><author><keyname>Gassend</keyname><forenames>Blaise</forenames></author><author><keyname>Jackson</keyname><forenames>Daniel</forenames></author><author><keyname>Devadas</keyname><forenames>Srinivas</forenames></author></authors><title>Knowledge Flow Analysis for Security Protocols</title><categories>cs.CR cs.SE</categories><comments>20 pages</comments><report-no>MIT-CSAIL-TR-2005-066</report-no><abstract>  Knowledge flow analysis offers a simple and flexible way to find flaws in
security protocols. A protocol is described by a collection of rules
constraining the propagation of knowledge amongst principals. Because this
characterization corresponds closely to informal descriptions of protocols, it
allows a succinct and natural formalization; because it abstracts away message
ordering, and handles communications between principals and applications of
cryptographic primitives uniformly, it is readily represented in a standard
logic. A generic framework in the Alloy modelling language is presented, and
instantiated for two standard protocols, and a new key management scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605110</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605110</id><created>2006-05-24</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Mapping the Bid Behavior of Conference Referees</title><categories>cs.DL cs.CY cs.GL</categories><report-no>LA-UR-06-0749</report-no><acm-class>H.3.7</acm-class><journal-ref>Journal of Informetrics, volume 1, number 1, pp. 62-82, ISSN:
  1751-1577, January 2007</journal-ref><doi>10.1016/j.joi.2006.09.006</doi><abstract>  The peer-review process, in its present form, has been repeatedly criticized.
Of the many critiques ranging from publication delays to referee bias, this
paper will focus specifically on the issue of how submitted manuscripts are
distributed to qualified referees. Unqualified referees, without the proper
knowledge of a manuscript's domain, may reject a perfectly valid study or
potentially more damaging, unknowingly accept a faulty or fraudulent result. In
this paper, referee competence is analyzed with respect to referee bid data
collected from the 2005 Joint Conference on Digital Libraries (JCDL). The
analysis of the referee bid behavior provides a validation of the intuition
that referees are bidding on conference submissions with regards to the subject
domain of the submission. Unfortunately, this relationship is not strong and
therefore suggests that there exists other factors beyond subject domain that
may be influencing referees to bid for particular submissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605111</id><created>2006-05-24</created><authors><author><keyname>Hillmann</keyname><forenames>Diane I.</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Sutton</keyname><forenames>Stuart A.</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Phipps</keyname><forenames>Jon</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Laundry</keyname><forenames>Ryan</forenames><affiliation>University of Washington</affiliation></author></authors><title>A Metadata Registry from Vocabularies UP: The NSDL Registry Project</title><categories>cs.DL</categories><comments>Submitted to Dublin Core 2006 Conference (DC2006)</comments><abstract>  The NSDL Metadata Registry is designed to provide humans and machines with
the means to discover, create, access and manage metadata schemes, schemas,
application profiles, crosswalks and concept mappings. This paper describes the
general goals and architecture of the NSDL Metadata Registry as well as issues
encountered during the first year of the project's implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605112</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605112</id><created>2006-05-24</created><updated>2008-07-15</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author></authors><title>An Algorithm to Determine Peer-Reviewers</title><categories>cs.DL cs.AI cs.DS</categories><comments>Rodriguez, M.A., Bollen, J., &quot;An Algorithm to Determine
  Peer-Reviewers&quot;, Conference on Information and Knowledge Management, in
  press, ACM, LA-UR-06-2261, October 2008; ISBN:978-1-59593-991-3</comments><report-no>LA-UR-06-2261</report-no><acm-class>H.3.7, H.3.3</acm-class><journal-ref>Conference on Information and Knowledge Management (CIKM), ACM,
  pages 319-328, (October 2008)</journal-ref><doi>10.1145/1458082.1458127</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The peer-review process is the most widely accepted certification mechanism
for officially accepting the written results of researchers within the
scientific community. An essential component of peer-review is the
identification of competent referees to review a submitted manuscript. This
article presents an algorithm to automatically determine the most appropriate
reviewers for a manuscript by way of a co-authorship network data structure and
a relative-rank particle-swarm algorithm. This approach is novel in that it is
not limited to a pre-selected set of referees, is computationally efficient,
requires no human-intervention, and, in some instances, can automatically
identify conflict of interest situations. A useful application of this
algorithm would be to open commentary peer-review systems because it provides a
weighting for each referee with respects to their expertise in the domain of a
manuscript. The algorithm is validated using referee bid data from the 2005
Joint Conference on Digital Libraries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605113</id><created>2006-05-24</created><authors><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>An Architecture for the Aggregation and Analysis of Scholarly Usage Data</title><categories>cs.DL</categories><comments>to be published in Proceedings of the Joint Conference on Digital
  Libraries, 2006</comments><acm-class>H.3.7</acm-class><abstract>  Although recording of usage data is common in scholarly information services,
its exploitation for the creation of value-added services remains limited due
to concerns regarding, among others, user privacy, data validity, and the lack
of accepted standards for the representation, sharing and aggregation of usage
data. This paper presents a technical, standards-based architecture for sharing
usage information, which we have designed and implemented. In this
architecture, OpenURL-compliant linking servers aggregate usage information of
a specific user community as it navigates the distributed information
environment that it has access to. This usage information is made OAI-PMH
harvestable so that usage information exposed by many linking servers can be
aggregated to facilitate the creation of value-added services with a reach
beyond that of a single community or a single information service. This paper
also discusses issues that were encountered when implementing the proposed
approach, and it presents preliminary results obtained from analyzing a usage
data set containing about 3,500,000 requests aggregated by a federation of
linking servers at the California State University system over a 20 month
period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605114</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605114</id><created>2006-05-24</created><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author></authors><title>Oblivious Transfer using Elliptic Curves</title><categories>cs.CR</categories><comments>10 pages</comments><journal-ref>Cryptologia, Volume 31, Issue 2 April 2007, pages 125 - 132</journal-ref><abstract>  This paper proposes an algorithm for oblivious transfer using elliptic
curves. Also, we present its application to chosen one-out-of-two oblivious
transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605115</identifier>
 <datestamp>2008-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605115</id><created>2006-05-24</created><updated>2008-05-12</updated><authors><author><keyname>Jones</keyname><forenames>Nick S.</forenames></author><author><keyname>Masanes</keyname><forenames>Lluis</forenames></author></authors><title>Key Distillation and the Secret-Bit Fraction</title><categories>cs.CR cs.IT math.IT quant-ph</categories><comments>12 pages</comments><journal-ref>IEEE Trans. Inf. Theory, Vol. 54, No. 2, pp 680-691 (2008)</journal-ref><doi>10.1109/TIT.2007.913264</doi><abstract>  We consider distillation of secret bits from partially secret noisy
correlations P_ABE, shared between two honest parties and an eavesdropper. The
most studied distillation scenario consists of joint operations on a large
number of copies of the distribution (P_ABE)^N, assisted with public
communication. Here we consider distillation with only one copy of the
distribution, and instead of rates, the 'quality' of the distilled secret bits
is optimized, where the 'quality' is quantified by the secret-bit fraction of
the result. The secret-bit fraction of a binary distribution is the proportion
which constitutes a secret bit between Alice and Bob. With local operations and
public communication the maximal extractable secret-bit fraction from a
distribution P_ABE is found, and is denoted by Lambda[P_ABE]. This quantity is
shown to be nonincreasing under local operations and public communication, and
nondecreasing under eavesdropper's local operations: it is a secrecy monotone.
It is shown that if Lambda[P_ABE]&gt;1/2 then P_ABE is distillable, thus providing
a sufficient condition for distillability. A simple expression for
Lambda[P_ABE] is found when the eavesdropper is decoupled, and when the honest
parties' information is binary and the local operations are reversible.
Intriguingly, for general distributions the (optimal) operation requires local
degradation of the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605116</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605116</id><created>2006-05-24</created><authors><author><keyname>Liu</keyname><forenames>Nan</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Optimal Distortion-Power Tradeoffs in Gaussian Sensor Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 0 figure, To appear in ISIT 2006</comments><abstract>  We investigate the optimal performance of dense sensor networks by studying
the joint source-channel coding problem. The overall goal of the sensor network
is to take measurements from an underlying random process, code and transmit
those measurement samples to a collector node in a cooperative multiple access
channel with imperfect feedback, and reconstruct the entire random process at
the collector node. We provide lower and upper bounds for the minimum
achievable expected distortion when the underlying random process is Gaussian.
In the case where the random process satisfies some general conditions, we
evaluate the lower and upper bounds explicitly and show that they are of the
same order for a wide range of sum power constraints. Thus, for these random
processes, under these sum power constraints, we determine the achievability
scheme that is order-optimal, and express the minimum achievable expected
distortion as a function of the sum power constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605117</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605117</id><created>2006-05-24</created><authors><author><keyname>Shim</keyname><forenames>Seijoon</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>A Lattice-Based MIMO Broadcast Precoder for Multi-Stream Transmission</title><categories>cs.IT math.IT</categories><comments>30 pages, 9 figures, submitted to IEEE Trans. on Communications and
  partly submitted to the Globecomm 2006</comments><abstract>  Precoding with block diagonalization is an attractive scheme for approaching
sum capacity in multiuser multiple input multiple output (MIMO) broadcast
channels. This method requires either global channel state information at every
receiver or an additional training phase, which demands additional system
planning. In this paper we propose a lattice based multi-user precoder that
uses block diagonalization combined with pre-equalization and perturbation for
the multiuser MIMO broadcast channel. An achievable sum rate of the proposed
scheme is derived and used to show that the proposed technique approaches the
achievable sum rate of block diagonalization with water-filling but does not
require the additional information at the receiver. Monte Carlo simulations
with equal power allocation show that the proposed method provides better bit
error rate and diversity performance than block diagonalization with a
zero-forcing receiver. Additionally, the proposed method shows similar
performance to the maximum likelihood receiver but with much lower receiver
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605118</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605118</id><created>2006-05-24</created><authors><author><keyname>Kelley</keyname><forenames>Christine A.</forenames></author><author><keyname>Sridhara</keyname><forenames>Deepak</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>Pseudocodeword weights for non-binary LDPC codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures. To appear in Proceedings of the 2006 IEEE
  International Symposium on Information Theory, July 9-14, 2006, Seattle, USA</comments><abstract>  Pseudocodewords of q-ary LDPC codes are examined and the weight of a
pseudocodeword on the q-ary symmetric channel is defined. The weight definition
of a pseudocodeword on the AWGN channel is also extended to two-dimensional
q-ary modulation such as q-PAM and q-PSK. The tree-based lower bounds on the
minimum pseudocodeword weight are shown to also hold for q-ary LDPC codes on
these channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605119</id><created>2006-05-25</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Tamaki</keyname><forenames>H.</forenames></author><author><keyname>Ueda</keyname><forenames>K.</forenames></author></authors><title>An Internet-enabled technology to support Evolutionary Design</title><categories>cs.CE cs.AI cs.AR cs.MA cs.NI</categories><comments>23 pages, 3 figures. Preprint completed in 2000</comments><journal-ref>Journal of Engineering Manufacture. 2001, Vol.215, No.B5, 647-655</journal-ref><abstract>  This paper discusses the systematic use of product feedback information to
support life-cycle design approaches and provides guidelines for developing a
design at both the product and the system levels. Design activities are
surveyed in the light of the product life cycle, and the design information
flow is interpreted from a semiotic perspective. The natural evolution of a
design is considered, the notion of design expectations is introduced, and the
importance of evaluation of these expectations in dynamic environments is
argued. Possible strategies for reconciliation of the expectations and
environmental factors are described. An Internet-enabled technology is proposed
to monitor product functionality, usage, and operational environment and supply
the designer with relevant information. A pilot study of assessing design
expectations of a refrigerator is outlined, and conclusions are drawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605120</id><created>2006-05-25</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Tamaki</keyname><forenames>H.</forenames></author><author><keyname>Kitamura</keyname><forenames>S.</forenames></author></authors><title>Understanding Design Fundamentals: How Synthesis and Analysis Drive
  Creativity, Resulting in Emergence</title><categories>cs.AI cs.CE cs.HC</categories><comments>33pages, 4 figures. Preprint completed in 2000</comments><journal-ref>AI in Engineering. 2001, Vol.15/4, 329-342</journal-ref><abstract>  This paper presents results of an ongoing interdisciplinary study to develop
a computational theory of creativity for engineering design. Human design
activities are surveyed, and popular computer-aided design methodologies are
examined. It is argued that semiotics has the potential to merge and unite
various design approaches into one fundamental theory that is naturally
interpretable and so comprehensible in terms of computer use. Reviewing related
work in philosophy, psychology, and cognitive science provides a general and
encompassing vision of the creativity phenomenon. Basic notions of algebraic
semiotics are given and explained in terms of design. This is to define a model
of the design creative process, which is seen as a process of semiosis, where
concepts and their attributes represented as signs organized into systems are
evolved, blended, and analyzed, resulting in the development of new concepts.
The model allows us to formally describe and investigate essential properties
of the design process, namely its dynamics and non-determinism inherent in
creative thinking. A stable pattern of creative thought - analogical and
metaphorical reasoning - is specified to demonstrate the expressive power of
the modeling approach; illustrative examples are given. The developed theory is
applied to clarify the nature of emergence in design: it is shown that while
emergent properties of a product may influence its creative value, emergence
can simply be seen as a by-product of the creative process. Concluding remarks
summarize the research, point to some unresolved issues, and outline directions
for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605121</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605121</id><created>2006-05-25</created><authors><author><keyname>Kryssanov</keyname><forenames>Victor V.</forenames></author><author><keyname>Okabe</keyname><forenames>Masayuki</forenames></author><author><keyname>Kakusho</keyname><forenames>Koh</forenames></author><author><keyname>Minoh</keyname><forenames>Michihiko</forenames></author></authors><title>Communication of Social Agents and the Digital City - A Semiotic
  Perspective</title><categories>cs.AI cs.CL cs.CY cs.HC</categories><comments>15 pages, 1 figure. Preprint completed in 2001. An earlier version of
  the paper was presented at the Second Kyoto Workshop on Digital Cities,
  Kyoto, Japan in 2001</comments><journal-ref>Lecture Notes in Computer Science. 2002, Vol. 2362, 56-70</journal-ref><abstract>  This paper investigates the concept of digital city. First, a functional
analysis of a digital city is made in the light of the modern study of
urbanism; similarities between the virtual and urban constructions are pointed
out. Next, a semiotic perspective on the subject matter is elaborated, and a
terminological basis is introduced to treat a digital city as a self-organizing
meaning-producing system intended to support social or spatial navigation. An
explicit definition of a digital city is formulated. Finally, the proposed
approach is discussed, conclusions are given, and future work is outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605122</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605122</id><created>2006-05-25</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Kakusho</keyname><forenames>K.</forenames></author><author><keyname>Kuleshov</keyname><forenames>E. L.</forenames></author><author><keyname>Minoh</keyname><forenames>M.</forenames></author></authors><title>Modeling Hypermedia-Based Communication</title><categories>cs.HC cs.CY cs.IR cs.IT math.IT</categories><comments>35 pages, 4 figures, 1 table. Preprint completed in 2004</comments><journal-ref>Information Sciences. 2005, Vol. 174/1-2, 37-53</journal-ref><abstract>  In this article, we explore two approaches to modeling hypermedia-based
communication. It is argued that the classical conveyor-tube framework is not
applicable to the case of computer- and Internet- mediated communication. We
then present a simple but very general system-theoretic model of the
communication process, propose its mathematical interpretation, and derive
several formulas, which qualitatively and quantitatively accord with data
obtained on-line. The devised theoretical results generalize and correct the
Zipf-Mandelbrot law and can be used in information system design. At the
paper's end, we give some conclusions and draw implications for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605123</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605123</id><created>2006-05-26</created><authors><author><keyname>Cardoso</keyname><forenames>Jaime S.</forenames></author></authors><title>Classification of Ordinal Data</title><categories>cs.AI</categories><comments>62 pages, MSc thesis</comments><abstract>  Classification of ordinal data is one of the most important tasks of relation
learning. In this thesis a novel framework for ordered classes is proposed. The
technique reduces the problem of classifying ordered classes to the standard
two-class problem. The introduced method is then mapped into support vector
machines and neural networks. Compared with a well-known approach using
pairwise objects as training samples, the new algorithm has a reduced
complexity and training time. A second novel model, the unimodal model, is also
introduced and a parametric version is mapped into neural networks. Several
case studies are presented to assert the validity of the proposed models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605124</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605124</id><created>2006-05-26</created><authors><author><keyname>Perez</keyname><forenames>Jorge</forenames></author><author><keyname>Arenas</keyname><forenames>Marcelo</forenames></author><author><keyname>Gutierrez</keyname><forenames>Claudio</forenames></author></authors><title>Semantics and Complexity of SPARQL</title><categories>cs.DB</categories><abstract>  SPARQL is the W3C candidate recommendation query language for RDF. In this
paper we address systematically the formal study of SPARQL, concentrating in
its graph pattern facility. We consider for this study a fragment without
literals and a simple version of filters which encompasses all the main issues
yet is simple to formalize. We provide a compositional semantics, prove there
are normal forms, prove complexity bounds, among others that the evaluation of
SPARQL patterns is PSPACE-complete, compare our semantics to an alternative
operational semantics, give simple and natural conditions when both semantics
coincide and discuss optimizations procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605125</id><created>2006-05-26</created><authors><author><keyname>Drolet</keyname><forenames>Germain</forenames><affiliation>Department of Electrical &amp; Computer Engineering, Royal Military College of Canada</affiliation></author></authors><title>Combinational Logic Circuit Design with the Buchberger Algorithm</title><categories>cs.AR</categories><comments>15 pages, 1 table</comments><acm-class>B.1.2</acm-class><abstract>  We detail a procedure for the computation of the polynomial form of an
electronic combinational circuit from the design equations in a truth table.
The method uses the Buchberger algorithm rather than current traditional
methods based on search algorithms. We restrict the analysis to a single
output, but the procedure can be generalized to multiple outputs. The procedure
is illustrated with the design of a simple arithmetic and logic unit with two
3-bit operands and two control bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605126</id><created>2006-05-26</created><authors><author><keyname>Bunde</keyname><forenames>David P.</forenames></author></authors><title>Power-aware scheduling for makespan and flow</title><categories>cs.DS</categories><comments>13 pages, 3 figures. To appear in 18th ACM Symposium on Parallelism
  in Algorithms and Architectures (SPAA), 2006</comments><abstract>  We consider offline scheduling algorithms that incorporate speed scaling to
address the bicriteria problem of minimizing energy consumption and a
scheduling metric. For makespan, we give linear-time algorithms to compute all
non-dominated solutions for the general uniprocessor problem and for the
multiprocessor problem when every job requires the same amount of work. We also
show that the multiprocessor problem becomes NP-hard when jobs can require
different amounts of work.
  For total flow, we show that the optimal flow corresponding to a particular
energy budget cannot be exactly computed on a machine supporting arithmetic and
the extraction of roots. This hardness result holds even when scheduling
equal-work jobs on a uniprocessor. We do, however, extend previous work by
Pruhs et al. to give an arbitrarily-good approximation for scheduling
equal-work jobs on a multiprocessor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605127</id><created>2006-05-26</created><authors><author><keyname>Keith</keyname><forenames>Steven</forenames></author><author><keyname>Kaser</keyname><forenames>Owen</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Analyzing Large Collections of Electronic Text Using OLAP</title><categories>cs.DB cs.DL</categories><report-no>TR-05-001</report-no><abstract>  Computer-assisted reading and analysis of text has various applications in
the humanities and social sciences. The increasing size of many electronic text
archives has the advantage of a more complete analysis but the disadvantage of
taking longer to obtain results. On-Line Analytical Processing is a method used
to store and quickly analyze multidimensional data. By storing text analysis
information in an OLAP system, a user can obtain solutions to inquiries in a
matter of seconds as opposed to minutes, hours, or even days. This analysis is
user-driven allowing various users the freedom to pursue their own direction of
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605128</id><created>2006-05-28</created><authors><author><keyname>Kurz</keyname><forenames>Alexander</forenames></author></authors><title>Logic Column 15: Coalgebras and Their Logics</title><categories>cs.LO</categories><comments>21 pages</comments><acm-class>F.4.1</acm-class><journal-ref>SIGACT News 37 (2), pp. 57-77, 2006</journal-ref><abstract>  This article describes recent work on the topic of specifying properties of
transition systems. By giving a suitably abstract description of transition
systems as coalgebras, it is possible to derive logics for capturing properties
of these transition systems in an elegant way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605129</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605129</id><created>2006-05-28</created><authors><author><keyname>Kang</keyname><forenames>W.</forenames></author><author><keyname>Ulukus</keyname><forenames>S.</forenames></author></authors><title>An Outer Bound for the Multi-Terminal Rate-Distortion Region</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, to appear in Proc. IEEE International Symp. on
  Information Theory (ISIT) 2006</comments><acm-class>H.1.1</acm-class><abstract>  The multi-terminal rate-distortion problem has been studied extensively.
Notably, among these, Tung and Housewright have provided the best known inner
and outer bounds for the rate region under certain distortion constraints. In
this paper, we first propose an outer bound for the rate region, and show that
it is tighter than the outer bound of Tung and Housewright. Our outer bound
involves some $n$-letter Markov chain constraints, which cause computational
difficulties. We utilize a necessary condition for the Markov chain constraints
to obtain another outer bound, which is represented in terms of some
single-letter mutual information expressions evaluated over probability
distributions that satisfy some single-letter conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605130</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605130</id><created>2006-05-29</created><authors><author><keyname>Mora</keyname><forenames>Thierry</forenames></author><author><keyname>Rivoire</keyname><forenames>Olivier</forenames></author></authors><title>Error Exponents of Low-Density Parity-Check Codes on the Binary Erasure
  Channel</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>5 pages, 4 figures</comments><journal-ref>Proceeding of the IEEE Information Theory Workshop, 2006 (ITW
  '06), Chengdu, pp. 81-85</journal-ref><doi>10.1109/ITW2.2006.323761</doi><abstract>  We introduce a thermodynamic (large deviation) formalism for computing error
exponents in error-correcting codes. Within this framework, we apply the
heuristic cavity method from statistical mechanics to derive the average and
typical error exponents of low-density parity-check (LDPC) codes on the binary
erasure channel (BEC) under maximum-likelihood decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605131</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605131</id><created>2006-05-29</created><updated>2006-05-30</updated><authors><author><keyname>Morgan</keyname><forenames>Simon P</forenames></author></authors><title>Notes on Geometric Measure Theory Applications to Image Processing;
  De-noising, Segmentation, Pattern, Texture, Lines, Gestalt and Occlusion</title><categories>cs.CV</categories><comments>9 pages, no figures. This informal discussion paper will be updated
  periodically</comments><abstract>  Regularization functionals that lower level set boundary length when used
with L^1 fidelity functionals on signal de-noising on images create artifacts.
These are (i) rounding of corners, (ii) shrinking of radii, (iii) shrinking of
cusps, and (iv) non-smoothing of staircasing. Regularity functionals based upon
total curvature of level set boundaries do not create artifacts (i) and (ii).
An adjusted fidelity term based on the flat norm on the current (a
distributional graph) representing the density of curvature of level sets
boundaries can minimize (iii) by weighting the position of a cusp. A regularity
term to eliminate staircasing can be based upon the mass of the current
representing the graph of an image function or its second derivatives.
Densities on the Grassmann bundle of the Grassmann bundle of the ambient space
of the graph can be used to identify patterns, textures, occlusion and lines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605132</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605132</id><created>2006-05-29</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Radzik</keyname><forenames>Tadeusz</forenames></author></authors><title>Stable partitions in coalitional games</title><categories>cs.GT cs.MA</categories><comments>18 pages</comments><abstract>  We propose a notion of a stable partition in a coalitional game that is
parametrized by the concept of a defection function. This function assigns to
each partition of the grand coalition a set of different coalition arrangements
for a group of defecting players. The alternatives are compared using their
social welfare. We characterize the stability of a partition for a number of
most natural defection functions and investigate whether and how so defined
stable partitions can be reached from any initial partition by means of simple
transformations. The approach is illustrated by analyzing an example in which a
set of stores seeks an optimal transportation arrangement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605133</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605133</id><created>2006-05-29</created><authors><author><keyname>Friedman</keyname><forenames>Benoit Donnet Philippe Raoult Timur</forenames></author></authors><title>Efficient Route Tracing from a Single Source</title><categories>cs.NI</categories><abstract>  Traceroute is a networking tool that allows one to discover the path that
packets take from a source machine, through the network, to a destination
machine. It is widely used as an engineering tool, and also as a scientific
tool, such as for discovery of the network topology at the IP level. In prior
work, authors on this technical report have shown how to improve the efficiency
of route tracing from multiple cooperating monitors. However, it is not unusual
for a route tracing monitor to operate in isolation. Somewhat different
strategies are required for this case, and this report is the first systematic
study of those requirements. Standard traceroute is inefficient when used
repeatedly towards multiple destinations, as it repeatedly probes the same
interfaces close to the source. Others have recognized this inefficiency and
have proposed tracing backwards from the destinations and stopping probing upon
encounter with a previously-seen interface. One of this technical report's
contributions is to quantify for the first time the efficiency of this
approach. Another contribution is to describe the effect of non-responding
destinations on this efficiency. Since a large portion of destination machines
do not reply to probe packets, backwards probing from the destination is often
infeasible. We propose an algorithm to tackle non-responding destinations, and
we find that our algorithm can strongly decrease probing redundancy at the cost
of a small reduction in node and link discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605134</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605134</id><created>2006-05-29</created><authors><author><keyname>Seet</keyname><forenames>Boon-Chong</forenames></author><author><keyname>Lee</keyname><forenames>Bu-Sung</forenames></author><author><keyname>Lau</keyname><forenames>Chiew-Tong</forenames></author></authors><title>DSR with Non-Optimal Route Suppression for MANETs</title><categories>cs.NI</categories><comments>10 pages, 17 figures</comments><acm-class>C.2.2</acm-class><abstract>  This paper revisits the issue of route discovery in dynamic source routing
(DSR) for mobile ad hoc networks (MANETs), and puts forward a proposal of a
lightweight non-optimal route suppression technique based on the observation of
a rarely noted but commonly occurring phenomenon in route discovery. The
technique exploits the observed phenomenon to extract query state information
that permits intermediate nodes to identify and suppress the initiation of
route replies with non-optimal routes, even if the route query is received for
the first time. A detailed evaluation of DSR with non-optimal route suppression
is found to yield significant improvements in both protocol efficiency and
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605135</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605135</id><created>2006-05-29</created><updated>2006-11-01</updated><authors><author><keyname>Dabora</keyname><forenames>R.</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Servetto</keyname><forenames>S. D.</forenames><affiliation>Cornell University</affiliation></author></authors><title>On the Role of Estimate-and-Forward with Time-Sharing in Cooperative
  Communications</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, May 2006;
  Revised, October 2006</comments><abstract>  In this work we focus on the general relay channel. We investigate the
application of estimate-and-forward (EAF) to different scenarios. Specifically,
we consider assignments of the auxiliary random variables that always satisfy
the feasibility constraints. We first consider the multiple relay channel and
obtain an achievable rate without decoding at the relays. We demonstrate the
benefits of this result via an explicit discrete memoryless multiple relay
scenario where multi-relay EAF is superior to multi-relay decode-and-forward
(DAF). We then consider the Gaussian relay channel with coded modulation, where
we show that a three-level quantization outperforms the Gaussian quantization
commonly used to evaluate the achievable rates in this scenario. Finally we
consider the cooperative general broadcast scenario with a multi-step
conference. We apply estimate-and-forward to obtain a general multi-step
achievable rate region. We then give an explicit assignment of the auxiliary
random variables, and use this result to obtain an explicit expression for the
single common message broadcast scenario with a two-step conference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605136</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605136</id><created>2006-05-29</created><updated>2006-06-05</updated><authors><author><keyname>Bourgeois</keyname><forenames>Gerald</forenames></author></authors><title>Attaque algebrique de NTRU a l'aide des vecteurs de Witt</title><categories>cs.CR</categories><comments>6 pages; correction of the miscalculations</comments><abstract>  One improves an algebraic attack of NTRU due to Silverman, Smart and
Vercauteren; the latter considered the first 2 bits of a Witt vector attached
to the research of the secret key; here the first 4 bits are considered, which
provides additional equations of degrees 4 and 8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605137</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605137</id><created>2006-05-29</created><authors><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Capacity Results for Block-Stationary Gaussian Fading Channels with a
  Peak Power Constraint</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><abstract>  We consider a peak-power-limited single-antenna block-stationary Gaussian
fading channel where neither the transmitter nor the receiver knows the channel
state information, but both know the channel statistics. This model subsumes
most previously studied Gaussian fading models. We first compute the asymptotic
channel capacity in the high SNR regime and show that the behavior of channel
capacity depends critically on the channel model. For the special case where
the fading process is symbol-by-symbol stationary, we also reveal a fundamental
interplay between the codeword length, communication rate, and decoding error
probability. Specifically, we show that the codeword length must scale with SNR
in order to guarantee that the communication rate can grow logarithmically with
SNR with bounded decoding error probability, and we find a necessary condition
for the growth rate of the codeword length. We also derive an expression for
the capacity per unit energy. Furthermore, we show that the capacity per unit
energy is achievable using temporal ON-OFF signaling with optimally allocated
ON symbols, where the optimal ON-symbol allocation scheme may depend on the
peak power constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605138</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605138</id><created>2006-05-30</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Abramov</keyname><forenames>V. A.</forenames></author><author><keyname>Fukuda</keyname><forenames>Y.</forenames></author><author><keyname>Konishi</keyname><forenames>K.</forenames></author></authors><title>The meaning of manufacturing know-how</title><categories>cs.AI cs.CE</categories><comments>12 pages. Preprint completed in March 1998. Presented in part at
  PROLAMAT'98</comments><journal-ref>In: G. Jacucci, G.J. Olling, K. Preiss, and M. Wozny (eds), The
  Globalization of Manufacturing in the Digital Communications Era of the 21st
  Century: Innovation, Agility and the Virtual Enterprise, pp. 375-387. 1998,
  Kluwer Academic Publishers</journal-ref><abstract>  This paper investigates the phenomenon of manufacturing know-how. First, the
abstract notion of knowledge is discussed, and a terminological basis is
introduced to treat know-how as a kind of knowledge. Next, a brief survey of
the recently reported works dealt with manufacturing know-how is presented, and
an explicit definition of know-how is formulated. Finally, the problem of
utilizing know-how with knowledge-based systems is analyzed, and some ideas
useful for its solving are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605139</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605139</id><created>2006-05-30</created><authors><author><keyname>Li</keyname><forenames>Na</forenames></author><author><keyname>Qi</keyname><forenames>Wen-Feng</forenames></author></authors><title>Construction and Count of Boolean Functions of an Odd Number of
  Variables with Maximum Algebraic Immunity</title><categories>cs.CR</categories><comments>This paper has been submitted on March 9, 2006</comments><abstract>  Algebraic immunity has been proposed as an important property of Boolean
functions. To resist algebraic attack, a Boolean function should possess high
algebraic immunity. It is well known now that the algebraic immunity of an
$n$-variable Boolean function is upper bounded by $\left\lceil {\frac{n}{2}}
\right\rceil $. In this paper, for an odd integer $n$, we present a
construction method which can efficiently generate a Boolean function of $n$
variables with maximum algebraic immunity, and we also show that any such
function can be generated by this method. Moreover, the number of such Boolean
functions is greater than $2^{2^{n-1}}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605140</identifier>
 <datestamp>2008-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605140</id><created>2006-05-30</created><updated>2007-07-30</updated><authors><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>Inapproximability of the Tutte polynomial</title><categories>cs.CC math.CO</categories><comments>Minor changes to correct typos and provide clarification. Also
  includes an extra figure</comments><journal-ref>Infomation and Computation 206(7), 908-929 (July 2008)</journal-ref><doi>10.1016/j.ic.2008.04.003</doi><abstract>  The Tutte polynomial of a graph G is a two-variable polynomial T(G;x,y) that
encodes many interesting properties of the graph. We study the complexity of
the following problem, for rationals x and y: take as input a graph G, and
output a value which is a good approximation to T(G;x,y). Jaeger, Vertigan and
Welsh have completely mapped the complexity of exactly computing the Tutte
polynomial. They have shown that this is #P-hard, except along the hyperbola
(x-1)(y-1)=1 and at four special points. We are interested in determining for
which points (x,y) there is a &quot;fully polynomial randomised approximation
scheme&quot; (FPRAS) for T(G;x,y). Under the assumption RP is not equal to NP, we
prove that there is no FPRAS at (x,y) if (x,y) is in one of the half-planes
x&lt;-1 or y&lt;-1 (excluding the easy-to-compute cases mentioned above). Two
exceptions to this result are the half-line x&lt;-1, y=1 (which is still open) and
the portion of the hyperbola (x-1)(y-1)=2 corresponding to y&lt;-1 which we show
to be equivalent in difficulty to approximately counting perfect matchings. We
give further intractability results for (x,y) in the vicinity of the origin. A
corollary of our results is that, under the assumption RP is not equal to NP,
there is no FPRAS at the point (x,y)=(0,1--lambda) when \lambda&gt;2 is a positive
integer. Thus there is no FPRAS for counting nowhere-zero \lambda flows for
\lambda&gt;2. This is an interesting consequence of our work since the
corresponding decision problem is in P for example for \lambda=6.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605141</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605141</id><created>2006-05-30</created><authors><author><keyname>Korman</keyname><forenames>Amos</forenames></author></authors><title>General Compact Labeling Schemes for Dynamic Trees</title><categories>cs.DC</categories><comments>32 pages, no figures, the extended abstarct appeired in DISC 2005</comments><abstract>  Let $F$ be a function on pairs of vertices. An {\em $F$- labeling scheme} is
composed of a {\em marker} algorithm for labeling the vertices of a graph with
short labels, coupled with a {\em decoder} algorithm allowing one to compute
$F(u,v)$ of any two vertices $u$ and $v$ directly from their labels. As
applications for labeling schemes concern mainly large and dynamically changing
networks, it is of interest to study {\em distributed dynamic} labeling
schemes. This paper investigates labeling schemes for dynamic trees.
  This paper presents a general method for constructing labeling schemes for
dynamic trees. Our method is based on extending an existing {\em static} tree
labeling scheme to the dynamic setting. This approach fits many natural
functions on trees, such as ancestry relation, routing (in both the adversary
and the designer port models), nearest common ancestor etc.. Our resulting
dynamic schemes incur overheads (over the static scheme) on the label size and
on the communication complexity. Informally, for any function $k(n)$ and any
static $F$-labeling scheme on trees, we present an $F$-labeling scheme on
dynamic trees incurring multiplicative overhead factors
 (over the static scheme) of $O(\log_{k(n)} n)$ on the label size and
$O(k(n)\log_{k(n)} n)$ on the amortized message complexity. In particular, by
setting $k(n)=n^{\epsilon}$ for any $0&lt;\epsilon&lt;1$, we obtain dynamic labeling
schemes with asymptotically optimal label sizes and sublinear amortized message
complexity for all the above mentioned functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605142</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605142</id><created>2006-05-30</created><authors><author><keyname>Corre</keyname><forenames>Gwenol&#xe9;</forenames><affiliation>LESTER</affiliation></author><author><keyname>Julien</keyname><forenames>Nathalie</forenames><affiliation>LESTER</affiliation></author><author><keyname>Senn</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author><author><keyname>Martin</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author></authors><title>Int\'{e}gration de la synth\`{e}se m\'{e}moire dans l'outil de
  synth\`{e}se d'architecture GAUT Low Power</title><categories>cs.AR</categories><proxy>ccsd ccsd-00077402</proxy><journal-ref>JFAAA'02 (Journ\'{e}es Francophone Ad\'{e}quation Algorithme
  Architecture), Tunisie (2002)</journal-ref><abstract>  The systems supporting signal and image applications process large amount of
data. That involves an intensive use of the memory which becomes the bottleneck
of systems. Memory limits performances and represents a significant proportion
of total consumption. In the development high level synthesis tool called GAUT
Low Power, we are interested in the synthesis of the memory unit. In this work,
we integrate the data storage and data transfert to constraint the high level
synthesis of the datapath's execution unit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605143</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605143</id><created>2006-05-30</created><authors><author><keyname>Coussy</keyname><forenames>Philippe</forenames><affiliation>LESTER</affiliation></author><author><keyname>Corre</keyname><forenames>Gwenol&#xe9;</forenames><affiliation>LESTER</affiliation></author><author><keyname>Bomel</keyname><forenames>Pierre</forenames><affiliation>LESTER</affiliation></author><author><keyname>Senn</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author><author><keyname>Martin</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author></authors><title>High-level synthesis under I/O Timing and Memory constraints</title><categories>cs.AR</categories><proxy>ccsd ccsd-00077297</proxy><journal-ref>International Symposium on Circuits And Systems (2005) 680-683</journal-ref><abstract>  The design of complex Systems-on-Chips implies to take into account
communication and memory access constraints for the integration of dedicated
hardware accelerator. In this paper, we present a methodology and a tool that
allow the High-Level Synthesis of DSP algorithm, under both I/O timing and
memory constraints. Based on formal models and a generic architecture, this
tool helps the designer to find a reasonable trade-off between both the
required I/O timing behavior and the internal memory access parallelism of the
circuit. The interest of our approach is demonstrated on the case study of a
FFT algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605144</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605144</id><created>2006-05-30</created><authors><author><keyname>Corre</keyname><forenames>Gwenol&#xe9;</forenames><affiliation>LESTER</affiliation></author><author><keyname>Julien</keyname><forenames>Nathalie</forenames><affiliation>LESTER</affiliation></author><author><keyname>Senn</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author><author><keyname>Martin</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author></authors><title>A Memory Aware High Level Synthesis Too</title><categories>cs.AR</categories><comments>ISBN 0-7695-2097-9</comments><proxy>ccsd ccsd-00077377</proxy><journal-ref>International Symposium on VLSI (2004) 279-280</journal-ref><abstract>  We introduce a new approach to take into account the memory architecture and
the memory mapping in High- Level Synthesis for data intensive applications. We
formalize the memory mapping as a set of constraints for the synthesis, and
defined a Memory Constraint Graph and an accessibility criterion to be used in
the scheduling step. We use a memory mapping file to include those memory
constraints in our HLS tool GAUT. It is possible, with the help of GAUT, to
explore a wide range of solutions, and to reach a good tradeoff between time,
power-consumption, and area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605145</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605145</id><created>2006-05-30</created><authors><author><keyname>Corre</keyname><forenames>Gwenol&#xe9;</forenames><affiliation>LESTER</affiliation></author><author><keyname>Senn</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author><author><keyname>Julien</keyname><forenames>Nathalie</forenames><affiliation>LESTER</affiliation></author><author><keyname>Martin</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author></authors><title>Memory Aware High-Level Synthesis for Embedded Systems</title><categories>cs.AR</categories><proxy>ccsd ccsd-00077375</proxy><journal-ref>IADIS conference on Applied Computing, Portugal (2004) 499-506</journal-ref><abstract>  We introduce a new approach to take into account the memory architecture and
the memory mapping in the High- Level Synthesis of Real-Time embedded systems.
We formalize the memory mapping as a set of constraints used in the scheduling
step. We use a memory mapping file to include those memory constraints in our
HLS tool GAUT. Our scheduling algorithm exhibits a relatively low complexity
that permits to tackle complex designs in a reasonable time. Finally, we show
how to explore, with the help of GAUT, a wide range of solutions, and to reach
a good tradeoff between time, power-consumption, and area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605146</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605146</id><created>2006-05-30</created><authors><author><keyname>Corre</keyname><forenames>Gwenol&#xe9;</forenames><affiliation>LESTER</affiliation></author><author><keyname>Coussy</keyname><forenames>Philippe</forenames><affiliation>LESTER</affiliation></author><author><keyname>Bomel</keyname><forenames>Pierre</forenames><affiliation>LESTER</affiliation></author><author><keyname>Senn</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author><author><keyname>Martin</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author></authors><title>Synth\`{e}se Comportementale Sous Contraintes de Communication et de
  Placement M\'{e}moire pour les composants du TDSI</title><categories>cs.AR</categories><proxy>ccsd ccsd-00077384</proxy><journal-ref>GRETSI'05 (Colloque sur le Traitement du Signal et de l'Image),
  Belgique (2005) 779-782</journal-ref><abstract>  The design of complex Digital Signal Processing systems implies to minimize
architectural cost and to maximize timing performances while taking into
account communication and memory accesses constraints for the integration of
dedicated hardware accelerator. Unfortunately, the traditional Matlab/ Simulink
design flows gather not very flexible hardware blocs. In this paper, we present
a methodology and a tool that permit the High-Level Synthesis of DSP
applications, under both I/O timing and memory constraints. Based on formal
models and a generic architecture, our tool GAUT helps the designer in finding
a reasonable trade-off between the circuit's performance and its architectural
complexity. The efficiency of our approach is demonstrated on the case study of
a FFT algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0605147</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0605147</id><created>2006-05-30</created><authors><author><keyname>Huet</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRISA / INRIA Rennes, IRISA / INRIA Rennes</affiliation></author><author><keyname>S&#xe9;billot</keyname><forenames>Pascale</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author><author><keyname>Gravier</keyname><forenames>Guillaume</forenames><affiliation>IRISA / INRIA Rennes</affiliation></author></authors><title>Utilisation de la linguistique en reconnaissance de la parole : un
  \'{e}tat de l'art</title><categories>cs.HC cs.CL</categories><proxy>ccsd inria-00077386</proxy><abstract>  To transcribe speech, automatic speech recognition systems use statistical
methods, particularly hidden Markov model and N-gram models. Although these
techniques perform well and lead to efficient systems, they approach their
maximum possibilities. It seems thus necessary, in order to outperform current
results, to use additional information, especially bound to language. However,
introducing such knowledge must be realized taking into account specificities
of spoken language (hesitations for example) and being robust to possible
misrecognized words. This document presents a state of the art of these
researches, evaluating the impact of the insertion of linguistic information on
the quality of the transcription.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606001</id><created>2006-05-31</created><authors><author><keyname>Steurer</keyname><forenames>David</forenames></author></authors><title>Tight Bounds for the Min-Max Boundary Decomposition Cost of Weighted
  Graphs</title><categories>cs.DS cs.DM</categories><comments>41 pages, full version of a paper that will appear in SPAA`06</comments><acm-class>F.2.2; G.2.2</acm-class><abstract>  Many load balancing problems that arise in scientific computing applications
ask to partition a graph with weights on the vertices and costs on the edges
into a given number of almost equally-weighted parts such that the maximum
boundary cost over all parts is small.
  Here, this partitioning problem is considered for bounded-degree graphs
G=(V,E) with edge costs c: E-&gt;R+ that have a p-separator theorem for some p&gt;1,
i.e., any (arbitrarily weighted) subgraph of G can be separated into two parts
of roughly the same weight by removing a vertex set S such that the edges
incident to S in the subgraph have total cost at most proportional to (SUM_e
c^p_e)^(1/p), where the sum is over all edges e in the subgraph.
  We show for all positive integers k and weights w that the vertices of G can
be partitioned into k parts such that the weight of each part differs from the
average weight by less than MAX{w_v; v in V}, and the boundary edges of each
part have cost at most proportional to (SUM_e c_e^p/k)^(1/p) + MAX_e c_e. The
partition can be computed in time nearly proportional to the time for computing
a separator S of G.
  Our upper bound on the boundary costs is shown to be tight up to a constant
factor for infinitely many instances with a broad range of parameters. Previous
results achieved this bound only if one has c=1, w=1, and one allows parts with
weight exceeding the average by a constant fraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606002</identifier>
 <datestamp>2007-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606002</id><created>2006-05-31</created><updated>2007-06-30</updated><authors><author><keyname>Hsu</keyname><forenames>Wei-jen</forenames></author><author><keyname>Dutta</keyname><forenames>Debojyoti</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>Mining Behavioral Groups in Large Wireless LANs</title><categories>cs.NI</categories><comments>14 pages, 12 figures</comments><acm-class>C.2.5</acm-class><abstract>  One vision of future wireless networks is that they will be deeply integrated
and embedded in our lives and will involve the use of personalized mobile
devices. User behavior in such networks is bound to affect the network
performance. It is imperative to study and characterize the fundamental
structure of wireless user behavior in order to model, manage, leverage and
design efficient mobile networks. It is also important to make such study as
realistic as possible, based on extensive measurements collected from existing
deployed wireless networks.
  In this study, using our systematic TRACE approach, we analyze wireless
users' behavioral patterns by extensively mining wireless network logs from two
major university campuses. We represent the data using location preference
vectors, and utilize unsupervised learning (clustering) to classify trends in
user behavior using novel similarity metrics. Matrix decomposition techniques
are used to identify (and differentiate between) major patterns. While our
findings validate intuitive repetitive behavioral trends and user grouping, it
is surprising to find the qualitative commonalities of user behaviors from the
two universities. We discover multi-modal user behavior for more than 60% of
the users, and there are hundreds of distinct groups with unique behavioral
patterns in both campuses. The sizes of the major groups follow a power-law
distribution. Our methods and findings provide an essential step towards
network management and behavior-aware network protocols and applications, to
name a few.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606003</id><created>2006-05-31</created><authors><author><keyname>Kojarski</keyname><forenames>Sergei</forenames></author><author><keyname>Lorenz</keyname><forenames>David H.</forenames></author></authors><title>Modeling Aspect Mechanisms: A Top-Down Approach</title><categories>cs.SE cs.PL</categories><report-no>CS-2006-04</report-no><acm-class>D.2.10; D.1.5; D.3.2</acm-class><journal-ref>In Proceedings of the 28th International Conference on Software
  Engineering (ICSE'06), pages 212--221, Shanghai, China, May 20-28, 2006</journal-ref><abstract>  A plethora of diverse aspect mechanisms exist today, all of which integrate
concerns into artifacts that exhibit crosscutting structure. What we lack and
need is a characterization of the design space that these aspect mechanisms
inhabit and a model description of their weaving processes. A good design space
representation provides a common framework for understanding and evaluating
existing mechanisms. A well-understood model of the weaving process can guide
the implementor of new aspect mechanisms. It can guide the designer when
mechanisms implementing new kinds of weaving are needed. It can also help teach
aspect-oriented programming (AOP). In this paper we present and evaluate such a
model of the design space for aspect mechanisms and their weaving processes. We
model weaving, at an abstract level, as a concern integration process. We
derive a weaving process model (WPM) top-down, differentiating a reactive from
a nonreactive process. The model provides an in-depth explanation of the key
subpro existing aspect mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606004</id><created>2006-05-31</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Abramov</keyname><forenames>V. A.</forenames></author><author><keyname>Hibino</keyname><forenames>H.</forenames></author><author><keyname>Fukuda</keyname><forenames>Y.</forenames></author></authors><title>A Framework for the Development of Manufacturing Simulators: Towards New
  Generation of Simulation Systems</title><categories>cs.CE cs.HC</categories><comments>9 pages, 6 figures. Preprint completed in 1998</comments><journal-ref>In: H. Fujimoto and R.E. DeVor (eds), Proceedings of the 1998
  Japan-U.S.A. Symposium on Flexible Automation. 1998, Vol. III, pp. 1307-1314</journal-ref><abstract>  In this paper, an attempt is made to systematically discuss the development
of simulation systems for manufacturing system design. General requirements on
manufacturing simulators are formulated and a framework to address the
requirements is suggested. Problems of information representation as an
activity underlying simulation are considered. This is to form the necessary
mathematical foundation for manufacturing simulations. The theoretical findings
are explored through a pilot study. A conclusion about the suitability of the
suggested approach to the development of simulation systems for manufacturing
system design is made, and implications for future research are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606005</id><created>2006-06-01</created><authors><author><keyname>Galice</keyname><forenames>Samuel</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legrand</keyname><forenames>V&#xe9;ronique</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Minier</keyname><forenames>Marine</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Mullins</keyname><forenames>John</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Ub&#xe9;da</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>The KAA project: a trust policy point of view</title><categories>cs.NI</categories><proxy>ccsd inria-00077648</proxy><abstract>  In the context of ambient networks where each small device must trust its
neighborhood rather than a fixed network, we propose in this paper a
\textit{trust management framework} inspired by known social patterns and based
on the following statements: each mobile constructs itself a local level of
trust what means that it does not accept recommendation by other peers, and the
only relevant parameter, beyond some special cases discussed later, to evaluate
the level of trust is the number of common trusted mobiles. These trusted
mobiles are considered as entries in a local database called history for each
device and we use identity-based cryptography to ensure strong security:
history must be a non-tansferable object.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606006</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606006</id><created>2006-06-01</created><authors><author><keyname>Wittenburg</keyname><forenames>Peter</forenames><affiliation>MPIPS</affiliation></author><author><keyname>Broeder</keyname><forenames>Daan</forenames><affiliation>MPIPS</affiliation></author><author><keyname>Klein</keyname><forenames>Wolfgang</forenames><affiliation>MPIPS</affiliation></author><author><keyname>Levinson</keyname><forenames>Stephen</forenames><affiliation>MPIPS</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Foundations of Modern Language Resource Archives</title><categories>cs.CL</categories><proxy>ccsd ccsd-00077780</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of serious reasons will convince an increasing amount of researchers
to store their relevant material in centers which we will call &quot;language
resource archives&quot;. They combine the duty of taking care of long-term
preservation as well as the task to give access to their material to different
user groups. Access here is meant in the sense that an active interaction with
the data will be made possible to support the integration of new data, new
versions or commentaries of all sort. Modern Language Resource Archives will
have to adhere to a number of basic principles to fulfill all requirements and
they will have to be involved in federations to create joint language resource
domains making it even more simple for the researchers to access the data. This
paper makes an attempt to formulate the essential pillars language resource
archives have to adhere to.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606007</id><created>2006-06-01</created><authors><author><keyname>Pavlo</keyname><forenames>Andrew</forenames><affiliation>University of Wisconsin-Madison</affiliation></author><author><keyname>Homan</keyname><forenames>Christopher</forenames><affiliation>Rochester Institute of Technology</affiliation></author><author><keyname>Schull</keyname><forenames>Jonathan</forenames><affiliation>Rochester Institute of Technology</affiliation></author></authors><title>A parent-centered radial layout algorithm for interactive graph
  visualization and animation</title><categories>cs.HC cs.CG cs.GR</categories><acm-class>I.3.3; H.5.0</acm-class><abstract>  We have developed (1) a graph visualization system that allows users to
explore graphs by viewing them as a succession of spanning trees selected
interactively, (2) a radial graph layout algorithm, and (3) an animation
algorithm that generates meaningful visualizations and smooth transitions
between graphs while minimizing edge crossings during transitions and in static
layouts.
  Our system is similar to the radial layout system of Yee et al. (2001), but
differs primarily in that each node is positioned on a coordinate system
centered on its own parent rather than on a single coordinate system for all
nodes. Our system is thus easy to define recursively and lends itself to
parallelization. It also guarantees that layouts have many nice properties,
such as: it guarantees certain edges never cross during an animation.
  We compared the layouts and transitions produced by our algorithms to those
produced by Yee et al. Results from several experiments indicate that our
system produces fewer edge crossings during transitions between graph drawings,
and that the transitions more often involve changes in local scaling rather
than structure.
  These findings suggest the system has promise as an interactive graph
exploration tool in a variety of settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606008</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606008</id><created>2006-06-01</created><updated>2006-11-02</updated><authors><author><keyname>Smith</keyname><forenames>Joan A.</forenames></author><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Repository Replication Using NNTP and SMTP</title><categories>cs.DL</categories><comments>This revised version has 24 figures and a more detailed discussion of
  the experiments conducted by us</comments><abstract>  We present the results of a feasibility study using shared, existing,
network-accessible infrastructure for repository replication. We investigate
how dissemination of repository contents can be ``piggybacked'' on top of
existing email and Usenet traffic. Long-term persistence of the replicated
repository may be achieved thanks to current policies and procedures which
ensure that mail messages and news posts are retrievable for evidentiary and
other legal purposes for many years after the creation date. While the
preservation issues of migration and emulation are not addressed with this
approach, it does provide a simple method of refreshing content with unknown
partners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606009</id><created>2006-06-01</created><updated>2006-08-16</updated><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>The Consequences of Eliminating NP Solutions</title><categories>cs.CC</categories><report-no>URCS TR-2006-898</report-no><acm-class>F.1.3; F.1.2; F.1.1</acm-class><abstract>  Given a function based on the computation of an NP machine, can one in
general eliminate some solutions? That is, can one in general decrease the
ambiguity? This simple question remains, even after extensive study by many
researchers over many years, mostly unanswered. However, complexity-theoretic
consequences and enabling conditions are known. In this tutorial-style article
we look at some of those, focusing on the most natural framings: reducing the
number of solutions of NP functions, refining the solutions of NP functions,
and subtracting from or otherwise shrinking #P functions. We will see how small
advice strings are important here, but we also will see how increasing advice
size to achieve robustness is central to the proof of a key ambiguity-reduction
result for NP functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606010</id><created>2006-06-01</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Abramov</keyname><forenames>V. A.</forenames></author><author><keyname>Fukuda</keyname><forenames>Y.</forenames></author><author><keyname>Konishi</keyname><forenames>K.</forenames></author></authors><title>A Decision-Making Support System Based on Know-How</title><categories>cs.CE cs.AI</categories><comments>6 pages, 5 figures. Preprint completed in 1997</comments><journal-ref>CIRP Journal of Manufacturing Systems. 1998, Vol. 27, No.4,
  427-432</journal-ref><abstract>  The research results described are concerned with: - developing a domain
modeling method and tools to provide the design and implementation of
decision-making support systems for computer integrated manufacturing; -
building a decision-making support system based on know-how and its software
environment. The research is funded by NEDO, Japan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606011</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606011</id><created>2006-06-02</created><updated>2006-09-19</updated><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Ma</keyname><forenames>Liang</forenames></author><author><keyname>Li</keyname><forenames>Jianhua</forenames></author></authors><title>Vectorial Resilient $PC(l)$ of Order $k$ Boolean Functions from AG-Codes</title><categories>cs.CR cs.IT math.IT</categories><comments>11 pages, new version, minor corrections</comments><abstract>  Propagation criterion of degree $l$ and order $k$ ($PC(l)$ of order $k$) and
resiliency of vectorial Boolean functions are important for cryptographic
purpose (see [1, 2, 3,6, 7,8,10,11,16]. Kurosawa, Stoh [8] and Carlet [1] gave
a construction of Boolean functions satisfying $PC(l)$ of order $k$ from binary
linear or nonlinear codes in. In this paper, algebraic-geometric codes over
$GF(2^m)$ are used to modify Carlet and Kurosawa-Satoh's construction for
giving vectorial resilient Boolean functions satisfying $PC(l)$ of order $k$.
The new construction is compared with previously known results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606012</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606012</id><created>2006-06-02</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>On the communication between cells of a cellular automaton on the penta-
  and heptagrids of the hyperbolic plane</title><categories>cs.CG cs.CC</categories><comments>19 pages, 6 figures</comments><acm-class>F.1.1; F.1.3</acm-class><journal-ref>Journal of Cellular Automata, 1(3), (2006), 213-232</journal-ref><abstract>  This contribution belongs to a combinatorial approach to hyperbolic geometry
and it is aimed at possible applications to computer simulations.
  It is based on the splitting method which was introduced by the author and
which is reminded in the second section of the paper. Then we sketchily remind
the application to the classical case of the pentagrid, i.e. the tiling of the
hyperbolic plane which is generated by reflections of the regular rectangular
pentagon in its sides and, recursively, of its images in their sides. From this
application, we derived a system of coordinates to locate the tiles, allowing
an implementation of cellular automata.
  At the software level, cells exchange messages thanks to a new representation
which improves the speed of contacts between cells. In the new setting,
communications are exchanged along actual geodesics and the contribution of the
cellular automaton is also linear in the coordinates of the cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606013</id><created>2006-06-02</created><authors><author><keyname>Abellanas</keyname><forenames>M.</forenames></author><author><keyname>Bajuelos</keyname><forenames>A.</forenames></author><author><keyname>Hern&#xe1;ndez</keyname><forenames>G.</forenames></author><author><keyname>Hurtado</keyname><forenames>F.</forenames></author><author><keyname>Matos</keyname><forenames>I.</forenames></author><author><keyname>Palop</keyname><forenames>B.</forenames></author></authors><title>Good Illumination of Minimum Range</title><categories>cs.CG</categories><acm-class>I.3.5</acm-class><abstract>  A point p is 1-well illuminated by a set F of n point lights if p lies in the
interior of the convex hull of F. This concept corresponds to triangle-guarding
or well-covering. In this paper we consider the illumination range of the light
sources as a parameter to be optimized. First, we solve the problem of
minimizing the light sources' illumination range to 1-well illuminate a given
point p. We also compute a minimal set of light sources that 1-well illuminates
p with minimum illumination range. Second, we solve the problem of minimizing
the light sources' illumination range to 1-well illuminate all the points of a
line segment with an O(n^2) algorithm. Finally, we give an O(n^2 log n)
algorithm for preprocessing the data so that one can obtain the illumination
range needed to 1-well illuminate a point of a line segment in O(log n) time.
These results can be applied to solve problems of 1-well illuminating a
trajectory by approaching it to a polygonal path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606014</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606014</id><created>2006-06-02</created><authors><author><keyname>Wu</keyname><forenames>Wei</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Arapostathis</keyname><forenames>Ari</forenames></author></authors><title>On the Capacity of Multiple Access Channels with State Information and
  Feedback</title><categories>cs.IT math.IT</categories><comments>Prelimenary result appears in ISIT 2006</comments><abstract>  In this paper, the multiple access channel (MAC) with channel state is
analyzed in a scenario where a) the channel state is known non-causally to the
transmitters and b) there is perfect causal feedback from the receiver to the
transmitters. An achievable region and an outer bound are found for a discrete
memoryless MAC that extend existing results, bringing together ideas from the
two separate domains of MAC with state and MAC with feedback. Although this
achievable region does not match the outer bound in general, special cases
where they meet are identified.
  In the case of a Gaussian MAC, a specialized achievable region is found by
using a combination of dirty paper coding and a generalization of the
Schalkwijk-Kailath, Ozarow and Merhav-Weissman schemes, and this region is
found to be capacity achieving. Specifically, it is shown that additive
Gaussian interference that is known non-causally to the transmitter causes no
loss in capacity for the Gaussian MAC with feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606015</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606015</id><created>2006-06-03</created><updated>2008-02-27</updated><authors><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author><author><keyname>Padakandla</keyname><forenames>Arun</forenames></author></authors><title>The Size of Optimal Sequence Sets for Synchronous CDMA Systems</title><categories>cs.IT math.IT</categories><comments>18 pages, 2 figures, technical report</comments><abstract>  The sum capacity on a symbol-synchronous CDMA system having processing gain
$N$ and supporting $K$ power constrained users is achieved by employing at most
$2N-1$ sequences. Analogously, the minimum received power (energy-per-chip) on
the symbol-synchronous CDMA system supporting $K$ users that demand specified
data rates is attained by employing at most $2N-1$ sequences. If there are $L$
oversized users in the system, at most $2N-L-1$ sequences are needed. $2N-1$ is
the minimum number of sequences needed to guarantee optimal allocation for
single dimensional signaling. $N$ orthogonal sequences are sufficient if a few
users (at most $N-1$) are allowed to signal in multiple dimensions. If there
are no oversized users, these split users need to signal only in two dimensions
each. The above results are shown by proving a converse to a well-known result
of Weyl on the interlacing eigenvalues of the sum of two Hermitian matrices,
one of which is of rank 1. The converse is analogous to Mirsky's converse to
the interlacing eigenvalues theorem for bordering matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606016</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606016</id><created>2006-06-04</created><authors><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Betz</keyname><forenames>Sharon M.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Performance Analysis of Iterative Channel Estimation and Multiuser
  Detection in Multipath DS-CDMA Channels</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2007.893229</doi><abstract>  This paper examines the performance of decision feedback based iterative
channel estimation and multiuser detection in channel coded aperiodic DS-CDMA
systems operating over multipath fading channels. First, explicit expressions
describing the performance of channel estimation and parallel interference
cancellation based multiuser detection are developed. These results are then
combined to characterize the evolution of the performance of a system that
iterates among channel estimation, multiuser detection and channel decoding.
Sufficient conditions for convergence of this system to a unique fixed point
are developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606017</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606017</id><created>2006-06-04</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Kakusho</keyname><forenames>K.</forenames></author></authors><title>From semiotics of hypermedia to physics of semiosis: A view from system
  theory</title><categories>cs.HC cs.CL cs.IT math.IT</categories><comments>46 pages, 5 figures; 2003 preprint</comments><journal-ref>Semiotica. 2005, Vol.154-1/4, 11-38</journal-ref><abstract>  Given that theoretical analysis and empirical validation is fundamental to
any model, whether conceptual or formal, it is surprising that these two tools
of scientific discovery are so often ignored in the contemporary studies of
communication. In this paper, we pursued the ideas of a) correcting and
expanding the modeling approaches of linguistics, which are otherwise
inapplicable (more precisely, which should not but are widely applied), to the
general case of hypermedia-based communication, and b) developing techniques
for empirical validation of semiotic models, which are nowadays routinely used
to explore (in fact, to conjecture about) internal mechanisms of complex
systems, yet on a purely speculative basis. This study thus offers two
experimentally tested substantive contributions: the formal representation of
communication as the mutually-orienting behavior of coupled autonomous systems,
and the mathematical interpretation of the semiosis of communication, which
together offer a concrete and parsimonious understanding of diverse
communication phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606018</id><created>2006-06-05</created><authors><author><keyname>Bauer</keyname><forenames>Matthias</forenames></author><author><keyname>Fabian</keyname><forenames>Benjamin</forenames></author><author><keyname>Fischmann</keyname><forenames>Matthias</forenames></author><author><keyname>G&#xfc;rses</keyname><forenames>Seda</forenames></author></authors><title>Emerging Markets for RFID Traces</title><categories>cs.CY cs.CR</categories><comments>submitted to WPES2006. Two figures are missing because of latex vs.
  pdflatex incompatibilities</comments><abstract>  RFID tags are held to become ubiquitous in logistics in the near future, and
item-level tagging will pave the way for Ubiquitous Computing, for example in
application fields like smart homes. Our paper addresses the value and the
production cost of information that can be gathered by observing these tags
over time and different locations. We argue that RFID technology will induce a
thriving market for such information, resulting in easy data access for
analysts to infer business intelligence and individual profiles of unusually
high detail. Understanding these information markets is important for many
reasons: They represent new business opportunities, and market players need to
be aware of their roles in these markets. Policy makers need to confirm that
the market structure will not negatively affect overall welfare. Finally,
though we are not addressing the complex issue of privacy, we are convinced
that market forces will have a significant impact on the effectiveness of
deployed security enhancements to RFID technology. In this paper we take a few
first steps into a relatively new field of economic research and conclude with
a list of research problems that promise deeper insights into the matter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606019</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606019</id><created>2006-06-05</created><updated>2007-02-09</updated><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author></authors><title>A synchronous pi-calculus</title><categories>cs.LO cs.PL</categories><proxy>ccsd ccsd-00078319</proxy><journal-ref>Journal of Information and Computation 205, 9 (2007) 1470-1490</journal-ref><abstract>  The SL synchronous programming model is a relaxation of the Esterel
synchronous model where the reaction to the absence of a signal within an
instant can only happen at the next instant. In previous work, we have
revisited the SL synchronous programming model. In particular, we have
discussed an alternative design of the model including thread spawning and
recursive definitions, introduced a CPS translation to a tail recursive form,
and proposed a notion of bisimulation equivalence. In the present work, we
extend the tail recursive model with first-order data types obtaining a
non-deterministic synchronous model whose complexity is comparable to the one
of the pi-calculus. We show that our approach to bisimulation equivalence can
cope with this extension and in particular that labelled bisimulation can be
characterised as a contextual bisimulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606020</id><created>2006-06-05</created><updated>2007-01-10</updated><authors><author><keyname>Astakhov</keyname><forenames>Vadim</forenames></author><author><keyname>Astakhova</keyname><forenames>Tamara</forenames></author><author><keyname>Sanders</keyname><forenames>Brian</forenames></author></authors><title>Imagination as Holographic Processor for Text Animation</title><categories>cs.AI</categories><comments>10 pages, 10 figures, prototype presented at 4th International
  Conference on Computer Science and its Applications (ICCSA-2006), paper
  submited to SIGCHI 2007</comments><abstract>  Imagination is the critical point in developing of realistic artificial
intelligence (AI) systems. One way to approach imagination would be simulation
of its properties and operations. We developed two models: AI-Brain Network
Hierarchy of Languages and Semantical Holographic Calculus as well as
simulation system ScriptWriter that emulate the process of imagination through
an automatic animation of English texts. The purpose of this paper is to
demonstrate the model and to present ScriptWriter system
http://nvo.sdsc.edu/NVO/JCSG/get_SRB_mime_file2.cgi//home/tamara.sdsc/test/demo.zip?F=/home/tamara.sdsc/test/demo.zip&amp;M=application/x-gtar
for simulation of the imagination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606021</id><created>2006-06-06</created><authors><author><keyname>Tamaki</keyname><forenames>H.</forenames></author><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Kitamura</keyname><forenames>S.</forenames></author></authors><title>A simulation engine to support production scheduling using
  genetics-based machine learning</title><categories>cs.CE cs.AI</categories><comments>8 pages, 2 figures, 1 table. Preprint completed in 1998</comments><journal-ref>In: K. Mertins, O. Krause, and B. Schallock (eds), Global
  Production Management, pp. 482-489. 1999, Kluwer Academic Publishers</journal-ref><abstract>  The ever higher complexity of manufacturing systems, continually shortening
life cycles of products and their increasing variety, as well as the unstable
market situation of the recent years require introducing grater flexibility and
responsiveness to manufacturing processes. From this perspective, one of the
critical manufacturing tasks, which traditionally attract significant attention
in both academia and the industry, but which have no satisfactory universal
solution, is production scheduling. This paper proposes an approach based on
genetics-based machine learning (GBML) to treat the problem of flow shop
scheduling. By the approach, a set of scheduling rules is represented as an
individual of genetic algorithms, and the fitness of the individual is
estimated based on the makespan of the schedule generated by using the
rule-set. A concept of the interactive software environment consisting of a
simulator and a GBML simulation engine is introduced to support human
decision-making during scheduling. A pilot study is underway to evaluate the
performance of the GBML technique in comparison with other methods (such as
Johnson's algorithm and simulated annealing) while completing test examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606022</identifier>
 <datestamp>2008-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606022</id><created>2006-06-06</created><updated>2008-05-02</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Limited Feedback Beamforming Over Temporally-Correlated Channels</title><categories>cs.IT math.IT</categories><comments>31 pages; submitted to IEEE Transactions on Signal Processing</comments><abstract>  Feedback of quantized channel state information (CSI), called limited
feedback, enables transmit beamforming in multiple-input-multiple-output (MIMO)
wireless systems with a small amount of overhead. Due to its efficiency,
beamforming with limited feedback has been adopted in several wireless
communication standards. Prior work on limited feedback commonly adopts the
block fading channel model where temporal correlation in wireless channels is
neglected. This paper considers temporally-correlated channels and designs
single-user transmit beamforming with limited feedback. Analytical results
concerning CSI feedback are derived by modeling quantized CSI as a first-order
finite-state Markov chain. These results include the source bit rate generated
by time-varying quantized CSI, the required bit rate for a CSI feedback
channel, and the effect of feedback delay. In particular, based on the theory
of Markov chain convergence rate, feedback delay is proved to reduce the
throughput gain due to CSI feedback at least exponentially. Furthermore, an
algorithm is proposed for CSI feedback compression in time. Combining the
results in this work leads to a new method for designing limited feedback
beamforming as demonstrated by a design example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606023</identifier>
 <datestamp>2015-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606023</id><created>2006-06-06</created><updated>2008-10-17</updated><authors><author><keyname>Maiti</keyname><forenames>Santanu K.</forenames></author></authors><title>Parallel Evaluation of Mathematica Programs in Remote Computers
  Available in Network</title><categories>cs.MS cs.PL</categories><comments>10 pages, 1 figure. arXiv admin note: substantial text overlap with
  arXiv:cs/0605090</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematica is a powerful application package for doing mathematics and is
used almost in all branches of science. It has widespread applications ranging
from quantum computation, statistical analysis, number theory, zoology,
astronomy, and many more. Mathematica gives a rich set of programming
extensions to its end-user language, and it permits us to write programs in
procedural, functional, or logic (rule-based) style, or a mixture of all three.
For tasks requiring interfaces to the external environment, mathematica
provides mathlink, which allows us to communicate mathematica programs with
external programs written in C, C++, F77, F90, F95, Java, or other languages.
It has also extensive capabilities for editing graphics, equations, text, etc.
  In this article, we explore the basic mechanisms of parallelization of a
mathematica program by sharing different parts of the program into all other
computers available in the network. Doing the parallelization, we can perform
large computational operations within a very short period of time, and
therefore, the efficiency of the numerical works can be achieved. Parallel
computation supports any version of mathematica and it also works as well even
if different versions of mathematica are installed in different computers. The
whole operation can run under any supported operating system like Unix,
Windows, Macintosh, etc. Here we focus our study only for the Unix based
operating system, but this method works as well for all other cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606024</id><created>2006-06-06</created><authors><author><keyname>de Graaf</keyname><forenames>Edgar</forenames></author><author><keyname>de Graaf</keyname><forenames>Jeannette</forenames></author><author><keyname>Kosters</keyname><forenames>Walter A.</forenames></author></authors><title>Consecutive Support: Better Be Close!</title><categories>cs.AI cs.DB</categories><comments>10 pages</comments><abstract>  We propose a new measure of support (the number of occur- rences of a
pattern), in which instances are more important if they occur with a certain
frequency and close after each other in the stream of trans- actions. We will
explain this new consecutive support and discuss how patterns can be found
faster by pruning the search space, for instance using so-called parent support
recalculation. Both consecutiveness and the notion of hypercliques are
incorporated into the Eclat algorithm. Synthetic examples show how interesting
phenomena can now be discov- ered in the datasets. The new measure can be
applied in many areas, ranging from bio-informatics to trade, supermarkets, and
even law en- forcement. E.g., in bio-informatics it is important to find
patterns con- tained in many individuals, where patterns close together in one
chro- mosome are more significant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606025</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606025</id><created>2006-06-06</created><authors><author><keyname>Zhang</keyname><forenames>Xiaowen</forenames></author><author><keyname>Shu</keyname><forenames>Li</forenames></author><author><keyname>Tang</keyname><forenames>Ke</forenames></author></authors><title>A Chaotic Cipher Mmohocc and Its Security Analysis</title><categories>cs.CR</categories><comments>14 pages, 4 figures, 4 tables</comments><doi>10.1117/12.717682</doi><abstract>  In this paper we introduce a new chaotic stream cipher Mmohocc which utilizes
the fundamental chaos characteristics. The designs of the major components of
the cipher are given. Its cryptographic properties of period, auto- and
cross-correlations, and the mixture of Markov processes and spatiotemporal
effects are investigated. The cipher is resistant to the related-key-IV
attacks, Time/Memory/Data tradeoff attacks, algebraic attacks, and chosen-text
attacks. The keystreams successfully passed two batteries of statistical tests
and the encryption speed is comparable with RC4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606026</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606026</id><created>2006-06-06</created><authors><author><keyname>Hollmann</keyname><forenames>Henk D. L.</forenames></author><author><keyname>Tolhuizen</keyname><forenames>Ludo M. G. M.</forenames></author></authors><title>Generating parity check equations for bounded-distance iterative erasure
  decoding</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in Proc Int Symposium on Information Theory
  2006, ISIT 06</comments><abstract>  A generic $(r,m)$-erasure correcting set is a collection of vectors in
$\bF_2^r$ which can be used to generate, for each binary linear code of
codimension $r$, a collection of parity check equations that enables iterative
decoding of all correctable erasure patterns of size at most $m$.
  That is to say, the only stopping sets of size at most $m$ for the generated
parity check equations are the erasure patterns for which there is more than
one manner to fill in theerasures to obtain a codeword.
  We give an explicit construction of generic $(r,m)$-erasure correcting sets
of cardinality $\sum_{i=0}^{m-1} {r-1\choose i}$. Using a random-coding-like
argument, we show that for fixed $m$, the minimum size of a generic
$(r,m)$-erasure correcting set is linear in $r$.
  Keywords: iterative decoding, binary erasure channel, stopping set
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606027</id><created>2006-06-06</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Kleshchev</keyname><forenames>A. S.</forenames></author><author><keyname>Fukuda</keyname><forenames>Y.</forenames></author><author><keyname>Konishi</keyname><forenames>K.</forenames></author></authors><title>Building a logical model in the machining domain for CAPP expert systems</title><categories>cs.AI cs.CE cs.SE</categories><comments>25 pages, 4 figures. Preprint completed in 1997</comments><journal-ref>International Journal of Production Research, 1998, vol. 36, No.
  4, 1075-1089</journal-ref><abstract>  Recently, extensive efforts have been made on the application of expert
system technique to solving the process planning task in the machining domain.
This paper introduces a new formal method to design CAPP expert systems. The
formal method is applied to provide a contour of the CAPP expert system
building technology. Theoretical aspects of the formalism are described and
illustrated by an example of know-how analysis. Flexible facilities to utilize
multiple knowledge types and multiple planning strategies within one system are
provided by the technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606028</id><created>2006-06-07</created><authors><author><keyname>Adutskevich</keyname><forenames>E. V.</forenames></author><author><keyname>Bakhanovich</keyname><forenames>S. V.</forenames></author><author><keyname>Likhoded</keyname><forenames>N. A.</forenames></author></authors><title>Affine Transformations of Loop Nests for Parallel Execution and
  Distribution of Data over Processors</title><categories>cs.DC</categories><comments>9 pages</comments><journal-ref>Preprint / The National Academy of Sciences of Belarus. Institute
  of Mathematics: N 3 (574). Minsk, 2005</journal-ref><abstract>  The paper is devoted to the problem of mapping affine loop nests onto
distributed memory parallel computers. A method to find affine transformations
of loop nests for parallel execution and distribution of data over processors
is presented. The method tends to minimize the number of communications between
processors and to improve locality of data within one processor. A problem of
determination of data exchange sequence is investigated. Conditions to
determine the ability to arrange broadcast is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606029</id><created>2006-06-07</created><authors><author><keyname>Josang</keyname><forenames>Audun</forenames></author></authors><title>Belief Calculus</title><categories>cs.AI</categories><comments>22 pages, 10 figures</comments><abstract>  In Dempster-Shafer belief theory, general beliefs are expressed as belief
mass distribution functions over frames of discernment. In Subjective Logic
beliefs are expressed as belief mass distribution functions over binary frames
of discernment. Belief representations in Subjective Logic, which are called
opinions, also contain a base rate parameter which express the a priori belief
in the absence of evidence. Philosophically, beliefs are quantitative
representations of evidence as perceived by humans or by other intelligent
agents. The basic operators of classical probability calculus, such as addition
and multiplication, can be applied to opinions, thereby making belief calculus
practical. Through the equivalence between opinions and Beta probability
density functions, this also provides a calculus for Beta probability density
functions. This article explains the basic elements of belief calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606030</id><created>2006-06-07</created><authors><author><keyname>Cortier</keyname><forenames>V&#xe9;ronique</forenames><affiliation>INRIA Lorraine - LORIA / LIFC</affiliation></author><author><keyname>H&#xf6;rdegen</keyname><forenames>Heinrich</forenames><affiliation>INRIA Lorraine - LORIA / LIFC</affiliation></author><author><keyname>Warinschi</keyname><forenames>Bogdan</forenames><affiliation>INRIA Lorraine - LORIA / LIFC</affiliation></author></authors><title>Explicit Randomness is not Necessary when Modeling Probabilistic
  Encryption</title><categories>cs.CR</categories><proxy>ccsd inria-00078825</proxy><abstract>  Although good encryption functions are probabilistic, most symbolic models do
not capture this aspect explicitly. A typical solution, recently used to prove
the soundness of such models with respect to computational ones, is to
explicitly represent the dependency of ciphertexts on random coins as labels.
In order to make these label-based models useful, it seems natural to try to
extend the underlying decision procedures and the implementation of existing
tools. In this paper we put forth a more practical alternative based on the
following soundness theorem. We prove that for a large class of security
properties (that includes rather standard formulations for secrecy and
authenticity properties), security of protocols in the simpler model implies
security in the label-based model. Combined with the soundness result of
(\textbf{?}) our theorem enables the translation of security results in
unlabeled symbolic models to computational security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606031</id><created>2006-06-07</created><authors><author><keyname>Moroz</keyname><forenames>Guillaume</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author></authors><title>Complexity of Resolution of Parametric Systems of Polynomial Equations
  and Inequations</title><categories>cs.SC</categories><proxy>ccsd inria-00078795</proxy><abstract>  Consider a system of n polynomial equations and r polynomial inequations in n
indeterminates of degree bounded by d with coefficients in a polynomial ring of
s parameters with rational coefficients of bit-size at most $\sigma$. From the
real viewpoint, solving such a system often means describing some
semi-algebraic sets in the parameter space over which the number of real
solutions of the considered parametric system is constant. Following the works
of Lazard and Rouillier, this can be done by the computation of a discriminant
variety. In this report we focus on the case where for a generic specialization
of the parameters the system of equations generates a radical zero-dimensional
ideal, which is usual in the applications. In this case, we provide a
deterministic method computing the minimal discriminant variety reducing the
problem to a problem of elimination. Moreover, we prove that the degree of the
computed minimal discriminant variety is bounded by $D:=(n+r)d^{(n+1)}$ and
that the complexity of our method is $\sigma^{\mathcal{O}(1)}
D^{\mathcal{O}(n+s)}$ bit-operations on a deterministic Turing machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606032</id><created>2006-06-07</created><authors><author><keyname>Hett</keyname><forenames>Christian</forenames></author><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>A secure archive for Voice-over-IP conversations</title><categories>cs.CR</categories><comments>9 pages, 2 figures. (C) ACM, (2006). This is the author's version of
  the work. It is posted here by permission of ACM for your personal use. Not
  for redistribution. The definitive version was published in Proceedings of
  VSW06, June, 2006, Berlin, Germany</comments><acm-class>C.2.0</acm-class><abstract>  An efficient archive securing the integrity of VoIP-based two-party
conversations is presented. The solution is based on chains of hashes and
continuously chained electronic signatures. Security is concentrated in a
single, efficient component, allowing for a detailed analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606033</id><created>2006-06-07</created><updated>2006-07-11</updated><authors><author><keyname>Calude</keyname><forenames>Cristian S.</forenames></author><author><keyname>Stay</keyname><forenames>Michael A.</forenames></author></authors><title>Natural Halting Probabilities, Partial Randomness, and Zeta Functions</title><categories>cs.CC</categories><comments>Accepted for publication in Information and Computing</comments><report-no>CDMTCS 273</report-no><acm-class>F.1.1; F.4.1</acm-class><abstract>  We introduce the zeta number, natural halting probability and natural
complexity of a Turing machine and we relate them to Chaitin's Omega number,
halting probability, and program-size complexity. A classification of Turing
machines according to their zeta numbers is proposed: divergent, convergent and
tuatara. We prove the existence of universal convergent and tuatara machines.
Various results on (algorithmic) randomness and partial randomness are proved.
For example, we show that the zeta number of a universal tuatara machine is
c.e. and random. A new type of partial randomness, asymptotic randomness, is
introduced. Finally we show that in contrast to classical (algorithmic)
randomness--which cannot be naturally characterised in terms of plain
complexity--asymptotic randomness admits such a characterisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606034</id><created>2006-06-08</created><updated>2007-01-12</updated><authors><author><keyname>Furon</keyname><forenames>Teddy</forenames><affiliation>IRISA</affiliation></author></authors><title>A constructive and unifying framework for zero-bit watermarking</title><categories>cs.MM cs.CR</categories><comments>submitted to IEEE Trans. on Information Forensics and Security</comments><proxy>ccsd inria-00078445</proxy><abstract>  In the watermark detection scenario, also known as zero-bit watermarking, a
watermark, carrying no hidden message, is inserted in content. The watermark
detector checks for the presence of this particular weak signal in content. The
article looks at this problem from a classical detection theory point of view,
but with side information enabled at the embedding side. This means that the
watermark signal is a function of the host content. Our study is twofold. The
first step is to design the best embedding function for a given detection
function, and the best detection function for a given embedding function. This
yields two conditions, which are mixed into one `fundamental' partial
differential equation. It appears that many famous watermarking schemes are
indeed solution to this `fundamental' equation. This study thus gives birth to
a constructive framework unifying solutions, so far perceived as very
different.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606035</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606035</id><created>2006-06-08</created><authors><author><keyname>Fedorenko</keyname><forenames>Sergei V.</forenames></author><author><keyname>Trifonov</keyname><forenames>Piter V.</forenames></author></authors><title>Finding roots of polynomials over finite fields</title><categories>cs.IT math.IT</categories><comments>6 pages. IEEE Transactions on Communications</comments><journal-ref>IEEE Transactions on Communications, Volume 50, Issue 11, Nov.
  2002, Pages:1709 - 1711</journal-ref><doi>10.1109/TCOMM.2002.805269</doi><abstract>  We propose an improved algorithm for finding roots of polynomials over finite
fields. This makes possible significant speedup of the decoding process of
Bose-Chaudhuri-Hocquenghem, Reed-Solomon, and some other error-correcting
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606036</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606036</id><created>2006-06-08</created><authors><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author><author><keyname>Moa</keyname><forenames>B.</forenames></author></authors><title>Computational Euclid</title><categories>cs.CG</categories><comments>8 pages, 3 figures</comments><report-no>DCS-315-IR</report-no><acm-class>I.3.5; G.1.0</acm-class><abstract>  We analyse the axioms of Euclidean geometry according to standard
object-oriented software development methodology. We find a perfect match: the
main undefined concepts of the axioms translate to object classes. The result
is a suite of C++ classes that efficiently supports the construction of complex
geometric configurations. Although all computations are performed in
floating-point arithmetic, they correctly implement as semi-decision algorithms
the tests for equality of points, a point being on a line or in a plane, a line
being in a plane, parallelness of lines, of a line and a plane, and of planes.
That is, in accordance to the fundamental limitations to computability
requiring that only negative outcomes are given with certainty, while positive
outcomes only imply possibility of these conditions being true.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606037</id><created>2006-06-08</created><updated>2006-09-29</updated><authors><author><keyname>Bogdanov</keyname><forenames>Andrej</forenames></author><author><keyname>Trevisan</keyname><forenames>Luca</forenames></author></authors><title>Average-Case Complexity</title><categories>cs.CC</categories><abstract>  We survey the average-case complexity of problems in NP.
  We discuss various notions of good-on-average algorithms, and present
completeness results due to Impagliazzo and Levin. Such completeness results
establish the fact that if a certain specific (but somewhat artificial) NP
problem is easy-on-average with respect to the uniform distribution, then all
problems in NP are easy-on-average with respect to all samplable distributions.
Applying the theory to natural distributional problems remain an outstanding
open question. We review some natural distributional problems whose
average-case complexity is of particular interest and that do not yet fit into
this theory.
  A major open question whether the existence of hard-on-average problems in NP
can be based on the P$\neq$NP assumption or on related worst-case assumptions.
We review negative results showing that certain proof techniques cannot prove
such a result. While the relation between worst-case and average-case
complexity for general NP problems remains open, there has been progress in
understanding the relation between different ``degrees'' of average-case
complexity. We discuss some of these ``hardness amplification'' results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606038</id><created>2006-06-08</created><authors><author><keyname>Thite</keyname><forenames>Shripad</forenames></author></authors><title>Tight Bounds on the Complexity of Recognizing Odd-Ranked Elements</title><categories>cs.CC cs.DS</categories><comments>3 pages</comments><abstract>  Let S = &lt;s_1, s_2, s_3, ..., s_n&gt; be a given vector of n real numbers. The
rank of a real z with respect to S is defined as the number of elements s_i in
S such that s_i is less than or equal to z. We consider the following decision
problem: determine whether the odd-numbered elements s_1, s_3, s_5, ... are
precisely the elements of S whose rank with respect to S is odd. We prove a
bound of Theta(n log n) on the number of operations required to solve this
problem in the algebraic computation tree model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606039</id><created>2006-06-09</created><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Tamaki</keyname><forenames>H.</forenames></author><author><keyname>Kitamura</keyname><forenames>S.</forenames></author></authors><title>Evolutionary Design: Philosophy, Theory, and Application Tactics</title><categories>cs.CE cs.AI</categories><comments>6 pages, 3 figures. Preprint completed in 1999</comments><journal-ref>CIRP Journal of Manufacturing Systems, 2005, Vol. 34/2</journal-ref><abstract>  Although it has contributed to remarkable improvements in some specific
areas, attempts to develop a universal design theory are generally
characterized by failure. This paper sketches arguments for a new approach to
engineering design based on Semiotics - the science about signs. The approach
is to combine different design theories over all the product life cycle stages
into one coherent and traceable framework. Besides, it is to bring together the
designer's and user's understandings of the notion of 'good product'. Building
on the insight from natural sciences that complex systems always exhibit a
self-organizing meaning-influential hierarchical dynamics, objective laws
controlling product development are found through an examination of design as a
semiosis process. These laws are then applied to support evolutionary design of
products. An experiment validating some of the theoretical findings is
outlined, and concluding remarks are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606040</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606040</id><created>2006-06-09</created><updated>2007-08-09</updated><authors><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author><author><keyname>Ram</keyname><forenames>L. Shankar</forenames></author></authors><title>Approximation Algorithms for Multi-Criteria Traveling Salesman Problems</title><categories>cs.DS cs.CC</categories><comments>To appear in Algorithmica. A preliminary version has been presented
  at the 4th Workshop on Approximation and Online Algorithms (WAOA 2006)</comments><acm-class>F.2.2; G.2.1; G.2.2</acm-class><abstract>  In multi-criteria optimization problems, several objective functions have to
be optimized. Since the different objective functions are usually in conflict
with each other, one cannot consider only one particular solution as the
optimal solution. Instead, the aim is to compute a so-called Pareto curve of
solutions. Since Pareto curves cannot be computed efficiently in general, we
have to be content with approximations to them.
  We design a deterministic polynomial-time algorithm for multi-criteria
g-metric STSP that computes (min{1 +g, 2g^2/(2g^2 -2g +1)} + eps)-approximate
Pareto curves for all 1/2&lt;=g&lt;=1. In particular, we obtain a
(2+eps)-approximation for multi-criteria metric STSP. We also present two
randomized approximation algorithms for multi-criteria g-metric STSP that
achieve approximation ratios of (2g^3 +2g^2)/(3g^2 -2g +1) + eps and (1 +g)/(1
+3g -4g^2) + eps, respectively.
  Moreover, we present randomized approximation algorithms for multi-criteria
g-metric ATSP (ratio 1/2 + g^3/(1 -3g^2) + eps) for g &lt; 1/sqrt(3)), STSP with
weights 1 and 2 (ratio 4/3) and ATSP with weights 1 and 2 (ratio 3/2). To do
this, we design randomized approximation schemes for multi-criteria cycle cover
and graph factor problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606041</id><created>2006-06-09</created><authors><author><keyname>Chen</keyname><forenames>Ming-Zhe</forenames></author></authors><title>Characterization of Pentagons Determined by Two X-rays</title><categories>cs.CG</categories><comments>4 pages, 2 figures</comments><abstract>  This paper contains some results of pentagons which can be determined by two
X-rays. The results reveal this problem is more complicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606042</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606042</id><created>2006-06-09</created><authors><author><keyname>Hascoet</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Araya-Polo</keyname><forenames>Mauricio</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Enabling user-driven Checkpointing strategies in Reverse-mode Automatic
  Differentiation</title><categories>cs.DS</categories><proxy>ccsd inria-00079223</proxy><abstract>  This paper presents a new functionality of the Automatic Differentiation (AD)
tool Tapenade. Tapenade generates adjoint codes which are widely used for
optimization or inverse problems. Unfortunately, for large applications the
adjoint code demands a great deal of memory, because it needs to store a large
set of intermediates values. To cope with that problem, Tapenade implements a
sub-optimal version of a technique called checkpointing, which is a trade-off
between storage and recomputation. Our long-term goal is to provide an optimal
checkpointing strategy for every code, not yet achieved by any AD tool. Towards
that goal, we first introduce modifications in Tapenade in order to give the
user the choice to select the checkpointing strategy most suitable for their
code. Second, we conduct experiments in real-size scientific codes in order to
gather hints that help us to deduce an optimal checkpointing strategy. Some of
the experimental results show memory savings up to 35% and execution time up to
90%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606043</id><created>2006-06-09</created><authors><author><keyname>Artigues</keyname><forenames>Christian</forenames><affiliation>LIA</affiliation></author><author><keyname>Lopez</keyname><forenames>Pierre</forenames><affiliation>LAAS</affiliation></author><author><keyname>Ayache</keyname><forenames>Pierre-Dimitri</forenames><affiliation>LIA</affiliation></author></authors><title>Schedule generation schemes for the job-shop problem with
  sequence-dependent setup times: dominance properties and computational
  analysis</title><categories>cs.CC math.CO</categories><proxy>ccsd ccsd-00022742</proxy><journal-ref>Annals of Operations Research 138 (2005) 21-52</journal-ref><abstract>  We consider the job-shop problem with sequence-dependent setup times. We
focus on the formal definition of schedule generation schemes (SGSs) based on
the semi-active, active, and non-delay schedule categories. We study dominance
properties of the sets of schedules obtainable with each SGS. We show how the
proposed SGSs can be used within single-pass and multi-pass priority rule based
heuristics. We study several priority rules for the problem and provide a
comparative computational analysis of the different SGSs on sets of instances
taken from the literature. The proposed SGSs significantly improve previously
best-known results on a set of hard benchmark instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606044</identifier>
 <datestamp>2007-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606044</id><created>2006-06-09</created><updated>2007-07-23</updated><authors><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Goldberg</keyname><forenames>Paul W.</forenames></author></authors><title>Frugality ratios and improved truthful mechanisms for vertex cover</title><categories>cs.GT</categories><comments>26 pages, 5 figures (minor revision of the previous version)</comments><abstract>  In {\em set-system auctions}, there are several overlapping teams of agents,
and a task that can be completed by any of these teams. The buyer's goal is to
hire a team and pay as little as possible. Recently, Karlin, Kempe and Tamir
introduced a new definition of {\em frugality ratio} for this setting.
Informally, the frugality ratio is the ratio of the total payment of a
mechanism to perceived fair cost. In this paper, we study this together with
alternative notions of fair cost, and how the resulting frugality ratios relate
to each other for various kinds of set systems.
  We propose a new truthful polynomial-time auction for the vertex cover
problem (where the feasible sets correspond to the vertex covers of a given
graph), based on the {\em local ratio} algorithm of Bar-Yehuda and Even. The
mechanism guarantees to find a winning set whose cost is at most twice the
optimal. In this situation, even though it is NP-hard to find a lowest-cost
feasible set, we show that {\em local optimality} of a solution can be used to
derive frugality bounds that are within a constant factor of best possible. To
prove this result, we use our alternative notions of frugality via a
bootstrapping technique, which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606045</id><created>2006-06-10</created><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Trusted Computing in Mobile Action</title><categories>cs.CR</categories><comments>In: Peer-reviewed Proceedings of the Information Security South
  Africa (ISSA) 2006 From Insight to Foresight Conference, 5 to 7 July 2006,
  Sandton, South Africa</comments><acm-class>C.2.0</acm-class><abstract>  Due to the convergence of various mobile access technologies like UMTS, WLAN,
and WiMax the need for a new supporting infrastructure arises. This
infrastructure should be able to support more efficient ways to authenticate
users and devices, potentially enabling novel services based on the security
provided by the infrastructure. In this paper we exhibit some usage scenarios
from the mobile domain integrating trusted computing, which show that trusted
computing offers new paradigms for implementing trust and by this enables new
technical applications and business scenarios. The scenarios show how the
traditional boundaries between technical and authentication domains become
permeable while a high security level is maintained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606046</id><created>2006-06-10</created><authors><author><keyname>Piechalski</keyname><forenames>Jan</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Authorised Translations of Electronic Documents</title><categories>cs.OH</categories><comments>In: Peer-reviewed Proceedings of the Information Security South
  Africa (ISSA) 2006 From Insight to Foresight Conference, 5 to 7 July 2006,
  Sandton, South Africa</comments><acm-class>H.4.1; K.6.5</acm-class><abstract>  A concept is proposed to extend authorised translations of documents to
electronically signed, digital documents. Central element of the solution is an
electronic seal, embodied as an XML data structure, which attests to the
correctness of the translation and the authorisation of the translator. The
seal contains a digital signature binding together original and translated
document, thus enabling forensic inspection and therefore legal security in the
appropriation of the translation. Organisational aspects of possible
implementation variants of electronic authorised translations are discussed and
a realisation as a stand-alone web-service is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606047</id><created>2006-06-11</created><authors><author><keyname>Kollias</keyname><forenames>Giorgos</forenames></author><author><keyname>Gallopoulos</keyname><forenames>Efstratios</forenames></author><author><keyname>Szyld</keyname><forenames>Daniel B.</forenames></author></authors><title>Asynchronous iterative computations with Web information retrieval
  structures: The PageRank case</title><categories>cs.DC</categories><comments>8 pages to appear at ParCo2005 Conference Proceedings</comments><report-no>TR HPCLAB-SCG 5/08-05</report-no><abstract>  There are several ideas being used today for Web information retrieval, and
specifically in Web search engines. The PageRank algorithm is one of those that
introduce a content-neutral ranking function over Web pages. This ranking is
applied to the set of pages returned by the Google search engine in response to
posting a search query. PageRank is based in part on two simple common sense
concepts: (i)A page is important if many important pages include links to it.
(ii)A page containing many links has reduced impact on the importance of the
pages it links to. In this paper we focus on asynchronous iterative schemes to
compute PageRank over large sets of Web pages. The elimination of the
synchronizing phases is expected to be advantageous on heterogeneous platforms.
The motivation for a possible move to such large scale distributed platforms
lies in the size of matrices representing Web structure. In orders of
magnitude: $10^{10}$ pages with $10^{11}$ nonzero elements and $10^{12}$ bytes
just to store a small percentage of the Web (the already crawled); distributed
memory machines are necessary for such computations. The present research is
part of our general objective, to explore the potential of asynchronous
computational models as an underlying framework for very large scale
computations over the Grid. The area of ``internet algorithmics'' appears to
offer many occasions for computations of unprecedent dimensionality that would
be good candidates for this framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606048</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606048</id><created>2006-06-11</created><authors><author><keyname>Cilibrasi</keyname><forenames>Rudi</forenames></author><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames></author></authors><title>A New Quartet Tree Heuristic for Hierarchical Clustering</title><categories>cs.DS cs.CV cs.DM math.ST physics.data-an q-bio.QM stat.TH</categories><comments>22 pages, 14 figures</comments><acm-class>F.2.2; G.1.6</acm-class><abstract>  We consider the problem of constructing an an optimal-weight tree from the
3*(n choose 4) weighted quartet topologies on n objects, where optimality means
that the summed weight of the embedded quartet topologiesis optimal (so it can
be the case that the optimal tree embeds all quartets as non-optimal
topologies). We present a heuristic for reconstructing the optimal-weight tree,
and a canonical manner to derive the quartet-topology weights from a given
distance matrix. The method repeatedly transforms a bifurcating tree, with all
objects involved as leaves, achieving a monotonic approximation to the exact
single globally optimal tree. This contrasts to other heuristic search methods
from biological phylogeny, like DNAML or quartet puzzling, which, repeatedly,
incrementally construct a solution from a random order of objects, and
subsequently add agreement values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606049</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606049</id><created>2006-06-12</created><authors><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Vinod</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Decentralized Erasure Codes for Distributed Networked Storage</title><categories>cs.IT cs.NI math.IT</categories><comments>to appear in IEEE Transactions on Information Theory, Special Issue:
  Networking and Information Theory</comments><abstract>  We consider the problem of constructing an erasure code for storage over a
network when the data sources are distributed. Specifically, we assume that
there are n storage nodes with limited memory and k&lt;n sources generating the
data. We want a data collector, who can appear anywhere in the network, to
query any k storage nodes and be able to retrieve the data. We introduce
Decentralized Erasure Codes, which are linear codes with a specific randomized
structure inspired by network coding on random bipartite graphs. We show that
decentralized erasure codes are optimally sparse, and lead to reduced
communication, storage and computation cost over random linear coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606050</id><created>2006-06-11</created><updated>2006-10-06</updated><authors><author><keyname>Manyem</keyname><forenames>Prabhu</forenames></author></authors><title>Syntactic Characterisations of Polynomial-Time Optimisation Classes
  (Syntactic Characterizations of Polynomial-Time Optimization Classes)</title><categories>cs.CC cs.LO</categories><comments>17 pages; presented at the July 2005 ACiD workshop at Durham,
  England; Included both American and British commonwealth spellings, so as to
  generate hits from readers in North America as well as from Commonwealth
  countries and Europe</comments><acm-class>F.1.3</acm-class><abstract>  In Descriptive Complexity, there is a vast amount of literature on decision
problems, and their classes such as \textbf{P, NP, L and NL}. ~ However,
research on the descriptive complexity of optimisation problems has been
limited. Optimisation problems corresponding to the \textbf{NP} class have been
characterised in terms of logic expressions by Papadimitriou and Yannakakis,
Panconesi and Ranjan, Kolaitis and Thakur, Khanna et al, and by Zimand.
Gr\&quot;{a}del characterised the polynomial class \textbf{P} of decision problems.
In this paper, we attempt to characterise the optimisation versions of
\textbf{P} via expressions in second order logic, many of them using universal
Horn formulae with successor relations. The polynomially bound versions of
maximisation (maximization) and minimisation (minimization) problems are
treated first, and then the maximisation problems in the &quot;not necessarily
polynomially bound&quot; class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606051</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606051</id><created>2006-06-12</created><updated>2006-11-11</updated><authors><author><keyname>Xia</keyname><forenames>Shu-Tao</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>Minimum Pseudo-Weight and Minimum Pseudo-Codewords of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>17 pages, 1 figure</comments><abstract>  In this correspondence, we study the minimum pseudo-weight and minimum
pseudo-codewords of low-density parity-check (LDPC) codes under linear
programming (LP) decoding. First, we show that the lower bound of Kelly,
Sridhara, Xu and Rosenthal on the pseudo-weight of a pseudo-codeword of an LDPC
code with girth greater than 4 is tight if and only if this pseudo-codeword is
a real multiple of a codeword. Then, we show that the lower bound of Kashyap
and Vardy on the stopping distance of an LDPC code is also a lower bound on the
pseudo-weight of a pseudo-codeword of this LDPC code with girth 4, and this
lower bound is tight if and only if this pseudo-codeword is a real multiple of
a codeword. Using these results we further show that for some LDPC codes, there
are no other minimum pseudo-codewords except the real multiples of minimum
codewords. This means that the LP decoding for these LDPC codes is
asymptotically optimal in the sense that the ratio of the probabilities of
decoding errors of LP decoding and maximum-likelihood decoding approaches to 1
as the signal-to-noise ratio leads to infinity. Finally, some LDPC codes are
listed to illustrate these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606052</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606052</id><created>2006-06-12</created><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Aldosari</keyname><forenames>Saeed</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author></authors><title>Topology for Distributed Inference on Graphs</title><categories>cs.IT math.IT</categories><comments>Submitted for Journal publication</comments><abstract>  Let $N$ local decision makers in a sensor network communicate with their
neighbors to reach a decision \emph{consensus}. Communication is local, among
neighboring sensors only, through noiseless or noisy links. We study the design
of the network topology that optimizes the rate of convergence of the iterative
decision consensus algorithm. We reformulate the topology design problem as a
spectral graph design problem, namely, maximizing the eigenratio~$\gamma$ of
two eigenvalues of the graph Laplacian~$L$, a matrix that is naturally
associated with the interconnectivity pattern of the network. This
reformulation avoids costly Monte Carlo simulations and leads to the class of
non-bipartite Ramanujan graphs for which we find a lower bound on~$\gamma$. For
Ramanujan topologies and noiseless links, the local probability of error
converges much faster to the overall global probability of error than for
structured graphs, random graphs, or graphs exhibiting small-world
characteristics. With noisy links, we determine the optimal number of
iterations before calling a decision. Finally, we introduce a new class of
random graphs that are easy to construct, can be designed with arbitrary number
of sensors, and whose spectral and convergence properties make them practically
equivalent to Ramanujan topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606053</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606053</id><created>2006-06-12</created><updated>2006-07-19</updated><authors><author><keyname>Carayol</keyname><forenames>Arnaud</forenames></author><author><keyname>Meyer</keyname><forenames>Antoine</forenames></author></authors><title>Context-Sensitive Languages, Rational Graphs and Determinism</title><categories>cs.LO</categories><acm-class>F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 2 (July 19,
  2006) lmcs:1197</journal-ref><doi>10.2168/LMCS-2(2:6)2006</doi><abstract>  We investigate families of infinite automata for context-sensitive languages.
An infinite automaton is an infinite labeled graph with two sets of initial and
final vertices. Its language is the set of all words labelling a path from an
initial vertex to a final vertex. In 2001, Morvan and Stirling proved that
rational graphs accept the context-sensitive languages between rational sets of
initial and final vertices. This result was later extended to sub-families of
rational graphs defined by more restricted classes of transducers.
languages.&lt;br&gt;&lt;br&gt;
  Our contribution is to provide syntactical and self-contained proofs of the
above results, when earlier constructions relied on a non-trivial normal form
of context-sensitive grammars defined by Penttonen in the 1970's. These new
proof techniques enable us to summarize and refine these results by considering
several sub-families defined by restrictions on the type of transducers, the
degree of the graph or the size of the set of initial vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606054</id><created>2006-06-12</created><authors><author><keyname>Lu</keyname><forenames>Qiming</forenames></author><author><keyname>Korniss</keyname><forenames>Gyorgy</forenames></author><author><keyname>Szymanski</keyname><forenames>Boleslaw K.</forenames></author></authors><title>Threshold-Controlled Global Cascading in Wireless Sensor Networks</title><categories>cs.NI</categories><journal-ref>Proceeding of third International Conference on Networked Sensing
  Systems, 164-171 (TRF, 2006)</journal-ref><abstract>  We investigate cascade dynamics in threshold-controlled (multiplex)
propagation on random geometric networks. We find that such local dynamics can
serve as an efficient, robust, and reliable prototypical activation protocol in
sensor networks in responding to various alarm scenarios. We also consider the
same dynamics on a modified network by adding a few long-range communication
links, resulting in a small-world network. We find that such construction can
further enhance and optimize the speed of the network's response, while keeping
energy consumption at a manageable level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606055</id><created>2006-06-12</created><authors><author><keyname>Gallier</keyname><forenames>Jean</forenames></author></authors><title>Simple Methods For Drawing Rational Surfaces as Four or Six Bezier
  Patches</title><categories>cs.CG cs.GR</categories><comments>33 pages</comments><abstract>  In this paper, we give several simple methods for drawing a whole rational
surface (without base points) as several Bezier patches. The first two methods
apply to surfaces specified by triangular control nets and partition the real
projective plane RP2 into four and six triangles respectively. The third method
applies to surfaces specified by rectangular control nets and partitions the
torus RP1 X RP1 into four rectangular regions. In all cases, the new control
nets are obtained by sign flipping and permutation of indices from the original
control net. The proofs that these formulae are correct involve very little
computations and instead exploit the geometry of the parameter space (RP2 or
RP1 X RP1). We illustrate our method on some classical examples. We also
propose a new method for resolving base points using a simple ``blowing up''
technique involving the computation of ``resolved'' control nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606056</id><created>2006-06-12</created><authors><author><keyname>Gallier</keyname><forenames>Jean</forenames></author><author><keyname>Gu</keyname><forenames>Weqing</forenames></author></authors><title>Fast and Simple Methods For Computing Control Points</title><categories>cs.CC cs.GR</categories><comments>15 pages</comments><abstract>  The purpose of this paper is to present simple and fast methods for computing
control points for polynomial curves and polynomial surfaces given explicitly
in terms of polynomials (written as sums of monomials). We give recurrence
formulae w.r.t. arbitrary affine frames. As a corollary, it is amusing that we
can also give closed-form expressions in the case of the frame (r, s) for
curves, and the frame ((1, 0, 0), (0, 1, 0), (0, 0, 1) for surfaces. Our
methods have the same low polynomial (time and space) complexity as the other
best known algorithms, and are very easy to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606057</id><created>2006-06-13</created><authors><author><keyname>Kuivinen</keyname><forenames>Fredrik</forenames></author></authors><title>Approximability of Bounded Occurrence Max Ones</title><categories>cs.CC</categories><comments>Accepted to MFCS 2006</comments><abstract>  We study the approximability of Max Ones when the number of variable
occurrences is bounded by a constant. For conservative constraint languages
(i.e., when the unary relations are included) we give a complete classification
when the number of occurrences is three or more and a partial classification
when the bound is two.
  For the non-conservative case we prove that it is either trivial or
equivalent to the corresponding conservative problem under polynomial-time
many-one reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606058</id><created>2006-06-13</created><authors><author><keyname>Chapdelaine</keyname><forenames>Philippe</forenames></author><author><keyname>Grandjean</keyname><forenames>Etienne</forenames></author></authors><title>Lower bounds and complete problems in nondeterministic linear time and
  sublinear space complexity classes</title><categories>cs.CC cs.LO</categories><comments>19 pages, 4 figures</comments><acm-class>F.1.3; F.4.1</acm-class><abstract>  Proving lower bounds remains the most difficult of tasks in computational
complexity theory. In this paper, we show that whereas most natural NP-complete
problems belong to NLIN (linear time on nondeterministic RAMs), some of them,
typically the planar versions of many NP-complete problems are recognized by
nondeterministic RAMs in linear time and sublinear space. The main results of
this paper are the following: as the second author did for NLIN, we give exact
logical characterizations of nondeterministic polynomial time-space complexity
classes; we derive from them a class of problems, which are complete in these
classes, and as a consequence of such a precise result and of some recent
separation theorems using diagonalization, prove time-space lower bounds for
these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606059</identifier>
 <datestamp>2007-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606059</id><created>2006-06-13</created><updated>2007-08-13</updated><authors><author><keyname>Aanjaneya</keyname><forenames>Mridul</forenames></author></authors><title>Tromino tilings of Domino-Deficient Rectangles</title><categories>cs.DM math.CO</categories><comments>19 pages, 13 figures</comments><report-no>Technical Report no. IIT/CSE/TR/2006/MA/1, June 05, 2006, Dept. of
  Computer Sc. and Engg., IIT Kharagpur 721302, India</report-no><abstract>  We consider tromino tilings of $m\times n$ domino-deficient rectangles, where
$3|(mn-2)$ and $m,n\geq0$, and characterize all cases of domino removal that
admit such tilings, thereby settling the open problem posed by J. M. Ash and S.
Golomb in \cite {marshall}. Based on this characterization, we design a
procedure for constructing such a tiling if one exists. We also consider the
problem of counting such tilings and derive the exact formula for the number of
tilings for $2\times(3t+1)$ rectangles, the exact generating function for
$4\times(3t+2)$ rectangles, where $t\geq0$, and an upper bound on the number of
tromino tilings for $m\times n$ domino-deficient rectangles. We also consider
general 2-deficiency in $n\times4$ rectangles, where $n\geq8$, and characterize
all pairs of squares which do not permit a tromino tiling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606060</id><created>2006-06-13</created><authors><author><keyname>Costa</keyname><forenames>Luciano da Fontoura</forenames></author></authors><title>Complex Networks: New Concepts and Tools for Real-Time Imaging and
  Vision</title><categories>cs.CV cs.DC physics.soc-ph</categories><comments>3 pages</comments><abstract>  This article discusses how concepts and methods of complex networks can be
applied to real-time imaging and computer vision. After a brief introduction of
complex networks basic concepts, their use as means to represent and
characterize images, as well as for modeling visual saliency, are briefly
described. The possibility to apply complex networks in order to model and
simulate the performance of parallel and distributed computing systems for
performance of visual methods is also proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606061</id><created>2006-06-13</created><authors><author><keyname>Gallier</keyname><forenames>Jean</forenames></author></authors><title>On the Efficiency of Strategies for Subdividing Polynomial Triangular
  Surface Patches</title><categories>cs.CG cs.GR</categories><comments>20 pages</comments><abstract>  In this paper, we investigate the efficiency of various strategies for
subdividing polynomial triangular surface patches. We give a simple algorithm
performing a regular subdivision in four calls to the standard de Casteljau
algorithm (in its subdivision version). A naive version uses twelve calls. We
also show that any method for obtaining a regular subdivision using the
standard de Casteljau algorithm requires at least 4 calls. Thus, our method is
optimal. We give another subdivision algorithm using only three calls to the de
Casteljau algorithm. Instead of being regular, the subdivision pattern is
diamond-like. Finally, we present a ``spider-like'' subdivision scheme
producing six subtriangles in four calls to the de Casteljau algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606062</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606062</id><created>2006-06-13</created><updated>2006-07-26</updated><authors><author><keyname>Libkin</keyname><forenames>Leonid</forenames></author></authors><title>Logics for Unranked Trees: An Overview</title><categories>cs.LO cs.DB</categories><acm-class>H.2.3; H.2.1; I.7; F.2.3; F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 3 (July 26,
  2006) lmcs:810</journal-ref><doi>10.2168/LMCS-2(3:2)2006</doi><abstract>  Labeled unranked trees are used as a model of XML documents, and logical
languages for them have been studied actively over the past several years. Such
logics have different purposes: some are better suited for extracting data,
some for expressing navigational properties, and some make it easy to relate
complex properties of trees to the existence of tree automata for those
properties. Furthermore, logics differ significantly in their model-checking
properties, their automata models, and their behavior on ordered and unordered
trees. In this paper we present a survey of logics for unranked trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606063</id><created>2006-06-13</created><authors><author><keyname>Slagell</keyname><forenames>Adam</forenames></author><author><keyname>Lakkaraju</keyname><forenames>Kiran</forenames></author><author><keyname>Luo</keyname><forenames>Katherine</forenames></author></authors><title>FLAIM: A Multi-level Anonymization Framework for Computer and Network
  Logs</title><categories>cs.CR</categories><comments>16 pages, 4 figures, in submission to USENIX Lisa</comments><abstract>  FLAIM (Framework for Log Anonymization and Information Management) addresses
two important needs not well addressed by current log anonymizers. First, it is
extremely modular and not tied to the specific log being anonymized. Second, it
supports multi-level anonymization, allowing system administrators to make
fine-grained trade-offs between information loss and privacy/security concerns.
In this paper, we examine anonymization solutions to date and note the above
limitations in each. We further describe how FLAIM addresses these problems,
and we describe FLAIM's architecture and features in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606064</id><created>2006-06-14</created><authors><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Tian</forenames></author><author><keyname>Peng</keyname><forenames>Han</forenames></author><author><keyname>Sun</keyname><forenames>Hongtao</forenames></author><author><keyname>Zhu</keyname><forenames>Jiaqi</forenames></author></authors><title>Improved Exponential Time Lower Bound of Knapsack Problem under BT model</title><categories>cs.CC</categories><comments>9 pages, 3 figures</comments><acm-class>F.2.2</acm-class><abstract>  M.Alekhnovich et al. recently have proposed a model of algorithms, called BT
model, which covers Greedy, Backtrack and Simple Dynamic Programming methods
and can be further divided into fixed, adaptive and fully adaptive three kinds,
and have proved exponential time lower bounds of exact and approximation
algorithms under adaptive BT model for Knapsack problem which are
$\Omega(2^{n/2}/\sqrt n)=\Omega(2^{0.5n}/\sqrt n)$ and
$\Omega((1/\epsilon)^{1/3.17})\approx\Omega((1/\epsilon)^{0.315})$(for
approximation ratio $1-\epsilon$) respectively (M. Alekhovich, A. Borodin, J.
Buresh-Oppenheim, R. Impagliazzo, A. Magen, and T. Pitassi, Toward a Model for
Backtracking and Dynamic Programming, \emph{Proceedings of Twentieth Annual
IEEE Conference on Computational Complexity}, pp308-322, 2005). In this note,
we slightly improved their lower bounds to
$\Omega(2^{(2-\epsilon)n/3}/\sqrt{n})\approx \Omega(2^{0.66n}/\sqrt{n})$ and
$\Omega((1/\epsilon)^{1/2.38})\approx\Omega((1/\epsilon)^{0.420})$, and
proposed as an open question what is the best achievable lower bounds for
knapsack under adaptive BT models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606065</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606065</id><created>2006-06-14</created><updated>2006-09-20</updated><authors><author><keyname>Neven</keyname><forenames>Frank</forenames></author><author><keyname>Schwentick</keyname><forenames>Thomas</forenames></author></authors><title>On the complexity of XPath containment in the presence of disjunction,
  DTDs, and variables</title><categories>cs.DB cs.LO</categories><comments>30 pages, will appear in Logical Methods in Computer Science
  (http://www.lmcs-online.org)</comments><acm-class>H.2; I.7.2; F.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 3 (July 26,
  2006) lmcs:900</journal-ref><doi>10.2168/LMCS-2(3:1)2006</doi><abstract>  XPath is a simple language for navigating an XML-tree and returning a set of
answer nodes. The focus in this paper is on the complexity of the containment
problem for various fragments of XPath. We restrict attention to the most
common XPath expressions which navigate along the child and/or descendant axis.
In addition to basic expressions using only node tests and simple predicates,
we also consider disjunction and variables (ranging over nodes). Further, we
investigate the containment problem relative to a given DTD. With respect to
variables we study two semantics, (1) the original semantics of XPath, where
the values of variables are given by an outer context, and (2) an existential
semantics introduced by Deutsch and Tannen, in which the values of variables
are existentially quantified. In this framework, we establish an exact
classification of the complexity of the containment problem for many XPath
fragments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606066</id><created>2006-06-14</created><authors><author><keyname>Josang</keyname><forenames>Audun</forenames></author></authors><title>The Cumulative Rule for Belief Fusion</title><categories>cs.AI</categories><abstract>  The problem of combining beliefs in the Dempster-Shafer belief theory has
attracted considerable attention over the last two decades. The classical
Dempster's Rule has often been criticised, and many alternative rules for
belief combination have been proposed in the literature. The consensus operator
for combining beliefs has nice properties and produces more intuitive results
than Dempster's rule, but has the limitation that it can only be applied to
belief distribution functions on binary state spaces. In this paper we present
a generalisation of the consensus operator that can be applied to Dirichlet
belief functions on state spaces of arbitrary size. This rule, called the
cumulative rule of belief combination, can be derived from classical
statistical theory, and corresponds well with human intuition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606067</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606067</id><created>2006-06-14</created><updated>2007-08-14</updated><authors><author><keyname>Bender</keyname><forenames>Michael A.</forenames></author><author><keyname>Clifford</keyname><forenames>Raphael</forenames></author><author><keyname>Tsichlas</keyname><forenames>Kostas</forenames></author></authors><title>Scheduling Algorithms for Procrastinators</title><categories>cs.DS</categories><comments>12 pages, 3 figures</comments><doi>10.1007/s10951-007-0038-4</doi><abstract>  This paper presents scheduling algorithms for procrastinators, where the
speed that a procrastinator executes a job increases as the due date
approaches. We give optimal off-line scheduling policies for linearly
increasing speed functions. We then explain the computational/numerical issues
involved in implementing this policy. We next explore the online setting,
showing that there exist adversaries that force any online scheduling policy to
miss due dates. This impossibility result motivates the problem of minimizing
the maximum interval stretch of any job; the interval stretch of a job is the
job's flow time divided by the job's due date minus release time. We show that
several common scheduling strategies, including the &quot;hit-the-highest-nail&quot;
strategy beloved by procrastinators, have arbitrarily large maximum interval
stretch. Then we give the &quot;thrashing&quot; scheduling policy and show that it is a
\Theta(1) approximation algorithm for the maximum interval stretch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606068</id><created>2006-06-14</created><authors><author><keyname>Hett</keyname><forenames>Christian</forenames></author><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Security and Non-Repudiation for Voice-Over-IP Conversations</title><categories>cs.CR</categories><comments>Poster presentation at the ISSA 2006 From Insight to Foresight
  Conference, Sandton, South Africa, 5th-7th July 2006</comments><acm-class>C.2.0</acm-class><abstract>  We present a concept to achieve non-repudiation for natural language
conversations by electronically signing packet-based, digital, voice
communication. Signing a VoIP-based conversation means to protect the integrity
and authenticity of the bidirectional data stream and its temporal sequence
which together establish the security context of the communication. Our concept
is conceptually close to the protocols that embody VoIP and provides a high
level of inherent security. It enables signatures over voice as true
declarations of will, in principle between unacquainted speakers. We point to
trusted computing enabled devices as possible trusted signature terminals for
voice communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606069</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606069</id><created>2006-06-14</created><authors><author><keyname>Rigouste</keyname><forenames>Lo&#xef;s</forenames><affiliation>TSI</affiliation></author><author><keyname>Capp&#xe9;</keyname><forenames>Olivier</forenames><affiliation>TSI</affiliation></author><author><keyname>Yvon</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>TSI</affiliation></author></authors><title>Inference and Evaluation of the Multinomial Mixture Model for Text
  Clustering</title><categories>cs.IR cs.CL</categories><proxy>ccsd ccsd-00080133</proxy><journal-ref>Information Processing &amp; Management 43, 5 (01/09/2007) 1260?1280</journal-ref><doi>10.1016/j.ipm.2006.11.001</doi><abstract>  In this article, we investigate the use of a probabilistic model for
unsupervised clustering in text collections. Unsupervised clustering has become
a basic module for many intelligent text processing applications, such as
information retrieval, text classification or information extraction. The model
considered in this contribution consists of a mixture of multinomial
distributions over the word counts, each component corresponding to a different
theme. We present and contrast various estimation procedures, which apply both
in supervised and unsupervised contexts. In supervised learning, this work
suggests a criterion for evaluating the posterior odds of new documents which
is more statistically sound than the &quot;naive Bayes&quot; approach. In an unsupervised
context, we propose measures to set up a systematic evaluation framework and
start with examining the Expectation-Maximization (EM) algorithm as the basic
tool for inference. We discuss the importance of initialization and the
influence of other features such as the smoothing strategy or the size of the
vocabulary, thereby illustrating the difficulties incurred by the high
dimensionality of the parameter space. We also propose a heuristic algorithm
based on iterative EM with vocabulary reduction to solve this problem. Using
the fact that the latent variables can be analytically integrated out, we
finally show that Gibbs sampling algorithm is tractable and compares favorably
to the basic expectation maximization approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606070</id><created>2006-06-14</created><authors><author><keyname>Legg</keyname><forenames>Shane</forenames></author></authors><title>Is there an Elegant Universal Theory of Prediction?</title><categories>cs.AI cs.CC</categories><report-no>IDSIA - 12 - 06</report-no><abstract>  Solomonoff's inductive learning model is a powerful, universal and highly
elegant theory of sequence prediction. Its critical flaw is that it is
incomputable and thus cannot be used in practice. It is sometimes suggested
that it may still be useful to help guide the development of very general and
powerful theories of prediction which are computable. In this paper it is shown
that although powerful algorithms exist, they are necessarily highly complex.
This alone makes their theoretical analysis problematic, however it is further
shown that beyond a moderate level of complexity the analysis runs into the
deeper problem of Goedel incompleteness. This limits the power of mathematics
to analyse and study prediction algorithms, and indeed intelligent systems in
general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606071</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606071</id><created>2006-06-14</created><updated>2007-03-28</updated><authors><author><keyname>Sadrabadi</keyname><forenames>Mehdi Ansari</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Scheduling and Codeword Length Optimization in Time Varying Wireless
  Networks</title><categories>cs.IT math.IT</categories><report-no>#2006-01</report-no><abstract>  In this paper, a downlink scenario in which a single-antenna base station
communicates with K single antenna users, over a time-correlated fading
channel, is considered. It is assumed that channel state information is
perfectly known at each receiver, while the statistical characteristics of the
fading process and the fading gain at the beginning of each frame are known to
the transmitter. By evaluating the random coding error exponent of the
time-correlated fading channel, it is shown that there is an optimal codeword
length which maximizes the throughput. The throughput of the conventional
scheduling that transmits to the user with the maximum signal to noise ratio is
examined using both fixed length codewords and variable length codewords.
Although optimizing the codeword length improves the performance, it is shown
that using the conventional scheduling, the gap between the achievable
throughput and the maximum possible throughput of the system tends to infinity
as K goes to infinity. A simple scheduling that considers both the signal to
noise ratio and the channel time variation is proposed. It is shown that by
using this scheduling, the gap between the achievable throughput and the
maximum throughput of the system approaches zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606072</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606072</id><created>2006-06-15</created><updated>2006-07-27</updated><authors><author><keyname>Hasegawa</keyname><forenames>Masahito</forenames></author></authors><title>Relational Parametricity and Control</title><categories>cs.PL cs.LO</categories><comments>22 pages, for Logical Methods in Computer Science</comments><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 3 (July 27,
  2006) lmcs:1076</journal-ref><doi>10.2168/LMCS-2(3:3)2006</doi><abstract>  We study the equational theory of Parigot's second-order
&amp;lambda;&amp;mu;-calculus in connection with a call-by-name continuation-passing
style (CPS) translation into a fragment of the second-order &amp;lambda;-calculus.
It is observed that the relational parametricity on the target calculus induces
a natural notion of equivalence on the &amp;lambda;&amp;mu;-terms. On the other hand,
the unconstrained relational parametricity on the &amp;lambda;&amp;mu;-calculus turns
out to be inconsistent with this CPS semantics. Following these facts, we
propose to formulate the relational parametricity on the &amp;lambda;&amp;mu;-calculus
in a constrained way, which might be called ``focal parametricity''.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606073</id><created>2006-06-15</created><authors><author><keyname>Roche</keyname><forenames>Muriel</forenames><affiliation>IF</affiliation></author><author><keyname>R&#xe9;fr&#xe9;gier</keyname><forenames>Philippe</forenames><affiliation>IF</affiliation></author></authors><title>Comparison of the estimation of the degree of polarization from four or
  two intensity images degraded by speckle noise</title><categories>cs.IR physics.optics</categories><proxy>ccsd ccsd-00080155</proxy><journal-ref>EUSIPCO 2006 (2006) -</journal-ref><abstract>  Active polarimetric imagery is a powerful tool for accessing the information
present in a scene. Indeed, the polarimetric images obtained can reveal
polarizing properties of the objects that are not avalaible using conventional
imaging systems. However, when coherent light is used to illuminate the scene,
the images are degraded by speckle noise. The polarization properties of a
scene are characterized by the degree of polarization. In standard polarimetric
imagery system, four intensity images are needed to estimate this degree . If
we assume the uncorrelation of the measurements, this number can be decreased
to two images using the Orthogonal State Contrast Image (OSCI). However, this
approach appears too restrictive in some cases. We thus propose in this paper a
new statistical parametric method to estimate the degree of polarization
assuming correlated measurements with only two intensity images. The estimators
obtained from four images, from the OSCI and from the proposed method, are
compared using simulated polarimetric data degraded by speckle noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606074</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606074</id><created>2006-06-15</created><authors><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Rate Regions for Relay Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, June 2006</comments><abstract>  A partially cooperative relay broadcast channel (RBC) is a three-node network
with one source node and two destination nodes (destinations 1 and 2) where
destination 1 can act as a relay to assist destination 2. Inner and outer
bounds on the capacity region of the discrete memoryless partially cooperative
RBC are obtained. When the relay function is disabled, the inner and outer
bounds reduce to new bounds on the capacity region of broadcast channels. Four
classes of RBCs are studied in detail. For the partially cooperative RBC with
degraded message sets, inner and outer bounds are obtained. For the
semideterministic partially cooperative RBC and the orthogonal partially
cooperative RBC, the capacity regions are established. For the parallel
partially cooperative RBC with unmatched degraded subchannels, the capacity
region is established for the case of degraded message sets. The capacity is
also established when the source node has only a private message for
destination 2, i.e., the channel reduces to a parallel relay channel with
unmatched degraded subchannels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606075</identifier>
 <datestamp>2008-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606075</id><created>2006-06-16</created><updated>2008-02-13</updated><authors><author><keyname>Antova</keyname><forenames>Lyublena</forenames></author><author><keyname>Koch</keyname><forenames>Christoph</forenames></author><author><keyname>Olteanu</keyname><forenames>Dan</forenames></author></authors><title>10^(10^6) Worlds and Beyond: Efficient Representation and Processing of
  Incomplete Information</title><categories>cs.DB</categories><comments>17 pages, 24 figures</comments><acm-class>H.2.1; H.2.4</acm-class><abstract>  Current systems and formalisms for representing incomplete information
generally suffer from at least one of two weaknesses. Either they are not
strong enough for representing results of simple queries, or the handling and
processing of the data, e.g. for query evaluation, is intractable.
  In this paper, we present a decomposition-based approach to addressing this
problem. We introduce world-set decompositions (WSDs), a space-efficient
formalism for representing any finite set of possible worlds over relational
databases. WSDs are therefore a strong representation system for any relational
query language. We study the problem of efficiently evaluating relational
algebra queries on sets of worlds represented by WSDs. We also evaluate our
technique experimentally in a large census data scenario and show that it is
both scalable and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606076</id><created>2006-06-16</created><authors><author><keyname>Chen</keyname><forenames>Bin Bin</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Primet</keyname><forenames>Pascale</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>A Flexible Bandwidth Reservation Framework for Bulk Data Transfers in
  Grid Networks</title><categories>cs.NI</categories><proxy>ccsd inria-00078069</proxy><abstract>  In grid networks, distributed resources are interconnected by wide area
network to support compute and data-intensive applications, which require
reliable and efficient transfer of gigabits (even terabits) of data. Different
from best-effort traffic in Internet, bulk data transfer in grid requires
bandwidth reservation as a fundamental service. Existing reservation schemes
such as RSVP are designed for real-time traffic specified by reservation rate,
transfer start time but with unknown lifetime. In comparison, bulk data
transfer requests are defined in terms of volume and deadline, which provide
more information, and allow more flexibility in reservation schemes, i.e.,
transfer start time can be flexibly chosen, and reservation for a single
request can be divided into multiple intervals with different reservation
rates. We define a flexible reservation framework using time-rate function
algebra, and identify a series of practical reservation scheme families with
increasing generality and potential performance, namely, FixTime-FixRate,
FixTime-FlexRate, FlexTime-FlexRate, and Multi-Interval. Simple heuristics are
used to select representative scheme from each family for performance
comparison. Simulation results show that the increasing flexibility can
potentially improve system performance, minimizing both blocking probability
and mean flow time. We also discuss the distributed implementation of proposed
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606077</identifier>
 <datestamp>2008-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606077</id><created>2006-06-16</created><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>On Sequence Prediction for Arbitrary Measures</title><categories>cs.LG</categories><comments>16 pages</comments><report-no>IDSIA-13-06</report-no><journal-ref>Proc. IEEE International Symposium on Information Theory (ISIT
  2007) pages 2346-2350</journal-ref><abstract>  Suppose we are given two probability measures on the set of one-way infinite
finite-alphabet sequences and consider the question when one of the measures
predicts the other, that is, when conditional probabilities converge (in a
certain sense) when one of the measures is chosen to generate the sequence.
This question may be considered a refinement of the problem of sequence
prediction in its most general formulation: for a given class of probability
measures, does there exist a measure which predicts all of the measures in the
class? To address this problem, we find some conditions on local absolute
continuity which are sufficient for prediction and which generalize several
different notions which are known to be sufficient for prediction. We also
formulate some open questions to outline a direction for finding the conditions
on classes of measures for which prediction is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606078</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606078</id><created>2006-06-18</created><updated>2007-03-11</updated><authors><author><keyname>Doty</keyname><forenames>David</forenames></author></authors><title>Dimension Extractors and Optimal Decompression</title><categories>cs.CC cs.IT math.IT</categories><comments>This report was combined with a different conference paper &quot;Every
  Sequence is Decompressible from a Random One&quot; (cs.IT/0511074, at
  http://dx.doi.org/10.1007/11780342_17), and both titles were changed, with
  the conference paper incorporated as section 5 of this new combined paper.
  The combined paper was accepted to the journal Theory of Computing Systems,
  as part of a special issue of invited papers from the second conference on
  Computability in Europe, 2006</comments><acm-class>F.1.3; E.4; H.1.1</acm-class><abstract>  A *dimension extractor* is an algorithm designed to increase the effective
dimension -- i.e., the amount of computational randomness -- of an infinite
binary sequence, in order to turn a &quot;partially random&quot; sequence into a &quot;more
random&quot; sequence. Extractors are exhibited for various effective dimensions,
including constructive, computable, space-bounded, time-bounded, and
finite-state dimension. Using similar techniques, the Kucera-Gacs theorem is
examined from the perspective of decompression, by showing that every infinite
sequence S is Turing reducible to a Martin-Loef random sequence R such that the
asymptotic number of bits of R needed to compute n bits of S, divided by n, is
precisely the constructive dimension of S, which is shown to be the optimal
ratio of query bits to computed bits achievable with Turing reductions. The
extractors and decompressors that are developed lead directly to new
characterizations of some effective dimensions in terms of optimal
decompression by Turing reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606079</id><created>2006-06-18</created><updated>2006-08-15</updated><authors><author><keyname>Hajjem</keyname><forenames>C.</forenames></author><author><keyname>Harnad</keyname><forenames>S.</forenames></author><author><keyname>Gingras</keyname><forenames>Y.</forenames></author></authors><title>Ten-Year Cross-Disciplinary Comparison of the Growth of Open Access and
  How it Increases Research Citation Impact</title><categories>cs.DL</categories><comments>10 pages, 5 figures, 3 tables</comments><journal-ref>IEEE Data Engineering Bulletin 28(4): 39-47; 2005</journal-ref><abstract>  Lawrence (2001)found computer science articles that were openly accessible
(OA) on the Web were cited more. We replicated this in physics. We tested
1,307,038 articles published across 12 years (1992-2003) in 10 disciplines
(Biology, Psychology, Sociology, Health, Political Science, Economics,
Education, Law, Business, Management). A robot trawls the Web for full-texts
using reference metadata ISI citation data (signal detectability d'=2.45; bias
= 0.52). Percentage OA (relative to total OA + NOA) articles varies from 5%-16%
(depending on discipline, year and country) and is slowly climbing annually
(correlation r=.76, sample size N=12, probability p &lt; 0.005). Comparing OA and
NOA articles in the same journal/year, OA articles have consistently more
citations, the advantage varying from 36%-172% by discipline and year.
Comparing articles within six citation ranges (0, 1, 2-3, 4-7, 8-15, 16+
citations), the annual percentage of OA articles is growing significantly
faster than NOA within every citation range (r &gt; .90, N=12, p &lt; .0005) and the
effect is greater with the more highly cited articles (r = .98, N=6, p &lt; .005).
Causality cannot be determined from these data, but our prior finding of a
similar pattern in physics, where percent OA is much higher (and even
approaches 100% in some subfields), makes it unlikely that the OA citation
advantage is merely or mostly a self-selection bias (for making only one's
better articles OA). Further research will analyze the effect's timing, causal
components and relation to other variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606080</id><created>2006-06-19</created><authors><author><keyname>Chapdelaine</keyname><forenames>Philippe</forenames></author></authors><title>On the structure of linear-time reducibility</title><categories>cs.CC</categories><comments>10 pages</comments><acm-class>F.1.3; F.4.1</acm-class><abstract>  In 1975, Ladner showed that under the hypothesis that P is not equal to NP,
there exists a language which is neither in P, nor NP-complete. This result was
latter generalized by Schoning and several authors to various polynomial-time
complexity classes. We show here that such results also apply to linear-time
reductions on RAMs (resp. Turing machines), and hence allow for separation
results in linear-time classes similar to Ladner's ones for polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606081</id><created>2006-06-19</created><updated>2006-06-29</updated><authors><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>New Millennium AI and the Convergence of History</title><categories>cs.AI</categories><comments>Speed Prior: clarification / 15 pages, to appear in &quot;Challenges to
  Computational Intelligence&quot;</comments><report-no>IDSIA-14-06</report-no><acm-class>I.2</acm-class><abstract>  Artificial Intelligence (AI) has recently become a real formal science: the
new millennium brought the first mathematically sound, asymptotically optimal,
universal problem solvers, providing a new, rigorous foundation for the
previously largely heuristic field of General AI and embedded agents. At the
same time there has been rapid progress in practical methods for learning true
sequence-processing programs, as opposed to traditional methods limited to
stationary pattern association. Here we will briefly review some of the new
results, and speculate about future developments, pointing out that the time
intervals between the most notable events in over 40,000 years or 2^9 lifetimes
of human history have sped up exponentially, apparently converging to zero
within the next few decades. Or is this impression just a by-product of the way
humans allocate memory space to past events?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606082</id><created>2006-06-19</created><authors><author><keyname>Ben-Naim</keyname><forenames>Jonathan</forenames><affiliation>LIF</affiliation></author></authors><title>Lack of Finite Characterizations for the Distance-based Revision</title><categories>cs.LO</categories><proxy>ccsd ccsd-00080505</proxy><journal-ref>Tenth International Conference on Principles of Knowledge
  Representation and Reasoning (KR'06) (2006) 239-248</journal-ref><abstract>  Lehmann, Magidor, and Schlechta developed an approach to belief revision
based on distances between any two valuations. Suppose we are given such a
distance D. This defines an operator |D, called a distance operator, which
transforms any two sets of valuations V and W into the set V |D W of all
elements of W that are closest to V. This operator |D defines naturally the
revision of K by A as the set of all formulas satisfied in M(K) |D M(A) (i.e.
those models of A that are closest to the models of K). This constitutes a
distance-based revision operator. Lehmann et al. characterized families of them
using a loop condition of arbitrarily big size. An interesting question is
whether this loop condition can be replaced by a finite one. Extending the
results of Schlechta, we will provide elements of negative answer. In fact, we
will show that for families of distance operators, there is no &quot;normal&quot;
characterization. Approximatively, a normal characterization contains only
finite and universally quantified conditions. These results have an interest of
their own for they help to understand the limits of what is possible in this
area. Now, we are quite confident that this work can be continued to show
similar impossibility results for distance-based revision operators, which
suggests that the big loop condition cannot be simplified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606083</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606083</id><created>2006-06-19</created><authors><author><keyname>Jalden</keyname><forenames>J.</forenames></author><author><keyname>Ottersten</keyname><forenames>B.</forenames></author></authors><title>The Diversity Order of the Semidefinite Relaxation Detector</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, June 2006</comments><abstract>  We consider the detection of binary (antipodal) signals transmitted in a
spatially multiplexed fashion over a fading multiple-input multiple-output
(MIMO) channel and where the detection is done by means of semidefinite
relaxation (SDR). The SDR detector is an attractive alternative to maximum
likelihood (ML) detection since the complexity is polynomial rather than
exponential. Assuming that the channel matrix is drawn with i.i.d. real valued
Gaussian entries, we study the receiver diversity and prove that the SDR
detector achieves the maximum possible diversity. Thus, the error probability
of the receiver tends to zero at the same rate as the optimal maximum
likelihood (ML) receiver in the high signal to noise ratio (SNR) limit. This
significantly strengthens previous performance guarantees available for the
semidefinite relaxation detector. Additionally, it proves that full diversity
detection is in certain scenarios also possible when using a non-combinatorial
receiver structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606084</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606084</id><created>2006-06-19</created><updated>2006-11-07</updated><authors><author><keyname>Gallier</keyname><forenames>Jean</forenames></author></authors><title>The Completeness of Propositional Resolution: A Simple and
  Constructive&lt;br&gt; Proof</title><categories>cs.LO cs.AI</categories><comments>7 pages, submitted to LMCS</comments><acm-class>F.4.1; I.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 5 (November
  7, 2006) lmcs:1114</journal-ref><doi>10.2168/LMCS-2(5:3)2006</doi><abstract>  It is well known that the resolution method (for propositional logic) is
complete. However, completeness proofs found in the literature use an argument
by contradiction showing that if a set of clauses is unsatisfiable, then it
must have a resolution refutation. As a consequence, none of these proofs
actually gives an algorithm for producing a resolution refutation from an
unsatisfiable set of clauses. In this note, we give a simple and constructive
proof of the completeness of propositional resolution which consists of an
algorithm together with a proof of its correctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606085</id><created>2006-06-20</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author></authors><title>Provably Secure Universal Steganographic Systems</title><categories>cs.CR</categories><comments>11 pages</comments><report-no>Cryptology ePrint Archive, Report 2006/063</report-no><abstract>  We propose a simple universal (that is, distribution--free) steganographic
system in which covertexts with and without hidden texts are statistically
indistinguishable. The stegosystem can be applied to any source generating
i.i.d. covertexts with unknown distribution, and the hidden text is transmitted
exactly, with zero probability of error. Moreover, the proposed steganographic
system has two important properties. First, the rate of transmission of hidden
information approaches the Shannon entropy of the covertext source as the size
of blocks used for hidden text encoding tends to infinity. Second, if the size
of the alphabet of the covertext source and its minentropy tend to infinity
then the number of bits of hidden text per letter of covertext tends to
$\log(n!)/n$ where $n$ is the (fixed) size of blocks used for hidden text
encoding. The proposed stegosystem uses randomization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606086</id><created>2006-06-20</created><authors><author><keyname>Denise</keyname><forenames>Alain</forenames><affiliation>LRI</affiliation></author><author><keyname>Gaudel</keyname><forenames>Marie-Claude</forenames><affiliation>LRI</affiliation></author><author><keyname>Gouraud</keyname><forenames>Sandrine-Dominique</forenames><affiliation>LRI</affiliation></author><author><keyname>Lasseigne</keyname><forenames>Richard</forenames><affiliation>ELM</affiliation></author><author><keyname>Peyronnet</keyname><forenames>Sylvain</forenames><affiliation>ELM</affiliation></author><author><keyname>Collaboration</keyname><forenames>the RaST</forenames></author></authors><title>Uniform Random Sampling of Traces in Very Large Models</title><categories>cs.LO</categories><proxy>ccsd ccsd-00080471</proxy><acm-class>D.2.4; D.2.5</acm-class><journal-ref>First International Workshop on Random Testing, \'{E}tats-Unis
  d'Am\'{e}rique (2006) 10-19</journal-ref><abstract>  This paper presents some first results on how to perform uniform random walks
(where every trace has the same probability to occur) in very large models. The
models considered here are described in a succinct way as a set of
communicating reactive modules. The method relies upon techniques for counting
and drawing uniformly at random words in regular languages. Each module is
considered as an automaton defining such a language. It is shown how it is
possible to combine local uniform drawings of traces, and to obtain some global
uniform random sampling, without construction of the global model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606087</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606087</id><created>2006-06-20</created><updated>2008-07-22</updated><authors><author><keyname>G&#xe4;rtner</keyname><forenames>Bernd</forenames></author><author><keyname>Matousek</keyname><forenames>Jirka</forenames></author><author><keyname>R&#xfc;st</keyname><forenames>Leo</forenames></author><author><keyname>Skovron</keyname><forenames>Petr</forenames></author></authors><title>Violator Spaces: Structure and Algorithms</title><categories>cs.DM</categories><comments>28 pages, 5 figures, extended abstract was presented at ESA 2006;
  author spelling fixed</comments><doi>10.1007/11841036_36</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sharir and Welzl introduced an abstract framework for optimization problems,
called LP-type problems or also generalized linear programming problems, which
proved useful in algorithm design. We define a new, and as we believe, simpler
and more natural framework: violator spaces, which constitute a proper
generalization of LP-type problems. We show that Clarkson's randomized
algorithms for low-dimensional linear programming work in the context of
violator spaces. For example, in this way we obtain the fastest known algorithm
for the P-matrix generalized linear complementarity problem with a constant
number of blocks. We also give two new characterizations of LP-type problems:
they are equivalent to acyclic violator spaces, as well as to concrete LP-type
problems (informally, the constraints in a concrete LP-type problem are subsets
of a linearly ordered ground set, and the value of a set of constraints is the
minimum of its intersection).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606088</id><created>2006-06-20</created><authors><author><keyname>Condado</keyname><forenames>Paulo A.</forenames></author><author><keyname>Lobo</keyname><forenames>Fernando G.</forenames></author></authors><title>Breaking barriers for people with voice disabilities: Combining virtual
  keyboards with speech synthesizers, and VoIP applications</title><categories>cs.CY</categories><report-no>Also UAlg-ILAB Report No. 200604</report-no><acm-class>H.5.2; H.4.3; K.3.1</acm-class><abstract>  Text-to-speech technology has been broadly used to help people with voice
disabilities to overcome their difficulties. With text-to-speech, a person
types at a keyboard, the text is synthesized, and the sound comes out through
the computer speakers.
  In recent years, Voice over IP (VoIP) applications have become very popular
and have been used by people worldwide. These applications allow people to talk
for free over the Internet and also to make traditional calls through the
Public-Switched Telephone Network (PSTN) at a small fraction of the cost
offered by traditional phone companies.
  We have created a system, called EasyVoice, which integrates speech
synthesizers with VoIP applications. The result allows a person with motor
impairments and voice disabilities to talk with another person located anywhere
in the world. The benefits in this case are much stronger than the ones
obtained by non-disabled people using VoIP applications. People with motor
impairments sometimes can hardly use a regular or mobile phone. Thus, the
advantage is not only the reduction in cost, but more important, the ability to
talk at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606089</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606089</id><created>2006-06-20</created><authors><author><keyname>Ermopoulos</keyname><forenames>Charis</forenames></author><author><keyname>Yurcik</keyname><forenames>William</forenames></author></authors><title>NVision-PA: A Tool for Visual Analysis of Command Behavior Based on
  Process Accounting Logs (with a Case Study in HPC Cluster Security)</title><categories>cs.CR cs.DC</categories><comments>25 pages, 13 Figures</comments><abstract>  In the UNIX/Linux environment the kernel can log every command process
created by every user with process accounting. Thus process accounting logs
have many potential uses, particularly the monitoring and forensic
investigation of security events. Previous work successfully leveraged the use
of process accounting logs to identify a difficult to detect and damaging
intrusion against high performance computing (HPC) clusters, masquerade
attacks, where intruders masquerade as legitimate users with purloined
authentication credentials. While masqueraders on HPC clusters were found to be
identifiable with a high accuracy (greater than 90%), this accuracy is still
not high enough for HPC production environments where greater than 99% accuracy
is needed.
  This paper incrementally advances the goal of more accurately identifying
masqueraders on HPC clusters by seeking to identify features within command
sets that distinguish masqueraders. To accomplish this goal, we created
NVision-PA, a software tool that produces text and graphic statistical
summaries describing input processing accounting logs. We report NVision-PA
results describing two different process accounting logs; one from Internet
usage and one from HPC cluster usage. These results identify the distinguishing
features of Internet users (as proxies for masqueraders) posing as clusters
users. This research is both a promising next step toward creating a real-time
masquerade detection sensor for production HPC clusters as well as providing
another tool for system administrators to use for statistically monitoring and
managing legitimate workloads (as indicated by command usage) in HPC
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606090</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606090</id><created>2006-06-20</created><authors><author><keyname>Snow</keyname><forenames>Chris</forenames></author><author><keyname>Lampe</keyname><forenames>Lutz</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Error Rate Analysis for Coded Multicarrier Systems over Quasi-Static
  Fading Channels</title><categories>cs.IT math.IT</categories><comments>31 pages, 9 figures, 1 table. Submitted to the IEEE Transactions on
  Communications (June 20, 2006)</comments><abstract>  Several recent standards such as IEEE 802.11a/g, IEEE 802.16, and ECMA
Multiband Orthogonal Frequency Division Multiplexing (MB-OFDM) for high
data-rate Ultra-Wideband (UWB), employ bit-interleaved convolutionally-coded
multicarrier modulation over quasi-static fading channels. Motivated by the
lack of appropriate error rate analysis techniques for this popular type of
system and channel model, we present two novel analytical methods for bit error
rate (BER) estimation of coded multicarrier systems operating over
frequency-selective quasi-static channels with non-ideal interleaving. In the
first method, the approximate performance of the system is calculated for each
realization of the channel, which is suitable for obtaining the outage BER
performance (a common performance measure for e.g. MB-OFDM systems). The second
method assumes Rayleigh distributed frequency-domain subcarrier channel gains
and knowledge of their correlation matrix, and can be used to directly obtain
the average BER performance. Both methods are applicable to
convolutionally-coded interleaved multicarrier systems employing Quadrature
Amplitude Modulation (QAM), and are also able to account for narrowband
interference (modeled as a sum of tone interferers). To illustrate the
application of the proposed analysis, both methods are used to study the
performance of a tone-interference-impaired MB-OFDM system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606091</identifier>
 <datestamp>2012-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606091</id><created>2006-06-21</created><authors><author><keyname>Baier</keyname><forenames>C.</forenames></author><author><keyname>Bertrand</keyname><forenames>N.</forenames></author><author><keyname>Schnoebelen</keyname><forenames>Ph.</forenames></author></authors><title>On computing fixpoints in well-structured regular model checking, with
  applications to lossy channel systems</title><categories>cs.SC cs.GT</categories><comments>16 pages</comments><journal-ref>Proc. LPAR 2006, LNCS 4246, pp. 347-361, Springer 2006</journal-ref><doi>10.1007/11916277_24</doi><abstract>  We prove a general finite convergence theorem for &quot;upward-guarded&quot; fixpoint
expressions over a well-quasi-ordered set. This has immediate applications in
regular model checking of well-structured systems, where a main issue is the
eventual convergence of fixpoint computations. In particular, we are able to
directly obtain several new decidability results on lossy channel systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606092</id><created>2006-06-21</created><updated>2006-07-03</updated><authors><author><keyname>Gallardo</keyname><forenames>Mar&#xed;a Del Mar</forenames><affiliation>GISUM</affiliation></author><author><keyname>Joubert</keyname><forenames>Christophe</forenames><affiliation>GISUM</affiliation></author><author><keyname>Merino</keyname><forenames>Pedro</forenames><affiliation>GISUM</affiliation></author></authors><title>Static Analysis using Parameterised Boolean Equation Systems</title><categories>cs.SE</categories><comments>Submitted to an international 2006 conference</comments><proxy>ccsd inria-00080518</proxy><abstract>  The well-known problem of state space explosion in model checking is even
more critical when applying this technique to programming languages, mainly due
to the presence of complex data structures. One recent and promising approach
to deal with this problem is the construction of an abstract and correct
representation of the global program state allowing to match visited states
during program model exploration. In particular, one powerful method to
implement abstract matching is to fill the state vector with a minimal amount
of relevant variables for each program point. In this paper, we combine the
on-the-fly model-checking approach (incremental construction of the program
state space) and the static analysis method called influence analysis
(extraction of significant variables for each program point) in order to
automatically construct an abstract matching function. Firstly, we describe the
problem as an alternation-free value-based mu-calculus formula, whose validity
can be checked on the program model expressed as a labeled transition system
(LTS). Secondly, we translate the analysis into the local resolution of a
parameterised boolean equation system (PBES), whose representation enables a
more efficient construction of the resulting abstract matching function.
Finally, we show how our proposal may be elegantly integrated into CADP, a
generic framework for both the design and analysis of distributed systems and
the development of verification tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606093</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606093</id><created>2006-06-22</created><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Predictions as statements and decisions</title><categories>cs.LG</categories><comments>48 pages</comments><abstract>  Prediction is a complex notion, and different predictors (such as people,
computer programs, and probabilistic theories) can pursue very different goals.
In this paper I will review some popular kinds of prediction and argue that the
theory of competitive on-line learning can benefit from the kinds of prediction
that are now foreign to it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606094</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606094</id><created>2006-06-22</created><authors><author><keyname>Martens</keyname><forenames>Wim</forenames></author><author><keyname>Neven</keyname><forenames>Frank</forenames></author><author><keyname>Gyssens</keyname><forenames>Marc</forenames></author></authors><title>On Typechecking Top-Down XML Tranformations: Fixed Input or Output
  Schemas</title><categories>cs.DB cs.PL</categories><abstract>  Typechecking consists of statically verifying whether the output of an XML
transformation always conforms to an output type for documents satisfying a
given input type. In this general setting, both the input and output schema as
well as the transformation are part of the input for the problem. However,
scenarios where the input or output schema can be considered to be fixed, are
quite common in practice. In the present work, we investigate the computational
complexity of the typechecking problem in the latter setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606095</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606095</id><created>2006-06-22</created><authors><author><keyname>Krivine</keyname><forenames>Jean</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A verification algorithm for Declarative Concurrent Programming</title><categories>cs.DC</categories><proxy>ccsd inria-00081218</proxy><abstract>  A verification method for distributed systems based on decoupling forward and
backward behaviour is proposed. This method uses an event structure based
algorithm that, given a CCS process, constructs its causal compression relative
to a choice of observable actions. Verifying the original process equipped with
distributed backtracking on non-observable actions, is equivalent to verifying
its relative compression which in general is much smaller. We call this method
Declarative Concurrent Programming (DCP). DCP technique compares well with
direct bisimulation based methods. Benchmarks for the classic dining
philosophers problem show that causal compression is rather efficient both
time- and space-wise. State of the art verification tools can successfully
handle more than 15 agents, whereas they can handle no more than 5 following
the traditional direct method; an altogether spectacular improvement, since in
this example the specification size is exponential in the number of agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606096</id><created>2006-06-22</created><authors><author><keyname>Cyrus</keyname><forenames>Lea</forenames></author></authors><title>Building a resource for studying translation shifts</title><categories>cs.CL</categories><comments>6 pages, 1 figure</comments><acm-class>I.2.7</acm-class><journal-ref>Proc. LREC 2006, Genoa, May 24-26, 2006; pp. 1240-1245</journal-ref><abstract>  This paper describes an interdisciplinary approach which brings together the
fields of corpus linguistics and translation studies. It presents ongoing work
on the creation of a corpus resource in which translation shifts are explicitly
annotated. Translation shifts denote departures from formal correspondence
between source and target text, i.e. deviations that have occurred during the
translation process. A resource in which such shifts are annotated in a
systematic way will make it possible to study those phenomena that need to be
addressed if machine translation output is to resemble human translation. The
resource described in this paper contains English source texts (parliamentary
proceedings) and their German translations. The shift annotation is based on
predicate-argument structures and proceeds in two steps: first, predicates and
their arguments are annotated monolingually in a straightforward manner. Then,
the corresponding English and German predicates and arguments are aligned with
each other. Whenever a shift - mainly grammatical or semantic -has occurred,
the alignment is tagged accordingly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606097</id><created>2006-06-22</created><updated>2006-06-23</updated><authors><author><keyname>Krizhanovsky</keyname><forenames>A.</forenames></author></authors><title>Synonym search in Wikipedia: Synarcher</title><categories>cs.IR cs.DM</categories><comments>4 pages, 2 figures, Synarcher program is available at
  http://synarcher.sourceforge.net</comments><acm-class>H.3.1; H.3.3; H.4.3; G.2.2</acm-class><abstract>  The program Synarcher for synonym (and related terms) search in the text
corpus of special structure (Wikipedia) was developed. The results of the
search are presented in the form of graph. It is possible to explore the graph
and search for graph elements interactively. Adapted HITS algorithm for synonym
search, program architecture, and program work evaluation with test examples
are presented in the paper. The proposed algorithm can be applied to a query
expansion by synonyms (in a search engine) and a synonym dictionary forming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606098</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606098</id><created>2006-06-22</created><authors><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Liu</keyname><forenames>Ran</forenames></author><author><keyname>Tomasi</keyname><forenames>Carlo</forenames></author></authors><title>Outlier Robust ICP for Minimizing Fractional RMSD</title><categories>cs.GR cs.CG</categories><comments>22 pages, 7 Figures, 9 Tables</comments><report-no>Duke University Technical Report: CS-2006-05</report-no><abstract>  We describe a variation of the iterative closest point (ICP) algorithm for
aligning two point sets under a set of transformations. Our algorithm is
superior to previous algorithms because (1) in determining the optimal
alignment, it identifies and discards likely outliers in a statistically robust
manner, and (2) it is guaranteed to converge to a locally optimal solution. To
this end, we formalize a new distance measure, fractional root mean squared
distance (frmsd), which incorporates the fraction of inliers into the distance
function. We lay out a specific implementation, but our framework can easily
incorporate most techniques and heuristics from modern registration algorithms.
We experimentally validate our algorithm against previous techniques on 2 and 3
dimensional data exposed to a variety of outlier types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606099</id><created>2006-06-22</created><authors><author><keyname>Maddah-Ali</keyname><forenames>Mohammad A.</forenames></author><author><keyname>Mobasher</keyname><forenames>Amin</forenames></author><author><keyname>Khandani</keyname><forenames>Amir Kayvan</forenames></author></authors><title>Fairness in Multiuser Systems with Polymatroid Capacity Region</title><categories>cs.IT math.IT</categories><comments>Submitted To IEEE Transactions on Information Theory, June 2006</comments><abstract>  For a wide class of multi-user systems, a subset of capacity region which
includes the corner points and the sum-capacity facet has a special structure
known as polymatroid. Multiaccess channels with fixed input distributions and
multiple-antenna broadcast channels are examples of such systems. Any interior
point of the sum-capacity facet can be achieved by time-sharing among corner
points or by an alternative method known as rate-splitting. The main purpose of
this paper is to find a point on the sum-capacity facet which satisfies a
notion of fairness among active users. This problem is addressed in two cases:
(i) where the complexity of achieving interior points is not feasible, and (ii)
where the complexity of achieving interior points is feasible. For the first
case, the corner point for which the minimum rate of the active users is
maximized (max-min corner point) is desired for signaling. A simple greedy
algorithm is introduced to find the optimum max-min corner point. For the
second case, the polymatroid properties are exploited to locate a rate-vector
on the sum-capacity facet which is optimally fair in the sense that the minimum
rate among all users is maximized (max-min rate). In the case that the rate of
some users can not increase further (attain the max-min value), the algorithm
recursively maximizes the minimum rate among the rest of the users. It is shown
that the problems of deriving the time-sharing coefficients or rate-spitting
scheme can be solved by decomposing the problem to some lower-dimensional
subproblems. In addition, a fast algorithm to compute the time-sharing
coefficients to attain a general point on the sum-capacity facet is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606100</identifier>
 <datestamp>2011-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606100</id><created>2006-06-23</created><updated>2011-10-11</updated><authors><author><keyname>Cuturi</keyname><forenames>Marco</forenames></author></authors><title>The generating function of the polytope of transport matrices $U(r,c)$
  as a positive semidefinite kernel of the marginals $r$ and $c$</title><categories>cs.LG cs.DM</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn by the author due to a crucial error in the
proof of Lemma 5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606101</id><created>2006-06-23</created><updated>2006-12-19</updated><authors><author><keyname>Daumas</keyname><forenames>Marc</forenames><affiliation>LIRMM, Lp2a</affiliation></author><author><keyname>Lester</keyname><forenames>David</forenames><affiliation>LP2A, University of Manchester</affiliation></author></authors><title>Stochastic Formal Methods: An application to accuracy of numeric
  software</title><categories>cs.MS</categories><proxy>ccsd ccsd-00081413</proxy><abstract>  This paper provides a bound on the number of numeric operations (fixed or
floating point) that can safely be performed before accuracy is lost. This work
has important implications for control systems with safety-critical software,
as these systems are now running fast enough and long enough for their errors
to impact on their functionality. Furthermore, worst-case analysis would
blindly advise the replacement of existing systems that have been successfully
running for years. We present here a set of formal theorems validated by the
PVS proof assistant. These theorems will allow code analyzing tools to produce
formal certificates of accurate behavior. For example, FAA regulations for
aircraft require that the probability of an error be below $10^{-9}$ for a 10
hour flight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606102</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606102</id><created>2006-06-24</created><updated>2011-02-17</updated><authors><author><keyname>Wang</keyname><forenames>Chengpu</forenames></author></authors><title>Toward Functionality Oriented Programming</title><categories>cs.PL cs.HC</categories><comments>This paper has been withdrawn by the author. 21 Pages, 7 Figures</comments><abstract>  The concept of functionality oriented programming is proposed, and some of
its aspects are discussed, such as: (1) implementation independent basic types
and generic collection types; (2) syntax requirements and recommendations for
implementation independence; (3) unified documentation and code; (4)
cross-module interface; and (5) cross-language program making scheme. A
prototype example is given to demonstrate functionality oriented programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606103</identifier>
 <datestamp>2014-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606103</id><created>2006-06-25</created><updated>2014-04-11</updated><authors><author><keyname>Wang</keyname><forenames>Chengpu</forenames></author></authors><title>Precision Arithmetic: A New Floating-Point Arithmetic</title><categories>cs.DM cs.DS cs.NA</categories><comments>54 Pages, 32 Figures</comments><msc-class>65Y04, 65T50</msc-class><acm-class>G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new deterministic floating-point arithmetic called precision arithmetic is
developed to track precision for arithmetic calculations. It uses a novel
rounding scheme to avoid excessive rounding error propagation of conventional
floating-point arithmetic. Unlike interval arithmetic, its uncertainty tracking
is based on statistics and the central limit theorem, with a much tighter
bounding range. Its stable rounding error distribution is approximated by a
truncated normal distribution. Generic standards and systematic methods for
validating uncertainty-bearing arithmetics are discussed. The precision
arithmetic is found to be better than interval arithmetic in both
uncertainty-tracking and uncertainty-bounding for normal usages.
  The precision arithmetic is available publicly at
http://precisionarithm.sourceforge.net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606104</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606104</id><created>2006-06-26</created><updated>2006-07-28</updated><authors><author><keyname>Han</keyname><forenames>Te Sun</forenames></author></authors><title>An information-spectrum approach to large deviation theorems</title><categories>cs.IT math.IT</categories><abstract>  In this paper we show a some new look at large deviation theorems from the
viewpoint of the information-spectrum (IS) methods, which has been first
exploited in information theory, and also demonstrate a new basic formula for
the large deviation rate function in general, which is a pair of the lower and
upper IS rate functions. In particular, we are interested in establishing the
general large deviation rate functions that can be derivable as the
Fenchel-Legendre transform of the cumulant generating function. The final goal
is to show a necessary and sufficient condition for the rate function to be of
Cram\'er-G\&quot;artner-Ellis type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606105</id><created>2006-06-26</created><authors><author><keyname>Deeb</keyname><forenames>Salah</forenames><affiliation>CRAN</affiliation></author><author><keyname>Iung</keyname><forenames>Beno&#xee;t</forenames><affiliation>CRAN</affiliation></author></authors><title>Iso9000 Based Advanced Quality Approach for Continuous Improvement of
  Manufacturing Processes</title><categories>cs.IR</categories><proxy>ccsd ccsd-00081864</proxy><journal-ref>12th IFAC Symposium on Information Control Problems in
  Manufacturing, St-Etienne, France (17/05/2006) CDROM</journal-ref><abstract>  The continuous improvement in TQM is considered as the core value by which
organisation could maintain a competitive edge. Several techniques and tools
are known to support this core value but most of the time these techniques are
informal and without modelling the interdependence between the core value and
tools. Thus, technique formalisation is one of TQM challenges for increasing
efficiency of quality process implementation. In that way, the paper proposes
and experiments an advanced quality modelling approach based on meta-modelling
the &quot;process approach&quot; as advocated by the standard ISO9000:2000. This
meta-model allows formalising the interdependence between technique, tools and
core value
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606106</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606106</id><created>2006-06-26</created><updated>2007-01-06</updated><authors><author><keyname>B</keyname><forenames>Sundeep</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author></authors><title>Self-orthogonality of $q$-ary Images of $q^m$-ary Codes and Quantum Code
  Construction</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><abstract>  A code over GF$(q^m)$ can be imaged or expanded into a code over GF$(q)$
using a basis for the extension field over the base field. The properties of
such an image depend on the original code and the basis chosen for imaging.
Problems relating the properties of a code and its image with respect to a
basis have been of great interest in the field of coding theory. In this work,
a generalized version of the problem of self-orthogonality of the $q$-ary image
of a $q^m$-ary code has been considered. Given an inner product (more
generally, a biadditive form), necessary and sufficient conditions have been
derived for a code over a field extension and an expansion basis so that an
image of that code is self-orthogonal. The conditions require that the original
code be self-orthogonal with respect to several related biadditive forms
whenever certain power sums of the dual basis elements do not vanish. Numerous
interesting corollaries have been derived by specializing the general
conditions. An interesting result for the canonical or regular inner product in
fields of characteristic two is that only self-orthogonal codes result in
self-orthogonal images. Another result is that image of a code is
self-orthogonal for all bases if and only if trace of the code is
self-orthogonal, except for the case of binary images of 4-ary codes. The
conditions are particularly simple to state and apply for cyclic codes. To
illustrate a possible application, new quantum error-correcting codes have been
constructed with larger minimum distance than previously known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606107</id><created>2006-06-26</created><authors><author><keyname>Burbey</keyname><forenames>Ingrid</forenames></author><author><keyname>Kwon</keyname><forenames>Gyuhyun</forenames></author><author><keyname>Murthy</keyname><forenames>Uma</forenames></author><author><keyname>Polys</keyname><forenames>Nicholas</forenames></author><author><keyname>Vincent</keyname><forenames>Prince</forenames></author></authors><title>Human Information Processing with the Personal Memex</title><categories>cs.HC</categories><abstract>  In this report, we describe the work done in a project that explored the
human information processing aspects of a personal memex (a memex to organize
personal information). In the project, we considered the use of the personal
memex, focusing on information recall, by three populations: people with Mild
Cognitive Impairment, those diagnosed with Macular Degeneration, and a
high-functioning population. The outcomes of the project included human
information processing-centered design guidelines for the memex interface, a
low-fidelity prototype, and an annotated bibliography for human information
processing, usability and design literature relating to the memex and the
populations we explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606108</id><created>2006-06-26</created><authors><author><keyname>Ba&#xef;na</keyname><forenames>Salah</forenames><affiliation>CRAN</affiliation></author><author><keyname>Panetto</keyname><forenames>Herv&#xe9;</forenames><affiliation>CRAN</affiliation></author><author><keyname>Benali</keyname><forenames>Khalid</forenames><affiliation>LORIA</affiliation></author></authors><title>A Product Oriented Modelling Concept: Holons for systems synchronisation
  and interoperability</title><categories>cs.SE</categories><proxy>ccsd ccsd-00082038</proxy><journal-ref>8th International Conference on Enterprise Information Systems,
  ICEIS'2006, Paphos, Chypre (23/05/2006) -</journal-ref><abstract>  Nowadays, enterprises are confronted to growing needs for traceability,
product genealogy and product life cycle management. To meet those needs, the
enterprise and applications in the enterprise environment have to manage flows
of information that relate to flows of material and that are managed in shop
floor level. Nevertheless, throughout product lifecycle coordination needs to
be established between reality in the physical world (physical view) and the
virtual world handled by manufacturing information systems (informational
view). This paper presents the &quot;Holon&quot; modelling concept as a means for the
synchronisation of both physical view and informational views. Afterwards, we
show how the concept of holon can play a major role in ensuring
interoperability in the enterprise context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606109</identifier>
 <datestamp>2012-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606109</id><created>2006-06-26</created><updated>2010-08-29</updated><authors><author><keyname>Mendel</keyname><forenames>Manor</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>Maximum gradient embeddings and monotone clustering</title><categories>cs.DS</categories><comments>25 pages, 2 figures. Final version, minor revision of the previous
  one. To appear in &quot;Combinatorica&quot;</comments><msc-class>30L05, 68W25</msc-class><journal-ref>Combinatorica 30(5) (2010), 581--615</journal-ref><doi>10.1007/s00493-010-2302-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let (X,d_X) be an n-point metric space. We show that there exists a
distribution D over non-contractive embeddings into trees f:X--&gt;T such that for
every x in X, the expectation with respect to D of the maximum over y in X of
the ratio d_T(f(x),f(y)) / d_X(x,y) is at most C (log n)^2, where C is a
universal constant. Conversely we show that the above quadratic dependence on
log n cannot be improved in general. Such embeddings, which we call maximum
gradient embeddings, yield a framework for the design of approximation
algorithms for a wide range of clustering problems with monotone costs,
including fault-tolerant versions of k-median and facility location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606110</id><created>2006-06-27</created><updated>2006-06-30</updated><authors><author><keyname>Mundinger</keyname><forenames>Jochen</forenames></author><author><keyname>Weber</keyname><forenames>Richard R.</forenames></author><author><keyname>Weiss</keyname><forenames>Gideon</forenames></author></authors><title>Optimal Scheduling of Peer-to-Peer File Dissemination</title><categories>cs.NI cs.DS math.OC</categories><comments>27 pages, 3 figures. (v2) added a note about possible strengthening
  of Theorem 5 at end of proof; updated some references</comments><abstract>  Peer-to-peer (P2P) overlay networks such as BitTorrent and Avalanche are
increasingly used for disseminating potentially large files from a server to
many end users via the Internet. The key idea is to divide the file into many
equally-sized parts and then let users download each part (or, for network
coding based systems such as Avalanche, linear combinations of the parts)
either from the server or from another user who has already downloaded it.
However, their performance evaluation has typically been limited to comparing
one system relative to another and typically been realized by means of
simulation and measurements. In contrast, we provide an analytic performance
analysis that is based on a new uplink-sharing version of the well-known
broadcasting problem. Assuming equal upload capacities, we show that the
minimal time to disseminate the file is the same as for the simultaneous
send/receive version of the broadcasting problem. For general upload
capacities, we provide a mixed integer linear program (MILP) solution and a
complementary fluid limit solution. We thus provide a lower bound which can be
used as a performance benchmark for any P2P file dissemination system. We also
investigate the performance of a decentralized strategy, providing evidence
that the performance of necessarily decentralized P2P file dissemination
systems should be close to this bound and therefore that it is useful in
practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606111</id><created>2006-06-27</created><authors><author><keyname>Haouzi</keyname><forenames>Hind El</forenames><affiliation>CRAN</affiliation></author></authors><title>Models simulation and interoperability using MDA and HLA</title><categories>cs.OH</categories><comments>8 pages</comments><proxy>ccsd ccsd-00082405</proxy><journal-ref>Doctoral Symposium, IFAC/IFIP International conference on
  Interoperability for Enterprise Applications and Software (I-ESA'2006), March
  22-24, 2006,, France (2006)</journal-ref><abstract>  In the manufacturing context, there have been numerous efforts to use
modeling and simulation tools and techniques to improve manufacturing
efficiency over the last four decades. While an increasing number of
manufacturing system decisions are being made based on the use of models, their
use is still sporadic in many manufacturing environments. Our paper advocates
for an approach combining MDA (model driven architecture) and HLA (High Level
Architecture), the IEEE standard for modeling and simulation, in order to
overcome the deficiencies of current simulation methods at the level of
interoperability and reuse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606112</id><created>2006-06-27</created><authors><author><keyname>Baina</keyname><forenames>Salah</forenames><affiliation>CRAN</affiliation></author><author><keyname>Morel</keyname><forenames>G&#xe9;rard</forenames><affiliation>CRAN</affiliation></author></authors><title>Product Centric Holons for Synchronisation and Interoperability in
  Manufacturing Environments</title><categories>cs.SE</categories><proxy>ccsd ccsd-00082140</proxy><journal-ref>12th IFAC Symposium on Information Control Problems in
  Manufacturing, INCOM'2006, St-Etienne, France (17/05/2006) CDROM</journal-ref><abstract>  In the last few years, lot of work has been done in order to ensure
enterprise applications interoperability; however, proposed solutions focus
mainly on enterprise processes. Indeed, throughout product lifecycle
coordination needs to be established between reality in the physical world
(physical view) and the virtual world handled by manufacturing information
systems (informational view). This paper presents a holonic approach that
enables synchronisation of both physical and informational views. A model
driven approach for interoperability is proposed to ensure interoperability of
holon based models with other applications in the enterprise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606113</identifier>
 <datestamp>2007-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606113</id><created>2006-06-27</created><authors><author><keyname>Marin</keyname><forenames>Marius</forenames></author><author><keyname>Moonen</keyname><forenames>Leon</forenames></author><author><keyname>van Deursen</keyname><forenames>Arie</forenames></author></authors><title>A common framework for aspect mining based on crosscutting concern sorts</title><categories>cs.SE cs.PL</categories><comments>14 pages</comments><report-no>TUD-SERG-2006-009</report-no><journal-ref>Proceedings Working Conference on Reverse Engineering (WCRE), IEEE
  Computer Society, 2006, pages 29-38</journal-ref><doi>10.1109/WCRE.2006.6</doi><abstract>  The increasing number of aspect mining techniques proposed in literature
calls for a methodological way of comparing and combining them in order to
assess, and improve on, their quality. This paper addresses this situation by
proposing a common framework based on crosscutting concern sorts which allows
for consistent assessment, comparison and combination of aspect mining
techniques. The framework identifies a set of requirements that ensure
homogeneity in formulating the mining goals, presenting the results and
assessing their quality.
  We demonstrate feasibility of the approach by retrofitting an existing aspect
mining technique to the framework, and by using it to design and implement two
new mining techniques. We apply the three techniques to a known aspect mining
benchmark and show how they can be consistently assessed and combined to
increase the quality of the results. The techniques and combinations are
implemented in FINT, our publicly available free aspect mining tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606114</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606114</id><created>2006-06-27</created><updated>2006-07-28</updated><authors><author><keyname>Rezaeian</keyname><forenames>Mohammad</forenames></author></authors><title>Hidden Markov Process: A New Representation, Entropy Rate and Estimation
  Entropy</title><categories>cs.IT math.IT</categories><comments>7 pages. Submitted to IEEE Transactions on Information Theory</comments><abstract>  We consider a pair of correlated processes {Z_n} and {S_n} (two sided), where
the former is observable and the later is hidden. The uncertainty in the
estimation of Z_n upon its finite past history is H(Z_n|Z_0^{n-1}), and for
estimation of S_n upon this observation is H(S_n|Z_0^{n-1}), which are both
sequences of n. The limits of these sequences (and their existence) are of
practical and theoretical interest. The first limit, if exists, is the entropy
rate. We call the second limit the estimation entropy. An example of a process
jointly correlated to another one is the hidden Markov process. It is the
memoryless observation of the Markov state process where state transitions are
independent of past observations. We consider a new representation of hidden
Markov process using iterated function system. In this representation the state
transitions are deterministically related to the process. This representation
provides a unified framework for the analysis of the two limiting entropies for
this process, resulting in integral expressions for the limits. This analysis
shows that under mild conditions the limits exist and provides a simple method
for calculating the elements of the corresponding sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606115</id><created>2006-06-28</created><authors><author><keyname>Borges</keyname><forenames>Jose</forenames></author><author><keyname>Levene</keyname><forenames>Mark</forenames></author></authors><title>Evaluating Variable Length Markov Chain Models for Analysis of User Web
  Navigation Sessions</title><categories>cs.AI cs.IR</categories><abstract>  Markov models have been widely used to represent and analyse user web
navigation data. In previous work we have proposed a method to dynamically
extend the order of a Markov chain model and a complimentary method for
assessing the predictive power of such a variable length Markov chain. Herein,
we review these two methods and propose a novel method for measuring the
ability of a variable length Markov model to summarise user web navigation
sessions up to a given length. While the summarisation ability of a model is
important to enable the identification of user navigation patterns, the ability
to make predictions is important in order to foresee the next link choice of a
user after following a given trail so as, for example, to personalise a web
site. We present an extensive experimental evaluation providing strong evidence
that prediction accuracy increases linearly with summarisation ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606116</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606116</id><created>2006-06-28</created><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author></authors><title>New Algorithms for Regular Expression Matching</title><categories>cs.DS</categories><abstract>  In this paper we revisit the classical regular expression matching problem,
namely, given a regular expression $R$ and a string $Q$, decide if $Q$ matches
one of the strings specified by $R$. Let $m$ and $n$ be the length of $R$ and
$Q$, respectively. On a standard unit-cost RAM with word length $w \geq \log
n$, we show that the problem can be solved in $O(m)$ space with the following
running times: \begin{equation*} \begin{cases}
  O(n\frac{m \log w}{w} + m \log w) &amp; \text{if $m &gt; w$} \\
  O(n\log m + m\log m) &amp; \text{if $\sqrt{w} &lt; m \leq w$} \\
  O(\min(n+ m^2, n\log m + m\log m)) &amp; \text{if $m \leq \sqrt{w}$.} \end{cases}
\end{equation*} This improves the best known time bound among algorithms using
$O(m)$ space. Whenever $w \geq \log^2 n$ it improves all known time bounds
regardless of how much space is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606117</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606117</id><created>2006-06-28</created><authors><author><keyname>Portier</keyname><forenames>Fabrice</forenames><affiliation>IETR</affiliation></author><author><keyname>Legouable</keyname><forenames>R.</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Maret</keyname><forenames>L.</forenames><affiliation>LETI</affiliation></author><author><keyname>Bauer</keyname><forenames>F.</forenames><affiliation>NOKIA Research Center</affiliation></author><author><keyname>Neda</keyname><forenames>N.</forenames><affiliation>UNIS</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>J. -F.</forenames><affiliation>IETR</affiliation></author><author><keyname>Hemming</keyname><forenames>E.</forenames><affiliation>NOKIA Research Center</affiliation></author><author><keyname>Noes</keyname><forenames>M. Des</forenames><affiliation>LETI</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>M.</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Collaboration</keyname><forenames>the projet europ&#xe9;en Matrice</forenames></author></authors><title>Performance comparison of multi-user detectors for the downlink of a
  broadband MC-CDMA system</title><categories>cs.IT math.IT</categories><proxy>ccsd ccsd-00082790</proxy><journal-ref>Proceedings IST Mobile &amp; Wireless Communications Summit (IST
  Summit 2004) (2004) 1</journal-ref><abstract>  In this paper multi-user detection techniques, such as Parallel and Serial
Interference Cancellations (PIC &amp; SIC), General Minimum Mean Square Error
(GMMSE) and polynomial MMSE, for the downlink of a broadband Multi-Carrier Code
Division Multiple Access (MCCDMA) system are investigated. The Bit Error Rate
(BER) and Frame Error Rate (FER) results are evaluated, and compared with
single-user detection (MMSEC, EGC) approaches, as well. The performance
evaluation takes into account the system load, channel coding and modulation
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606118</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606118</id><created>2006-06-28</created><authors><author><keyname>Aubin</keyname><forenames>Sophie</forenames><affiliation>LIPN</affiliation></author><author><keyname>Nazarenko</keyname><forenames>Adeline</forenames><affiliation>LIPN</affiliation></author><author><keyname>N&#xe9;dellec</keyname><forenames>Claire</forenames><affiliation>MIG</affiliation></author></authors><title>Adapting a general parser to a sublanguage</title><categories>cs.CL cs.IR</categories><proxy>ccsd ccsd-00082542</proxy><acm-class>H.4</acm-class><journal-ref>Proceedings of the International Conference on Recent Advances in
  Natural Language Processing (RANLP'05) (2005) 89-93</journal-ref><abstract>  In this paper, we propose a method to adapt a general parser (Link Parser) to
sublanguages, focusing on the parsing of texts in biology. Our main proposal is
the use of terminology (identication and analysis of terms) in order to reduce
the complexity of the text to be parsed. Several other strategies are explored
and finally combined among which text normalization, lexicon and
morpho-guessing module extensions and grammar rules adaptation. We compare the
parsing results before and after these adaptations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606119</id><created>2006-06-28</created><authors><author><keyname>Pyysalo</keyname><forenames>Sampo</forenames><affiliation>LIPN</affiliation></author><author><keyname>Salakoski</keyname><forenames>Tapio</forenames><affiliation>LIPN</affiliation></author><author><keyname>Aubin</keyname><forenames>Sophie</forenames><affiliation>LIPN</affiliation></author><author><keyname>Nazarenko</keyname><forenames>Adeline</forenames><affiliation>LIPN</affiliation></author></authors><title>Lexical Adaptation of Link Grammar to the Biomedical Sublanguage: a
  Comparative Evaluation of Three Approaches</title><categories>cs.CL cs.IR</categories><proxy>ccsd ccsd-00082533</proxy><acm-class>H.4</acm-class><journal-ref>Proceedings of the Second International Symposium on Semantic
  Mining in Biomedicine (SMBM 2006) (2006) 60-67</journal-ref><abstract>  We study the adaptation of Link Grammar Parser to the biomedical sublanguage
with a focus on domain terms not found in a general parser lexicon. Using two
biomedical corpora, we implement and evaluate three approaches to addressing
unknown words: automatic lexicon expansion, the use of morphological clues, and
disambiguation using a part-of-speech tagger. We evaluate each approach
separately for its effect on parsing performance and consider combinations of
these approaches. In addition to a 45% increase in parsing efficiency, we find
that the best approach, incorporating information from a domain part-of-speech
tagger, offers a statistically signicant 10% relative decrease in error. The
adapted parser is available under an open-source license at
http://www.it.utu.fi/biolg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606120</id><created>2006-06-29</created><authors><author><keyname>Formenti</keyname><forenames>Enrico</forenames><affiliation>I3S</affiliation></author><author><keyname>Masson</keyname><forenames>Beno&#xee;t</forenames><affiliation>I3S</affiliation></author><author><keyname>Pisokas</keyname><forenames>Theophilos</forenames><affiliation>I3S</affiliation></author></authors><title>On symmetric sandpiles</title><categories>cs.CC cs.PF</categories><comments>Will be presented at ACRI2006 conference</comments><proxy>ccsd ccsd-00083034</proxy><acm-class>F.1.1; G.2.1</acm-class><abstract>  A symmetric version of the well-known SPM model for sandpiles is introduced.
We prove that the new model has fixed point dynamics. Although there might be
several fixed points, a precise description of the fixed points is given.
Moreover, we provide a simple closed formula for counting the number of fixed
points originated by initial conditions made of a single column of grains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606121</identifier>
 <datestamp>2008-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606121</id><created>2006-06-29</created><updated>2008-05-03</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Performance of Orthogonal Beamforming for SDMA with Limited Feedback</title><categories>cs.IT math.IT</categories><comments>27 pages; to appear in IEEE Transactions on Vehicular Technology</comments><abstract>  On the multi-antenna broadcast channel, the spatial degrees of freedom
support simultaneous transmission to multiple users. The optimal multiuser
transmission, known as dirty paper coding, is not directly realizable.
Moreover, close-to-optimal solutions such as Tomlinson-Harashima precoding are
sensitive to CSI inaccuracy. This paper considers a more practical design
called per user unitary and rate control (PU2RC), which has been proposed for
emerging cellular standards. PU2RC supports multiuser simultaneous
transmission, enables limited feedback, and is capable of exploiting multiuser
diversity. Its key feature is an orthogonal beamforming (or precoding)
constraint, where each user selects a beamformer (or precoder) from a codebook
of multiple orthonormal bases. In this paper, the asymptotic throughput scaling
laws for PU2RC with a large user pool are derived for different regimes of the
signal-to-noise ratio (SNR). In the multiuser-interference-limited regime, the
throughput of PU2RC is shown to scale logarithmically with the number of users.
In the normal SNR and noise-limited regimes, the throughput is found to scale
double logarithmically with the number of users and also linearly with the
number of antennas at the base station. In addition, numerical results show
that PU2RC achieves higher throughput and is more robust against CSI
quantization errors than the popular alternative of zero-forcing beamforming if
the number of users is sufficiently large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606122</id><created>2006-06-29</created><authors><author><keyname>Mueller</keyname><forenames>Wolfgang</forenames></author><author><keyname>Boykin</keyname><forenames>P. Oscar</forenames></author><author><keyname>Sarshar</keyname><forenames>Nima</forenames></author><author><keyname>Roychowdhury</keyname><forenames>Vwani P.</forenames></author></authors><title>Comparison of Image Similarity Queries in P2P Systems</title><categories>cs.DC cs.NI</categories><comments>To appear in IEEE P2P2006</comments><abstract>  Given some of the recent advances in Distributed Hash Table (DHT) based
Peer-To-Peer (P2P) systems we ask the following questions: Are there
applications where unstructured queries are still necessary (i.e., the
underlying queries do not efficiently map onto any structured framework), and
are there unstructured P2P systems that can deliver the high bandwidth and
computing performance necessary to support such applications. Toward this end,
we consider an image search application which supports queries based on image
similarity metrics, such as color histogram intersection, and discuss why in
this setting, standard DHT approaches are not directly applicable. We then
study the feasibility of implementing such an image search system on two
different unstructured P2P systems: power-law topology with percolation search,
and an optimized super-node topology using structured broadcasts. We examine
the average and maximum values for node bandwidth, storage and processing
requirements in the percolation and super-node models, and show that current
high-end computers and high-speed links have sufficient resources to enable
deployments of large-scale complex image search systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606123</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606123</id><created>2006-06-29</created><authors><author><keyname>Alves</keyname><forenames>Atos Ramos</forenames></author></authors><title>Use MPLS in Lan's</title><categories>cs.NI cs.CR</categories><comments>9 pages, 0 figures tests in laboratory</comments><acm-class>K.6.3; J.7; I.6.4; I.6.1; D.4.6; D.4.8</acm-class><abstract>  To demonstrate the result of researches in laboratory with the focus in
exhibiting the real impact of the use of the technology MPLS in LAN. Through
these researches we will verify that the investment in this technology is
shown, of the point of view cost/benefit, very interesting, being necessary,
however, the adoption of another measured, in order to settle down a
satisfactory level in the items Quality and safety in the sending of packages
in VPN but assisting to the requirement latency of the net very well being
shown in the tests that it consumes on average one Tuesday leaves of the time
spend for the same function in routing IP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606124</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606124</id><created>2006-06-29</created><updated>2007-05-11</updated><authors><author><keyname>Falconer</keyname><forenames>Sean M.</forenames></author><author><keyname>Maslov</keyname><forenames>Dmitri</forenames></author></authors><title>Weighted hierarchical alignment of directed acyclic graph</title><categories>cs.DS</categories><abstract>  In some applications of matching, the structural or hierarchical properties
of the two graphs being aligned must be maintained. The hierarchical properties
are induced by the direction of the edges in the two directed graphs. These
structural relationships defined by the hierarchy in the graphs act as a
constraint on the alignment. In this paper, we formalize the above problem as
the weighted alignment between two directed acyclic graphs. We prove that this
problem is NP-complete, show several upper bounds for approximating the
solution, and finally introduce polynomial time algorithms for sub-classes of
directed acyclic graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606125</id><created>2006-06-29</created><authors><author><keyname>Marin</keyname><forenames>Marius</forenames></author></authors><title>Formalizing typical crosscutting concerns</title><categories>cs.SE cs.PL</categories><comments>24 pages</comments><report-no>TUD-SERG-2006-010</report-no><abstract>  We present a consistent system for referring crosscutting functionality,
relating crosscutting concerns to specific implementation idioms, and
formalizing their underlying relations through queries. The system is based on
generic crosscutting concerns that we organize and describe in a catalog.
  We have designed and implemented a tool support for querying source code for
instances of the proposed generic concerns and organizing them in composite
concern models. The composite concern model adds a new dimension to the
dominant decomposition of the system for describing and making explicit source
code relations specific to crosscutting concerns implementations.
  We use the proposed approach to describe crosscutting concerns in design
patterns and apply the tool to an opensource system (JHotDraw).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606126</id><created>2006-06-29</created><authors><author><keyname>Goldenberg</keyname><forenames>Eldan</forenames></author><author><keyname>Garcowski</keyname><forenames>Jacob R.</forenames></author><author><keyname>Beer</keyname><forenames>Randall D.</forenames></author></authors><title>May We Have Your Attention: Analysis of a Selective Attention Task</title><categories>cs.NE cs.AI</categories><comments>In S. Schaal, A. Ijspeert, A. Billard, S. Vijayakumar, J. Hallam &amp;
  J-A. Meyer (Eds.), From Animals to Animats 8: Proceedings of the Eighth
  International Conference on the Simulation of Adaptive Behavior (pp 49-56).
  MIT Press</comments><abstract>  In this paper we present a deeper analysis than has previously been carried
out of a selective attention problem, and the evolution of continuous-time
recurrent neural networks to solve it. We show that the task has a rich
structure, and agents must solve a variety of subproblems to perform well. We
consider the relationship between the complexity of an agent and the ease with
which it can evolve behavior that generalizes well across subproblems, and
demonstrate a shaping protocol that improves generalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606127</id><created>2006-06-29</created><authors><author><keyname>Roughgarden</keyname><forenames>Tim</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Sundararajan</keyname><forenames>Mukund</forenames><affiliation>Stanford University</affiliation></author></authors><title>Approximately Efficient Cost-Sharing Mechanisms</title><categories>cs.GT</categories><comments>latex source, 22 pages, 1 figure</comments><acm-class>F.2.0</acm-class><abstract>  We make three different types of contributions to cost-sharing: First, we
identify several new classes of combinatorial cost functions that admit
incentive-compatible mechanisms achieving both a constant-factor approximation
of budget-balance and a polylogarithmic approximation of the social cost
formulation of efficiency. Second, we prove a new, optimal lower bound on the
approximate efficiency of every budget-balanced Moulin mechanism for Steiner
tree or SSRoB cost functions. This lower bound exposes a latent approximation
hierarchy among different cost-sharing problems. Third, we show that weakening
the definition of incentive-compatibility to strategyproofness can permit
exponentially more efficient approximately budget-balanced mechanisms, in
particular for set cover cost-sharing problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0606128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0606128</id><created>2006-06-30</created><authors><author><keyname>Krizhanovsky</keyname><forenames>A.</forenames></author></authors><title>Automatic forming lists of semantically related terms based on texts
  rating in the corpus with hyperlinks and categories (In Russian)</title><categories>cs.IR cs.DM</categories><comments>6 pages, 1 figure, in Russian, PDF, for other formats see
  http://whinger.narod.ru/paper/index.html</comments><acm-class>H.3.1; H.3.3; H.4.3; G.2.2</acm-class><abstract>  HITS adapted algorithm for synonym search, the program architecture, and the
program work evaluation with test examples are presented in the paper.
Synarcher program for synonym (and related terms) search in the text corpus of
special structure (Wikipedia) was developed. The results of search are
presented in the form of a graph. It is possible to explore the graph and
search graph elements interactively. The proposed algorithm could be applied to
the search request extending and for synonym dictionary forming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607001</id><created>2006-07-01</created><authors><author><keyname>Bhattacharya</keyname><forenames>Chinmoy</forenames></author><author><keyname>Mahapatra</keyname><forenames>P. R.</forenames></author></authors><title>A Novel Application of Lifting Scheme for Multiresolution Correlation of
  Complex Radar Signals</title><categories>cs.DC cs.CC</categories><abstract>  The lifting scheme of discrete wavelet transform (DWT) is now quite well
established as an efficient technique for image compression, and has been
incorporated into the JPEG2000 standards. However, the potential of the lifting
scheme has not been exploited in the context of correlationbased processing,
such as encountered in radar applications. This paper presents a complete and
consistent framework for the application of DWT for correlation of complex
signals. In particular, lifting scheme factorization of biorthogonal
filterbanks is carried out in dual analysis basis spaces for multiresolution
correlation of complex radar signals in the DWT domain only. A causal
formulation of lifting for orthogonal filterbank is also developed. The
resulting parallel algorithms and consequent saving of computational effort are
briefly dealt with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607002</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607002</id><created>2006-07-02</created><authors><author><keyname>Sason</keyname><forenames>I.</forenames></author><author><keyname>Goldenberg</keyname><forenames>I.</forenames></author></authors><title>Coding for Parallel Channels: Gallager Bounds for Binary Linear Codes
  with Applications to Repeat-Accumulate Codes and Variations</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory, June 2006 (57 pages,
  9 figures)</comments><abstract>  This paper is focused on the performance analysis of binary linear block
codes (or ensembles) whose transmission takes place over independent and
memoryless parallel channels. New upper bounds on the maximum-likelihood (ML)
decoding error probability are derived. These bounds are applied to various
ensembles of turbo-like codes, focusing especially on repeat-accumulate codes
and their recent variations which possess low encoding and decoding complexity
and exhibit remarkable performance under iterative decoding. The framework of
the second version of the Duman and Salehi (DS2) bounds is generalized to the
case of parallel channels, along with the derivation of their optimized tilting
measures. The connection between the generalized DS2 and the 1961 Gallager
bounds, addressed by Divsalar and by Sason and Shamai for a single channel, is
explored in the case of an arbitrary number of independent parallel channels.
The generalization of the DS2 bound for parallel channels enables to re-derive
specific bounds which were originally derived by Liu et al. as special cases of
the Gallager bound. In the asymptotic case where we let the block length tend
to infinity, the new bounds are used to obtain improved inner bounds on the
attainable channel regions under ML decoding. The tightness of the new bounds
for independent parallel channels is exemplified for structured ensembles of
turbo-like codes. The improved bounds with their optimized tilting measures
show, irrespectively of the block length of the codes, an improvement over the
union bound and other previously reported bounds for independent parallel
channels; this improvement is especially pronounced for moderate to large block
lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607003</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607003</id><created>2006-07-02</created><authors><author><keyname>Twitto</keyname><forenames>M.</forenames></author><author><keyname>Sason</keyname><forenames>I.</forenames></author><author><keyname>Shamai</keyname><forenames>S.</forenames></author></authors><title>Tightened Upper Bounds on the ML Decoding Error Probability of Binary
  Linear Block Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Trans. on Information Theory (as a
  correspondence), February 2006</comments><abstract>  The performance of maximum-likelihood (ML) decoded binary linear block codes
is addressed via the derivation of tightened upper bounds on their decoding
error probability. The upper bounds on the block and bit error probabilities
are valid for any memoryless, binary-input and output-symmetric communication
channel, and their effectiveness is exemplified for various ensembles of
turbo-like codes over the AWGN channel. An expurgation of the distance spectrum
of binary linear block codes further tightens the resulting upper bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607004</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607004</id><created>2006-07-02</created><updated>2006-09-02</updated><authors><author><keyname>Twitto</keyname><forenames>M.</forenames></author><author><keyname>Sason</keyname><forenames>I.</forenames></author></authors><title>On the Error Exponents of Some Improved Tangential-Sphere Bounds</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Trans. on Information Theory (as a
  correspondence), March 2006. Revised (August 2006)</comments><abstract>  The performance of maximum-likelihood (ML) decoded binary linear block codes
over the AWGN channel is addressed via the tangential-sphere bound (TSB) and
two of its recent improved versions. The paper is focused on the derivation of
the error exponents of these bounds. Although it was exemplified that some
recent improvements of the TSB tighten this bound for finite-length codes, it
is demonstrated in this paper that their error exponents coincide. For an
arbitrary ensemble of binary linear block codes, the common value of these
error exponents is explicitly expressed in terms of the asymptotic growth rate
of the average distance spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607005</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607005</id><created>2006-07-02</created><updated>2006-11-29</updated><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Dezert</keyname><forenames>Jean</forenames></author></authors><title>Belief Conditioning Rules (BCRs)</title><categories>cs.AI</categories><comments>26 pages</comments><acm-class>I.4.8</acm-class><abstract>  In this paper we propose a new family of Belief Conditioning Rules (BCRs) for
belief revision. These rules are not directly related with the fusion of
several sources of evidence but with the revision of a belief assignment
available at a given time according to the new truth (i.e. conditioning
constraint) one has about the space of solutions of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607006</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607006</id><created>2006-07-02</created><authors><author><keyname>Ceccato</keyname><forenames>Mariano</forenames></author><author><keyname>Marin</keyname><forenames>Marius</forenames></author><author><keyname>Mens</keyname><forenames>Kim</forenames></author><author><keyname>Moonen</keyname><forenames>Leon</forenames></author><author><keyname>Tonella</keyname><forenames>Paolo</forenames></author><author><keyname>Tourwe</keyname><forenames>Tom</forenames></author></authors><title>Applying and Combining Three Different Aspect Mining Techniques</title><categories>cs.SE cs.PL</categories><comments>28 pages</comments><report-no>TUD-SERG-2006-002</report-no><abstract>  Understanding a software system at source-code level requires understanding
the different concerns that it addresses, which in turn requires a way to
identify these concerns in the source code. Whereas some concerns are
explicitly represented by program entities (like classes, methods and
variables) and thus are easy to identify, crosscutting concerns are not
captured by a single program entity but are scattered over many program
entities and are tangled with the other concerns. Because of their crosscutting
nature, such crosscutting concerns are difficult to identify, and reduce the
understandability of the system as a whole.
  In this paper, we report on a combined experiment in which we try to identify
crosscutting concerns in the JHotDraw framework automatically. We first apply
three independently developed aspect mining techniques to JHotDraw and evaluate
and compare their results. Based on this analysis, we present three interesting
combinations of these three techniques, and show how these combinations provide
a more complete coverage of the detected concerns as compared to the original
techniques individually. Our results are a first step towards improving the
understandability of a system that contains crosscutting concerns, and can be
used as a basis for refactoring the identified crosscutting concerns into
aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607007</identifier>
 <datestamp>2009-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607007</id><created>2006-07-03</created><updated>2009-10-04</updated><authors><author><keyname>Lubachevsky</keyname><forenames>Boris D.</forenames></author></authors><title>Theory of sexes by Geodakian as it is advanced by Iskrin</title><categories>cs.NE cs.GL</categories><comments>9 pages</comments><acm-class>F.1.1; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1960s V.Geodakian proposed a theory that explains sexes as a mechanism for
evolutionary adaptation of the species to changing environmental conditions. In
2001 V.Iskrin refined and augmented the concepts of Geodakian and gave a new
and interesting explanation to several phenomena which involve sex, and sex
ratio, including the war-years phenomena. He also introduced a new concept of
the &quot;catastrophic sex ratio.&quot; This note is an attempt to digest technical
aspects of the new ideas by Iskrin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607008</id><created>2006-07-03</created><authors><author><keyname>Havet</keyname><forenames>F&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Sereni</keyname><forenames>Jean-S&#xe9;bastien</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Skrekovski</keyname><forenames>Riste</forenames></author></authors><title>3-facial colouring of plane graphs</title><categories>cs.DM</categories><proxy>ccsd inria-00083533</proxy><abstract>  A plane graph is l-facially k-colourable if its vertices can be coloured with
k colours such that any two distinct vertices on a facial segment of length at
most l are coloured differently. We prove that every plane graph is 3-facially
11-colourable. As a consequence, we derive that every 2-connected plane graph
with maximum face-size at most 7 is cyclically 11-colourable. These two bounds
are for one off from those that are proposed by the (3l+1)-Conjecture and the
Cyclic Conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607009</id><created>2006-07-03</created><authors><author><keyname>Pritykin</keyname><forenames>Yuri</forenames></author></authors><title>Almost Periodicity, Finite Automata Mappings and Related Effectiveness
  Issues</title><categories>cs.DM</categories><comments>12 pages. Continuation of the results from the paper &quot;Strongly Almost
  Periodic Sequences under Finite Automata Mappings&quot; on cs.DM/0605026 Enhanced
  version of the talk on Workshop on Words and Automata, St Petersburg, Russia,
  June 7th, 2006 (satellite to CSR'06)</comments><acm-class>G.2.1; F.1.1</acm-class><abstract>  The paper studies different variants of almost periodicity notion. We
introduce the class of eventually strongly almost periodic sequences where some
suffix is strongly almost periodic (=uniformly recurrent). The class of almost
periodic sequences includes the class of eventually strongly almost periodic
sequences, and we prove this inclusion to be strict. We prove that the class of
eventually strongly almost periodic sequences is closed under finite automata
mappings and finite transducers. Moreover, an effective form of this result is
presented. Finally we consider some algorithmic questions concerning almost
periodicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607010</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607010</id><created>2006-07-03</created><authors><author><keyname>Sattath</keyname><forenames>Samuel</forenames></author></authors><title>ITs, a structure sensitive information theory</title><categories>cs.IT math.IT</categories><abstract>  Broadly speaking Information theory (IT) assumes no structure of the
underlying states. But what about contexts where states do have a clear
structure - how should IT cope with such situations? And if such coping is at
all possible then - how should structure be expressed so that it can be coped
with? A possible answer to these questions is presented here. Noting that IT
can cope well with a structure expressed as an accurate clustering (by shifting
to the implied reduced alphabet), a generalization is suggested in which
structure is expressed as a measure on reduced alphabets. Given such structure
an extension of IT is presented where the reduced alphabets are treated
simultaneously. This structure-sensitive IT, called ITs, extends traditional IT
in the sense that: a)there are structure-sensitive analogs to the notions of
traditional IT and b)translating a theorem in IT by replacing its notions with
their structure-sensitive counterparts, yields a (provable) theorem of ITs.
Seemingly paradoxically, ITs extends IT but it's completely within the
framework of IT. The richness of the suggested structures is demonstrated by
two disparate families studied in more detail: the family of hierarchical
structures and the family of linear structures. The formal findings extend the
scope of cases to which a rigorous application of IT can be applied (with
implications on quantization, for example). The implications on the foundations
of IT are that the assumption regarding no underlying structure of states is
not mandatory and that there is a framework for expressing such underlying
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607011</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607011</id><created>2006-07-04</created><updated>2007-05-07</updated><authors><author><keyname>Mahalanobis</keyname><forenames>Ayan</forenames></author></authors><title>A simple generalization of El-Gamal cryptosystem to non-abelian groups</title><categories>cs.CR math.GR</categories><abstract>  In this paper we study the MOR cryptosystem. We use the group of
unitriangular matrices over a finite field as the non-abelian group in the MOR
cryptosystem. We show that a cryptosystem similar to the El-Gamal cryptosystem
over finite fields can be built using the proposed groups and a set of
automorphisms of these groups. We also show that the security of this proposed
MOR cryptosystem is equivalent to the El-Gamal cryptosystem over finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607012</id><created>2006-07-05</created><authors><author><keyname>Vercoustre</keyname><forenames>Anne-Marie</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Fegas</keyname><forenames>Mounir</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Gul</keyname><forenames>Saba</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Lechevallier</keyname><forenames>Yves</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author></authors><title>A Flexible Structured-based Representation for XML Document Mining</title><categories>cs.IR</categories><comments>This is the authors' version. To access the final version go to the
  editor's site through the DOI</comments><proxy>ccsd inria-00000839</proxy><journal-ref>Dans The Fourth International Workshop of the Initiative for the
  Evaluation of XML Retrieval (INEX 2005)</journal-ref><doi>10.1007/11766278\_34</doi><abstract>  This paper reports on the INRIA group's approach to XML mining while
participating in the INEX XML Mining track 2005. We use a flexible
representation of XML documents that allows taking into account the structure
only or both the structure and content. Our approach consists of representing
XML documents by a set of their sub-paths, defined according to some criteria
(length, root beginning, leaf ending). By considering those sub-paths as words,
we can use standard methods for vocabulary reduction, and simple clustering
methods such as K-means that scale well. We actually use an implementation of
the clustering algorithm known as &quot;dynamic clouds&quot; that can work with distinct
groups of independent variables put in separate variables. This is useful in
our model since embedded sub-paths are not independent: we split potentially
dependant paths into separate variables, resulting in each of them containing
independant paths. Experiments with the INEX collections show good results for
the structure-only collections, but our approach could not scale well for large
structure-and-content collections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607013</id><created>2006-07-05</created><authors><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author></authors><title>Database Querying under Changing Preferences</title><categories>cs.DB cs.AI</categories><comments>Submitted to a journal</comments><acm-class>H.2.3; F.4.1; I.2.3</acm-class><abstract>  We present here a formal foundation for an iterative and incremental approach
to constructing and evaluating preference queries. Our main focus is on query
modification: a query transformation approach which works by revising the
preference relation in the query. We provide a detailed analysis of the cases
where the order-theoretic properties of the preference relation are preserved
by the revision. We consider a number of different revision operators: union,
prioritized and Pareto composition. We also formulate algebraic laws that
enable incremental evaluation of preference queries. Finally, we consider two
variations of the basic framework: finite restrictions of preference relations
and weak-order extensions of strict partial order preference relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607014</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607014</id><created>2006-07-05</created><authors><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author></authors><title>Strong Consistency of the Good-Turing Estimator</title><categories>cs.IT math.IT</categories><comments>To appear at IEEE ISIT 2006</comments><abstract>  We consider the problem of estimating the total probability of all symbols
that appear with a given frequency in a string of i.i.d. random variables with
unknown distribution. We focus on the regime in which the block length is large
yet no symbol appears frequently in the string. This is accomplished by
allowing the distribution to change with the block length. Under a natural
convergence assumption on the sequence of underlying distributions, we show
that the total probabilities converge to a deterministic limit, which we
characterize. We then show that the Good-Turing total probability estimator is
strongly consistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607015</id><created>2006-07-05</created><authors><author><keyname>Valle-Lisboa</keyname><forenames>Juan C.</forenames><affiliation>Seccion Biofisica, Facultad de Ciencias, Universidad de la Republica</affiliation></author><author><keyname>Mizraji</keyname><forenames>Eduardo</forenames><affiliation>Seccion Biofisica, Facultad de Ciencias, Universidad de la Republica</affiliation></author></authors><title>The uncovering of hidden structures by Latent Semantic Analysis</title><categories>cs.IR</categories><comments>51 pages, 7 figures, pdf</comments><acm-class>H.3.3; H.3.1</acm-class><abstract>  Latent Semantic Analysis (LSA) is a well known method for information
retrieval. It has also been applied as a model of cognitive processing and
word-meaning acquisition. This dual importance of LSA derives from its capacity
to modulate the meaning of words by contexts, dealing successfully with
polysemy and synonymy. The underlying reasons that make the method work are not
clear enough. We propose that the method works because it detects an underlying
block structure (the blocks corresponding to topics) in the term by document
matrix. In real cases this block structure is hidden because of perturbations.
We propose that the correct explanation for LSA must be searched in the
structure of singular vectors rather than in the profile of singular values.
Using Perron-Frobenius theory we show that the presence of disjoint blocks of
documents is marked by sign-homogeneous entries in the vectors corresponding to
the documents of one block and zeros elsewhere. In the case of nearly disjoint
blocks, perturbation theory shows that if the perturbations are small the zeros
in the leading vectors are replaced by small numbers (pseudo-zeros). Since the
singular values of each block might be very different in magnitude, their order
does not mirror the order of blocks. When the norms of the blocks are similar,
LSA works fine, but we propose that when the topics have different sizes, the
usual procedure of selecting the first k singular triplets (k being the number
of blocks) should be replaced by a method that selects the perturbed Perron
vectors for each block.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607016</id><created>2006-07-06</created><updated>2007-03-21</updated><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Zoeteweij</keyname><forenames>Peter</forenames></author></authors><title>An Analysis of Arithmetic Constraints on Integer Intervals</title><categories>cs.AI cs.PL</categories><comments>44 pages, to appear in 'Constraints' journal</comments><acm-class>D.3.2; D.3.3</acm-class><abstract>  Arithmetic constraints on integer intervals are supported in many constraint
programming systems. We study here a number of approaches to implement
constraint propagation for these constraints. To describe them we introduce
integer interval arithmetic. Each approach is explained using appropriate proof
rules that reduce the variable domains. We compare these approaches using a set
of benchmarks. For the most promising approach we provide results that
characterize the effect of constraint propagation. This is a full version of
our earlier paper, cs.PL/0403016.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607017</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607017</id><created>2006-07-06</created><authors><author><keyname>Portier</keyname><forenames>Fabrice</forenames><affiliation>IETR</affiliation></author><author><keyname>Baudais</keyname><forenames>Jean-Yves</forenames><affiliation>IETR</affiliation></author><author><keyname>H&#xe9;lard</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>IETR</affiliation></author><author><keyname>Collaboration</keyname><forenames>the Projet europeen IST-MATRICE</forenames></author></authors><title>Performance of STBC MC-CDMA systems over outdoor realistic MIMO channels</title><categories>cs.IT math.IT</categories><proxy>ccsd ccsd-00082805</proxy><journal-ref>Proceedings IEEE 60th Vehicular Technology Conference (VTC
  2004-Fall) (2004) 2409-2413</journal-ref><abstract>  The paper deals with orthogonal space-time block coded MC-CDMA systems in
outdoor realistic downlink scenarios with up to two transmit and receive
antennas. Assuming no channel state information at the transmitter, we compare
several linear single-user detection and spreading schemes, with or without
channel coding, achieving a spectral efficiency of 1-2 bits/s/Hz. The different
results obtained demonstrate that spatial diversity significantly improves the
performance of MC-CDMA systems, and allows different chip-mapping without
notably decreasing performance. Moreover, the global system exhibits a good
trade-off between complexity at mobile stations and performance. Then,
Alamouti's STBC MC-CDMA schemes derive full benefit from the frequency and
spatial diversities and can be considered as a very realistic and promising
candidate for the air interface downlink of the 4/sup th/ generation mobile
radio systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607018</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607018</id><created>2006-07-06</created><updated>2006-08-12</updated><authors><author><keyname>Hanna</keyname><forenames>Edward</forenames></author></authors><title>Feynman Checkerboard as a Model of Discrete Space-Time</title><categories>cs.CE</categories><comments>10 pages, 14 figures - changed section 6 title</comments><acm-class>I.6; J.2</acm-class><abstract>  In 1965, Feynman wrote of using a lattice containing one dimension of space
and one dimension of time to derive aspects of quantum mechanics. Instead of
summing the behavior of all possible paths as he did, this paper will consider
the motion of single particles within this discrete Space-Time lattice,
sometimes called Feynman's Checkerboard. This empirical approach yielded
several predicted emergent properties for a discrete Space-Time lattice, one of
which is novel and testable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607019</id><created>2006-07-06</created><authors><author><keyname>Luttrell</keyname><forenames>Stephen</forenames></author></authors><title>Modelling the Probability Density of Markov Sources</title><categories>cs.NE</categories><comments>26 pages</comments><acm-class>I.2.6; I.5.1</acm-class><abstract>  This paper introduces an objective function that seeks to minimise the
average total number of bits required to encode the joint state of all of the
layers of a Markov source. This type of encoder may be applied to the problem
of optimising the bottom-up (recognition model) and top-down (generative model)
connections in a multilayer neural network, and it unifies several previous
results on the optimisation of multilayer neural networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607020</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607020</id><created>2006-07-06</created><updated>2006-07-18</updated><authors><author><keyname>Hsu</keyname><forenames>Chun-Hao</forenames></author><author><keyname>Anastasopoulos</keyname><forenames>Achilleas</forenames></author></authors><title>Iterative Decoding Performance Bounds for LDPC Codes on Noisy Channels</title><categories>cs.IT math.IT</categories><comments>10 pages, no figures. This paper is submitted to the 44rd Annual
  Allerton Conference on Communication, Control and Computing, Monticello, IL,
  USA, Sept. 27-29, 2006</comments><abstract>  The asymptotic iterative decoding performances of low-density parity-check
(LDPC) codes using min-sum (MS) and sum-product (SP) decoding algorithms on
memoryless binary-input output-symmetric (MBIOS) channels are analyzed in this
paper. For MS decoding, the analysis is done by upper bounding the bit error
probability of the root bit of a tree code by the sequence error probability of
a subcode of the tree code assuming the transmission of the all-zero codeword.
The result is a recursive upper bound on the bit error probability after each
iteration. For SP decoding, we derive a recursively determined lower bound on
the bit error probability after each iteration. This recursive lower bound
recovers the density evolution equation of LDPC codes on the binary erasure
channel (BEC) with inequalities satisfied with equalities. A significant
implication of this result is that the performance of LDPC codes under SP
decoding on the BEC is an upper bound of the performance on all MBIOS channels
with the same uncoded bit error probability. All results hold for the more
general multi-edge type LDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607021</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607021</id><created>2006-07-06</created><authors><author><keyname>Chen</keyname><forenames>Jun</forenames></author><author><keyname>He</keyname><forenames>Da-ke</forenames></author><author><keyname>Jagmohan</keyname><forenames>Ashish</forenames></author></authors><title>Slepian-Wolf Code Design via Source-Channel Correspondence</title><categories>cs.IT math.IT</categories><comments>to appear at ISIT 2006</comments><abstract>  We consider Slepian-Wolf code design based on LDPC (low-density parity-check)
coset codes for memoryless source-side information pairs. A density evolution
formula, equipped with a concentration theorem, is derived for Slepian- Wolf
coding based on LDPC coset codes. As a consequence, an intimate connection
between Slepian-Wolf coding and channel coding is established. Specifically we
show that, under density evolution, design of binary LDPC coset codes for
Slepian-Wolf coding of an arbitrary memoryless source-side information pair
reduces to design of binary LDPC codes for binary-input output-symmetric
channels without loss of optimality. With this connection, many classic results
in channel coding can be easily translated into the Slepian-Wolf setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607022</id><created>2006-07-06</created><authors><author><keyname>Maney</keyname><forenames>G. A.</forenames></author></authors><title>Ten Incredibly Dangerous Software Ideas</title><categories>cs.GL</categories><comments>14 page software industry interest book synopsis</comments><abstract>  This is a rough draft synopsis of a book presently in preparation. This book
provides a systematic critique of the software industry. This critique is
accomplished using classical methods in practical design science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607023</id><created>2006-07-07</created><authors><author><keyname>Diaz</keyname><forenames>J.</forenames></author><author><keyname>Mitsche</keyname><forenames>D.</forenames></author><author><keyname>Perez</keyname><forenames>X.</forenames></author></authors><title>Sharp threshold for hamiltonicity of random geometric graphs</title><categories>cs.DM</categories><comments>10 pages, 2 figures</comments><abstract>  We show for an arbitrary $\ell_p$ norm that the property that a random
geometric graph $\mathcal G(n,r)$ contains a Hamiltonian cycle exhibits a sharp
threshold at $r=r(n)=\sqrt{\frac{\log n}{\alpha_p n}}$, where $\alpha_p$ is the
area of the unit disk in the $\ell_p$ norm. The proof is constructive and
yields a linear time algorithm for finding a Hamiltonian cycle of $\RG$ a.a.s.,
provided $r=r(n)\ge\sqrt{\frac{\log n}{(\alpha_p -\epsilon)n}}$ for some fixed
$\epsilon &gt; 0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607024</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607024</id><created>2006-07-07</created><authors><author><keyname>Weber</keyname><forenames>Jos H.</forenames></author><author><keyname>Abdel-Ghaffar</keyname><forenames>Khaled A. S.</forenames></author></authors><title>Results on Parity-Check Matrices with Optimal Stopping and/or Dead-End
  Set Enumerators</title><categories>cs.IT math.IT</categories><comments>8 pages, submitted to IEEE Transactions on Information Theory</comments><abstract>  The performance of iterative decoding techniques for linear block codes
correcting erasures depends very much on the sizes of the stopping sets
associated with the underlying Tanner graph, or, equivalently, the parity-check
matrix representing the code. In this paper, we introduce the notion of
dead-end sets to explicitly demonstrate this dependency. The choice of the
parity-check matrix entails a trade-off between performance and complexity. We
give bounds on the complexity of iterative decoders achieving optimal
performance in terms of the sizes of the underlying parity-check matrices.
Further, we fully characterize codes for which the optimal stopping set
enumerator equals the weight enumerator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607025</id><created>2006-07-07</created><authors><author><keyname>Sandberg</keyname><forenames>Oskar</forenames></author><author><keyname>Clarke</keyname><forenames>Ian</forenames></author></authors><title>The evolution of navigable small-world networks</title><categories>cs.DS cs.DC</categories><abstract>  Small-world networks, which combine randomized and structured elements, are
seen as prevalent in nature. Several random graph models have been given for
small-world networks, with one of the most fruitful, introduced by Jon
Kleinberg, showing in which type of graphs it is possible to route, or
navigate, between vertices with very little knowledge of the graph itself.
Kleinberg's model is static, with random edges added to a fixed grid. In this
paper we introduce, analyze and test a randomized algorithm which successively
rewires a graph with every application. The resulting process gives a model for
the evolution of small-world networks with properties similar to those studied
by Kleinberg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607026</id><created>2006-07-07</created><authors><author><keyname>Aspnes</keyname><forenames>James</forenames></author><author><keyname>Yang</keyname><forenames>Yang Richard</forenames></author><author><keyname>Yin</keyname><forenames>Yitong</forenames></author></authors><title>Path-independent load balancing with unreliable machines</title><categories>cs.DS cs.NI</categories><comments>Full version of paper submitted to SODA 2007</comments><acm-class>F.2.2</acm-class><abstract>  We consider algorithms for load balancing on unreliable machines. The
objective is to optimize the two criteria of minimizing the makespan and
minimizing job reassignments in response to machine failures. We assume that
the set of jobs is known in advance but that the pattern of machine failures is
unpredictable. Motivated by the requirements of BGP routing, we consider
path-independent algorithms, with the property that the job assignment is
completely determined by the subset of available machines and not the previous
history of the assignments. We examine first the question of performance
measurement of path-independent load-balancing algorithms, giving the measure
of makespan and the normalized measure of reassignments cost. We then describe
two classes of algorithms for optimizing these measures against an oblivious
adversary for identical machines. The first, based on independent random
assignments, gives expected reassignment costs within a factor of 2 of optimal
and gives a makespan within a factor of O(log m/log log m) of optimal with high
probability, for unknown job sizes. The second, in which jobs are first grouped
into bins and at most one bin is assigned to each machine, gives
constant-factor ratios on both reassignment cost and makespan, for known job
sizes. Several open problems are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607027</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607027</id><created>2006-07-07</created><updated>2006-10-01</updated><authors><author><keyname>Hu</keyname><forenames>Junli</forenames></author><author><keyname>Loeliger</keyname><forenames>Hans-Andrea</forenames></author><author><keyname>Dauwels</keyname><forenames>Justin</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank</forenames></author></authors><title>A general computation rule for lossy summaries/messages with examples
  from equalization</title><categories>cs.IT math.IT</categories><comments>Proc. of the 44th Allerton Conference on Communication, Control, and
  Computing, Monticello, Ill., USA, Sept. 2006</comments><abstract>  Elaborating on prior work by Minka, we formulate a general computation rule
for lossy messages. An important special case (with many applications in
communications) is the conversion of &quot;soft-bit&quot; messages to Gaussian messages.
By this method, the performance of a Kalman equalizer is improved, both for
uncoded and coded transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607028</id><created>2006-07-07</created><authors><author><keyname>Lavault</keyname><forenames>Christian</forenames><affiliation>LIPN</affiliation></author><author><keyname>Marckert</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Ravelomanana</keyname><forenames>Vlady</forenames><affiliation>LIPN</affiliation></author></authors><title>A Quasi-Optimal Leader Election Algorithm in Radio Networks with
  Log-Logarithmic Awake Time Slots</title><categories>cs.DC cs.NI</categories><proxy>ccsd ccsd-00084603</proxy><abstract>  Radio networks (RN) are distributed systems (\textit{ad hoc networks})
consisting in $n \ge 2$ radio stations. Assuming the number $n$ unknown, two
distinct models of RN without collision detection (\textit{no-CD}) are
addressed: the model with \textit{weak no-CD} RN and the one with
\textit{strong no-CD} RN. We design and analyze two distributed leader election
protocols, each one running in each of the above two (no-CD RN) models,
respectively. Both randomized protocols are shown to elect a leader within
$\BO(\log{(n)})$ expected time, with no station being awake for more than
$\BO(\log{\log{(n)}})$ time slots (such algorithms are said to be
\textit{energy-efficient}). Therefore, a new class of efficient algorithms is
set up that matchthe $\Omega(\log{(n)})$ time lower-bound established by
Kushilevitz and Mansour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607029</identifier>
 <datestamp>2009-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607029</id><created>2006-07-08</created><updated>2006-10-28</updated><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Bansal</keyname><forenames>R. K.</forenames></author></authors><title>A Coding Theorem Characterizing Renyi's Entropy through
  Variable-to-Fixed Length Codes</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607030</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607030</id><created>2006-07-10</created><authors><author><keyname>Vielhaber</keyname><forenames>Michael</forenames></author><author><keyname>Canales</keyname><forenames>Monica del Pilar</forenames></author></authors><title>Towards a General Theory of Simultaneous Diophantine Approximation of
  Formal Power Series: Multidimensional Linear Complexity</title><categories>cs.IT math.IT</categories><comments>28 pages, 1 figure</comments><abstract>  We model the development of the linear complexity of multisequences by a
stochastic infinite state machine, the Battery-Discharge-Model, BDM. The states
s in S of the BDM have asymptotic probabilities or mass Pr(s)=1/(P(q,M)
q^K(s)), where K(s) in N_0 is the class of the state s, and P(q,M)=\sum_(K
in\N0) P_M(K)q^(-K)=\prod_(i=1..M) q^i/(q^i-1) is the generating function of
the number of partitions into at most M parts. We have (for each timestep
modulo M+1) just P_M(K) states of class K \.
  We obtain a closed formula for the asymptotic probability for the linear
complexity deviation d(n) := L(n)-\lceil n\cdot M/(M+1)\rceil with
Pr(d)=O(q^(-|d|(M+1))), for M in N, for d in Z. The precise formula is given in
the text. It has been verified numerically for M=1..8, and is conjectured to
hold for all M in N.
  From the asymptotic growth (proven for all M in N), we infer the Law of the
Logarithm for the linear complexity deviation, -liminf_{n\to\infty} d_a(n) /
log n = 1 /((M+1)log q) = limsup_{n\to\infty} d_a(n) / log n, which immediately
yields L_a(n)/n \to M/(M+1) with measure one, for all M in N, a result recently
shown already by Niederreiter and Wang. Keywords: Linear complexity, linear
complexity deviation, multisequence, Battery Discharge Model, isometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607031</id><created>2006-07-08</created><authors><author><keyname>Lavault</keyname><forenames>Christian</forenames><affiliation>LIPN</affiliation></author><author><keyname>Valencia-Pabon</keyname><forenames>Mario</forenames><affiliation>LIPN</affiliation></author></authors><title>A distributed approximation algorithm for the minimum degree minimum
  weight spanning trees</title><categories>cs.DC cs.DM</categories><proxy>ccsd ccsd-00084600</proxy><abstract>  Fischer has shown how to compute a minimum weight spanning tree of degree at
most $b \Delta^* + \lceil \log\_b n\rceil$ in time $O(n^{4 + 1/\ln b})$ for any
constant $b &gt; 1$, where $\Delta^*$ is the value of an optimal solution and $n$
is the number of nodes in the network. In this paper, we propose a distributed
version of Fischer's algorithm that requires messages and time complexity
$O(n^{2 + 1/\ln b})$, and O(n) space per node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607032</id><created>2006-07-08</created><authors><author><keyname>Lavault</keyname><forenames>Christian</forenames><affiliation>LIPN</affiliation></author><author><keyname>Louchard</keyname><forenames>Guy</forenames><affiliation>ULB</affiliation></author></authors><title>Asymptotic Analysis of a Leader Election Algorithm</title><categories>cs.DC cs.NA</categories><proxy>ccsd ccsd-00084608</proxy><abstract>  Itai and Rodeh showed that, on the average, the communication of a leader
election algorithm takes no more than $LN$ bits, where $L \simeq 2.441716$ and
$N$ denotes the size of the ring. We give a precise asymptotic analysis of the
average number of rounds M(n) required by the algorithm, proving for example
that $\dis M(\infty) := \lim\_{n\to \infty} M(n) = 2.441715879...$, where $n$
is the number of starting candidates in the election. Accurate asymptotic
expressions of the second moment $M^{(2)}(n)$ of the discrete random variable
at hand, its probability distribution, and the generalization to all moments
are given. Corresponding asymptotic expansions $(n\to \infty)$ are provided for
sufficiently large $j$, where $j$ counts the number of rounds. Our numerical
results show that all computations perfectly fit the observed values. Finally,
we investigate the generalization to probability $t/n$, where $t$ is a non
negative real parameter. The real function $\dis M(\infty,t) := \lim\_{n\to
\infty} M(n,t)$ is shown to admit \textit{one unique minimum} $M(\infty,t^{*})$
on the real segment $(0,2)$. Furthermore, the variations of $M(\infty,t)$ on
thewhole real line are also studied in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607033</id><created>2006-07-08</created><authors><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>Planar Graphs: Logical Complexity and Parallel Isomorphism Tests</title><categories>cs.CC cs.LO</categories><comments>36 pages</comments><abstract>  We prove that every triconnected planar graph is definable by a first order
sentence that uses at most 15 variables and has quantifier depth at most
$11\log_2 n+43$. As a consequence, a canonic form of such graphs is computable
in $AC^1$ by the 14-dimensional Weisfeiler-Lehman algorithm. This provides
another way to show that the planar graph isomorphism is solvable in $AC^1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607034</id><created>2006-07-08</created><authors><author><keyname>Lavault</keyname><forenames>Christian</forenames><affiliation>LIPN</affiliation></author><author><keyname>Marckert</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Ravelomanana</keyname><forenames>Vlady</forenames><affiliation>LIPN</affiliation></author></authors><title>Quasi-Optimal Leader Election Algorithms in Radio Networks with
  Loglogarithmic Awake Time Slots</title><categories>cs.DC cs.NI</categories><proxy>ccsd ccsd-00084617</proxy><journal-ref>10th IEEE International Conference on Telecommunications (2003)
  1113-1119</journal-ref><abstract>  A radio network (RN) is a distributed system consisting of $n$ radio
stations. We design and analyze two distributed leader election protocols in RN
where the number $n$ of radio stations is unknown. The first algorithm runs
under the assumption of {\it limited collision detection}, while the second
assumes that {\it no collision detection} is available. By ``limited collision
detection'', we mean that if exactly one station sends (broadcasts) a message,
then all stations (including the transmitter) that are listening at this moment
receive the sent message. By contrast, the second no-collision-detection
algorithm assumes that a station cannot simultaneously send and listen signals.
Moreover, both protocols allow the stations to keep asleep as long as possible,
thus minimizing their awake time slots (such algorithms are called {\it
energy-efficient}). Both randomized protocols in RN areshown to elect a leader
in $O(\log{(n)})$ expected time, with no station being awake for more than
$O(\log{\log{(n)}})$ time slots. Therefore, a new class of efficient algorithms
is set up that match the $\Omega(\log{(n)})$ time lower-bound established by
Kushilevitz and Mansour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607035</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607035</id><created>2006-07-10</created><updated>2006-07-24</updated><authors><author><keyname>Deng</keyname><forenames>Yi</forenames></author><author><keyname>Lin</keyname><forenames>Dongdai</forenames></author></authors><title>Resettable Zero Knowledge in the Bare Public-Key Model under Standard
  Assumption</title><categories>cs.CR</categories><comments>19 page</comments><abstract>  In this paper we resolve an open problem regarding resettable zero knowledge
in the bare public-key (BPK for short) model: Does there exist constant round
resettable zero knowledge argument with concurrent soundness for $\mathcal{NP}$
in BPK model without assuming \emph{sub-exponential hardness}? We give a
positive answer to this question by presenting such a protocol for any language
in $\mathcal{NP}$ in the bare public-key model assuming only
collision-resistant hash functions against \emph{polynomial-time} adversaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607036</identifier>
 <datestamp>2008-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607036</id><created>2006-07-10</created><updated>2007-06-23</updated><authors><author><keyname>Hildebrand</keyname><forenames>Roland</forenames></author><author><keyname>Mancini</keyname><forenames>Stefano</forenames></author><author><keyname>Severini</keyname><forenames>Simone</forenames></author></authors><title>Combinatorial laplacians and positivity under partial transpose</title><categories>cs.CC quant-ph</categories><comments>19 pages, 7 eps figures, final version accepted for publication in
  Math. Struct. in Comp. Sci</comments><journal-ref>Math. Struct. in Comp. Sci. Vol.18, pp.205-219 (2008)</journal-ref><abstract>  Density matrices of graphs are combinatorial laplacians normalized to have
trace one (Braunstein \emph{et al.} \emph{Phys. Rev. A,} \textbf{73}:1, 012320
(2006)). If the vertices of a graph are arranged as an array, then its density
matrix carries a block structure with respect to which properties such as
separability can be considered. We prove that the so-called degree-criterion,
which was conjectured to be necessary and sufficient for separability of
density matrices of graphs, is equivalent to the PPT-criterion. As such it is
not sufficient for testing the separability of density matrices of graphs (we
provide an explicit example). Nonetheless, we prove the sufficiency when one of
the array dimensions has length two (for an alternative proof see Wu,
\emph{Phys. Lett. A}\textbf{351} (2006), no. 1-2, 18--22).
  Finally we derive a rational upper bound on the concurrence of density
matrices of graphs and show that this bound is exact for graphs on four
vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607037</id><created>2006-07-09</created><updated>2007-04-11</updated><authors><author><keyname>Fan</keyname><forenames>Zhujun</forenames></author></authors><title>The Minimal Cost Algorithm for Off-Line Diagnosability of Discrete Event
  Systems</title><categories>cs.AI cs.CC</categories><comments>12 pages, 7 figures, critical comments and suggestions are welcomed
  and appreciated</comments><acm-class>B.1.2; B.2.3; F.1.1; I.2.8</acm-class><abstract>  The failure diagnosis for {\it discrete event systems} (DESs) has been given
considerable attention in recent years. Both on-line and off-line diagnostics
in the framework of DESs was first considered by Lin Feng in 1994, and
particularly an algorithm for diagnosability of DESs was presented. Motivated
by some existing problems to be overcome in previous work, in this paper, we
investigate the minimal cost algorithm for diagnosability of DESs.
  More specifically: (i) we give a generic method for judging a system's
off-line diagnosability, and the complexity of this algorithm is
polynomial-time; (ii) and in particular, we present an algorithm of how to
search for the minimal set in all observable event sets, whereas the previous
algorithm may find {\it non-minimal} one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607038</id><created>2006-07-09</created><updated>2006-12-01</updated><authors><author><keyname>Donnet</keyname><forenames>Benoit</forenames></author><author><keyname>Baynat</keyname><forenames>Bruno</forenames></author><author><keyname>Friedman</keyname><forenames>Timur</forenames></author></authors><title>Retouched Bloom Filters: Allowing Networked Applications to Flexibly
  Trade Off False Positives Against False Negatives</title><categories>cs.NI</categories><comments>This is a new version of the technical reports with improved
  algorithms and theorical analysis of algorithms</comments><abstract>  Where distributed agents must share voluminous set membership information,
Bloom filters provide a compact, though lossy, way for them to do so. Numerous
recent networking papers have examined the trade-offs between the bandwidth
consumed by the transmission of Bloom filters, and the error rate, which takes
the form of false positives, and which rises the more the filters are
compressed. In this paper, we introduce the retouched Bloom filter (RBF), an
extension that makes the Bloom filter more flexible by permitting the removal
of selected false positives at the expense of generating random false
negatives. We analytically show that RBFs created through a random process
maintain an overall error rate, expressed as a combination of the false
positive rate and the false negative rate, that is equal to the false positive
rate of the corresponding Bloom filters. We further provide some simple
heuristics and improved algorithms that decrease the false positive rate more
than than the corresponding increase in the false negative rate, when creating
RBFs. Finally, we demonstrate the advantages of an RBF over a Bloom filter in a
distributed network topology measurement application, where information about
large stop sets must be shared among route tracing monitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607039</id><created>2006-07-09</created><authors><author><keyname>van Emden</keyname><forenames>M. H.</forenames></author></authors><title>Set-Theoretic Preliminaries for Computer Scientists</title><categories>cs.DM cs.DB</categories><comments>36 pages, 5 figures</comments><report-no>DCS-304-IR</report-no><abstract>  The basics of set theory are usually copied, directly or indirectly, by
computer scientists from introductions to mathematical texts. Often
mathematicians are content with special cases when the general case is of no
mathematical interest. But sometimes what is of no mathematical interest is of
great practical interest in computer science. For example, non-binary relations
in mathematics tend to have numerical indexes and tend to be unsorted. In the
theory and practice of relational databases both these simplifications are
unwarranted. In response to this situation we present here an alternative to
the ``set-theoretic preliminaries'' usually found in computer science texts.
This paper separates binary relations from the kind of relations that are
needed in relational databases. Its treatment of functions supports both
computer science in general and the kind of relations needed in databases. As a
sample application this paper shows how the mathematical theory of relations
naturally leads to the relational data model and how the operations on
relations are by themselves already a powerful vehicle for queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607040</id><created>2006-07-09</created><authors><author><keyname>Pontelli</keyname><forenames>Enrico</forenames><affiliation>New Mexico State University</affiliation></author><author><keyname>Villaverde</keyname><forenames>Karen</forenames><affiliation>New Mexico State University</affiliation></author><author><keyname>Guo</keyname><forenames>Hai-Feng</forenames><affiliation>University of Nebraska at Omaha</affiliation></author><author><keyname>Gupta</keyname><forenames>Gopal</forenames><affiliation>University of Texas at Dallas</affiliation></author></authors><title>PALS: Efficient Or-Parallelism on Beowulf Clusters</title><categories>cs.DC cs.PL</categories><comments>63 pages, 32 figures, 5 tabels. Theory and Practice of Logic
  Programming (to appear)</comments><abstract>  This paper describes the development of the PALS system, an implementation of
Prolog capable of efficiently exploiting or-parallelism on distributed-memory
platforms--specifically Beowulf clusters. PALS makes use of a novel technique,
called incremental stack-splitting. The technique proposed builds on the
stack-splitting approach, previously described by the authors and
experimentally validated on shared-memory systems, which in turn is an
evolution of the stack-copying method used in a variety of parallel logic and
constraint systems--e.g., MUSE, YAP, and Penny. The PALS system is the first
distributed or-parallel implementation of Prolog based on the stack-splitting
method ever realized. The results presented confirm the superiority of this
method as a simple yet effective technique to transition from shared-memory to
distributed-memory systems. PALS extends stack-splitting by combining it with
incremental copying; the paper provides a description of the implementation of
PALS, including details of how distributed scheduling is handled. We also
investigate methodologies to effectively support order-sensitive predicates
(e.g., side-effects) in the context of the stack-splitting scheme. Experimental
results obtained from running PALS on both Shared Memory and Beowulf systems
are presented and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607041</id><created>2006-07-10</created><authors><author><keyname>C&#xe9;rin</keyname><forenames>Christophe</forenames><affiliation>LIPN</affiliation></author><author><keyname>Dubacq</keyname><forenames>Jean-Christophe</forenames><affiliation>LIPN</affiliation></author><author><keyname>Roch</keyname><forenames>Jean-Louis</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / ID-IMAG</affiliation></author><author><keyname>Collaboration</keyname><forenames>the SafeScale</forenames></author></authors><title>Methods for Partitioning Data to Improve Parallel Execution Time for
  Sorting on Heterogeneous Clusters</title><categories>cs.DC cs.PF</categories><proxy>ccsd ccsd-00084822</proxy><acm-class>F.2.2</acm-class><journal-ref>Advances in Grid and Pervasive Computing (2006) 175-186</journal-ref><abstract>  The aim of the paper is to introduce general techniques in order to optimize
the parallel execution time of sorting on a distributed architectures with
processors of various speeds. Such an application requires a partitioning step.
For uniformly related processors (processors speeds are related by a constant
factor), we develop a constant time technique for mastering processor load and
execution time in an heterogeneous environment and also a technique to deal
with unknown cost functions. For non uniformly related processors, we use a
technique based on dynamic programming. Most of the time, the solutions are in
O(p) (p is the number of processors), independent of the problem size n.
Consequently, there is a small overhead regarding the problem we deal with but
it is inherently limited by the knowing of time complexity of the portion of
code following the partitioning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607042</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607042</id><created>2006-07-10</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author></authors><title>Towards a classical proof of exponential lower bound for 2-probe smooth
  codes</title><categories>cs.CR cs.IT math.IT</categories><comments>7 pages, no figure</comments><abstract>  Let C: {0,1}^n -&gt; {0,1}^m be a code encoding an n-bit string into an m-bit
string. Such a code is called a (q, c, e) smooth code if there exists a
decoding algorithm which while decoding any bit of the input, makes at most q
probes on the code word and the probability that it looks at any location is at
most c/m. The error made by the decoding algorithm is at most e. Smooth codes
were introduced by Katz and Trevisan in connection with Locally decodable
codes.
  For 2-probe smooth codes Kerenedis and de Wolf have shown exponential in n
lower bound on m in case c and e are constants. Their lower bound proof went
through quantum arguments and interestingly there is no completely classical
argument as yet for the same (albeit completely classical !) statement.
  We do not match the bounds shown by Kerenedis and de Wolf but however show
the following. Let C: {0,1}^n -&gt; {0,1}^m be a (2,c,e) smooth code and if e &lt;=
c^2/8n^2, then m &gt;= 2^(n/320c^2 - 1)$. We hope that the arguments and
techniques used in this paper extend (or are helpful in making similar other
arguments), to match the bounds shown using quantum arguments. More so,
hopefully they extend to show bounds for codes with greater number of probes
where quantum arguments unfortunately do not yield good bounds (even for
3-probe codes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607043</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607043</id><created>2006-07-11</created><updated>2007-01-10</updated><authors><author><keyname>Takeda</keyname><forenames>Koujin</forenames></author><author><keyname>Uda</keyname><forenames>Shinsuke</forenames></author><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>Analysis of CDMA systems that are characterized by eigenvalue spectrum</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>7 pages, 2 figures</comments><journal-ref>Europhys. Lett. 76 (2006) 1193-1199</journal-ref><doi>10.1209/epl/i2006-10380-5</doi><abstract>  An approach by which to analyze the performance of the code division multiple
access (CDMA) scheme, which is a core technology used in modern wireless
communication systems, is provided. The approach characterizes the objective
system by the eigenvalue spectrum of a cross-correlation matrix composed of
signature sequences used in CDMA communication, which enables us to handle a
wider class of CDMA systems beyond the basic model reported by Tanaka. The
utility of the novel scheme is shown by analyzing a system in which the
generation of signature sequences is designed for enhancing the orthogonality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607044</id><created>2006-07-11</created><authors><author><keyname>Kalnins</keyname><forenames>Audris</forenames></author><author><keyname>Vitolins</keyname><forenames>Valdis</forenames></author></authors><title>Use of UML and Model Transformations for Workflow Process Definitions</title><categories>cs.SE</categories><comments>12 pages, 7 figures, communications of the conference &quot;Baltic DB&amp;IS
  2006&quot;, July 3-6, Vilnius, Lithuania</comments><acm-class>D.2.2; D.2.13; D.3.1</acm-class><journal-ref>Audris Kalnins, Valdis Vitolins, Databases and Information
  Systems, BalticDB&amp;IS'2006, edited by Olegas Vasilecas, Johann Eder, Albertas
  Caplinskas, Vilnius, Technika, 2006, pp. 3.-15</journal-ref><abstract>  Currently many different modeling languages are used for workflow definitions
in BPM systems. Authors of this paper analyze the two most popular graphical
languages, with highest possibility of wide practical usage - UML Activity
diagrams (AD) and Business Process Modeling Notation (BPMN). The necessary in
practice workflow aspects are briefly discussed, and on this basis a natural AD
profile is proposed, which covers all of them. A functionally equivalent BPMN
subset is also selected. The semantics of both languages in the context of
process execution (namely, mapping to BPEL) is also analyzed in the paper. By
analyzing AD and BPMN metamodels, authors conclude that an exact transformation
from AD to BPMN is not trivial even for the selected subset, though these
languages are considered to be similar. Authors show how this transformation
could be defined in the MOLA transformation language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607045</id><created>2006-07-11</created><updated>2006-09-05</updated><authors><author><keyname>Han</keyname><forenames>Xin</forenames></author><author><keyname>Ye</keyname><forenames>Deshi</forenames></author><author><keyname>Zhou</keyname><forenames>Yong</forenames></author></authors><title>Improved online hypercube packing</title><categories>cs.DS</categories><comments>13 pages, one figure, accepted in WAOA'06</comments><abstract>  In this paper, we study online multidimensional bin packing problem when all
items are hypercubes.
 Based on the techniques in one dimensional bin packing algorithm Super
Harmonic by Seiden, we give a framework for online hypercube packing problem
and obtain new upper bounds of asymptotic competitive ratios.
 For square packing, we get an upper bound of 2.1439, which is better than
2.24437.
 For cube packing, we also give a new upper bound 2.6852 which is better than
2.9421 by Epstein and van Stee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607046</id><created>2006-07-11</created><updated>2006-08-22</updated><authors><author><keyname>Han</keyname><forenames>Xin</forenames></author><author><keyname>Iwama</keyname><forenames>Kazuo</forenames></author><author><keyname>Ye</keyname><forenames>Deshi</forenames></author><author><keyname>Zhang</keyname><forenames>Guochuan</forenames></author></authors><title>Strip Packing vs. Bin Packing</title><categories>cs.DS</categories><comments>12 pages, 3 figures</comments><abstract>  In this paper we establish a general algorithmic framework between bin
packing and strip packing, with which we achieve the same asymptotic bounds by
applying bin packing algorithms to strip packing. More precisely we obtain the
following results: (1) Any offline bin packing algorithm can be applied to
strip packing maintaining the same asymptotic worst-case ratio. Thus using FFD
(MFFD) as a subroutine, we get a practical (simple and fast) algorithm for
strip packing with an upper bound 11/9 (71/60). A simple AFPTAS for strip
packing immediately follows. (2) A class of Harmonic-based algorithms for bin
packing can be applied to online strip packing maintaining the same asymptotic
competitive ratio. It implies online strip packing admits an upper bound of
1.58889 on the asymptotic competitive ratio, which is very close to the lower
bound 1.5401 and significantly improves the previously best bound of 1.6910 and
affirmatively answers an open question posed by Csirik et. al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607047</id><created>2006-07-11</created><authors><author><keyname>Palmer</keyname><forenames>Nick</forenames></author><author><keyname>Goldberg</keyname><forenames>Paul W.</forenames></author></authors><title>PAC Classification based on PAC Estimates of Label Class Distributions</title><categories>cs.LG</categories><comments>14 pages</comments><abstract>  A standard approach in pattern classification is to estimate the
distributions of the label classes, and then to apply the Bayes classifier to
the estimates of the distributions in order to classify unlabeled examples. As
one might expect, the better our estimates of the label class distributions,
the better the resulting classifier will be. In this paper we make this
observation precise by identifying risk bounds of a classifier in terms of the
quality of the estimates of the label class distributions. We show how PAC
learnability relates to estimates of the distributions that have a PAC
guarantee on their $L_1$ distance from the true distribution, and we bound the
increase in negative log likelihood risk in terms of PAC bounds on the
KL-divergence. We give an inefficient but general-purpose smoothing method for
converting an estimated distribution that is good under the $L_1$ metric into a
distribution that is good under the KL-divergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607048</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607048</id><created>2006-07-11</created><authors><author><keyname>Viennet</keyname><forenames>Emmanuel</forenames><affiliation>LIPN</affiliation></author><author><keyname>Souli&#xe9;</keyname><forenames>Fran&#xe7;oise Fogelman</forenames><affiliation>KXEN</affiliation></author><author><keyname>Rognier</keyname><forenames>Benoit</forenames><affiliation>KXEN</affiliation></author></authors><title>Evaluation de Techniques de Traitement des Refus\'{e}s pour l'Octroi de
  Cr\'{e}dit</title><categories>cs.NE math.ST stat.TH</categories><proxy>ccsd ccsd-00085108</proxy><journal-ref>38i\`{e}mes Journ\'{e}es de Statistiques (2006) 105</journal-ref><abstract>  We present the problem of &quot;Reject Inference&quot; for credit acceptance. Because
of the current legal framework (Basel II), credit institutions need to
industrialize their processes for credit acceptance, including Reject
Inference. We present here a methodology to compare various techniques of
Reject Inference and show that it is necessary, in the absence of real
theoretical results, to be able to produce and compare models adapted to
available data (selection of &quot;best&quot; model conditionnaly on data). We describe
some simulations run on a small data set to illustrate the approach and some
strategies for choosing the control group, which is the only valid approach to
Reject Inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607049</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607049</id><created>2006-07-11</created><updated>2006-08-01</updated><authors><author><keyname>Parrend</keyname><forenames>Pierre</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Fr&#xe9;not</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Secure Component Deployment in the OSGi(tm) Release 4 Platform</title><categories>cs.CR cs.OS</categories><proxy>ccsd inria-00084795</proxy><abstract>  Last years have seen a dramatic increase in the use of component platforms,
not only in classical application servers, but also more and more in the domain
of Embedded Systems. The OSGi(tm) platform is one of these platforms dedicated
to lightweight execution environments, and one of the most prominent. However,
new platforms also imply new security flaws, and a lack of both knowledge and
tools for protecting the exposed systems. This technical report aims at
fostering the understanding of security mechanisms in component deployment. It
focuses on securing the deployment of components. It presents the cryptographic
mechanisms necessary for signing OSGi(tm) bundles, as well as the detailed
process of bundle signature and validation. We also present the SFelix
platform, which is a secure extension to Felix OSGi(tm) framework
implementation. It includes our implementation of the bundle signature process,
as specified by OSGi(tm) Release 4 Security Layer. Moreover, a tool for signing
and publishing bundles, SFelix JarSigner, has been developed to conveniently
integrate bundle signature in the bundle deployment process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607050</identifier>
 <datestamp>2008-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607050</id><created>2006-07-11</created><updated>2008-03-25</updated><authors><author><keyname>Barla</keyname><forenames>Pascal</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / GRAVIR-IMAG</affiliation></author><author><keyname>Breslav</keyname><forenames>Simon</forenames><affiliation>EECS</affiliation></author><author><keyname>Markosian</keyname><forenames>Lee</forenames><affiliation>EECS</affiliation></author><author><keyname>Thollot</keyname><forenames>Jo&#xeb;lle</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / GRAVIR-IMAG</affiliation></author></authors><title>Interactive Hatching and Stippling by Example</title><categories>cs.GR</categories><proxy>ccsd inria-00084569</proxy><abstract>  We describe a system that lets a designer interactively draw patterns of
strokes in the picture plane, then guide the synthesis of similar patterns over
new picture regions. Synthesis is based on an initial user-assisted analysis
phase in which the system recognizes distinct types of strokes (hatching and
stippling) and organizes them according to perceptual grouping criteria. The
synthesized strokes are produced by combining properties (eg. length,
orientation, parallelism, proximity) of the stroke groups extracted from the
input examples. We illustrate our technique with a drawing application that
allows the control of attributes and scale-dependent reproduction of the
synthesized patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607051</id><created>2006-07-11</created><authors><author><keyname>Recanati</keyname><forenames>Catherine</forenames><affiliation>LIPN</affiliation></author></authors><title>Raisonner avec des diagrammes : perspectives cognitives et
  computationnelles</title><categories>cs.CL</categories><comments>paru initialement comme Rapport LIPN en 2004</comments><proxy>ccsd ccsd-00085004</proxy><journal-ref>Intellectica 40 (2005) 9-42</journal-ref><abstract>  Diagrammatic, analogical or iconic representations are often contrasted with
linguistic or logical representations, in which the shape of the symbols is
arbitrary. The aim of this paper is to make a case for the usefulness of
diagrams in inferential knowledge representation systems. Although commonly
used, diagrams have for a long time suffered from the reputation of being only
a heuristic tool or a mere support for intuition. The first part of this paper
is an historical background paying tribute to the logicians, psychologists and
computer scientists who put an end to this formal prejudice against diagrams.
The second part is a discussion of their characteristics as opposed to those of
linguistic forms. The last part is aimed at reviving the interest for
heterogeneous representation systems including both linguistic and diagrammatic
representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607052</identifier>
 <datestamp>2007-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607052</id><created>2006-07-11</created><authors><author><keyname>Poibeau</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author></authors><title>Dealing with Metonymic Readings of Named Entities</title><categories>cs.AI cs.CL</categories><proxy>ccsd ccsd-00085166</proxy><journal-ref>Dans Actes de The 28th Annual Conference of the Cognitive Science
  Society (CogSci 2006) - The 28th Annual Conference of the Cognitive Science
  Society (CogSci 2006), Vancouver : Canada (2006)</journal-ref><abstract>  The aim of this paper is to propose a method for tagging named entities (NE),
using natural language processing techniques. Beyond their literal meaning,
named entities are frequently subject to metonymy. We show the limits of
current NE type hierarchies and detail a new proposal aiming at dynamically
capturing the semantics of entities in context. This model can analyze complex
linguistic phenomena like metonymy, which are known to be difficult for natural
language processing but crucial for most applications. We present an
implementation and some test using the French ESTER corpus and give significant
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607053</id><created>2006-07-11</created><authors><author><keyname>Poibeau</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author></authors><title>Linguistically Grounded Models of Language Change</title><categories>cs.AI cs.CL</categories><proxy>ccsd ccsd-00085168</proxy><journal-ref>The 28th Annual Conference of the Cognitive Science Society
  (CogSci 2006), Canada (2006)</journal-ref><abstract>  Questions related to the evolution of language have recently known an
impressive increase of interest (Briscoe, 2002). This short paper aims at
questioning the scientific status of these models and their relations to
attested data. We show that one cannot directly model non-linguistic factors
(exogenous factors) even if they play a crucial role in language evolution. We
then examine the relation between linguistic models and attested language data,
as well as their contribution to cognitive linguistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607054</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607054</id><created>2006-07-11</created><authors><author><keyname>Lieb</keyname><forenames>Elliott H.</forenames></author><author><keyname>Osherson</keyname><forenames>Daniel</forenames></author><author><keyname>Weinstein</keyname><forenames>Scott</forenames></author></authors><title>Elementary Proof of a Theorem of Jean Ville</title><categories>cs.CC</categories><comments>12 pages latex</comments><abstract>  Considerable thought has been devoted to an adequate definition of the class
of infinite, random binary sequences (the sort of sequence that almost
certainly arises from flipping a fair coin indefinitely). The first
mathematical exploration of this problem was due to R. Von Mises, and based on
his concept of a &quot;selection function.&quot; A decisive objection to Von Mises' idea
was formulated in a theorem offered by Jean Ville in 1939. It shows that some
sequences admitted by Von Mises as &quot;random&quot; in fact manifest a certain kind of
systematicity. Ville's proof is challenging, and an alternative approach has
appeared only in condensed form. We attempt to provide an expanded version of
the latter, alternative argument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607055</id><created>2006-07-11</created><authors><author><keyname>Hara</keyname><forenames>Hisayuki</forenames></author><author><keyname>Takemura</keyname><forenames>Akimichi</forenames></author></authors><title>Boundary cliques, clique trees and perfect sequences of maximal cliques
  of a chordal graph</title><categories>cs.DM</categories><acm-class>G.2.2</acm-class><abstract>  We characterize clique trees of a chordal graph in their relation to
simplicial vertices and perfect sequences of maximal cliques. We investigate
boundary cliques defined by Shibata and clarify their relation to endpoints of
clique trees. Next we define a symmetric binary relation between the set of
clique trees and the set of perfect sequences of maximal cliques. We describe
the relation as a bipartite graph and prove that the bipartite graph is always
connected. Lastly we consider to characterize chordal graphs from the aspect of
non-uniqueness of clique trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607056</id><created>2006-07-12</created><authors><author><keyname>Schwer</keyname><forenames>Sylviane</forenames><affiliation>LIPN</affiliation></author></authors><title>Reasoning with Intervals on Granules</title><categories>cs.AI cs.DM</categories><proxy>ccsd ccsd-00085191</proxy><acm-class>G.2.0</acm-class><journal-ref>Journal of Universal Computer Science 8 (8) (2002) 793-808</journal-ref><abstract>  The formalizations of periods of time inside a linear model of Time are
usually based on the notion of intervals, that may contain or may not their
endpoints. This is not enought when the periods are written in terms of coarse
granularities with respect to the event taken into account. For instance, how
to express the inter-war period in terms of a {\em years} interval? This paper
presents a new type of intervals, neither open, nor closed or open-closed and
the extension of operations on intervals of this new type, in order to reduce
the gap between the discourse related to temporal relationship and its
translation into a discretized model of Time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607057</id><created>2006-07-12</created><authors><author><keyname>Ravelomanana</keyname><forenames>Vlady</forenames><affiliation>LIPN</affiliation></author><author><keyname>Collaboration</keyname><forenames>the Projet PAI Amadeus</forenames></author></authors><title>The Average Size of Giant Components Between the Double-Jump</title><categories>cs.DM math.CO math.PR</categories><comments>A para\^{i}tre dans Algorithmica</comments><proxy>ccsd ccsd-00085226</proxy><acm-class>G.2.1; G.2.2; G.3</acm-class><journal-ref>Algorithmica Issue sp\'{e}ciale &quot;Analysis of Algorithms&quot; (2006) A
  para\^{i}tre</journal-ref><abstract>  We study the sizes of connected components according to their excesses during
a random graph process built with $n$ vertices. The considered model is the
continuous one defined in Janson 2000. An ${\ell}$-component is a connected
component with ${\ell}$ edges more than vertices. $\ell$ is also called the
\textit{excess} of such component. As our main result, we show that when $\ell$
and ${n \over \ell}$ are both large, the expected number of vertices that ever
belong to an $\ell$-component is about ${12}^{1/3} {\ell}^{1/3} n^{2/3}$. We
also obtain limit theorems for the number of creations of $\ell$-components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607058</id><created>2006-07-12</created><authors><author><keyname>Ridge</keyname><forenames>Tom</forenames></author></authors><title>Craig's Interpolation Theorem formalised and mechanised in Isabelle/HOL</title><categories>cs.LO</categories><abstract>  We formalise and mechanise a construtive, proof theoretic proof of Craig's
Interpolation Theorem in Isabelle/HOL. We give all the definitions and lemma
statements both formally and informally. We also transcribe informally the
formal proofs. We detail the main features of our mechanisation, such as the
formalisation of binding for first order formulae. We also give some
applications of Craig's Interpolation Theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607059</id><created>2006-07-12</created><authors><author><keyname>Ravelomanana</keyname><forenames>Vlady</forenames><affiliation>LIPN</affiliation></author><author><keyname>Rijamame</keyname><forenames>Alphonse Laza</forenames><affiliation>D.M.I</affiliation></author></authors><title>Creation and Growth of Components in a Random Hypergraph Process</title><categories>cs.DM math.CO math.PR</categories><comments>R\'{e}sum\'{e} \'{e}tendu</comments><proxy>ccsd ccsd-00085237</proxy><acm-class>G.2.1; G.2.2; G.3</acm-class><journal-ref>Proceedings of The Twelfth Annual International Computing and
  Combinatorics Conference (COCOON'06) -- Lecture Notes in Computer Science
  (2006) \`{a} para\^{i}tre</journal-ref><abstract>  Denote by an $\ell$-component a connected $b$-uniform hypergraph with $k$
edges and $k(b-1) - \ell$ vertices. We prove that the expected number of
creations of $\ell$-component during a random hypergraph process tends to 1 as
$\ell$ and $b$ tend to $\infty$ with the total number of vertices $n$ such that
$\ell = o(\sqrt[3]{\frac{n}{b}})$. Under the same conditions, we also show that
the expected number of vertices that ever belong to an $\ell$-component is
approximately $12^{1/3} (b-1)^{1/3} \ell^{1/3} n^{2/3}$. As an immediate
consequence, it follows that with high probability the largest $\ell$-component
during the process is of size $O((b-1)^{1/3} \ell^{1/3} n^{2/3})$. Our results
give insight about the size of giant components inside the phase transition of
random hypergraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607060</id><created>2006-07-12</created><authors><author><keyname>Dieudonne</keyname><forenames>Yoann</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Labbani-Igbida</keyname><forenames>Ouiddad</forenames><affiliation>CREA</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LaRIA</affiliation></author></authors><title>Circle Formation of Weak Mobile Robots</title><categories>cs.RO</categories><proxy>ccsd ccsd-00085394</proxy><abstract>  In this paper we prove the conjecture of D\'{e}fago &amp; Konagaya. Furthermore,
we describe a deterministic protocol for forming a regular n-gon in finite
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607061</id><created>2006-07-12</created><authors><author><keyname>Mackarov</keyname><forenames>Igor</forenames><affiliation>Maharishi University of Management</affiliation></author></authors><title>On Some Peculiarities of Dynamic Switch between Component
  Implementations in an Autonomic Computing System</title><categories>cs.DS cs.DC cs.NA</categories><comments>16 pages, 3 figures</comments><abstract>  Behavior of the delta algorithm of autonomic switch between two component
implementations is considered on several examples of a client-server systems
involving, in particular, periodic change of intensities of requests for the
component. It is shown that in the cases of some specific combinations of
elementary requests costs, the number of clients in the system, the number of
requests per unit of time, and the cost of switch between the implementations,
the algorithm may reveal behavior that is rather far from the desired. A
sufficient criterion of a success of the algorithm is proposed based on the
analysis of the accumulated implementations costs difference as a function of
time. Suggestions are pointed out of practical evaluation of the algorithm
functioning regarding the observations made in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607062</identifier>
 <datestamp>2012-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607062</id><created>2006-07-12</created><updated>2012-06-06</updated><authors><author><keyname>Thomas</keyname><forenames>Matt</forenames></author><author><keyname>Pang</keyname><forenames>Bo</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author></authors><title>Get out the vote: Determining support or opposition from Congressional
  floor-debate transcripts</title><categories>cs.CL cs.SI physics.soc-ph</categories><comments>Proceedings of EMNLP 2006. This revision (created Dec 2006) contains
  clearly-marked updates from the proceedings version. Data available at
  http://www.cs.cornell.edu/home/llee/data/convote.html</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate whether one can determine from the transcripts of U.S.
Congressional floor debates whether the speeches represent support of or
opposition to proposed legislation. To address this problem, we exploit the
fact that these speeches occur as part of a discussion; this allows us to use
sources of information regarding relationships between discourse segments, such
as whether a given utterance indicates agreement with the opinion expressed by
another. We find that the incorporation of such information yields substantial
improvements over classifying speeches in isolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607063</id><created>2006-07-12</created><authors><author><keyname>Boogerd</keyname><forenames>Cathal</forenames></author><author><keyname>Moonen</keyname><forenames>Leon</forenames></author></authors><title>Prioritizing Software Inspection Results using Static Profiling</title><categories>cs.SE</categories><comments>14 pages</comments><report-no>TUD-SERG-2006-001</report-no><abstract>  Static software checking tools are useful as an additional automated software
inspection step that can easily be integrated in the development cycle and
assist in creating secure, reliable and high quality code. However, an often
quoted disadvantage of these tools is that they generate an overly large number
of warnings, including many false positives due to the approximate analysis
techniques. This information overload effectively limits their usefulness.
  In this paper we present ELAN, a technique that helps the user prioritize the
information generated by a software inspection tool, based on a demand-driven
computation of the likelihood that execution reaches the locations for which
warnings are reported. This analysis is orthogonal to other prioritization
techniques known from literature, such as severity levels and statistical
analysis to reduce false positives. We evaluate feasibility of our technique
using a number of case studies and assess the quality of our predictions by
comparing them to actual values obtained by dynamic profiling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607064</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607064</id><created>2006-07-13</created><authors><author><keyname>Amraoui</keyname><forenames>Abdelaziz</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>How to Find Good Finite-Length Codes: From Art Towards Science</title><categories>cs.IT math.IT</categories><comments>13 pages, 13 eps figures, enhanced version of an invited paperat the
  4th International Symposium on Turbo Codes and Related Topics, Munich,
  Germany, 2006</comments><abstract>  We explain how to optimize finite-length LDPC codes for transmission over the
binary erasure channel. Our approach relies on an analytic approximation of the
erasure probability. This is in turn based on a finite-length scaling result to
model large scale erasures and a union bound involving minimal stopping sets to
take into account small error events. We show that the performances of
optimized ensembles as observed in simulations are well described by our
approximation. Although we only address the case of transmission over the
binary erasure channel, our method should be applicable to a more general
setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607065</id><created>2006-07-13</created><authors><author><keyname>Djelloul</keyname><forenames>Khalil</forenames></author></authors><title>Decomposable Theories</title><categories>cs.LO cs.AI</categories><abstract>  We present in this paper a general algorithm for solving first-order formulas
in particular theories called &quot;decomposable theories&quot;. First of all, using
special quantifiers, we give a formal characterization of decomposable theories
and show some of their properties. Then, we present a general algorithm for
solving first-order formulas in any decomposable theory &quot;T&quot;. The algorithm is
given in the form of five rewriting rules. It transforms a first-order formula
&quot;P&quot;, which can possibly contain free variables, into a conjunction &quot;Q&quot; of
solved formulas easily transformable into a Boolean combination of
existentially quantified conjunctions of atomic formulas. In particular, if &quot;P&quot;
has no free variables then &quot;Q&quot; is either the formula &quot;true&quot; or &quot;false&quot;. The
correctness of our algorithm proves the completeness of the decomposable
theories.
  Finally, we show that the theory &quot;Tr&quot; of finite or infinite trees is a
decomposable theory and give some benchmarks realized by an implementation of
our algorithm, solving formulas on two-partner games in &quot;Tr&quot; with more than 160
nested alternated quantifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607066</id><created>2006-07-13</created><authors><author><keyname>Sidiropoulos</keyname><forenames>Antonis</forenames></author><author><keyname>Katsaros</keyname><forenames>Dimitrios</forenames></author><author><keyname>Manolopoulos</keyname><forenames>Yannis</forenames></author></authors><title>Generalized h-index for Disclosing Latent Facts in Citation Networks</title><categories>cs.DL</categories><comments>19 pages, 17 tables, 27 figures</comments><abstract>  What is the value of a scientist and its impact upon the scientific thinking?
How can we measure the prestige of a journal or of a conference? The evaluation
of the scientific work of a scientist and the estimation of the quality of a
journal or conference has long attracted significant interest, due to the
benefits from obtaining an unbiased and fair criterion. Although it appears to
be simple, defining a quality metric is not an easy task. To overcome the
disadvantages of the present metrics used for ranking scientists and journals,
J.E. Hirsch proposed a pioneering metric, the now famous h-index. In this
article, we demonstrate several inefficiencies of this index and develop a pair
of generalizations and effective variants of it to deal with scientist ranking
and with publication forum ranking. The new citation indices are able to
disclose trendsetters in scientific research, as well as researchers that
constantly shape their field with their influential work, no matter how old
they are. We exhibit the effectiveness and the benefits of the new indices to
unfold the full potential of the h-index, with extensive experimental results
obtained from DBLP, a widely known on-line digital library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607067</id><created>2006-07-13</created><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Competing with stationary prediction strategies</title><categories>cs.LG</categories><comments>20 pages</comments><abstract>  In this paper we introduce the class of stationary prediction strategies and
construct a prediction algorithm that asymptotically performs as well as the
best continuous stationary strategy. We make mild compactness assumptions but
no stochastic assumptions about the environment. In particular, no assumption
of stationarity is made about the environment, and the stationarity of the
considered strategies only means that they do not depend explicitly on time; we
argue that it is natural to consider only stationary strategies even for highly
non-stationary environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607068</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607068</id><created>2006-07-13</created><authors><author><keyname>Manganiello</keyname><forenames>Felice</forenames></author></authors><title>Computation of the Weight Distribution of CRC Codes</title><categories>cs.IT math.AC math.IT</categories><comments>16 pages, 1 figure, submitted for publication</comments><abstract>  In this article, we illustrate an algorithm for the computation of the weight
distribution of CRC codes. The recursive structure of CRC codes will give us an
iterative way to compute the weight distribution of their dual codes starting
from just some ``representative'' words. Thanks to MacWilliams Theorem, the
computation of the weight distribution of dual codes can be easily brought back
to that of CRC codes. This algorithm is a good alternative to the standard
algorithm that involves listing every word of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607069</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607069</id><created>2006-07-14</created><updated>2006-07-17</updated><authors><author><keyname>Shastry</keyname><forenames>Mahesh C</forenames></author><author><keyname>Nagaraj</keyname><forenames>Nithin</forenames></author><author><keyname>Vaidya</keyname><forenames>Prabhakar G</forenames></author></authors><title>The B-Exponential Map: A Generalization of the Logistic Map, and Its
  Applications In Generating Pseudo-random Numbers</title><categories>cs.CR nlin.CD</categories><comments>25 pages, 15 figures</comments><abstract>  A 1-dimensional generalization of the well known Logistic Map is proposed.
The proposed family of maps is referred to as the B-Exponential Map. The
dynamics of this map are analyzed and found to have interesting properties. In
particular, the B-Exponential Map exhibits robust chaos for all real values of
the parameter B &gt;= e^(-4). We then propose a pseudo-random number generator
based on the B-Exponential Map by chaotically hopping between different
trajectories for different values of B. We call this BEACH (B-Exponential
All-Chaotic Map Hopping) pseudo-random number generator. BEACH successfully
passes stringent statistical randomness tests such as ENT, NIST and Diehard. An
implementation of BEACH is also outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607070</id><created>2006-07-14</created><updated>2006-07-16</updated><authors><author><keyname>Kryssanov</keyname><forenames>V. V.</forenames></author><author><keyname>Rinaldo</keyname><forenames>F. J.</forenames></author><author><keyname>Ogawa</keyname><forenames>H.</forenames></author><author><keyname>Kuleshov</keyname><forenames>E.</forenames></author></authors><title>Citation as a Representation Process</title><categories>cs.DL cs.CY physics.data-an</categories><comments>5 pages, 2 figures. Preprint completed in July 2006</comments><abstract>  The presented work proposes a novel approach to model the citation rate. The
paper begins with a brief introduction into informetrics studies and highlights
drawbacks of the contemporary approaches to modeling the citation process as a
product of social interactions. An alternative modeling framework based on
results obtained in cognitive psychology is then introduced and applied in an
experiment to investigate properties of the citation process, as they are
revealed by a large collection of citation statistics. Major research findings
are discussed, and a summary is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607071</id><created>2006-07-14</created><authors><author><keyname>Fang</keyname><forenames>H.</forenames></author><author><keyname>Kilani</keyname><forenames>Y.</forenames></author><author><keyname>Lee</keyname><forenames>J. H. M.</forenames></author><author><keyname>Stuckey</keyname><forenames>P. J.</forenames></author></authors><title>Islands for SAT</title><categories>cs.AI</categories><comments>7 pages</comments><abstract>  In this note we introduce the notion of islands for restricting local search.
We show how we can construct islands for CNF SAT problems, and how much search
space can be eliminated by restricting search to the island.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607072</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607072</id><created>2006-07-14</created><authors><author><keyname>Turner</keyname><forenames>Scott A.</forenames></author><author><keyname>Perez-Quinones</keyname><forenames>Manuel A.</forenames></author><author><keyname>Edwards</keyname><forenames>Stephen H.</forenames></author></authors><title>Effect of Interface Style in Peer Review Comments for UML Designs</title><categories>cs.HC</categories><comments>8 pages, 7 figures</comments><acm-class>H.1; H.4; H.5</acm-class><abstract>  This paper presents our evaluation of using a Tablet-PC to provide
peer-review comments in the first year Computer Science course. Our exploration
consisted of an evaluation of how students write comments on other students'
assignments using three different methods: pen and paper, a Tablet-PC, and a
desktop computer. Our ultimate goal is to explore the effect that interface
style (Tablet vs. Desktop) has on the quality and quantity of the comments
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607073</id><created>2006-07-14</created><authors><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>Counting good truth assignments of random k-SAT formulae</title><categories>cs.DM cond-mat.dis-nn</categories><comments>13 pages, 1 eps figure</comments><abstract>  We present a deterministic approximation algorithm to compute logarithm of
the number of `good' truth assignments for a random k-satisfiability (k-SAT)
formula in polynomial time (by `good' we mean that violate a small fraction of
clauses). The relative error is bounded above by an arbitrarily small constant
epsilon with high probability as long as the clause density (ratio of clauses
to variables) alpha&lt;alpha_{u}(k) = 2k^{-1}\log k(1+o(1)). The algorithm is
based on computation of marginal distribution via belief propagation and use of
an interpolation procedure. This scheme substitutes the traditional one based
on approximation of marginal probabilities via MCMC, in conjunction with
self-reduction, which is not easy to extend to the present problem.
  We derive 2k^{-1}\log k (1+o(1)) as threshold for uniqueness of the Gibbs
distribution on satisfying assignment of random infinite tree k-SAT formulae to
establish our results, which is of interest in its own right.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607074</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607074</id><created>2006-07-14</created><authors><author><keyname>Peng</keyname><forenames>Xiao-Hong</forenames></author><author><keyname>Farrell</keyname><forenames>Paddy</forenames></author></authors><title>On Construction of the (24,12,8) Golay Codes</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Trans. on Information Theory Vol. 24 No. 8</comments><abstract>  Two product array codes are used to construct the (24, 12, 8) binary Golay
code through the direct sum operation. This construction provides a systematic
way to find proper (8, 4, 4) linear block component codes for generating the
Golay code, and it generates and extends previously existing methods that use a
similar construction framework. The code constructed is simple to decode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607075</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607075</id><created>2006-07-14</created><updated>2007-01-17</updated><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Prabhakar</keyname><forenames>Balaji</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>On entropy for mixtures of discrete and continuous variables</title><categories>cs.IT math.IT</categories><comments>10 pages, two-column</comments><abstract>  Let $X$ be a discrete random variable with support $S$ and $f : S \to
S^\prime$ be a bijection. Then it is well-known that the entropy of $X$ is the
same as the entropy of $f(X)$. This entropy preservation property has been
well-utilized to establish non-trivial properties of discrete stochastic
processes, e.g. queuing process \cite{prg03}. Entropy as well as entropy
preservation is well-defined only in the context of purely discrete or
continuous random variables. However for a mixture of discrete and continuous
random variables, which arise in many interesting situations, the notions of
entropy and entropy preservation have not been well understood.
  In this paper, we extend the notion of entropy in a natural manner for a
mixed-pair random variable, a pair of random variables with one discrete and
the other continuous. Our extensions are consistent with the existing
definitions of entropy in the sense that there exist natural injections from
discrete or continuous random variables into mixed-pair random variables such
that their entropy remains the same. This extension of entropy allows us to
obtain sufficient conditions for entropy preservation in mixtures of discrete
and continuous random variables under bijections.
  The extended definition of entropy leads to an entropy rate for continuous
time Markov chains. As an application, we recover a known probabilistic result
related to Poisson process. We strongly believe that the frame-work developed
in this paper can be useful in establishing probabilistic properties of complex
processes, such as load balancing systems, queuing network, caching algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607076</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607076</id><created>2006-07-14</created><authors><author><keyname>Kosut</keyname><forenames>Oliver</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author></authors><title>Capacity of Cooperative Fusion in the Presence of Byzantine Sensors</title><categories>cs.IT math.IT</categories><comments>8 pages, 2 figures</comments><abstract>  The problem of cooperative fusion in the presence of Byzantine sensors is
considered. An information theoretic formulation is used to characterize the
Shannon capacity of sensor fusion. It is shown that when less than half of the
sensors are Byzantine, the effect of Byzantine attack can be entirely
mitigated, and the fusion capacity is identical to that when all sensors are
honest. But when at least half of the sensors are Byzantine, they can
completely defeat the sensor fusion so that no information can be transmitted
reliably. A capacity achieving transmit-then-verify strategy is proposed for
the case that less than half of the sensors are Byzantine, and its error
probability and coding rate is analyzed by using a Markov decision process
modeling of the transmission protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607077</id><created>2006-07-17</created><authors><author><keyname>Gabrielyan</keyname><forenames>Emin</forenames></author></authors><title>Fault-Tolerant Real-Time Streaming with FEC thanks to Capillary
  Multi-Path Routing</title><categories>cs.NI cs.MM</categories><journal-ref>Emin Gabrielyan, Fault-Tolerant Real-Time Streaming with FEC
  thanks to Capillary Multi-Path Routing, International Conference on
  Communications, Circuits and Systems - ICCCAS'06 - Gui Lin, China, 25-28 June
  2006, Vol. 3, pp. 1497-1501</journal-ref><abstract>  Erasure resilient FEC codes in off-line packetized streaming rely on time
diversity. This requires unrestricted buffering time at the receiver. In
real-time streaming the playback buffering time must be very short. Path
diversity is an orthogonal strategy. However, the large number of long paths
increases the number of underlying links and consecutively the overall link
failure rate. This may increase the overall requirement in redundant FEC
packets for combating the link failures. We introduce the Redundancy Overall
Requirement (ROR) metric, a routing coefficient specifying the total number of
FEC packets required for compensation of all underlying link failures. We
present a capillary routing algorithm for constructing layer by layer steadily
diversifying multi-path routing patterns. By measuring the ROR coefficients of
a dozen of routing layers on hundreds of network samples, we show that the
number of required FEC packets decreases substantially when the path diversity
is increased by the capillary routing construction algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607078</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607078</id><created>2006-07-17</created><authors><author><keyname>Gan</keyname><forenames>Ying Hung</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author><author><keyname>Mow</keyname><forenames>Wai Ho</forenames></author></authors><title>Complex Lattice Reduction Algorithm for Low-Complexity MIMO Detection</title><categories>cs.DS cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communication in March
  2006. Part of this work was presented at the 2005 Global Telecommunications
  Conference, United States, November 2005</comments><abstract>  Recently, lattice-reduction-aided detectors have been proposed for
multiple-input multiple-output (MIMO) systems to give performance with full
diversity like maximum likelihood receiver, and yet with complexity similar to
linear receivers. However, these lattice-reduction-aided detectors are based on
the traditional LLL reduction algorithm that was originally introduced for
reducing real lattice bases, in spite of the fact that the channel matrices are
inherently complex-valued. In this paper, we introduce the complex LLL
algorithm for direct application to reduce the basis of a complex lattice which
is naturally defined by a complex-valued channel matrix. We prove that complex
LLL reduction-aided detection can also achieve full diversity. Our analysis
reveals that the new complex LLL algorithm can achieve a reduction in
complexity of nearly 50% over the traditional LLL algorithm, and this is
confirmed by simulation. It is noteworthy that the complex LLL algorithm
aforementioned has nearly the same bit-error-rate performance as the
traditional LLL algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607079</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607079</id><created>2006-07-17</created><updated>2007-05-31</updated><authors><author><keyname>Ruinskiy</keyname><forenames>Dima</forenames></author><author><keyname>Shamir</keyname><forenames>Adi</forenames></author><author><keyname>Tsaban</keyname><forenames>Boaz</forenames></author></authors><title>Length-based cryptanalysis: The case of Thompson's Group</title><categories>cs.CR cs.CC math.GR</categories><comments>Final version, to appear in JMC</comments><journal-ref>Journal of Mathematical Cryptology 1 (2007), 359--372</journal-ref><doi>10.1515/jmc.2007.018</doi><abstract>  The length-based approach is a heuristic for solving randomly generated
equations in groups which possess a reasonably behaved length function. We
describe several improvements of the previously suggested length-based
algorithms, that make them applicable to Thompson's group with significant
success rates. In particular, this shows that the Shpilrain-Ushakov public key
cryptosystem based on Thompson's group is insecure, and suggests that no
practical public key cryptosystem based on this group can be secure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607080</identifier>
 <datestamp>2007-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607080</id><created>2006-07-17</created><authors><author><keyname>Carmi</keyname><forenames>Shai</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Kirkpatrick</keyname><forenames>Scott</forenames></author><author><keyname>Shavitt</keyname><forenames>Yuval</forenames></author><author><keyname>Shir</keyname><forenames>Eran</forenames></author></authors><title>New Model of Internet Topology Using k-shell Decomposition</title><categories>cs.NI cond-mat.dis-nn</categories><comments>4 pages, 4 figures</comments><journal-ref>PNAS 104, 11150-11154 (2007).</journal-ref><doi>10.1073/pnas.0701175104</doi><abstract>  We introduce and use k-shell decomposition to investigate the topology of the
Internet at the AS level. Our analysis separates the Internet into three
sub-components: (a) a nucleus which is a small (~100 nodes) very well connected
globally distributed subgraph; (b) a fractal sub-component that is able to
connect the bulk of the Internet without congesting the nucleus, with self
similar properties and critical exponents; and (c) dendrite-like structures,
usually isolated nodes that are connected to the rest of the network through
the nucleus only. This unique decomposition is robust, and provides insight
into the underlying structure of the Internet and its functional consequences.
Our approach is general and useful also when studying other complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607081</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607081</id><created>2006-07-18</created><authors><author><keyname>Ango-Obiang</keyname><forenames>Marie-France</forenames><affiliation>LORIA</affiliation></author></authors><title>Syst\`{e}me de repr\'{e}sentation d'aide au besoin dans le domaine
  architectural</title><categories>cs.OH cs.IR</categories><proxy>ccsd inria-00083966</proxy><journal-ref>Dans CONFERE 2006, Conception et Innovation</journal-ref><abstract>  The image is a very important mean of communication in the field of
architectural who intervenes in the various phases of the design of a project.
It can be regarded as a tool of decision-making aid. The study of our research
aims at to see the contribution of the Economic Intelligence in the resolution
of a decisional problem of the various partners (Architect, Contractor,
Customer) in the architectural field, in order to make strategic decisions
within the framework of the realization or design of an architectural work. The
economic Intelligence allows the taking into account of the real needs for the
user-decision makers, so that their waiting are considered at the first stage
of a search for information and not in the final stage of the development of
the tool in the evaluation of this last.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607082</id><created>2006-07-18</created><authors><author><keyname>D'Alessandro</keyname><forenames>Flavio</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Richomme</keyname><forenames>Gw&#xe9;na&#xeb;l</forenames><affiliation>LaRIA</affiliation></author><author><keyname>Varrichio</keyname><forenames>Stefano</forenames></author></authors><title>Well quasi-orders and the shuffle closure of finite sets</title><categories>cs.DM</categories><proxy>ccsd ccsd-00085839</proxy><abstract>  Given a set I of word, the set of all words obtained by the shuffle of
(copies of) words of I is naturally provided with a partial order. In [FS05],
the authors have opened the problem of the characterization of the finite sets
I such that the order is a well quasi-order . In this paper we give an answer
in the case when I consists of a single word w.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607083</id><created>2006-07-18</created><authors><author><keyname>Shtrakov</keyname><forenames>Stanko Vl.</forenames></author><author><keyname>Stoilov</keyname><forenames>Anton</forenames></author></authors><title>Mathematical Modelling of the Thermal Accumulation in Hot Water Solar
  Systems</title><categories>cs.CE</categories><comments>11 pages, 5 figures</comments><acm-class>K.1.6</acm-class><abstract>  Mathematical modelling and defining useful recommendations for construction
and regimes of exploitation for hot water solar installation with thermal
stratification is the main purpose of this work. A special experimental solar
module for hot water was build and equipped with sufficient measure apparatus.
The main concept of investigation is to optimise the stratified regime of
thermal accumulation and constructive parameters of heat exchange equipment
(heat serpentine in tank). Accumulation and heat exchange processes were
investigated by theoretical end experimental means. Special mathematical model
was composed to simulate the energy transfer in stratified tank. Computer
program was developed to solve mathematical equations for thermal accumulation
and energy exchange. Extensive numerical and experimental tests were carried
out. A good correspondence between theoretical and experimental data was
arrived. Keywords: Mathematical modelling, accumulation
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607084</id><created>2006-07-18</created><authors><author><keyname>Kayser</keyname><forenames>Daniel</forenames><affiliation>LIPN</affiliation></author><author><keyname>Nouioua</keyname><forenames>Farid</forenames><affiliation>LIPN</affiliation></author></authors><title>About Norms and Causes</title><categories>cs.AI</categories><proxy>ccsd ccsd-00085148</proxy><journal-ref>The 17th FLAIRS'04 Conference (2004) 502-507</journal-ref><abstract>  Knowing the norms of a domain is crucial, but there exist no repository of
norms. We propose a method to extract them from texts: texts generally do not
describe a norm, but rather how a state-of-affairs differs from it. Answers
concerning the cause of the state-of-affairs described often reveal the
implicit norm. We apply this idea to the domain of driving, and validate it by
designing algorithms that identify, in a text, the &quot;basic&quot; norms to which it
refers implicitly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607085</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607085</id><created>2006-07-18</created><updated>2008-11-07</updated><authors><author><keyname>Habrard</keyname><forenames>Amaury</forenames><affiliation>LIF</affiliation></author><author><keyname>Denis</keyname><forenames>Francois</forenames><affiliation>LIF</affiliation></author><author><keyname>Esposito</keyname><forenames>Yann</forenames><affiliation>LIF</affiliation></author></authors><title>Using Pseudo-Stochastic Rational Languages in Probabilistic Grammatical
  Inference</title><categories>cs.LG</categories><proxy>ccsd ccsd-00085176</proxy><journal-ref>8th International Colloquium on Grammatical Inference (ICGI'06),
  Japan (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In probabilistic grammatical inference, a usual goal is to infer a good
approximation of an unknown distribution P called a stochastic language. The
estimate of P stands in some class of probabilistic models such as
probabilistic automata (PA). In this paper, we focus on probabilistic models
based on multiplicity automata (MA). The stochastic languages generated by MA
are called rational stochastic languages; they strictly include stochastic
languages generated by PA; they also admit a very concise canonical
representation. Despite the fact that this class is not recursively enumerable,
it is efficiently identifiable in the limit by using the algorithm DEES,
introduced by the authors in a previous paper. However, the identification is
not proper and before the convergence of the algorithm, DEES can produce MA
that do not define stochastic languages. Nevertheless, it is possible to use
these MA to define stochastic languages. We show that they belong to a broader
class of rational series, that we call pseudo-stochastic rational languages.
The aim of this paper is twofold. First we provide a theoretical study of
pseudo-stochastic rational languages, the languages output by DEES, showing for
example that this class is decidable within polynomial time. Second, we have
carried out a lot of experiments in order to compare DEES to classical
inference algorithms such as ALERGIA and MDI. They show that DEES outperforms
them in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607086</id><created>2006-07-18</created><authors><author><keyname>Kayser</keyname><forenames>Daniel</forenames><affiliation>LIPN</affiliation></author><author><keyname>Nouioua</keyname><forenames>Farid</forenames><affiliation>LIPN</affiliation></author></authors><title>Representing Knowledge about Norms</title><categories>cs.AI</categories><proxy>ccsd ccsd-00085147</proxy><journal-ref>The 16th European Conference on Artificial Intelligence (ECAI'04)
  (2004) 363-367</journal-ref><abstract>  Norms are essential to extend inference: inferences based on norms are far
richer than those based on logical implications. In the recent decades, much
effort has been devoted to reason on a domain, once its norms are represented.
How to extract and express those norms has received far less attention.
Extraction is difficult: as the readers are supposed to know them, the norms of
a domain are seldom made explicit. For one thing, extracting norms requires a
language to represent them, and this is the topic of this paper. We apply this
language to represent norms in the domain of driving, and show that it is
adequate to reason on the causes of accidents, as described by car-crash
reports.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607087</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607087</id><created>2006-07-18</created><authors><author><keyname>Ramasso</keyname><forenames>Emmanuel</forenames><affiliation>LIS</affiliation></author><author><keyname>Rombaut</keyname><forenames>Mich&#xe8;le</forenames><affiliation>LIS</affiliation></author><author><keyname>Pellerin</keyname><forenames>Denis</forenames><affiliation>LIS</affiliation></author></authors><title>Un filtre temporel cr\'edibiliste pour la reconnaissance d'actions
  humaines dans les vid\'eos</title><categories>cs.MM</categories><comments>8 pages</comments><proxy>ccsd ccsd-00086119</proxy><abstract>  In the context of human action recognition in video sequences, a temporal
belief filter is presented. It allows to cope with human action disparity and
low quality videos. The whole system of action recognition is based on the
Transferable Belief Model (TBM) proposed by P. Smets. The TBM allows to
explicitly model the doubt between actions. Furthermore, the TBM emphasizes the
conflict which is exploited for action recognition. The filtering performance
is assessed on real video sequences acquired by a moving camera and under
several unknown view angles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607088</id><created>2006-07-18</created><authors><author><keyname>Nouioua</keyname><forenames>Farid</forenames><affiliation>LIPN</affiliation></author><author><keyname>Nicolas</keyname><forenames>Pascal</forenames><affiliation>LERIA</affiliation></author></authors><title>Using Answer Set Programming in an Inference-Based approach to Natural
  Language Semantics</title><categories>cs.CL cs.AI</categories><proxy>ccsd ccsd-00085158</proxy><journal-ref>Inference in Computational Semantics ICoS-5, France (2006) 77-86</journal-ref><abstract>  Using Answer Set Programming in an Inference-Based approach to Natural
Language Semantics
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607089</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607089</id><created>2006-07-18</created><updated>2006-07-19</updated><authors><author><keyname>Hutchinson</keyname><forenames>R.</forenames></author><author><keyname>Smarandache</keyname><forenames>R.</forenames></author><author><keyname>Trumpf</keyname><forenames>J.</forenames></author></authors><title>Superregular Matrices and the Construction of Convolutional Codes having
  a Maximum Distance Profile</title><categories>cs.IT math.CO math.IT</categories><comments>20 pages. Replaced on 19/7/2006, because bibtex files were not
  included in the original submission</comments><abstract>  Superregular matrices are a class of lower triangular Toeplitz matrices that
arise in the context of constructing convolutional codes having a maximum
distance profile. These matrices are characterized by the property that no
submatrix has a zero determinant unless it is trivially zero due to the lower
triangular structure. In this paper, we discuss how superregular matrices may
be used to construct codes having a maximum distance profile. We also introduce
group actions that preserve the superregularity property and present an upper
bound on the minimum size a finite field must have in order that a superregular
matrix of a given size can exist over that field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607090</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607090</id><created>2006-07-18</created><authors><author><keyname>Rishiyur</keyname><forenames>Adityan</forenames></author></authors><title>Neural Networks with Complex and Quaternion Inputs</title><categories>cs.NE</categories><comments>14 pages, 2 figures</comments><abstract>  This article investigates Kak neural networks, which can be instantaneously
trained, for complex and quaternion inputs. The performance of the basic
algorithm has been analyzed and shown how it provides a plausible model of
human perception and understanding of images. The motivation for studying
quaternion inputs is their use in representing spatial rotations that find
applications in computer graphics, robotics, global navigation, computer vision
and the spatial orientation of instruments. The problem of efficient mapping of
data in quaternion neural networks is examined. Some problems that need to be
addressed before quaternion neural networks find applications are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607091</id><created>2006-07-19</created><authors><author><keyname>Shtrakov</keyname><forenames>Stanko</forenames></author><author><keyname>Stoilov</keyname><forenames>Anton</forenames></author></authors><title>Finite element method for thermal analysis of concentrating solar
  receivers</title><categories>cs.CE</categories><comments>8 pages; 5 figures</comments><abstract>  Application of finite element method and heat conductivity transfer model for
calculation of temperature distribution in receiver for dish-Stirling
concentrating solar system is described. The method yields discretized
equations that are entirely local to the elements and provides complete
geometric flexibility. A computer program solving the finite element method
problem is created and great number of numerical experiments is carried out.
Illustrative numerical results are given for an array of triangular elements in
receiver for dish-Stirling system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607092</identifier>
 <datestamp>2008-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607092</id><created>2006-07-19</created><updated>2008-03-26</updated><authors><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Francis</keyname><forenames>Mathew C.</forenames></author><author><keyname>Sivadasan</keyname><forenames>Naveen</forenames></author></authors><title>Representing graphs as the intersection of axis-parallel cubes</title><categories>cs.DM</categories><comments>12 pages, 0 figures</comments><abstract>  A unit cube in $k$ dimensional space (or \emph{$k$-cube} in short) is defined
as the Cartesian product $R_1\times R_2\times...\times R_k$ where $R_i$(for
$1\leq i\leq k$) is a closed interval of the form $[a_i,a_i+1]$ on the real
line. A $k$-cube representation of a graph $G$ is a mapping of the vertices of
$G$ to $k$-cubes such that two vertices in $G$ are adjacent if and only if
their corresponding $k$-cubes have a non-empty intersection. The
\emph{cubicity} of $G$, denoted as $\cubi(G)$, is the minimum $k$ such that $G$
has a $k$-cube representation. Roberts \cite{Roberts} showed that for any graph
$G$ on $n$ vertices, $\cubi(G)\leq 2n/3$. Many NP-complete graph problems have
polynomial time deterministic algorithms or have good approximation ratios in
graphs of low cubicity. In most of these algorithms, computing a low
dimensional cube representation of the given graph is usually the first step.
  We present an efficient algorithm to compute the $k$-cube representation of
$G$ with maximum degree $\Delta$ in $O(\Delta \ln b)$ dimensions where $b$ is
the bandwidth of $G$. Bandwidth of $G$ is at most $n$ and can be much lower.
The algorithm takes as input a bandwidth ordering of the vertices in $G$.
Though computing the bandwidth ordering of vertices for a graph is NP-hard,
there are heuristics that perform very well in practice. Even theoretically,
there is an $O(\log^4 n)$ approximation algorithm for computing the bandwidth
ordering of a graph using which our algorithm can produce a $k$-cube
representation of any given graph in $k=O(\Delta(\ln b + \ln\ln n))$
dimensions. Both the bounds on cubicity are shown to be tight upto a factor of
$O(\log\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607093</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607093</id><created>2006-07-19</created><updated>2011-10-10</updated><authors><author><keyname>Feinstein</keyname><forenames>Craig Alan</forenames></author></authors><title>An Elegant Argument that P is not NP</title><categories>cs.CC</categories><comments>2 pages; Version 14 is the published version, but this version is
  clearer</comments><journal-ref>Progress in Physics Volume 2 (2011), 30-31</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we present an elegant argument that P is not NP by
demonstrating that the Meet-in-the-Middle algorithm must have the fastest
running-time of all deterministic and exact algorithms which solve the
SUBSET-SUM problem on a classical computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607094</identifier>
 <datestamp>2008-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607094</id><created>2006-07-20</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Upright-Quad Drawing of st-Planar Learning Spaces</title><categories>cs.CG</categories><comments>12 pages, 10 figures. To appear at 14th Int. Symp. Graph Drawing,
  2006</comments><acm-class>F.2.2</acm-class><journal-ref>J. Graph Algorithms &amp; Applications 12(1):51-72, 2008</journal-ref><abstract>  We consider graph drawing algorithms for learning spaces, a type of
st-oriented partial cube derived from antimatroids and used to model states of
knowledge of students. We show how to draw any st-planar learning space so all
internal faces are convex quadrilaterals with the bottom side horizontal and
the left side vertical, with one minimal and one maximal vertex. Conversely,
every such drawing represents an st-planar learning space. We also describe
connections between these graphs and arrangements of translates of a quadrant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607095</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607095</id><created>2006-07-20</created><authors><author><keyname>Shin</keyname><forenames>Hyundong</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Gallager's Exponent for MIMO Channels: A Reliability-Rate Tradeoff</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Communications</comments><abstract>  In this paper, we derive Gallager's random coding error exponent for
multiple-input multiple-output (MIMO) channels, assuming no channel-state
information (CSI) at the transmitter and perfect CSI at the receiver. This
measure gives insight into a fundamental tradeoff between the communication
reliability and information rate of MIMO channels, enabling to determine the
required codeword length to achieve a prescribed error probability at a given
rate below the channel capacity. We quantify the effects of the number of
antennas, channel coherence time, and spatial fading correlation on the MIMO
exponent. In addition, general formulae for the ergodic capacity and the cutoff
rate in the presence of spatial correlation are deduced from the exponent
expressions. These formulae are applicable to arbitrary structures of transmit
and receive correlation, encompassing all the previously known results as
special cases of our expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607096</id><created>2006-07-20</created><authors><author><keyname>Bouthinon</keyname><forenames>Dominique</forenames><affiliation>LIPN</affiliation></author><author><keyname>Soldano</keyname><forenames>Henry</forenames><affiliation>LIPN</affiliation></author><author><keyname>Ventos</keyname><forenames>V&#xe9;ronique</forenames><affiliation>LRI</affiliation></author></authors><title>Logical settings for concept learning from incomplete examples in First
  Order Logic</title><categories>cs.LG</categories><proxy>ccsd ccsd-00086995</proxy><abstract>  We investigate here concept learning from incomplete examples. Our first
purpose is to discuss to what extent logical learning settings have to be
modified in order to cope with data incompleteness. More precisely we are
interested in extending the learning from interpretations setting introduced by
L. De Raedt that extends to relational representations the classical
propositional (or attribute-value) concept learning from examples framework. We
are inspired here by ideas presented by H. Hirsh in a work extending the
Version space inductive paradigm to incomplete data. H. Hirsh proposes to
slightly modify the notion of solution when dealing with incomplete examples: a
solution has to be a hypothesis compatible with all pieces of information
concerning the examples. We identify two main classes of incompleteness. First,
uncertainty deals with our state of knowledge concerning an example. Second,
generalization (or abstraction) deals with what part of the description of the
example is sufficient for the learning purpose. These two main sources of
incompleteness can be mixed up when only part of the useful information is
known. We discuss a general learning setting, referred to as &quot;learning from
possibilities&quot; that formalizes these ideas, then we present a more specific
learning setting, referred to as &quot;assumption-based learning&quot; that cope with
examples which uncertainty can be reduced when considering contextual
information outside of the proper description of the examples. Assumption-based
learning is illustrated on a recent work concerning the prediction of a
consensus secondary structure common to a set of RNA sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607097</id><created>2006-07-20</created><authors><author><keyname>Razafindralambo</keyname><forenames>Tahiry</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Gu&#xe9;rin-Lassous</keyname><forenames>Isabelle</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Iannone</keyname><forenames>Luigi</forenames><affiliation>LIP6</affiliation></author><author><keyname>Fdida</keyname><forenames>Serge</forenames><affiliation>LIP6</affiliation></author></authors><title>Dynamic Packet Aggregation to Solve Performance Anomaly in 802.11
  Wireless Networks</title><categories>cs.NI</categories><proxy>ccsd inria-00086502</proxy><abstract>  In the widely used 802.11 standard, the so called performance anomaly is a
well known issue. Several works have tried to solve this problem by introducing
mechanisms such as packet fragmentation, backoff adaptation, or packet
aggregation during a fixed time interval. In this paper, we propose a novel
approach solving the performance anomaly problem by packet aggregation using a
dynamic time interval, which depends on the busy time of the wireless medium.
Our solution differs from other proposition in the literature because of this
dynamic time interval, which allows increasing fairness, reactivity, and in
some cases efficiency. In this article, we emphasize the performance evaluation
of our proposal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607098</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607098</id><created>2006-07-20</created><updated>2006-08-02</updated><authors><author><keyname>Calderbank</keyname><forenames>A. R.</forenames></author><author><keyname>Gilbert</keyname><forenames>Anna C.</forenames></author><author><keyname>Strauss</keyname><forenames>Martin J.</forenames></author></authors><title>List decoding of noisy Reed-Muller-like codes</title><categories>cs.DS cs.IT math.IT</categories><acm-class>E.4; F.2.1</acm-class><abstract>  First- and second-order Reed-Muller (RM(1) and RM(2), respectively) codes are
two fundamental error-correcting codes which arise in communication as well as
in probabilistically-checkable proofs and learning. In this paper, we take the
first steps toward extending the quick randomized decoding tools of RM(1) into
the realm of quadratic binary and, equivalently, Z_4 codes. Our main
algorithmic result is an extension of the RM(1) techniques from Goldreich-Levin
and Kushilevitz-Mansour algorithms to the Hankel code, a code between RM(1) and
RM(2). That is, given signal s of length N, we find a list that is a superset
of all Hankel codewords phi with dot product to s at least (1/sqrt(k)) times
the norm of s, in time polynomial in k and log(N). We also give a new and
simple formulation of a known Kerdock code as a subcode of the Hankel code. As
a corollary, we can list-decode Kerdock, too. Also, we get a quick algorithm
for finding a sparse Kerdock approximation. That is, for k small compared with
1/sqrt{N} and for epsilon &gt; 0, we find, in time polynomial in (k
log(N)/epsilon), a k-Kerdock-term approximation s~ to s with Euclidean error at
most the factor (1+epsilon+O(k^2/sqrt{N})) times that of the best such
approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607099</id><created>2006-07-21</created><updated>2007-05-11</updated><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Degrees of Freedom Region for the MIMO X Channel</title><categories>cs.IT math.IT</categories><comments>31 pages</comments><abstract>  We provide achievability as well as converse results for the degrees of
freedom region of a MIMO $X$ channel, i.e., a system with two transmitters, two
receivers, each equipped with multiple antennas, where independent messages
need to be conveyed over fixed channels from each transmitter to each receiver.
With M=1 antennas at each node, we find that the total (sum rate) degrees of
freedom are bounded above and below as $1 \leq\eta_X^\star \leq {4/3}$. If
$M&gt;1$ and channel matrices are non-degenerate then the precise degrees of
freedom $\eta_X^\star = {4/3}M$. Simple zero forcing without dirty paper
encoding or successive decoding, suffices to achieve the ${4/3}M$ degrees of
freedom. With equal number of antennas at all nodes, we explore the increase in
degrees of freedom when some of the messages are made available to a
transmitter or receiver in the manner of cognitive radio. With a cognitive
transmitter we show that the number of degrees of freedom $\eta = {3/2}M$ (for
$M&gt;1$) on the MIMO $X$ channel. The same degrees of freedom are obtained on the
MIMO $X$ channel with a cognitive receiver as well. In contrast to the $X$
channel result, we show that for the MIMO \emph{interference} channel, the
degrees of freedom are not increased even if both the transmitter and the
receiver of one user know the other user's message. However, the interference
channel can achieve the full $2M$ degrees of freedom if \emph{each} user has
either a cognitive transmitter or a cognitive receiver. Lastly, if the channels
vary with time/frequency then the $X$ channel with single antennas $(M=1)$ at
all nodes has exactly 4/3 degrees of freedom with no shared messages and
exactly 3/2 degrees of freedom with a cognitive transmitter or a cognitive
receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607100</id><created>2006-07-21</created><authors><author><keyname>Han</keyname><forenames>Xin</forenames></author><author><keyname>Iwama</keyname><forenames>Kazuo</forenames></author><author><keyname>Zhang</keyname><forenames>Guochuan</forenames></author></authors><title>New Upper Bounds on The Approximability of 3D Strip Packing</title><categories>cs.DS</categories><comments>Submitted to SODA 2007</comments><abstract>  In this paper, we study the 3D strip packing problem in which we are given a
list of 3-dimensional boxes and required to pack all of them into a
3-dimensional strip with length 1 and width 1 and unlimited height to minimize
the height used. Our results are below: i) we give an approximation algorithm
with asymptotic worst-case ratio 1.69103, which improves the previous best
bound of $2+\epsilon$ by Jansen and Solis-Oba of SODA 2006; ii) we also present
an asymptotic PTAS for the case in which all items have {\em square} bases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607101</id><created>2006-07-24</created><updated>2006-07-28</updated><authors><author><keyname>Hill</keyname><forenames>Patricia M.</forenames></author><author><keyname>Spoto</keyname><forenames>Fausto</forenames></author></authors><title>Deriving Escape Analysis by Abstract Interpretation: Proofs of results</title><categories>cs.PL</categories><acm-class>F.2</acm-class><abstract>  Escape analysis of object-oriented languages approximates the set of objects
which do not escape from a given context. If we take a method as context, the
non-escaping objects can be allocated on its activation stack; if we take a
thread, Java synchronisation locks on such objects are not needed. In this
paper, we formalise a basic escape domain e as an abstract interpretation of
concrete states, which we then refine into an abstract domain er which is more
concrete than e and, hence, leads to a more precise escape analysis than e. We
provide optimality results for both e and er, in the form of Galois insertions
from the concrete to the abstract domains and of optimal abstract operations.
The Galois insertion property is obtained by restricting the abstract domains
to those elements which do not contain garbage, by using an abstract garbage
collector. Our implementation of er is hence an implementation of a formally
correct escape analyser, able to detect the stack allocatable creation points
of Java (bytecode) applications.
  This report contains the proofs of results of a paper with the same title and
authors and to be published in the Journal &quot;Higher-Order Symbolic Computation&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607102</identifier>
 <datestamp>2008-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607102</id><created>2006-07-23</created><updated>2008-03-30</updated><authors><author><keyname>Kotagiri</keyname><forenames>Shiva Prasad</forenames></author><author><keyname>Laneman</keyname><forenames>J. Nicholas</forenames></author></authors><title>Multiaccess Channels with State Known to Some Encoders and Independent
  Messages</title><categories>cs.IT math.IT</categories><comments>Accepted to EURASIP Journal on Wireless Communication and Networking,
  Feb. 2008</comments><abstract>  We consider a state-dependent multiaccess channel (MAC) with state
non-causally known to some encoders. We derive an inner bound for the capacity
region in the general discrete memoryless case and specialize to a binary
noiseless case. In the case of maximum entropy channel state, we obtain the
capacity region for binary noiseless MAC with one informed encoder by deriving
a non-trivial outer bound for this case. For a Gaussian state-dependent MAC
with one encoder being informed of the channel state, we present an inner bound
by applying a slightly generalized dirty paper coding (GDPC) at the informed
encoder that allows for partial state cancellation, and a trivial outer bound
by providing channel state to the decoder also. The uninformed encoders benefit
from the state cancellation in terms of achievable rates, however, appears that
GDPC cannot completely eliminate the effect of the channel state on the
achievable rate region, in contrast to the case of all encoders being informed.
In the case of infinite state variance, we analyze how the uninformed encoder
benefits from the informed encoder's actions using the inner bound and also
provide a non-trivial outer bound for this case which is better than the
trivial outer bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607103</id><created>2006-07-23</created><authors><author><keyname>Ingber</keyname><forenames>Lester</forenames></author></authors><title>Ideas by Statistical Mechanics (ISM)</title><categories>cs.CE cs.MS cs.NE</categories><abstract>  Ideas by Statistical Mechanics (ISM) is a generic program to model evolution
and propagation of ideas/patterns throughout populations subjected to
endogenous and exogenous interactions. The program is based on the author's
work in Statistical Mechanics of Neocortical Interactions (SMNI), and uses the
author's Adaptive Simulated Annealing (ASA) code for optimizations of training
sets, as well as for importance-sampling to apply the author's copula financial
risk-management codes, Trading in Risk Dimensions (TRD), for assessments of
risk and uncertainty. This product can be used for decision support for
projects ranging from diplomatic, information, military, and economic (DIME)
factors of propagation/evolution of ideas, to commercial sales, trading
indicators across sectors of financial markets, advertising and political
campaigns, etc. A statistical mechanical model of neocortical interactions,
developed by the author and tested successfully in describing short-term memory
and EEG indicators, is the proposed model. Parameters with a given subset of
macrocolumns will be fit using ASA to patterns representing ideas. Parameters
of external and inter-regional interactions will be determined that promote or
inhibit the spread of these ideas. Tools of financial risk management,
developed by the author to process correlated multivariate systems with
differing non-Gaussian distributions using modern copula analysis,
importance-sampled using ASA, will enable bona fide correlations and
uncertainties of success and failure to be calculated. Marginal distributions
will be evolved to determine their expected duration and stability using
algorithms developed by the author, i.e., PATHTREE and PATHINT codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607104</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607104</id><created>2006-07-23</created><updated>2006-09-17</updated><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author></authors><title>Reducing the Computation of Linear Complexities of Periodic Sequences
  over $GF(p^m)$</title><categories>cs.CR cs.IT math.IT</categories><comments>10 pages. To appear in IEEE Transactions on Innformation Theory</comments><abstract>  The linear complexity of a periodic sequence over $GF(p^m)$ plays an
important role in cryptography and communication [12]. In this correspondence,
we prove a result which reduces the computation of the linear complexity and
minimal connection polynomial of a period $un$ sequence over $GF(p^m)$ to the
computation of the linear complexities and minimal connection polynomials of
$u$ period $n$ sequences. The conditions $u|p^m-1$ and
 $\gcd(n,p^m-1)=1$ are required for the result to hold. Some applications of
this reduction in fast algorithms to determine the linear complexities and
minimal connection polynomials of sequences over $GF(p^m)$ are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607105</identifier>
 <datestamp>2012-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607105</id><created>2006-07-24</created><updated>2012-09-13</updated><authors><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Nearly-Linear Time Algorithms for Preconditioning and Solving Symmetric,
  Diagonally Dominant Linear Systems</title><categories>cs.NA cs.DS</categories><comments>This revised version contains a new section in which we prove that it
  suffices to carry out the computations with limited precision</comments><acm-class>F.2.1; G.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a randomized algorithm that, on input a symmetric, weakly
diagonally dominant n-by-n matrix A with m nonzero entries and an n-vector b,
produces a y such that $\norm{y - \pinv{A} b}_{A} \leq \epsilon \norm{\pinv{A}
b}_{A}$ in expected time $O (m \log^{c}n \log (1/\epsilon)),$ for some constant
c. By applying this algorithm inside the inverse power method, we compute
approximate Fiedler vectors in a similar amount of time. The algorithm applies
subgraph preconditioners in a recursive fashion. These preconditioners improve
upon the subgraph preconditioners first introduced by Vaidya (1990).
  For any symmetric, weakly diagonally-dominant matrix A with non-positive
off-diagonal entries and $k \geq 1$, we construct in time $O (m \log^{c} n)$ a
preconditioner B of A with at most $2 (n - 1) + O ((m/k) \log^{39} n)$ nonzero
off-diagonal entries such that the finite generalized condition number
$\kappa_{f} (A,B)$ is at most k, for some other constant c.
  In the special case when the nonzero structure of the matrix is planar the
corresponding linear system solver runs in expected time $ O (n \log^{2} n + n
\log n \ \log \log n \ \log (1/\epsilon))$.
  We hope that our introduction of algorithms of low asymptotic complexity will
lead to the development of algorithms that are also fast in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607106</id><created>2006-07-24</created><updated>2006-07-25</updated><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author></authors><title>The Complexity of Quantified Constraint Satisfaction: Collapsibility,
  Sink Algebras, and the Three-Element Case</title><categories>cs.LO cs.CC</categories><abstract>  The constraint satisfaction probem (CSP) is a well-acknowledged framework in
which many combinatorial search problems can be naturally formulated. The CSP
may be viewed as the problem of deciding the truth of a logical sentence
consisting of a conjunction of constraints, in front of which all variables are
existentially quantified. The quantified constraint satisfaction problem (QCSP)
is the generalization of the CSP where universal quantification is permitted in
addition to existential quantification. The general intractability of these
problems has motivated research studying the complexity of these problems under
a restricted constraint language, which is a set of relations that can be used
to express constraints.
  This paper introduces collapsibility, a technique for deriving positive
complexity results on the QCSP. In particular, this technique allows one to
show that, for a particular constraint language, the QCSP reduces to the CSP.
We show that collapsibility applies to three known tractable cases of the QCSP
that were originally studied using disparate proof techniques in different
decades: Quantified 2-SAT (Aspvall, Plass, and Tarjan 1979), Quantified
Horn-SAT (Karpinski, Kleine B\&quot;{u}ning, and Schmitt 1987), and Quantified
Affine-SAT (Creignou, Khanna, and Sudan 2001). This reconciles and reveals
common structure among these cases, which are describable by constraint
languages over a two-element domain. In addition to unifying these known
tractable cases, we study constraint languages over domains of larger size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607107</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607107</id><created>2006-07-24</created><authors><author><keyname>Mello</keyname><forenames>Louis</forenames></author></authors><title>Linear Predictive Coding as an Estimator of Volatility</title><categories>cs.IT math.IT</categories><abstract>  In this paper, we present a method of estimating the volatility of a signal
that displays stochastic noise (such as a risky asset traded on an open market)
utilizing Linear Predictive Coding. The main purpose is to associate volatility
with a series of statistical properties that can lead us, through further
investigation, toward a better understanding of structural volatility as well
as to improve the quality of our current estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607108</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607108</id><created>2006-07-25</created><authors><author><keyname>Gabidulin</keyname><forenames>E. M.</forenames></author><author><keyname>Loidreau</keyname><forenames>P.</forenames></author></authors><title>Properties of subspace subcodes of optimum codes in rank metric</title><categories>cs.IT cs.DM math.IT</categories><comments>17 pages, Submitted to IEEE-IT</comments><abstract>  Maximum rank distance codes denoted MRD-codes are the equivalent in rank
metric of MDS-codes. Given any integer $q$ power of a prime and any integer $n$
there is a family of MRD-codes of length $n$ over $\FF{q^n}$ having
polynomial-time decoding algorithms. These codes can be seen as the analogs of
Reed-Solomon codes (hereafter denoted RS-codes) for rank metric. In this paper
their subspace subcodes are characterized. It is shown that hey are equivalent
to MRD-codes constructed in the same way but with smaller parameters. A
specific polynomial-time decoding algorithm is designed. Moreover, it is shown
that the direct sum of subspace subcodes is equivalent to the direct product of
MRD-codes with smaller parameters. This implies that the decoding procedure can
correct errors of higher rank than the error-correcting capability. Finally it
is shown that, for given parameters, subfield subcodes are completely
characterized by elements of the general linear group ${GL}_n(\FF{q})$ of
non-singular $q$-ary matrices of size $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607109</id><created>2006-07-25</created><updated>2006-07-31</updated><authors><author><keyname>Samer</keyname><forenames>Marko</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Complexity and Applications of Edge-Induced Vertex-Cuts</title><categories>cs.DM cs.CC</categories><comments>17 pages, 5 figures, 2 tables</comments><acm-class>G.2.2; F.2.2</acm-class><abstract>  Motivated by hypergraph decomposition algorithms, we introduce the notion of
edge-induced vertex-cuts and compare it with the well-known notions of
edge-cuts and vertex-cuts. We investigate the complexity of computing minimum
edge-induced vertex-cuts and demonstrate the usefulness of our notion by
applications in network reliability and constraint satisfaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607110</id><created>2006-07-25</created><authors><author><keyname>Grossmann</keyname><forenames>Etienne</forenames></author></authors><title>A Theory of Probabilistic Boosting, Decision Trees and Matryoshki</title><categories>cs.LG</categories><acm-class>I.5.1; I.2.6; G.3</acm-class><abstract>  We present a theory of boosting probabilistic classifiers. We place ourselves
in the situation of a user who only provides a stopping parameter and a
probabilistic weak learner/classifier and compare three types of boosting
algorithms: probabilistic Adaboost, decision tree, and tree of trees of ... of
trees, which we call matryoshka. &quot;Nested tree,&quot; &quot;embedded tree&quot; and &quot;recursive
tree&quot; are also appropriate names for this algorithm, which is one of our
contributions. Our other contribution is the theoretical analysis of the
algorithms, in which we give training error bounds. This analysis suggests that
the matryoshka leverages probabilistic weak classifiers more efficiently than
simple decision trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607111</id><created>2006-07-25</created><authors><author><keyname>Yurcik</keyname><forenames>William</forenames></author><author><keyname>Abad</keyname><forenames>Cristina</forenames></author><author><keyname>Hasan</keyname><forenames>Ragib</forenames></author><author><keyname>Saleem</keyname><forenames>Moazzam</forenames></author><author><keyname>Sridharan</keyname><forenames>Shyama</forenames></author></authors><title>UCLog+ : A Security Data Management System for Correlating Alerts,
  Incidents, and Raw Data From Remote Logs</title><categories>cs.CR</categories><comments>10 pages, 9 Tables, 16 Figures</comments><abstract>  Source data for computer network security analysis takes different forms
(alerts, incidents, logs) and each source may be voluminous. Due to the
challenge this presents for data management, this has often lead to security
stovepipe operations which focus primarily on a small number of data sources
for analysis with little or no automated correlation between data sources
(although correlation may be done manually). We seek to address this systemic
problem.
  In previous work we developed a unified correlated logging system (UCLog)
that automatically processes alerts from different devices. We take this work
one step further by presenting the architecture and applications of UCLog+
which adds the new capability to correlate between alerts and incidents and raw
data located on remote logs. UCLog+ can be used for forensic analysis including
queries and report generation but more importantly it can be used for
near-real-time situational awareness of attack patterns in progress. The
system, implemented with open source tools, can also be a repository for secure
information sharing by different organizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607112</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607112</id><created>2006-07-25</created><authors><author><keyname>Stepanov</keyname><forenames>M. G.</forenames></author><author><keyname>Chertkov</keyname><forenames>M.</forenames></author></authors><title>Improving convergence of Belief Propagation decoding</title><categories>cs.IT math.IT</categories><report-no>LA-UR-06-5058</report-no><abstract>  The decoding of Low-Density Parity-Check codes by the Belief Propagation (BP)
algorithm is revisited. We check the iterative algorithm for its convergence to
a codeword (termination), we run Monte Carlo simulations to find the
probability distribution function of the termination time, n_it. Tested on an
example [155, 64, 20] code, this termination curve shows a maximum and an
extended algebraic tail at the highest values of n_it. Aiming to reduce the
tail of the termination curve we consider a family of iterative algorithms
modifying the standard BP by means of a simple relaxation. The relaxation
parameter controls the convergence of the modified BP algorithm to a minimum of
the Bethe free energy. The improvement is experimentally demonstrated for
Additive-White-Gaussian-Noise channel in some range of the signal-to-noise
ratios. We also discuss the trade-off between the relaxation parameter of the
improved iterative scheme and the number of iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607113</id><created>2006-07-25</created><authors><author><keyname>Carlson</keyname><forenames>Josiah</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Trees with Convex Faces and Optimal Angles</title><categories>cs.CG</categories><comments>12 pages, 10 figures. To appear at 14th Int. Symp. Graph Drawing,
  2006</comments><acm-class>F.2.2</acm-class><abstract>  We consider drawings of trees in which all edges incident to leaves can be
extended to infinite rays without crossing, partitioning the plane into
infinite convex polygons. Among all such drawings we seek the one maximizing
the angular resolution of the drawing. We find linear time algorithms for
solving this problem, both for plane trees and for trees without a fixed
embedding. In any such drawing, the edge lengths may be set independently of
the angles, without crossing; we describe multiple strategies for setting these
lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607114</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607114</id><created>2006-07-26</created><updated>2006-09-11</updated><authors><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Revising Type-2 Computation and Degrees of Discontinuity</title><categories>cs.LO math.LO</categories><comments>to appear in Proc. CCA'06</comments><acm-class>F.1.1; F.1.2; F.4.1</acm-class><journal-ref>Electronic Notes in Theoretical Computer Science vol.167
  (Jan.2007)</journal-ref><doi>10.1016/j.entcs.2006.08.015</doi><abstract>  By the sometimes so-called MAIN THEOREM of Recursive Analysis, every
computable real function is necessarily continuous. Weihrauch and Zheng
(TCS'2000), Brattka (MLQ'2005), and Ziegler (ToCS'2006) have considered
different relaxed notions of computability to cover also discontinuous
functions. The present work compares and unifies these approaches. This is
based on the concept of the JUMP of a representation: both a TTE-counterpart to
the well known recursion-theoretic jump on Kleene's Arithmetical Hierarchy of
hypercomputation: and a formalization of revising computation in the sense of
Shoenfield.
  We also consider Markov and Banach/Mazur oracle-computation of discontinuous
fu nctions and characterize the computational power of Type-2 nondeterminism to
coincide with the first level of the Analytical Hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607115</id><created>2006-07-26</created><authors><author><keyname>Kaminski</keyname><forenames>Marcin</forenames></author><author><keyname>Lozin</keyname><forenames>Vadim</forenames></author></authors><title>Polynomial-time algorithm for vertex k-colorability of P_5-free graphs</title><categories>cs.DM cs.DS</categories><abstract>  We give the first polynomial-time algorithm for coloring vertices of P_5-free
graphs with k colors. This settles an open problem and generalizes several
previously known results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607116</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607116</id><created>2006-07-26</created><authors><author><keyname>Abreu</keyname><forenames>Rui</forenames></author><author><keyname>Zoeteweij</keyname><forenames>Peter</forenames></author><author><keyname>van Gemund</keyname><forenames>Arjan JC</forenames></author></authors><title>Program Spectra Analysis in Embedded Software: A Case Study</title><categories>cs.SE</categories><report-no>TUD-SERG-2006-007</report-no><abstract>  Because of constraints imposed by the market, embedded software in consumer
electronics is almost inevitably shipped with faults and the goal is just to
reduce the inherent unreliability to an acceptable level before a product has
to be released. Automatic fault diagnosis is a valuable tool to capture
software faults without extra effort spent on testing. Apart from a debugging
aid at design and integration time, fault diagnosis can help analyzing problems
during operation, which allows for more accurate system recovery. In this paper
we discuss perspectives and limitations for applying a particular fault
diagnosis technique, namely the analysis of program spectra, in the area of
embedded software in consumer electronics devices. We illustrate these by our
first experience with a test case from industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607117</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607117</id><created>2006-07-26</created><authors><author><keyname>Aggarwal</keyname><forenames>Gagan</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Feldman</keyname><forenames>Jon</forenames></author></authors><title>Bidding to the Top: VCG and Equilibria of Position-Based Auctions</title><categories>cs.GT</categories><abstract>  Many popular search engines run an auction to determine the placement of
advertisements next to search results. Current auctions at Google and Yahoo!
let advertisers specify a single amount as their bid in the auction. This bid
is interpreted as the maximum amount the advertiser is willing to pay per click
on its ad. When search queries arrive, the bids are used to rank the ads
linearly on the search result page. The advertisers pay for each user who
clicks on their ad, and the amount charged depends on the bids of all the
advertisers participating in the auction. In order to be effective, advertisers
seek to be as high on the list as their budget permits, subject to the market.
  We study the problem of ranking ads and associated pricing mechanisms when
the advertisers not only specify a bid, but additionally express their
preference for positions in the list of ads. In particular, we study &quot;prefix
position auctions&quot; where advertiser $i$ can specify that she is interested only
in the top $b_i$ positions.
  We present a simple allocation and pricing mechanism that generalizes the
desirable properties of current auctions that do not have position constraints.
In addition, we show that our auction has an &quot;envy-free&quot; or &quot;symmetric&quot; Nash
equilibrium with the same outcome in allocation and pricing as the well-known
truthful Vickrey-Clarke-Groves (VCG) auction. Furthermore, we show that this
equilibrium is the best such equilibrium for the advertisers in terms of the
profit made by each advertiser. We also discuss other position-based auctions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607118</identifier>
 <datestamp>2008-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607118</id><created>2006-07-27</created><updated>2008-03-05</updated><authors><author><keyname>Arai</keyname><forenames>Toshiyasu</forenames></author><author><keyname>Eguchi</keyname><forenames>Naohi</forenames></author></authors><title>A new function algebra of EXPTIME functions by safe nested recursion</title><categories>cs.CC</categories><acm-class>F.4.1; F.1.1; F.1.3</acm-class><abstract>  Bellantoni and Cook have given a function-algebra characterization of the
polynomial-time computable functions via an unbounded recursion scheme which is
called safe recursion. Inspired by their work, we characterize the
exponential-time computable functions with the use of a safe variant of nested
recursion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607119</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>Web-Based Enterprise Information Systems Development: The Integrated
  Methodology</title><categories>cs.SE cs.DC</categories><comments>5 pages</comments><journal-ref>Proceedings of the 5th International Conference on Computer
  Science and Information Technologies (CSIT 2005), Yerevan, Armenia, 19-23
  September 2005. National Academy of Sciences of Armenia Publishers, 2005,
  pp.373-381</journal-ref><abstract>  The paper considers software development issues for large-scale enterprise
information systems (IS) with databases (DB) in global heterogeneous
distributed computational environment. Due to high IT development rates, the
present-day society has accumulated and rapidly increases an extremely huge
data burden. Manipulating with such huge data arrays becomes an essential
problem, particularly due to their global distribution, heterogeneous and
weak-structured character. The conceptual approach to integrated Internet-based
IS design, development and implementation is presented, including formal
models, software development methodology and original software development
tools for visual problem-oriented development and content management. IS
implementation results proved shortening terms and reducing costs of
implementation compared to commercial software available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607120</id><created>2006-07-27</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames><affiliation>National Research Council of Canada</affiliation></author></authors><title>Expressing Implicit Semantic Relations without Supervision</title><categories>cs.CL cs.AI cs.IR cs.LG</categories><comments>8 pages, related work available at http://purl.org/peter.turney/</comments><report-no>NRC-48761</report-no><acm-class>H.3.1; I.2.6; I.2.7</acm-class><journal-ref>Proceedings of the 21st International Conference on Computational
  Linguistics and 44th Annual Meeting of the Association for Computational
  Linguistics (ACL-06), (2006), Sydney, Australia, 313-320</journal-ref><abstract>  We present an unsupervised learning algorithm that mines large text corpora
for patterns that express implicit semantic relations. For a given input word
pair X:Y with some unspecified semantic relations, the corresponding output
list of patterns &lt;P1,...,Pm&gt; is ranked according to how well each pattern Pi
expresses the relations between X and Y. For example, given X=ostrich and
Y=bird, the two highest ranking output patterns are &quot;X is the largest Y&quot; and &quot;Y
such as the X&quot;. The output patterns are intended to be useful for finding
further pairs with the same relations, to support the construction of lexicons,
ontologies, and semantic networks. The patterns are sorted by pertinence, where
the pertinence of a pattern Pi for a word pair X:Y is the expected relational
similarity between the given pair and typical pairs for Pi. The algorithm is
empirically evaluated on two tasks, solving multiple-choice SAT word analogy
questions and classifying semantic relations in noun-modifier pairs. On both
tasks, the algorithm achieves state-of-the-art results, performing
significantly better than several alternative pattern ranking algorithms, based
on tf-idf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607121</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607121</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author><author><keyname>Pogodayev</keyname><forenames>Gleb G.</forenames></author></authors><title>Object-Based Groupware: Theory, Design and Implementation Issues</title><categories>cs.SE</categories><comments>8 pages, 2 figures</comments><journal-ref>In: J.Eder and L.A. Kalinichenko, (Ed.) Advances in Databases and
  Information Systems, Vol.2. St.-Petersburg: Nevsky Dialect, 1997, p.p.10-17</journal-ref><abstract>  Document management software systems are having a wide audience at present.
However, groupware as a term has a wide variety of possible definitions.
Groupware classification attempt is made in this paper. Possible approaches to
groupware are considered including document management, document control and
mailing systems. Lattice theory and concept modelling are presented as a
theoretical background for the systems in question. Current technologies in
state-of-the-art document managenent software are discussed. Design and
implementation aspects for user-friendly integrate enterprise systems are
described. Results for a real system to be implemented are given. Perspectives
of the field in question are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607122</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607122</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>Enterprise Content Management: Theory and Engineering for Entire
  Lifecycle Support</title><categories>cs.SE cs.DC</categories><comments>6 pages, 1 figure</comments><journal-ref>Proceedings of the 8th International Workshop on Computer Science
  and Information Technologies (CSIT'2006), Vol.1, Karlsruhe, Germany,
  Sept.28-29, 2006.- Karlsruhe University Publishers, Karlsruhe, 2006.- Vol.1,
  p.p.92-97</journal-ref><abstract>  The paper considers enterprise content management (ECM) issues in global
heterogeneous distributed computational environment. Present-day enterprises
have accumulated a huge data burden. Manipulating with such a bulk becomes an
essential problem, particularly due to its global distribution, heterogeneous
and weak-structured character. The conceptual approach to integrated ECM
lifecycle support is presented, including overview of formal models, software
development methodology and innovative software development tools.
Implementation results proved shortening terms and reducing costs of
implementation compared to commercial software available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607123</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607123</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>Enterprise Portal Development Tools: Problem-Oriented Approach</title><categories>cs.SE cs.DC</categories><comments>4 pages, 2 figures</comments><journal-ref>Proceedings of the 7th International Workshop on Computer Science
  and Information Technologies (CSIT'2005), Vol.1, Ufa State Aviation Technical
  University, USATU Editorial-Publishing Office, Ufa, 2005, pp. 110-113</journal-ref><abstract>  The paper deals with problem-oriented visual information system (IS)
engineering for enterprise Internet-based applications, which is a vital part
of the whole development process. The suggested approach is based on semantic
network theory and a novel ConceptModeller CASE tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607124</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607124</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>ConceptModeller: a Problem-Oriented Visual SDK for Globally Distributed
  Enterprise Systems</title><categories>cs.SE cs.DC</categories><comments>4 pages, 2 figures</comments><report-no>cs.szykov.27374</report-no><journal-ref>Proceedings of the 7th International Workshop on Computer Science
  and Information Technologies (CSIT'2005), Vol.1, Ufa State Aviation Technical
  University, USATU Editorial-Publishing Office, Ufa, 2005, pp. 114-117</journal-ref><abstract>  The paper describes problem-oriented approach to software development. The
approach is a part of the original integrated methodology of enterprise
Internet-based software design and implementation. All aspects of software
development, from theory to implementation, are covered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607125</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>Enterprise Portal: from Model to Implementation</title><categories>cs.SE cs.DC</categories><comments>6 pages, 1 figure</comments><journal-ref>Workshop on Computer Science and Information Technologies
  (CSIT'2004), Budapest, Hungary, 2004, Vol.2, p.p.188-193</journal-ref><abstract>  Portal technology can significantly improve the entire corporate information
infrastructure. The approach proposed is based on rigorous and consistent
(meta)data model and provides for efficient and accurate front-end integration
of heterogeneous corporate applications including enterprise resource planning
(ERP) systems, multimedia data warehouses and proprietary content databases.
The methodology proposed embraces entire software lifecycle; it is illustrated
by an enterprise-level Intranet portal implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607126</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607126</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>Abstract Machine as a Model of Content Management Information System</title><categories>cs.SE cs.DC</categories><comments>4 pages</comments><journal-ref>Workshop on Computer Science and Information Technologies
  (CSIT'2004), Budapest, Hungary, 2004, Vol.2, p.p.251-252</journal-ref><abstract>  Enterprise content management is an urgent issue of current scientific and
practical activities in software design and implementation. However, papers
known as yet give insufficient coverage of theoretical background of the
software in question. The paper gives an attempt of building a state-based
model of content management. In accordance with the theoretical principles
outlined, a content management information system (CMIS) has been implemented
in a large international oil-and-gas group of companies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607127</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>Integrating Enterprise Software Applications with Web Portal Technology</title><categories>cs.SE cs.DC</categories><comments>6 pages, 1 picture</comments><journal-ref>Proceedings of 5th International Workshop on Computer Science and
  Information Technologies (CSIT'2003), Vol.1, Ufa State Aviation Technical
  University, Ufa:USATU Editorial-Publishing Office, 2003, p.p.60-65</journal-ref><abstract>  Web-portal based approach can significantly improve the entire corporate
information infrastructure. The approach proposed provides for rapid and
accurate front-end integration of heterogeneous corporate applications
including enterprise resource planning (ERP) systems. Human resources ERP
component and multimedia data warehouse implementations are discussed as
essential instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607128</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>The Integrated Approach to ERP: Embracing the Web</title><categories>cs.SE cs.DC</categories><comments>6 pages, 3 pictures</comments><journal-ref>Proceedings of 4th International Workshop on Computer Science and
  Information Technologies, (CSIT'2002) Sept., 2002, Patras, Greece, Vol.1,
  p.p.73-78</journal-ref><abstract>  Integrated approach to enterprise resource planning (ERP) software design and
implementation can significantly improve the entire corporate information
infrastructure and it helps to benefit from power of Internet services. The
approach proposed provides for corporate Web portal integrity, consistency,
urgency and front-end data processing. Human resources (HR) ERP component
implementation is discussed as an essential instance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607129</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607129</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>Enterprise Resource Planning Systems: the Integrated Approach</title><categories>cs.SE cs.DC</categories><comments>12 pages, 6 pictures</comments><journal-ref>Proceedings of the 3d International Workshop on Computer Science
  and Information Technologies, (CSIT'2001), Ufa:USATU, 2001, Vol.1,
  p.p.284-295</journal-ref><abstract>  Enterprise resource planning (ERP) systems enjoy an increasingly wide
coverage. However, no truly integrate solution has been proposed as yet. ERP
classification is given. Recent trends in commercial systems are analyzed on
the basis of human resources (HR) management software. An innovative &quot;straight
through&quot; design and implementation process of an open, secure, and scalable
integrated event-driven enterprise solution is suggested. Implementation
results are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607130</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607130</id><created>2006-07-27</created><authors><author><keyname>Zykov</keyname><forenames>Sergey V.</forenames></author></authors><title>Towards Implementing an Enterprise Groupware-Integrated Human Resources
  Information System</title><categories>cs.SE cs.CY</categories><comments>9 pages, 3 pictures</comments><journal-ref>Proceedings of the 2nd International Workshop on Computer Science
  and Information Technologies (CSIT'2000), Vol.1, Ufa State Aviation Technical
  University, USATU Editorial-Publishing Office, Ufa, 2000, p.p.188-196</journal-ref><abstract>  Human resources management software is having a wide audience at present.
However, no truly integrate solution has been proposed yet to improve the
systems concerned. Approaches to extra data collection for appraisal
decision-making are considered on the concept modeling theoretical basis.
Current technologies in state-of-the-art HR management software are compared.
Design and implementation aspects for a Web-wired truly integrated secure and
scalable event-driven enterprise system are described. Benchmark results are
presented. Field perspectives are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607131</identifier>
 <datestamp>2008-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607131</id><created>2006-07-27</created><updated>2008-06-03</updated><authors><author><keyname>Skoric</keyname><forenames>B.</forenames></author><author><keyname>Vladimirova</keyname><forenames>T. U.</forenames></author><author><keyname>Celik</keyname><forenames>M.</forenames></author><author><keyname>Talstra</keyname><forenames>J. C.</forenames></author></authors><title>Tardos fingerprinting is better than we thought</title><categories>cs.CR</categories><comments>Modified presentation of results</comments><report-no>PR-MS 26.957</report-no><abstract>  We review the fingerprinting scheme by Tardos and show that it has a much
better performance than suggested by the proofs in Tardos' original paper. In
particular, the length of the codewords can be significantly reduced.
  First we generalize the proofs of the false positive and false negative error
probabilities with the following modifications: (1) we replace Tardos'
hard-coded numbers by variables and (2) we allow for independently chosen false
positive and false negative error rates. It turns out that all the
collusion-resistance properties can still be proven when the code length is
reduced by a factor of more than 2.
  Second, we study the statistical properties of the fingerprinting scheme, in
particular the average and variance of the accusations. We identify which
colluder strategy forces the content owner to employ the longest code. Using a
gaussian approximation for the probability density functions of the
accusations, we show that the required false negative and false positive error
rate can be achieved with codes that are a factor 2 shorter than required for
rigid proofs.
  Combining the results of these two approaches, we show that the Tardos scheme
can be used with a code length approximately 5 times shorter than in the
original construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607132</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607132</id><created>2006-07-27</created><authors><author><keyname>Ahlswede</keyname><forenames>R.</forenames></author><author><keyname>Aydinian</keyname><forenames>H.</forenames></author><author><keyname>Khachatrian</keyname><forenames>L. H.</forenames></author><author><keyname>Tolhuizen</keyname><forenames>L. M. G. M.</forenames></author></authors><title>On q-ary codes correcting all unidirectional errors of a limited
  magnitude</title><categories>cs.IT math.IT</categories><comments>22 pages,no figures. Accepted for publication of Journal of Armenian
  Academy of Sciences, special issue dedicated to Rom Varshamov</comments><abstract>  We consider codes over the alphabet Q={0,1,..,q-1}intended for the control of
unidirectional errors of level l. That is, the transmission channel is such
that the received word cannot contain both a component larger than the
transmitted one and a component smaller than the transmitted one. Moreover, the
absolute value of the difference between a transmitted component and its
received version is at most l.
  We introduce and study q-ary codes capable of correcting all unidirectional
errors of level l. Lower and upper bounds for the maximal size of those codes
are presented.
  We also study codes for this aim that are defined by a single equation on the
codeword coordinates(similar to the Varshamov-Tenengolts codes for correcting
binary asymmetric errors). We finally consider the problem of detecting all
unidirectional errors of level l.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607133</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607133</id><created>2006-07-27</created><authors><author><keyname>Ewaschuk</keyname><forenames>Robert</forenames></author><author><keyname>Turney</keyname><forenames>Peter D.</forenames></author></authors><title>Self-Replication and Self-Assembly for Manufacturing</title><categories>cs.MA cs.CE</categories><comments>Java code available at http://purl.org/net/johnnyvon/</comments><report-no>NRC-48760</report-no><acm-class>I.6.3; I.6.8; J.2; J.3</acm-class><journal-ref>Artificial Life, (2006), 12, 411-433</journal-ref><abstract>  It has been argued that a central objective of nanotechnology is to make
products inexpensively, and that self-replication is an effective approach to
very low-cost manufacturing. The research presented here is intended to be a
step towards this vision. We describe a computational simulation of nanoscale
machines floating in a virtual liquid. The machines can bond together to form
strands (chains) that self-replicate and self-assemble into user-specified
meshes. There are four types of machines and the sequence of machine types in a
strand determines the shape of the mesh they will build. A strand may be in an
unfolded state, in which the bonds are straight, or in a folded state, in which
the bond angles depend on the types of machines. By choosing the sequence of
machine types in a strand, the user can specify a variety of polygonal shapes.
A simulation typically begins with an initial unfolded seed strand in a soup of
unbonded machines. The seed strand replicates by bonding with free machines in
the soup. The child strands fold into the encoded polygonal shape, and then the
polygons drift together and bond to form a mesh. We demonstrate that a variety
of polygonal meshes can be manufactured in the simulation, by simply changing
the sequence of machine types in the seed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607134</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607134</id><created>2006-07-27</created><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Leading strategies in competitive on-line prediction</title><categories>cs.LG</categories><comments>20 pages; a conference version is to appear in the ALT'2006
  proceedings</comments><abstract>  We start from a simple asymptotic result for the problem of on-line
regression with the quadratic loss function: the class of continuous
limited-memory prediction strategies admits a &quot;leading prediction strategy&quot;,
which not only asymptotically performs at least as well as any continuous
limited-memory strategy but also satisfies the property that the excess loss of
any continuous limited-memory strategy is determined by how closely it imitates
the leading strategy. More specifically, for any class of prediction strategies
constituting a reproducing kernel Hilbert space we construct a leading
strategy, in the sense that the loss of any prediction strategy whose norm is
not too large is determined by how closely it imitates the leading strategy.
This result is extended to the loss functions given by Bregman divergences and
by strictly proper scoring rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607135</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607135</id><created>2006-07-28</created><authors><author><keyname>Friedland</keyname><forenames>Shmuel</forenames></author><author><keyname>Levy</keyname><forenames>Daniel</forenames></author></authors><title>A polynomial-time approximation algorithm for the number of k-matchings
  in bipartite graphs</title><categories>cs.CC cs.DM</categories><comments>6 pages</comments><abstract>  We show that the number of $k$-matching in a given undirected graph
 $G$ is equal to the number of perfect matching of the corresponding graph
 $G_k$ on an even number of vertices divided by a suitable factor.
 If $G$ is bipartite then one can construct a bipartite $G_k$.
 For bipartite graphs this result implies that the number of $k$-matching has a
polynomial-time approximation algorithm. The above results are extended to
permanents and hafnians of corresponding matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607136</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607136</id><created>2006-07-28</created><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Competing with Markov prediction strategies</title><categories>cs.LG</categories><comments>11 pages</comments><abstract>  Assuming that the loss function is convex in the prediction, we construct a
prediction strategy universal for the class of Markov prediction strategies,
not necessarily continuous. Allowing randomization, we remove the requirement
of convexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607137</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607137</id><created>2006-07-28</created><authors><author><keyname>Petander</keyname><forenames>Henrik</forenames></author><author><keyname>Perera</keyname><forenames>Eranga</forenames></author><author><keyname>Seneviratne</keyname><forenames>Aruna</forenames></author></authors><title>Multicasting with selective delivery: A SafetyNet for vertical handoffs</title><categories>cs.NI</categories><comments>20 pages</comments><abstract>  In future mobility support will require handling roaming in heterogeneous
access networks. In order to enable seamless roaming it is necessary to
minimize the impact of the vertical handoffs. Localized mobility management
schemes such as FMIPv6 and HMIPv6 do not provide sufficient handoff
performance, since they have been designed for horizontal handoffs. In this
paper, we propose the SafetyNet protocol, which allows a Mobile Node to perform
seamless vertical handoffs. Further, we propose a handoff timing algorithm
which allows a Mobile Node to delay or even completely avoid upward vertical
handoffs. We implement the SafetyNet protocol and compare its performance with
the Fast Handovers for Mobile IPv6 protocol in our wireless test bed and
analyze the results. The experimental results indicate that the proposed
SafetyNet protocol can provide an improvement of up to 95% for TCP performance
in vertical handoffs, when compared with FMIPv6 and an improvement of 64% over
FMIPv6 with bicasting. We use numerical analysis of the protocol to show that
its signaling and data transmission overhead is comparable to Fast Mobile IPv6
and significantly smaller than that of FMIPv6 with bicasting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607138</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607138</id><created>2006-07-30</created><authors><author><keyname>Belal</keyname><forenames>Mohamed A.</forenames></author></authors><title>A Foundation to Perception Computing, Logic and Automata</title><categories>cs.AI cs.LG</categories><comments>39 pages, pdf format, to be published</comments><acm-class>I.2.0; I.2.6</acm-class><abstract>  In this report, a novel approach to intelligence and learning is introduced,
this approach is based on what we call 'perception logic'. Based on this logic,
a computing mechanism and automata are introduced. Multi-resolution analysis of
perceptual information is given, in which learning is accomplished in at most
O(log(N))epochs, where N is the number of samples, and the convergence is
guarnteed. This approach combines the favors of computational modeles in the
sense that they are structured and mathematically well-defined, and the
adaptivity of soft computing approaches, in addition to the continuity and
real-time response of dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607139</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607139</id><created>2006-07-31</created><updated>2006-12-27</updated><authors><author><keyname>Holenstein</keyname><forenames>Thomas</forenames></author></authors><title>Parallel repetition: simplifications and the no-signaling case</title><categories>cs.CC quant-ph</categories><comments>27 pages; v2:PRW97 strengthening added, references added, typos
  fixed; v3: fixed error in the proof of the no-signaling theorem, minor
  changes</comments><journal-ref>Theory of Computing 5 (2009) 1, pp. 141-172</journal-ref><doi>10.4086/toc.2009.v005a008</doi><abstract>  Consider a game where a refereed a referee chooses (x,y) according to a
publicly known distribution P_XY, sends x to Alice, and y to Bob. Without
communicating with each other, Alice responds with a value &quot;a&quot; and Bob responds
with a value &quot;b&quot;. Alice and Bob jointly win if a publicly known predicate
Q(x,y,a,b) holds.
  Let such a game be given and assume that the maximum probability that Alice
and Bob can win is v&lt;1. Raz (SIAM J. Comput. 27, 1998) shows that if the game
is repeated n times in parallel, then the probability that Alice and Bob win
all games simultaneously is at most v'^(n/log(s)), where s is the maximal
number of possible responses from Alice and Bob in the initial game, and v' is
a constant depending only on v.
  In this work, we simplify Raz's proof in various ways and thus shorten it
significantly. Further we study the case where Alice and Bob are not restricted
to local computations and can use any strategy which does not imply
communication among them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607140</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607140</id><created>2006-07-31</created><updated>2006-08-02</updated><authors><author><keyname>Pichl</keyname><forenames>Lukas</forenames></author><author><keyname>Kaizoji</keyname><forenames>Taisei</forenames></author><author><keyname>Yamano</keyname><forenames>Takuya</forenames></author></authors><title>Stylized Facts in Internal Rates of Return on Stock Index and its
  Derivative Transactions</title><categories>cs.IT cs.CE math.IT</categories><comments>APFA 5</comments><acm-class>H.1.1</acm-class><doi>10.1016/j.physa.2007.03.042</doi><abstract>  Universal features in stock markets and their derivative markets are studied
by means of probability distributions in internal rates of return on buy and
sell transaction pairs. Unlike the stylized facts in log normalized returns,
the probability distributions for such single asset encounters encorporate the
time factor by means of the internal rate of return defined as the continuous
compound interest. Resulting stylized facts are shown in the probability
distributions derived from the daily series of TOPIX, S &amp; P 500 and FTSE 100
index close values. The application of the above analysis to minute-tick data
of NIKKEI 225 and its futures market, respectively, reveals an interesting
diffference in the behavior of the two probability distributions, in case a
threshold on the minimal duration of the long position is imposed. It is
therefore suggested that the probability distributions of the internal rates of
return could be used for causality mining between the underlying and derivative
stock markets. The highly specific discrete spectrum, which results from noise
trader strategies as opposed to the smooth distributions observed for
fundamentalist strategies in single encounter transactions may be also useful
in deducing the type of investment strategy from trading revenues of small
portfolio investors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607141</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607141</id><created>2006-07-31</created><authors><author><keyname>Crary</keyname><forenames>Karl</forenames></author><author><keyname>Harper</keyname><forenames>Robert</forenames></author></authors><title>Logic Column 16: Higher-Order Abstract Syntax: Setting the Record
  Straight</title><categories>cs.LO</categories><comments>4 pages</comments><acm-class>F.4.1; F.3.1</acm-class><abstract>  This article responds to a critique of higher-order abstract syntax appearing
in Logic Column 14, ``Nominal Logic and Abstract Syntax'', cs.LO/0511025.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607142</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607142</id><created>2006-07-31</created><updated>2006-08-29</updated><authors><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Maehler</keyname><forenames>Dominique</forenames></author><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author></authors><title>Employing Trusted Computing for the forward pricing of pseudonyms in
  reputation systems</title><categories>cs.CR</categories><comments>Refereed contribution to the 4th International Workshop for
  Technical, Economic and Legal Aspects of Business Models for Virtual Goods,
  December 13 -15, 2006 on AXMEDIS 2006 in Leeds, England. 5 pages, 3 figures,
  final version</comments><abstract>  Reputation and recommendation systems are fundamental for the formation of
community market places. Yet, they are easy targets for attacks which disturb a
market's equilibrium and are often based on cheap pseudonyms used to submit
ratings. We present a method to price ratings using trusted computing, based on
pseudonymous tickets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607143</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607143</id><created>2006-07-31</created><authors><author><keyname>Dezert</keyname><forenames>Jean</forenames></author><author><keyname>Tchamova</keyname><forenames>Albena</forenames></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Konstantinova</keyname><forenames>Pavlina</forenames></author></authors><title>Target Type Tracking with PCR5 and Dempster's rules: A Comparative
  Analysis</title><categories>cs.AI</categories><comments>10 pages, 5 diagrams. Presented to Fusion 2006 International
  Conference, Florence, Italy, July 2006</comments><acm-class>I.4.8</acm-class><journal-ref>Proceedings of Fusion 2006 International Conference, Florence,
  Italy, July 2006</journal-ref><abstract>  In this paper we consider and analyze the behavior of two combinational rules
for temporal (sequential) attribute data fusion for target type estimation. Our
comparative analysis is based on Dempster's fusion rule proposed in
Dempster-Shafer Theory (DST) and on the Proportional Conflict Redistribution
rule no. 5 (PCR5) recently proposed in Dezert-Smarandache Theory (DSmT). We
show through very simple scenario and Monte-Carlo simulation, how PCR5 allows a
very efficient Target Type Tracking and reduces drastically the latency delay
for correct Target Type decision with respect to Demspter's rule. For cases
presenting some short Target Type switches, Demspter's rule is proved to be
unable to detect the switches and thus to track correctly the Target Type
changes. The approach proposed here is totally new, efficient and promising to
be incorporated in real-time Generalized Data Association - Multi Target
Tracking systems (GDA-MTT) and provides an important result on the behavior of
PCR5 with respect to Dempster's rule. The MatLab source code is provided in
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607144</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607144</id><created>2006-07-31</created><authors><author><keyname>Andonov</keyname><forenames>Stanimir</forenames></author></authors><title>Levels of Product Differentiation in the Global Mobile Phones Market</title><categories>cs.OH</categories><abstract>  The sixth product level called compliant product is a connecting element
between the physical product characteristics and the strategy of the producer
company. The article discusses the differentiation among the product offers of
companies working in the global markets, as well as the strategies which they
use and could use in that respect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607145</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607145</id><created>2006-07-31</created><updated>2006-09-26</updated><authors><author><keyname>Bakopoulos</keyname><forenames>Yannis</forenames></author><author><keyname>Raptis</keyname><forenames>Theophanis</forenames></author><author><keyname>Ioannis</keyname><forenames>Doxaras</forenames></author></authors><title>Geometric definition of a new skeletonization concept</title><categories>cs.CG</categories><comments>9 pages, 3 figures, to appear in &quot;2nd Interdisciplinary Symposium and
  2nd Summer School on Mathematical Modeling in Modern Technologies and
  Economics&quot;, 1-5 September, Athens, Greece</comments><abstract>  The Divider set, as an innovative alternative concept to maximal disks,
Voronoi sets and cut loci, is presented with a formal definition based on
topology and differential geometry. The relevant mathematical theory by
previous authors and a comparison with other medial axis definitions is
presented. Appropriate applications are proposed and examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607146</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607146</id><created>2006-07-31</created><updated>2012-03-09</updated><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Pucella</keyname><forenames>Riccardo</forenames><affiliation>Northeastern University</affiliation></author></authors><title>Modeling Adversaries in a Logic for Security Protocol Analysis</title><categories>cs.CR cs.LO</categories><comments>23 pages. A preliminary version appeared in the proceedings of
  FaSec'02</comments><proxy>LMCS</proxy><acm-class>cs.LO</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (March 9,
  2012) lmcs:688</journal-ref><doi>10.2168/LMCS-8(1:22)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logics for security protocol analysis require the formalization of an
adversary model that specifies the capabilities of adversaries. A common model
is the Dolev-Yao model, which considers only adversaries that can compose and
replay messages, and decipher them with known keys. The Dolev-Yao model is a
useful abstraction, but it suffers from some drawbacks: it cannot handle the
adversary knowing protocol-specific information, and it cannot handle
probabilistic notions, such as the adversary attempting to guess the keys. We
show how we can analyze security protocols under different adversary models by
using a logic with a notion of algorithmic knowledge. Roughly speaking,
adversaries are assumed to use algorithms to compute their knowledge; adversary
capabilities are captured by suitable restrictions on the algorithms used. We
show how we can model the standard Dolev-Yao adversary in this setting, and how
we can capture more general capabilities including protocol-specific knowledge
and guesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0607147</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0607147</id><created>2006-07-31</created><updated>2006-11-29</updated><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Dezert</keyname><forenames>Jean</forenames></author></authors><title>Fusion of qualitative beliefs using DSmT</title><categories>cs.AI</categories><comments>13 pages. To appear in &quot;Advances and Applications of DSmT for
  Information Fusion&quot;, collected works, second volume, 2006</comments><acm-class>I.4.8</acm-class><journal-ref>Presented as an extended version (Tutorial MO2) to the Fusion 2006
  International Conference, Florence, Italy, July 10-13, 2006</journal-ref><abstract>  This paper introduces the notion of qualitative belief assignment to model
beliefs of human experts expressed in natural language (with linguistic
labels). We show how qualitative beliefs can be efficiently combined using an
extension of Dezert-Smarandache Theory (DSmT) of plausible and paradoxical
quantitative reasoning to qualitative reasoning. We propose a new arithmetic on
linguistic labels which allows a direct extension of classical DSm fusion rule
or DSm Hybrid rules. An approximate qualitative PCR5 rule is also proposed
jointly with a Qualitative Average Operator. We also show how crisp or interval
mappings can be used to deal indirectly with linguistic labels. A very simple
example is provided to illustrate our qualitative fusion rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608001</id><created>2006-08-01</created><updated>2006-08-02</updated><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author><author><keyname>Ingolfsdottir</keyname><forenames>Anna</forenames></author><author><keyname>Luttik</keyname><forenames>Bas</forenames></author></authors><title>A Finite Equational Base for CCS with Left Merge and Communication Merge</title><categories>cs.LO</categories><acm-class>D.3.1; F.1.1; F.1.2; F.3.2; F.4.1</acm-class><abstract>  Using the left merge and communication merge from ACP, we present an
equational base (i.e., a ground-complete and $\omega$-complete set of valid
equations) for the fragment of CCS without recursion, restriction and
relabelling. Our equational base is finite if the set of actions is finite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608002</id><created>2006-08-01</created><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Dezert</keyname><forenames>Jean</forenames></author></authors><title>An Introduction to the DSm Theory for the Combination of Paradoxical,
  Uncertain, and Imprecise Sources of Information</title><categories>cs.AI</categories><comments>21 pages, many tables, figures. To appear in Information&amp;Security
  International Journal, 2006</comments><acm-class>I.4.8</acm-class><journal-ref>Presented at 13th International Congress of Cybernetics and
  Systems, Maribor, Slovenia, July 6-10, 2005.</journal-ref><abstract>  The management and combination of uncertain, imprecise, fuzzy and even
paradoxical or high conflicting sources of information has always been, and
still remains today, of primal importance for the development of reliable
modern information systems involving artificial reasoning. In this
introduction, we present a survey of our recent theory of plausible and
paradoxical reasoning, known as Dezert-Smarandache Theory (DSmT) in the
literature, developed for dealing with imprecise, uncertain and paradoxical
sources of information. We focus our presentation here rather on the
foundations of DSmT, and on the two important new rules of combination, than on
browsing specific applications of DSmT available in literature. Several simple
examples are given throughout the presentation to show the efficiency and the
generality of this new approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608003</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608003</id><created>2006-08-01</created><updated>2006-08-01</updated><authors><author><keyname>Rosa</keyname><forenames>Alessandro</forenames></author></authors><title>On a solution to display non-filled-in quaternionic Julia sets</title><categories>cs.GR cs.MS math.DS</categories><comments>15 pages, 28 figures</comments><abstract>  During early 1980s, the so-called `escape time' method, developed to display
the Julia sets for complex dynamical systems, was exported to quaternions in
order to draw analogous pictures in this wider numerical field. Despite of the
fine results in the complex plane, where all topological configurations of
Julia sets have been successfully displayed, the `escape time' method fails to
render properly the non-filled-in variety of quaternionic Julia sets. So their
digital visualisation remained an open problem for several years. Both the
solution for extending this old method to non-filled-in quaternionic Julia sets
and its implementation into a program are explained here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608004</id><created>2006-08-01</created><authors><author><keyname>Soler</keyname><forenames>Jose M.</forenames></author></authors><title>Separating the articles of authors with the same name</title><categories>cs.DL cs.IR</categories><comments>4 pages, 0 figures</comments><abstract>  I describe a method to separate the articles of different authors with the
same name. It is based on a distance between any two publications, defined in
terms of the probability that they would have as many coincidences if they were
drawn at random from all published documents. Articles with a given author name
are then clustered according to their distance, so that all articles in a
cluster belong very likely to the same author. The method has proven very
useful in generating groups of papers that are then selected manually. This
simplifies considerably citation analysis when the author publication lists are
not available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608005</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608005</id><created>2006-08-01</created><updated>2007-06-12</updated><authors><author><keyname>Peeters</keyname><forenames>Kasper</forenames></author></authors><title>A field-theory motivated approach to symbolic computer algebra</title><categories>cs.SC gr-qc hep-th</categories><comments>14 pages; v2: several clarifications and references added, version as
  published</comments><report-no>AEI-2006-037</report-no><journal-ref>Comput.Phys.Commun.176:550-558,2007</journal-ref><doi>10.1016/j.cpc.2007.01.003</doi><abstract>  Field theory is an area in physics with a deceptively compact notation.
Although general purpose computer algebra systems, built around generic
list-based data structures, can be used to represent and manipulate
field-theory expressions, this often leads to cumbersome input formats,
unexpected side-effects, or the need for a lot of special-purpose code. This
makes a direct translation of problems from paper to computer and back
needlessly time-consuming and error-prone. A prototype computer algebra system
is presented which features TeX-like input, graph data structures, lists with
Young-tableaux symmetries and a multiple-inheritance property system. The
usefulness of this approach is illustrated with a number of explicit
field-theory problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608006</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608006</id><created>2006-08-01</created><authors><author><keyname>Choi</keyname><forenames>Suhan</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>A Graph-based Framework for Transmission of Correlated Sources over
  Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>36 pages, 9 figures</comments><abstract>  In this paper we consider the communication problem that involves
transmission of correlated sources over broadcast channels. We consider a
graph-based framework for this information transmission problem. The system
involves a source coding module and a channel coding module. In the source
coding module, the sources are efficiently mapped into a nearly semi-regular
bipartite graph, and in the channel coding module, the edges of this graph are
reliably transmitted over a broadcast channel. We consider nearly semi-regular
bipartite graphs as discrete interface between source coding and channel coding
in this multiterminal setting. We provide an information-theoretic
characterization of (1) the rate of exponential growth (as a function of the
number of channel uses) of the size of the bipartite graphs whose edges can be
reliably transmitted over a broadcast channel and (2) the rate of exponential
growth (as a function of the number of source samples) of the size of the
bipartite graphs which can reliably represent a pair of correlated sources to
be transmitted over a broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608007</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608007</id><created>2006-08-01</created><authors><author><keyname>Holenstein</keyname><forenames>Thomas</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>On the randomness of independent experiments</title><categories>cs.IT math.IT</categories><comments>latex, 15 pages</comments><abstract>  Given a probability distribution P, what is the minimum amount of bits needed
to store a value x sampled according to P, such that x can later be recovered
(except with some small probability)? Or, what is the maximum amount of uniform
randomness that can be extracted from x? Answering these and similar
information-theoretic questions typically boils down to computing so-called
smooth entropies. In this paper, we derive explicit and almost tight bounds on
the smooth entropies of n-fold product distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608008</id><created>2006-08-02</created><authors><author><keyname>Safro</keyname><forenames>Ilya</forenames></author></authors><title>The minimum linear arrangement problem on proper interval graphs</title><categories>cs.DM cs.DS</categories><abstract>  We present a linear time algorithm for the minimum linear arrangement problem
on proper interval graphs. The obtained ordering is a 4-approximation for
general interval graphs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608009</id><created>2006-08-02</created><authors><author><keyname>Cerri</keyname><forenames>Andrea</forenames></author><author><keyname>Frosini</keyname><forenames>Patrizio</forenames></author><author><keyname>Landi</keyname><forenames>Claudia</forenames></author></authors><title>Stability in multidimensional Size Theory</title><categories>cs.CG cs.CV</categories><comments>15 pages, 1 figure, uses psfrag</comments><report-no>Universita' di Modena e Reggio Emilia, DISMI-85 june 2006</report-no><acm-class>I.3.5; I.5.1</acm-class><abstract>  This paper proves that in Size Theory the comparison of multidimensional size
functions can be reduced to the 1-dimensional case by a suitable change of
variables. Indeed, we show that a foliation in half-planes can be given, such
that the restriction of a multidimensional size function to each of these
half-planes turns out to be a classical size function in two scalar variables.
This leads to the definition of a new distance between multidimensional size
functions, and to the proof of their stability with respect to that distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608010</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608010</id><created>2006-08-02</created><updated>2006-09-29</updated><authors><author><keyname>Stepanov</keyname><forenames>Sander</forenames></author></authors><title>MIMO scheme performance and detection in epsilon noise</title><categories>cs.IT math.IT</categories><comments>30 pages</comments><abstract>  New approach for analysis and decoding MIMO signaling is developed for usual
model of nongaussion noise consists of background and impulsive noise named
epsilon - noise. It is shown that non-gaussion noise performance significantly
worse than gaussion ones. Stimulation results strengthen out theory. Robust in
statistical sense detection rule is suggested for such kind of noise features
much best robust detector performance than detector designed for Gaussian noise
in impulsive environment and modest margin in background noise. Proposed
algorithms performance are comparable with developed potential bound. Proposed
tool, is crucial issue for MIMO communication system design, since real noise
environment has impulsive character that contradict with wide used Gaussian
approach, so real MIMO performance much different for Gaussian a non-Gaussian
noise model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608011</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608011</id><created>2006-08-02</created><updated>2007-05-25</updated><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>The Many Faces of Rationalizability</title><categories>cs.GT</categories><comments>39 pages, appeared in The B.E. Journal of Theoretical Economics: Vol.
  7 : Iss. 1 (Topics), Article 18. Available at:
  http://www.bepress.com/bejte/vol7/iss1/art18</comments><abstract>  The rationalizability concept was introduced in \cite{Ber84} and
  \cite{Pea84} to assess what can be inferred by rational players in a
non-cooperative game in the presence of common knowledge. However, this notion
can be defined in a number of ways that differ in seemingly unimportant minor
details. We shed light on these differences, explain their impact, and clarify
for which games these definitions coincide. Then we apply the same analysis to
explain the differences and similarities between various ways the iterated
elimination of strictly dominated strategies was defined in the literature.
This allows us to clarify the results of \cite{DS02} and \cite{CLL05} and
improve upon them. We also consider the extension of these results to strict
dominance by a mixed strategy. Our approach is based on a general study of the
operators on complete lattices. We allow transfinite iterations of the
considered operators and clarify the need for them. The advantage of such a
general approach is that a number of results, including order independence for
some of the notions of rationalizability and strict dominance, come for free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608012</identifier>
 <datestamp>2013-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608012</id><created>2006-08-02</created><updated>2013-10-23</updated><authors><author><keyname>Catanuto</keyname><forenames>R.</forenames></author><author><keyname>Toumpis</keyname><forenames>S.</forenames></author><author><keyname>Morabito</keyname><forenames>G.</forenames></author></authors><title>Opti{c,m}al: Optical/Optimal Routing in Massively Dense Wireless
  Networks</title><categories>cs.NI</categories><journal-ref>Proc. INFOCOM 2007, Anchorage, AL, May 2007</journal-ref><doi>10.1109/INFCOM.2007.122</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study routing for massively dense wireless networks, i.e., wireless
networks that contain so many nodes that, in addition to their usual
microscopic description, a novel macroscopic description becomes possible. The
macroscopic description is not detailed, but nevertheless contains enough
information to permit a meaningful study and performance optimization of the
network. Within this context, we continue and significantly expand previous
work on the analogy between optimal routing and the propagation of light
according to the laws of Geometrical Optics. Firstly, we pose the analogy in a
more general framework than previously, notably showing how the eikonal
equation, which is the central equation of Geometrical Optics, also appears in
the networking context. Secondly, we develop a methodology for calculating the
cost function, which is the function describing the network at the macroscopic
level. We apply this methodology for two important types of networks: bandwidth
limited and energy limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608013</id><created>2006-08-02</created><authors><author><keyname>Robert</keyname><forenames>Julien</forenames></author><author><keyname>Schabanel</keyname><forenames>Nicolas</forenames></author></authors><title>Pull-Based Data Broadcast with Dependencies: Be Fair to Users, not to
  Items</title><categories>cs.DS cs.CC</categories><abstract>  Broadcasting is known to be an efficient means of disseminating data in
wireless communication environments (such as Satellite, mobile phone
networks,...). It has been recently observed that the average service time of
broadcast systems can be considerably improved by taking into consideration
existing correlations between requests. We study a pull-based data broadcast
system where users request possibly overlapping sets of items; a request is
served when all its requested items are downloaded. We aim at minimizing the
average user perceived latency, i.e. the average flow time of the requests. We
first show that any algorithm that ignores the dependencies can yield arbitrary
bad performances with respect to the optimum even if it is given arbitrary
extra resources. We then design a $(4+\epsilon)$-speed
$O(1+1/\epsilon^2)$-competitive algorithm for this setting that consists in 1)
splitting evenly the bandwidth among each requested set and in 2) broadcasting
arbitrarily the items still missing in each set into the bandwidth the set has
received. Our algorithm presents several interesting features: it is simple to
implement, non-clairvoyant, fair to users so that no user may starve for a long
period of time, and guarantees good performances in presence of correlations
between user requests (without any change in the broadcast protocol). We also
present a $ (4+\epsilon)$-speed $O(1+1/\epsilon^3)$-competitive algorithm which
broadcasts at most one item at any given time and preempts each item broadcast
at most once on average. As a side result of our analysis, we design a
competitive algorithm for a particular setting of non-clairvoyant job
scheduling with dependencies, which might be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608014</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608014</id><created>2006-08-02</created><authors><author><keyname>Baryshnikov</keyname><forenames>Yuliy</forenames></author><author><keyname>Tan</keyname><forenames>Jian</forenames></author></authors><title>Localization for Anchoritic Sensor Networks</title><categories>cs.NI cs.CG</categories><abstract>  We introduce a class of anchoritic sensor networks, where communications
between sensor nodes is undesirable or infeasible, e.g., due to harsh
environment, energy constraints, or security considerations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608015</id><created>2006-08-02</created><authors><author><keyname>Brand</keyname><forenames>Sebastian</forenames></author><author><keyname>Yap</keyname><forenames>Roland H. C.</forenames></author></authors><title>Towards &quot;Propagation = Logic + Control&quot;</title><categories>cs.PL cs.AI</categories><comments>15 pages; 22nd International Conference on Logic Programming
  (ICLP'06)</comments><abstract>  Constraint propagation algorithms implement logical inference. For
efficiency, it is essential to control whether and in what order basic
inference steps are taken. We provide a high-level framework that clearly
differentiates between information needed for controlling propagation versus
that needed for the logical semantics of complex constraints composed from
primitive ones. We argue for the appropriateness of our controlled propagation
framework by showing that it captures the underlying principles of manually
designed propagation algorithms, such as literal watching for unit clause
propagation and the lexicographic ordering constraint. We provide an
implementation and benchmark results that demonstrate the practicality and
efficiency of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608016</id><created>2006-08-02</created><authors><author><keyname>Duck</keyname><forenames>Gregory J.</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author><author><keyname>Brand</keyname><forenames>Sebastian</forenames></author></authors><title>ACD Term Rewriting</title><categories>cs.PL cs.SC</categories><comments>21 pages; 22nd International Conference on Logic Programming
  (ICLP'06)</comments><abstract>  We introduce Associative Commutative Distributive Term Rewriting (ACDTR), a
rewriting language for rewriting logical formulae. ACDTR extends AC term
rewriting by adding distribution of conjunction over other operators.
Conjunction is vital for expressive term rewriting systems since it allows us
to require that multiple conditions hold for a term rewriting rule to be used.
ACDTR uses the notion of a &quot;conjunctive context&quot;, which is the conjunction of
constraints that must hold in the context of a term, to enable the programmer
to write very expressive and targeted rewriting rules. ACDTR can be seen as a
general logic programming language that extends Constraint Handling Rules and
AC term rewriting. In this paper we define the semantics of ACDTR and describe
our prototype implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608017</id><created>2006-08-02</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Brand</keyname><forenames>Sebastian</forenames></author></authors><title>Infinite Qualitative Simulations by Means of Constraint Programming</title><categories>cs.AI cs.LO</categories><comments>15 pages; 12th International Conference on Principles and Practice of
  Constraint Programming (CP'06)</comments><abstract>  We introduce a constraint-based framework for studying infinite qualitative
simulations concerned with contingencies such as time, space, shape, size,
abstracted into a finite set of qualitative relations. To define the
simulations, we combine constraints that formalize the background knowledge
concerned with qualitative reasoning with appropriate inter-state constraints
that are formulated using linear temporal logic. We implemented this approach
in a constraint programming system by drawing on ideas from bounded model
checking. The resulting system allows us to test and modify the problem
specifications in a straightforward way and to combine various knowledge
aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608018</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608018</id><created>2006-08-02</created><authors><author><keyname>Renner</keyname><forenames>Renato</forenames></author><author><keyname>Wolf</keyname><forenames>Stefan</forenames></author><author><keyname>Wullschleger</keyname><forenames>Juerg</forenames></author></authors><title>The single-serving channel capacity</title><categories>cs.IT math.IT</categories><comments>4 pages, latex</comments><journal-ref>Proceedings of the 2006 IEEE International Symposium on
  Information Theory (ISIT)</journal-ref><abstract>  In this paper we provide the answer to the following question: Given a noisy
channel and epsilon&gt;0, how many bits can be transmitted with an error of at
most epsilon by a single use of the channel?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608019</id><created>2006-08-02</created><authors><author><keyname>Brand</keyname><forenames>Sebastian</forenames></author></authors><title>Relation Variables in Qualitative Spatial Reasoning</title><categories>cs.AI</categories><comments>14 pages; 27th German Conference on Artificial Intelligence (KI'04)</comments><abstract>  We study an alternative to the prevailing approach to modelling qualitative
spatial reasoning (QSR) problems as constraint satisfaction problems. In the
standard approach, a relation between objects is a constraint whereas in the
alternative approach it is a variable. The relation-variable approach greatly
simplifies integration and implementation of QSR. To substantiate this point,
we discuss several QSR algorithms from the literature which in the
relation-variable approach reduce to the customary constraint propagation
algorithm enforcing generalised arc-consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608020</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608020</id><created>2006-08-03</created><authors><author><keyname>Marion</keyname><forenames>Jean-Yves</forenames></author><author><keyname>Pechoux</keyname><forenames>Romain</forenames></author></authors><title>Quasi-friendly sup-interpretations</title><categories>cs.CC</categories><abstract>  In a previous paper, the sup-interpretation method was proposed as a new tool
to control memory resources of first order functional programs with pattern
matching by static analysis. Basically, a sup-interpretation provides an upper
bound on the size of function outputs. In this former work, a criterion, which
can be applied to terminating as well as non-terminating programs, was
developed in order to bound polynomially the stack frame size. In this paper,
we suggest a new criterion which captures more algorithms computing values
polynomially bounded in the size of the inputs. Since this work is related to
quasi-interpretations, we compare the two notions obtaining two main features.
The first one is that, given a program, we have heuristics for finding a
sup-interpretation when we consider polynomials of bounded degree. The other
one consists in the characterizations of the set of function computable in
polynomial time and in polynomial space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608021</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608021</id><created>2006-08-03</created><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Lubetzky</keyname><forenames>Eyal</forenames></author></authors><title>The Shannon capacity of a graph and the independence numbers of its
  powers</title><categories>cs.IT cs.DM math.IT</categories><journal-ref>IEEE Trans. on Information Theory 52 (2006), 2172-2176</journal-ref><abstract>  The independence numbers of powers of graphs have been long studied, under
several definitions of graph products, and in particular, under the strong
graph product. We show that the series of independence numbers in strong powers
of a fixed graph can exhibit a complex structure, implying that the Shannon
Capacity of a graph cannot be approximated (up to a sub-polynomial factor of
the number of vertices) by any arbitrarily large, yet fixed, prefix of the
series. This is true even if this prefix shows a significant increase of the
independence number at a given power, after which it stabilizes for a while.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608022</id><created>2006-08-03</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Petride</keyname><forenames>Sabina</forenames></author></authors><title>Expressing Security Properties Using Selective Interleaving Functions</title><categories>cs.CR</categories><acm-class>D.4.6</acm-class><abstract>  McLean's notion of Selective Interleaving Functions (SIFs) is perhaps the
best-known attempt to construct a framework for expressing various security
properties. We examine the expressive power of SIFs carefully. We show that
SIFs cannot capture nondeducibility on strategies (NOS). We also prove that the
set of security properties expressed with SIFs is not closed under conjunction,
from which it follows that separability is strictly stronger than double
generalized noninterference. However, we show that if we generalize the notion
of SIF in a natural way, then NOS is expressible, and the set of security
properties expressible by generalized SIFs is closed under conjunction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608023</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608023</id><created>2006-08-04</created><authors><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author><author><keyname>Michel</keyname><forenames>Thomas</forenames></author></authors><title>Optimal resource allocation for OFDM multiuser channels</title><categories>cs.IT math.IT</categories><abstract>  In this paper, a unifying framework for orthogonal frequency division
multiplexing (OFDM) multiuser resource allocation is presented. The isolated
seeming problems of maximizing a weighted sum of rates for a given power budget
$\bar{P}$ and minimizing sum power for given rate requirements
$\mathbf{\bar{R}}$ can be interpreted jointly in this framework. To this end we
embed the problems in a higher dimensional space. Based on these results, we
subsequently consider the combined problem of maximizing a weighted sum of
rates under given rate requirements $\mathbf{\bar{R}}$ and a fixed power budget
$\bar{P}$. This new problem is challenging, since the additional constraints do
not allow to use the hitherto existing approaches. Interestingly, the optimal
decoding orders turn out to be the ordering of the Lagrangian factors in all
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608024</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608024</id><created>2006-08-04</created><authors><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Lo</keyname><forenames>Kwok-Tung</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author></authors><title>Cryptanalysis of an Encryption Scheme Based on Blind Source Separation</title><categories>cs.CR cs.MM</categories><comments>8 pages, 10 figures, IEEE format</comments><journal-ref>IEEE Transactions on Circuits and Systems-I: Regular Papers, vol.
  55, no. 4, pp. 1055-1063, April 2008</journal-ref><doi>10.1109/TCSI.2008.916540</doi><abstract>  Recently Lin et al. proposed a method of using the underdetermined BSS (blind
source separation) problem to realize image and speech encryption. In this
paper, we give a cryptanalysis of this BSS-based encryption and point out that
it is not secure against known/chosen-plaintext attack and chosen-ciphertext
attack. In addition, there exist some other security defects: low sensitivity
to part of the key and the plaintext, a ciphertext-only differential attack,
divide-and-conquer (DAC) attack on part of the key. We also discuss the role of
BSS in Lin et al.'s efforts towards cryptographically secure ciphers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608025</id><created>2006-08-04</created><authors><author><keyname>Kumar</keyname><forenames>Dinesh</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Altman</keyname><forenames>Eitan</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Kelif</keyname><forenames>Jean-Marc</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>User-Network Association in a WLAN-UMTS Hybrid Cell: Global &amp; Individual
  Optimality</title><categories>cs.NI</categories><proxy>ccsd inria-00088728</proxy><abstract>  We study optimal user-network association in an integrated 802.11 WLAN and
3G-UMTS hybrid cell. Assuming saturated resource allocation on the downlink of
WLAN and UMTS networks and a single QoS class of mobiles arriving at an average
location in the hybrid cell, we formulate the problem with two different
approaches: Global and Individual optimality. The Globally optimal association
is formulated as an SMDP (Semi Markov Decision Process) connection routing
decision problem where rewards comprise a financial gain component and an
aggregate network throughput component. The corresponding Dynamic Programming
equations are solved using Value Iteration method and a stationary optimal
policy with neither convex nor concave type switching curve structure is
obtained. Threshold type and symmetric switching curves are observed for the
analogous homogenous network cases. The Individual optimality is studied under
a non-cooperative dynamic game framework with expected service time of a mobile
as the decision cost criteria. It is shown that individual optimality in a
WLAN-UMTS hybrid cell, results in a threshold policy curve of descending
staircase form with increasing Poisson arrival rate of mobiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608026</id><created>2006-08-04</created><authors><author><keyname>Kumar</keyname><forenames>Dinesh</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Barman</keyname><forenames>Dhiman</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Altman</keyname><forenames>Eitan</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Kelif</keyname><forenames>Jean-Marc</forenames><affiliation>FT R&amp;D</affiliation></author></authors><title>New Cross-Layer Channel Switching Policy for TCP Transmission on 3G UMTS
  Downlink</title><categories>cs.NI</categories><proxy>ccsd inria-00088730</proxy><abstract>  In 3G UMTS, two main transport channels have been provided for downlink data
transmission: a common FACH channel and a dedicated DCH channel. The
performance of TCP in UMTS depends much on the channel switching policy used.
In this paper, we propose and analyze three new basic threshold-based channel
switching policies for UMTS that we name as QS (Queue Size), FS (Flow Size) and
QSFS (QS &amp; FS combined) policy. These policies significantly improve over a
modified threshold policy in [1] by about 17% in response time metrics. We
further propose and evaluate a new improved switching policy that we call
FS-DCH (at-least flow-size threshold on DCH) policy. This policy is biased
towards short TCP flows of few packets and is thus a cross-layer policy that
improves the performance of TCP by giving priority to the initial few packets
of a flow on the fast DCH channel. Extensive simulation results confirm this
improvement for the case when number of TCP connections is low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608027</id><created>2006-08-04</created><authors><author><keyname>Henneken</keyname><forenames>E.</forenames></author><author><keyname>Kurtz</keyname><forenames>M. J.</forenames></author><author><keyname>Eichhorn</keyname><forenames>G.</forenames></author><author><keyname>Accomazzi</keyname><forenames>A.</forenames></author><author><keyname>Grant</keyname><forenames>C. S.</forenames></author><author><keyname>Thompson</keyname><forenames>D.</forenames></author><author><keyname>Bohlen</keyname><forenames>E.</forenames></author><author><keyname>Murray</keyname><forenames>S. S.</forenames></author></authors><title>myADS-arXiv - a Tailor-Made, Open Access, Virtual Journal</title><categories>cs.DL astro-ph</categories><comments>4 pages, 2 figures, poster paper to appear in the proceedings of the
  LISA V conference</comments><abstract>  The myADS-arXiv service provides the scientific community with a one stop
shop for staying up-to-date with a researcher's field of interest. The service
provides a powerful and unique filter on the enormous amount of bibliographic
information added to the ADS on a daily basis. It also provides a complete view
with the most relevant papers available in the subscriber's field of interest.
With this service, the subscriber will get to know the lastest developments,
popular trends and the most important papers. This makes the service not only
unique from a technical point of view, but also from a content point of view.
On this poster we will argue why myADS-arXiv is a tailor-made, open access,
virtual journal and we will illustrate its unique character.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608028</id><created>2006-08-04</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Using Sets of Probability Measures to Represent Uncertainty</title><categories>cs.AI</categories><acm-class>I.2.4</acm-class><abstract>  I explore the use of sets of probability measures as a representation of
uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608029</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608029</id><created>2006-08-04</created><updated>2006-08-11</updated><authors><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Guessing Facets: Polytope Structure and Improved LP Decoder</title><categories>cs.IT math.IT</categories><comments>Appeared in International Symposium on Information Theory, Seattle,
  WA. July 2006. Revision: fixed author names in abstract (to be recognized as
  two separate authors)</comments><abstract>  A new approach for decoding binary linear codes by solving a linear program
(LP) over a relaxed codeword polytope was recently proposed by Feldman et al.
In this paper we investigate the structure of the polytope used in the LP
relaxation decoding. We begin by showing that for expander codes, every
fractional pseudocodeword always has at least a constant fraction of
non-integral bits. We then prove that for expander codes, the active set of any
fractional pseudocodeword is smaller by a constant fraction than the active set
of any codeword. We exploit this fact to devise a decoding algorithm that
provably outperforms the LP decoder for finite blocklengths. It proceeds by
guessing facets of the polytope, and resolving the linear program on these
facets. While the LP decoder succeeds only if the ML codeword has the highest
likelihood over all pseudocodewords, we prove that for expander codes the
proposed algorithm succeeds even with a constant number of pseudocodewords of
higher likelihood. Moreover, the complexity of the proposed algorithm is only a
constant factor larger than that of the LP decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608030</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608030</id><created>2006-08-06</created><authors><author><keyname>Baillot</keyname><forenames>Patrick</forenames></author><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Moyen</keyname><forenames>Jean-Yves</forenames></author></authors><title>On Quasi-Interpretations, Blind Abstractions and Implicit Complexity</title><categories>cs.PL cs.CC cs.LO</categories><comments>18 pages</comments><abstract>  Quasi-interpretations are a technique to guarantee complexity bounds on
first-order functional programs: with termination orderings they give in
particular a sufficient condition for a program to be executable in polynomial
time, called here the P-criterion. We study properties of the programs
satisfying the P-criterion, in order to better understand its intensional
expressive power. Given a program on binary lists, its blind abstraction is the
nondeterministic program obtained by replacing lists by their lengths (natural
numbers). A program is blindly polynomial if its blind abstraction terminates
in polynomial time. We show that all programs satisfying a variant of the
P-criterion are in fact blindly polynomial. Then we give two extensions of the
P-criterion: one by relaxing the termination ordering condition, and the other
one (the bounded value property) giving a necessary and sufficient condition
for a program to be polynomial time executable, with memoisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608031</id><created>2006-08-07</created><authors><author><keyname>Fujii</keyname><forenames>Mikio</forenames></author></authors><title>Secure Positioning of Mobile Terminals with Simplex Radio Communication</title><categories>cs.CR</categories><comments>8 pages, 4 figures</comments><abstract>  With the rapid spread of various mobile terminals in our society, the
importance of secure positioning is growing for wireless networks in
adversarial settings. Recently, several authors have proposed a secure
positioning mechanism of mobile terminals which is based on the geometric
property of wireless node placement, and on the postulate of modern physics
that a propagation speed of information never exceeds the velocity of light. In
particular, they utilize the measurements of the round-trip time of radio
signal propagation and bidirectional communication for variants of the
challenge-and-response. In this paper, we propose a novel means to construct
the above mechanism by use of unidirectional communication instead of
bidirectional communication. Our proposal is based on the assumption that a
mobile terminal incorporates a high-precision inner clock in a tamper-resistant
protected area. In positioning, the mobile terminal uses its inner clock and
the time and location information broadcasted by radio from trusted stations.
Our proposal has a major advantage in protecting the location privacy of mobile
terminal users, because the mobile terminal need not provide any information to
the trusted stations through positioning procedures. Besides, our proposal is
free from the positioning error due to claimant's processing-time fluctuations
in the challenge-and-response, and is well-suited for mobile terminals in the
open air, or on the move at high speed, in terms of practical usage. We analyze
the security, the functionality, and the feasibility of our proposal in
comparison to previous proposals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608032</id><created>2006-08-06</created><updated>2007-04-03</updated><authors><author><keyname>Zankl</keyname><forenames>Harald</forenames></author><author><keyname>Middeldorp</keyname><forenames>Aart</forenames></author></authors><title>Satisfying KBO Constraints</title><categories>cs.SC cs.LO</categories><comments>15 pages</comments><abstract>  This paper presents two new approaches to prove termination of rewrite
systems with the Knuth-Bendix order efficiently. The constraints for the weight
function and for the precedence are encoded in (pseudo-)propositional logic and
the resulting formula is tested for satisfiability. Any satisfying assignment
represents a weight function and a precedence such that the induced
Knuth-Bendix order orients the rules of the encoded rewrite system from left to
right.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608033</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608033</id><created>2006-08-06</created><authors><author><keyname>Bonato</keyname><forenames>Roberto</forenames><affiliation>INRIA Futurs, LaBRI</affiliation></author></authors><title>A Study on Learnability for Rigid Lambek Grammars</title><categories>cs.LG</categories><proxy>ccsd inria-00088818</proxy><abstract>  We present basic notions of Gold's &quot;learnability in the limit&quot; paradigm,
first presented in 1967, a formalization of the cognitive process by which a
native speaker gets to grasp the underlying grammar of his/her own native
language by being exposed to well formed sentences generated by that grammar.
Then we present Lambek grammars, a formalism issued from categorial grammars
which, although not as expressive as needed for a full formalization of natural
languages, is particularly suited to easily implement a natural interface
between syntax and semantics. In the last part of this work, we present a
learnability result for Rigid Lambek grammars from structured examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608034</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608034</id><created>2006-08-06</created><authors><author><keyname>Sharma</keyname><forenames>Aashish</forenames></author><author><keyname>Yurcik</keyname><forenames>William</forenames></author></authors><title>Security Assessment of E-Tax Filing Websites</title><categories>cs.CR</categories><comments>9 pages</comments><abstract>  Technical security is only part of E-Commerce security operations; human
usability and security perception play major and sometimes dominating factors.
For instance, slick websites with impressive security icons but no real
technical security are often perceived by users to be trustworthy (and thus
more profitable) than plain vanilla websites that use powerful encryption for
transmission and server protection. We study one important type of E-Commerce
transaction website, E-Tax Filing, that is exposed to large populations. We
assess a large number of international (5), Federal (USA), and state E-Tax
filing websites (38) for both technical security protection and human
perception of security. As a result of this assessment, we identify security
best practices across these E-Tax Filing websites and recommend additional
security techniques that have not been found in current use by E-Tax Filing
websites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608035</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608035</id><created>2006-08-07</created><updated>2006-09-13</updated><authors><author><keyname>Kobayashi</keyname><forenames>Naoki</forenames></author><author><keyname>Suenaga</keyname><forenames>Kohei</forenames></author><author><keyname>Wischik</keyname><forenames>Lucian</forenames></author></authors><title>Resource Usage Analysis for the Pi-Calculus</title><categories>cs.PL cs.LO</categories><acm-class>F.3.1; D.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 3 (September
  13, 2006) lmcs:769</journal-ref><doi>10.2168/LMCS-2(3:4)2006</doi><abstract>  We propose a type-based resource usage analysis for the &amp;#960;-calculus
extended with resource creation/access primitives. The goal of the resource
usage analysis is to statically check that a program accesses resources such as
files and memory in a valid manner. Our type system is an extension of previous
behavioral type systems for the &amp;#960;-calculus, and can guarantee the safety
property that no invalid access is performed, as well as the property that
necessary accesses (such as the close operation for a file) are eventually
performed unless the program diverges. A sound type inference algorithm for the
type system is also developed to free the programmer from the burden of writing
complex type annotations. Based on the algorithm, we have implemented a
prototype resource usage analyzer for the &amp;#960;-calculus. To the authors'
knowledge, ours is the first type-based resource usage analysis that deals with
an expressive concurrent language like the pi-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608036</id><created>2006-08-07</created><authors><author><keyname>Hernich</keyname><forenames>Andre</forenames></author><author><keyname>Schweikardt</keyname><forenames>Nicole</forenames></author></authors><title>Reversal Complexity Revisited</title><categories>cs.CC</categories><comments>19 pages, 2 figures</comments><acm-class>F.1.1; F.1.3</acm-class><abstract>  We study a generalized version of reversal bounded Turing machines where,
apart from several tapes on which the number of head reversals is bounded by
r(n), there are several further tapes on which head reversals remain
unrestricted, but size is bounded by s(n). Recently, such machines were
introduced as a formalization of a computation model that restricts random
access to external memory and internal memory space. Here, each of the tapes
with a restriction on the head reversals corresponds to an external memory
device, and the tapes of restricted size model internal memory. We use
ST(r(n),s(n),O(1)) to denote the class of all problems that can be solved by
deterministic Turing machines that comply to the above resource bounds.
Similarly, NST and RST, respectively, are used for the corresponding
nondeterministic and randomized classes.
  While previous papers focused on lower bounds for particular problems,
including sorting, the set equality problem, and several query evaluation
problems, the present paper addresses the relations between the (R,N)ST-classes
and classical complexity classes and investigates the structural complexity of
the (R,N)ST-classes. Our main results are (1) a trade-off between internal
memory space and external memory head reversals, (2) correspondences between
the (R,N)ST-classes and ``classical'' time-bounded, space-bounded,
reversal-bounded, and circuit complexity classes, and (3) hierarchies of
(R)ST-classes in terms of increasing numbers of head reversals on external
memory tapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608037</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608037</id><created>2006-08-07</created><updated>2015-06-25</updated><authors><author><keyname>Li</keyname><forenames>Shaohua</forenames></author></authors><title>Cascade hash tables: a series of multilevel double hashing schemes with
  O(1) worst case lookup time</title><categories>cs.DS cs.AI</categories><comments>this manuscript is poorly written and contains little technical
  novelty</comments><abstract>  In this paper, the author proposes a series of multilevel double hashing
schemes called cascade hash tables. They use several levels of hash tables. In
each table, we use the common double hashing scheme. Higher level hash tables
work as fail-safes of lower level hash tables. By this strategy, it could
effectively reduce collisions in hash insertion. Thus it gains a constant worst
case lookup time with a relatively high load factor(70%-85%) in random
experiments. Different parameters of cascade hash tables are tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608038</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608038</id><created>2006-08-07</created><authors><author><keyname>Wehler</keyname><forenames>Joachim</forenames></author></authors><title>Morphisms of Coloured Petri Nets</title><categories>cs.SE</categories><acm-class>D.2.2</acm-class><abstract>  We introduce the concept of a morphism between coloured nets. Our definition
generalizes Petris definition for ordinary nets. A morphism of coloured nets
maps the topological space of the underlying undirected net as well as the
kernel and cokernel of the incidence map. The kernel are flows along the
transition-bordered fibres of the morphism, the cokernel are classes of
markings of the place-bordered fibres. The attachment of bindings, colours,
flows and marking classes to a subnet is formalized by using concepts from
sheaf theory. A coloured net is a sheaf-cosheaf pair over a Petri space and a
morphism between coloured nets is a morphism between such pairs. Coloured nets
and their morphisms form a category. We prove the existence of a product in the
subcategory of sort-respecting morphisms. After introducing markings our
concepts generalize to coloured Petri nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608039</id><created>2006-08-07</created><authors><author><keyname>Danner</keyname><forenames>Norman</forenames></author><author><keyname>Pollett</keyname><forenames>Chris</forenames></author></authors><title>The weak pigeonhole principle for function classes in S^1_2</title><categories>cs.LO</categories><comments>11 pages</comments><acm-class>F.4.1</acm-class><journal-ref>Mathematical Logic Quarterly 52(6):575-584, 2006</journal-ref><doi>10.1002/malq.200610015</doi><abstract>  It is well known that S^1_2 cannot prove the injective weak pigeonhole
principle for polynomial time functions unless RSA is insecure. In this note we
investigate the provability of the surjective (dual) weak pigeonhole principle
in S^1_2 for provably weaker function classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608040</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608040</id><created>2006-08-08</created><authors><author><keyname>Baillot</keyname><forenames>Patrick</forenames><affiliation>LIPN</affiliation></author><author><keyname>Pedicini</keyname><forenames>Marco</forenames></author></authors><title>An Embedding of the BSS Model of Computation in Light Affine
  Lambda-Calculus</title><categories>cs.LO</categories><comments>11 pages. A preliminary version appeared as Research Report IAC CNR
  Roma, N.57 (11/2004), november 2004</comments><proxy>ccsd ccsd-00085547</proxy><journal-ref>8th International Workshop on Logic and Computational Complexity
  Seattle, August 10 - 11, 2006 (Satellite Workshop of FLOC-LICS 2006),
  \'{E}tats-Unis d'Am\'{e}rique (2006)</journal-ref><abstract>  This paper brings together two lines of research: implicit characterization
of complexity classes by Linear Logic (LL) on the one hand, and computation
over an arbitrary ring in the Blum-Shub-Smale (BSS) model on the other. Given a
fixed ring structure K we define an extension of Terui's light affine
lambda-calculus typed in LAL (Light Affine Logic) with a basic type for K. We
show that this calculus captures the polynomial time function class FP(K):
every typed term can be evaluated in polynomial time and conversely every
polynomial time BSS machine over K can be simulated in this calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608041</id><created>2006-08-08</created><authors><author><keyname>Sobrado</keyname><forenames>Igor</forenames></author><author><keyname>Uhring</keyname><forenames>Dave</forenames></author></authors><title>The Dynamics of A Self-Forming Network</title><categories>cs.NI</categories><comments>5 pages; 8 figures; 2 tables</comments><acm-class>C.2.1; C.2.3; C.2.6; C.4</acm-class><abstract>  This article describes our strategy for deploying self-forming ad hoc
networks based on the Internet Protocol version 6 and evaluates the dynamics of
this proposal. Among others, we suggest a technique called adaptive routing
that provides secure intelligent routing capabilities to computer communication
networks. This technique uses the flow label, supports hybrid metrics, network
load sharing, and is not restricted to evaluation of performance on first hop
routers when making routing decisions. Selective anycasting is an extension to
the anycast addressing model that supports exclusion of members of groups that
perform poorly or inappropriately on a per-host basis. Distributed name lookup
is suggested for integrating self-forming and global networks where they
coexist. At last, we pose an address hierarchy to support unmanaged discovery
of services in unknown networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608042</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608042</id><created>2006-08-08</created><updated>2007-03-17</updated><authors><author><keyname>Wiechman</keyname><forenames>Gil</forenames></author><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>An Improved Sphere-Packing Bound for Finite-Length Codes on Symmetric
  Memoryless Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory (40 pages,
  10 figures)</comments><abstract>  This paper derives an improved sphere-packing (ISP) bound for finite-length
codes whose transmission takes place over symmetric memoryless channels. We
first review classical results, i.e., the 1959 sphere-packing (SP59) bound of
Shannon for the Gaussian channel, and the 1967 sphere-packing (SP67) bound of
Shannon et al. for discrete memoryless channels. A recent improvement on the
SP67 bound, as suggested by Valembois and Fossorier, is also discussed. These
concepts are used for the derivation of a new lower bound on the decoding error
probability (referred to as the ISP bound) which is uniformly tighter than the
SP67 bound and its recent improved version. The ISP bound is applicable to
symmetric memoryless channels, and some of its applications are exemplified.
Its tightness is studied by comparing it with bounds on the ML decoding error
probability, and computer simulations of iteratively decoded turbo-like codes.
The paper also presents a technique which performs the entire calculation of
the SP59 bound in the logarithmic domain, thus facilitating the exact
calculation of this bound for moderate to large block lengths without the need
for the asymptotic approximations provided by Shannon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608043</id><created>2006-08-08</created><authors><author><keyname>Afolabi</keyname><forenames>Babajide</forenames><affiliation>LORIA</affiliation></author><author><keyname>Thiery</keyname><forenames>Odile</forenames><affiliation>LORIA</affiliation></author></authors><title>Using Users' Expectations to Adapt Business Intelligence Systems</title><categories>cs.IR</categories><proxy>ccsd inria-00088985</proxy><journal-ref>Advances in Knowledge Organization 10 (2006) 247-254</journal-ref><abstract>  This paper takes a look at the general characteristics of business or
economic intelligence system. The role of the user within this type of system
is emphasized. We propose two models which we consider important in order to
adapt this system to the user. The first model is based on the definition of
decisional problem and the second on the four cognitive phases of human
learning. We also describe the application domain we are using to test these
models in this type of system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608044</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608044</id><created>2006-08-08</created><authors><author><keyname>Sundararajan</keyname><forenames>Jay Kumar</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author></authors><title>Network Coding in a Multicast Switch</title><categories>cs.NI cs.IT math.IT</categories><comments>9 pages, submitted to IEEE INFOCOM 2007</comments><abstract>  We consider the problem of serving multicast flows in a crossbar switch. We
show that linear network coding across packets of a flow can sustain traffic
patterns that cannot be served if network coding were not allowed. Thus,
network coding leads to a larger rate region in a multicast crossbar switch. We
demonstrate a traffic pattern which requires a switch speedup if coding is not
allowed, whereas, with coding the speedup requirement is eliminated completely.
In addition to throughput benefits, coding simplifies the characterization of
the rate region. We give a graph-theoretic characterization of the rate region
with fanout splitting and intra-flow coding, in terms of the stable set
polytope of the 'enhanced conflict graph' of the traffic pattern. Such a
formulation is not known in the case of fanout splitting without coding. We
show that computing the offline schedule (i.e. using prior knowledge of the
flow arrival rates) can be reduced to certain graph coloring problems. Finally,
we propose online algorithms (i.e. using only the current queue occupancy
information) for multicast scheduling based on our graph-theoretic formulation.
In particular, we show that a maximum weighted stable set algorithm stabilizes
the queues for all rates within the rate region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608045</id><created>2006-08-08</created><updated>2006-08-08</updated><authors><author><keyname>Kouretis</keyname><forenames>Giannis</forenames></author><author><keyname>Georgatos</keyname><forenames>Fotis</forenames></author></authors><title>LiveWN, cpu scavenging in the Grid Era</title><categories>cs.DC cs.NI</categories><comments>4 pages</comments><abstract>  The goal of this research is to introduce an easy and versatile way to
provide and use Grid resources without the need of any OS installation or
middleware configuration. At the same time we provide an excellent training
tool for newer Grid users and people that want to experiment, without enforcing
any installation. We have been testing it thoroughly under different
circumstances with firm success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608046</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608046</id><created>2006-08-08</created><authors><author><keyname>Ali</keyname><forenames>Arshad</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Anjum</keyname><forenames>Ashiq</forenames></author><author><keyname>Habib</keyname><forenames>Irfan</forenames></author><author><keyname>Soomro</keyname><forenames>Kamran</forenames></author><author><keyname>Asif</keyname><forenames>Mohammed</forenames></author><author><keyname>Adil</keyname><forenames>Ali</forenames></author><author><keyname>Mohsin</keyname><forenames>Athar</forenames></author></authors><title>From Grid Middleware to a Grid Operating System</title><categories>cs.DC</categories><comments>8 pages, 5 figures. Presented at the 7th IEEE/ACM International
  Conference on Grid and Cooperative Computing. Changsha, China. October 2006</comments><acm-class>H.2.4; J.3</acm-class><abstract>  Grid computing has made substantial advances during the last decade. Grid
middleware such as Globus has contributed greatly in making this possible.
There are, however, significant barriers to the adoption of Grid computing in
other fields, most notably day-to-day user computing environments. We will
demonstrate in this paper that this is primarily due to the limitations of the
existing Grid middleware which does not take into account the needs of everyday
scientific and business users. In this paper we will formally advocate a Grid
Operating System and propose an architecture to migrate Grid computing into a
Grid operating system which we believe would help remove most of the technical
barriers to the adoption of Grid computing and make it relevant to the
day-to-day user. We believe this proposed transition to a Grid operating system
will drive more pervasive Grid computing research and application development
and deployment in future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608047</id><created>2006-08-08</created><authors><author><keyname>McClatchey</keyname><forenames>R. H.</forenames></author><author><keyname>Manset</keyname><forenames>D.</forenames></author><author><keyname>Solomonides</keyname><forenames>A. E.</forenames></author></authors><title>Lessons Learned from MammoGrid for Integrated Biomedical Solutions</title><categories>cs.DC</categories><comments>10 pages, 1 figure. Presented at the 19th IEEE Symposium on
  Computer-Based Medical Systems (CBMS 2006). Salt Lake City, USA. June 2006</comments><acm-class>H.2.4; J.3</acm-class><abstract>  This paper presents an overview of the MammoGrid project and some of its
achievements. In terms of the global grid project, and European research in
particular, the project has successfully demonstrated the capacity of a
grid-based system to support effective collaboration between physicians,
including handling and querying image databases, as well as using grid
services, such as image standardization and Computer-Aided Detection (CADe) of
suspect or indicative features. In terms of scientific results, in radiology,
there have been significant epidemiological findings in the assessment of
breast density as a risk factor, but the results for CADe are less clear-cut.
Finally, the foundations of a technology transfer process to establish a
working MammoGrid plus system in Spain through the company Maat GKnowledge and
the collaboration of CIEMAT and hospitals in Extremadura.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608048</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608048</id><created>2006-08-08</created><authors><author><keyname>Anjum</keyname><forenames>Ashiq</forenames></author><author><keyname>McClatchey</keyname><forenames>Richard</forenames></author><author><keyname>Ali</keyname><forenames>Arshad</forenames></author><author><keyname>Willers</keyname><forenames>Ian</forenames></author></authors><title>Bulk Scheduling with the DIANA Scheduler</title><categories>cs.DC</categories><comments>12 pages, 11 figures. To be published in the IEEE Transactions in
  Nuclear Science, IEEE Press. 2006</comments><acm-class>H.2.4; J.3</acm-class><doi>10.1109/TNS.2006.886047</doi><abstract>  Results from the research and development of a Data Intensive and Network
Aware (DIANA) scheduling engine, to be used primarily for data intensive
sciences such as physics analysis, are described. In Grid analyses, tasks can
involve thousands of computing, data handling, and network resources. The
central problem in the scheduling of these resources is the coordinated
management of computation and data at multiple locations and not just data
replication or movement. However, this can prove to be a rather costly
operation and efficient sing can be a challenge if compute and data resources
are mapped without considering network costs. We have implemented an adaptive
algorithm within the so-called DIANA Scheduler which takes into account data
location and size, network performance and computation capability in order to
enable efficient global scheduling. DIANA is a performance-aware and
economy-guided Meta Scheduler. It iteratively allocates each job to the site
that is most likely to produce the best performance as well as optimizing the
global queue for any remaining jobs. Therefore it is equally suitable whether a
single job is being submitted or bulk scheduling is being performed. Results
indicate that considerable performance improvements can be gained by adopting
the DIANA scheduling approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608049</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608049</id><created>2006-08-08</created><updated>2009-06-10</updated><authors><author><keyname>Fernandez</keyname><forenames>Alberto</forenames></author><author><keyname>Gomez</keyname><forenames>Sergio</forenames></author></authors><title>Solving non-uniqueness in agglomerative hierarchical clustering using
  multidendrograms</title><categories>cs.IR math.ST physics.data-an stat.TH</categories><comments>Free Software for Agglomerative Hierarchical Clustering using
  Multidendrograms available at
  http://deim.urv.cat/~sgomez/multidendrograms.php</comments><acm-class>H.3.3; I.5.3</acm-class><journal-ref>Journal of Classification 25 (2008) 43-65</journal-ref><doi>10.1007/s00357-008-9004-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In agglomerative hierarchical clustering, pair-group methods suffer from a
problem of non-uniqueness when two or more distances between different clusters
coincide during the amalgamation process. The traditional approach for solving
this drawback has been to take any arbitrary criterion in order to break ties
between distances, which results in different hierarchical classifications
depending on the criterion followed. In this article we propose a
variable-group algorithm that consists in grouping more than two clusters at
the same time when ties occur. We give a tree representation for the results of
the algorithm, which we call a multidendrogram, as well as a generalization of
the Lance and Williams' formula which enables the implementation of the
algorithm in a recursive way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608050</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608050</id><created>2006-08-09</created><authors><author><keyname>Pons</keyname><forenames>Pascal</forenames></author></authors><title>Post-Processing Hierarchical Community Structures: Quality Improvements
  and Multi-scale View</title><categories>cs.DS cond-mat.dis-nn physics.soc-ph</categories><comments>12 Pages, 4 figures</comments><abstract>  Dense sub-graphs of sparse graphs (communities), which appear in most
real-world complex networks, play an important role in many contexts. Most
existing community detection algorithms produce a hierarchical structure of
community and seek a partition into communities that optimizes a given quality
function. We propose new methods to improve the results of any of these
algorithms. First we show how to optimize a general class of additive quality
functions (containing the modularity, the performance, and a new similarity
based quality function we propose) over a larger set of partitions than the
classical methods. Moreover, we define new multi-scale quality functions which
make it possible to detect the different scales at which meaningful community
structures appear, while classical approaches find only one partition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608051</id><created>2006-08-11</created><updated>2007-05-07</updated><authors><author><keyname>Hirschowitz</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Maggesi</keyname><forenames>Marco</forenames></author></authors><title>Modules over Monads and Linearity</title><categories>cs.LO cs.PL</categories><comments>15 pages, too many changes to be summarized</comments><abstract>  Inspired by the classical theory of modules over a monoid, we give a first
account of the natural notion of module over a monad. The associated notion of
morphism of left modules (&quot;Linear&quot; natural transformations) captures an
important property of compatibility with substitution, in the heterogeneous
case where &quot;terms&quot; and variables therein could be of different types as well as
in the homogeneous case. In this paper, we present basic constructions of
modules and we show examples concerning in particular abstract syntax and
lambda-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608052</identifier>
 <datestamp>2013-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608052</id><created>2006-08-11</created><updated>2013-03-26</updated><authors><author><keyname>Schl&#xf6;gl</keyname><forenames>Alois</forenames></author></authors><title>GDF - A general dataformat for biosignals</title><categories>cs.DL</categories><comments>GDF v2.51 add support for SCP sections 7-11</comments><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biomedical signals are stored in many different data formats. Most formats
have been developed for a specific purpose of a specialized community for ECG
research, EEG analysis, sleep research, etc. So far none of the existing
formats can be considered a general purpose data format for biomedical signals.
In order to solve this problem and to unify the various needs of the various
biomedical signal processing fields, the so-called &quot;General Data Format for
biomedical signals&quot; (GDF) is developed. This GDF format is fully described and
specified. Software for reading and writing GDF data is implemented in
Octave/Matlab and C/C++ and provided through BioSig - an free and open source
software library for biomedical signal processing. BioSig privides also
converters from various data formats to GDF, and a viewing and scoring
software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608053</id><created>2006-08-11</created><updated>2006-10-01</updated><authors><author><keyname>Coppersmith</keyname><forenames>S. N.</forenames></author></authors><title>Renormalization group approach to the P versus NP question</title><categories>cs.CC cond-mat.stat-mech</categories><comments>Original version had a conjecture that is known to be false. Revised
  version corrects this error</comments><acm-class>F.1.3</acm-class><abstract>  This paper argues that the ideas underlying the renormalization group
technique used to characterize phase transitions in condensed matter systems
could be useful for distinguishing computational complexity classes. The paper
presents a renormalization group transformation that maps an arbitrary Boolean
function of $N$ Boolean variables to one of $N-1$ variables. When this
transformation is applied repeatedly, the behavior of the resulting sequence of
functions is different for a generic Boolean function than for Boolean
functions that can be written as a polynomial of degree $\xi$ with $\xi \ll N$
as well as for functions that depend on composite variables such as the
arithmetic sum of the inputs. Being able to demonstrate that functions are
non-generic is of interest because it suggests an avenue for constructing an
algorithm capable of demonstrating that a given Boolean function cannot be
computed using resources that are bounded by a polynomial of $N$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608054</identifier>
 <datestamp>2008-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608054</id><created>2006-08-12</created><updated>2008-06-17</updated><authors><author><keyname>Rademacher</keyname><forenames>Luis</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>Dispersion of Mass and the Complexity of Randomized Geometric Algorithms</title><categories>cs.CC cs.CG cs.DS math.FA</categories><comments>Full version of L. Rademacher, S. Vempala: Dispersion of Mass and the
  Complexity of Randomized Geometric Algorithms. Proc. 47th IEEE Annual Symp.
  on Found. of Comp. Sci. (2006). A version of it to appear in Advances in
  Mathematics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How much can randomness help computation? Motivated by this general question
and by volume computation, one of the few instances where randomness provably
helps, we analyze a notion of dispersion and connect it to asymptotic convex
geometry. We obtain a nearly quadratic lower bound on the complexity of
randomized volume algorithms for convex bodies in R^n (the current best
algorithm has complexity roughly n^4, conjectured to be n^3). Our main tools,
dispersion of random determinants and dispersion of the length of a random
point from a convex body, are of independent interest and applicable more
generally; in particular, the latter is closely related to the variance
hypothesis from convex geometry. This geometric dispersion also leads to lower
bounds for matrix problems and property testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608055</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608055</id><created>2006-08-13</created><updated>2006-09-02</updated><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author></authors><title>MDS Ideal Secret Sharing Scheme from AG-codes on Elliptic Curves</title><categories>cs.CR</categories><abstract>  For a secret sharing scheme, two parameters $d_{min}$ and $d_{cheat}$ are
defined in [12] and [13]. These two parameters measure the error-correcting
capability and the secret-recovering capability of the secret sharing scheme
against cheaters. Some general properties of the parameters have been studied
in [12,[9] and [13]. The MDS secret-sharing scheme was defined in [12] and it
is proved that MDS perfect secret sharing scheme can be constructed for any
monotone access structure. The famous Shamir $(k,n)$ threshold secret sharing
scheme is the MDS with $d_{min}=d_{cheat}=n-k+1$. In [3] we proposed the linear
secret sharing scheme from algebraic-geometric codes. In this paper the linear
secret sharing scheme from AG-codes on elliptic curves is studied and it is
shown that many of them are MDS linear secret sharing scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608056</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608056</id><created>2006-08-14</created><updated>2006-08-25</updated><authors><author><keyname>Dai</keyname><forenames>Bin</forenames></author><author><keyname>Luo</keyname><forenames>Yuan</forenames></author></authors><title>Wiretap Channel With Side Information</title><categories>cs.IT math.IT</categories><abstract>  This submission has been withdrawn by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608057</identifier>
 <datestamp>2008-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608057</id><created>2006-08-14</created><updated>2008-09-26</updated><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Hybrid Elections Broaden Complexity-Theoretic Resistance to Control</title><categories>cs.GT cs.CC cs.MA</categories><report-no>URCS TR-2006-900</report-no><acm-class>I.2.11; F.2.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electoral control refers to attempts by an election's organizer (&quot;the chair&quot;)
to influence the outcome by adding/deleting/partitioning voters or candidates.
The groundbreaking work of Bartholdi, Tovey, and Trick [BTT92] on
(constructive) control proposes computational complexity as a means of
resisting control attempts: Look for election systems where the chair's task in
seeking control is itself computationally infeasible.
  We introduce and study a method of combining two or more candidate-anonymous
election schemes in such a way that the combined scheme possesses all the
resistances to control (i.e., all the NP-hardnesses of control) possessed by
any of its constituents: It combines their strengths. From this and new
resistance constructions, we prove for the first time that there exists an
election scheme that is resistant to all twenty standard types of electoral
control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608058</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608058</id><created>2006-08-14</created><updated>2010-04-09</updated><authors><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author><author><keyname>Fomenkov</keyname><forenames>Marina</forenames></author><author><keyname>Koga</keyname><forenames>Ryan</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>claffy</keyname><forenames>kc</forenames></author></authors><title>Evolution of the Internet AS-Level Ecosystem</title><categories>cs.NI cs.GT physics.soc-ph</categories><journal-ref>Eur. Phys. J. B 74, 271-278 (2010)</journal-ref><doi>10.1140/epjb/e2010-00057-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analytically tractable model of Internet evolution at the level
of Autonomous Systems (ASs). We call our model the multiclass preferential
attachment (MPA) model. As its name suggests, it is based on preferential
attachment. All of its parameters are measurable from available Internet
topology data. Given the estimated values of these parameters, our analytic
results predict a definitive set of statistics characterizing the AS topology
structure. These statistics are not part of the model formulation. The MPA
model thus closes the &quot;measure-model-validate-predict&quot; loop, and provides
further evidence that preferential attachment is a driving force behind
Internet evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608059</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608059</id><created>2006-08-14</created><updated>2008-05-14</updated><authors><author><keyname>Hirschkoff</keyname><forenames>Daniel</forenames></author><author><keyname>Pous</keyname><forenames>Damien</forenames></author></authors><title>A Distribution Law for CCS and a New Congruence Result for the
  pi-calculus</title><categories>cs.LO</categories><comments>20 pages</comments><proxy>ccsd ccsd-00089219</proxy><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 2 (May 14,
  2008) lmcs:823</journal-ref><doi>10.2168/LMCS-4(2:4)2008</doi><abstract>  We give an axiomatisation of strong bisimilarity on a small fragment of CCS
that does not feature the sum operator. This axiomatisation is then used to
derive congruence of strong bisimilarity in the finite pi-calculus in absence
of sum. To our knowledge, this is the only nontrivial subcalculus of the
pi-calculus that includes the full output prefix and for which strong
bisimilarity is a congruence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608060</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608060</id><created>2006-08-14</created><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Gomadam</keyname><forenames>Krishna S.</forenames></author></authors><title>Duality and Capacity Region of AF Relay MAC and BC</title><categories>cs.IT math.IT</categories><comments>33 pages</comments><abstract>  We consider multi-hop multiple access (MAC) and broadcast channels (BC) where
communication takes place with the assistance of relays that amplify and
forward (AF) their received signals. For a two hop parallel AF relay MAC,
assuming a sum power constraint across all relays we characterize optimal relay
amplification factors and the resulting capacity regions. We find that the
parallel AF relay MAC with total transmit power of the two users $P_1+P_2=P$
and total relay power $P_R$ is the dual of the parallel AF relay BC where the
MAC source nodes become the BC destination nodes, the MAC destination node
becomes the BC source node, the dual BC source transmit power is $P_R$ and the
total transmit power of the AF relays is $P$. The duality means that the
capacity region of the AF relay MAC with a sum power constraint $P$ on the
transmitters is the same as that of the dual BC. The duality relationship is
found to be useful in characterizing the capacity region of the AF relay BC as
the union of MAC capacity regions. The duality extends to distributed relays
with multiple antennas and more than 2 hops as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608061</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608061</id><created>2006-08-14</created><updated>2010-09-24</updated><authors><author><keyname>Wang</keyname><forenames>Chengpu</forenames></author></authors><title>Concurrent Processing Memory</title><categories>cs.DC cs.AR cs.PF</categories><comments>35 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A theoretical memory with limited processing power and internal connectivity
at each element is proposed. This memory carries out parallel processing within
itself to solve generic array problems. The applicability of this in-memory
finest-grain massive SIMD approach is studied in some details. For an array of
N items, it reduces the total instruction cycle count of universal operations
such as insertion/deletion and match finding to ~ 1, local operations such as
filtering and template matching to ~ local operation size, and global
operations such as sum, finding global limit and sorting to ~\sqroot{N}
instruction cycles. It eliminates most streaming activities for data processing
purpose on the system bus. Yet it remains general-purposed, easy to use, pin
compatible with conventional memory, and practical for implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608062</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608062</id><created>2006-08-15</created><updated>2006-09-27</updated><authors><author><keyname>Feferman</keyname><forenames>Solomon</forenames></author></authors><title>Tarski's influence on computer science</title><categories>cs.GL cs.LO</categories><acm-class>F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 3 (September
  27, 2006) lmcs:1077</journal-ref><doi>10.2168/LMCS-2(3:6)2006</doi><abstract>  The influence of Alfred Tarski on computer science was indirect but
significant in a number of directions and was in certain respects fundamental.
Here surveyed is the work of Tarski on the decision procedure for algebra and
geometry, the method of elimination of quantifiers, the semantics of formal
languages, modeltheoretic preservation theorems, and algebraic logic; various
connections of each with computer science are taken up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608063</id><created>2006-08-15</created><authors><author><keyname>Pion</keyname><forenames>Sylvain</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Fabri</keyname><forenames>Andreas</forenames></author></authors><title>A Generic Lazy Evaluation Scheme for Exact Geometric Computations</title><categories>cs.CG cs.PF</categories><proxy>ccsd inria-00089229</proxy><abstract>  We present a generic C++ design to perform efficient and exact geometric
computations using lazy evaluations. Exact geometric computations are critical
for the robustness of geometric algorithms. Their efficiency is also critical
for most applications, hence the need for delaying the exact computations at
run time until they are actually needed. Our approach is generic and extensible
in the sense that it is possible to make it a library which users can extend to
their own geometric objects or primitives. It involves techniques such as
generic functor adaptors, dynamic polymorphism, reference counting for the
management of directed acyclic graphs and exception handling for detecting
cases where exact computations are needed. It also relies on multiple precision
arithmetic as well as interval arithmetic. We apply our approach to the whole
geometric kernel of CGAL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608064</identifier>
 <datestamp>2007-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608064</id><created>2006-08-15</created><updated>2007-08-02</updated><authors><author><keyname>D'Alfonso</keyname><forenames>Lisi</forenames></author><author><keyname>Jeronimo</keyname><forenames>Gabriela</forenames></author><author><keyname>Solerno</keyname><forenames>Pablo</forenames></author></authors><title>A linear algebra approach to the differentiation index of generic DAE
  systems</title><categories>cs.SC math.AC</categories><abstract>  The notion of differentiation index for DAE systems of arbitrary order with
generic second members is discussed by means of the study of the behavior of
the ranks of certain Jacobian associated sub-matrices. As a by-product, we
obtain upper bounds for the regularity of the Hilbert-Kolchin function and the
order of the ideal associated to the DAE systems under consideration, not
depending on characteristic sets. Some quantitative and algorithmic results
concerning differential transcendence bases and induced equivalent explicit ODE
systems are also established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608065</id><created>2006-08-16</created><updated>2006-08-17</updated><authors><author><keyname>Balkov&#xe1;</keyname><forenames>Lubom&#xed;ra</forenames></author><author><keyname>Pelantov&#xe1;</keyname><forenames>Edita</forenames></author><author><keyname>Turek</keyname><forenames>Ond&#x159;ej</forenames></author></authors><title>Combinatorial and Arithmetical Properties of Infinite Words Associated
  with Non-simple Quadratic Parry Numbers</title><categories>cs.DM</categories><comments>15 pages</comments><acm-class>D.3.1</acm-class><abstract>  We study arithmetical and combinatorial properties of $\beta$-integers for
$\beta$ being the root of the equation $x^2=mx-n, m,n \in \mathbb N, m \geq
n+2\geq 3$. We determine with the accuracy of $\pm 1$ the maximal number of
$\beta$-fractional positions, which may arise as a result of addition of two
$\beta$-integers. For the infinite word $u_\beta$ coding distances between
consecutive $\beta$-integers, we determine precisely also the balance. The word
$u_\beta$ is the fixed point of the morphism $A \to A^{m-1}B$ and $B\to
A^{m-n-1}B$. In the case $n=1$ the corresponding infinite word $u_\beta$ is
sturmian and therefore 1-balanced. On the simplest non-sturmian example with
$n\geq 2$, we illustrate how closely the balance and arithmetical properties of
$\beta$-integers are related.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608066</id><created>2006-08-16</created><authors><author><keyname>Zelke</keyname><forenames>Mariano</forenames></author></authors><title>k-Connectivity in the Semi-Streaming Model</title><categories>cs.DM cs.DS</categories><comments>13 pages, submitted to Theoretical Computer Science</comments><acm-class>G.2.2; F.2.2</acm-class><abstract>  We present the first semi-streaming algorithms to determine k-connectivity of
an undirected graph with k being any constant. The semi-streaming model for
graph algorithms was introduced by Muthukrishnan in 2003 and turns out to be
useful when dealing with massive graphs streamed in from an external storage
device.
  Our two semi-streaming algorithms each compute a sparse subgraph of an input
graph G and can use this subgraph in a postprocessing step to decide
k-connectivity of G. To this end the first algorithm reads the input stream
only once and uses time O(k^2*n) to process each input edge. The second
algorithm reads the input k+1 times and needs time O(k+alpha(n)) per input
edge. Using its constructed subgraph the second algorithm can also generate all
l-separators of the input graph for all l&lt;k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608067</id><created>2006-08-16</created><authors><author><keyname>Matsui</keyname><forenames>Tetsushi</forenames></author></authors><title>On Polynomial Time Computable Numbers</title><categories>cs.CC</categories><comments>19 pages</comments><abstract>  It will be shown that the polynomial time computable numbers form a field,
and especially an algebraically closed field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608068</identifier>
 <datestamp>2008-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608068</id><created>2006-08-16</created><authors><author><keyname>Liu</keyname><forenames>Ke</forenames></author><author><keyname>Abu-Ghazaleh</keyname><forenames>Nael</forenames></author></authors><title>The Aligned-Coordinated Geographical Routing for Multihop Wireless
  Networks</title><categories>cs.NI cs.DC</categories><journal-ref>ijsnet 2008</journal-ref><abstract>  The stateless, low overhead and distributed nature of the Geographic routing
protocols attract a lot of research attentions recently. Since the geographic
routing would face void problems, leading to complementary routing such as
perimeter routing which degrades the performance of geographic routing, most
research works are focus on optimizing this complementary part of geographic
routing to improve it. The greedy forwarding part of geographic routing
provides an optimal routing performance in terms of path stretch. If the
geographic routing could adapt the greedy forwarding more, its performance
would be enhanced much more than to optimize the complementary routing such as
perimeter routings. Our work is the first time to do so. The aligned physical
coordinate is used to do the greedy forwarding routing decision which would
lead more greedy forwarding. We evaluate our design to most geographic routing
protocols, showing it helps much and maintain the stateless nature of
geographic routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608069</identifier>
 <datestamp>2008-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608069</id><created>2006-08-16</created><authors><author><keyname>Liu</keyname><forenames>Ke</forenames></author><author><keyname>Abu-Ghazaleh</keyname><forenames>Nael</forenames></author><author><keyname>Kang</keyname><forenames>Kyoung-Don</forenames></author></authors><title>JiTS: Just-in-Time Scheduling for Real-Time Sensor Data Dissemination</title><categories>cs.NI cs.DC cs.PF</categories><journal-ref>PerCom 2006</journal-ref><abstract>  We consider the problem of real-time data dissemination in wireless sensor
networks, in which data are associated with deadlines and it is desired for
data to reach the sink(s) by their deadlines. To this end, existing real-time
data dissemination work have developed packet scheduling schemes that
prioritize packets according to their deadlines. In this paper, we first
demonstrate that not only the scheduling discipline but also the routing
protocol has a significant impact on the success of real-time sensor data
dissemination. We show that the shortest path routing using the minimum number
of hops leads to considerably better performance than Geographical Forwarding,
which has often been used in existing real-time data dissemination work. We
also observe that packet prioritization by itself is not enough for real-time
data dissemination, since many high priority packets may simultaneously contend
for network resources, deteriorating the network performance. Instead,
real-time packets could be judiciously delayed to avoid severe contention as
long as their deadlines can be met. Based on this observation, we propose a
Just-in-Time Scheduling (JiTS) algorithm for scheduling data transmissions to
alleviate the shortcomings of the existing solutions. We explore several
policies for non-uniformly delaying data at different intermediate nodes to
account for the higher expected contention as the packet gets closer to the
sink(s). By an extensive simulation study, we demonstrate that JiTS can
significantly improve the deadline miss ratio and packet drop ratio compared to
existing approaches in various situations. Notably, JiTS improves the
performance requiring neither lower layer support nor synchronization among the
sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608070</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608070</id><created>2006-08-17</created><authors><author><keyname>Permuter</keyname><forenames>Haim</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Finite State Channels with Time-Invariant Deterministic Feedback</title><categories>cs.IT math.IT</categories><abstract>  We consider capacity of discrete-time channels with feedback for the general
case where the feedback is a time-invariant deterministic function of the
output samples. Under the assumption that the channel states take values in a
finite alphabet, we find an achievable rate and an upper bound on the capacity.
We further show that when the channel is indecomposable, and has no intersymbol
interference (ISI), its capacity is given by the limit of the maximum of the
(normalized) directed information between the input $X^N$ and the output $Y^N$,
i.e. $C = \lim_{N \to \infty} \frac{1}{N} \max I(X^N \to Y^N)$, where the
maximization is taken over the causal conditioning probability
$Q(x^N||z^{N-1})$ defined in this paper. The capacity result is used to show
that the source-channel separation theorem holds for time-invariant determinist
feedback. We also show that if the state of the channel is known both at the
encoder and the decoder then feedback does not increase capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608071</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608071</id><created>2006-08-17</created><authors><author><keyname>Steiner</keyname><forenames>Avi</forenames><affiliation>Shitz</affiliation></author><author><keyname>Sanderovich</keyname><forenames>Amichai</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Broadcast Cooperation Strategies for Two Colocated Users</title><categories>cs.IT math.IT</categories><abstract>  This work considers the problem of communication from a single transmitter,
over a network with colocated users, through an independent block Rayleigh
fading channel. The colocation nature of the users allows cooperation, which
increases the overall achievable rate, from the transmitter to the destined
user. The transmitter is ignorant of the fading coefficients, while receivers
have access to perfect channel state information (CSI). This gives rise to the
multi-layer broadcast approach used by the transmitter. The broadcast approach
allows, in our network setting, to improve the cooperation between the
colocated users. That is due to the nature of broadcasting, where the better
the channel quality, the more layers that can be decoded. The cooperation
between the users is performed over an additive white Gaussian channels (AWGN),
with a relaying power constraint, and unlimited bandwidth. Three commonly used
cooperation techniques are studied: amplify-forward (AF), compress-forward
(CF), and decode-forward (DF). These methods are extended using the broadcast
approach, for the case of relaxed decoding delay constraint. For this case a
separated processing of the layers, which includes multi-session cooperation is
shown to be beneficial. Further, closed form expressions for infinitely many AF
sessions and recursive expressions for the more complex CF are given. Numerical
results for the various cooperation strategies demonstrate the efficiency of
multi-session cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608072</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608072</id><created>2006-08-17</created><authors><author><keyname>Luo</keyname><forenames>Dandan</forenames></author><author><keyname>Zhu</keyname><forenames>Yunmin</forenames></author></authors><title>Applications of Random Parameter Matrices Kalman Filtering in Uncertain
  Observation and Multi-Model Systems</title><categories>cs.IT math.IT</categories><comments>4 figures</comments><abstract>  This paper considers the Linear Minimum Variance recursive state estimation
for the linear discrete time dynamic system with random state transition and
measurement matrices, i.e., random parameter matrices Kalman filtering. It is
shown that such system can be converted to a linear dynamic system with
deterministic parameter matrices but state-dependent process and measurement
noises. It is proved that under mild conditions, the recursive state estimation
of this system is still of the form of a modified Kalman filtering. More
importantly, this result can be applied to Kalman filtering with intermittent
and partial observations as well as randomly variant dynamic systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608073</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608073</id><created>2006-08-18</created><authors><author><keyname>Litinskii</keyname><forenames>Leonid B.</forenames></author></authors><title>Parametrical Neural Networks and Some Other Similar Architectures</title><categories>cs.CV cs.NE</categories><comments>15 pages, 2 figures, accepted for publication in &quot;Optical Memory &amp;
  Neural Networks&quot; (2006)</comments><abstract>  A review of works on associative neural networks accomplished during last
four years in the Institute of Optical Neural Technologies RAS is given. The
presentation is based on description of parametrical neural networks (PNN). For
today PNN have record recognizing characteristics (storage capacity, noise
immunity and speed of operation). Presentation of basic ideas and principles is
accentuated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608074</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608074</id><created>2006-08-18</created><updated>2007-12-14</updated><authors><author><keyname>Koebler</keyname><forenames>Johannes</forenames></author><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>From Invariants to Canonization in Parallel</title><categories>cs.CC</categories><comments>14 pages. A minor correction in the proof of Theorem 4.1 made</comments><abstract>  A function $f$ of a graph is called a complete graph invariant if the
isomorphism of graphs $G$ and $H$ is equivalent to the equality $f(G)=f(H)$.
If, in addition, $f(G)$ is a graph isomorphic to $G$, then $f$ is called a
canonical form for graphs. Gurevich proves that graphs have a polynomial-time
computable canonical form exactly when they have a polynomial-time computable
complete invariant. We extend this equivalence to the polylogarithmic-time
model of parallel computation for classes of graphs with bounded rigidity index
and for classes of graphs with small separators. In particular, our results
apply to three representative classes of graphs embeddable into a fixed
surface, namely, to 5-connected graphs, to 3-connected graphs admitting a
polyhedral embedding, and 3-connected graphs admitting a large-edge-width
embedding. Another application covers graphs with bounded treewidth. Since in
the latter case an NC complete-invariant algorithm is known, we conclude that
graphs of bounded treewidth have a canonical form (and even a canonical
labeling) computable in NC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608075</id><created>2006-08-18</created><authors><author><keyname>Amor</keyname><forenames>Nader Ben</forenames><affiliation>LESTER, CES</affiliation></author><author><keyname>Moullec</keyname><forenames>Yannick Le</forenames><affiliation>LESTER</affiliation></author><author><keyname>Diguet</keyname><forenames>Jean-Philippe</forenames><affiliation>LESTER</affiliation></author><author><keyname>Philippe</keyname><forenames>Jean Luc</forenames><affiliation>LESTER</affiliation></author><author><keyname>Abid</keyname><forenames>Mohamed</forenames><affiliation>CES</affiliation></author></authors><title>Design of multimedia processor based on metric computation</title><categories>cs.AR</categories><proxy>ccsd ccsd-00089402</proxy><journal-ref>Advances in Engineering Software (Elsevier) Vol.36 No.7 (2005)
  448-458</journal-ref><doi>10.1016/j.advengsoft.2005.01.010</doi><abstract>  Media-processing applications, such as signal processing, 2D and 3D graphics
rendering, and image compression, are the dominant workloads in many embedded
systems today. The real-time constraints of those media applications have
taxing demands on today's processor performances with low cost, low power and
reduced design delay. To satisfy those challenges, a fast and efficient
strategy consists in upgrading a low cost general purpose processor core. This
approach is based on the personalization of a general RISC processor core
according the target multimedia application requirements. Thus, if the extra
cost is justified, the general purpose processor GPP core can be enforced with
instruction level coprocessors, coarse grain dedicated hardware, ad hoc
memories or new GPP cores. In this way the final design solution is tailored to
the application requirements. The proposed approach is based on three main
steps: the first one is the analysis of the targeted application using
efficient metrics. The second step is the selection of the appropriate
architecture template according to the first step results and recommendations.
The third step is the architecture generation. This approach is experimented
using various image and video algorithms showing its feasibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608076</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608076</id><created>2006-08-18</created><updated>2007-04-12</updated><authors><author><keyname>Wullschleger</keyname><forenames>J&#xfc;rg</forenames></author></authors><title>Oblivious-Transfer Amplification</title><categories>cs.CR</categories><comments>PhD thesis, March 2007, ETH Zurich, 125 pages. Full version of the
  EUROCRYPT 2007 paper. Errors in the computational part corrected</comments><abstract>  Oblivious transfer is a primitive of paramount importance in cryptography or,
more precisely, two- and multi-party computation due to its universality.
Unfortunately, oblivious transfer cannot be achieved in an unconditionally
secure way for both parties from scratch. Therefore, it is a natural question
what information-theoretic primitives or computational assumptions oblivious
transfer can be based on.
  The results in our thesis are threefold. First, we present a protocol that
implements oblivious transfer from a weakened oblivious transfer called
universal oblivious transfer, where one of the two players may get additional
information. Our reduction is about twice as efficient as previous results.
  Weak oblivious transfer is an even weaker form of oblivious transfer, where
both players may obtain additional information about the other player's input,
and where the output can contain errors. We give a new, weaker definition of
weak oblivious transfer, as well as new reductions with a more detailed
analysis.
  Finally, we carry over our results to the computational setting and show how
a weak oblivious transfer that is sometimes incorrect and only mildly secure
against computationally bounded adversaries can be strengthened.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608077</id><created>2006-08-18</created><authors><author><keyname>Kolar</keyname><forenames>Vinay</forenames></author><author><keyname>Abu-Ghazaleh</keyname><forenames>Nael</forenames></author></authors><title>The Effect of Scheduling on Link Capacity in Multi-hopWireless Networks</title><categories>cs.NI cs.AR cs.PF</categories><comments>11 pages</comments><acm-class>C.2.1</acm-class><abstract>  Existing models of Multi-Hop Wireless Networks (MHWNs) assume that
interference estimators of link quality such as observed busy time predict the
capacity of the links. We show that these estimators do not capture the
intricate interactions that occur at the scheduling level, which have a large
impact on effective link capacity under contention based MAC protocols. We
observe that scheduling problems arise only among those interfering sources
whose concurrent transmissions cannot be prevented by the MAC protocol's
collision management mechanisms; other interfering sources can arbitrate the
medium and coexist successfully. Based on this observation, we propose a
methodology for rating links and show that it achieves high correlation with
observed behavior in simulation. We then use this rating as part of a
branch-and-bound framework based on a linear programming formulation for
traffic engineering in static MHWNs and show that it achieves considerable
improvement in performance relative to interference based models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608078</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608078</id><created>2006-08-18</created><authors><author><keyname>Slepoy</keyname><forenames>A.</forenames></author><author><keyname>Thompson</keyname><forenames>A. P.</forenames></author><author><keyname>Peters</keyname><forenames>M. D.</forenames></author></authors><title>Searching for Globally Optimal Functional Forms for Inter-Atomic
  Potentials Using Parallel Tempering and Genetic Programming</title><categories>cs.NE cs.AI</categories><abstract>  We develop a Genetic Programming-based methodology that enables discovery of
novel functional forms for classical inter-atomic force-fields, used in
molecular dynamics simulations. Unlike previous efforts in the field, that fit
only the parameters to the fixed functional forms, we instead use a novel
algorithm to search the space of many possible functional forms. While a
follow-on practical procedure will use experimental and {\it ab inito} data to
find an optimal functional form for a forcefield, we first validate the
approach using a manufactured solution. This validation has the advantage of a
well-defined metric of success. We manufactured a training set of atomic
coordinate data with an associated set of global energies using the well-known
Lennard-Jones inter-atomic potential. We performed an automatic functional form
fitting procedure starting with a population of random functions, using a
genetic programming functional formulation, and a parallel tempering
Metropolis-based optimization algorithm. Our massively-parallel method
independently discovered the Lennard-Jones function after searching for several
hours on 100 processors and covering a miniscule portion of the configuration
space. We find that the method is suitable for unsupervised discovery of
functional forms for inter-atomic potentials/force-fields. We also find that
our parallel tempering Metropolis-based approach significantly improves the
optimization convergence time, and takes good advantage of the parallel cluster
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608079</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608079</id><created>2006-08-18</created><authors><author><keyname>Gilbert</keyname><forenames>A. C.</forenames></author><author><keyname>Strauss</keyname><forenames>M. J.</forenames></author><author><keyname>Tropp</keyname><forenames>J. A.</forenames></author><author><keyname>Vershynin</keyname><forenames>R.</forenames></author></authors><title>Algorithmic linear dimension reduction in the l_1 norm for sparse
  vectors</title><categories>cs.DS</categories><abstract>  This paper develops a new method for recovering m-sparse signals that is
simultaneously uniform and quick. We present a reconstruction algorithm whose
run time, O(m log^2(m) log^2(d)), is sublinear in the length d of the signal.
The reconstruction error is within a logarithmic factor (in m) of the optimal
m-term approximation error in l_1. In particular, the algorithm recovers
m-sparse signals perfectly and noisy signals are recovered with polylogarithmic
distortion. Our algorithm makes O(m log^2 (d)) measurements, which is within a
logarithmic factor of optimal. We also present a small-space implementation of
the algorithm. These sketching techniques and the corresponding reconstruction
algorithms provide an algorithmic dimension reduction in the l_1 norm. In
particular, vectors of support m in dimension d can be linearly embedded into
O(m log^2 d) dimensions with polylogarithmic distortion. We can reconstruct a
vector from its low-dimensional sketch in time O(m log^2(m) log^2(d)).
Furthermore, this reconstruction is stable and robust under small
perturbations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608080</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608080</id><created>2006-08-18</created><updated>2006-09-02</updated><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author><author><keyname>Li</keyname><forenames>Jianhua</forenames></author></authors><title>Lower Bounds on the Algebraic Immunity of Boolean Functions</title><categories>cs.CR</categories><abstract>  From the motivation of algebraic attacks to stream and block
ciphers([1,2,7,13,14,15]), the concept of {\em algebraic immunity} (AI) was
introduced in [21] and studied in [3,5,10,11,17,18,19,20,21]. High algebraic
immunity is a necessary condition for resisting algebraic attacks. In this
paper, we give some lower bounds on algebraic immunity of Boolean functions.
The results are applied to give lower bounds on AI of symmetric Boolean
functions and rotation symmetric Boolean functions. Some balanced rotation
symmetric Boolean functions with their AI near the maximum possible value
$\lceil \frac{n}{2}\rceil$ are constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608081</identifier>
 <datestamp>2008-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608081</id><created>2006-08-19</created><updated>2008-08-22</updated><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>How Hard Is Bribery in Elections?</title><categories>cs.GT cs.CC cs.MA</categories><comments>Earlier version appears in Proc. of AAAI-06, pp. 641-646, 2006</comments><report-no>URCS TR-2006-895</report-no><acm-class>I.2.11; F.2.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of influencing elections through bribery: How
computationally complex is it for an external actor to determine whether by a
certain amount of bribing voters a specified candidate can be made the
election's winner? We study this problem for election systems as varied as
scoring protocols and Dodgson voting, and in a variety of settings regarding
homogeneous-vs.-nonhomogeneous electorate bribability,
bounded-size-vs.-arbitrary-sized candidate sets, weighted-vs.-unweighted
voters, and succinct-vs.-nonsuccinct input specification. We obtain both
polynomial-time bribery algorithms and proofs of the intractability of bribery,
and indeed our results show that the complexity of bribery is extremely
sensitive to the setting. For example, we find settings in which bribery is
NP-complete but manipulation (by voters) is in P, and we find settings in which
bribing weighted voters is NP-complete but bribing voters with individual bribe
thresholds is in P. For the broad class of elections (including plurality,
Borda, k-approval, and veto) known as scoring protocols, we prove a dichotomy
result for bribery of weighted voters: We find a simple-to-evaluate condition
that classifies every case as either NP-complete or in P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608082</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608082</id><created>2006-08-20</created><authors><author><keyname>Alam</keyname><forenames>S. M. Nazrul</forenames></author><author><keyname>Marbach</keyname><forenames>Peter</forenames></author></authors><title>Competition and Request Routing Policies in Content Delivery Networks</title><categories>cs.NI</categories><abstract>  The role of competition and monetary benefits in the design of Content
Delivery Networks (CDNs) is largely an unexplored area. In this paper, we
investigate the effect of competition among the competitive web based CDNs and
show that little difference in their performance may cause significant
financial gain/loss. It turns out that the economy of scale effect is very
significant for the success of a CDN in a competitive market. So CDN peering
might be a good idea. Since performance and conforming to the service level
agreement (SLA) with content providers is very important, we then focus on
designing CDN from this perspective. We provide an asymptotically optimal
static request routing policy for a CDN under a model where a CDN company
guarantees a certain level of user latency to the content providers in the SLA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608083</id><created>2006-08-20</created><updated>2006-09-13</updated><authors><author><keyname>Aoki</keyname><forenames>Paul M.</forenames></author><author><keyname>Szymanski</keyname><forenames>Margaret H.</forenames></author><author><keyname>Plurkowski</keyname><forenames>Luke</forenames></author><author><keyname>Thornton</keyname><forenames>James D.</forenames></author><author><keyname>Woodruff</keyname><forenames>Allison</forenames></author><author><keyname>Yi</keyname><forenames>Weilie</forenames></author></authors><title>Where's the &quot;Party&quot; in &quot;Multi-Party&quot;? Analyzing the Structure of
  Small-Group Sociable Talk</title><categories>cs.HC</categories><comments>10 pages</comments><acm-class>H.5.3</acm-class><journal-ref>Proc. ACM Conf. on Computer Supported Cooperative Work, Banff,
  Alberta, Canada, Nov. 2006, 393-402. ACM Press.</journal-ref><doi>10.1145/1180875.1180934</doi><abstract>  Spontaneous multi-party interaction - conversation among groups of three or
more participants - is part of daily life. While automated modeling of such
interactions has received increased attention in ubiquitous computing research,
there is little applied research on the organization of this highly dynamic and
spontaneous sociable interaction within small groups. We report here on an
applied conversation analytic study of small-group sociable talk, emphasizing
structural and temporal aspects that can inform computational models. In
particular, we examine the mechanics of multiple simultaneous conversational
floors - how participants initiate a new floor amidst an on-going floor, and
how they subsequently show their affiliation with one floor over another. We
also discuss the implications of these findings for the design of &quot;smart&quot;
multi-party applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608084</id><created>2006-08-21</created><authors><author><keyname>Angluin</keyname><forenames>Dana</forenames></author><author><keyname>Aspnes</keyname><forenames>James</forenames></author><author><keyname>Eisenstat</keyname><forenames>David</forenames></author><author><keyname>Ruppert</keyname><forenames>Eric</forenames></author></authors><title>The computational power of population protocols</title><categories>cs.CC cs.DC</categories><comments>Combined version of OPODIS 2005 and PODC 2006 papers; submitted to
  Distributed Computing</comments><abstract>  We consider the model of population protocols introduced by Angluin et al.,
in which anonymous finite-state agents stably compute a predicate of the
multiset of their inputs via two-way interactions in the all-pairs family of
communication networks. We prove that all predicates stably computable in this
model (and certain generalizations of it) are semilinear, answering a central
open question about the power of the model. Removing the assumption of two-way
interaction, we also consider several variants of the model in which agents
communicate by anonymous message-passing where the recipient of each message is
chosen by an adversary and the sender is not identified to the recipient. These
one-way models are distinguished by whether messages are delivered immediately
or after a delay, whether a sender can record that it has sent a message, and
whether a recipient can queue incoming messages, refusing to accept new
messages until it has had a chance to send out messages of its own. We
characterize the classes of predicates stably computable in each of these
one-way models using natural subclasses of the semilinear predicates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608085</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608085</id><created>2006-08-22</created><updated>2010-11-17</updated><authors><author><keyname>Santhi</keyname><forenames>Nandakishore</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>A Quadratic Time-Space Tradeoff for Unrestricted Deterministic Decision
  Branching Programs</title><categories>cs.CC cs.DM cs.IT math.IT</categories><comments>Withdrawn</comments><acm-class>F.2.3; E.4</acm-class><abstract>  Withdrawn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608086</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608086</id><created>2006-08-22</created><authors><author><keyname>Santhi</keyname><forenames>Nandakishore</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>Analog Codes on Graphs</title><categories>cs.IT cs.DM math.IT</categories><comments>18 pages, 15 figures, Portions appeared in Proceedings of the
  International Symposium on Information Theory (ISIT), Yokohama, Japan, July
  2003</comments><acm-class>E.4</acm-class><abstract>  We consider the problem of transmission of a sequence of real data produced
by a Nyquist sampled band-limited analog source over a band-limited analog
channel, which introduces an additive white Gaussian noise. An analog coding
scheme is described, which can achieve a mean-squared error distortion
proportional to $(1+SNR)^{-B}$ for a bandwidth expansion factor of $B/R$, where
$0 &lt; R &lt; 1$ is the rate of individual component binary codes used in the
construction and $B \geq 1$ is an integer. Thus, over a wide range of SNR
values, the proposed code performs much better than any single previously known
analog coding system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608087</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608087</id><created>2006-08-22</created><authors><author><keyname>Santhi</keyname><forenames>Nandakishore</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>On an Improvement over R\'enyi's Equivocation Bound</title><categories>cs.IT cs.DM math.IT</categories><comments>8 pages, 6 figures, To be presented at the 44-th Annual Allerton
  Conference on Communication, Control, and Computing, September 2006</comments><acm-class>E.4</acm-class><abstract>  We consider the problem of estimating the probability of error in
multi-hypothesis testing when MAP criterion is used. This probability, which is
also known as the Bayes risk is an important measure in many communication and
information theory problems. In general, the exact Bayes risk can be difficult
to obtain. Many upper and lower bounds are known in literature. One such upper
bound is the equivocation bound due to R\'enyi which is of great philosophical
interest because it connects the Bayes risk to conditional entropy. Here we
give a simple derivation for an improved equivocation bound.
  We then give some typical examples of problems where these bounds can be of
use. We first consider a binary hypothesis testing problem for which the exact
Bayes risk is difficult to derive. In such problems bounds are of interest.
Furthermore using the bounds on Bayes risk derived in the paper and a random
coding argument, we prove a lower bound on equivocation valid for most random
codes over memoryless channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608088</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608088</id><created>2006-08-22</created><authors><author><keyname>Holme</keyname><forenames>Petter</forenames></author><author><keyname>Karlin</keyname><forenames>Josh</forenames></author><author><keyname>Forrest</keyname><forenames>Stephanie</forenames></author></authors><title>Radial Structure of the Internet</title><categories>cs.NI physics.soc-ph</categories><journal-ref>Proc. R. Soc. A 463, (2007) 1231-1246</journal-ref><doi>10.1098/rspa.2007.1820</doi><abstract>  The structure of the Internet at the Autonomous System (AS) level has been
studied by both the Physics and Computer Science communities. We extend this
work to include features of the core and the periphery, taking a radial
perspective on AS network structure. New methods for plotting AS data are
described, and they are used to analyze data sets that have been extended to
contain edges missing from earlier collections. In particular, the average
distance from one vertex to the rest of the network is used as the baseline
metric for investigating radial structure. Common vertex-specific quantities
are plotted against this metric to reveal distinctive characteristics of
central and peripheral vertices. Two data sets are analyzed using these
measures as well as two common generative models (Barabasi-Albert and Inet). We
find a clear distinction between the highly connected core and a sparse
periphery. We also find that the periphery has a more complex structure than
that predicted by degree distribution or the two generative models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608089</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608089</id><created>2006-08-22</created><authors><author><keyname>Aeron</keyname><forenames>Shuchin</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Wireless ad-hoc networks: Strategies and Scaling laws for the fixed SNR
  regime</title><categories>cs.IT math.IT</categories><comments>26 pages single column, submitted to Transactions on Information
  Theory</comments><journal-ref>IEEE Transactions on Information Theory, Volume 53, No. 6, June
  2007, pp. 2044-2059</journal-ref><doi>10.1109/TIT.2007.896858</doi><abstract>  This paper deals with throughput scaling laws for random ad-hoc wireless
networks in a rich scattering environment. We develop schemes to optimize the
ratio, $\rho(n)$ of achievable network sum capacity to the sum of the
point-to-point capacities of source-destinations pairs operating in isolation.
For fixed SNR networks, i.e., where the worst case SNR over the
source-destination pairs is fixed independent of $n$, we show that
collaborative strategies yield a scaling law of $\rho(n) = {\cal
O}(\frac{1}{n^{1/3}})$ in contrast to multi-hop strategies which yield a
scaling law of $\rho(n) = {\cal O}(\frac{1}{\sqrt{n}})$. While, networks where
worst case SNR goes to zero, do not preclude the possibility of collaboration,
multi-hop strategies achieve optimal throughput. The plausible reason is that
the gains due to collaboration cannot offset the effect of vanishing receive
SNR. This suggests that for fixed SNR networks, a network designer should look
for network protocols that exploit collaboration. The fact that most current
networks operate in a fixed SNR interference limited environment provides
further motivation for considering this regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608090</identifier>
 <datestamp>2007-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608090</id><created>2006-08-22</created><updated>2007-10-21</updated><authors><author><keyname>Srijuntongsiri</keyname><forenames>Gun</forenames></author><author><keyname>Vavasis</keyname><forenames>Stephen A.</forenames></author></authors><title>A Condition Number Analysis of a Line-Surface Intersection Algorithm</title><categories>cs.NA cs.CG</categories><abstract>  We propose an algorithm based on Newton's method and subdivision for finding
all zeros of a polynomial system in a bounded region of the plane. This
algorithm can be used to find the intersections between a line and a surface,
which has applications in graphics and computer-aided geometric design. The
algorithm can operate on polynomials represented in any basis that satisfies a
few conditions. The power basis, the Bernstein basis, and the first-kind
Chebyshev basis are among those compatible with the algorithm. The main novelty
of our algorithm is an analysis showing that its running is bounded only in
terms of the condition number of the polynomial's zeros and a constant
depending on the polynomial basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608091</id><created>2006-08-23</created><authors><author><keyname>Geerts</keyname><forenames>Floris</forenames></author><author><keyname>Revesz</keyname><forenames>Peter</forenames></author><author><keyname>Bussche</keyname><forenames>Jan Van den</forenames></author></authors><title>On-line topological simplification of weighted graphs</title><categories>cs.DS cs.DB</categories><comments>This is the full techreport corresponding to the paper &quot;On-line
  maintenance of simplified weighted graphs for efficient distance queries&quot; in
  the proceedings of ACM-GIS 2006</comments><journal-ref>Proceedings ACM-GIS 2006, ACM Press</journal-ref><abstract>  We describe two efficient on-line algorithms to simplify weighted graphs by
eliminating degree-two vertices. Our algorithms are on-line in that they react
to updates on the data, keeping the simplification up-to-date. The supported
updates are insertions of vertices and edges; hence, our algorithms are
partially dynamic. We provide both analytical and empirical evaluations of the
efficiency of our approaches. Specifically, we prove an O(log n) upper bound on
the amortized time complexity of our maintenance algorithms, with n the number
of insertions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608092</id><created>2006-08-24</created><updated>2006-08-24</updated><authors><author><keyname>Daliot</keyname><forenames>Ariel</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Self-Stabilizing Byzantine Pulse Synchronization</title><categories>cs.DC</categories><comments>An updated version. The original version appeared as TR-2005-84, The
  Hebrew university, Aug. 2005</comments><report-no>TR-2005-84</report-no><acm-class>C.2.4; D.4.5</acm-class><abstract>  The ``Pulse Synchronization'' problem can be loosely described as targeting
to invoke a recurring distributed event as simultaneously as possible at the
different nodes and with a frequency that is as regular as possible. This
target becomes surprisingly subtle and difficult to achieve when facing both
transient and permanent failures. In this paper we present an algorithm for
pulse synchronization that self-stabilizes while at the same time tolerating a
permanent presence of Byzantine faults. The Byzantine nodes might incessantly
try to de-synchronize the correct nodes. Transient failures might throw the
system into an arbitrary state in which correct nodes have no common notion
what-so-ever, such as time or round numbers, and can thus not infer anything
from their own local states upon the state of other correct nodes. The
presented algorithm grants nodes the ability to infer that eventually all
correct nodes will invoke their pulses within a very short time interval of
each other and will do so regularly.
  Pulse synchronization has previously been shown to be a powerful tool for
designing general self-stabilizing Byzantine algorithms and is hitherto the
only method that provides for the general design of efficient practical
protocols in the confluence of these two fault models. The difficulty, in
general, to design any algorithm in this fault model may be indicated by the
remarkably few algorithms resilient to both fault models. The few published
self-stabilizing Byzantine algorithms are typically complicated and sometimes
converge from an arbitrary initial state only after exponential or super
exponential time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608093</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608093</id><created>2006-08-24</created><authors><author><keyname>Evako</keyname><forenames>Alexander</forenames></author></authors><title>Connection between continuous and digital n-manifolds and the Poincare
  conjecture</title><categories>cs.DM cs.CV math.AT</categories><comments>39 pages, 26 figures</comments><abstract>  We introduce LCL covers of closed n-dimensional manifolds by n-dimensional
disks and study their properties. We show that any LCL cover of an
n-dimensional sphere can be converted to the minimal LCL cover, which consists
of 2n+2 disks. We prove that an LCL collection of n-disks is a cover of a
continuous n-sphere if and only if the intersection graph of this collection is
a digital n-sphere. Using a link between LCL covers of closed continuous
n-manifolds and digital n-manifolds, we find conditions where a continuous
closed three-dimensional manifold is the three-dimensional sphere. We discuss a
connection between the classification problems for closed continuous
three-dimensional manifolds and digital three-manifolds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608094</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608094</id><created>2006-08-24</created><updated>2010-12-16</updated><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>On Universality in Real Computation</title><categories>cs.CC cs.LO</categories><comments>Paper in French. 10 pages. Forthcoming a detailed English version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models of computation operating over the real numbers and computing a larger
class of functions compared to the class of general recursive functions
invariably introduce a non-finite element of infinite information encoded in an
arbitrary non-computable number or non-recursive function. In this paper we
show that Turing universality is only possible at every Turing degree but not
over all, in that sense universality at the first level is elegantly well
defined while universality at higher degrees is at least ambiguous. We propose
a concept of universal relativity and universal jump between levels in the
arithmetical and analytical hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608095</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608095</id><created>2006-08-24</created><updated>2009-02-04</updated><authors><author><keyname>Mueller</keyname><forenames>Markus</forenames></author></authors><title>Stationary Algorithmic Probability</title><categories>cs.IT cs.CC math.IT math.PR</categories><comments>13 pages, 5 figures. Added an example of a positive recurrent
  computer set</comments><journal-ref>Theoretical Computer Science 411 pp. 113-130 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kolmogorov complexity and algorithmic probability are defined only up to an
additive resp. multiplicative constant, since their actual values depend on the
choice of the universal reference computer. In this paper, we analyze a natural
approach to eliminate this machine-dependence.
  Our method is to assign algorithmic probabilities to the different computers
themselves, based on the idea that &quot;unnatural&quot; computers should be hard to
emulate. Therefore, we study the Markov process of universal computers randomly
emulating each other. The corresponding stationary distribution, if it existed,
would give a natural and machine-independent probability measure on the
computers, and also on the binary strings.
  Unfortunately, we show that no stationary distribution exists on the set of
all computers; thus, this method cannot eliminate machine-dependence. Moreover,
we show that the reason for failure has a clear and interesting physical
interpretation, suggesting that every other conceivable attempt to get rid of
those additive constants must fail in principle, too.
  However, we show that restricting to some subclass of computers might help to
get rid of some amount of machine-dependence in some situations, and the
resulting stationary computer and string probabilities have beautiful
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608096</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608096</id><created>2006-08-24</created><authors><author><keyname>Daliot</keyname><forenames>Ariel</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Parnas</keyname><forenames>Hanna</forenames></author></authors><title>Linear-time Self-stabilizing Byzantine Clock Synchronization</title><categories>cs.DC</categories><comments>This is a corrected version. The original paper appeared in OPODIS'03</comments><acm-class>C.1.4; C.2.4; D.4.5</acm-class><journal-ref>Proc. of 7th International Conference on Principles of Distributed
  Systems (OPODIS'03 La Martinique, France), December, 2003</journal-ref><abstract>  Clock synchronization is a very fundamental task in distributed system. It
thus makes sense to require an underlying clock synchronization mechanism to be
highly fault-tolerant. A self-stabilizing algorithm seeks to attain
synchronization once lost; a Byzantine algorithm assumes synchronization is
never lost and focuses on containing the influence of the permanent presence of
faulty nodes. There are efficient self-stabilizing solutions for clock
synchronization as well as efficient solutions that are resilient to Byzantine
faults. In contrast, to the best of our knowledge there is no practical
solution that is self-stabilizing while tolerating the permanent presence of
Byzantine nodes. We present the first linear-time self-stabilizing Byzantine
clock synchronization algorithm. Our deterministic clock synchronization
algorithm is based on the observation that all clock synchronization algorithms
require events for exchanging clock values and re-synchronizing the clocks to
within safe bounds. These events usually need to happen synchronously at the
different nodes. In classic Byzantine algorithms this is fulfilled or aided by
having the clocks initially close to each other and thus the actual clock
values can be used for synchronizing the events. This implies that clock values
cannot differ arbitrarily, which necessarily renders these solutions to be
non-stabilizing. Our scheme suggests using an underlying distributed pulse
synchronization module that is uncorrelated to the clock values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608097</identifier>
 <datestamp>2007-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608097</id><created>2006-08-25</created><updated>2007-05-28</updated><authors><author><keyname>Mingarelli</keyname><forenames>Angelo B.</forenames></author></authors><title>A study of fuzzy and many-valued logics in cellular automata</title><categories>cs.LO cs.CC</categories><comments>Corrected version: Tables 1, 3 and 4 have a missing left-most
  diagonal, thus resulting in misleading data output. Minor typos in the text
  corrected as a result. Note that all table values are truncations of actual
  values</comments><acm-class>B.6.1; F.1.1; I.2.3</acm-class><journal-ref>J. Cellular Automata, 1 (3) (2006), 233-252</journal-ref><abstract>  In this paper we provide an analytical study of the theory of multi-valued
and fuzzy cellular automata where the fuzziness appears as the result of the
application of an underlying multi-valued or continuous logic as opposed to
standard logic as used conventionally. Using the disjunctive normal form of any
one of the 255 ECA's so defined, we modify the underlying logic structure and
redefine the ECA within the framework of this new logic. The idea here is to
show that the evolution of space-time diagrams of ECA's under even a
probabilistic logic can exhibit non-chaotic behavior. This is looked at
specifically for Probabilistic Rule 110, in contrast with Boolean Rule 110
which is known to be capable of universal computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608098</id><created>2006-08-25</created><authors><author><keyname>Parthasarathy</keyname><forenames>Arvind</forenames></author></authors><title>Improved Content Based Image Watermarking</title><categories>cs.CR</categories><comments>24 pages</comments><abstract>  This paper presents a robust and transparent scheme of watermarking that
exploits the human visual systems' sensitivity to frequency, along with local
image characteristics obtained from the spatial domain. The underlying idea is
generating a visual mask based on the visual systems' perception of image
content. This mask is used to embed a decimal sequence while keeping its
amplitude below the distortion sensitivity of the image pixel. We consider
texture, luminance, corner and the edge information in the image to generate a
mask that makes the addition of the watermark imperceptible to the human eye.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608099</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608099</id><created>2006-08-25</created><authors><author><keyname>Janhunen</keyname><forenames>Tomi</forenames></author><author><keyname>Oikarinen</keyname><forenames>Emilia</forenames></author></authors><title>Automated verification of weak equivalence within the SMODELS system</title><categories>cs.AI cs.LO</categories><comments>48 pages, 7 figures, 2 tables</comments><acm-class>I.2.4; F.4.1; F.2.2</acm-class><abstract>  In answer set programming (ASP), a problem at hand is solved by (i) writing a
logic program whose answer sets correspond to the solutions of the problem, and
by (ii) computing the answer sets of the program using an answer set solver as
a search engine. Typically, a programmer creates a series of gradually
improving logic programs for a particular problem when optimizing program
length and execution time on a particular solver. This leads the programmer to
a meta-level problem of ensuring that the programs are equivalent, i.e., they
give rise to the same answer sets. To ease answer set programming at
methodological level, we propose a translation-based method for verifying the
equivalence of logic programs. The basic idea is to translate logic programs P
and Q under consideration into a single logic program EQT(P,Q) whose answer
sets (if such exist) yield counter-examples to the equivalence of P and Q. The
method is developed here in a slightly more general setting by taking the
visibility of atoms properly into account when comparing answer sets. The
translation-based approach presented in the paper has been implemented as a
translator called lpeq that enables the verification of weak equivalence within
the smodels system using the same search engine as for the search of models.
Our experiments with lpeq and smodels suggest that establishing the equivalence
of logic programs in this way is in certain cases much faster than naive
cross-checking of answer sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608100</id><created>2006-08-25</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames><affiliation>National Research Council of Canada</affiliation></author></authors><title>Similarity of Semantic Relations</title><categories>cs.CL cs.IR cs.LG</categories><comments>related work available at http://purl.org/peter.turney/</comments><report-no>NRC-48775</report-no><acm-class>H.3.1; I.2.6; I.2.7</acm-class><journal-ref>Computational Linguistics, (2006), 32(3), 379-416</journal-ref><abstract>  There are at least two kinds of similarity. Relational similarity is
correspondence between relations, in contrast with attributional similarity,
which is correspondence between attributes. When two words have a high degree
of attributional similarity, we call them synonyms. When two pairs of words
have a high degree of relational similarity, we say that their relations are
analogous. For example, the word pair mason:stone is analogous to the pair
carpenter:wood. This paper introduces Latent Relational Analysis (LRA), a
method for measuring relational similarity. LRA has potential applications in
many areas, including information extraction, word sense disambiguation, and
information retrieval. Recently the Vector Space Model (VSM) of information
retrieval has been adapted to measuring relational similarity, achieving a
score of 47% on a collection of 374 college-level multiple-choice word analogy
questions. In the VSM approach, the relation between a pair of words is
characterized by a vector of frequencies of predefined patterns in a large
corpus. LRA extends the VSM approach in three ways: (1) the patterns are
derived automatically from the corpus, (2) the Singular Value Decomposition
(SVD) is used to smooth the frequency data, and (3) automatically generated
synonyms are used to explore variations of the word pairs. LRA achieves 56% on
the 374 analogy questions, statistically equivalent to the average human score
of 57%. On the related problem of classifying semantic relations, LRA achieves
similar gains over the VSM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608101</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608101</id><created>2006-08-25</created><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Rafiey</keyname><forenames>A.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>Minimum Cost Homomorphisms to Semicomplete Bipartite Digraphs</title><categories>cs.DM cs.CC</categories><abstract>  For digraphs $D$ and $H$, a mapping $f: V(D)\dom V(H)$ is a homomorphism of
$D$ to $H$ if $uv\in A(D)$ implies $f(u)f(v)\in A(H).$ If, moreover, each
vertex $u \in V(D)$ is associated with costs $c_i(u), i \in V(H)$, then the
cost of the homomorphism $f$ is $\sum_{u\in V(D)}c_{f(u)}(u)$. For each fixed
digraph $H$, we have the {\em minimum cost homomorphism problem for} $H$. The
problem is to decide, for an input graph $D$ with costs $c_i(u),$ $u \in V(D),
i\in V(H)$, whether there exists a homomorphism of $D$ to $H$ and, if one
exists, to find one of minimum cost. Minimum cost homomorphism problems
encompass (or are related to) many well studied optimization problems. We
describe a dichotomy of the minimum cost homomorphism problem for semicomplete
multipartite digraphs $H$. This solves an open problem from an earlier paper.
To obtain the dichotomy of this paper, we introduce and study a new notion, a
$k$-Min-Max ordering of digraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608102</id><created>2006-08-25</created><authors><author><keyname>Mundinger</keyname><forenames>Jochen</forenames></author><author><keyname>Boudec</keyname><forenames>Jean-Yves Le</forenames></author></authors><title>Analysis of a Reputation System for Mobile Ad-Hoc Networks with Liars</title><categories>cs.PF</categories><comments>17 pages, 6 figures</comments><report-no>LCA-REPORT-2006-009</report-no><abstract>  The application of decentralized reputation systems is a promising approach
to ensure cooperation and fairness, as well as to address random failures and
malicious attacks in Mobile Ad-Hoc Networks. However, they are potentially
vulnerable to liars. With our work, we provide a first step to analyzing
robustness of a reputation system based on a deviation test. Using a mean-field
approach to our stochastic process model, we show that liars have no impact
unless their number exceeds a certain threshold (phase transition). We give
precise formulae for the critical values and thus provide guidelines for an
optimal choice of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608103</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608103</id><created>2006-08-25</created><authors><author><keyname>Marek</keyname><forenames>V. W.</forenames></author><author><keyname>Niemela</keyname><forenames>I.</forenames></author><author><keyname>Truszczynski]</keyname><forenames>M.</forenames></author></authors><title>Logic programs with monotone abstract constraint atoms</title><categories>cs.AI cs.LO</categories><comments>33 pages</comments><acm-class>F.4.1; D.1.6</acm-class><abstract>  We introduce and study logic programs whose clauses are built out of monotone
constraint atoms. We show that the operational concept of the one-step
provability operator generalizes to programs with monotone constraint atoms,
but the generalization involves nondeterminism. Our main results demonstrate
that our formalism is a common generalization of (1) normal logic programming
with its semantics of models, supported models and stable models, (2) logic
programming with weight atoms (lparse programs) with the semantics of stable
models, as defined by Niemela, Simons and Soininen, and (3) of disjunctive
logic programming with the possible-model semantics of Sakama and Inoue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608104</identifier>
 <datestamp>2013-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608104</id><created>2006-08-28</created><updated>2007-09-01</updated><authors><author><keyname>Khedker</keyname><forenames>Uday</forenames></author><author><keyname>Sanyal</keyname><forenames>Amitabha</forenames></author><author><keyname>Karkare</keyname><forenames>Amey</forenames></author></authors><title>Heap Reference Analysis Using Access Graphs</title><categories>cs.PL cs.SE</categories><comments>Accepted for printing by ACM TOPLAS. This version incorporates
  referees' comments</comments><acm-class>D.3.4; F.3.2</acm-class><journal-ref>ACM TOPLAS, 30(1), 2007</journal-ref><doi>10.1145/1290520.1290521</doi><abstract>  Despite significant progress in the theory and practice of program analysis,
analysing properties of heap data has not reached the same level of maturity as
the analysis of static and stack data. The spatial and temporal structure of
stack and static data is well understood while that of heap data seems
arbitrary and is unbounded. We devise bounded representations which summarize
properties of the heap data. This summarization is based on the structure of
the program which manipulates the heap. The resulting summary representations
are certain kinds of graphs called access graphs. The boundedness of these
representations and the monotonicity of the operations to manipulate them make
it possible to compute them through data flow analysis.
  An important application which benefits from heap reference analysis is
garbage collection, where currently liveness is conservatively approximated by
reachability from program variables. As a consequence, current garbage
collectors leave a lot of garbage uncollected, a fact which has been confirmed
by several empirical studies. We propose the first ever end-to-end static
analysis to distinguish live objects from reachable objects. We use this
information to make dead objects unreachable by modifying the program. This
application is interesting because it requires discovering data flow
information representing complex semantics. In particular, we discover four
properties of heap data: liveness, aliasing, availability, and anticipability.
Together, they cover all combinations of directions of analysis (i.e. forward
and backward) and confluence of information (i.e. union and intersection). Our
analysis can also be used for plugging memory leaks in C/C++ languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608105</id><created>2006-08-28</created><updated>2006-08-31</updated><authors><author><keyname>Guo</keyname><forenames>Hui</forenames></author><author><keyname>Jiang</keyname><forenames>Ying</forenames></author></authors><title>Application Layer Definition and Analyses of Controller Area Network Bus
  for Wire Harness Assembly Machine</title><categories>cs.RO cs.NI</categories><comments>6 pages, 2 figures, 4 tables</comments><abstract>  With the feature of multi-master bus access, nondestructive contention-based
arbitration and flexible configuration, Controller Area Network (CAN) bus is
applied into the control system of Wire Harness Assembly Machine (WHAM). To
accomplish desired goal, the specific features of the CAN bus is analyzed by
compared with other field buses and the functional performances in the CAN bus
system of WHAM is discussed. Then the application layer planning of CAN bus for
dynamic priority is presented. The critical issue for the use of CAN bus system
in WHAM is the data transfer rate between different nodes. So processing
efficient model is introduced to assist analyzing data transfer procedure.
Through the model, it is convenient to verify the real time feature of the CAN
bus system in WHAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608106</id><created>2006-08-28</created><updated>2007-05-11</updated><authors><author><keyname>Moser</keyname><forenames>Philippe</forenames></author></authors><title>Lp Computable Functions and Fourier Series</title><categories>cs.CC</categories><comments>corrected abstract</comments><abstract>  This paper studies how well computable functions can be approximated by their
Fourier series. To this end, we equip the space of Lp-computable functions
(computable Lebesgue integrable functions) with a size notion, by introducing
Lp-computable Baire categories.
  We show that Lp-computable Baire categories satisfy the following three basic
properties. Singleton sets {f} (where f is Lp-computable) are meager, suitable
infinite unions of meager sets are meager, and the whole space of Lp-computable
functions is not meager. We give an alternative characterization of meager sets
via Banach Mazur games.
  We study the convergence of Fourier series for Lp-computable functions and
show that whereas for every p&gt;1, the Fourier series of every Lp-computable
function f converges to f in the Lp norm, the set of L1-computable functions
whose Fourier series does not diverge almost everywhere is meager.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608107</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608107</id><created>2006-08-28</created><updated>2007-02-19</updated><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>The Haar Wavelet Transform of a Dendrogram</title><categories>cs.IR</categories><comments>38 pp, 8 figures. Forthcoming in Journal of Classification</comments><acm-class>I.5.3; H.3.1; I.1.m</acm-class><journal-ref>Journal of Classification, 24, 3-32, 2007</journal-ref><doi>10.1007/s00357-007-0007-9</doi><abstract>  We describe a new wavelet transform, for use on hierarchies or binary rooted
trees. The theoretical framework of this approach to data analysis is
described. Case studies are used to further exemplify this approach. A first
set of application studies deals with data array smoothing, or filtering. A
second set of application studies relates to hierarchical tree condensation.
Finally, a third study explores the wavelet decomposition, and the
reproducibility of data sets such as text, including a new perspective on the
generation or computability of such data objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608108</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608108</id><created>2006-08-28</created><authors><author><keyname>Brodu</keyname><forenames>Nicolas</forenames></author></authors><title>Spherical Indexing for Neighborhood Queries</title><categories>cs.DS cs.CG</categories><comments>9 pages, 10 figures. The source code is available at
  http://nicolas.brodu.free.fr/en/programmation/neighand/index.html</comments><abstract>  This is an algorithm for finding neighbors when the objects can freely move
and have no predefined position. The query consists in finding neighbors for a
center location and a given radius. Space is discretized in cubic cells. This
algorithm introduces a direct spherical indexing that gives the list of all
cells making up the query sphere, for any radius and any center location. It
can additionally take in account both cyclic and non-cyclic regions of
interest. Finding only the K nearest neighbors naturally benefits from the
spherical indexing by minimally running through the sphere from center to edge,
and reducing the maximum distance when K neighbors have been found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608109</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608109</id><created>2006-08-29</created><authors><author><keyname>Hohensee</keyname><forenames>Michael</forenames></author></authors><title>Realistic Boundary Conditions for Ad Hoc Network Node Mobility Models
  and a New Approach to the Random Waypoint Model</title><categories>cs.NI</categories><comments>12 pages</comments><acm-class>C.2.1</acm-class><abstract>  In this paper, we examine the cause of the border effect observed in many
mobility models used to construct simulations of ad hoc networking protocol
performance. We specify conditions under which a node mobility model must
produce spatial mobile node distribution functions that obey the diffusion
equation. In particular demonstrate that these conditions are satisfied by the
random direction (RD) model. We show that it is possible to construct mobility
models that attain uniform steady-state distributions without resorting to
reflection or ``wrapping'' of nodes at the border of a test region. Finally, we
show that the random waypoint (RWP) model may be reproduced by the application
of a ``volume rule'' to an RD model. This volume rule violates the assumptions
that lead to the diffusion equation. We suggest a generalization of the RWP
model that can provide more uniform mobile node distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608110</id><created>2006-08-29</created><authors><author><keyname>Colvin</keyname><forenames>Robert</forenames></author><author><keyname>Hayes</keyname><forenames>Ian J.</forenames></author><author><keyname>Strooper</keyname><forenames>Paul</forenames></author></authors><title>Calculating modules in contextual logic program refinement</title><categories>cs.LO</categories><abstract>  The refinement calculus for logic programs is a framework for deriving logic
programs from specifications. It is based on a wide-spectrum language that can
express both specifications and code, and a refinement relation that models the
notion of correct implementation. In this paper we extend and generalise
earlier work on contextual refinement. Contextual refinement simplifies the
refinement process by abstractly capturing the context of a subcomponent of a
program, which typically includes information about the values of the free
variables. This paper also extends and generalises module refinement. A module
is a collection of procedures that operate on a common data type; module
refinement between a specification module A and an implementation module C
allows calls to the procedures of A to be systematically replaced with calls to
the corresponding procedures of C. Based on the conditions for module
refinement, we present a method for calculating an implementation module from a
specification module. Both contextual and module refinement within the
refinement calculus have been generalised from earlier work and the results are
presented in a unified framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608111</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608111</id><created>2006-08-29</created><updated>2006-10-02</updated><authors><author><keyname>Mesbah</keyname><forenames>Ali</forenames></author><author><keyname>van Deursen</keyname><forenames>Arie</forenames></author></authors><title>An Architectural Style for Ajax</title><categories>cs.SE</categories><comments>2nd revision: references ordered, images resized, typos</comments><report-no>TUD-SERG-2006-016</report-no><journal-ref>Proceedings of the 6th Working IEEE/IFIP Conference on Software
  Architecture (WICSA'07). IEEE Computer Society, 2007</journal-ref><abstract>  A new breed of web application, dubbed AJAX, is emerging in response to a
limited degree of interactivity in large-grain stateless Web interactions. At
the heart of this new approach lies a single page interaction model that
facilitates rich interactivity. We have studied and experimented with several
AJAX frameworks trying to understand their architectural properties. In this
paper, we summarize three of these frameworks and examine their properties and
introduce the SPIAR architectural style. We describe the guiding software
engineering principles and the constraints chosen to induce the desired
properties. The style emphasizes user interface component development, and
intermediary delta-communication between client/server components, to improve
user interactivity and ease of development. In addition, we use the concepts
and principles to discuss various open issues in AJAX frameworks and
application development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608112</id><created>2006-08-29</created><authors><author><keyname>Hudzia</keyname><forenames>B.</forenames></author><author><keyname>McDermott</keyname><forenames>L.</forenames></author><author><keyname>Illahi</keyname><forenames>T. N.</forenames></author><author><keyname>Kechadi</keyname><forenames>M-T.</forenames></author></authors><title>Entity Based Peer-to-Peer in a Data Grid Environment</title><categories>cs.DC</categories><journal-ref>B. Hudzia, L. McDermott, T.N. Illahi, and M-T. Kechadi, &quot;Entity
  Based Peer-to-Peer in a Data Grid Environment&quot;, The 17th IMACS World Congress
  Scientific Computation, Applied Mathematics and Simulation, Paris, France,
  July, 11-15, 2005</journal-ref><abstract>  During the last decade there has been a huge interest in Grid technologies,
and numerous Grid projects have been initiated with various visions of the
Grid. While all these visions have the same goal of resource sharing, they
differ in the functionality that a Grid supports, the grid characterisation,
programming environments, etc. In this paper we present a new Grid system
dedicated to deal with data issues, called DGET (Data Grid Environment and
Tools). DGET is characterized by its peer-to-peer communication system and
entity-based architecture, therefore, taking advantage of the main
functionality of both systems; P2P and Grid. DGET is currently under
development and a prototype implementing the main components is in its first
phase of testing. In this paper we limit our description to the system
architectural features and to the main differences with other systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608113</id><created>2006-08-29</created><authors><author><keyname>Hudzia</keyname><forenames>B.</forenames></author><author><keyname>Ellahi</keyname><forenames>T. N.</forenames></author><author><keyname>McDermott</keyname><forenames>L.</forenames></author><author><keyname>Kechadi</keyname><forenames>T.</forenames></author></authors><title>A Java Based Architecture of P2P-Grid Middleware</title><categories>cs.DC</categories><journal-ref>B. Hudzia, T. N. Ellahi, L. McDermott, T. Kechadi, 'A Java Based
  Architecture of P2P-Grid Middleware', The 2006 International Conference on
  Parallel and Distributed Processing Techniques and Applications, June 26-29,
  2006, Las Vegas, USA</journal-ref><abstract>  During the last decade there has been a huge interest in Grid technologies,
and numerous Grid projects have been initiated with various visions of the
Grid. While all these visions have the same goal of resource sharing, they
differ in the functionality that a Grid supports, characterization, programming
environments, etc. We present a new Grid system dedicated to dealing with data
issues, called DGET (Data Grid Environment and Tools). DGET is characterized by
its peerto- peer communication system and entity-based architecture, therefore,
taking advantage of the main functionality of both systems; P2P and Grid. DGET
is currently under development and a prototype implementing the main components
is in its first phase of testing. In this paper we limit our description to the
system architectural features and to the main differences with other systems.
Keywords: Grid Computing, Peer to Peer, Peer to Peer Grid
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608114</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608114</id><created>2006-08-29</created><authors><author><keyname>Hudzia</keyname><forenames>Benoit</forenames></author><author><keyname>Petiton</keyname><forenames>Serge</forenames></author></authors><title>Reliable multicast fault tolerant MPI in the Grid environment</title><categories>cs.DC</categories><journal-ref>Benoit Hudzia and Serge Petiton, &quot;Reliable multicast fault
  tolerant MPI in the Grid environment&quot;, International Conference GRIDnet,
  october 2004</journal-ref><abstract>  Grid environments have recently been developed with low stretch and overheads
that increase with the logarithm of the number of nodes in the system. Getting
and sending data to/from a large numbers of nodes is gaining importance due to
an increasing number of independent data providers and the heterogeneity of the
network/Grid. One of the key challenges is to achieve a balance between low
bandwidth consumption and good reliability. In this paper we present an
implementation of a reliable multicast protocol over a fault tolerant MPI:
MPICHV2. It can provide one way to solve the problem of transferring large
chunks of data between applications running on a grid with limited network
links. We first show that we can achieve similar performance as the MPICH-P4
implementation by using multicast with data compression in a cluster. Next, we
provide a theoretical cluster organization and GRID network architecture to
harness the performance provided by using multicast. Finally, we present the
conclusion and future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608115</id><created>2006-08-29</created><authors><author><keyname>Litinskii</keyname><forenames>Leonid B.</forenames></author><author><keyname>Romanov</keyname><forenames>Dmitry E.</forenames></author></authors><title>Neural Network Clustering Based on Distances Between Objects</title><categories>cs.CV cs.NE</categories><comments>7 pages,4 figures, presentation on ICANN (Athens, Greece, 2006)</comments><abstract>  We present an algorithm of clustering of many-dimensional objects, where only
the distances between objects are used. Centers of classes are found with the
aid of neuron-like procedure with lateral inhibition. The result of clustering
does not depend on starting conditions. Our algorithm makes it possible to give
an idea about classes that really exist in the empirical data. The results of
computer simulations are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608116</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608116</id><created>2006-08-29</created><authors><author><keyname>Ellahi</keyname><forenames>T. N.</forenames></author><author><keyname>Hudzia</keyname><forenames>B.</forenames></author><author><keyname>McDermott</keyname><forenames>L.</forenames></author><author><keyname>Kechadi</keyname><forenames>T.</forenames></author></authors><title>Transparent Migration of Multi-Threaded Applications on a Java Based
  Grid</title><categories>cs.DC</categories><journal-ref>T. N. Ellahi, B. Hudzia, L. McDermott, T. Kechadi, Transparent
  Migration of Multi-Threaded Applications on a Java Based Grid, The IASTED
  International Conference on Web Technologies, Applications, and Services
  (WTAS 2006), July 17-19, 2006, Alberta, Canada</journal-ref><abstract>  Grid computing has enabled pooling a very large number of heterogeneous
resource administered by different security domains. Applications are
dynamically deployed on the resources available at the time. Dynamic nature of
the resources and applications requirements makes needs the grid middleware to
support the ability of migrating a running application to a different resource.
Especially, Grid applications are typically long running and thus stoping them
and starting them from scratch is not a feasible option. This paper presents an
overview of migration support in a java based grid middleware called DGET.
Migration support in DGET includes multi-threaded migration and asynchronous
migration as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608117</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608117</id><created>2006-08-29</created><authors><author><keyname>Wang</keyname><forenames>Chih-Chun</forenames><affiliation>Purdue University</affiliation></author></authors><title>Code Annealing and the Suppressing Effect of the Cyclically Lifted LDPC
  Code Ensemble</title><categories>cs.IT math.IT</categories><comments>To appear in the Proc. 2006 IEEE Information Theory Workshop,
  Chengdu, China</comments><abstract>  Code annealing, a new method of designing good codes of short block length,
is proposed, which is then concatenated with cyclic lifting to create finite
codes of low frame error rate (FER) error floors without performance outliers.
The stopping set analysis is performed on the cyclically lifted code ensemble
assuming uniformly random lifting sequences, and the suppressing effect/weight
of the cyclic lifting is identified for the first time, based on which the
ensemble FER error floor can be analytically determined and a scaling law is
derived. Both the first-order and high-order suppressing effects are discussed
and quantified by different methods including the explicit expression, an
algorithmic upper bound, and an algebraic lower bound.
  The mismatch between the suppressing weight and the stopping distances
explains the dramatic performance discrepancy among different cyclically lifted
codes when the underlying base codes have degree 2 variable nodes or not. For
the former case, a degree augmentation method is further introduced to mitigate
this metric mismatch, and a systematic method of constructing irregular codes
of low FER error floors is presented. Both regular and irregular codes of very
low FER error floors are reported, for which the improvement factor ranges from
10^6-10^4 when compared to the classic graph-based code ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608118</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608118</id><created>2006-08-29</created><authors><author><keyname>Hudzia</keyname><forenames>B.</forenames></author><author><keyname>Kechadi</keyname><forenames>M-T.</forenames></author><author><keyname>Ottewill</keyname><forenames>A.</forenames></author></authors><title>TreeP: A Tree-Based P2P Network Architecture</title><categories>cs.DC</categories><journal-ref>B. Hudzia, M-T. Kechadi, and A. Ottewill, &quot;TreeP: A Tree-Based P2P
  Network Architecture&quot;, International Workshop on Algorithms, Models and tools
  for parallel computing on heterogeneous networks (HeteroPar' 05), Boston,
  Massachusetts, USA, September 27-30, 2005</journal-ref><abstract>  In this paper we proposed a hierarchical P2P network based on a dynamic
partitioning on a 1-D space. This hierarchy is created and maintained
dynamically and provides a gridmiddleware (like DGET) a P2P basic functionality
for resource discovery and load-balancing.This network architecture is called
TreeP (Tree based P2P network architecture) and is based on atessellation of a
1-D space. We show that this topology exploits in an efficient way
theheterogeneity feature of the network while limiting the overhead introduced
by the overlaymaintenance. Experimental results show that this topology is
highly resilient to a large number ofnetwork failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608119</id><created>2006-08-29</created><authors><author><keyname>Lian</keyname><forenames>Shiguo</forenames></author><author><keyname>Sun</keyname><forenames>Jinsheng</forenames></author><author><keyname>Wang</keyname><forenames>Zhiquan</forenames></author></authors><title>Security Analysis of A Chaos-based Image Encryption Algorithm</title><categories>cs.MM cs.CR</categories><comments>16 pages,4 figures</comments><abstract>  The security of Fridrich Image Encryption Algorithm against brute-force
attack, statistical attack, known-plaintext attack and select-plaintext attack
is analyzed by investigating the properties of the involved chaotic maps and
diffusion functions. Based on the given analyses, some means are proposed to
strengthen the overall performance of the focused cryptosystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608120</id><created>2006-08-30</created><updated>2006-10-30</updated><authors><author><keyname>Cachat</keyname><forenames>Thierry</forenames><affiliation>LIAFA</affiliation></author></authors><title>Controller synthesis &amp; Ordinal Automata</title><categories>cs.GT</categories><comments>with appendix</comments><proxy>ccsd ccsd-00019897</proxy><journal-ref>Proceedings of the 4th International Symposium on Automated
  Technology for Verification and Analysis (ATVA'06) Springer (Ed.) (2006)
  215-228</journal-ref><abstract>  Ordinal automata are used to model physical systems with Zeno behavior. Using
automata and games techniques we solve a control problem formulated and left
open by Demri and Nowak in 2005. It involves partial observability and a new
synchronization between the controller and the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608121</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608121</id><created>2006-08-30</created><authors><author><keyname>Liou</keyname><forenames>Cheng-Yuan</forenames></author><author><keyname>Musicus</keyname><forenames>Bruce R.</forenames></author></authors><title>Cross Entropy Approximation of Structured Covariance Matrices</title><categories>cs.IT math.IT</categories><comments>20 pages</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 56, issue 7, Part 2,
  pages 3362-3367, 2008</journal-ref><abstract>  We apply two variations of the principle of Minimum Cross Entropy (the
Kullback information measure) to fit parameterized probability density models
to observed data densities. For an array beamforming problem with P incident
narrowband point sources, N &gt; P sensors, and colored noise, both approaches
yield eigenvector fitting methods similar to that of the MUSIC algorithm[1].
Furthermore, the corresponding cross-entropies are related to the MDL model
order selection criterion[2].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608122</identifier>
 <datestamp>2015-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608122</id><created>2006-08-30</created><updated>2015-07-17</updated><authors><author><keyname>Mani</keyname><forenames>A.</forenames></author></authors><title>FOSS-Based Grid Computing</title><categories>cs.DC cs.PL</categories><comments>47 Pages. arXiv admin note: text overlap with arXiv:cs/0605056 by
  other authors</comments><report-no>EG -15 (RMCE)</report-no><acm-class>C.2.4; D.1.3</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this expository paper we will be primarily concerned with core aspects of
Grids and Grid computing using free and open-source software with some emphasis
on utility computing. It is based on a technical report entitled
'Grid-Computing Using GNU/Linux' by the present author. This article was
written in 2006 and should be of historical interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608123</identifier>
 <datestamp>2007-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608123</id><created>2006-08-31</created><updated>2007-10-29</updated><authors><author><keyname>Zha</keyname><forenames>Zhengbang</forenames></author><author><keyname>Wang</keyname><forenames>XueLi</forenames></author></authors><title>Proof of a Conjecture of Helleseth Regarding Pairs of Binary m-Sequences</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn by the author(s), due a crucial sign error in
Thm. 11.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608124</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608124</id><created>2006-08-31</created><updated>2011-01-18</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>Goertz</keyname><forenames>Inge Li</forenames></author></authors><title>The Tree Inclusion Problem: In Linear Space and Faster</title><categories>cs.DS</categories><comments>Minor updates from last time</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two rooted, ordered, and labeled trees $P$ and $T$ the tree inclusion
problem is to determine if $P$ can be obtained from $T$ by deleting nodes in
$T$. This problem has recently been recognized as an important query primitive
in XML databases. Kilpel\&quot;ainen and Mannila [\emph{SIAM J. Comput. 1995}]
presented the first polynomial time algorithm using quadratic time and space.
Since then several improved results have been obtained for special cases when
$P$ and $T$ have a small number of leaves or small depth. However, in the worst
case these algorithms still use quadratic time and space. Let $n_S$, $l_S$, and
$d_S$ denote the number of nodes, the number of leaves, and the %maximum depth
of a tree $S \in \{P, T\}$. In this paper we show that the tree inclusion
problem can be solved in space $O(n_T)$ and time: O(\min(l_Pn_T, l_Pl_T\log
\log n_T + n_T, \frac{n_Pn_T}{\log n_T} + n_{T}\log n_{T})). This improves or
matches the best known time complexities while using only linear space instead
of quadratic. This is particularly important in practical applications, such as
XML databases, where the space is likely to be a bottleneck.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0608125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0608125</id><created>2006-08-31</created><updated>2006-09-11</updated><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Decidability of Type-checking in the Calculus of Algebraic Constructions
  with Size Annotations</title><categories>cs.LO cs.PL</categories><proxy>ccsd inria-00000200</proxy><doi>10.1007/11538363\_11</doi><abstract>  Since Val Tannen's pioneer work on the combination of simply-typed
lambda-calculus and first-order rewriting (LICS'88), many authors have
contributed to this subject by extending it to richer typed lambda-calculi and
rewriting paradigms, culminating in calculi like the Calculus of Algebraic
Constructions. These works provide theoretical foundations for type-theoretic
proof assistants where functions and predicates are defined by oriented
higher-order equations. This kind of definitions subsumes induction-based
definitions, is easier to write and provides more automation. On the other
hand, checking that user-defined rewrite rules are strongly normalizing and
confluent, and preserve the decidability of type-checking when combined with
beta-reduction, is more difficult. Most termination criteria rely on the term
structure. In a previous work, we extended to dependent types and higher-order
rewriting, the notion of ``sized types'' studied by several authors in the
simpler framework of ML-like languages, and proved that it preserves strong
normalization. The main contribution of the present paper is twofold. First, we
prove that, in the Calculus of Algebraic Constructions with size annotations,
the problems of type inference and type-checking are decidable, provided that
the sets of constraints generated by size annotations are satisfiable and admit
most general solutions. Second, we prove the later properties for a size
algebra rich enough for capturing usual induction-based definitions and much
more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609001</identifier>
 <datestamp>2011-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609001</id><created>2006-08-31</created><updated>2011-06-14</updated><authors><author><keyname>Shontz</keyname><forenames>Suzanne M.</forenames></author><author><keyname>Vavasis</keyname><forenames>Stephen A.</forenames></author></authors><title>A Robust Solution Procedure for Hyperelastic Solids with Large Boundary
  Deformation</title><categories>cs.NA cs.CE</categories><comments>Revision of earlier version of paper. Submitted for publication in
  Engineering with Computers on 9 September 2010. Accepted for publication on
  20 May 2011. Published online 11 June 2011. The final publication is
  available at http://www.springerlink.com</comments><acm-class>G.1.0; G.1.5; G.1.8; J.2</acm-class><doi>10.1007/s00366-011-0225-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressible Mooney-Rivlin theory has been used to model hyperelastic solids,
such as rubber and porous polymers, and more recently for the modeling of soft
tissues for biomedical tissues, undergoing large elastic deformations. We
propose a solution procedure for Lagrangian finite element discretization of a
static nonlinear compressible Mooney-Rivlin hyperelastic solid. We consider the
case in which the boundary condition is a large prescribed deformation, so that
mesh tangling becomes an obstacle for straightforward algorithms. Our solution
procedure involves a largely geometric procedure to untangle the mesh: solution
of a sequence of linear systems to obtain initial guesses for interior nodal
positions for which no element is inverted. After the mesh is untangled, we
take Newton iterations to converge to a mechanical equilibrium. The Newton
iterations are safeguarded by a line search similar to one used in
optimization. Our computational results indicate that the algorithm is up to 70
times faster than a straightforward Newton continuation procedure and is also
more robust (i.e., able to tolerate much larger deformations). For a few
extremely large deformations, the deformed mesh could only be computed through
the use of an expensive Newton continuation method while using a tight
convergence tolerance and taking very small steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609002</id><created>2006-09-01</created><updated>2006-09-11</updated><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Kirchner</keyname><forenames>Claude</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Riba</keyname><forenames>Colin</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>On the confluence of lambda-calculus with conditional rewriting</title><categories>cs.LO cs.PL</categories><proxy>ccsd inria-00000729</proxy><doi>10.1007/11690634\_26</doi><abstract>  The confluence of untyped lambda-calculus with unconditional rewriting has
already been studied in various directions. In this paper, we investigate the
confluence of lambda-calculus with conditional rewriting and provide general
results in two directions. First, when conditional rules are algebraic. This
extends results of Muller and Dougherty for unconditional rewriting. Two cases
are considered, whether beta-reduction is allowed or not in the evaluation of
conditions. Moreover, Dougherty's result is improved from the assumption of
strongly normalizing beta-reduction to weakly normalizing beta-reduction. We
also provide examples showing that outside these conditions, modularity of
confluence is difficult to achieve. Second, we go beyond the algebraic
framework and get new confluence results using an extended notion of
orthogonality that takes advantage of the conditional part of rewrite rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609003</id><created>2006-09-02</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>In Quest of Image Semantics: Are We Looking for It Under the Right
  Lamppost?</title><categories>cs.CV cs.IR</categories><comments>In 2006, this paper has been submitted to 13 computer vision
  conferences, and was strongly rejected by 12 of them</comments><abstract>  In the last years we witness a dramatic growth of research focused on
semantic image understanding. Indeed, without understanding image content
successful accomplishment of any image-processing task is simply incredible. Up
to the recent times, the ultimate need for such understanding has been met by
the knowledge that a domain expert or a vision system supervisor have
contributed to every image-processing application. The advent of the Internet
has drastically changed this situation. Internet sources of visual information
are diffused and dispersed over the whole Web, so the duty of information
content discovery and evaluation must be relegated now to an image
understanding agent (a machine or a computer program) capable to perform image
content assessment at a remote image location. Development of Content Based
Image Retrieval (CBIR) techniques was a right move in a right direction,
launched about ten years ago. Unfortunately, very little progress has been made
since then. The reason for this can be seen in a rank of long lasting
misconceptions that CBIR designers are continuing to adhere to. I hope, my
arguments will help them to change their minds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609004</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609004</id><created>2006-09-02</created><updated>2007-05-13</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>Equality of complexity classes P and NP: Linear programming formulation
  of the quadratic assignment problem</title><categories>cs.CC cs.DM</categories><comments>6 pages; Published in the 2006 IMECS Conference Proceedings (ISBN:
  988 98671-3-3); Hofman's claimed &quot;counter-example&quot; is invalid: violates set
  of constraints 2.10</comments><acm-class>F.2.2</acm-class><abstract>  In this paper, we present a polynomial-sized linear programming formulation
of the Quadratic Assignment Problem (QAP). The proposed linear program is a
network flow-based model. Hence, it provides for the solution of the QAP in
polynomial time. Computational testing and results are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609005</identifier>
 <datestamp>2014-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609005</id><created>2006-09-02</created><updated>2014-07-10</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>The traveling salesman problem: A Linear programming formulation</title><categories>cs.CC cs.DM</categories><comments>10 pages; Published in &quot;WSEAS Transactions on Mathematics.&quot;
  Constraints added to rectify minor oversight in proof of proposition 2
  (Theoretical development is same). Hofman's claim of a &quot;counter-example&quot;
  (arXiv cs/0610125 and cs/0611008) is invalid: violates constraints 2.11-2.15</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a polynomial-sized linear programming formulation
of the Traveling Salesman Problem (TSP). The proposed linear program is a
network flow-based model. Numerical implementation issues and results are
discussed. (The exposition and proofs are much more detailed in an edition
which I wrote in collaboration with Dr. M.H. Karwan in 2012-2014 . That edition
is available at
http://users.business.uconn.edu/mdiaby/P=NPProofPapers/tspPaper.pdf)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609006</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609006</id><created>2006-09-02</created><updated>2006-11-20</updated><authors><author><keyname>Chen</keyname><forenames>Eric Zhi</forenames></author></authors><title>New Quasi-Cyclic Codes from Simplex Codes</title><categories>cs.IT math.IT</categories><comments>3 pages</comments><acm-class>E.4</acm-class><abstract>  As a generalization of cyclic codes, quasi-cyclic (QC) codes contain many
good linear codes. But quasi-cyclic codes studied so far are mainly limited to
one generator (1-generator) QC codes. In this correspondence, 2-generator and
3-generator QC codes are studied, and many good, new QC codes are constructed
from simplex codes. Some new binary QC codes or related codes, that improve the
bounds on maximum minimum distance for binary linear codes are constructed.
They are 5-generator QC [93, 17, 34] and [254, 23, 102] codes, and related [96,
17, 36], [256, 23, 104] codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609007</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609007</id><created>2006-09-03</created><authors><author><keyname>Malyshkin</keyname><forenames>Vladislav</forenames></author><author><keyname>Bakhramov</keyname><forenames>Ray</forenames></author><author><keyname>Gorodetsky</keyname><forenames>Andrey</forenames></author></authors><title>A Massive Local Rules Search Approach to the Classification Problem</title><categories>cs.LG</categories><comments>24 pages</comments><abstract>  An approach to the classification problem of machine learning, based on
building local classification rules, is developed. The local rules are
considered as projections of the global classification rules to the event we
want to classify. A massive global optimization algorithm is used for
optimization of quality criterion. The algorithm, which has polynomial
complexity in typical case, is used to find all high--quality local rules. The
other distinctive feature of the algorithm is the integration of attributes
levels selection (for ordered attributes) with rules searching and original
conflicting rules resolution strategy. The algorithm is practical; it was
tested on a number of data sets from UCI repository, and a comparison with the
other predicting techniques is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609008</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609008</id><created>2006-09-04</created><updated>2006-09-29</updated><authors><author><keyname>Demri</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Lazic</keyname><forenames>Ranko</forenames></author><author><keyname>Nowak</keyname><forenames>David</forenames></author></authors><title>On the freeze quantifier in Constraint LTL: decidability and complexity</title><categories>cs.LO cs.CC</categories><comments>29 pages</comments><journal-ref>Information and Computation, 205(1):2-24, January 2007</journal-ref><doi>10.1016/j.ic.2006.08.003</doi><abstract>  Constraint LTL, a generalisation of LTL over Presburger constraints, is often
used as a formal language to specify the behavior of operational models with
constraints. The freeze quantifier can be part of the language, as in some
real-time logics, but this variable-binding mechanism is quite general and
ubiquitous in many logical languages (first-order temporal logics, hybrid
logics, logics for sequence diagrams, navigation logics, logics with
lambda-abstraction etc.). We show that Constraint LTL over the simple domain
(N,=) augmented with the freeze quantifier is undecidable which is a surprising
result in view of the poor language for constraints (only equality tests). Many
versions of freeze-free Constraint LTL are decidable over domains with
qualitative predicates and our undecidability result actually establishes
Sigma_1^1-completeness. On the positive side, we provide complexity results
when the domain is finite (EXPSPACE-completeness) or when the formulae are flat
in a sense introduced in the paper. Our undecidability results are sharp (i.e.
with restrictions on the number of variables) and all our complexity
characterisations ensure completeness with respect to some complexity class
(mainly PSPACE and EXPSPACE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609009</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609009</id><created>2006-09-04</created><authors><author><keyname>Vassilevska</keyname><forenames>Virginia</forenames></author><author><keyname>Williams</keyname><forenames>Ryan</forenames></author><author><keyname>Yuster</keyname><forenames>Raphael</forenames></author></authors><title>Finding heaviest H-subgraphs in real weighted graphs, with applications</title><categories>cs.DS cs.DM</categories><comments>23 pages</comments><abstract>  For a graph G with real weights assigned to the vertices (edges), the MAX
H-SUBGRAPH problem is to find an H-subgraph of G with maximum total weight, if
one exists. The all-pairs MAX H-SUBGRAPH problem is to find for every pair of
vertices u,v, a maximum H-subgraph containing both u and v, if one exists. Our
main results are new strongly polynomial algorithms for the all-pairs MAX
H-SUBGRAPH problem for vertex weighted graphs. We also give improved algorithms
for the MAX-H SUBGRAPH problem for edge weighted graphs, and various related
problems, including computing the first k most significant bits of the distance
product of two matrices. Some of our algorithms are based, in part, on fast
matrix multiplication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609010</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609010</id><created>2006-09-04</created><authors><author><keyname>Rataj</keyname><forenames>Artur</forenames></author></authors><title>An effective edge--directed frequency filter for removal of aliasing in
  upsampled images</title><categories>cs.CV</categories><comments>10 pages, 11 figures</comments><acm-class>I.4.3</acm-class><abstract>  Raster images can have a range of various distortions connected to their
raster structure. Upsampling them might in effect substantially yield the
raster structure of the original image, known as aliasing. The upsampling
itself may introduce aliasing into the upsampled image as well. The presented
method attempts to remove the aliasing using frequency filters based on the
discrete fast Fourier transform, and applied directionally in certain regions
placed along the edges in the image.
  As opposed to some anisotropic smoothing methods, the presented algorithm
aims to selectively reduce only the aliasing, preserving the sharpness of image
details.
  The method can be used as a post--processing filter along with various
upsampling algorithms. It was experimentally shown that the method can improve
the visual quality of the upsampled images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609011</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609011</id><created>2006-09-05</created><authors><author><keyname>Sayee</keyname><forenames>K. C. V. Kalyanarama Sesha</forenames></author></authors><title>Scheduling for Stable and Reliable Communication over Multiaccess
  Channels and Degraded Broadcast Channels</title><categories>cs.NI cs.IT math.IT</categories><comments>Ph.D. Thesis submitted to Department of Electrical Communication
  Engineering at Indian Institute of Science, Bangalore, India</comments><abstract>  Information-theoretic arguments focus on modeling the reliability of
information transmission, assuming availability of infinite data at sources,
thus ignoring randomness in message generation times at the respective sources.
However, in information transport networks, not only is reliable transmission
important, but also stability, i.e., finiteness of mean delay incurred by
messages from the time of generation to the time of successful reception.
Usually, delay analysis is done separately using queueing-theoretic arguments,
whereas reliable information transmission is studied using information theory.
In this thesis, we investigate these two important aspects of data
communication jointly by suitably combining models from these two fields. In
particular, we model scheduled communication of messages, that arrive in a
random process, (i) over multiaccess channels, with either independent decoding
or joint decoding, and (ii) over degraded broadcast channels. The scheduling
policies proposed permit up to a certain maximum number of messages for
simultaneous transmission.
  In the first part of the thesis, we develop a multi-class discrete-time
processor-sharing queueing model, and then investigate the stability of this
queue. In particular, we model the queue by a discrete-time Markov chain
defined on a countable state space, and then establish (i) a sufficient
condition for $c$-regularity of the chain, and hence positive recurrence and
finiteness of stationary mean of the function $c$ of the state, and (ii) a
sufficient condition for transience of the chain. These stability results form
the basis for the conclusions drawn in the thesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609012</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609012</id><created>2006-09-05</created><authors><author><keyname>Moser</keyname><forenames>Philippe</forenames></author></authors><title>Baire Categories on Small Complexity Classes and Meager-Comeager Laws</title><categories>cs.CC</categories><comments>to be published in Inform. and comp</comments><abstract>  We introduce two resource-bounded Baire category notions on small complexity
classes such as P, SUBEXP, and PSPACE and on probabilistic classes such as BPP,
which differ on how the corresponding finite extension strategies are computed.
We give an alternative characterization of small sets via resource-bounded
Banach-Mazur games.
  As an application of the first notion, we show that for almost every language
A (i.e. all except a meager class) computable in subexponential time,
P(A)=BPP(A). We also show that almost all languages in PSPACE do not have small
nonuniform complexity.
  We then switch to the second Baire category notion (called
locally-computable), and show that the class SPARSE is meager in P. We show
that in contrast to the resource-bounded measure case, meager-comeager laws can
be obtained for many standard complexity classes, relative to
locally-computable Baire category on BPP and PSPACE.
  Another topic where locally-computable Baire categories differ from
resource-bounded measure is regarding weak-completeness: we show that there is
no weak-completeness notion in P based on locally-computable Baire categories,
i.e. every P-weakly-complete set is complete for P. We also prove that the
class of complete sets for P under Turing-logspace reductions is meager in P,
if P is not equal to DSPACE(log n), and that the same holds unconditionally for
quasi-poly time.
  Finally we observe that locally-computable Baire categories are incomparable
with all existing resource-bounded measure notions on small complexity classes,
which might explain why those two settings seem to differ so fundamentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609013</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609013</id><created>2006-09-05</created><updated>2006-09-11</updated><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Riba</keyname><forenames>Colin</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Combining typing and size constraints for checking the termination of
  higher-order conditional rewrite systems</title><categories>cs.LO</categories><proxy>ccsd inria-00084837</proxy><journal-ref>Dans 13th International Conference on Logic for Programming,
  Artificial Intelligence and Reasoning - LPAR 2006</journal-ref><abstract>  In a previous work, the first author extended to higher-order rewriting and
dependent types the use of size annotations in types, a termination proof
technique called type or size based termination and initially developed for
ML-like programs. Here, we go one step further by considering conditional
rewriting and explicit quantifications and constraints on size annotations.
This allows to describe more precisely how the size of the output of a function
depends on the size of its inputs. Hence, we can check the termination of more
functions. We first give a general type-checking algorithm based on constraint
solving. Then, we give a termination criterion with constraints in Presburger
arithmetic. To our knowledge, this is the first termination criterion for
higher-order conditional rewriting taking into account the conditions in
termination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609014</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609014</id><created>2006-09-05</created><authors><author><keyname>Reynier</keyname><forenames>Julien</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A simple stability condition for RED using TCP mean-field modeling</title><categories>cs.NI math.PR</categories><proxy>ccsd inria-00091036</proxy><abstract>  Congestion on the Internet is an old problem but still a subject of intensive
research. The TCP protocol with its AIMD (Additive Increase and Multiplicative
Decrease) behavior hides very challenging problems; one of them is to
understand the interaction between a large number of users with delayed
feedback. This article will focus on two modeling issues of TCP which appeared
to be important to tackle concrete scenarios when implementing the model
proposed in [Baccelli McDonald Reynier 02] firstly the modeling of the maximum
TCP window size: this maximum can be reached quickly in many practical cases;
secondly the delay structure: the usual Little-like formula behaves really
poorly when queuing delays are variable, and may change dramatically the
evolution of the predicted queue size, which makes it useless to study
drop-tail or RED (Random Early Detection) mechanisms. Within proposed TCP
modeling improvements, we are enabled to look at a concrete example where RED
should be used in FIFO routers instead of letting the default drop-tail happen.
We study mathematically fixed points of the window size distribution and local
stability of RED. An interesting case is when RED operates at the limit when
the congestion starts, it avoids unwanted loss of bandwidth and delay
variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609015</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609015</id><created>2006-09-05</created><authors><author><keyname>Carme</keyname><forenames>J.</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Gilleron</keyname><forenames>R.</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Lemay</keyname><forenames>A.</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Terlutte</keyname><forenames>A.</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Tommasi</keyname><forenames>M.</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Residual Finite Tree Automata</title><categories>cs.CC cs.LO</categories><proxy>ccsd inria-00091272</proxy><abstract>  Tree automata based algorithms are essential in many fields in computer
science such as verification, specification, program analysis. They become also
essential for databases with the development of standards such as XML. In this
paper, we define new classes of non deterministic tree automata, namely
residual finite tree automata (RFTA). In the bottom-up case, we obtain a new
characterization of regular tree languages. In the top-down case, we obtain a
subclass of regular tree languages which contains the class of languages
recognized by deterministic top-down tree automata. RFTA also come with the
property of existence of canonical non deterministic tree automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609016</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609016</id><created>2006-09-05</created><updated>2006-09-06</updated><authors><author><keyname>Ciszkowski</keyname><forenames>Tomasz</forenames></author><author><keyname>Kotulski</keyname><forenames>Zbigniew</forenames></author></authors><title>ANAP: Anonymous Authentication Protocol in Mobile Ad hoc Networks</title><categories>cs.CR cs.NI</categories><comments>12 pages, 10th Domestic Conference on Applied Cryptography ENIGMA,
  Warsaw, Poland, May 2006, The second author's last name was corrected</comments><acm-class>C.2.1; C.2.2; K.6.5</acm-class><abstract>  The pervasiveness of wireless communication recently gave mobile ad hoc
networks (MANET) a significant researchers' attention, due to its innate
capabilities of instant communication in many time and mission critical
applications. However, its natural advantages of networking in civilian and
military environments make them vulnerable to security threats. Support for an
anonymity in MANET is an orthogonal to security critical challenge we faced in
this paper. We propose a new anonymous authentication protocol for mobile ad
hoc networks enhanced with a distributed reputation system. The main its
objective is to provide mechanisms concealing a real identity of communicating
nodes with an ability of resist to known attacks. The distributed reputation
system is incorporated for a trust management and malicious behavior detection
in the network. The end-to-end anonymous authentication is conducted in
three-pass handshake based on an asymmetric and symmetric key cryptography.
After successfully finished authentication phase secure and multiple anonymous
data channels are established. The anonymity is guarantied by randomly chosen
pseudonyms owned by a user. Nodes of the network are publicly identified and
are independent of users' pseudonyms. In this paper we presented an example of
the protocol implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609017</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609017</id><created>2006-09-05</created><authors><author><keyname>Slany</keyname><forenames>Wolfgang</forenames></author><author><keyname>Kienreich</keyname><forenames>Wolfgang</forenames></author></authors><title>On some winning strategies for the Iterated Prisoner's Dilemma or Mr.
  Nice Guy and the Cosa Nostra</title><categories>cs.GT</categories><abstract>  We submitted two kinds of strategies to the iterated prisoner's dilemma (IPD)
competitions organized by Graham Kendall, Paul Darwen and Xin Yao in 2004 and
2005. Our strategies performed exceedingly well in both years. One type is an
intelligent and optimistic enhanced version of the well known TitForTat
strategy which we named OmegaTitForTat. It recognizes common behaviour patterns
and detects and recovers from repairable mutual defect deadlock situations,
otherwise behaving much like TitForTat. The second type consists of a set of
strategies working together as a team. These group strategies have one
distinguished individual Godfather strategy that plays OmegaTitForTat against
non-members while heavily profiting from the behaviour of the other members of
his group, the Hitman. The Hitman willingly let themselves being abused by
their Godfather while themselves lowering the scores of all other players as
much as possible, thus further maximizing the performance of their Godfather in
relation to other participants. The study of collusion in the simplified
framework of the iterated prisoner's dilemma allows us to draw parallels to
many common aspects of reality both in Nature as well as Human Society, and
therefore further extends the scope of the iterated prisoner's dilemma as a
metaphor for the study of cooperative behaviour in a new and natural direction.
We further provide evidence that it will be unavoidable that such group
strategies will dominate all future iterated prisoner's dilemma competitions as
they can be stealthy camouflaged as non-group strategies with arbitrary
subtlety. Moreover, we show that the general problem of recognizing stealth
colluding strategies is undecidable in the theoretical sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609018</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609018</id><created>2006-09-05</created><authors><author><keyname>Razaghi</keyname><forenames>Peyman</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Bilayer Low-Density Parity-Check Codes for Decode-and-Forward in Relay
  Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Info. Theory</comments><abstract>  This paper describes an efficient implementation of binning for the relay
channel using low-density parity-check (LDPC) codes. We devise bilayer LDPC
codes to approach the theoretically promised rate of the decode-and-forward
relaying strategy by incorporating relay-generated information bits in
specially designed bilayer graphical code structures. While conventional LDPC
codes are sensitively tuned to operate efficiently at a certain channel
parameter, the proposed bilayer LDPC codes are capable of working at two
different channel parameters and two different rates: that at the relay and at
the destination. To analyze the performance of bilayer LDPC codes, bilayer
density evolution is devised as an extension of the standard density evolution
algorithm. Based on bilayer density evolution, a design methodology is
developed for the bilayer codes in which the degree distribution is iteratively
improved using linear programming. Further, in order to approach the
theoretical decode-and-forward rate for a wide range of channel parameters,
this paper proposes two different forms bilayer codes, the bilayer-expurgated
and bilayer-lengthened codes. It is demonstrated that a properly designed
bilayer LDPC code can achieve an asymptotic infinite-length threshold within
0.24 dB gap to the Shannon limits of two different channels simultaneously for
a wide range of channel parameters. By practical code construction,
finite-length bilayer codes are shown to be able to approach within a 0.6 dB
gap to the theoretical decode-and-forward rate of the relay channel at a block
length of $10^5$ and a bit-error probability (BER) of $10^{-4}$. Finally, it is
demonstrated that a generalized version of the proposed bilayer code
construction is applicable to relay networks with multiple relays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609019</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609019</id><created>2006-09-06</created><authors><author><keyname>Aubin</keyname><forenames>Sophie</forenames><affiliation>LIPN</affiliation></author><author><keyname>Hamon</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author></authors><title>Improving Term Extraction with Terminological Resources</title><categories>cs.CL</categories><proxy>ccsd ccsd-00091444</proxy><journal-ref>Advances in Natural Language Processing 5th International
  Conference on NLP, FinTAL 2006 (2006) 380</journal-ref><abstract>  Studies of different term extractors on a corpus of the biomedical domain
revealed decreasing performances when applied to highly technical texts. The
difficulty or impossibility of customising them to new domains is an additional
limitation. In this paper, we propose to use external terminologies to
influence generic linguistic data in order to augment the quality of the
extraction. The tool we implemented exploits testified terms at different steps
of the process: chunking, parsing and extraction of term candidates.
Experiments reported here show that, using this method, more term candidates
can be acquired with a higher level of reliability. We further describe the
extraction process involving endogenous disambiguation implemented in the term
extractor YaTeA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609020</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609020</id><created>2006-09-06</created><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Morain</keyname><forenames>Francois</forenames><affiliation>LIX, INRIA Futurs</affiliation></author><author><keyname>Schost</keyname><forenames>Eric</forenames><affiliation>LIX</affiliation></author></authors><title>Fast algorithms for computing isogenies between elliptic curves</title><categories>cs.CC cs.SC math.NT</categories><proxy>ccsd inria-00091441</proxy><doi>10.1090/S0025-5718-08-02066-8</doi><abstract>  We survey algorithms for computing isogenies between elliptic curves defined
over a field of characteristic either 0 or a large prime. We introduce a new
algorithm that computes an isogeny of degree $\ell$ ($\ell$ different from the
characteristic) in time quasi-linear with respect to $\ell$. This is based in
particular on fast algorithms for power series expansion of the Weierstrass
$\wp$-function and related functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609021</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609021</id><created>2006-09-06</created><authors><author><keyname>Boudes</keyname><forenames>Pierre</forenames><affiliation>LIPN</affiliation></author></authors><title>Non uniform (hyper/multi)coherence spaces</title><categories>cs.LO</categories><comments>32 pages</comments><proxy>ccsd ccsd-00091450</proxy><acm-class>F.3.2</acm-class><abstract>  In (hyper)coherence semantics, proofs/terms are cliques in (hyper)graphs.
Intuitively, vertices represent results of computations and the edge relation
witnesses the ability of being assembled into a same piece of data or a same
(strongly) stable function, at arrow types. In (hyper)coherence semantics, the
argument of a (strongly) stable functional is always a (strongly) stable
function. As a consequence, comparatively to the relational semantics, where
there is no edge relation, some vertices are missing. Recovering these vertices
is essential for the purpose of reconstructing proofs/terms from their
interpretations. It shall also be useful for the comparison with other
semantics, like game semantics. In [BE01], Bucciarelli and Ehrhard introduced a
so called non uniform coherence space semantics where no vertex is missing. By
constructing the co-free exponential we set a new version of this last
semantics, together with non uniform versions of hypercoherences and
multicoherences, a new semantics where an edge is a finite multiset. Thanks to
the co-free construction, these non uniform semantics are deterministic in the
sense that the intersection of a clique and of an anti-clique contains at most
one vertex, a result of interaction, and extensionally collapse onto the
corresponding uniform semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609022</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609022</id><created>2006-09-06</created><updated>2006-11-28</updated><authors><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author></authors><title>Dichotomies and Duality in First-order Model Checking Problems</title><categories>cs.LO cs.CC</categories><abstract>  We study the complexity of the model checking problem, for fixed model A,
over certain fragments L of first-order logic. These are sometimes known as the
expression complexities of L. We obtain various complexity classification
theorems for these logics L as each ranges over models A, in the spirit of the
dichotomy conjecture for the Constraint Satisfaction Problem -- which itself
may be seen as the model checking problem for existential conjunctive positive
first-order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609023</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609023</id><created>2006-09-06</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Srinivas</keyname><forenames>M. B.</forenames></author></authors><title>Novel Reversible TSG Gate and Its Application for Designing Components
  of Primitive Reversible/Quantum ALU</title><categories>cs.AR</categories><comments>5 Pages; Published in Proceedings of the Fifth IEEE International
  Conference on Information, Communications and Signal Processing (ICICS 2005),
  Bangkok, Thailand, 6-9 December 2005,pp.1425-1429</comments><abstract>  In recent years, reversible logic has emerged as a promising computing
paradigm having application in low power CMOS, quantum computing,
nanotechnology, and optical computing. The classical set of gates such as AND,
OR, and EXOR are not reversible. This paper utilizes a new 4 * 4 reversible
gate called TSG gate to build the components of a primitive reversible/quantum
ALU. The most significant aspect of the TSG gate is that it can work singly as
a reversible full adder, that is reversible full adder can now be implemented
with a single gate only. A Novel reversible 4:2 compressor is also designed
from the TSG gate which is later used to design a novel 8x8 reversible Wallace
tree multiplier. It is proved that the adder, 4:2 compressor and multiplier
architectures designed using the TSG gate are better than their counterparts
available in literature, in terms of number of reversible gates and garbage
outputs. This is perhaps, the first attempt to design a reversible 4:2
compressor and a reversible Wallace tree multiplier as far as existing
literature and our knowledge is concerned. Thus, this paper provides an initial
threshold to build more complex systems which can execute complicated
operations using reversible logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609024</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609024</id><created>2006-09-06</created><updated>2007-01-11</updated><authors><author><keyname>Prashant</keyname></author></authors><title>Linux, Open Source and Unicode</title><categories>cs.SE</categories><comments>10 pages, 1 figure, 1 table</comments><abstract>  The paper is taken out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609025</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609025</id><created>2006-09-06</created><updated>2007-01-11</updated><authors><author><keyname>Prashant</keyname></author></authors><title>A XML Schema Definition based Universal User Interface</title><categories>cs.SE</categories><comments>6 pages, 5 figures</comments><abstract>  The article is taken out for change of contents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609026</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609026</id><created>2006-09-06</created><authors><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Urvoy-Keller</keyname><forenames>Guillaume</forenames><affiliation>EURECOM</affiliation></author><author><keyname>Michiardi</keyname><forenames>Pietro</forenames><affiliation>EURECOM</affiliation></author></authors><title>Rarest First and Choke Algorithms Are Enough</title><categories>cs.NI</categories><proxy>ccsd inria-00091678</proxy><journal-ref>Dans ACM SIGCOMM/USENIX IMC'2006</journal-ref><abstract>  The performance of peer-to-peer file replication comes from its piece and
peer selection strategies. Two such strategies have been introduced by the
BitTorrent protocol: the rarest first and choke algorithms. Whereas it is
commonly admitted that BitTorrent performs well, recent studies have proposed
the replacement of the rarest first and choke algorithms in order to improve
efficiency and fairness. In this paper, we use results from real experiments to
advocate that the replacement of the rarest first and choke algorithms cannot
be justified in the context of peer-to-peer file replication in the Internet.
We instrumented a BitTorrent client and ran experiments on real torrents with
different characteristics. Our experimental evaluation is peer oriented,
instead of tracker oriented, which allows us to get detailed information on all
exchanged messages and protocol events. We go beyond the mere observation of
the good efficiency of both algorithms. We show that the rarest first algorithm
guarantees close to ideal diversity of the pieces among peers. In particular,
on our experiments, replacing the rarest first algorithm with source or network
coding solutions cannot be justified. We also show that the choke algorithm in
its latest version fosters reciprocation and is robust to free riders. In
particular, the choke algorithm is fair and its replacement with a bit level
tit-for-tat solution is not appropriate. Finally, we identify new areas of
improvements for efficient peer-to-peer file replication protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609027</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609027</id><created>2006-09-06</created><authors><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Pathan</keyname><forenames>Al-Mukaddim Khan</forenames></author><author><keyname>Broberg</keyname><forenames>James</forenames></author><author><keyname>Tari</keyname><forenames>Zahir</forenames></author></authors><title>A Case for Peering of Content Delivery Networks</title><categories>cs.DC</categories><comments>Short Article (Submitted in DS Online as Work in Progress)</comments><abstract>  The proliferation of Content Delivery Networks (CDN) reveals that existing
content networks are owned and operated by individual companies. As a
consequence, closed delivery networks are evolved which do not cooperate with
other CDNs and in practice, islands of CDNs are formed. Moreover, the logical
separation between contents and services in this context results in two content
networking domains. But present trends in content networks and content
networking capabilities give rise to the interest in interconnecting content
networks. Finding ways for distinct content networks to coordinate and
cooperate with other content networks is necessary for better overall service.
In addition to that, meeting the QoS requirements of users according to the
negotiated Service Level Agreements between the user and the content network is
a burning issue in this perspective. In this article, we present an open,
scalable and Service-Oriented Architecture based system to assist the creation
of open Content and Service Delivery Networks (CSDN) that scale and support
sharing of resources with other CSDNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609028</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609028</id><created>2006-09-07</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Srinivas</keyname><forenames>M. B</forenames></author></authors><title>VLSI Implementation of RSA Encryption System Using Ancient Indian Vedic
  Mathematics</title><categories>cs.AR</categories><comments>5 Pages: Proceedings of SPIE -- Volume 5837 VLSI Circuits and Systems
  II, Jose F. Lopez, Francisco V. Fernandez, Jose Maria Lopez-Villegas, Jose M.
  de la Rosa, Editors, June 2005, pp. 888-892</comments><abstract>  This paper proposes the hardware implementation of RSA encryption/decryption
algorithm using the algorithms of Ancient Indian Vedic Mathematics that have
been modified to improve performance. The recently proposed hierarchical
overlay multiplier architecture is used in the RSA circuitry for multiplication
operation. The most significant aspect of the paper is the development of a
division architecture based on Straight Division algorithm of Ancient Indian
Vedic Mathematics and embedding it in RSA encryption/decryption circuitry for
improved efficiency. The coding is done in Verilog HDL and the FPGA synthesis
is done using Xilinx Spartan library. The results show that RSA circuitry
implemented using Vedic division and multiplication is efficient in terms of
area/speed compared to its implementation using conventional multiplication and
division architectures
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609029</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609029</id><created>2006-09-07</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Arabnia</keyname><forenames>Hamid R.</forenames></author></authors><title>Reversible Programmable Logic Array (RPLA) using Fredkin &amp; Feynman Gates
  for Industrial Electronics and Applications</title><categories>cs.AR</categories><comments>Published in Proceedings of the International Conference on Embedded
  Systems and Applications(ESA'06),Las Vegas, U.S.A, June 2006(CSREA Press)</comments><abstract>  In recent years, reversible logic has emerged as a promising computing
paradigm having application in low power CMOS, quantum computing,
nanotechnology, and optical computing. The classical set of gates such as AND,
OR, and EXOR are not reversible. In this paper, the authors have proposed
reversible programmable logic array (RPLA) architecture using reversible
Fredkin and Feynman gates. The proposed RPLA has n inputs and m outputs and can
realize m functions of n variables. In order to demonstrate the design of RPLA,
a 3 input RPLA is designed which can perform any 28 functions using the
combination of 8 min terms (23). Furthermore, the application of the designed 3
input RPLA is shown by implementing the full adder and full subtractor
functions through it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609030</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609030</id><created>2006-09-07</created><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Heath,</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Space Division Multiple Access with a Sum Feedback Rate Constraint</title><categories>cs.IT cs.NI math.IT</categories><comments>29 pages; submitted to IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2007.894245</doi><abstract>  On a multi-antenna broadcast channel, simultaneous transmission to multiple
users by joint beamforming and scheduling is capable of achieving high
throughput, which grows double logarithmically with the number of users. The
sum rate for channel state information (CSI) feedback, however, increases
linearly with the number of users, reducing the effective uplink capacity. To
address this problem, a novel space division multiple access (SDMA) design is
proposed, where the sum feedback rate is upper-bounded by a constant. This
design consists of algorithms for CSI quantization, threshold based CSI
feedback, and joint beamforming and scheduling. The key feature of the proposed
approach is the use of feedback thresholds to select feedback users with large
channel gains and small CSI quantization errors such that the sum feedback rate
constraint is satisfied. Despite this constraint, the proposed SDMA design is
shown to achieve a sum capacity growth rate close to the optimal one. Moreover,
the feedback overflow probability for this design is found to decrease
exponentially with the difference between the allowable and the average sum
feedback rates. Numerical results show that the proposed SDMA design is capable
of attaining higher sum capacities than existing ones, even though the sum
feedback rate is bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609031</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609031</id><created>2006-09-07</created><updated>2006-09-26</updated><authors><author><keyname>Kenkre</keyname><forenames>Sreyash</forenames></author><author><keyname>Vishwanathan</keyname><forenames>Sundar</forenames></author></authors><title>Approximation Algorithms for the Bipartite Multi-cut Problem</title><categories>cs.CC cs.DS</categories><comments>11 pages</comments><abstract>  We introduce the {\it Bipartite Multi-cut} problem. This is a generalization
of the {\it st-Min-cut} problem, is similar to the {\it Multi-cut} problem
(except for more stringent requirements) and also turns out to be an immediate
generalization of the {\it Min UnCut} problem. We prove that this problem is
{\bf NP}-hard and then present LP and SDP based approximation algorithms. While
the LP algorithm is based on the Garg-Vazirani-Yannakakis algorithm for {\it
Multi-cut}, the SDP algorithm uses the {\it Structure Theorem} of $\ell_2^2$
Metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609032</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609032</id><created>2006-09-07</created><updated>2006-10-10</updated><authors><author><keyname>Ganguly</keyname><forenames>Sumit</forenames></author><author><keyname>Majumder</keyname><forenames>Anirban</forenames></author></authors><title>CR-precis: A deterministic summary structure for update data streams</title><categories>cs.DS</categories><comments>11 pages</comments><report-no>IIT Kanpur, July 1 2006</report-no><acm-class>F.2.2</acm-class><abstract>  We present the \crprecis structure, that is a general-purpose, deterministic
and sub-linear data structure for summarizing \emph{update} data streams. The
\crprecis structure yields the \emph{first deterministic sub-linear space/time
algorithms for update streams} for answering a variety of fundamental stream
queries, such as, (a) point queries, (b) range queries, (c) finding approximate
frequent items, (d) finding approximate quantiles, (e) finding approximate
hierarchical heavy hitters, (f) estimating inner-products, (g) near-optimal
$B$-bucket histograms, etc..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609033</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609033</id><created>2006-09-07</created><authors><author><keyname>Dillencourt</keyname><forenames>Michael B.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Choosing Colors for Geometric Graphs via Color Space Embeddings</title><categories>cs.CG</categories><comments>12 pages, 4 figures. To appear at 14th Int. Symp. Graph Drawing, 2006</comments><acm-class>G.1.6</acm-class><abstract>  Graph drawing research traditionally focuses on producing geometric
embeddings of graphs satisfying various aesthetic constraints. After the
geometric embedding is specified, there is an additional step that is often
overlooked or ignored: assigning display colors to the graph's vertices. We
study the additional aesthetic criterion of assigning distinct colors to
vertices of a geometric graph so that the colors assigned to adjacent vertices
are as different from one another as possible. We formulate this as a problem
involving perceptual metrics in color space and we develop algorithms for
solving this problem by embedding the graph in color space. We also present an
application of this work to a distributed load-balancing visualization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609034</identifier>
 <datestamp>2009-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609034</id><created>2006-09-07</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>Social Decision Making with Multi-Relational Networks and Grammar-Based
  Particle Swarms</title><categories>cs.CY cs.HC</categories><report-no>LA-UR-06-2139</report-no><journal-ref>Hawaii International Conference on Systems Science (HICSS), pages
  39-49, Waikoloa, Hawaii, IEEE Computer Society, ISSN: 1530-1605, January 2007</journal-ref><doi>10.1109/HICSS.2007.487</doi><abstract>  Social decision support systems are able to aggregate the local perspectives
of a diverse group of individuals into a global social decision. This paper
presents a multi-relational network ontology and grammar-based particle swarm
algorithm capable of aggregating the decisions of millions of individuals. This
framework supports a diverse problem space and a broad range of vote
aggregation algorithms. These algorithms account for individual expertise and
representation across different domains of the group problem space. Individuals
are able to pose and categorize problems, generate potential solutions, choose
trusted representatives, and vote for particular solutions. Ultimately, via a
social decision making algorithm, the system aggregates all the individual
votes into a single collective decision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609035</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609035</id><created>2006-09-07</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Teague</keyname><forenames>Vanessa</forenames></author></authors><title>Rational Secret Sharing and Multiparty Computation: Extended Abstract</title><categories>cs.GT cs.CR cs.DC</categories><comments>Appears in STOC, 2004</comments><acm-class>F.m</acm-class><abstract>  We consider the problems of secret sharing and multiparty computation,
assuming that agents prefer to get the secret (resp., function value) to not
getting it, and secondarily, prefer that as few as possible of the other agents
get it. We show that, under these assumptions, neither secret sharing nor
multiparty function computation is possible using a mechanism that has a fixed
running time. However, we show that both are possible using randomized
mechanisms with constant expected running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609036</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609036</id><created>2006-09-08</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Arabnia</keyname><forenames>Hamid R.</forenames></author><author><keyname>Srinivas</keyname><forenames>M. B</forenames></author></authors><title>Reduced Area Low Power High Throughput BCD Adders for IEEE 754r Format</title><categories>cs.AR</categories><comments>6 Pages;Published in Proceedings of the 11th International CSI
  Computer Conference (CSICC'06), Tehran, Jan 24-26, 2006, pp.59-64</comments><abstract>  IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and
a major enhancement to the standard is the addition of decimal format. Firstly,
this paper proposes novel two transistor AND and OR gates. The proposed AND
gate has no power supply, thus it can be referred as the Powerless AND gate.
Similarly, the proposed two transistor OR gate has no ground and can be
referred as Groundless OR. Secondly for IEEE 754r format, two novel BCD adders
called carry skip and carry look-ahead BCD adders are also proposed in this
paper. In order to design the carry look-ahead BCD adder, a novel 4 bit carry
look-ahead adder called NCLA is proposed which forms the basic building block
of the proposed carry look-ahead BCD adder. Finally, the proposed two
transistors AND and OR gates are used to provide the optimized small area low
power high throughput circuitries of the proposed BCD adders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609037</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609037</id><created>2006-09-08</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>(HO)RPO Revisited</title><categories>cs.LO</categories><proxy>ccsd inria-00090488</proxy><abstract>  The notion of computability closure has been introduced for proving the
termination of the combination of higher-order rewriting and beta-reduction. It
is also used for strengthening the higher-order recursive path ordering. In the
present paper, we study in more details the relations between the computability
closure and the (higher-order) recursive path ordering. We show that the
first-order recursive path ordering is equal to an ordering naturally defined
from the computability closure. In the higher-order case, we get an ordering
containing the higher-order recursive path ordering whose well-foundedness
relies on the correctness of the computability closure. This provides a simple
way to extend the higher-order recursive path ordering to richer type systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609038</identifier>
 <datestamp>2013-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609038</id><created>2006-09-08</created><authors><author><keyname>Blaszczyszyn</keyname><forenames>Bartlomiej Bartek</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Radunovic</keyname><forenames>Bozidar</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>On Performance of Event-to-Sink Transport in Transmit-Only Sensor
  Networks</title><categories>cs.NI math.PR</categories><proxy>ccsd inria-00092002</proxy><journal-ref>Proc. of IEEE Infocom 2008</journal-ref><doi>10.1109/INFOCOM.2008.176</doi><abstract>  We consider a hybrid wireless sensor network with regular and transmit-only
sensors. The transmit-only sensors do not have receiver circuit, hence are
cheaper and less energy consuming, but their transmissions cannot be
coordinated. Regular sensors, also called cluster-heads, are responsible for
receiving information from transmit-only sensors and forwarding it to sinks.
The main goal of such a hybrid network is to reduce the cost of deployment
while achieving some performance constraints (minimum coverage, sensing rate,
etc). In this paper we are interested in the communication between
transmit-only sensors and cluster-heads. We develop a detailed analytical model
of the physical and MAC layer using tools from queuing theory and stochastic
geometry. (The MAC model, that we call Erlang's loss model with interference,
might be of independent interest as adequate for any non-slotted; i.e.,
unsynchronized, wireless communication channel.) We give an explicit formula
for the frequency of successful packet reception by a cluster-head, given
sensors' locations. We further define packet admission policies at a
cluster-head, and we calculate the optimal policies for different performance
criteria. Finally we show that the proposed hybrid network, using the optimal
policies, can achieve substantial cost savings as compared to conventional
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609039</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609039</id><created>2006-09-08</created><updated>2007-01-05</updated><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Jouannaud</keyname><forenames>Jean-Pierre</forenames><affiliation>LIX</affiliation></author><author><keyname>Rubio</keyname><forenames>Albert</forenames></author></authors><title>Higher-Order Termination: from Kruskal to Computability</title><categories>cs.LO</categories><proxy>ccsd inria-00091308</proxy><journal-ref>Dans 13th International Conference on Logic for Programming,
  Artificial Intelligence and Reasoning - LPAR 2006 4246 (2006)</journal-ref><doi>10.1007/11916277_1</doi><abstract>  Termination is a major question in both logic and computer science. In logic,
termination is at the heart of proof theory where it is usually called strong
normalization (of cut elimination). In computer science, termination has always
been an important issue for showing programs correct. In the early days of
logic, strong normalization was usually shown by assigning ordinals to
expressions in such a way that eliminating a cut would yield an expression with
a smaller ordinal. In the early days of verification, computer scientists used
similar ideas, interpreting the arguments of a program call by a natural
number, such as their size. Showing the size of the arguments to decrease for
each recursive call gives a termination proof of the program, which is however
rather weak since it can only yield quite small ordinals. In the sixties, Tait
invented a new method for showing cut elimination of natural deduction, based
on a predicate over the set of terms, such that the membership of an expression
to the predicate implied the strong normalization property for that expression.
The predicate being defined by induction on types, or even as a fixpoint, this
method could yield much larger ordinals. Later generalized by Girard under the
name of reducibility or computability candidates, it showed very effective in
proving the strong normalization property of typed lambda-calculi...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609040</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609040</id><created>2006-09-08</created><updated>2006-11-08</updated><authors><author><keyname>Adamek</keyname><forenames>Jiri</forenames></author><author><keyname>Milius</keyname><forenames>Stefan</forenames></author><author><keyname>Velebil</keyname><forenames>Jiri</forenames></author></authors><title>Elgot Algebras</title><categories>cs.LO math.CT</categories><acm-class>F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 5 (November
  8, 2006) lmcs:1176</journal-ref><doi>10.2168/LMCS-2(5:4)2006</doi><abstract>  Denotational semantics can be based on algebras with additional structure
(order, metric, etc.) which makes it possible to interpret recursive
specifications. It was the idea of Elgot to base denotational semantics on
iterative theories instead, i.e., theories in which abstract recursive
specifications are required to have unique solutions. Later Bloom and Esik
studied iteration theories and iteration algebras in which a specified solution
has to obey certain axioms. We propose so-called Elgot algebras as a convenient
structure for semantics in the present paper. An Elgot algebra is an algebra
with a specified solution for every system of flat recursive equations. That
specification satisfies two simple and well motivated axioms: functoriality
(stating that solutions are stable under renaming of recursion variables) and
compositionality (stating how to perform simultaneous recursion). These two
axioms stem canonically from Elgot's iterative theories: We prove that the
category of Elgot algebras is the Eilenberg-Moore category of the monad given
by a free iterative theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609041</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609041</id><created>2006-09-08</created><authors><author><keyname>Hendrickx</keyname><forenames>Julien M.</forenames></author><author><keyname>Fidan</keyname><forenames>Baris</forenames></author><author><keyname>Yu</keyname><forenames>Changbin</forenames></author><author><keyname>Anderson</keyname><forenames>Brian D. O.</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author></authors><title>Primitive operations for the construction and reorganization of
  minimally persistent formations</title><categories>cs.MA</categories><comments>26 pages, 31 .eps files for the figures</comments><report-no>CESAME research report 2006.62</report-no><abstract>  In this paper, we study the construction and transformation of
two-dimensional persistent graphs. Persistence is a generalization to directed
graphs of the undirected notion of rigidity. In the context of moving
autonomous agent formations, persistence characterizes the efficacy of a
directed structure of unilateral distances constraints seeking to preserve a
formation shape. Analogously to the powerful results about Henneberg sequences
in minimal rigidity theory, we propose different types of directed graph
operations allowing one to sequentially build any minimally persistent graph
(i.e. persistent graph with a minimal number of edges for a given number of
vertices), each intermediate graph being also minimally persistent. We also
consider the more generic problem of obtaining one minimally persistent graph
from another, which corresponds to the on-line reorganization of an autonomous
agent formation. We prove that we can obtain any minimally persistent formation
from any other one by a sequence of elementary local operations such that
minimal persistence is preserved throughout the reorganization process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609042</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609042</id><created>2006-09-08</created><authors><author><keyname>Binia</keyname><forenames>Jacob</forenames></author></authors><title>On Divergence-Power Inequalities</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  Expressions for (EPI Shannon type) Divergence-Power Inequalities (DPI) in two
cases (time-discrete and band-limited time-continuous) of stationary random
processes are given. The new expressions connect the divergence rate of the sum
of independent processes, the individual divergence rate of each process, and
their power spectral densities. All divergences are between a process and a
Gaussian process with same second order statistics, and are assumed to be
finite. A new proof of the Shannon entropy-power inequality EPI, based on the
relationship between divergence and causal minimum mean-square error (CMMSE) in
Gaussian channels with large signal-to-noise ratio, is also shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609043</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609043</id><created>2006-09-08</created><authors><author><keyname>Gayral</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>LIPN</affiliation></author><author><keyname>Kayser</keyname><forenames>Daniel</forenames><affiliation>LIPN</affiliation></author><author><keyname>L&#xe9;vy</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIPN</affiliation></author></authors><title>Challenging the principle of compositionality in interpreting natural
  language texts</title><categories>cs.CL</categories><proxy>ccsd ccsd-00092218</proxy><journal-ref>conference on Compositionality, Concepts and Cognition, Allemagne
  (2004)</journal-ref><abstract>  The paper aims at emphasizing that, even relaxed, the hypothesis of
compositionality has to face many problems when used for interpreting natural
language texts. Rather than fixing these problems within the compositional
framework, we believe that a more radical change is necessary, and propose
another approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609044</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609044</id><created>2006-09-08</created><authors><author><keyname>Gayral</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>LIPN</affiliation></author><author><keyname>Kayser</keyname><forenames>Daniel</forenames><affiliation>LIPN</affiliation></author><author><keyname>L&#xe9;vy</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIPN</affiliation></author></authors><title>The role of time in considering collections</title><categories>cs.CL</categories><proxy>ccsd ccsd-00092223</proxy><journal-ref>Journ\'{e}es de S\'{e}mantique et Mod\'{e}lisation, France (2004)</journal-ref><abstract>  The paper concerns the understanding of plurals in the framework of
Artificial Intelligence and emphasizes the role of time. The construction of
collection(s) and their evolution across time is often crucial and has to be
accounted for. The paper contrasts a &quot;de dicto&quot; collection where the collection
can be considered as persisting over these situations even if its members
change with a &quot;de re&quot; collection whose composition does not vary through time.
It expresses different criteria of choice between the two interpretations (de
re and de dicto) depending on the context of enunciation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609045</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609045</id><created>2006-09-09</created><authors><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Metric entropy in competitive on-line prediction</title><categories>cs.LG</categories><comments>41 pages</comments><abstract>  Competitive on-line prediction (also known as universal prediction of
individual sequences) is a strand of learning theory avoiding making any
stochastic assumptions about the way the observations are generated. The
predictor's goal is to compete with a benchmark class of prediction rules,
which is often a proper Banach function space. Metric entropy provides a
unifying framework for competitive on-line prediction: the numerous known upper
bounds on the metric entropy of various compact sets in function spaces readily
imply bounds on the performance of on-line prediction strategies. This paper
discusses strengths and limitations of the direct approach to competitive
on-line prediction via metric entropy, including comparisons to other
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609046</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609046</id><created>2006-09-10</created><authors><author><keyname>Wang</keyname><forenames>Chih-Chun</forenames><affiliation>Purdue University</affiliation></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Princeton University</affiliation></author></authors><title>Exhausting Error-Prone Patterns in LDPC Codes</title><categories>cs.IT cs.DS math.IT</categories><comments>submitted to IEEE Trans. Information Theory</comments><abstract>  It is proved in this work that exhaustively determining bad patterns in
arbitrary, finite low-density parity-check (LDPC) codes, including stopping
sets for binary erasure channels (BECs) and trapping sets (also known as
near-codewords) for general memoryless symmetric channels, is an NP-complete
problem, and efficient algorithms are provided for codes of practical short
lengths n~=500. By exploiting the sparse connectivity of LDPC codes, the
stopping sets of size &lt;=13 and the trapping sets of size &lt;=11 can be
efficiently exhaustively determined for the first time, and the resulting
exhaustive list is of great importance for code analysis and finite code
optimization. The featured tree-based narrowing search distinguishes this
algorithm from existing ones for which inexhaustive methods are employed. One
important byproduct is a pair of upper bounds on the bit-error rate (BER) &amp;
frame-error rate (FER) iterative decoding performance of arbitrary codes over
BECs that can be evaluated for any value of the erasure probability, including
both the waterfall and the error floor regions. The tightness of these upper
bounds and the exhaustion capability of the proposed algorithm are proved when
combining an optimal leaf-finding module with the tree-based search. These
upper bounds also provide a worst-case-performance guarantee which is crucial
to optimizing LDPC codes for extremely low error rate applications, e.g.,
optical/satellite communications. Extensive numerical experiments are conducted
that include both randomly and algebraically constructed LDPC codes, the
results of which demonstrate the superior efficiency of the exhaustion
algorithm and its significant value for finite length code optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609047</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609047</id><created>2006-09-10</created><authors><author><keyname>Alam</keyname><forenames>S. M. Nazrul</forenames></author><author><keyname>Haas</keyname><forenames>Zygmunt J.</forenames></author></authors><title>Topology Control and Network Lifetime in Three-Dimensional Wireless
  Sensor Networks</title><categories>cs.NI cs.CG</categories><comments>Submitted for publication</comments><acm-class>C.2.1</acm-class><abstract>  Coverage and connectivity issues of three-dimensional (3D) networks are
addressed in [2], but that work assumes that a node can be placed at any
arbitrary location. In this work, we drop that assumption and rather assume
that nodes are uniformly and densely deployed in a 3D space. We want to devise
a mechanism that keeps some nodes active and puts other nodes into sleep so
that the number of active nodes at a time is minimized (and thus network life
time is maximized), while maintaining full coverage and connectivity. One
simple way to do that is to partition the 3D space into cells, and only one
node in each cell remains active at a time. Our results show that the number of
active nodes can be minimized if the shape of each cell is a truncated
octahedron. It requires the sensing range to be at least 0.542326 times the
transmission radius. This value is 0.5, 0.53452 and 0.5 for cube, hexagonal
prism, and rhombic dodecahedron, respectively. However, at a time the number of
active nodes for cube, hexagonal prism and rhombic dodecahedron model is
respectively 2.372239, 1.82615 and 1.49468 times of that of truncated
octahedron model. So clearly truncated octahedron model has the highest network
lifetime. We also provide a distributed topology control algorithm that can be
used by each sensor node to determine its cell id using a constant number of
local arithmetic operations provided that the sensor node knows its location.
We also validate our results by simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609048</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609048</id><created>2006-09-11</created><authors><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI</affiliation></author></authors><title>On the logical definability of certain graph and poset languages</title><categories>cs.LO</categories><proxy>ccsd ccsd-00092417</proxy><journal-ref>Journal of Automata, Languages and Computation 9 (2004) 147-165</journal-ref><abstract>  We show that it is equivalent, for certain sets of finite graphs, to be
definable in CMS (counting monadic second-order logic, a natural extension of
monadic second-order logic), and to be recognizable in an algebraic framework
induced by the notion of modular decomposition of a finite graph. More
precisely, we consider the set $F\_\infty$ of composition operations on graphs
which occur in the modular decomposition of finite graphs. If $F$ is a subset
of $F\_{\infty}$, we say that a graph is an $\calF$-graph if it can be
decomposed using only operations in $F$. A set of $F$-graphs is recognizable if
it is a union of classes in a finite-index equivalence relation which is
preserved by the operations in $F$. We show that if $F$ is finite and its
elements enjoy only a limited amount of commutativity -- a property which we
call weak rigidity, then recognizability is equivalent to CMS-definability.
This requirement is weak enough to be satisfied whenever all $F$-graphs are
posets, that is, transitive dags. In particular, our result generalizes Kuske's
recent result on series-parallel poset languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609049</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609049</id><created>2006-09-11</created><updated>2007-05-08</updated><authors><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Scanning and Sequential Decision Making for Multi-Dimensional Data -
  Part I: the Noiseless Case</title><categories>cs.IT cs.LG math.IT</categories><comments>46 pages, 2 figures. Revised version: title changed, section 1
  revised, section 3.1 added, a few minor/technical corrections made</comments><acm-class>H.1.1; I.2.6</acm-class><abstract>  We investigate the problem of scanning and prediction (&quot;scandiction&quot;, for
short) of multidimensional data arrays. This problem arises in several aspects
of image and video processing, such as predictive coding, for example, where an
image is compressed by coding the error sequence resulting from scandicting it.
Thus, it is natural to ask what is the optimal method to scan and predict a
given image, what is the resulting minimum prediction loss, and whether there
exist specific scandiction schemes which are universal in some sense.
  Specifically, we investigate the following problems: First, modeling the data
array as a random field, we wish to examine whether there exists a scandiction
scheme which is independent of the field's distribution, yet asymptotically
achieves the same performance as if this distribution was known. This question
is answered in the affirmative for the set of all spatially stationary random
fields and under mild conditions on the loss function. We then discuss the
scenario where a non-optimal scanning order is used, yet accompanied by an
optimal predictor, and derive bounds on the excess loss compared to optimal
scanning and prediction.
  This paper is the first part of a two-part paper on sequential decision
making for multi-dimensional data. It deals with clean, noiseless data arrays.
The second part deals with noisy data arrays, namely, with the case where the
decision maker observes only a noisy version of the data, yet it is judged with
respect to the original, clean data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609050</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609050</id><created>2006-09-11</created><authors><author><keyname>Cariolaro</keyname><forenames>G.</forenames></author><author><keyname>Erseghe</keyname><forenames>T.</forenames></author><author><keyname>Laurenti</keyname><forenames>N.</forenames></author></authors><title>Exact Spectral Analysis of Single-h and Multi-h CPM Signals through PAM
  decomposition and Matrix Series Evaluation</title><categories>cs.IT math.IT</categories><comments>31 pages, 10 figures</comments><journal-ref>IEEE Transactions on Communications 59 (7), 1893-1903</journal-ref><doi>10.1109/TCOMM.2011.050911.100631</doi><abstract>  In this paper we address the problem of closed-form spectral evaluation of
CPM. We show that the multi-h CPM signal can be conveniently generated by a PTI
SM. The output is governed by a Markov chain with the unusual peculiarity of
being cyclostationary and reducible; this holds also in the single-h context.
Judicious reinterpretation of the result leads to a formalization through a
stationary and irreducible Markov chain, whose spectral evaluation is known in
closed-form from the literature. Two are the major outcomes of this paper.
First, unlike the literature, we obtain a PSD in true closed-form. Second, we
give novel insights into the CPM format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609051</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609051</id><created>2006-09-11</created><authors><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Ignat</keyname><forenames>Camelia</forenames></author><author><keyname>Temnikova</keyname><forenames>Irina</forenames></author><author><keyname>Widiger</keyname><forenames>Anna</forenames></author><author><keyname>Zaghouani</keyname><forenames>Wajdi</forenames></author><author><keyname>Zizka</keyname><forenames>Jan</forenames></author></authors><title>Multilingual person name recognition and transliteration</title><categories>cs.CL cs.IR</categories><comments>Explains the technology behind the JRC's NewsExplorer application,
  which is freely accessible at http://press.jrc.it/NewsExplorer</comments><acm-class>H.3.1; H.3.3; H.3.4; H.3.5</acm-class><journal-ref>Journal CORELA - Cognition, Representation, Langage. Numeros
  speciaux, Le traitement lexicographique des noms propres. December 2005. ISSN
  1638-5748</journal-ref><abstract>  We present an exploratory tool that extracts person names from multilingual
news collections, matches name variants referring to the same person, and
infers relationships between people based on the co-occurrence of their names
in related news. A novel feature is the matching of name variants across
languages and writing systems, including names written with the Greek, Cyrillic
and Arabic writing system. Due to our highly multilingual setting, we use an
internal standard representation for name representation and matching, instead
of adopting the traditional bilingual approach to transliteration. This work is
part of the news analysis system NewsExplorer that clusters an average of
25,000 news articles per day to detect related news within the same and across
different languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609052</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609052</id><created>2006-09-11</created><authors><author><keyname>Wolter</keyname><forenames>Frank</forenames></author><author><keyname>Zakharyaschev</keyname><forenames>Michael</forenames></author></authors><title>Undecidability of the unification and admissibility problems for modal
  and description logics</title><categories>cs.LO cs.AI</categories><abstract>  We show that the unification problem `is there a substitution instance of a
given formula that is provable in a given logic?' is undecidable for basic
modal logics K and K4 extended with the universal modality. It follows that the
admissibility problem for inference rules is undecidable for these logics as
well. These are the first examples of standard decidable modal logics for which
the unification and admissibility problems are undecidable. We also prove
undecidability of the unification and admissibility problems for K and K4 with
at least two modal operators and nominals (instead of the universal modality),
thereby showing that these problems are undecidable for basic hybrid logics.
Recently, unification has been introduced as an important reasoning service for
description logics. The undecidability proof for K with nominals can be used to
show the undecidability of unification for boolean description logics with
nominals (such as ALCO and SHIQO). The undecidability proof for K with the
universal modality can be used to show that the unification problem relative to
role boxes is undecidable for Boolean description logic with transitive roles,
inverse roles, and role hierarchies (such as SHI and SHIQ).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609053</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609053</id><created>2006-09-11</created><authors><author><keyname>Steinberger</keyname><forenames>Ralf</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Ignat</keyname><forenames>Camelia</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author></authors><title>Navigating multilingual news collections using automatically extracted
  information</title><categories>cs.CL cs.IR</categories><comments>This paper describes the main functionality of the JRC's
  fully-automatic news analysis system NewsExplorer, which is freely accessible
  in currently thirteen languages at http://press.jrc.it/NewsExplorer/ . 8
  pages</comments><acm-class>H.3.1; H.3.3; H.3.4; H.3.5</acm-class><journal-ref>Proceedings of the 27th International Conference 'Information
  Technology Interfaces' (ITI'2005). Cavtat / Dubrovnik</journal-ref><abstract>  We are presenting a text analysis tool set that allows analysts in various
fields to sieve through large collections of multilingual news items quickly
and to find information that is of relevance to them. For a given document
collection, the tool set automatically clusters the texts into groups of
similar articles, extracts names of places, people and organisations, lists the
user-defined specialist terms found, links clusters and entities, and generates
hyperlinks. Through its daily news analysis operating on thousands of articles
per day, the tool also learns relationships between people and other entities.
The fully functional prototype system allows users to explore and navigate
multilingual document collections across languages and time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609054</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609054</id><created>2006-09-11</created><updated>2009-08-10</updated><authors><author><keyname>Yi</keyname><forenames>Zhihang</forenames></author><author><keyname>Kim</keyname><forenames>Il-Min</forenames></author></authors><title>High Data-Rate Single-Symbol ML Decodable Distributed STBCs for
  Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High data-rate Distributed Orthogonal Space-Time Block Codes (DOSTBCs) which
achieve the single-symbol decodability and full diversity order are proposed in
this paper. An upper bound of the data-rate of the DOSTBC is derived and it is
approximately twice larger than that of the conventional repetition-based
cooperative strategy. In order to facilitate the systematic constructions of
the DOSTBCs achieving the upper bound of the data-rate, some special DOSTBCs,
which have diagonal noise covariance matrices at the destination terminal, are
investigated. These codes are referred to as the row-monomial DOSTBCs. An upper
bound of the data-rate of the row-monomial DOSTBC is derived and it is equal to
or slightly smaller than that of the DOSTBC. Lastly, the systematic
construction methods of the row-monomial DOSTBCs achieving the upper bound of
the data-rate are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609055</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609055</id><created>2006-09-11</created><authors><author><keyname>Martins</keyname><forenames>Nuno C</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Coding for Additive White Noise Channels with Feedback Corrupted by
  Uniform Quantization or Bounded Noise</title><categories>cs.IT math.IT</categories><abstract>  We present simple coding strategies, which are variants of the
Schalkwijk-Kailath scheme, for communicating reliably over additive white noise
channels in the presence of corrupted feedback. More specifically, we consider
a framework comprising an additive white forward channel and a backward link
which is used for feedback. We consider two types of corruption mechanisms in
the backward link. The first is quantization noise, i.e., the encoder receives
the quantized values of the past outputs of the forward channel. The
quantization is uniform, memoryless and time invariant (that is,
symbol-by-symbol scalar quantization), with bounded quantization error. The
second corruption mechanism is an arbitrarily distributed additive bounded
noise in the backward link. Here we allow symbol-by-symbol encoding at the
input to the backward channel. We propose simple explicit schemes that
guarantee positive information rate, in bits per channel use, with positive
error exponent. If the forward channel is additive white Gaussian then our
schemes achieve capacity, in the limit of diminishing amplitude of the noise
components at the backward link, while guaranteeing that the probability of
error converges to zero as a doubly exponential function of the block length.
Furthermore, if the forward channel is additive white Gaussian and the backward
link consists of an additive bounded noise channel, with signal-to-noise ratio
(SNR) constrained symbol-by-symbol encoding, then our schemes are also
capacity-achieving in the limit of high SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609056</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609056</id><created>2006-09-11</created><authors><author><keyname>Vaserstein</keyname><forenames>L. N.</forenames></author></authors><title>Matrix Games, Linear Programming, and Linear Approximation</title><categories>cs.GT cs.AI</categories><comments>5 pages</comments><abstract>  The following four classes of computational problems are equivalent: solving
matrix games, solving linear programs, best $l^{\infty}$ linear approximation,
best $l^1$ linear approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609057</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609057</id><created>2006-09-12</created><authors><author><keyname>Deng</keyname><forenames>Yi</forenames></author><author><keyname>Di Crescenzo</keyname><forenames>Giovanni</forenames></author><author><keyname>Lin</keyname><forenames>Dongdai</forenames></author></authors><title>Concurrently Non-Malleable Zero Knowledge in the Authenticated
  Public-Key Model</title><categories>cs.CR</categories><abstract>  We consider a type of zero-knowledge protocols that are of interest for their
practical applications within networks like the Internet: efficient
zero-knowledge arguments of knowledge that remain secure against concurrent
man-in-the-middle attacks. In an effort to reduce the setup assumptions
required for efficient zero-knowledge arguments of knowledge that remain secure
against concurrent man-in-the-middle attacks, we consider a model, which we
call the Authenticated Public-Key (APK) model. The APK model seems to
significantly reduce the setup assumptions made by the CRS model (as no trusted
party or honest execution of a centralized algorithm are required), and can be
seen as a slightly stronger variation of the Bare Public-Key (BPK) model from
\cite{CGGM,MR}, and a weaker variation of the registered public-key model used
in \cite{BCNP}. We then define and study man-in-the-middle attacks in the APK
model. Our main result is a constant-round concurrent non-malleable
zero-knowledge argument of knowledge for any polynomial-time relation
(associated to a language in $\mathcal{NP}$), under the (minimal) assumption of
the existence of a one-way function family. Furthermore,We show time-efficient
instantiations of our protocol based on known number-theoretic assumptions. We
also note a negative result with respect to further reducing the setup
assumptions of our protocol to those in the (unauthenticated) BPK model, by
showing that concurrently non-malleable zero-knowledge arguments of knowledge
in the BPK model are only possible for trivial languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609058</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609058</id><created>2006-09-12</created><authors><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames></author><author><keyname>Widiger</keyname><forenames>Anna</forenames></author><author><keyname>Ignat</keyname><forenames>Camelia</forenames></author><author><keyname>Erjavec</keyname><forenames>Tomaz</forenames></author><author><keyname>Tufis</keyname><forenames>Dan</forenames></author><author><keyname>Varga</keyname><forenames>Daniel</forenames></author></authors><title>The JRC-Acquis: A multilingual aligned parallel corpus with 20+
  languages</title><categories>cs.CL</categories><comments>A multilingual textual resource with meta-data freely available for
  download at http://langtech.jrc.it/JRC-Acquis.html</comments><acm-class>H.3.1; H.3.6</acm-class><journal-ref>Proceedings of the 5th International Conference on Language
  Resources and Evaluation (LREC'2006), pp. 2142-2147. Genoa, Italy, 24-26 May
  2006</journal-ref><abstract>  We present a new, unique and freely available parallel corpus containing
European Union (EU) documents of mostly legal nature. It is available in all 20
official EUanguages, with additional documents being available in the languages
of the EU candidate countries. The corpus consists of almost 8,000 documents
per language, with an average size of nearly 9 million words per language.
Pair-wise paragraph alignment information produced by two different aligners
(Vanilla and HunAlign) is available for all 190+ language pair combinations.
Most texts have been manually classified according to the EUROVOC subject
domains so that the collection can also be used to train and test multi-label
classification algorithms and keyword-assignment software. The corpus is
encoded in XML, according to the Text Encoding Initiative Guidelines. Due to
the large number of parallel texts in many languages, the JRC-Acquis is
particularly suitable to carry out all types of cross-language research, as
well as to test and benchmark text analysis software across different languages
(for instance for alignment, sentence splitting and term extraction).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609059</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609059</id><created>2006-09-12</created><authors><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Ignat</keyname><forenames>Camelia</forenames></author></authors><title>Automatic annotation of multilingual text collections with a conceptual
  thesaurus</title><categories>cs.CL cs.IR</categories><comments>10 pages</comments><acm-class>H.3.1; H.3.3; H.3.4; H.3.6</acm-class><journal-ref>Proceedings of the Workshop 'Ontologies and Information
  Extraction' at the Summer School 'The Semantic Web and Language Technology -
  Its Potential and Practicalities' (EUROLAN'2003), pp 9-28. Bucharest,
  Romania, 28 July - 8 August 2003</journal-ref><abstract>  Automatic annotation of documents with controlled vocabulary terms
(descriptors) from a conceptual thesaurus is not only useful for document
indexing and retrieval. The mapping of texts onto the same thesaurus
furthermore allows to establish links between similar documents. This is also a
substantial requirement of the Semantic Web. This paper presents an almost
language-independent system that maps documents written in different languages
onto the same multilingual conceptual thesaurus, EUROVOC. Conceptual thesauri
differ from Natural Language Thesauri in that they consist of relatively small
controlled lists of words or phrases with a rather abstract meaning. To
automatically identify which thesaurus descriptors describe the contents of a
document best, we developed a statistical, associative system that is trained
on texts that have previously been indexed manually. In addition to describing
the large number of empirically optimised parameters of the fully functional
application, we present the performance of the software according to a human
evaluation by professional indexers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609060</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609060</id><created>2006-09-12</created><authors><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Ignat</keyname><forenames>Camelia</forenames></author></authors><title>Automatic Identification of Document Translations in Large Multilingual
  Document Collections</title><categories>cs.CL cs.IR</categories><comments>This technology is used daily to link related news items across
  languages in the multilingual news analysis system NewsExplorer, which is
  freely accessible at http://press.jrc.it/NewsExplorer . 8 pages</comments><acm-class>H.3.1; H.3.3; H.3.4; H.3.6</acm-class><journal-ref>Proceedings of the International Conference 'Recent Advances in
  Natural Language Processing' (RANLP'2003), pp. 401-408. Borovets, Bulgaria,
  10 - 12 September 2003</journal-ref><abstract>  Texts and their translations are a rich linguistic resource that can be used
to train and test statistics-based Machine Translation systems and many other
applications. In this paper, we present a working system that can identify
translations and other very similar documents among a large number of
candidates, by representing the document contents with a vector of thesaurus
terms from a multilingual thesaurus, and by then measuring the semantic
similarity between the vectors. Tests on different text types have shown that
the system can detect translations with over 96% precision in a large search
space of 820 documents or more. The system was tuned to ignore
language-specific similarities and to give similar documents in a second
language the same similarity score as equivalent documents in the same
language. The application can also be used to detect cross-lingual document
plagiarism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609061</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609061</id><created>2006-09-12</created><authors><author><keyname>Steinberger</keyname><forenames>Ralf</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author></authors><title>Cross-lingual keyword assignment</title><categories>cs.CL cs.IR</categories><comments>Precursor paper to cs.CL/0609059. The automatic classification system
  described here has now matured and is in daily use for document indexing in a
  European parliament. See http://langtech.jrc.it/Eurovoc.html for more
  details. 8 pages</comments><acm-class>H.3.1; H.3.3; H.3.4; H.3.6</acm-class><journal-ref>Proceedings of the XVII Conference of the Spanish Society for
  Natural Language Processing (SEPLN-2001). Procesamiento del Lenguaje Natural,
  Revista No. 27, pp. 273-280. Jaen, Spain, 12-14 September 2001. ISSN
  1135-5948</journal-ref><abstract>  This paper presents a language-independent approach to controlled vocabulary
keyword assignment using the EUROVOC thesaurus. Due to the multilingual nature
of EUROVOC, the keywords for a document written in one language can be
displayed in all eleven official European Union languages. The mapping of
documents written in different languages to the same multilingual thesaurus
furthermore allows cross-language document comparison. The assignment of the
controlled vocabulary thesaurus descriptors is achieved by applying a
statistical method that uses a collection of manually indexed documents to
identify, for each thesaurus descriptor, a large number of lemmas that are
statistically associated to the descriptor. These associated words are then
used during the assignment procedure to identify a ranked list of those EUROVOC
terms that are most likely to be good keywords for a given document. The paper
also describes the challenges of this task and discusses the achieved results
of the fully functional prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609062</identifier>
 <datestamp>2008-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609062</id><created>2006-09-12</created><updated>2007-08-20</updated><authors><author><keyname>Cheney</keyname><forenames>James</forenames></author><author><keyname>Urban</keyname><forenames>Christian</forenames></author></authors><title>Nominal Logic Programming</title><categories>cs.PL cs.LO</categories><comments>46 pages; 19 page appendix; 13 figures. Revised journal submission as
  of July 23, 2007</comments><acm-class>D.1.6; F.3.2; F.4.1</acm-class><journal-ref>ACM Transactions on Programming Languages and Systems 30(5):26,
  August 2008</journal-ref><doi>10.1145/1387673.1387675</doi><abstract>  Nominal logic is an extension of first-order logic which provides a simple
foundation for formalizing and reasoning about abstract syntax modulo
consistent renaming of bound names (that is, alpha-equivalence). This article
investigates logic programming based on nominal logic. We describe some typical
nominal logic programs, and develop the model-theoretic, proof-theoretic, and
operational semantics of such programs. Besides being of interest for ensuring
the correct behavior of implementations, these results provide a rigorous
foundation for techniques for analysis and reasoning about nominal logic
programs, as we illustrate via examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609063</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609063</id><created>2006-09-12</created><authors><author><keyname>Ignat</keyname><forenames>Camelia</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Ribeiro</keyname><forenames>Antonio</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author></authors><title>Extending an Information Extraction tool set to Central and Eastern
  European languages</title><categories>cs.CL cs.IR</categories><comments>7 pages</comments><acm-class>H.3.1; H.3.6; H.3.4</acm-class><journal-ref>Proceedings of the International Workshop 'Information Extraction
  for Slavonic and other Central and Eastern European Languages' (IESL-2003),
  held at RANLP-2003, pp. 33-39. Borovets, Bulgaria, 8 - 9 September 2003</journal-ref><abstract>  In a highly multilingual and multicultural environment such as in the
European Commission with soon over twenty official languages, there is an
urgent need for text analysis tools that use minimal linguistic knowledge so
that they can be adapted to many languages without much human effort. We are
presenting two such Information Extraction tools that have already been adapted
to various Western and Eastern European languages: one for the recognition of
date expressions in text, and one for the detection of geographical place names
and the visualisation of the results in geographical maps. An evaluation of the
performance has produced very satisfying results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609064</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609064</id><created>2006-09-12</created><authors><author><keyname>Steinberger</keyname><forenames>Ralf</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Ignat</keyname><forenames>Camelia</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author></authors><title>Exploiting multilingual nomenclatures and language-independent text
  features as an interlingua for cross-lingual text analysis applications</title><categories>cs.CL cs.IR</categories><comments>The approach described in this paper is used to link related
  documents across languages in the multilingual news analysis system
  NewsExplorer, which is freely accessible at http://press.jrc.it/NewsExplorer
  . 11 pages</comments><acm-class>H.3.1; H.3.3; H.3.4</acm-class><journal-ref>Information Society 2004 (IS-2004) - Proceedings B of the 7th
  International Multiconference - Language Technologies, pages 2-12. Ljubljana,
  Slovenia, 13-14 October 2004</journal-ref><abstract>  We are proposing a simple, but efficient basic approach for a number of
multilingual and cross-lingual language technology applications that are not
limited to the usual two or three languages, but that can be applied with
relatively little effort to larger sets of languages. The approach consists of
using existing multilingual linguistic resources such as thesauri,
nomenclatures and gazetteers, as well as exploiting the existence of additional
more or less language-independent text items such as dates, currency
expressions, numbers, names and cognates. Mapping texts onto the multilingual
resources and identifying word token links between texts in different languages
are basic ingredients for applications such as cross-lingual document
similarity calculation, multilingual clustering and categorisation,
cross-lingual document retrieval, and tools to provide cross-lingual
information access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609065</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609065</id><created>2006-09-12</created><authors><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Kimler</keyname><forenames>Marco</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Ignat</keyname><forenames>Camelia</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Oellinger</keyname><forenames>Tamara</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Blackler</keyname><forenames>Ken</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Fuart</keyname><forenames>Flavio</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Zaghouani</keyname><forenames>Wajdi</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Widiger</keyname><forenames>Anna</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Forslund</keyname><forenames>Ann-Charlotte</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Best</keyname><forenames>Clive</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author></authors><title>Geocoding multilingual texts: Recognition, disambiguation and
  visualisation</title><categories>cs.CL cs.IR</categories><comments>6 pages</comments><acm-class>H.3.1; H.3.3; H.3.4</acm-class><journal-ref>Proceedings of the 5th International Conference on Language
  Resources and Evaluation (LREC-2006), pp. 53-58. Genoa, Italy, 24-26 May 2006</journal-ref><abstract>  We are presenting a method to recognise geographical references in free text.
Our tool must work on various languages with a minimum of language-dependent
resources, except a gazetteer. The main difficulty is to disambiguate these
place names by distinguishing places from persons and by selecting the most
likely place out of a list of homographic place names world-wide. The system
uses a number of language-independent clues and heuristics to disambiguate
place name homographs. The final aim is to index texts with the countries and
cities they mention and to automatically visualise this information on
geographical maps using various tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609066</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609066</id><created>2006-09-12</created><authors><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Ignat</keyname><forenames>Camelia</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Oellinger</keyname><forenames>Tamara</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author></authors><title>Building and displaying name relations using automatic unsupervised
  analysis of newspaper articles</title><categories>cs.CL cs.IR</categories><comments>Builds upon the recognition of person names described in paper
  cs.CL/0609051. Resulting person relations can be explored in the multilingual
  online application NewsExplorer at http://press.jrc.it/NewsExplorer . 12
  pages</comments><acm-class>H.3.1; H.3.3; H.3.4</acm-class><journal-ref>Proceedings of the 8th International Conference on the Statistical
  Analysis of Textual Data (JADT-2006). Besancon, 19-21 April 2006</journal-ref><abstract>  We present a tool that, from automatically recognised names, tries to infer
inter-person relations in order to present associated people on maps. Based on
an in-house Named Entity Recognition tool, applied on clusters of an average of
15,000 news articles per day, in 15 different languages, we build a knowledge
base that allows extracting statistical co-occurrences of persons and
visualising them on a per-person page or in various graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609067</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609067</id><created>2006-09-12</created><authors><author><keyname>Ignat</keyname><forenames>Camelia</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author><author><keyname>Erjavec</keyname><forenames>Tomaz</forenames><affiliation>European Commission - Joint Research Centre</affiliation></author></authors><title>A tool set for the quick and efficient exploration of large document
  collections</title><categories>cs.CL cs.IR</categories><comments>10 pages</comments><acm-class>H.3.1; H.3.3; H.3.4</acm-class><journal-ref>Proceedings of the Symposium on Safeguards and Nuclear Material
  Management. 27th Annual Meeting of the European SAfeguards Research and
  Development Association (ESARDA-2005). London, UK, 10-12 May 2005</journal-ref><abstract>  We are presenting a set of multilingual text analysis tools that can help
analysts in any field to explore large document collections quickly in order to
determine whether the documents contain information of interest, and to find
the relevant text passages. The automatic tool, which currently exists as a
fully functional prototype, is expected to be particularly useful when users
repeatedly have to sieve through large collections of documents such as those
downloaded automatically from the internet. The proposed system takes a whole
document collection as input. It first carries out some automatic analysis
tasks (named entity recognition, geo-coding, clustering, term extraction),
annotates the texts with the generated meta-information and stores the
meta-information in a database. The system then generates a zoomable and
hyperlinked geographic map enhanced with information on entities and terms
found. When the system is used on a regular basis, it builds up a historical
database that contains information on which names have been mentioned together
with which other names or places, and users can query this database to retrieve
information extracted in the past.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609068</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609068</id><created>2006-09-12</created><updated>2007-01-05</updated><authors><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>Leguay</keyname><forenames>Jeremie</forenames></author><author><keyname>Friedman</keyname><forenames>Timur</forenames></author></authors><title>The heterogeneity of inter-contact time distributions: its importance
  for routing in delay tolerant networks</title><categories>cs.NI</categories><comments>6 pages</comments><abstract>  Prior work on routing in delay tolerant networks (DTNs) has commonly made the
assumption that each pair of nodes shares the same inter-contact time
distribution as every other pair. The main argument in this paper is that
researchers should also be looking at heterogeneous inter-contact time
distributions. We demonstrate the presence of such heterogeneity in the
often-used Dartmouth Wi-Fi data set. We also show that DTN routing can benefit
from knowing these distributions. We first introduce a new stochastic model
focusing on the inter-contact time distributions between all pairs of nodes,
which we validate on real connectivity patterns. We then analytically derive
the mean delivery time for a bundle of information traversing the network for
simple single copy routing schemes. The purpose is to examine the theoretic
impact of heterogeneous inter-contact time distributions. Finally, we show that
we can exploit this user diversity to improve routing performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609069</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609069</id><created>2006-09-12</created><authors><author><keyname>Alam</keyname><forenames>S. M. Nazrul</forenames></author><author><keyname>Haas</keyname><forenames>Zygmunt J.</forenames></author></authors><title>Coverage and Connectivity in Three-Dimensional Networks</title><categories>cs.NI</categories><comments>To appear in ACM Mobicom 2006</comments><acm-class>C.2.1</acm-class><abstract>  Most wireless terrestrial networks are designed based on the assumption that
the nodes are deployed on a two-dimensional (2D) plane. However, this 2D
assumption is not valid in underwater, atmospheric, or space communications. In
fact, recent interest in underwater acoustic ad hoc and sensor networks hints
at the need to understand how to design networks in 3D. Unfortunately, the
design of 3D networks is surprisingly more difficult than the design of 2D
networks. For example, proofs of Kelvin's conjecture and Kepler's conjecture
required centuries of research to achieve breakthroughs, whereas their 2D
counterparts are trivial to solve. In this paper, we consider the coverage and
connectivity issues of 3D networks, where the goal is to find a node placement
strategy with 100% sensing coverage of a 3D space, while minimizing the number
of nodes required for surveillance. Our results indicate that the use of the
Voronoi tessellation of 3D space to create truncated octahedral cells results
in the best strategy. In this truncated octahedron placement strategy, the
transmission range must be at least 1.7889 times the sensing range in order to
maintain connectivity among nodes. If the transmission range is between 1.4142
and 1.7889 times the sensing range, then a hexagonal prism placement strategy
or a rhombic dodecahedron placement strategy should be used. Although the
required number of nodes in the hexagonal prism and the rhombic dodecahedron
placement strategies is the same, this number is 43.25% higher than the number
of nodes required by the truncated octahedron placement strategy. We verify by
simulation that our placement strategies indeed guarantee ubiquitous coverage.
We believe that our approach and our results presented in this paper could be
used for extending the processes of 2D network design to 3D networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609070</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609070</id><created>2006-09-12</created><updated>2006-09-12</updated><authors><author><keyname>Distasio</keyname><forenames>Joseph</forenames></author><author><keyname>Way</keyname><forenames>Thomas P.</forenames></author></authors><title>Exploring Computer Science Concepts with a Ready-made Computer Game
  Framework</title><categories>cs.OH</categories><comments>5 pages, 3 figures</comments><acm-class>K.3.1; I.2.1</acm-class><abstract>  Leveraging the prevailing interest in computer games among college students,
both for entertainment and as a possible career path, is a major reason for the
increasing prevalence of computer game design courses in computer science
curricula. Because implementing a computer game requires strong programming
skills, game design courses are most often restricted to more advanced computer
science students. This paper reports on a ready-made game design and
experimentation framework, implemented in Java, that makes game programming
more widely accessible. This framework, called Labyrinth, enables students at
all programming skill levels to participate in computer game design. We
describe the architecture of the framework, and discuss programming projects
suitable for a wide variety of computer science courses, from capstone to
non-major.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609071</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609071</id><created>2006-09-12</created><updated>2007-02-14</updated><authors><author><keyname>Akaho</keyname><forenames>Shotaro</forenames></author></authors><title>A kernel method for canonical correlation analysis</title><categories>cs.LG cs.CV</categories><comments>Full version of paper presented in IMPS2001 (International Meeting of
  Psychometric Society) 2007-Feb-14: typos in equations (23) and (24) in page 3
  of the first version have been corrected</comments><abstract>  Canonical correlation analysis is a technique to extract common features from
a pair of multivariate data. In complex situations, however, it does not
extract useful features because of its linearity. On the other hand, kernel
method used in support vector machine is an efficient approach to improve such
a linear method. In this paper, we investigate the effectiveness of applying
kernel method to canonical correlation analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609072</identifier>
 <datestamp>2007-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609072</id><created>2006-09-13</created><updated>2007-10-03</updated><authors><author><keyname>Gopalan</keyname><forenames>Parikshit</forenames></author><author><keyname>Kolaitis</keyname><forenames>Phokion G.</forenames></author><author><keyname>Maneva</keyname><forenames>Elitza</forenames></author><author><keyname>Papadimitriou</keyname><forenames>Christos H.</forenames></author></authors><title>The Connectivity of Boolean Satisfiability: Computational and Structural
  Dichotomies</title><categories>cs.CC</categories><journal-ref>Extended abstract in Proceedings of ICALP 2006, pp 346-357</journal-ref><abstract>  Boolean satisfiability problems are an important benchmark for questions
about complexity, algorithms, heuristics and threshold phenomena. Recent work
on heuristics, and the satisfiability threshold has centered around the
structure and connectivity of the solution space. Motivated by this work, we
study structural and connectivity-related properties of the space of solutions
of Boolean satisfiability problems and establish various dichotomies in
Schaefer's framework.
  On the structural side, we obtain dichotomies for the kinds of subgraphs of
the hypercube that can be induced by the solutions of Boolean formulas, as well
as for the diameter of the connected components of the solution space. On the
computational side, we establish dichotomy theorems for the complexity of the
connectivity and st-connectivity questions for the graph of solutions of
Boolean formulas. Our results assert that the intractable side of the
computational dichotomies is PSPACE-complete, while the tractable side - which
includes but is not limited to all problems with polynomial time algorithms for
satisfiability - is in P for the st-connectivity question, and in coNP for the
connectivity question. The diameter of components can be exponential for the
PSPACE-complete cases, whereas in all other cases it is linear; thus, small
diameter and tractability of the connectivity problems are remarkably aligned.
The crux of our results is an expressibility theorem showing that in the
tractable cases, the subgraphs induced by the solution space possess certain
good structural properties, whereas in the intractable cases, the subgraphs can
be arbitrary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609073</identifier>
 <datestamp>2007-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609073</id><created>2006-09-13</created><updated>2007-09-19</updated><authors><author><keyname>Pischella</keyname><forenames>Mylene</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Optimal power allocation for downlink cooperative cellular networks</title><categories>cs.IT math.IT</categories><acm-class>H.1.1</acm-class><abstract>  This paper has been withdrawn by the author
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609074</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609074</id><created>2006-09-13</created><authors><author><keyname>Chung</keyname><forenames>Yoo Chul</forenames></author><author><keyname>Lee</keyname><forenames>Dongman</forenames></author></authors><title>A Non-anchored Unified Naming System for Ad Hoc Computing Environments</title><categories>cs.DC cs.AR cs.NI</categories><comments>Submitted to Percom 2007</comments><abstract>  A ubiquitous computing environment consists of many resources that need to be
identified by users and applications. Users and developers require some way to
identify resources by human readable names. In addition, ubiquitous computing
environments impose additional requirements such as the ability to work well
with ad hoc situations and the provision of names that depend on context.
  The Non-anchored Unified Naming (NUN) system was designed to satisfy these
requirements. It is based on relative naming among resources and provides the
ability to name arbitrary types of resources. By having resources themselves
take part in naming, resources are able to able contribute their specialized
knowledge into the name resolution process, making context-dependent mapping of
names to resources possible. The ease of which new resource types can be added
makes it simple to incorporate new types of contextual information within
names.
  In this paper, we describe the naming system and evaluate its use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609075</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609075</id><created>2006-09-13</created><updated>2006-12-27</updated><authors><author><keyname>Tsarev</keyname><forenames>S. P.</forenames></author></authors><title>On factorization and solution of multidimensional linear partial
  differential equations</title><categories>cs.SC nlin.SI</categories><comments>11 pages, Plain LaTeX; Submitted to Proceedings of Waterloo Workshop
  on Computer Algebra devoted to the 60th birthday Of S.A.Abramov. The second
  version includes grant acknowledgements and minor changes in a couple of
  places</comments><acm-class>F.2.2</acm-class><abstract>  We describe a method of obtaining closed-form complete solutions of certain
second-order linear partial differential equations with more than two
independent variables. This method generalizes the classical method of Laplace
transformations of second-order hyperbolic equations in the plane and is based
on an idea given by Ulisse Dini in 1902.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609076</identifier>
 <datestamp>2008-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609076</id><created>2006-09-13</created><updated>2008-10-06</updated><authors><author><keyname>Hwang</keyname><forenames>Chien-Hwa</forenames></author></authors><title>Asymptotic Spectral Distribution of Crosscorrelation Matrix in
  Asynchronous CDMA</title><categories>cs.IT math.IT</categories><comments>63 pages, 8 figures, submitted to IEEE Transactions on Information
  Theory, Sept. 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asymptotic spectral distribution (ASD) of the crosscorrelation matrix is
investigated for a random spreading short/long-code asynchronous direct
sequence-code division multiple access (DS-CDMA) system. The discrete-time
decision statistics are obtained as the output samples of a bank of symbol
matched filters of all users. The crosscorrelation matrix is studied when the
number of symbols transmitted by each user tends to infinity. Two levels of
asynchronism are considered. One is symbol-asynchronous but chip-synchronous,
and the other is chip-asynchronous. The existence of a nonrandom ASD is proved
by moment convergence theorem, where the focus is on the derivation of
asymptotic eigenvalue moments (AEM) of the crosscorrelation matrix. A
combinatorics approach based on noncrossing partition of set partition theory
is adopted for AEM computation. The spectral efficiency and the minimum
mean-square-error (MMSE) achievable by a linear receiver of asynchronous CDMA
are plotted by AEM using a numerical method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609077</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609077</id><created>2006-09-13</created><authors><author><keyname>Xiao</keyname><forenames>Shi</forenames></author><author><keyname>Xiao</keyname><forenames>Gaoxi</forenames></author></authors><title>On Intentional Attacks and Protections in Complex Communication Networks</title><categories>cs.NI</categories><comments>5 pages, 11 figures, accepted by IEEE Globecom 2006 conference</comments><abstract>  Being motivated by recent developments in the theory of complex networks, we
examine the robustness of communication networks under intentional attack that
takes down network nodes in a decreasing order of their nodal degrees. In this
paper, we study two different effects that have been largely missed in the
existing results: (i) some communication networks, like Internet, are too large
for anyone to have global information of their topologies, which makes the
accurate intentional attack practically impossible; and (ii) most attacks in
communication networks are propagated from one node to its neighborhood
node(s), utilizing local network-topology information only. We show that
incomplete global information has different impacts to the intentional attack
in different circumstances, while local information-based attacks can be
actually highly efficient. Such insights would be helpful for the future
developments of efficient network attack/protection schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609078</identifier>
 <datestamp>2007-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609078</id><created>2006-09-13</created><updated>2007-07-04</updated><authors><author><keyname>Bunin</keyname><forenames>Guy</forenames></author></authors><title>A Continuum Theory for Unstructured Mesh Generation in Two Dimensions</title><categories>cs.CG</categories><abstract>  A continuum description of unstructured meshes in two dimensions, both for
planar and curved surface domains, is proposed. The meshes described are those
which, in the limit of an increasingly finer mesh (smaller cells), and away
from irregular vertices, have ideally-shaped cells (squares or equilateral
triangles), and can therefore be completely described by two local properties:
local cell size and local edge directions. The connection between the two
properties is derived by defining a Riemannian manifold whose geodesics trace
the edges of the mesh. A function $\phi$, proportional to the logarithm of the
cell size, is shown to obey the Poisson equation, with localized charges
corresponding to irregular vertices. The problem of finding a suitable manifold
for a given domain is thus shown to exactly reduce to an Inverse Poisson
problem on $\phi$, of finding a distribution of localized charges adhering to
the conditions derived for boundary alignment. Possible applications to mesh
generation are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609079</identifier>
 <datestamp>2009-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609079</id><created>2006-09-14</created><updated>2009-07-29</updated><authors><author><keyname>Suslo</keyname><forenames>Tomasz</forenames></author></authors><title>Modern Statistics by Kriging</title><categories>cs.NA cs.CE</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present statistics (S-statistics) based only on random variable (not
random value) with a mean squared error of mean estimation as a concept of
error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609080</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609080</id><created>2006-09-14</created><updated>2006-10-18</updated><authors><author><keyname>Intrigila</keyname><forenames>Benedetto</forenames></author><author><keyname>Statman</keyname><forenames>Richard</forenames></author></authors><title>Solution of a Problem of Barendregt on Sensible lambda-Theories</title><categories>cs.LO</categories><comments>17 pages</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 4 (October
  18, 2006) lmcs:836</journal-ref><doi>10.2168/LMCS-2(4:5)2006</doi><abstract>  &lt;i&gt;H&lt;/i&gt; is the theory extending &amp;#946;-conversion by identifying all closed
unsolvables. &lt;i&gt;H&lt;/i&gt;&amp;#969; is the closure of this theory under the &amp;#969;-rule
(and &amp;#946;-conversion). A long-standing conjecture of H. Barendregt states
that the provable equations of &lt;i&gt;H&lt;/i&gt;&amp;#969; form
&amp;#928;&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;1&lt;/sup&gt;-complete set. Here we prove that conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609081</identifier>
 <datestamp>2010-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609081</id><created>2006-09-14</created><authors><author><keyname>Tygert</keyname><forenames>Mark</forenames></author></authors><title>Recurrence relations and fast algorithms</title><categories>cs.CE cs.NA</categories><comments>24 pages</comments><acm-class>F.2.1; G.1.2</acm-class><journal-ref>Recurrence relations and fast algorithms, Applied and
  Computational Harmonic Analysis, 28 (1): 121-128, 2010</journal-ref><abstract>  We construct fast algorithms for evaluating transforms associated with
families of functions which satisfy recurrence relations. These include
algorithms both for computing the coefficients in linear combinations of the
functions, given the values of these linear combinations at certain points,
and, vice versa, for evaluating such linear combinations at those points, given
the coefficients in the linear combinations; such procedures are also known as
analysis and synthesis of series of certain special functions. The algorithms
of the present paper are efficient in the sense that their computational costs
are proportional to n (ln n) (ln(1/epsilon))^3, where n is the amount of input
and output data, and epsilon is the precision of computations. Stated somewhat
more precisely, we find a positive real number C such that, for any positive
integer n &gt; 10, the algorithms require at most C n (ln n) (ln(1/epsilon))^3
floating-point operations and words of memory to evaluate at n appropriately
chosen points any linear combination of n special functions, given the
coefficients in the linear combination, where epsilon is the precision of
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609082</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609082</id><created>2006-09-14</created><authors><author><keyname>Gutowski</keyname><forenames>Marek W.</forenames></author></authors><title>Classifying extrema using intervals</title><categories>cs.MS cs.CC cs.NA</categories><comments>LaTeX, 7 pages, no figures</comments><acm-class>F.2.2; G.1.0; G.1.2; J.2</acm-class><abstract>  We present a straightforward and verified method of deciding whether the
n-dimensional point x (n&gt;=1), such that \nabla f(x)=0, is the local minimizer,
maximizer or just a saddle point of a real-valued function f.
  The method scales linearly with dimensionality of the problem and never
produces false results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609083</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609083</id><created>2006-09-14</created><authors><author><keyname>Hoang</keyname><forenames>C. T.</forenames></author><author><keyname>Sawada</keyname><forenames>J.</forenames></author><author><keyname>Shu</keyname><forenames>X.</forenames></author></authors><title>k-Colorability of P5-free graphs</title><categories>cs.DM cs.DS</categories><acm-class>G.2.2</acm-class><abstract>  A polynomial time algorithm that determines for a fixed integer k whether or
not a P5-free graph can be k-colored is presented in this paper. If such a
coloring exists, the algorithm will produce a valid k-coloring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609084</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609084</id><created>2006-09-15</created><authors><author><keyname>Sparavigna</keyname><forenames>A.</forenames></author><author><keyname>Montrucchio</keyname><forenames>B.</forenames></author></authors><title>Non-photorealistic image rendering with a labyrinthine tiling</title><categories>cs.GR</categories><comments>9 pages, 5 figures</comments><abstract>  The paper describes a new image processing for a non-photorealistic
rendering. The algorithm is based on a random generation of gray tones and
competing statistical requirements. The gray tone value of each pixel in the
starting image is replaced selecting among randomly generated tone values,
according to the statistics of nearest-neighbor and next-nearest-neighbor
pixels. Two competing conditions for replacing the tone values - one position
on the local mean value the other on the local variance - produce a peculiar
pattern on the image. This pattern has a labyrinthine tiling aspect. For
certain subjects, the pattern enhances the look of the image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609085</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609085</id><created>2006-09-15</created><updated>2007-05-03</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>Fagerberg</keyname><forenames>Rolf</forenames></author><author><keyname>Goertz</keyname><forenames>Inge Li</forenames></author></authors><title>Improved Approximate String Matching and Regular Expression Matching on
  Ziv-Lempel Compressed Texts</title><categories>cs.DS</categories><abstract>  We study the approximate string matching and regular expression matching
problem for the case when the text to be searched is compressed with the
Ziv-Lempel adaptive dictionary compression schemes. We present a time-space
trade-off that leads to algorithms improving the previously known complexities
for both problems. In particular, we significantly improve the space bounds,
which in practical applications are likely to be a bottleneck.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609086</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609086</id><created>2006-09-15</created><authors><author><keyname>Rivano</keyname><forenames>Herv&#xe9;</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Theoleyre</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Valois</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>About the Capacity of Flat and Self-Organized Ad Hoc and Hybrid Networks</title><categories>cs.NI</categories><proxy>ccsd inria-00095216</proxy><abstract>  Ad hoc networking specific challenges foster a strong research effort on
efficient protocols design. Routing protocols based on a self-organized
structure have been studied principally for the robustness and the scalability
they provide. On the other hand, self-organization schemes may decrease the
network capacity since they concentrate the traffic on privileged links. This
paper presents four models for evaluating the capacity of a routing schemes on
802.11 like networks. Our approach consists in modeling the radio resource
sharing principles of 802.11 like MAC protocols as a set of linear constraints.
We have implemented two models of fairness. The first one assumes that nodes
have a fair access to the channel, while the second one assumes that on the
radio links. We then develop a pessimistic and an optimistic scenarii of
spatial re-utilization of the medium, yielding a lower bound and an upper bound
on the network capacity for each fairness case. Our models are independent of
the routing protocols and provide therefore a relevant framework for their
comparison. We apply our models to a comparative analysis of the well-known
shortest path base flat routing protocol OLSR against two main self-organized
structure approaches, VSR, and Wu &amp; Li's protocols. This study concludes on the
relevance of self-organized approaches from the network capacity point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609087</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609087</id><created>2006-09-15</created><authors><author><keyname>Michalski</keyname><forenames>Jacek</forenames></author><author><keyname>Skoczylas</keyname><forenames>Leszek</forenames></author></authors><title>A comparative analysis of the geometrical surface texture of a real and
  virtual model of a tooth flank of a cylindrical gear</title><categories>cs.CE</categories><comments>32 pages, 10 figures</comments><acm-class>I.6.4; J.6</acm-class><abstract>  The paper presents the methodology of modelling tooth flanks of cylindrical
gears in the Cad environment. The modelling consists in a computer simulation
of gear generation. A model of tooth flanks is an envelope curve of a family of
envelopes that originate from the rolling motion of a solid tool model in
relation to a solid model of the cylindrical gear. The surface stereometry and
topography of the tooth flanks, hobbed and chiselled by Fellows method, are
compared to their numerical models. Metrological measurements of the real gears
were carried out using a coordinated measuring machine and a two - and a
three-dimensional profilometer. A computer simulation of the gear generation
was performed in the Mechanical Desktop environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609088</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609088</id><created>2006-09-15</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author></authors><title>Deriving the Normalized Min-Sum Algorithm from Cooperative Optimization</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Information Theory Workshop, Chengdu, China, 2006</comments><abstract>  The normalized min-sum algorithm can achieve near-optimal performance at
decoding LDPC codes. However, it is a critical question to understand the
mathematical principle underlying the algorithm. Traditionally, people thought
that the normalized min-sum algorithm is a good approximation to the
sum-product algorithm, the best known algorithm for decoding LDPC codes and
Turbo codes. This paper offers an alternative approach to understand the
normalized min-sum algorithm. The algorithm is derived directly from
cooperative optimization, a newly discovered general method for
global/combinatorial optimization. This approach provides us another
theoretical basis for the algorithm and offers new insights on its power and
limitation. It also gives us a general framework for designing new decoding
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609089</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609089</id><created>2006-09-15</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author><author><keyname>Ding</keyname><forenames>Suquan</forenames></author><author><keyname>Yang</keyname><forenames>Zhixing</forenames></author><author><keyname>Wu</keyname><forenames>Youshou</forenames></author></authors><title>Fast Min-Sum Algorithms for Decoding of LDPC over GF(q)</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Information Theory Workshop, Chengdu, China, 2006</comments><abstract>  In this paper, we present a fast min-sum algorithm for decoding LDPC codes
over GF(q). Our algorithm is different from the one presented by David Declercq
and Marc Fossorier in ISIT 05 only at the way of speeding up the horizontal
scan in the min-sum algorithm. The Declercq and Fossorier's algorithm speeds up
the computation by reducing the number of configurations, while our algorithm
uses the dynamic programming instead. Compared with the configuration reduction
algorithm, the dynamic programming one is simpler at the design stage because
it has less parameters to tune. Furthermore, it does not have the performance
degradation problem caused by the configuration reduction because it searches
the whole configuration space efficiently through dynamic programming. Both
algorithms have the same level of complexity and use simple operations which
are suitable for hardware implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609090</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609090</id><created>2006-09-15</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author></authors><title>Single-Scan Min-Sum Algorithms for Fast Decoding of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Information Theory Workshop, Chengdu, China, 2006</comments><abstract>  Many implementations for decoding LDPC codes are based on the
(normalized/offset) min-sum algorithm due to its satisfactory performance and
simplicity in operations. Usually, each iteration of the min-sum algorithm
contains two scans, the horizontal scan and the vertical scan. This paper
presents a single-scan version of the min-sum algorithm to speed up the
decoding process. It can also reduce memory usage or wiring because it only
needs the addressing from check nodes to variable nodes while the original
min-sum algorithm requires that addressing plus the addressing from variable
nodes to check nodes. To cut down memory usage or wiring further, another
version of the single-scan min-sum algorithm is presented where the messages of
the algorithm are represented by single bit values instead of using fixed point
ones. The software implementation has shown that the single-scan min-sum
algorithm is more than twice as fast as the original min-sum algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609091</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609091</id><created>2006-09-16</created><authors><author><keyname>Dehornoy</keyname><forenames>Patrick</forenames><affiliation>LMNO</affiliation></author></authors><title>Using shifted conjugacy in braid-based cryptography</title><categories>cs.CR</categories><proxy>ccsd ccsd-00095575</proxy><abstract>  Conjugacy is not the only possible primitive for designing braid-based
protocols. To illustrate this principle, we describe a Fiat--Shamir-style
authentication protocol that be can be implemented using any binary operation
that satisfies the left self-distributive law. Conjugation is an example of
such an operation, but there are other examples, in particular the shifted
conjugation on Artin's braid group B\_oo, and the finite Laver tables. In both
cases, the underlying structures have a high combinatorial complexity, and they
lead to difficult problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609092</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609092</id><created>2006-09-16</created><authors><author><keyname>Emelyanov</keyname><forenames>P.</forenames></author></authors><title>Analysis of Equality Relationships for Imperative Programs</title><categories>cs.PL</categories><comments>31 pages, 10 figures, 2 tables, 1 appendix</comments><acm-class>D.3.1; F.3.2</acm-class><abstract>  In this article, we discuss a flow--sensitive analysis of equality
relationships for imperative programs. We describe its semantic domains,
general purpose operations over abstract computational states (term evaluation
and identification, semantic completion, widening operator, etc.) and semantic
transformers corresponding to program constructs. We summarize our experiences
from the last few years concerning this analysis and give attention to
applications of analysis of automatically generated code. Among other
illustrating examples, we consider a program for which the analysis diverges
without a widening operator and results of analyzing residual programs produced
by some automatic partial evaluator. An example of analysis of a program
generated by this evaluator is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609093</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609093</id><created>2006-09-16</created><authors><author><keyname>Feldman</keyname><forenames>Jon</forenames></author><author><keyname>O'Donnell</keyname><forenames>Ryan</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author></authors><title>PAC Learning Mixtures of Axis-Aligned Gaussians with No Separation
  Assumption</title><categories>cs.LG</categories><comments>19 pages; no figures; preliminary abridged version appeared in
  Proceedings of 19th Annual Conference on Learning Theory (COLT) 2006</comments><journal-ref>Proceedings of 19th Annual Conference on Learning Theory (COLT),
  Pittsburgh, PA, pp. 20--34, 2006</journal-ref><abstract>  We propose and analyze a new vantage point for the learning of mixtures of
Gaussians: namely, the PAC-style model of learning probability distributions
introduced by Kearns et al. Here the task is to construct a hypothesis mixture
of Gaussians that is statistically indistinguishable from the actual mixture
generating the data; specifically, the KL-divergence should be at most epsilon.
  In this scenario, we give a poly(n/epsilon)-time algorithm that learns the
class of mixtures of any constant number of axis-aligned Gaussians in
n-dimensional Euclidean space. Our algorithm makes no assumptions about the
separation between the means of the Gaussians, nor does it have any dependence
on the minimum mixing weight. This is in contrast to learning results known in
the ``clustering'' model, where such assumptions are unavoidable.
  Our algorithm relies on the method of moments, and a subalgorithm developed
in previous work by the authors (FOCS 2005) for a discrete mixture-learning
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609094</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609094</id><created>2006-09-17</created><authors><author><keyname>Wiechman</keyname><forenames>Gil</forenames></author><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>An Improved Sphere-Packing Bound Targeting Codes of Short to Moderate
  Block Lengths and Applications</title><categories>cs.IT math.IT</categories><comments>To be presented in the 44th Allerton conference, 27-29 September
  2006. The full paper version was submitted to the IEEE Trans. on Information
  Theory, August 2006 (see http://www.ee.technion.ac.il/people/sason/ISP.pdf)</comments><abstract>  This paper derives an improved sphere-packing (ISP) bound targeting codes of
short to moderate block lengths. We first review the 1967 sphere-packing (SP67)
bound for discrete memoryless channels, and a recent improvement by Valembois
and Fossorier. These concepts are used for the derivation of a new lower bound
on the decoding error probability (referred to as the ISP bound) which is
uniformly tighter than the SP67 bound and its recent improved version. Under a
mild condition, the ISP bound is applicable to general memoryless channels, and
some of its applications are exemplified. Its tightness is studied by comparing
it with bounds on the ML decoding error probability. It is exemplified that the
ISP bound suggests an interesting alternative to the 1959 sphere-packing (SP59)
bound of Shannon for the Gaussian channel, especially for digital modulations
of high spectral efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609095</identifier>
 <datestamp>2007-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609095</id><created>2006-09-17</created><updated>2007-09-10</updated><authors><author><keyname>Wehler</keyname><forenames>Joachim</forenames></author></authors><title>Free Choice Petri Nets without frozen tokens and Bipolar Synchronization
  Systems</title><categories>cs.LO</categories><acm-class>D.2.2</acm-class><abstract>  Bipolar synchronization systems (BP-systems) constitute a class of coloured
Petri nets, well suited for modeling the control flow of discrete, dynamical
systems. Every BP-system has an underlying ordinary Petri net, which is a
T-system. Moreover, it has a second ordinary net attached, which is a
free-choice system. We prove that a BP-system is live and safe if the T-system
and the free-choice system are live and safe and if the free-choice system has
no frozen tokens. This result is the converse of a theorem of Genrich and
Thiagarajan and proves an elder conjecture. The proof compares the different
Petri nets by Petri net morphisms and makes use of the classical theory of
free-choice systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609096</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609096</id><created>2006-09-18</created><updated>2006-11-28</updated><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Moser</keyname><forenames>Philippe</forenames></author></authors><title>Finite-State Dimension and Lossy Decompressors</title><categories>cs.CC cs.IT math.IT</categories><comments>We found that Theorem 3.11, which was basically the motive for this
  paper, was already proven by Sheinwald, Ziv, and Lempel in 1991 and 1995
  papers</comments><abstract>  This paper examines information-theoretic questions regarding the difficulty
of compressing data versus the difficulty of decompressing data and the role
that information loss plays in this interaction. Finite-state compression and
decompression are shown to be of equivalent difficulty, even when the
decompressors are allowed to be lossy.
  Inspired by Kolmogorov complexity, this paper defines the optimal
*decompression *ratio achievable on an infinite sequence by finite-state
decompressors (that is, finite-state transducers outputting the sequence in
question). It is shown that the optimal compression ratio achievable on a
sequence S by any *information lossless* finite state compressor, known as the
finite-state dimension of S, is equal to the optimal decompression ratio
achievable on S by any finite-state decompressor. This result implies a new
decompression characterization of finite-state dimension in terms of lossy
finite-state transducers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609097</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609097</id><created>2006-09-17</created><authors><author><keyname>Savla</keyname><forenames>Ketan</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>Traveing Salesperson Problems for a double integrator</title><categories>cs.RO</categories><abstract>  In this paper we propose some novel path planning strategies for a double
integrator with bounded velocity and bounded control inputs. First, we study
the following version of the Traveling Salesperson Problem (TSP): given a set
of points in $\real^d$, find the fastest tour over the point set for a double
integrator. We first give asymptotic bounds on the time taken to complete such
a tour in the worst-case. Then, we study a stochastic version of the TSP for
double integrator where the points are randomly sampled from a uniform
distribution in a compact environment in $\real^2$ and $\real^3$. We propose
novel algorithms that perform within a constant factor of the optimal strategy
with high probability. Lastly, we study a dynamic TSP: given a stochastic
process that generates targets, is there a policy which guarantees that the
number of unvisited targets does not diverge over time? If such stable policies
exist, what is the minimum wait for a target? We propose novel stabilizing
receding-horizon algorithms whose performances are within a constant factor
from the optimum with high probability, in $\real^2$ as well as $\real^3$. We
also argue that these algorithms give identical performances for a particular
nonholonomic vehicle, Dubins vehicle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609098</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609098</id><created>2006-09-17</created><authors><author><keyname>Byun</keyname><forenames>Sang-Seon</forenames></author><author><keyname>Yoo</keyname><forenames>Chuck</forenames></author></authors><title>Reducing the Makespan in Hierarchical Reliable Multicast Tree</title><categories>cs.NI</categories><comments>26 pages, 9 figures, submitted to IEEE Transactions on Information
  Theory</comments><abstract>  In hierarchical reliable multicast environment, makespan is the time that is
required to fully and successfully transmit a packet from the sender to all
receivers. Low makespan is vital for achieving high throughput with a TCP-like
window based sending scheme. In hierarchical reliable multicast methods, the
number of repair servers and their locations influence the makespan. In this
paper we propose a new method to decide the locations of repair servers that
can reduce the makespan in hierarchical reliable multicast networks. Our method
has a formulation based on mixed integer programming to analyze the makespan
minimization problem. A notable aspect of the formulation is that heterogeneous
links and packet losses are taken into account in the formulation. Three
different heuristics are presented to find the locations of repair servers in
reasonable time in the formulation. Through simulations, three heuristics are
carefully analyzed and compared on networks with different sizes. We also
evaluate our proposals on PGM (Pragmatic General Multicast) reliable multicast
protocol using ns-2 simulation. The results show that the our best heuristic is
close to the lower bound by a factor of 2.3 in terms of makespan and by a
factor of 5.5 in terms of the number of repair servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609099</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609099</id><created>2006-09-18</created><authors><author><keyname>Sason</keyname><forenames>Igal</forenames></author><author><keyname>Goldenberg</keyname><forenames>Idan</forenames></author></authors><title>Coding for Parallel Channels: Gallager Bounds and Applications to
  Repeat-Accumulate Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures. To be presented in the IEEE Conference for
  Electrical Engineers in Israel, Eilat, Nov. 15-17, 2006. The full paper
  version was submitted to the IEEE Trans. on Information Theory in June 2006,
  and is available at http://arxiv.org/abs/cs.IT/0607002</comments><abstract>  This paper is focused on the performance analysis of binary linear block
codes (or ensembles) whose transmission takes place over independent and
memoryless parallel channels. New upper bounds on the maximum-likelihood (ML)
decoding error probability are derived. The framework of the second version of
the Duman and Salehi (DS2) bounds is generalized to the case of parallel
channels, along with the derivation of optimized tilting measures. The
connection between the generalized DS2 and the 1961 Gallager bounds, known
previously for a single channel, is revisited for the case of parallel
channels. The new bounds are used to obtain improved inner bounds on the
attainable channel regions under ML decoding. These improved bounds are applied
to ensembles of turbo-like codes, focusing on repeat-accumulate codes and their
recent variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609100</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609100</id><created>2006-09-18</created><authors><author><keyname>Ranchin</keyname><forenames>Florent</forenames><affiliation>CEREMADE</affiliation></author><author><keyname>Chambolle</keyname><forenames>Antonin</forenames><affiliation>CMAP</affiliation></author><author><keyname>Dibos</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>LAGA</affiliation></author></authors><title>Total Variation Minimization and Graph Cuts for Moving Objects
  Segmentation</title><categories>cs.CV</categories><proxy>ccsd ccsd-00092007</proxy><acm-class>I.4.6; G.3</acm-class><abstract>  In this paper, we are interested in the application to video segmentation of
the discrete shape optimization problem involving the shape weighted perimeter
and an additional term depending on a parameter. Based on recent works and in
particular the one of Darbon and Sigelle, we justify the equivalence of the
shape optimization problem and a weighted total variation regularization. For
solving this problem, we adapt the projection algorithm proposed recently for
solving the basic TV regularization problem. Another solution to the shape
optimization investigated here is the graph cut technique. Both methods have
the advantage to lead to a global minimum. Since we can distinguish moving
objects from static elements of a scene by analyzing norm of the optical flow
vectors, we choose the optical flow norm as initial data. In order to have the
contour as close as possible to an edge in the image, we use a classical edge
detector function as the weight of the weighted total variation. This model has
been used in one of our former works. We also apply the same methods to a video
segmentation model used by Jehan-Besson, Barlaud and Aubert. In this case, only
standard perimeter is incorporated in the shape functional. We also propose
another way for finding moving objects by using an a contrario detection of
objects on the image obtained by solving the Rudin-Osher-Fatemi Total Variation
regularization problem.We can notice the segmentation can be associated to a
level set in the former methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609101</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609101</id><created>2006-09-18</created><updated>2006-12-12</updated><authors><author><keyname>Altarelli</keyname><forenames>Fabrizio</forenames></author><author><keyname>Monasson</keyname><forenames>Remi</forenames></author><author><keyname>Zamponi</keyname><forenames>Francesco</forenames></author></authors><title>Can rare SAT formulas be easily recognized? On the efficiency of message
  passing algorithms for K-SAT at large clause-to-variable ratios</title><categories>cs.CC cond-mat.stat-mech</categories><comments>8 pages of text and 7 of appendices; updated to take into account
  comments received on the first version; to be published on J.Phys.A:Math.Gen</comments><journal-ref>J. Phys. A: Math. Theor. 40, 867-886 (2007)</journal-ref><doi>10.1088/1751-8113/40/5/001</doi><abstract>  For large clause-to-variable ratio, typical K-SAT instances drawn from the
uniform distribution have no solution. We argue, based on statistical mechanics
calculations using the replica and cavity methods, that rare satisfiable
instances from the uniform distribution are very similar to typical instances
drawn from the so-called planted distribution, where instances are chosen
uniformly between the ones that admit a given solution. It then follows, from a
recent article by Feige, Mossel and Vilenchik, that these rare instances can be
easily recognized (in O(log N) time and with probability close to 1) by a
simple message-passing algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609102</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609102</id><created>2006-09-18</created><authors><author><keyname>Dehornoy</keyname><forenames>Patrick</forenames><affiliation>LMNO</affiliation></author></authors><title>Using groups for investigating rewrite systems</title><categories>cs.LO</categories><proxy>ccsd ccsd-00095690</proxy><abstract>  We describe several technical tools that prove to be efficient for
investigating the rewrite systems associated with a family of algebraic laws,
and might be useful for more general rewrite systems. These tools consist in
introducing a monoid of partial operators, listing the monoid relations
expressing the possible local confluence of the rewrite system, then
introducing the group presented by these relations, and finally replacing the
initial rewrite system with a internal process entirely sitting in the latter
group. When the approach can be completed, one typically obtains a practical
method for constructing algebras satisfying prescribed laws and for solving the
associated word problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609103</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609103</id><created>2006-09-18</created><updated>2007-05-02</updated><authors><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author></authors><title>Minimum-weight Cycle Covers and Their Approximability</title><categories>cs.DS cs.CC cs.DM</categories><comments>To appear in the Proceedings of the 33rd Workshop on Graph-Theoretic
  Concepts in Computer Science (WG 2007). Minor changes</comments><acm-class>F.2.2; G.2.1; G.2.2</acm-class><abstract>  A cycle cover of a graph is a set of cycles such that every vertex is part of
exactly one cycle. An L-cycle cover is a cycle cover in which the length of
every cycle is in the set L.
  We investigate how well L-cycle covers of minimum weight can be approximated.
For undirected graphs, we devise a polynomial-time approximation algorithm that
achieves a constant approximation ratio for all sets L. On the other hand, we
prove that the problem cannot be approximated within a factor of 2-eps for
certain sets L.
  For directed graphs, we present a polynomial-time approximation algorithm
that achieves an approximation ratio of O(n), where $n$ is the number of
vertices. This is asymptotically optimal: We show that the problem cannot be
approximated within a factor of o(n).
  To contrast the results for cycle covers of minimum weight, we show that the
problem of computing L-cycle covers of maximum weight can, at least in
principle, be approximated arbitrarily well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609104</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609104</id><created>2006-09-18</created><authors><author><keyname>Wies</keyname><forenames>Thomas</forenames></author><author><keyname>Kuncak</keyname><forenames>Viktor</forenames></author><author><keyname>Zee</keyname><forenames>Karen</forenames></author><author><keyname>Podelski</keyname><forenames>Andreas</forenames></author><author><keyname>Rinard</keyname><forenames>Martin</forenames></author></authors><title>On Verifying Complex Properties using Symbolic Shape Analysis</title><categories>cs.PL cs.LO cs.SE</categories><report-no>MPI-I-2006-2-001</report-no><abstract>  One of the main challenges in the verification of software systems is the
analysis of unbounded data structures with dynamic memory allocation, such as
linked data structures and arrays. We describe Bohne, a new analysis for
verifying data structures. Bohne verifies data structure operations and shows
that 1) the operations preserve data structure invariants and 2) the operations
satisfy their specifications expressed in terms of changes to the set of
objects stored in the data structure. During the analysis, Bohne infers loop
invariants in the form of disjunctions of universally quantified Boolean
combinations of formulas. To synthesize loop invariants of this form, Bohne
uses a combination of decision procedures for Monadic Second-Order Logic over
trees, SMT-LIB decision procedures (currently CVC Lite), and an automated
reasoner within the Isabelle interactive theorem prover. This architecture
shows that synthesized loop invariants can serve as a useful communication
mechanism between different decision procedures. Using Bohne, we have verified
operations on data structures such as linked lists with iterators and back
pointers, trees with and without parent pointers, two-level skip lists, array
data structures, and sorted lists. We have deployed Bohne in the Hob and Jahob
data structure analysis systems, enabling us to combine Bohne with analyses of
data structure clients and apply it in the context of larger programs. This
report describes the Bohne algorithm as well as techniques that Bohne uses to
reduce the ammount of annotations and the running time of the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609105</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609105</id><created>2006-09-18</created><authors><author><keyname>Lavrenov</keyname><forenames>A.</forenames></author></authors><title>Binomial multichannel algorithm</title><categories>cs.CR</categories><comments>11 pages, 2 tables, 8 schemes</comments><acm-class>D.4.6; E.3</acm-class><abstract>  The binomial multichannel algorithm is proposed. Some its properties are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609106</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609106</id><created>2006-09-18</created><authors><author><keyname>Xi</keyname><forenames>Yufang</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>Throughput Optimal Distributed Control of Stochastic Wireless Networks</title><categories>cs.NI</categories><comments>12 pages, six figures, submitted to Transactions on Networking</comments><abstract>  The Maximum Differential Backlog (MDB) control policy of Tassiulas and
Ephremides has been shown to adaptively maximize the stable throughput of
multi-hop wireless networks with random traffic arrivals and queueing. The
practical implementation of the MDB policy in wireless networks with mutually
interfering links, however, requires the development of distributed
optimization algorithms. Within the context of CDMA-based multi-hop wireless
networks, we develop a set of node-based scaled gradient projection power
control algorithms which solves the MDB optimization problem in a distributed
manner using low communication overhead. As these algorithms require time to
converge to a neighborhood of the optimum, the optimal rates determined by the
MDB policy can only be found iteratively over time. For this, we show that the
iterative MDB policy with convergence time remains throughput optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609107</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609107</id><created>2006-09-19</created><updated>2006-10-14</updated><authors><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Solomon</keyname><forenames>Allan I.</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Blasiak</keyname><forenames>Pawel</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Penson</keyname><forenames>Karol A.</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Horzela</keyname><forenames>Andrzej</forenames><affiliation>LPTMC</affiliation></author></authors><title>A multipurpose Hopf deformation of the Algebra of Feynman-like Diagrams</title><categories>cs.OH math-ph math.MP</categories><comments>5 pages</comments><proxy>ccsd ccsd-00095588</proxy><abstract>  We construct a three parameter deformation of the Hopf algebra
$\mathbf{LDIAG}$. This new algebra is a true Hopf deformation which reduces to
$\mathbf{LDIAG}$ on one hand and to $\mathbf{MQSym}$ on the other, relating
$\mathbf{LDIAG}$ to other Hopf algebras of interest in contemporary physics.
Further, its product law reproduces that of the algebra of polyzeta functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609108</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609108</id><created>2006-09-19</created><updated>2006-09-27</updated><authors><author><keyname>Dalmau</keyname><forenames>Victor</forenames></author></authors><title>Generalized Majority-Minority Operations are Tractable</title><categories>cs.CC cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 4 (September
  28, 2006) lmcs:1078</journal-ref><doi>10.2168/LMCS-2(4:1)2006</doi><abstract>  Generalized majority-minority (GMM) operations are introduced as a common
generalization of near unanimity operations and Mal'tsev operations on finite
sets. We show that every instance of the constraint satisfaction problem (CSP),
where all constraint relations are invariant under a (fixed) GMM operation, is
solvable in polynomial time. This constitutes one of the largest tractable
cases of the CSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609109</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609109</id><created>2006-09-19</created><authors><author><keyname>Courcelle</keyname><forenames>Bruno</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI</affiliation></author></authors><title>The recognizability of sets of graphs is a robust property</title><categories>cs.LO math.LO</categories><proxy>ccsd ccsd-00096607</proxy><journal-ref>Theoretical Computer Science 342 (2005) 173-228</journal-ref><abstract>  Once the set of finite graphs is equipped with an algebra structure (arising
from the definition of operations that generalize the concatenation of words),
one can define the notion of a recognizable set of graphs in terms of finite
congruences. Applications to the construction of efficient algorithms and to
the theory of context-free sets of graphs follow naturally. The class of
recognizable sets depends on the signature of graph operations. We consider
three signatures related respectively to Hyperedge Replacement (HR)
context-free graph grammars, to Vertex Replacement (VR) context-free graph
grammars, and to modular decompositions of graphs. We compare the corresponding
classes of recognizable sets. We show that they are robust in the sense that
many variants of each signature (where in particular operations are defined by
quantifier-free formulas, a quite flexible framework) yield the same notions of
recognizability. We prove that for graphs without large complete bipartite
subgraphs, HR-recognizability and VR-recognizability coincide. The same
combinatorial condition equates HR-context-free and VR-context-free sets of
graphs. Inasmuch as possible, results are formulated in the more general
framework of relational structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609110</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609110</id><created>2006-09-19</created><authors><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI</affiliation></author></authors><title>Algebraic recognizability of languages</title><categories>cs.LO</categories><proxy>ccsd ccsd-00096619</proxy><journal-ref>Mathematical Foundations of Computer Science 2004, Tch\`{e}que,
  R\'{e}publique (2004) 149-175</journal-ref><abstract>  Recognizable languages of finite words are part of every computer science
cursus, and they are routinely described as a cornerstone for applications and
for theory. We would like to briefly explore why that is, and how this
word-related notion extends to more complex models, such as those developed for
modeling distributed or timed behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609111</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609111</id><created>2006-09-19</created><updated>2006-10-01</updated><authors><author><keyname>Tuan</keyname><forenames>Le-Chi</forenames></author><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Son</keyname><forenames>Tran Cao</forenames></author></authors><title>A State-Based Regression Formulation for Domains with Sensing
  Actions&lt;br&gt; and Incomplete Information</title><categories>cs.AI</categories><comments>34 pages, 7 Figures</comments><acm-class>I.2.4; I.2.8</acm-class><journal-ref>Logical Methods in Computer Science, Volume 2, Issue 4 (October 2,
  2006) lmcs:1194</journal-ref><doi>10.2168/LMCS-2(4:2)2006</doi><abstract>  We present a state-based regression function for planning domains where an
agent does not have complete information and may have sensing actions. We
consider binary domains and employ a three-valued characterization of domains
with sensing actions to define the regression function. We prove the soundness
and completeness of our regression formulation with respect to the definition
of progression. More specifically, we show that (i) a plan obtained through
regression for a planning problem is indeed a progression solution of that
planning problem, and that (ii) for each plan found through progression, using
regression one obtains that plan or an equivalent one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609112</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609112</id><created>2006-09-19</created><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>A Richer Understanding of the Complexity of Election Systems</title><categories>cs.GT cs.CC cs.MA</categories><report-no>URCS TR-2006-903</report-no><acm-class>I.2.11; F.2.2; F.1.3</acm-class><abstract>  We provide an overview of some recent progress on the complexity of election
systems. The issues studied include the complexity of the winner, manipulation,
bribery, and control problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609113</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609113</id><created>2006-09-20</created><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI</affiliation></author></authors><title>Algebraic recognizability of regular tree languages</title><categories>cs.DM</categories><proxy>ccsd ccsd-00096701</proxy><journal-ref>Theoretical Computer Science 340 (2005) 291-321</journal-ref><abstract>  We propose a new algebraic framework to discuss and classify recognizable
tree languages, and to characterize interesting classes of such languages. Our
algebraic tool, called preclones, encompasses the classical notion of syntactic
Sigma-algebra or minimal tree automaton, but adds new expressivity to it. The
main result in this paper is a variety theorem \`{a} la Eilenberg, but we also
discuss important examples of logically defined classes of recognizable tree
languages, whose characterization and decidability was established in recent
papers (by Benedikt and S\'{e}goufin, and by Bojanczyk and Walukiewicz) and can
be naturally formulated in terms of pseudovarieties of preclones. Finally, this
paper constitutes the foundation for another paper by the same authors, where
first-order definable tree languages receive an algebraic characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609114</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609114</id><created>2006-09-20</created><authors><author><keyname>Bello</keyname><forenames>Abdou Wahidi</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>A VFRoe scheme for 1D shallow water flows : wetting and drying
  simulation</title><categories>cs.NA</categories><proxy>ccsd inria-00095492</proxy><abstract>  A finite-volume method for the one-dimensional shallow-water equations
including topographic source terms is presented. Exploiting an original idea by
Leroux, the system of partial-differential equations is completed by a trivial
equation for the bathymetry. By applying a change of variable, the system is
given a celerity-speed formulation, and linearized. As a result, an approximate
Riemann solver preserving the positivity of the celerity can be constructed,
permitting wetting and drying flow simulations to be performed. Finally, the
simulation of numerical test cases is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609115</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609115</id><created>2006-09-20</created><updated>2007-03-01</updated><authors><author><keyname>Latapy</keyname><forenames>Matthieu</forenames><affiliation>LIP6 - CNRS and UPMC, France</affiliation></author><author><keyname>Magnien</keyname><forenames>Clemence</forenames><affiliation>LIP6 - CNRS and UPMC, France</affiliation></author></authors><title>Measuring Fundamental Properties of Real-World Complex Networks</title><categories>cs.NI cond-mat.stat-mech cs.DS</categories><abstract>  Complex networks, modeled as large graphs, received much attention during
these last years. However, data on such networks is only available through
intricate measurement procedures. Until recently, most studies assumed that
these procedures eventually lead to samples large enough to be representative
of the whole, at least concerning some key properties. This has crucial impact
on network modeling and simulation, which rely on these properties.
  Recent contributions proved that this approach may be misleading, but no
solution has been proposed. We provide here the first practical way to
distinguish between cases where it is indeed misleading, and cases where the
observed properties may be trusted. It consists in studying how the properties
of interest evolve when the sample grows, and in particular whether they reach
a steady state or not.
  In order to illustrate this method and to demonstrate its relevance, we apply
it to data-sets on complex network measurements that are representative of the
ones commonly used. The obtained results show that the method fulfills its
goals very well. We moreover identify some properties which seem easier to
evaluate in practice, thus opening interesting perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609116</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609116</id><created>2006-09-20</created><authors><author><keyname>Latapy</keyname><forenames>Matthieu</forenames><affiliation>LIAFA - CNRS, Universite Paris 7</affiliation></author></authors><title>Theory and Practice of Triangle Problems in Very Large (Sparse
  (Power-Law)) Graphs</title><categories>cs.DS cond-mat.stat-mech cs.NI</categories><abstract>  Finding, counting and/or listing triangles (three vertices with three edges)
in large graphs are natural fundamental problems, which received recently much
attention because of their importance in complex network analysis. We provide
here a detailed state of the art on these problems, in a unified way. We note
that, until now, authors paid surprisingly little attention to space
complexity, despite its both fundamental and practical interest. We give the
space complexities of known algorithms and discuss their implications. Then we
propose improvements of a known algorithm, as well as a new algorithm, which
are time optimal for triangle listing and beats previous algorithms concerning
space complexity. They have the additional advantage of performing better on
power-law graphs, which we also study. We finally show with an experimental
study that these two algorithms perform very well in practice, allowing to
handle cases that were previously out of reach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609117</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609117</id><created>2006-09-20</created><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author><author><keyname>Yang</keyname><forenames>En-hui</forenames></author></authors><title>Constructing LDPC Codes by 2-Lifts</title><categories>cs.IT math.IT</categories><comments>11 pages, 7 figures</comments><journal-ref>Proceeding of IEEE International Symposium on Information Theory
  (ISIT) 2007</journal-ref><abstract>  We propose a new low-density parity-check code construction scheme based on
2-lifts. The proposed codes have an advantage of admitting efficient hardware
implementations. With the motivation of designing codes with low error floors,
we present an analysis of the low-weight stopping set distributions of the
proposed codes. Based on this analysis, we propose design criteria for
designing codes with low error floors. Numerical results show that the
resulting codes have low error probabilities over binary erasure channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609118</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609118</id><created>2006-09-21</created><authors><author><keyname>Sampath</keyname><forenames>Prahladavaradan</forenames></author></authors><title>Duality of Fix-Points for Distributive Lattices</title><categories>cs.DS cs.DM</categories><comments>7 pages</comments><abstract>  We present a novel algorithm for calculating fix-points. The algorithm
calculates fix-points of an endo-function f on a distributive lattice, by
performing reachability computation a graph derived from the dual of f; this is
in comparison to traditional algorithms that are based on iterated application
of f until a fix-point is reached.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609119</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609119</id><created>2006-09-21</created><updated>2006-09-29</updated><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>Verification, Validation and Integrity of Distributed and Interchanged
  Rule Based Policies and Contracts in the Semantic Web</title><categories>cs.AI cs.SE</categories><comments>A.Paschke: Verification, Validation, Integrity of Rule Based Policies
  and Contracts in the Semantic Web, 2nd International Semantic Web Policy
  Workshop (SWPW'06), Nov. 5-9, 2006, Athens, GA, USA</comments><acm-class>K.6.3; I.2; I.2.4</acm-class><journal-ref>A.Paschke: Verification, Validation, Integrity of Rule Based
  Policies and Contracts in the Semantic Web, 2nd International Semantic Web
  Policy Workshop (SWPW'06), Nov. 5-9, 2006, Athens, GA, USA</journal-ref><abstract>  Rule-based policy and contract systems have rarely been studied in terms of
their software engineering properties. This is a serious omission, because in
rule-based policy or contract representation languages rules are being used as
a declarative programming language to formalize real-world decision logic and
create IS production systems upon. This paper adopts an SE methodology from
extreme programming, namely test driven development, and discusses how it can
be adapted to verification, validation and integrity testing (V&amp;V&amp;I) of policy
and contract specifications. Since, the test-driven approach focuses on the
behavioral aspects and the drawn conclusions instead of the structure of the
rule base and the causes of faults, it is independent of the complexity of the
rule language and the system under test and thus much easier to use and
understand for the rule engineer and the user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609120</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609120</id><created>2006-09-21</created><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>Rule-based Knowledge Representation for Service Level Agreement</title><categories>cs.AI cs.DB cs.LO cs.MA cs.SE</categories><comments>Doctoral Symposium of 4th Conf. on Multiagent System Technologies
  (MATES'06), Germany, 2006</comments><abstract>  Automated management and monitoring of service contracts like Service Level
Agreements (SLAs) or higher-level policies is vital for efficient and reliable
distributed service-oriented architectures (SOA) with high quality of ser-vice
(QoS) levels. IT service provider need to manage, execute and maintain
thousands of SLAs for different customers and different types of services,
which needs new levels of flexibility and automation not available with the
current technol-ogy. I propose a novel rule-based knowledge representation (KR)
for SLA rules and a respective rule-based service level management (RBSLM)
framework. My rule-based approach based on logic programming provides several
advantages including automated rule chaining allowing for compact knowledge
representation and high levels of automation as well as flexibility to adapt to
rapidly changing business requirements. Therewith, I address an urgent need
service-oriented busi-nesses do have nowadays which is to dynamically change
their business and contractual logic in order to adapt to rapidly changing
business environments and to overcome the restricting nature of slow change
cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609121</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609121</id><created>2006-09-21</created><authors><author><keyname>de Rooij</keyname><forenames>Steven</forenames></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames></author></authors><title>Approximating Rate-Distortion Graphs of Individual Data: Experiments in
  Lossy Compression and Denoising</title><categories>cs.IT math.IT</categories><comments>22 pages, submitted to IEEE transactions on information theory</comments><acm-class>E.4; H.1.1</acm-class><abstract>  Classical rate-distortion theory requires knowledge of an elusive source
distribution. Instead, we analyze rate-distortion properties of individual
objects using the recently developed algorithmic rate-distortion theory. The
latter is based on the noncomputable notion of Kolmogorov complexity. To apply
the theory we approximate the Kolmogorov complexity by standard data
compression techniques, and perform a number of experiments with lossy
compression and denoising of objects from different domains. We also introduce
a natural generalization to lossy compression with side information. To
maintain full generality we need to address a difficult searching problem.
While our solutions are therefore not time efficient, we do observe good
denoising and compression performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609122</identifier>
 <datestamp>2007-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609122</id><created>2006-09-21</created><updated>2007-07-21</updated><authors><author><keyname>Yuksel</keyname><forenames>Melda</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>Multi-Antenna Cooperative Wireless Systems: A Diversity-Multiplexing
  Tradeoff Perspective</title><categories>cs.IT math.IT</categories><comments>version 1: 58 pages, 15 figures, Submitted to IEEE Transactions on
  Information Theory, version 2: Final version, to appear IEEE IT, title
  changed, extra figures added</comments><abstract>  We consider a general multiple antenna network with multiple sources,
multiple destinations and multiple relays in terms of the
diversity-multiplexing tradeoff (DMT). We examine several subcases of this most
general problem taking into account the processing capability of the relays
(half-duplex or full-duplex), and the network geometry (clustered or
non-clustered). We first study the multiple antenna relay channel with a
full-duplex relay to understand the effect of increased degrees of freedom in
the direct link. We find DMT upper bounds and investigate the achievable
performance of decode-and-forward (DF), and compress-and-forward (CF)
protocols. Our results suggest that while DF is DMT optimal when all terminals
have one antenna each, it may not maintain its good performance when the
degrees of freedom in the direct link is increased, whereas CF continues to
perform optimally. We also study the multiple antenna relay channel with a
half-duplex relay. We show that the half-duplex DMT behavior can significantly
be different from the full-duplex case. We find that CF is DMT optimal for
half-duplex relaying as well, and is the first protocol known to achieve the
half-duplex relay DMT. We next study the multiple-access relay channel (MARC)
DMT. Finally, we investigate a system with a single source-destination pair and
multiple relays, each node with a single antenna, and show that even under the
idealistic assumption of full-duplex relays and a clustered network, this
virtual multi-input multi-output (MIMO) system can never fully mimic a real
MIMO DMT. For cooperative systems with multiple sources and multiple
destinations the same limitation remains to be in effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609123</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609123</id><created>2006-09-21</created><authors><author><keyname>Huang</keyname><forenames>Xiang</forenames></author><author><keyname>Wu</keyname><forenames>Xiaolin</forenames></author></authors><title>Optimal Design of Multiple Description Lattice Vector Quantizers</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory, Sep 2006 (30 pages, 7
  figures)</comments><abstract>  In the design of multiple description lattice vector quantizers (MDLVQ),
index assignment plays a critical role. In addition, one also needs to choose
the Voronoi cell size of the central lattice v, the sublattice index N, and the
number of side descriptions K to minimize the expected MDLVQ distortion, given
the total entropy rate of all side descriptions Rt and description loss
probability p. In this paper we propose a linear-time MDLVQ index assignment
algorithm for any K &gt;= 2 balanced descriptions in any dimensions, based on a
new construction of so-called K-fraction lattice. The algorithm is greedy in
nature but is proven to be asymptotically (N -&gt; infinity) optimal for any K &gt;=
2 balanced descriptions in any dimensions, given Rt and p. The result is
stronger when K = 2: the optimality holds for finite N as well, under some mild
conditions. For K &gt; 2, a local adjustment algorithm is developed to augment the
greedy index assignment, and conjectured to be optimal for finite N.
  Our algorithmic study also leads to better understanding of v, N and K in
optimal MDLVQ design. For K = 2 we derive, for the first time, a
non-asymptotical closed form expression of the expected distortion of optimal
MDLVQ in p, Rt, N. For K &gt; 2, we tighten the current asymptotic formula of the
expected distortion, relating the optimal values of N and K to p and Rt more
precisely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609124</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609124</id><created>2006-09-22</created><authors><author><keyname>Mayero</keyname><forenames>Micaela</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>The Three Gap Theorem (Steinhauss Conjecture)</title><categories>cs.LO</categories><proxy>ccsd ccsd-00090031</proxy><journal-ref>Types for Proofs and Programs: International Workshop, TYPES'99,
  L\&quot;{o}keberg, Sweden, June 1999. Selected Papers (2000) 162</journal-ref><abstract>  We deal with the distribution of N points placed consecutively around the
circle by a fixed angle of a. From the proof of Tony van Ravenstein, we propose
a detailed proof of the Steinhaus conjecture whose result is the following: the
N points partition the circle into gaps of at most three different lengths. We
study the mathematical notions required for the proof of this theorem revealed
during a formal proof carried out in Coq.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609125</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609125</id><created>2006-09-22</created><authors><author><keyname>Gordon</keyname><forenames>Goren</forenames></author><author><keyname>Einziger-Lowicz</keyname><forenames>Uri</forenames></author></authors><title>Problem Evolution: A new approach to problem solving systems</title><categories>cs.NE</categories><comments>10 pages, 2 figures</comments><abstract>  In this paper we present a novel tool to evaluate problem solving systems.
Instead of using a system to solve a problem, we suggest using the problem to
evaluate the system. By finding a numerical representation of a problem's
complexity, one can implement genetic algorithm to search for the most complex
problem the given system can solve. This allows a comparison between different
systems that solve the same set of problems. In this paper we implement this
approach on pattern recognition neural networks to try and find the most
complex pattern a given configuration can solve. The complexity of the pattern
is calculated using linguistic complexity. The results demonstrate the power of
the problem evolution approach in ranking different neural network
configurations according to their pattern recognition abilities. Future
research and implementations of this technique are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609126</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609126</id><created>2006-09-22</created><authors><author><keyname>Henneken</keyname><forenames>Edwin A.</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Warner</keyname><forenames>Simeon</forenames></author><author><keyname>Ginsparg</keyname><forenames>Paul</forenames></author><author><keyname>Eichhorn</keyname><forenames>Guenther</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Thompson</keyname><forenames>Donna</forenames></author><author><keyname>Bohlen</keyname><forenames>Elizabeth</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>E-prints and Journal Articles in Astronomy: a Productive Co-existence</title><categories>cs.DL astro-ph</categories><comments>8 pages, 4 figures, submitted to Learned Publishing</comments><journal-ref>Learn.Publ.20:16-22,2007</journal-ref><doi>10.1087/095315107779490661</doi><abstract>  Are the e-prints (electronic preprints) from the arXiv repository being used
instead of the journal articles? In this paper we show that the e-prints have
not undermined the usage of journal papers in the astrophysics community. As
soon as the journal article is published, the astronomical community prefers to
read the journal article and the use of e-prints through the NASA Astrophysics
Data System drops to zero. This suggests that the majority of astronomers have
access to institutional subscriptions and that they choose to read the journal
article when given the choice. Within the NASA Astrophysics Data System they
are given this choice, because the e-print and the journal article are treated
equally, since both are just one click away. In other words, the e-prints have
not undermined journal use in the astrophysics community and thus currently do
not pose a financial threat to the publishers. We present readership data for
the arXiv category &quot;astro-ph&quot; and the 4 core journals in astronomy
(Astrophysical Journal, Astronomical Journal, Monthly Notices of the Royal
Astronomical Society and Astronomy &amp; Astrophysics). Furthermore, we show that
the half-life (the point where the use of an article drops to half the use of a
newly published article) for an e-print is shorter than for a journal paper.
  The ADS is funded by NASA Grant NNG06GG68G. arXiv receives funding from NSF
award #0404553
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609127</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609127</id><created>2006-09-22</created><authors><author><keyname>Ada</keyname><forenames>Anil</forenames></author><author><keyname>Coggan</keyname><forenames>Melanie</forenames></author><author><keyname>Di Marco</keyname><forenames>Paul</forenames></author><author><keyname>Doyon</keyname><forenames>Alain</forenames></author><author><keyname>Flookes</keyname><forenames>Liam</forenames></author><author><keyname>Heilala</keyname><forenames>Samuli</forenames></author><author><keyname>Kim</keyname><forenames>Ethan</forenames></author><author><keyname>Wing</keyname><forenames>Jonathan Li On</forenames></author><author><keyname>Preville-Ratelle</keyname><forenames>Louis-Francois</forenames></author><author><keyname>Whitesides</keyname><forenames>Sue</forenames></author><author><keyname>Yu</keyname><forenames>Nuo</forenames></author></authors><title>On Bus Graph Realizability</title><categories>cs.CG cs.DM</categories><comments>Tech Report in School of Computer Science, McGill University Poster
  version of this paper was presented at the International Symposium on Graph
  Drawing 2006</comments><report-no>SOCS-TR-2006.1</report-no><abstract>  In this paper, we consider the following graph embedding problem: Given a
bipartite graph G = (V1; V2;E), where the maximum degree of vertices in V2 is
4, can G be embedded on a two dimensional grid such that each vertex in V1 is
drawn as a line segment along a grid line, each vertex in V2 is drawn as a
point at a grid point, and each edge e = (u; v) for some u 2 V1 and v 2 V2 is
drawn as a line segment connecting u and v, perpendicular to the line segment
for u? We show that this problem is NP-complete, and sketch how our proof
techniques can be used to show the hardness of several other related problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609128</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609128</id><created>2006-09-22</created><authors><author><keyname>Diaz</keyname><forenames>Josep</forenames></author><author><keyname>Kaminski</keyname><forenames>Marcin</forenames></author></authors><title>Max-Cut and Max-Bisection are NP-hard on unit disk graphs</title><categories>cs.DS cs.CC</categories><abstract>  We prove that the Max-Cut and Max-Bisection problems are NP-hard on unit disk
graphs. We also show that $\lambda$-precision graphs are planar for $\lambda$ &gt;
1 / \sqrt{2}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609129</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609129</id><created>2006-09-22</created><updated>2006-09-24</updated><authors><author><keyname>Rosa</keyname><forenames>Alessandro</forenames></author></authors><title>One approach to the digital visualization of hedgehogs in holomorphic
  dynamics</title><categories>cs.MS math.DS</categories><comments>29 pages, 51 figures</comments><journal-ref>Electronic Journal of Differential Equations and Control
  Processes, n.1, 2007</journal-ref><abstract>  In the field of holomorphic dynamics in one complex variable, hedgehog is the
local invariant set arising about a Cremer point and endowed with a very
complicate shape as well as relating to very weak numerical conditions. We give
a solution to the open problem of its digital visualization, featuring either a
time saving approach and a far-reaching insight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609130</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609130</id><created>2006-09-23</created><authors><author><keyname>Caporaso</keyname><forenames>Salvatore</forenames></author></authors><title>A Predicative Harmonization of the Time and Provable Hierarchies</title><categories>cs.LO cs.CC</categories><comments>11 pages</comments><abstract>  A decidable transfinite hierarchy is defined by assigning ordinals to the
programs of an imperative language. It singles out: the classes TIMEF(n^c) and
TIMEF(n_c); the finite Grzegorczyk classes at and above the elementary level,
and the \Sigma_k-IND fragments of PA. Limited operators, diagonalization, and
majorization functions are not used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609131</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609131</id><created>2006-09-24</created><authors><author><keyname>Ren</keyname><forenames>Ran</forenames></author><author><keyname>Manokar</keyname><forenames>Madan mohan</forenames></author><author><keyname>Shi</keyname><forenames>Yaogang</forenames></author><author><keyname>Zheng</keyname><forenames>Baoyu</forenames></author></authors><title>A Fast Block Matching Algorithm for Video Motion Estimation Based on
  Particle Swarm Optimization and Motion Prejudgment</title><categories>cs.MM</categories><comments>10 pages, 12 figures, submitted to ACM Symposium of Applied
  Computing(SAC)</comments><abstract>  In this paper, we propose a fast 2-D block-based motion estimation algorithm
called Particle Swarm Optimization - Zero-motion Prejudgment(PSO-ZMP) which
consists of three sequential routines: 1)Zero-motion prejudgment. The routine
aims at finding static macroblocks(MB) which do not need to perform remaining
search thus reduces the computational cost; 2)Predictive image coding and 3)PSO
matching routine. Simulation results obtained show that the proposed PSO-ZMP
algorithm achieves over 10 times of computation less than Diamond Search(DS)
and 5 times less than the recent proposed Adaptive Rood Pattern
Searching(ARPS). Meanwhile the PSNR performances using PSO-ZMP are very close
to that using DS and ARPS in some less-motioned sequences. While in some
sequences containing dense and complex motion contents, the PSNR performances
of PSO-ZMP are several dB lower than that using DS and ARPS but in an
acceptable degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609132</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609132</id><created>2006-09-24</created><authors><author><keyname>Gruber</keyname><forenames>Jochen</forenames></author></authors><title>Semantic Description of Parameters in Web Service Annotations</title><categories>cs.AI</categories><comments>7 pages, 3 figures</comments><acm-class>F.3.0</acm-class><abstract>  A modification of OWL-S regarding parameter description is proposed. It is
strictly based on Description Logic. In addition to class description of
parameters it also allows the modelling of relations between parameters and the
precise description of the size of data to be supplied to a service. In
particular, it solves two major issues identified within current proposals for
a Semantic Web Service annotation standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609133</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609133</id><created>2006-09-24</created><authors><author><keyname>Mekki</keyname><forenames>Touria A&#xef;t El</forenames><affiliation>LERIA</affiliation></author><author><keyname>Nazarenko</keyname><forenames>Adeline</forenames><affiliation>LIPN</affiliation></author></authors><title>An application-oriented terminology evaluation: the case of back-of-the
  book indexes</title><categories>cs.AI cs.IR</categories><comments>4 pages</comments><proxy>ccsd ccsd-00098033</proxy><acm-class>H.3.1</acm-class><journal-ref>Workshop on Terminology design: quality criteria and evaluation
  methods (TermEval), Italie (2006) 18-21</journal-ref><abstract>  This paper addresses the problem of computational terminology evaluation not
per se but in a specific application context. This paper describes the
evaluation procedure that has been used to assess the validity of our overall
indexing approach and the quality of the IndDoc indexing tool. Even if
user-oriented extended evaluation is irreplaceable, we argue that early
evaluations are possible and they are useful for development guidance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609134</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609134</id><created>2006-09-24</created><authors><author><keyname>Mekki</keyname><forenames>Touria A&#xef;t El</forenames><affiliation>LIPN</affiliation></author><author><keyname>Nazarenko</keyname><forenames>Adeline</forenames><affiliation>LERIA</affiliation></author></authors><title>Using NLP to build the hypertextuel network of a back-of-the-book index</title><categories>cs.AI cs.IR</categories><proxy>ccsd ccsd-00098036</proxy><acm-class>H.3.1</acm-class><journal-ref>Proceedings of the International Conference on Recent Advances in
  Natural Language Processing (RANLP) (2005) 316-320</journal-ref><abstract>  Relying on the idea that back-of-the-book indexes are traditional devices for
navigation through large documents, we have developed a method to build a
hypertextual network that helps the navigation in a document. Building such an
hypertextual network requires selecting a list of descriptors, identifying the
relevant text segments to associate with each descriptor and finally ranking
the descriptors and reference segments by relevance order. We propose a
specific document segmentation method and a relevance measure for information
ranking. The algorithms are tested on 4 corpora (of different types and
domains) without human intervention or any semantic knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609135</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609135</id><created>2006-09-24</created><authors><author><keyname>Alphonse</keyname><forenames>Erick</forenames><affiliation>MIG</affiliation></author><author><keyname>Aubin</keyname><forenames>Sophie</forenames><affiliation>LIPN</affiliation></author><author><keyname>Bessi&#xe8;res</keyname><forenames>Philippe</forenames><affiliation>MIG</affiliation></author><author><keyname>Bisson</keyname><forenames>Gilles</forenames><affiliation>Leibniz - IMAG</affiliation></author><author><keyname>Hamon</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author><author><keyname>Lagarrigue</keyname><forenames>Sandrine</forenames><affiliation>INRA-ENSAR</affiliation></author><author><keyname>Nazarenko</keyname><forenames>Adeline</forenames><affiliation>LIPN</affiliation></author><author><keyname>Manine</keyname><forenames>Alain-Pierre</forenames><affiliation>MIG</affiliation></author><author><keyname>N&#xe9;dellec</keyname><forenames>Claire</forenames><affiliation>MIG</affiliation></author><author><keyname>Vetah</keyname><forenames>Mohamed Ould Abdel</forenames><affiliation>MIG</affiliation></author><author><keyname>Poibeau</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author><author><keyname>Weissenbacher</keyname><forenames>Davy</forenames><affiliation>LIPN</affiliation></author></authors><title>Event-based Information Extraction for the biomedical domain: the
  Caderige project</title><categories>cs.AI cs.IR</categories><proxy>ccsd ccsd-00098040</proxy><acm-class>H.3.1</acm-class><journal-ref>Proceedings of the International Joint Workshop on Natural
  Language Processing in Biomedicine and Its Applications (COLING'04), Suisse
  (2004) 43-39</journal-ref><abstract>  This paper gives an overview of the Caderige project. This project involves
teams from different areas (biology, machine learning, natural language
processing) in order to develop high-level analysis tools for extracting
structured information from biological bibliographical databases, especially
Medline. The paper gives an overview of the approach and compares it to the
state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609136</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609136</id><created>2006-09-24</created><authors><author><keyname>Nazarenko</keyname><forenames>Adeline</forenames><affiliation>LIPN</affiliation></author><author><keyname>Alphonse</keyname><forenames>Erick</forenames><affiliation>LIPN</affiliation></author><author><keyname>Derivi&#xe8;re</keyname><forenames>Julien</forenames><affiliation>LIPN</affiliation></author><author><keyname>Hamon</keyname><forenames>Thierry</forenames><affiliation>LIPN</affiliation></author><author><keyname>Vauvert</keyname><forenames>Guillaume</forenames><affiliation>LIPN</affiliation></author><author><keyname>Weissenbacher</keyname><forenames>Davy</forenames><affiliation>LIPN</affiliation></author></authors><title>The ALVIS Format for Linguistically Annotated Documents</title><categories>cs.AI</categories><proxy>ccsd ccsd-00080472</proxy><acm-class>H.3.1</acm-class><journal-ref>Proceedings of the fifth international conference on Language
  Resources and Evaluation, LREC 2006 (2006) 1782-1786</journal-ref><abstract>  The paper describes the ALVIS annotation format designed for the indexing of
large collections of documents in topic-specific search engines. This paper is
exemplified on the biological domain and on MedLine abstracts, as developing a
specialized search engine for biologists is one of the ALVIS case studies. The
ALVIS principle for linguistic annotations is based on existing works and
standard propositions. We made the choice of stand-off annotations rather than
inserted mark-up. Annotations are encoded as XML elements which form the
linguistic subsection of the document record.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609137</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609137</id><created>2006-09-24</created><authors><author><keyname>N&#xe9;dellec</keyname><forenames>Claire</forenames><affiliation>MIG</affiliation></author><author><keyname>Nazarenko</keyname><forenames>Adeline</forenames><affiliation>LIPN</affiliation></author></authors><title>Ontologies and Information Extraction</title><categories>cs.AI cs.IR</categories><proxy>ccsd ccsd-00098068</proxy><acm-class>H.3.1</acm-class><journal-ref>LIPN Internal Report (2005)</journal-ref><abstract>  This report argues that, even in the simplest cases, IE is an ontology-driven
process. It is not a mere text filtering method based on simple pattern
matching and keywords, because the extracted pieces of texts are interpreted
with respect to a predefined partial domain model. This report shows that
depending on the nature and the depth of the interpretation to be done for
extracting the information, more or less knowledge must be involved. This
report is mainly illustrated in biology, a domain in which there are critical
needs for content-based exploration of the scientific literature and which
becomes a major application domain for IE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609138</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609138</id><created>2006-09-25</created><authors><author><keyname>Roos</keyname><forenames>Teemu</forenames></author><author><keyname>Myllym&#xe4;ki</keyname><forenames>Petri</forenames></author><author><keyname>Rissanen</keyname><forenames>Jorma</forenames></author></authors><title>MDL Denoising Revisited</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, June 2006</comments><abstract>  We refine and extend an earlier MDL denoising criterion for wavelet-based
denoising. We start by showing that the denoising problem can be reformulated
as a clustering problem, where the goal is to obtain separate clusters for
informative and non-informative wavelet coefficients, respectively. This
suggests two refinements, adding a code-length for the model index, and
extending the model in order to account for subband-dependent coefficient
distributions. A third refinement is derivation of soft thresholding inspired
by predictive universal coding with weighted mixtures. We propose a practical
method incorporating all three refinements, which is shown to achieve good
performance and robustness in denoising both artificial and natural signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609139</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609139</id><created>2006-09-25</created><authors><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author><author><keyname>Mitter</keyname><forenames>Sanjoy</forenames></author></authors><title>The Capacity of Channels with Feedback</title><categories>cs.IT math.IT</categories><abstract>  We introduce a general framework for treating channels with memory and
feedback. First, we generalize Massey's concept of directed information and use
it to characterize the feedback capacity of general channels. Second, we
present coding results for Markov channels. This requires determining
appropriate sufficient statistics at the encoder and decoder. Third, a dynamic
programming framework for computing the capacity of Markov channels is
presented. Fourth, it is shown that the average cost optimality equation (ACOE)
can be viewed as an implicit single-letter characterization of the capacity.
Fifth, scenarios with simple sufficient statistics are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609140</identifier>
 <datestamp>2008-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609140</id><created>2006-09-25</created><updated>2008-10-15</updated><authors><author><keyname>Perk</keyname><forenames>Baris E.</forenames></author><author><keyname>Slotine</keyname><forenames>J. J. E.</forenames></author></authors><title>Motion Primitives for Robotic Flight Control</title><categories>cs.RO cs.LG</categories><comments>The paper has been revised with small editorial changes and updated
  references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a simple framework for learning aggressive maneuvers in flight
control of UAVs. Having inspired from biological environment, dynamic movement
primitives are analyzed and extended using nonlinear contraction theory.
Accordingly, primitives of an observed movement are stably combined and
concatenated. We demonstrate our results experimentally on the Quanser
Helicopter, in which we first imitate aggressive maneuvers and then use them as
primitives to achieve new maneuvers that can fly over an obstacle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609141</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609141</id><created>2006-09-25</created><authors><author><keyname>Pinelis</keyname><forenames>Iosif</forenames></author></authors><title>Polygon Convexity: A Minimal O(n) Test</title><categories>cs.CG cs.CC math.CO math.MG</categories><comments>14 pages</comments><acm-class>I.3.5; F.2.2; G.2.1; G.2.2</acm-class><abstract>  An O(n) test for polygon convexity is stated and proved. It is also proved
that the test is minimal in a certain exact sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609142</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609142</id><created>2006-09-26</created><authors><author><keyname>Scherrer</keyname><forenames>Bruno</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Modular self-organization</title><categories>cs.AI</categories><proxy>ccsd inria-00098315</proxy><abstract>  The aim of this paper is to provide a sound framework for addressing a
difficult problem: the automatic construction of an autonomous agent's modular
architecture. We combine results from two apparently uncorrelated domains:
Autonomous planning through Markov Decision Processes and a General Data
Clustering Approach using a kernel-like method. Our fundamental idea is that
the former is a good framework for addressing autonomy whereas the latter
allows to tackle self-organizing problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609143</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609143</id><created>2006-09-26</created><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>ECA-LP / ECA-RuleML: A Homogeneous Event-Condition-Action Logic
  Programming Language</title><categories>cs.AI cs.LO cs.SE</categories><comments>Paschke, A.: ECA-LP / ECA-RuleML: A Homogeneous
  Event-Condition-Action Logic Programming Language, Int. Conf. on Rules and
  Rule Markup Languages for the Semantic Web (RuleML06), Athens, Georgia, USA,
  Nov. 2006</comments><acm-class>I.2</acm-class><journal-ref>Paschke, A.: ECA-LP / ECA-RuleML: A Homogeneous
  Event-Condition-Action Logic Programming Language, Int. Conf. on Rules and
  Rule Markup Languages for the Semantic Web (RuleML06), Athens, Georgia, USA,
  Nov. 2006</journal-ref><abstract>  Event-driven reactive functionalities are an urgent need in nowadays
distributed service-oriented applications and (Semantic) Web-based
environments. An important problem to be addressed is how to correctly and
efficiently capture and process the event-based behavioral, reactive logic
represented as ECA rules in combination with other conditional decision logic
which is represented as derivation rules. In this paper we elaborate on a
homogeneous integration approach which combines derivation rules, reaction
rules (ECA rules) and other rule types such as integrity constraint into the
general framework of logic programming. The developed ECA-LP language provides
expressive features such as ID-based updates with support for external and
self-updates of the intensional and extensional knowledge, transac-tions
including integrity testing and an event algebra to define and process complex
events and actions based on a novel interval-based Event Calculus variant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609144</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609144</id><created>2006-09-26</created><authors><author><keyname>Jimenez-Ruiz</keyname><forenames>E.</forenames></author><author><keyname>Berlanga</keyname><forenames>R.</forenames></author><author><keyname>Sanz</keyname><forenames>I.</forenames></author><author><keyname>McClatchey</keyname><forenames>R.</forenames></author><author><keyname>Danger</keyname><forenames>R.</forenames></author><author><keyname>Manset</keyname><forenames>D.</forenames></author><author><keyname>Paraire</keyname><forenames>J.</forenames></author><author><keyname>Rios</keyname><forenames>A.</forenames></author></authors><title>The Management and Integration of Biomedical Knowledge: Application in
  the Health-e-Child Project (Position Paper)</title><categories>cs.DB</categories><comments>6 pages; 2 figures. Proceedings of the 1st International Workshop on
  Ontology content and evaluation in Enterprise</comments><acm-class>H.2.4; J.3</acm-class><abstract>  The Health-e-Child project aims to develop an integrated healthcare platform
for European paediatrics. In order to achieve a comprehensive view of childrens
health, a complex integration of biomedical data, information, and knowledge is
necessary. Ontologies will be used to formally define this domain knowledge and
will form the basis for the medical knowledge management system. This paper
introduces an innovative methodology for the vertical integration of biomedical
knowledge. This approach will be largely clinician-centered and will enable the
definition of ontology fragments, connections between them (semantic bridges)
and enriched ontology fragments (views). The strategy for the specification and
capture of fragments, bridges and views is outlined with preliminary examples
demonstrated in the collection of biomedical information from hospital
databases, biomedical ontologies, and biomedical public databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609145</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609145</id><created>2006-09-26</created><authors><author><keyname>d'Aspremont</keyname><forenames>Alexandre</forenames></author><author><keyname>Ghaoui</keyname><forenames>Laurent El</forenames></author></authors><title>A Semidefinite Relaxation for Air Traffic Flow Scheduling</title><categories>cs.CE</categories><comments>Submitted to RIVF 2007</comments><abstract>  We first formulate the problem of optimally scheduling air traffic low with
sector capacity constraints as a mixed integer linear program. We then use
semidefinite relaxation techniques to form a convex relaxation of that problem.
Finally, we present a randomization algorithm to further improve the quality of
the solution. Because of the specific structure of the air traffic flow
problem, the relaxation has a single semidefinite constraint of size dn where d
is the maximum delay and n the number of flights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609146</identifier>
 <datestamp>2008-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609146</id><created>2006-09-26</created><authors><author><keyname>Krishnan</keyname><forenames>K. Murali</forenames></author><author><keyname>Singh</keyname><forenames>Rajdeep</forenames></author><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Shankar</keyname><forenames>Priti</forenames></author></authors><title>A Combinatorial Family of Near Regular LDPC Codes</title><categories>cs.IT math.IT</categories><comments>5 pages 3 figures</comments><journal-ref>ISIT 2007</journal-ref><abstract>  An elementary combinatorial Tanner graph construction for a family of
near-regular low density parity check codes achieving high girth is presented.
The construction allows flexibility in the choice of design parameters like
rate, average degree, girth and block length of the code and yields an
asymptotic family. The complexity of constructing codes in the family grows
only quadratically with the block length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609147</identifier>
 <datestamp>2007-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609147</id><created>2006-09-26</created><updated>2007-02-19</updated><authors><author><keyname>Marin</keyname><forenames>Marius</forenames></author><author><keyname>van Deursen</keyname><forenames>Arie</forenames></author><author><keyname>Moonen</keyname><forenames>Leon</forenames></author></authors><title>Identifying Crosscutting Concerns Using Fan-in Analysis</title><categories>cs.SE</categories><comments>34+4 pages; Extended version [Marin et al. 2004a]</comments><report-no>TUD-SERG-2006-013</report-no><acm-class>D.2.3; D.2.7; D.2.8</acm-class><journal-ref>ACM Transactions on Software Engineering and Methodology, 2007</journal-ref><abstract>  Aspect mining is a reverse engineering process that aims at finding
crosscutting concerns in existing systems. This paper proposes an aspect mining
approach based on determining methods that are called from many different
places, and hence have a high fan-in, which can be seen as a symptom of
crosscutting functionality. The approach is semi-automatic, and consists of
three steps: metric calculation, method filtering, and call site analysis.
Carrying out these steps is an interactive process supported by an Eclipse
plug-in called FINT. Fan-in analysis has been applied to three open source Java
systems, totaling around 200,000 lines of code. The most interesting concerns
identified are discussed in detail, which includes several concerns not
previously discussed in the aspect-oriented literature. The results show that a
significant number of crosscutting concerns can be recognized using fan-in
analysis, and each of the three steps can be supported by tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609148</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609148</id><created>2006-09-26</created><authors><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Pusane</keyname><forenames>Ali E.</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author><author><keyname>Costello</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>Pseudo-Codeword Performance Analysis for LDPC Convolutional Codes</title><categories>cs.IT math.IT</categories><comments>26 pages, 6 figures, 2 tables</comments><abstract>  Message-passing iterative decoders for low-density parity-check (LDPC) block
codes are known to be subject to decoding failures due to so-called
pseudo-codewords. These failures can cause the large signal-to-noise ratio
performance of message-passing iterative decoding to be worse than that
predicted by the maximum-likelihood decoding union bound. In this paper we
address the pseudo-codeword problem from the convolutional-code perspective. In
particular, we compare the performance of LDPC convolutional codes with that of
their ``wrapped'' quasi-cyclic block versions and we show that the minimum
pseudo-weight of an LDPC convolutional code is at least as large as the minimum
pseudo-weight of an underlying quasi-cyclic code. This result, which parallels
a well-known relationship between the minimum Hamming weight of convolutional
codes and the minimum Hamming weight of their quasi-cyclic counterparts, is due
to the fact that every pseudo-codeword in the convolutional code induces a
pseudo-codeword in the block code with pseudo-weight no larger than that of the
convolutional code's pseudo-codeword. This difference in the weight spectra
leads to improved performance at low-to-moderate signal-to-noise ratios for the
convolutional code, a conclusion supported by simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609149</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609149</id><created>2006-09-27</created><authors><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Sadler</keyname><forenames>Brian M.</forenames></author></authors><title>Dynamic Spectrum Access: Signal Processing, Networking, and Regulatory
  Policy</title><categories>cs.NI</categories><comments>20 pages, 7 figures, submitted to IEEE Signal Processing Magazine</comments><abstract>  In this article, we first provide a taxonomy of dynamic spectrum access. We
then focus on opportunistic spectrum access, the overlay approach under the
hierarchical access model of dynamic spectrum access. we aim to provide an
overview of challenges and recent developments in both technological and
regulatory aspects of opportunistic spectrum access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609150</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609150</id><created>2006-09-27</created><authors><author><keyname>Brahimi</keyname><forenames>Belynda</forenames><affiliation>CRAN</affiliation></author><author><keyname>Aubrun</keyname><forenames>Christophe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Rondeau</keyname><forenames>Eric</forenames><affiliation>CRAN</affiliation></author></authors><title>Modelling and Simulation of Scheduling Policies Implemented in Ethernet
  Switch by Using Coloured Petri Nets</title><categories>cs.NI</categories><comments>8 pages</comments><proxy>ccsd ccsd-00101374</proxy><journal-ref>11th IEEE International Conference on Emerging Technologies and
  Factory Automation, Tch\`{e}que, R\'{e}publique (2006) 667 - 674</journal-ref><abstract>  The objective of this paper is to propose models enabling to study the
behaviour of Ethernet switch for Networked Control Systems. Two scheduler
policies are analyzed: the static priority and the WRR (Weighted Round Robin).
The modelling work is based on Coloured Petri Nets. A temporal validation step
based on the simulation of these modelling, shows that the obtained results are
near to the expected behaviour of these scheduler policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609151</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609151</id><created>2006-09-27</created><authors><author><keyname>Vatanski</keyname><forenames>Nikolai</forenames><affiliation>CRAN</affiliation></author><author><keyname>Georges</keyname><forenames>Jean-Philippe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Aubrun</keyname><forenames>Christophe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Rondeau</keyname><forenames>Eric</forenames><affiliation>CRAN</affiliation></author><author><keyname>Jounela</keyname><forenames>Sirkka-Liisa J&#xe4;ms&#xe4;</forenames></author></authors><title>Control compensation based on upper bound delay in networked control
  systems</title><categories>cs.NI</categories><comments>6 pages</comments><proxy>ccsd ccsd-00101375</proxy><journal-ref>17th International Symposium on Mathematical Theory of Networks
  and Systems (MTNS), Japon (2006)</journal-ref><abstract>  Recent interest in networked control systems (NCS) has instigated research in
both communication networks and control. Analysis of NCSs has usually been
performed from either the network or the control point of view, but not many
papers exist where the analysis of both is done in the same context. In this
paper an overall analysis of the networked control system is presented. First,
the procedure of obtaining the upper bound delay value for packet transmission
in the switched Ethernet network is presented. Next, the obtained delay
estimate is utilised in delay compensation for improving the Quality of
Performance (QoP) of the control systems. The presented upper bound delay
algorithm applies ideas from network calculus theory. For the improvement of
QoP, two delay compensation strategies, the Smith predictor based and the
robust control based delay compensation strategies, are presented and compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609152</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609152</id><created>2006-09-27</created><authors><author><keyname>Georges</keyname><forenames>Jean-Philippe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Vatanski</keyname><forenames>Nikolai</forenames><affiliation>CRAN</affiliation></author><author><keyname>Rondeau</keyname><forenames>Eric</forenames><affiliation>CRAN</affiliation></author><author><keyname>Jounela</keyname><forenames>Sirkka-Liisa J&#xe4;ms&#xe4;</forenames></author></authors><title>Use of upper bound delay estimate in stability analysis and robust
  control compensation in networked control systems</title><categories>cs.NI</categories><comments>6 pages</comments><proxy>ccsd ccsd-00101537</proxy><journal-ref>12th IFAC Symposium on Information Control Problems in
  Manufacturing, INCOM 2006, St-Etienne, France (16/05/2006) CDROM</journal-ref><abstract>  Recent interest in networked control systems (NCS) has instigated research in
various areas of both communication networks and control. The analysis of NCS
has often been performed either from the network, or the control point of view
and not many papers exist were the analysis of both is done in the same
context. Here a simple overall analysis is presented. In the paper the
procedure of obtaining the upper bound delay value in the switched Ethernet
network is proposed and the obtained delay estimate is used in stability
analysis of the feedback loop and in the control compensation. The upper bound
delay algorithm is based on the network calculus theory, the stability analysis
uses the small gain theorem, and control compensating strategy is based on
Smith predictor, where however the upper bound delay is utilised in obtaining
the delay estimate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609153</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609153</id><created>2006-09-27</created><authors><author><keyname>Dmitriev</keyname><forenames>Pavel</forenames></author><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author></authors><title>Mining Generalized Graph Patterns based on User Examples</title><categories>cs.DS cs.LG</categories><comments>11 pages, 11 figures. A short version of this paper appears in
  proceedings of ICDM-2006 conference</comments><abstract>  There has been a lot of recent interest in mining patterns from graphs.
Often, the exact structure of the patterns of interest is not known. This
happens, for example, when molecular structures are mined to discover fragments
useful as features in chemical compound classification task, or when web sites
are mined to discover sets of web pages representing logical documents. Such
patterns are often generated from a few small subgraphs (cores), according to
certain generalization rules (GRs). We call such patterns &quot;generalized
patterns&quot;(GPs). While being structurally different, GPs often perform the same
function in the network. Previously proposed approaches to mining GPs either
assumed that the cores and the GRs are given, or that all interesting GPs are
frequent. These are strong assumptions, which often do not hold in practical
applications. In this paper, we propose an approach to mining GPs that is free
from the above assumptions. Given a small number of GPs selected by the user,
our algorithm discovers all GPs similar to the user examples. First, a machine
learning-style approach is used to find the cores. Second, generalizations of
the cores in the graph are computed to identify GPs. Evaluation on synthetic
data, generated using real cores and GRs from biological and web domains,
demonstrates effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609154</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609154</id><created>2006-09-28</created><authors><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames></author></authors><title>Loop Calculus Helps to Improve Belief Propagation and Linear Programming
  Decodings of Low-Density-Parity-Check Codes</title><categories>cs.IT cond-mat.dis-nn cond-mat.stat-mech math.IT</categories><comments>10 pages, 2 figures; Invited talk at 44-th annual Allerton Conference
  on Communications, Control and Computing, Sep 27-Sep 29, 2006</comments><report-no>LAUR-06-6751</report-no><abstract>  We illustrate the utility of the recently developed loop calculus for
improving the Belief Propagation (BP) algorithm. If the algorithm that
minimizes the Bethe free energy fails we modify the free energy by accounting
for a critical loop in a graphical representation of the code. The
log-likelihood specific critical loop is found by means of the loop calculus.
The general method is tested using an example of the Linear Programming (LP)
decoding, that can be viewed as a special limit of the BP decoding. Considering
the (155,64,20) code that performs over Additive-White-Gaussian-Noise channel
we show that the loop calculus improves the LP decoding and corrects all
previously found dangerous configurations of log-likelihoods related to
pseudo-codewords with low effective distance, thus reducing the code's
error-floor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609155</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609155</id><created>2006-09-27</created><authors><author><keyname>Zhu</keyname><forenames>Ying</forenames></author><author><keyname>Cheng</keyname><forenames>Taikun</forenames></author><author><keyname>Sivakumar</keyname><forenames>Krishnamoorthy</forenames></author><author><keyname>Belzer</keyname><forenames>Benjamin J.</forenames></author></authors><title>Detection of Markov Random Fields on Two-Dimensional Intersymbol
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>8 pages, 17 figures</comments><abstract>  We present a novel iterative algorithm for detection of binary Markov random
fields (MRFs) corrupted by two-dimensional (2D) intersymbol interference (ISI)
and additive white Gaussian noise (AWGN). We assume a first-order binary MRF as
a simple model for correlated images. We assume a 2D digital storage channel,
where the MRF is interleaved before being written and then read by a 2D
transducer; such channels occur in recently proposed optical disk storage
systems. The detection algorithm is a concatenation of two
soft-input/soft-output (SISO) detectors: an iterative row-column soft-decision
feedback (IRCSDF) ISI detector, and a MRF detector. The MRF detector is a SISO
version of the stochastic relaxation algorithm by Geman and Geman in IEEE
Trans. Pattern Anal. and Mach. Intell., Nov. 1984. On the 2 x 2 averaging-mask
ISI channel, at a bit error rate (BER) of 10^{-5}, the concatenated algorithm
achieves SNR savings of between 0.5 and 2.0 dB over the IRCSDF detector alone;
the savings increase as the MRFs become more correlated, or as the SNR
decreases. The algorithm is also fairly robust to mismatches between the
assumed and actual MRF parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609156</identifier>
 <datestamp>2007-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609156</id><created>2006-09-28</created><authors><author><keyname>Rahiminia</keyname><forenames>Hadi</forenames></author><author><keyname>Amini</keyname><forenames>Massoud</forenames></author></authors><title>Entangled Graphs</title><categories>cs.IT cs.DM math.IT</categories><comments>Part of M.Sc. Thesis of the first author</comments><abstract>  In this paper we prove a separability criterion for mixed states in $\mathbb
C^p\otimes\mathbb C^q$. We also show that the density matrix of a graph with
only one entangled edge is entangled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609157</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609157</id><created>2006-09-29</created><updated>2006-09-30</updated><authors><author><keyname>Rezaeian</keyname><forenames>Mohammad</forenames></author></authors><title>Sensor Scheduling for Optimal Observability Using Estimation Entropy</title><categories>cs.IT cs.AI math.IT</categories><comments>5 pages, submitted to 2007 IEEE PerCom/PerSeNS conference</comments><acm-class>I.2.8; G.3; H.1.1</acm-class><abstract>  We consider sensor scheduling as the optimal observability problem for
partially observable Markov decision processes (POMDP). This model fits to the
cases where a Markov process is observed by a single sensor which needs to be
dynamically adjusted or by a set of sensors which are selected one at a time in
a way that maximizes the information acquisition from the process. Similar to
conventional POMDP problems, in this model the control action is based on all
past measurements; however here this action is not for the control of state
process, which is autonomous, but it is for influencing the measurement of that
process. This POMDP is a controlled version of the hidden Markov process, and
we show that its optimal observability problem can be formulated as an average
cost Markov decision process (MDP) scheduling problem. In this problem, a
policy is a rule for selecting sensors or adjusting the measuring device based
on the measurement history. Given a policy, we can evaluate the estimation
entropy for the joint state-measurement processes which inversely measures the
observability of state process for that policy. Considering estimation entropy
as the cost of a policy, we show that the problem of finding optimal policy is
equivalent to an average cost MDP scheduling problem where the cost function is
the entropy function over the belief space. This allows the application of the
policy iteration algorithm for finding the policy achieving minimum estimation
entropy, thus optimum observability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609158</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609158</id><created>2006-09-29</created><authors><author><keyname>Wong</keyname><forenames>Kwok-Wo</forenames></author><author><keyname>Kwok</keyname><forenames>Bernie Sin-Hung</forenames></author><author><keyname>Law</keyname><forenames>Wing-Shing</forenames></author></authors><title>A Fast Image Encryption Scheme based on Chaotic Standard Map</title><categories>cs.CR cs.MM</categories><comments>16 pages, 7 figures</comments><abstract>  In recent years, a variety of effective chaos-based image encryption schemes
have been proposed. The typical structure of these schemes has the permutation
and the diffusion stages performed alternatively. The confusion and diffusion
effect is solely contributed by the permutation and the diffusion stage,
respectively. As a result, more overall rounds than necessary are required to
achieve a certain level of security. In this paper, we suggest to introduce
certain diffusion effect in the confusion stage by simple sequential
add-and-shift operations. The purpose is to reduce the workload of the
time-consuming diffusion part so that fewer overall rounds and hence a shorter
encryption time is needed. Simulation results show that at a similar
performance level, the proposed cryptosystem needs less than one-third the
encryption time of an existing cryptosystem. The effective acceleration of the
encryption speed is thus achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609159</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609159</id><created>2006-09-29</created><updated>2006-12-11</updated><authors><author><keyname>Bras-Amor&#xf3;s</keyname><forenames>Maria</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Michael E.</forenames></author></authors><title>Duality for Several Families of Evaluation Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>Added references</comments><acm-class>E.4</acm-class><abstract>  We consider generalizations of Reed-Muller codes, toric codes, and codes from
certain plane curves, such as those defined by norm and trace functions on
finite fields. In each case we are interested in codes defined by evaluating
arbitrary subsets of monomials, and in identifying when the dual codes are also
obtained by evaluating monomials. We then move to the context of order domain
theory, in which the subsets of monomials can be chosen to optimize decoding
performance using the Berlekamp-Massey-Sakata algorithm with majority voting.
We show that for the codes under consideration these subsets are well-behaved
and the dual codes are also defined by monomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609160</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609160</id><created>2006-09-29</created><authors><author><keyname>Bras-Amor&#xf3;s</keyname><forenames>Maria</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Michael E.</forenames></author></authors><title>Redundancies of Correction-Capability-Optimized Reed-Muller Codes</title><categories>cs.IT cs.DM math.IT</categories><acm-class>E.4</acm-class><abstract>  This article is focused on some variations of Reed-Muller codes that yield
improvements to the rate for a prescribed decoding performance under the
Berlekamp-Massey-Sakata algorithm with majority voting. Explicit formulas for
the redundancies of the new codes are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609161</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609161</id><created>2006-09-29</created><updated>2006-11-15</updated><authors><author><keyname>Bras-Amor&#xf3;s</keyname><forenames>Maria</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Michael E.</forenames></author></authors><title>The Order Bound on the Minimum Distance of the One-Point Codes
  Associated to a Garcia-Stichtenoth Tower of Function Fields</title><categories>cs.IT cs.DM math.IT</categories><comments>A new section is added in which the order bound is derived</comments><acm-class>E.4</acm-class><abstract>  Garcia and Stichtenoth discovered two towers of function fields that meet the
Drinfeld-Vl\u{a}du\c{t} bound on the ratio of the number of points to the
genus. For one of these towers, Garcia, Pellikaan and Torres derived a
recursive description of the Weierstrass semigroups associated to a tower of
points on the associated curves. In this article, a non-recursive description
of the semigroups is given and from this the enumeration of each of the
semigroups is derived as well as its inverse. This enables us to find an
explicit formula for the order (Feng-Rao) bound on the minimum distance of the
associated one-point codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609162</identifier>
 <datestamp>2007-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609162</id><created>2006-09-29</created><updated>2006-11-15</updated><authors><author><keyname>Bras-Amor&#xf3;s</keyname><forenames>Maria</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Michael E.</forenames></author></authors><title>On Semigroups Generated by Two Consecutive Integers and Improved
  Hermitian Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>Added references</comments><acm-class>E.4</acm-class><abstract>  Analysis of the Berlekamp-Massey-Sakata algorithm for decoding one-point
codes leads to two methods for improving code rate. One method, due to Feng and
Rao, removes parity checks that may be recovered by their majority voting
algorithm. The second method is to design the code to correct only those error
vectors of a given weight that are also geometrically generic. In this work,
formulae are given for the redundancies of Hermitian codes optimized with
respect to these criteria as well as the formula for the order bound on the
minimum distance. The results proceed from an analysis of numerical semigroups
generated by two consecutive integers. The formula for the redundancy of
optimal Hermitian codes correcting a given number of errors answers an open
question stated by Pellikaan and Torres in 1999.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609163</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609163</id><created>2006-09-29</created><authors><author><keyname>Korman</keyname><forenames>Amos</forenames></author><author><keyname>Kutten</keyname><forenames>Shay</forenames></author></authors><title>Labeling Schemes with Queries</title><categories>cs.DC</categories><abstract>  We study the question of ``how robust are the known lower bounds of labeling
schemes when one increases the number of consulted labels''. Let $f$ be a
function on pairs of vertices. An $f$-labeling scheme for a family of graphs
$\cF$ labels the vertices of all graphs in $\cF$ such that for every graph
$G\in\cF$ and every two vertices $u,v\in G$, the value $f(u,v)$ can be inferred
by merely inspecting the labels of $u$ and $v$.
  This paper introduces a natural generalization: the notion of $f$-labeling
schemes with queries, in which the value $f(u,v)$ can be inferred by inspecting
not only the labels of $u$ and $v$ but possibly the labels of some additional
vertices. We show that inspecting the label of a single additional vertex (one
{\em query}) enables us to reduce the label size of many labeling schemes
significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609164</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609164</id><created>2006-09-29</created><authors><author><keyname>Aogaki</keyname><forenames>S.</forenames></author><author><keyname>Moritani</keyname><forenames>I.</forenames></author><author><keyname>Sugai</keyname><forenames>T.</forenames></author><author><keyname>Takeutchi</keyname><forenames>F.</forenames></author><author><keyname>Toyama</keyname><forenames>F. M.</forenames></author></authors><title>Conditional Expressions for Blind Deconvolution: Multi-point form</title><categories>cs.CV</categories><comments>4 pages, 3 figures, conference</comments><abstract>  We present conditional expression (CE) for finding blurs convolved in given
images. The CE is given in terms of the zero-values of the blurs evaluated at
multi-point. The CE can detect multiple blur all at once. We illustrate the
multiple blur-detection by using a test image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609165</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609165</id><created>2006-09-29</created><authors><author><keyname>Aogaki</keyname><forenames>S.</forenames></author><author><keyname>Moritani</keyname><forenames>I.</forenames></author><author><keyname>Sugai</keyname><forenames>T.</forenames></author><author><keyname>Takeutchi</keyname><forenames>F.</forenames></author><author><keyname>Toyama</keyname><forenames>F. M.</forenames></author></authors><title>Simple method to eliminate blur based on Lane and Bates algorithm</title><categories>cs.CV</categories><comments>3 pages, 2 figures, conference</comments><abstract>  A simple search method for finding a blur convolved in a given image is
presented. The method can be easily extended to a large blur. The method has
been experimentally tested with a model blurred image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609166</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609166</id><created>2006-09-29</created><authors><author><keyname>Strauss</keyname><forenames>Martin J.</forenames></author><author><keyname>Zheng</keyname><forenames>Xuan</forenames></author></authors><title>Private Approximate Heavy Hitters</title><categories>cs.CR</categories><comments>17 pages, submitted</comments><abstract>  We consider the problem of private computation of approximate Heavy Hitters.
Alice and Bob each hold a vector and, in the vector sum, they want to find the
B largest values along with their indices. While the exact problem requires
linear communication, protocols in the literature solve this problem
approximately using polynomial computation time, polylogarithmic communication,
and constantly many rounds. We show how to solve the problem privately with
comparable cost, in the sense that nothing is learned by Alice and Bob beyond
what is implied by their input, the ideal top-B output, and goodness of
approximation (equivalently, the Euclidean norm of the vector sum). We give
lower bounds showing that the Euclidean norm must leak by any efficient
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0609167</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0609167</id><created>2006-09-29</created><authors><author><keyname>Osorio</keyname><forenames>Mauricio</forenames></author><author><keyname>Cuevas</keyname><forenames>V&#xed;ctor</forenames></author></authors><title>Updates in Answer Set Programming: An Approach Based on Basic Structural
  Properties</title><categories>cs.LO</categories><comments>30 pages, to be published in Theory and Practice of Logic Programming</comments><acm-class>I.2.3; F.4.1</acm-class><abstract>  We have studied the update operator defined for update sequences by Eiter et
al. without tautologies and we have observed that it satisfies an interesting
property This property, which we call Weak Independence of Syntax (WIS), is
similar to one of the postulates proposed by Alchourron, Gardenfors, and
Makinson (AGM); only that in this case it applies to nonmonotonic logic. In
addition, we consider other five additional basic properties about update
programs and we show that the operator of Eiter et al. satisfies them. This
work continues the analysis of the AGM postulates under a refined view that
considers nelson logic as a monotonic logic which allows us to expand our
understanding of answer sets. Moreover, nelson logic helped us to derive an
alternative definition of the operator defined by Eiter et al. avoiding the use
of unnecessary extra atoms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610001</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610001</id><created>2006-09-29</created><authors><author><keyname>Okanohara</keyname><forenames>Daisuke</forenames></author><author><keyname>Sadakane</keyname><forenames>Kunihiko</forenames></author></authors><title>Practical Entropy-Compressed Rank/Select Dictionary</title><categories>cs.DS</categories><abstract>  Rank/Select dictionaries are data structures for an ordered set $S \subset
\{0,1,...,n-1\}$ to compute $\rank(x,S)$ (the number of elements in $S$ which
are no greater than $x$), and $\select(i,S)$ (the $i$-th smallest element in
$S$), which are the fundamental components of \emph{succinct data structures}
of strings, trees, graphs, etc. In those data structures, however, only
asymptotic behavior has been considered and their performance for real data is
not satisfactory. In this paper, we propose novel four Rank/Select
dictionaries, esp, recrank, vcode and sdarray, each of which is small if the
number of elements in $S$ is small, and indeed close to $nH_0(S)$ ($H_0(S) \leq
1$ is the zero-th order \textit{empirical entropy} of $S$) in practice, and its
query time is superior to the previous ones. Experimental results reveal the
characteristics of our data structures and also show that these data structures
are superior to existing implementations in both size and query time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610002</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610002</id><created>2006-09-30</created><authors><author><keyname>Aogaki</keyname><forenames>S.</forenames></author><author><keyname>Moritani</keyname><forenames>I.</forenames></author><author><keyname>Sugai</keyname><forenames>T.</forenames></author><author><keyname>Takeutchi</keyname><forenames>F.</forenames></author><author><keyname>Toyama</keyname><forenames>F. M.</forenames></author></authors><title>Conditional Expressions for Blind Deconvolution: Derivative form</title><categories>cs.CV</categories><comments>5 page, 3 figures, conference</comments><abstract>  We developed novel conditional expressions (CEs) for Lane and Bates' blind
deconvolution. The CEs are given in term of the derivatives of the zero-values
of the z-transform of given images. The CEs make it possible to automatically
detect multiple blur convolved in the given images all at once without
performing any analysis of the zero-sheets of the given images. We illustrate
the multiple blur-detection by the CEs for a model image
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:cs/0610003</identifier>
 <datestamp>2007-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>cs/0610003</id><created>2006-10-01</created><updated>2006-10-16</updated><authors><author><keyname>Abraham</keyname><forenames>Ittai</forenames></author><author><keyname>Bartal</keyname><forenames>Yair</forenames></author><author><keyname>Neiman</keyname><forenames>Ofer</forenames></author></authors><title>Embedding Metrics into Ultrametrics and Graphs into Spanning Trees with
  Constant Average Distortion</title><categories>cs.DM</categories><comments>Extended abstrat apears in SODA 2007</comments><abstract>  This paper addresses the basic question of how well can a tree approximate
distances of a metric space or a graph. Given a graph, the problem of
constructing a spanning tree in a graph which strongly preserves distances in
the graph is a fundamental problem in network design. We present scaling
distortion embeddings where the distortion scales as a function of $\epsilon$,
with the guarantee that for each $\epsilon$ the distortion of a fraction
$1-\epsilon$ of all pairs is bounded accordingly. Such a bound implies, in
particular, that the \emph{average distortion} and $\ell_q$-distortions are
small. Specifically, our embeddings have \emph{constant} average distortion and
$O(\sqrt{\log n})$ $\ell_2$-distortion. This follows from the following
results: we prove that any metric space embeds into an ultrametric with scaling
distortion $O(\sqrt{1/\epsilon})$. For the graph setting we prove that any
weighted graph contains a spanning tree with scaling distortion
$O(\sqrt{1/\epsilon})$. These bounds are tight even for embedding in arbitrary
trees.
 For probabilistic embedding into spanning trees we prove a scaling distortion
of $\tilde{O}(\log^2 (1/\epsilon))$, which implies \emph{constant}
$\ell_q$-distortion for every fixed $q&lt;\infty$.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="99000" completeListSize="102538">1122234|100001</resumptionToken>
</ListRecords>
</OAI-PMH>
