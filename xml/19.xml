<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:47:54Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|18001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3323</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3323</id><created>2010-12-15</created><authors><author><keyname>Bentosela</keyname><forenames>Francois</forenames></author><author><keyname>Cornean</keyname><forenames>Horia D.</forenames></author><author><keyname>Fleury</keyname><forenames>Bernard</forenames></author><author><keyname>Marchetti</keyname><forenames>Nicola</forenames></author></authors><title>On the transfer matrix of a MIMO system</title><categories>cs.IT math-ph math.IT math.MP</categories><comments>Accepted for publication in Mathematical Methods in the Applied
  Sciences</comments><doi>10.1002/mma.1415</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a deterministic ab-initio model for the input-output relationship
of a multiple-input multiple-output (MIMO) wireless channel, starting from the
Maxwell equations combined with Ohm's Law. The main technical tools are
scattering and geometric perturbation theories. The derived relationship can
lead us to a deep understanding of how the propagation conditions and the
coupling effects between the elements of multiple-element arrays affect the
properties of a MIMO channel, e.g. its capacity and its number of degrees of
freedom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3336</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3336</id><created>2010-12-15</created><authors><author><keyname>Okunoye</keyname><forenames>Olusoji</forenames><affiliation>LORIA</affiliation></author><author><keyname>Oladejo</keyname><forenames>Bolanle</forenames><affiliation>LORIA</affiliation></author><author><keyname>Odumuyiwa</keyname><forenames>Victor</forenames><affiliation>LORIA</affiliation></author></authors><title>Dynamic Knowledge Capitalization through Annotation among Economic
  Intelligence Actors in a Collaborative Environment</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>Veille strat\'egique et scientifique VSST 2010, Toulouse : France
  (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The shift from industrial economy to knowledge economy in today's world has
revolutionalized strategic planning in organizations as well as their problem
solving approaches. The point of focus today is knowledge and service
production with more emphasis been laid on knowledge capital. Many
organizations are investing on tools that facilitate knowledge sharing among
their employees and they are as well promoting and encouraging collaboration
among their staff in order to build the organization's knowledge capital with
the ultimate goal of creating a lasting competitive advantage for their
organizations. One of the current leading approaches used for solving
organization's decision problem is the Economic Intelligence (EI) approach
which involves interactions among various actors called EI actors. These actors
collaborate to ensure the overall success of the decision problem solving
process. In the course of the collaboration, the actors express knowledge which
could be capitalized for future reuse. In this paper, we propose in the first
place, an annotation model for knowledge elicitation among EI actors. Because
of the need to build a knowledge capital, we also propose a dynamic knowledge
capitalisation approach for managing knowledge produced by the actors. Finally,
the need to manage the interactions and the interdependencies among
collaborating EI actors, led to our third proposition which constitute an
awareness mechanism for group work management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3340</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3340</id><created>2010-12-15</created><authors><author><keyname>Nuida</keyname><forenames>Koji</forenames></author></authors><title>Short collusion-secure fingerprint codes against three pirates</title><categories>cs.CR</categories><comments>20 pages, a preliminary version was presented at Information Hiding
  2010, Calgary, Canada, June 28-30, 2010</comments><journal-ref>International Journal of Information Security, vol.11, no.2 (2012)
  85-102</journal-ref><doi>10.1007/s10207-012-0155-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose a new construction of probabilistic
collusion-secure fingerprint codes against up to three pirates and give a
theoretical security evaluation. Our pirate tracing algorithm combines a
scoring method analogous to Tardos codes (J. ACM, 2008) with an extension of
parent search techniques of some preceding 2-secure codes. Numerical examples
show that our code lengths are significantly shorter than (about 30% to 40% of)
the shortest known c-secure codes by Nuida et al. (Des. Codes Cryptogr., 2009)
with c = 3. Some preliminary proposal for improving efficiency of our tracing
algorithm is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3347</identifier>
 <datestamp>2013-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3347</id><created>2010-12-15</created><updated>2013-04-12</updated><authors><author><keyname>Simalango</keyname><forenames>Mikael Fernandus</forenames></author><author><keyname>Oh</keyname><forenames>Sangyoon</forenames></author></authors><title>An Architectural Design for Brokered Collaborative Content Delivery
  System</title><categories>cs.DC</categories><comments>This paper has been withdrawn due to various reasons</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Advances in web technologies have driven massive content uploads and requests
that can be identified by the increased usage of multimedia web and social web
services. This situation enforces the content providers to scale their
infrastructure in order to cope with the extra provisioning of network traffic,
storage and other resources. Since the complexity and cost factors in scaling
the infrastructure exist, we propose a novel solution for providing and
delivering contents to clients by introducing a brokered collaborative content
delivery system. The architectural design of this system leverages content
redundancy and content distribution mechanisms in other content providers to
deliver contents to the clients. With the recent emergence of cloud computing,
we show that this system can also be adopted to run on the cloud. In this
paper, we focus on a brokering scheme to mediate user requests to the most
appropriate content provider based on a ranking system. The architecture
provides a novel Global Rank Value (GRV) concept in estimating content provider
capability and transforming the QoS requirement of a content request. A
fairness model that will bring this design to be attractive to the current
content delivery regime is also introduced. Through simulation, we show that
using fair provider selection, contents can be provisioned by a better pool of
qualified providers thus leveraging the collaboration and preventing potential
QoS violation that may occur when the size of pool is smaller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3359</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3359</id><created>2010-12-15</created><updated>2010-12-20</updated><authors><author><keyname>Shah</keyname><forenames>Pratik</forenames></author><author><keyname>Chatterji</keyname><forenames>Samaresh</forenames></author></authors><title>Curve Reconstruction in Riemannian Manifolds: Ordering Motion Frames</title><categories>cs.CG cs.GR cs.RO math.DG</categories><comments>20 Figures, 27 Equations, 12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we extend the computational geometric curve reconstruction
approach to curves in Riemannian manifolds. We prove that the minimal spanning
tree, given a sufficiently dense sample, correctly reconstructs the smooth arcs
and further closed and simple curves in Riemannian manifolds. The proof is
based on the behaviour of the curve segment inside the tubular neighbourhood of
the curve. To take care of the local topological changes of the manifold, the
tubular neighbourhood is constructed in consideration with the injectivity
radius of the underlying Riemannian manifold. We also present examples of
successfully reconstructed curves and show an applications of curve
reconstruction to ordering motion frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3364</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3364</id><created>2010-12-15</created><updated>2013-09-04</updated><authors><author><keyname>Bouman</keyname><forenames>Niek</forenames></author><author><keyname>Borst</keyname><forenames>Sem</forenames></author><author><keyname>van Leeuwaarden</keyname><forenames>Johan</forenames></author></authors><title>Stability of Random Admissible-Set Scheduling in Spatially Continuous
  Wireless Systems</title><categories>math.PR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the stability of wireless networks whose users are distributed
over a compact space. A subset of users is called {\it admissible} when their
simultaneous activity obeys the prevailing interference constraints and, in
each time slot, an admissible subset of users is selected uniformly at random
to transmit one packet. We show that, under a mild condition, this random
admissible-set scheduling mechanism achieves maximum stability in a broad set
of scenarios, and in particular in symmetric cases. The proof relies on a
description of the system as a measure-valued process and the identification of
a Lyapunov function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3372</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3372</id><created>2010-12-15</created><updated>2011-03-23</updated><authors><author><keyname>Lengrand</keyname><forenames>St&#xe9;phane Jean Eric</forenames><affiliation>CNRS, Ecole Polytechnique, France</affiliation></author><author><keyname>Dyckhoff</keyname><forenames>Roy</forenames><affiliation>School of Computer Science, University of St Andrews, Scotland</affiliation></author><author><keyname>McKinna</keyname><forenames>James</forenames><affiliation>Radboud University, Nijmegen, The Netherlands</affiliation></author></authors><title>A Focused Sequent Calculus Framework for Proof Search in Pure Type
  Systems</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 23,
  2011) lmcs:842</journal-ref><doi>10.2168/LMCS-7(1:6)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Basic proof-search tactics in logic and type theory can be seen as the
root-first applications of rules in an appropriate sequent calculus, preferably
without the redundancies generated by permutation of rules. This paper
addresses the issues of defining such sequent calculi for Pure Type Systems
(PTS, which were originally presented in natural deduction style) and then
organizing their rules for effective proof-search. We introduce the idea of
Pure Type Sequent Calculus with meta-variables (PTSCalpha), by enriching the
syntax of a permutation-free sequent calculus for propositional logic due to
Herbelin, which is strongly related to natural deduction and already well
adapted to proof-search. The operational semantics is adapted from Herbelin's
and is defined by a system of local rewrite rules as in cut-elimination, using
explicit substitutions. We prove confluence for this system. Restricting our
attention to PTSC, a type system for the ground terms of this system, we obtain
the Subject Reduction property and show that each PTSC is logically equivalent
to its corresponding PTS, and the former is strongly normalising iff the latter
is. We show how to make the logical rules of PTSC into a syntax-directed system
PS for proof-search, by incorporating the conversion rules as in
syntax-directed presentations of the PTS rules for type-checking. Finally, we
consider how to use the explicitly scoped meta-variables of PTSCalpha to
represent partial proof-terms, and use them to analyse interactive proof
construction. This sets up a framework PE in which we are able to study
proof-search strategies, type inhabitant enumeration and (higher-order)
unification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3409</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3409</id><created>2010-12-15</created><updated>2012-01-03</updated><authors><author><keyname>Expert</keyname><forenames>Paul</forenames></author><author><keyname>Evans</keyname><forenames>Tim</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author><author><keyname>Lambiotte</keyname><forenames>Renaud</forenames></author></authors><title>Uncovering space-independent communities in spatial networks</title><categories>physics.soc-ph cs.SI</categories><comments>This preprint version combines paper and supplemenatary material of
  published version. Original title &quot;Beyond Space For Spatial Networks&quot; changed
  for journal</comments><report-no>Imperial/TP/10/TSE/4</report-no><journal-ref>PNAS 2011 108 (19) 7663-7668</journal-ref><doi>10.1073/pnas.1018962108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many complex systems are organized in the form of a network embedded in
space. Important examples include the physical Internet infrastucture, road
networks, flight connections, brain functional networks and social networks.
The effect of space on network topology has recently come under the spotlight
because of the emergence of pervasive technologies based on geo-localization,
which constantly fill databases with people's movements and thus reveal their
trajectories and spatial behaviour. Extracting patterns and regularities from
the resulting massive amount of human mobility data requires the development of
appropriate tools for uncovering information in spatially-embedded networks. In
contrast with most works that tend to apply standard network metrics to any
type of network, we argue in this paper for a careful treatment of the
constraints imposed by space on network topology. In particular, we focus on
the problem of community detection and propose a modularity function adapted to
spatial networks. We show that it is possible to factor out the effect of space
in order to reveal more clearly hidden structural similarities between the
nodes. Methods are tested on a large mobile phone network and
computer-generated benchmarks where the effect of space has been incorporated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3410</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3410</id><created>2010-12-15</created><authors><author><keyname>Kovacs</keyname><forenames>Laszlo</forenames></author><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>Descriptive-complexity based distance for fuzzy sets</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new distance function dist(A,B) for fuzzy sets A and B is introduced. It is
based on the descriptive complexity, i.e., the number of bits (on average) that
are needed to describe an element in the symmetric difference of the two sets.
The distance gives the amount of additional information needed to describe any
one of the two sets given the other. We prove its mathematical properties and
perform pattern clustering on data based on this distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3439</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3439</id><created>2010-12-15</created><authors><author><keyname>Augot</keyname><forenames>Daniel</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Barbier</keyname><forenames>Morgan</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Couvreur</keyname><forenames>Alain</forenames><affiliation>IMB</affiliation></author></authors><title>List-decoding of binary Goppa codes up to the binary Johnson bound</title><categories>cs.IT math.IT</categories><proxy>ccsd</proxy><report-no>RR-7490</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the list-decoding problem of alternant codes, with the notable case
of classical Goppa codes. The major consideration here is to take into account
the size of the alphabet, which shows great influence on the list-decoding
radius. This amounts to compare the \emph{generic} Johnson bound to the
\emph{$q$-ary} Johnson bound. This difference is important when $q$ is very
small. Essentially, the most favourable case is $q=2$, for which the decoding
radius is greatly improved, notably when the relative minimum distance gets
close to 1/2. Even though the announced result, which is the list-decoding
radius of binary Goppa codes, is new, it can be rather easily made up from
previous sources (V. Guruswami, R. M. Roth and I. Tal, R .M. Roth), which may
be a little bit unknown, and in which the case of binary Goppa codes has
apparently not been thought at. Only D. J. Bernstein treats the case of binary
Goppa codes in a preprint. References are given in the introduction. We propose
an autonomous treatment and also a complexity analysis of the studied
algorithm, which is quadratic in the blocklength $n$, when decoding at some
distance of the relative maximum decoding radius, and in $O(n^7)$ when reaching
the maximum radius.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3440</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3440</id><created>2010-12-15</created><authors><author><keyname>Turner</keyname><forenames>D. Z.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Notz</keyname><forenames>P. K.</forenames></author></authors><title>On the performance of the variational multiscale formulation for
  subsurface flow and transport in heterogeneous porous media</title><categories>cs.NA math-ph math.MP math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following work compares two popular mixed finite elements used to model
subsurface flow and transport in heterogeneous porous media; the lowest order
Raviart-Thomas element and the variational multiscale stabilized element.
Comparison is made based on performance for several problems of engineering
relevance that involve highly heterogenous material properties (permeability
ratios of up to $1\times10^5$), open flow boundary conditions (pressure driven
flows), and large scale domains in two dimensions. Numerical experiments are
performed to show the degree to which mass conservation is violated when a flow
field computed using either element is used as the advection velocity in a
transport model. The results reveal that the variational multiscale element
shows considerable mass production or loss for problems that involve flow
tangential to layers of differing permeability, but marginal violation of local
mass balance for problems of less orthogonality in the permeability. The
results are useful in establishing rudimentary estimates of the error produced
by using the variational mutliscale element for several different types of
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3442</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3442</id><created>2010-12-15</created><authors><author><keyname>Valibouze</keyname><forenames>Annick</forenames><affiliation>LSTA, LIP6</affiliation></author></authors><title>Th\'eorie de Galois effective : aide m\'emoire</title><categories>cs.SC</categories><comments>27 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper collects many results on galoisian ideals and Galois theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3452</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3452</id><created>2010-12-15</created><authors><author><keyname>Nikseresht</keyname><forenames>Mohammad R</forenames></author><author><keyname>Somayaji</keyname><forenames>Anil</forenames></author><author><keyname>Maheshwari</keyname><forenames>Anil</forenames></author></authors><title>Customer Appeasement Scheduling</title><categories>cs.OS</categories><report-no>TR-10-18</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Almost all of the current process scheduling algorithms which are used in
modern operating systems (OS) have their roots in the classical scheduling
paradigms which were developed during the 1970's. But modern computers have
different types of software loads and user demands. We think it is important to
run what the user wants at the current moment. A user can be a human, sitting
in front of a desktop machine, or it can be another machine sending a request
to a server through a network connection. We think that OS should become
intelligent to distinguish between different processes and allocate resources,
including CPU, to those processes which need them most. In this work, as a
first step to make the OS aware of the current state of the system, we consider
process dependencies and interprocess communications. We are developing a
model, which considers the need to satisfy interactive users and other possible
remote users or customers, by making scheduling decisions based on process
dependencies and interprocess communications. Our simple proof of concept
implementation and experiments show the effectiveness of this approach in the
real world applications. Our implementation does not require any change in the
software applications nor any special kind of configuration in the system,
Moreover, it does not require any additional information about CPU needs of
applications nor other resource requirements. Our experiments show significant
performance improvement for real world applications. For example, almost
constant average response time for Mysql data base server and constant frame
rate for mplayer under different simulated load values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3476</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3476</id><created>2010-12-15</created><authors><author><keyname>Desjardins</keyname><forenames>Guillaume</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Adaptive Parallel Tempering for Stochastic Maximum Likelihood Learning
  of RBMs</title><categories>stat.ML cs.NE</categories><comments>Presented at the &quot;NIPS 2010 Workshop on Deep Learning and
  Unsupervised Feature Learning&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restricted Boltzmann Machines (RBM) have attracted a lot of attention of
late, as one the principle building blocks of deep networks. Training RBMs
remains problematic however, because of the intractibility of their partition
function. The maximum likelihood gradient requires a very robust sampler which
can accurately sample from the model despite the loss of ergodicity often
incurred during learning. While using Parallel Tempering in the negative phase
of Stochastic Maximum Likelihood (SML-PT) helps address the issue, it imposes a
trade-off between computational complexity and high ergodicity, and requires
careful hand-tuning of the temperatures. In this paper, we show that this
trade-off is unnecessary. The choice of optimal temperatures can be automated
by minimizing average return time (a concept first proposed by [Katzgraber et
al., 2006]) while chains can be spawned dynamically, as needed, thus minimizing
the computational overhead. We show on a synthetic dataset, that this results
in better likelihood scores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3502</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3502</id><created>2010-12-15</created><authors><author><keyname>Gatterbauer</keyname><forenames>Wolfgang</forenames></author></authors><title>Rules of Thumb for Information Acquisition from Large and Redundant Data</title><categories>cs.IR cs.DB physics.data-an</categories><comments>40 pages, 17 figures; for details see the project page:
  http://uniquerecall.com</comments><journal-ref>Full version of upcoming ECIR 2011 conference paper</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an abstract model of information acquisition from redundant data.
We assume a random sampling process from data which provide information with
bias and are interested in the fraction of information we expect to learn as
function of (i) the sampled fraction (recall) and (ii) varying bias of
information (redundancy distributions). We develop two rules of thumb with
varying robustness. We first show that, when information bias follows a Zipf
distribution, the 80-20 rule or Pareto principle does surprisingly not hold,
and we rather expect to learn less than 40% of the information when randomly
sampling 20% of the overall data. We then analytically prove that for large
data sets, randomized sampling from power-law distributions leads to &quot;truncated
distributions&quot; with the same power-law exponent. This second rule is very
robust and also holds for distributions that deviate substantially from a
strict power law. We further give one particular family of powerlaw functions
that remain completely invariant under sampling. Finally, we validate our model
with two large Web data sets: link distributions to domains and tag
distributions on delicious.com.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3506</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3506</id><created>2010-12-15</created><authors><author><keyname>Machmouchi</keyname><forenames>Widad</forenames></author></authors><title>Local-Testability and Self-Correctability of q-ary Sparse Linear Codes</title><categories>cs.CC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that q-ary sparse codes with small bias are self-correctable and
locally testable. We generalize a result of Kaufman and Sudan that proves the
local testability and correctability of binary sparse codes with small bias. We
use properties of q-ary Krawtchouk polynomials and the McWilliams identity
-that relates the weight distribution of a code to the weight distribution of
its dual- to derive bounds on the error probability of the randomized tester
and self-corrector we are analyzing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3531</identifier>
 <datestamp>2011-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3531</id><created>2010-12-16</created><authors><author><keyname>Peper</keyname><forenames>Ferdinand</forenames></author><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author></authors><title>Instantaneous, non-squeezed, noise-based logic</title><categories>cs.OH</categories><comments>6 pages</comments><journal-ref>Fluctuation and Noise Letters 10 (2011) 231-237</journal-ref><doi>10.1142/S0219477511000521</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noise-based logic, by utilizing its multidimensional logic hyperspace, has
significant potential for low-power parallel operations in beyond-Moore-chips.
However universal gates for Boolean logic thus far had to rely on either time
averaging to distinguish signals from each other or, alternatively, on squeezed
logic signals, where the logic-high was represented by a random process and the
logic-low was a zero signal. A major setback is that squeezed logic variables
are unable to work in the hyperspace, because the logic-low zero value sets the
hyperspace product vector to zero. This paper proposes Boolean universal logic
gates that alleviate such shortcomings. They are able to work with non-squeezed
logic values where both the high and low values are encoded into nonzero,
bipolar, independent random telegraph waves. Non-squeezed universal Boolean
logic gates for spike-based brain logic are also shown. The advantages vs.
disadvantages of the two logic types are compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3548</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3548</id><created>2010-12-16</created><updated>2010-12-31</updated><authors><author><keyname>Moser</keyname><forenames>Philippe</forenames></author></authors><title>On the polynomial depth of various sets of random strings</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes new notions of polynomial depth (called monotone poly
depth), based on a polynomial version of monotone Kolmogorov complexity. We
show that monotone poly depth satisfies all desirable properties of depth
notions i.e., both trivial and random sequences are not monotone poly deep,
monotone poly depth satisfies the slow growth law i.e., no simple process can
transform a non deep sequence into a deep one, and monotone poly deep sequences
exist (unconditionally). We give two natural examples of deep sets, by showing
that both the set of Levin-random strings and the set of Kolmogorov random
strings are monotone poly deep.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3583</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3583</id><created>2010-12-16</created><authors><author><keyname>Tria</keyname><forenames>Francesca</forenames></author><author><keyname>Mukherjee</keyname><forenames>Animesh</forenames></author><author><keyname>Baronchelli</keyname><forenames>Andrea</forenames></author><author><keyname>Puglisi</keyname><forenames>Andrea</forenames></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author></authors><title>A fast no-rejection algorithm for the Category Game</title><categories>physics.comp-ph cs.SI physics.soc-ph</categories><comments>17 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Category Game is a multi-agent model that accounts for the emergence of
shared categorization patterns in a population of interacting individuals. In
the framework of the model, linguistic categories appear as long lived
consensus states that are constantly reshaped and re-negotiated by the
communicating individuals. It is therefore crucial to investigate the long time
behavior to gain a clear understanding of the dynamics. However, it turns out
that the evolution of the emerging category system is so slow, already for
small populations, that such an analysis has remained so far impossible. Here,
we introduce a fast no-rejection algorithm for the Category Game that
disentangles the physical simulation time from the CPU time, thus opening the
way for thorough analysis of the model. We verify that the new algorithm is
equivalent to the old one in terms of the emerging phenomenology and we
quantify the CPU performances of the two algorithms, pointing out the neat
advantages offered by the no-rejection one. This technical advance has already
opened the way to new investigations of the model, thus helping to shed light
on the fundamental issue of categorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3607</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3607</id><created>2010-12-16</created><authors><author><keyname>Vilar</keyname><forenames>Jose M. G.</forenames></author></authors><title>Accurate prediction of gene expression by integration of DNA sequence
  statistics with detailed modeling of transcription regulation</title><categories>q-bio.MN cond-mat.stat-mech cs.CE physics.bio-ph q-bio.SC</categories><comments>15 pages, 5 figures</comments><journal-ref>Biophys. J. 99, 2408-2413 (2010)</journal-ref><doi>10.1016/j.bpj.2010.08.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gene regulation involves a hierarchy of events that extend from specific
protein-DNA interactions to the combinatorial assembly of nucleoprotein
complexes. The effects of DNA sequence on these processes have typically been
studied based either on its quantitative connection with single-domain binding
free energies or on empirical rules that combine different DNA motifs to
predict gene expression trends on a genomic scale. The middle-point approach
that quantitatively bridges these two extremes, however, remains largely
unexplored. Here, we provide an integrated approach to accurately predict gene
expression from statistical sequence information in combination with detailed
biophysical modeling of transcription regulation by multidomain binding on
multiple DNA sites. For the regulation of the prototypical lac operon, this
approach predicts within 0.3-fold accuracy transcriptional activity over a
10,000-fold range from DNA sequence statistics for different intracellular
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3628</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3628</id><created>2010-12-16</created><updated>2010-12-21</updated><authors><author><keyname>Fyhn</keyname><forenames>Karsten</forenames></author><author><keyname>Jacobsen</keyname><forenames>Rasmus M.</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author><author><keyname>Larsen</keyname><forenames>Torben</forenames></author></authors><title>Fast and Power Efficient Sensor Arbitration: Physical Layer Collision
  Recovery of Passive RFID Tags</title><categories>cs.NI</categories><comments>33 pages, 10 figures, 1 table, submitted to IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work concerns physical layer collision recovery for cheap sensors with
allowed variations in frequency and delay of their communications. The work is
presented as a generic, communication theoretic framework and demonstrated
using UHF RFID tag technology. Previous work in this area has not provided
recovery for more than two tags, which is shown to be possible in this work.
Also presented is a novel mathematical model of the tag signal, incorporating
the allowed variations in frequency and delay. The main motivation is seen in
the observation that random variations in frequency and delay make the collided
signals of different tags separable. The collision recovery is done by
estimating the sensor specific variation in frequency and delay and using these
estimates in a successive interference cancellation algorithm and a maximum
likelihood sequence decoder, to iteratively reconstruct a sensor signal and
remove it from the received signal. Numerical simulations show that the
estimates and proposed algorithm are effective in recovering collisions. The
proposed algorithm is then incorporated into a numerical simulation of the
Qprotocol for UHF RFID tags and is shown to be effective in providing fast and
power efficient sensor arbitration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3638</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3638</id><created>2010-12-16</created><updated>2011-02-14</updated><authors><author><keyname>Haboba</keyname><forenames>Salvador Javier</forenames></author><author><keyname>Rovatti</keyname><forenames>Riccardo</forenames></author><author><keyname>Setti</keyname><forenames>Gianluca</forenames></author></authors><title>Determination of the Integrated Sidelobe Level of Sets of Rotated
  Legendre Sequences</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequences sets with low aperiodic auto- and cross-correlations play an
important role in many applications like communications, radar and other active
sensing applications. The use of antipodal sequences reduces hardware
requirements while increases the difficult of the task of signal design. In
this paper we present a method for the computation of the Integrated Sidelobe
Level (ISL), and we use it to calculate the asymptotic expression for the ISL
of a set of sequences formed by different rotations of a Legendre sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3646</identifier>
 <datestamp>2014-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3646</id><created>2010-12-15</created><updated>2011-09-22</updated><authors><author><keyname>Stefanatos</keyname><forenames>Dionisis</forenames></author><author><keyname>Schaettler</keyname><forenames>Heinz</forenames></author><author><keyname>Li</keyname><forenames>Jr-Shin</forenames></author></authors><title>Minimum-Time Frictionless Atom Cooling in Harmonic Traps</title><categories>math.OC cs.SY quant-ph</categories><comments>To appear in SIAM Journal on Control and Optimization</comments><msc-class>49K15, 93C15, 81V45</msc-class><journal-ref>SIAM J. Control Optim., Vol. 49, pp. 2440-2462, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frictionless atom cooling in harmonic traps is formulated as a time-optimal
control problem and a synthesis of optimal controlled trajectories is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3651</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3651</id><created>2010-12-16</created><updated>2011-04-05</updated><authors><author><keyname>Hackett</keyname><forenames>Adam</forenames></author><author><keyname>Melnik</keyname><forenames>Sergey</forenames></author><author><keyname>Gleeson</keyname><forenames>James P.</forenames></author></authors><title>Cascades on a class of clustered random networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>10 pages</comments><journal-ref>Phys. Rev. E 83, 056107 (2011)</journal-ref><doi>10.1103/PhysRevE.83.056107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analytical approach to determining the expected cascade size in
a broad range of dynamical models on the class of random networks with
arbitrary degree distribution and nonzero clustering introduced in [M.E.J.
Newman, Phys. Rev. Lett. 103, 058701 (2009)]. A condition for the existence of
global cascades is derived as well as a general criterion which determines
whether increasing the level of clustering will increase, or decrease, the
expected cascade size. Applications, examples of which are provided, include
site percolation, bond percolation, and Watts' threshold model; in all cases
analytical results give excellent agreement with numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3656</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3656</id><created>2010-12-16</created><authors><author><keyname>Luttrell</keyname><forenames>Stephen</forenames></author></authors><title>Adaptive Cluster Expansion (ACE): A Multilayer Network for Estimating
  Probability Density Functions</title><categories>cs.NE cs.CV</categories><comments>20 pages, 14 figures</comments><acm-class>I.2.6; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive an adaptive hierarchical method of estimating high dimensional
probability density functions. We call this method of density estimation the
&quot;adaptive cluster expansion&quot; or ACE for short. We present an application of
this approach, based on a multilayer topographic mapping network, that
adaptively estimates the joint probability density function of the pixel values
of an image, and presents this result as a &quot;probability image&quot;. We apply this
to the problem of identifying statistically anomalous regions in otherwise
statistically homogeneous images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3697</identifier>
 <datestamp>2014-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3697</id><created>2010-12-16</created><updated>2014-03-07</updated><authors><author><keyname>Ackermann</keyname><forenames>Marcel R.</forenames></author><author><keyname>Bl&#xf6;mer</keyname><forenames>Johannes</forenames></author><author><keyname>Kuntze</keyname><forenames>Daniel</forenames></author><author><keyname>Sohler</keyname><forenames>Christian</forenames></author></authors><title>Analysis of Agglomerative Clustering</title><categories>cs.DS cs.CG cs.LG</categories><comments>A preliminary version of this article appeared in Proceedings of the
  28th International Symposium on Theoretical Aspects of Computer Science
  (STACS '11), March 2011, pp. 308-319. This article also appeared in
  Algorithmica. The final publication is available at
  http://link.springer.com/article/10.1007/s00453-012-9717-4</comments><acm-class>F.2.2; H.3.3; I.5.3</acm-class><journal-ref>Ackermann, M. R., Bl\&quot;omer, J., Kuntze, D., and Sohler, C. (2014).
  Analysis of Agglomerative Clustering. Algorithmica, 69(1):184-215</journal-ref><doi>10.1007/s00453-012-9717-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diameter $k$-clustering problem is the problem of partitioning a finite
subset of $\mathbb{R}^d$ into $k$ subsets called clusters such that the maximum
diameter of the clusters is minimized. One early clustering algorithm that
computes a hierarchy of approximate solutions to this problem (for all values
of $k$) is the agglomerative clustering algorithm with the complete linkage
strategy. For decades, this algorithm has been widely used by practitioners.
However, it is not well studied theoretically. In this paper, we analyze the
agglomerative complete linkage clustering algorithm. Assuming that the
dimension $d$ is a constant, we show that for any $k$ the solution computed by
this algorithm is an $O(\log k)$-approximation to the diameter $k$-clustering
problem. Our analysis does not only hold for the Euclidean distance but for any
metric that is based on a norm. Furthermore, we analyze the closely related
$k$-center and discrete $k$-center problem. For the corresponding agglomerative
algorithms, we deduce an approximation factor of $O(\log k)$ as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3704</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3704</id><created>2010-12-16</created><authors><author><keyname>Misra</keyname><forenames>Janardan</forenames></author><author><keyname>Roy</keyname><forenames>Suman</forenames></author></authors><title>A Decidable Timeout based Extension of Propositional Linear Temporal
  Logic</title><categories>cs.LO</categories><msc-class>68Q60</msc-class><acm-class>F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a timeout based extension of propositional linear temporal logic
(which we call TLTL) to specify timing properties of timeout based models of
real time systems. TLTL formulas explicitly refer to a running global clock
together with static timing variables as well as a dynamic variable abstracting
the timeout behavior. We extend LTL with the capability to express timeout
constraints. From the expressiveness view point, TLTL is not comparable with
important known clock based real-time logics including TPTL, XCTL, and MTL,
i.e., TLTL can specify certain properties, which cannot be specified in these
logics (also vice-versa). We define a corresponding timeout tableau for
satisfiability checking of the TLTL formulas. Also a model checking algorithm
over timeout Kripke structure is presented. Further we prove that the validity
checking for such an extended logic remains PSPACE-complete even in the
presence of timeout constraints and infinite state models. Under discrete time
semantics, with bounded timeout increments, the model-checking problem that if
a TLTL-formula holds in a timeout Kripke structure is also PSPACE complete. We
further prove that when TLTL is interpreted over discrete time, it can be
embedded in the monadic second order logic with time, and when TLTL is
interpreted over dense time without the condition of non-zenoness, the
resulting logic becomes $\Sigma_1^1$-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3705</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3705</id><created>2010-12-16</created><authors><author><keyname>Luttrell</keyname><forenames>Stephen</forenames></author></authors><title>Stochastic Vector Quantisers</title><categories>cs.NE cs.CV</categories><comments>22 pages, 12 figures</comments><acm-class>I.2.6; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a stochastic generalisation of the standard Linde-Buzo-Gray
(LBG) approach to vector quantiser (VQ) design is presented, in which the
encoder is implemented as the sampling of a vector of code indices from a
probability distribution derived from the input vector, and the decoder is
implemented as a superposition of reconstruction vectors, and the stochastic VQ
is optimised using a minimum mean Euclidean reconstruction distortion
criterion, as in the LBG case. Numerical simulations are used to demonstrate
how this leads to self-organisation of the stochastic VQ, where different
stochastically sampled code indices become associated with different input
subspaces. This property may be used to automate the process of splitting
high-dimensional input vectors into low-dimensional blocks before encoding
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3721</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3721</id><created>2010-12-16</created><authors><author><keyname>Frougny</keyname><forenames>Christiane</forenames></author><author><keyname>Lai</keyname><forenames>Anna Chiara</forenames></author></authors><title>Negative bases and automata</title><categories>cs.FL cs.DM math.DS math.NT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study expansions in non-integer negative base -{\beta} introduced by Ito
and Sadahiro. Using countable automata associated with (-{\beta})-expansions,
we characterize the case where the (-{\beta})-shift is a system of finite type.
We prove that, if {\beta} is a Pisot number, then the (-{\beta})-shift is a
sofic system. In that case, addition (and more generally normalization on any
alphabet) is realizable by a finite transducer. We then give an on-line
algorithm for the conversion from positive base {\beta} to negative base
-{\beta}. When {\beta} is a Pisot number, the conversion can be realized by a
finite on-line transducer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3722</identifier>
 <datestamp>2012-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3722</id><created>2010-12-16</created><updated>2012-01-15</updated><authors><author><keyname>Labeur</keyname><forenames>Robert Jan</forenames></author><author><keyname>Wells</keyname><forenames>Garth N.</forenames></author></authors><title>Energy stable and momentum conserving hybrid finite element method for
  the incompressible Navier-Stokes equations</title><categories>cs.CE math.NA</categories><comments>To appear in SIAM Journal on Scientific Computing</comments><msc-class>65N12, 65N30, 76D05, 76D07</msc-class><journal-ref>SIAM J. Sci. Comput., 34(2), 2012, A889-A913</journal-ref><doi>10.1137/100818583</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hybrid method for the incompressible Navier--Stokes equations is presented.
The method inherits the attractive stabilizing mechanism of upwinded
discontinuous Galerkin methods when momentum advection becomes significant,
equal-order interpolations can be used for the velocity and pressure fields,
and mass can be conserved locally. Using continuous Lagrange multiplier spaces
to enforce flux continuity across cell facets, the number of global degrees of
freedom is the same as for a continuous Galerkin method on the same mesh.
Different from our earlier investigations on the approach for the
Navier--Stokes equations, the pressure field in this work is discontinuous
across cell boundaries. It is shown that this leads to very good local mass
conservation and, for an appropriate choice of finite element spaces, momentum
conservation. Also, a new form of the momentum transport terms for the method
is constructed such that global energy stability is guaranteed, even in the
absence of a point-wise solenoidal velocity field. Mass conservation, momentum
conservation and global energy stability are proved for the time-continuous
case, and for a fully discrete scheme. The presented analysis results are
supported by a range of numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3724</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3724</id><created>2010-12-16</created><authors><author><keyname>Luttrell</keyname><forenames>Stephen</forenames></author></authors><title>The Development of Dominance Stripes and Orientation Maps in a
  Self-Organising Visual Cortex Network (VICON)</title><categories>cs.NE cs.CV</categories><comments>33 pages, 19 figures</comments><acm-class>I.2.6; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A self-organising neural network is presented that is based on a rigorous
Bayesian analysis of the information contained in individual neural firing
events. This leads to a visual cortex network (VICON) that has many of the
properties emerge when a mammalian visual cortex is exposed to data arriving
from two imaging sensors (i.e. the two retinae), such as dominance stripes and
orientation maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3763</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3763</id><created>2010-12-16</created><updated>2011-05-27</updated><authors><author><keyname>Burghelea</keyname><forenames>Dan</forenames></author><author><keyname>Dey</keyname><forenames>Tamal K.</forenames></author><author><keyname>Dong</keyname><forenames>Du</forenames></author></authors><title>Defining and Computing Topological Persistence for 1-cocycles</title><categories>math.AT cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of topological persistence, introduced recently in computational
topology, finds applications in studying a map in relation to the topology of
its domain. Since its introduction, it has been extended and generalized in
various directions. However, no attempt has been made so far to extend the
concept of topological persistence to a generalization of `maps' such as
cocycles which are discrete analogs of closed differential forms, a well known
concept in differential geometry. We define a notion of topological persistence
for 1-cocycles in this paper and show how to compute its relevant numbers. It
turns out that, instead of the standard persistence, one of its variants which
we call level persistence can be leveraged for this purpose. It is worth
mentioning that 1-cocyles appear in practice such as in data ranking or in
discrete vector fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3788</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3788</id><created>2010-12-16</created><authors><author><keyname>Ansari</keyname><forenames>Imran Shafique</forenames></author><author><keyname>Al-Ahmadi</keyname><forenames>Saad</forenames></author><author><keyname>Yilmaz</keyname><forenames>Ferkan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author></authors><title>A New Formula for the BER of Binary Modulations with Dual-Branch
  Selection over Generalized-K Composite Fading Channels</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>Diversity schemes, selection combining, dual-branch selection
  diversity, binary modulation schemes, generalized-K (GK) model, composite
  fading, bit error rate (BER), and Meijer G-function distribution</comments><doi>10.1109/TCOMM.2011.063011.100303A</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Error performance is one of the main performance measures and derivation of
its closed-form expression has proved to be quite involved for certain systems.
In this letter, a unified closed-form expression, applicable to different
binary modulation schemes, for the bit error rate of dual-branch selection
diversity based systems undergoing independent but not necessarily identically
distributed generalized-K fading is derived in terms of the extended
generalized bivariate Meijer G-function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3790</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3790</id><created>2010-12-16</created><updated>2011-01-15</updated><authors><author><keyname>Hu</keyname><forenames>Yichuan</forenames><affiliation>Charlie</affiliation></author><author><keyname>Jianzhong</keyname><affiliation>Charlie</affiliation></author><author><keyname>Zhang</keyname></author><author><keyname>Khan</keyname><forenames>Farooq</forenames></author><author><keyname>Li</keyname><forenames>Ying</forenames></author></authors><title>Improving PPM Algorithm Using Dictionaries</title><categories>cs.IT math.IT</categories><comments>7 pages, 4 figures, longer version for DCC 2011 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method to improve traditional character-based PPM text
compression algorithms. Consider a text file as a sequence of alternating words
and non-words, the basic idea of our algorithm is to encode non-words and
prefixes of words using character-based context models and encode suffixes of
words using dictionary models. By using dictionary models, the algorithm can
encode multiple characters as a whole, and thus enhance the compression
efficiency. The advantages of the proposed algorithm are: 1) it does not
require any text preprocessing; 2) it does not need any explicit codeword to
identify switch between context and dictionary models; 3) it can be applied to
any character-based PPM algorithms without incurring much additional
computational cost. Test results show that significant improvements can be
obtained over character-based PPM, especially in low order cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3793</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3793</id><created>2010-12-16</created><authors><author><keyname>Zhou</keyname><forenames>Yanbo</forenames></author><author><keyname>Lei</keyname><forenames>Ting</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>A robust ranking algorithm to spamming</title><categories>cs.IR physics.data-an</categories><comments>4 pages, 4 figures, 3 Tables</comments><journal-ref>EPL 94 (2011) 48002</journal-ref><doi>10.1209/0295-5075/94/48002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ranking problem of web-based rating system has attracted many attentions. A
good ranking algorithm should be robust against spammer attack. Here we
proposed a correlation based reputation algorithm to solve the ranking problem
of such rating systems where user votes some objects with ratings. In this
algorithm, reputation of user is iteratively determined by the correlation
coefficient between his/her rating vector and the corresponding objects'
weighted average rating vector. Comparing with iterative refinement (IR) and
mean score algorithm, results for both artificial and real data indicate that,
the present algorithm shows a higher robustness against spammer attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3802</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3802</id><created>2010-12-16</created><authors><author><keyname>Wu</keyname><forenames>Lin</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author></authors><title>Detecting Image Forgeries using Geometric Cues</title><categories>cs.CV</categories><comments>18 pages, 10 figures</comments><acm-class>I.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This chapter presents a framework for detecting fake regions by using various
methods including watermarking technique and blind approaches. In particular,
we describe current categories on blind approaches which can be divided into
five: pixel-based techniques, format-based techniques, camera-based techniques,
physically-based techniques and geometric-based techniques. Then we take a
second look on the geometric-based techniques and further categorize them in
detail. In the following section, the state-of-the-art methods involved in the
geometric technique are elaborated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3805</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3805</id><created>2010-12-16</created><authors><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Chen</keyname><forenames>Zhikui</forenames></author><author><keyname>Huang</keyname><forenames>Xiaodi</forenames></author></authors><title>Element Retrieval using Namespace Based on keyword search over XML
  Documents</title><categories>cs.IR</categories><comments>9 pages</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Querying over XML elements using keyword search is steadily gaining
popularity. The traditional similarity measure is widely employed in order to
effectively retrieve various XML documents. A number of authors have already
proposed different similarity-measure methods that take advantage of the
structure and content of XML documents. They do not, however, consider the
similarity between latent semantic information of element texts and that of
keywords in a query. Although many algorithms on XML element search are
available, some of them have the high computational complexity due to searching
a huge number of elements. In this paper, we propose a new algorithm that makes
use of the semantic similarity between elements instead of between entire XML
documents, considering not only the structure and content of an XML document,
but also semantic information of namespaces in elements. We compare our
algorithm with the three other algorithms by testing on the real datasets. The
experiments have demonstrated that our proposed method is able to improve the
query accuracy, as well as to reduce the running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3828</identifier>
 <datestamp>2011-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3828</id><created>2010-12-17</created><updated>2011-09-15</updated><authors><author><keyname>Mundhenk</keyname><forenames>Martin</forenames></author><author><keyname>Weiss</keyname><forenames>Felix</forenames></author></authors><title>The model checking problem for intuitionistic propositional logic with
  one variable is AC1-complete</title><categories>cs.CC cs.LO</categories><comments>A preliminary version of this work was presented at STACS 2011. 19
  pages, 3 figures</comments><msc-class>68Q17 (Primary), 03B20 (Secondary)</msc-class><acm-class>F.2; F.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We show that the model checking problem for intuitionistic propositional
logic with one variable is complete for logspace-uniform AC1. As basic tool we
use the connection between intuitionistic logic and Heyting algebra, and
investigate its complexity theoretical aspects. For superintuitionistic logics
with one variable, we obtain NC1-completeness for the model checking problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3853</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3853</id><created>2010-12-17</created><authors><author><keyname>Bailleux</keyname><forenames>Olivier</forenames></author></authors><title>On the CNF encoding of cardinality constraints and beyond</title><categories>cs.AI cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, we propose a quick survey of the currently known techniques
for encoding a Boolean cardinality constraint into a CNF formula, and we
discuss about the relevance of these encodings. We also propose models to
facilitate analysis and design of CNF encodings for Boolean constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3875</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3875</id><created>2010-12-17</created><updated>2011-04-17</updated><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author></authors><title>Optimal and Robust Transmit Designs for MISO Channel Secrecy by
  Semidefinite Programming</title><categories>cs.IT math.IT</categories><comments>32 pages, 5 figures; to appear, IEEE Transactions on Signal
  Processing, 2011</comments><doi>10.1109/TSP.2011.2146775</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years there has been growing interest in study of multi-antenna
transmit designs for providing secure communication over the physical layer.
This paper considers the scenario of an intended multi-input single-output
channel overheard by multiple multi-antenna eavesdroppers. Specifically, we
address the transmit covariance optimization for secrecy-rate maximization
(SRM) of that scenario. The challenge of this problem is that it is a nonconvex
optimization problem. This paper shows that the SRM problem can actually be
solved in a convex and tractable fashion, by recasting the SRM problem as a
semidefinite program (SDP). The SRM problem we solve is under the premise of
perfect channel state information (CSI). This paper also deals with the
imperfect CSI case. We consider a worst-case robust SRM formulation under
spherical CSI uncertainties, and we develop an optimal solution to it, again
via SDP. Moreover, our analysis reveals that transmit beamforming is generally
the optimal transmit strategy for SRM of the considered scenario, for both the
perfect and imperfect CSI cases. Simulation results are provided to illustrate
the secrecy-rate performance gains of the proposed SDP solutions compared to
some suboptimal transmit designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3877</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3877</id><created>2010-12-17</created><authors><author><keyname>Cui</keyname><forenames>Ying</forenames></author><author><keyname>Huang</keyname><forenames>Qingqing</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Queue-Aware Dynamic Clustering and Power Allocation for Network MIMO
  Systems via Distributive Stochastic Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a two-timescale delay-optimal dynamic clustering
and power allocation design for downlink network MIMO systems. The dynamic
clustering control is adaptive to the global queue state information (GQSI)
only and computed at the base station controller (BSC) over a longer time
scale. On the other hand, the power allocations of all the BSs in one cluster
are adaptive to both intra-cluster channel state information (CCSI) and
intra-cluster queue state information (CQSI), and computed at the cluster
manager (CM) over a shorter time scale. We show that the two-timescale
delay-optimal control can be formulated as an infinite-horizon average cost
Constrained Partially Observed Markov Decision Process (CPOMDP). By exploiting
the special problem structure, we shall derive an equivalent Bellman equation
in terms of Pattern Selection Q-factor to solve the CPOMDP. To address the
distributive requirement and the issue of exponential memory requirement and
computational complexity, we approximate the Pattern Selection Q-factor by the
sum of Per-cluster Potential functions and propose a novel distributive online
learning algorithm to estimate the Per-cluster Potential functions (at each CM)
as well as the Lagrange multipliers (LM) (at each BS). We show that the
proposed distributive online learning algorithm converges almost surely (with
probability 1). By exploiting the birth-death structure of the queue dynamics,
we further decompose the Per-cluster Potential function into sum of Per-cluster
Per-user Potential functions and formulate the instantaneous power allocation
as a Per-stage QSI-aware Interference Game played among all the CMs. We also
propose a QSI-aware Simultaneous Iterative Water-filling Algorithm (QSIWFA) and
show that it can achieve the Nash Equilibrium (NE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3878</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3878</id><created>2010-12-17</created><authors><author><keyname>H&#xe4;nggi</keyname><forenames>Esther</forenames></author></authors><title>Device-independent quantum key distribution</title><categories>quant-ph cs.CR</categories><comments>PhD Thesis, ETH Zurich, August 2010. 188 pages, a5</comments><report-no>Diss. ETH No. 19226</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this thesis, we study two approaches to achieve device-independent quantum
key distribution: in the first approach, the adversary can distribute any
system to the honest parties that cannot be used to communicate between the
three of them, i.e., it must be non-signalling. In the second approach, we
limit the adversary to strategies which can be implemented using quantum
physics. For both approaches, we show how device-independent quantum key
distribution can be achieved when imposing an additional condition. In the
non-signalling case this additional requirement is that communication is
impossible between all pairwise subsystems of the honest parties, while, in the
quantum case, we demand that measurements on different subsystems must commute.
We give a generic security proof for device-independent quantum key
distribution in these cases and apply it to an existing quantum key
distribution protocol, thus proving its security even in this setting. We also
show that, without any additional such restriction there always exists a
successful joint attack by a non-signalling adversary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3889</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3889</id><created>2010-12-17</created><authors><author><keyname>Escoffier</keyname><forenames>Bruno</forenames></author><author><keyname>Gourv&#xe8;s</keyname><forenames>Laurent</forenames></author><author><keyname>Monnot</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author></authors><title>Minimum regulation of uncoordinated matchings</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the lack of coordination, it is unlikely that the selfish players of a
strategic game reach a socially good state. A possible way to cope with
selfishness is to compute a desired outcome (if it is tractable) and impose it.
However this answer is often inappropriate because compelling an agent can be
costly, unpopular or just hard to implement. Since both situations (no
coordination and full coordination) show opposite advantages and drawbacks, it
is natural to study possible tradeoffs. In this paper we study a strategic game
where the nodes of a simple graph G are independent agents who try to form
pairs: e.g. jobs and applicants, tennis players for a match, etc. In many
instances of the game, a Nash equilibrium significantly deviates from a social
optimum. We analyze a scenario where we fix the strategy of some players; the
other players are free to make their choice. The goal is to compel a minimum
number of players and guarantee that any possible equilibrium of the modified
game is a social optimum, i.e. created pairs must form a maximum matching of G.
We mainly show that this intriguing problem is NP-hard and propose an
approximation algorithm with a constant ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3929</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3929</id><created>2010-12-17</created><updated>2011-05-11</updated><authors><author><keyname>Gillette</keyname><forenames>Andrew</forenames></author><author><keyname>Bajaj</keyname><forenames>Chandrajit</forenames></author></authors><title>Dual Formulations of Mixed Finite Element Methods with Applications</title><categories>math.DG cs.NA math.NA</categories><comments>Invited paper. Submitted. Version 4 has revisions and restructuring
  but same essential ideas</comments><msc-class>65N30, 53-04, 55-04,</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Mixed finite element methods solve a PDE using two or more variables. The
theory of Discrete Exterior Calculus explains why the degrees of freedom
associated to the different variables should be stored on both primal and dual
domain meshes with a discrete Hodge star used to transfer information between
the meshes. We show through analysis and examples that the choice of discrete
Hodge star is essential to the numerical stability of the method. Additionally,
we define interpolation functions and discrete Hodge stars on dual meshes which
can be used to create previously unconsidered mixed methods. Examples from
magnetostatics and Darcy flow are examined in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3932</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3932</id><created>2010-12-17</created><authors><author><keyname>Antoniadis</keyname><forenames>Antonios</forenames></author><author><keyname>H&#xfc;ffner</keyname><forenames>Falk</forenames></author><author><keyname>Lenzner</keyname><forenames>Pascal</forenames></author><author><keyname>Moldenhauer</keyname><forenames>Carsten</forenames></author><author><keyname>Souza</keyname><forenames>Alexander</forenames></author></authors><title>Balanced Interval Coloring</title><categories>cs.DS</categories><comments>Accepted at STACS 2011</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the discrepancy problem of coloring $n$ intervals with $k$ colors
such that at each point on the line, the maximal difference between the number
of intervals of any two colors is minimal. Somewhat surprisingly, a coloring
with maximal difference at most one always exists. Furthermore, we give an
algorithm with running time $O(n \log n + kn \log k)$ for its construction.
This is in particular interesting because many known results for discrepancy
problems are non-constructive. This problem naturally models a load balancing
scenario, where $n$ tasks with given start- and endtimes have to be distributed
among $k$ servers. Our results imply that this can be done ideally balanced.
  When generalizing to $d$-dimensional boxes (instead of intervals), a solution
with difference at most one is not always possible. We show that for any $d \ge
2$ and any $k \ge 2$ it is NP-complete to decide if such a solution exists,
which implies also NP-hardness of the respective minimization problem.
  In an online scenario, where intervals arrive over time and the color has to
be decided upon arrival, the maximal difference in the size of color classes
can become arbitrarily high for any online algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3947</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3947</id><created>2010-12-17</created><authors><author><keyname>Gabbay</keyname><forenames>Dov</forenames></author><author><keyname>Pearce</keyname><forenames>David</forenames></author><author><keyname>Valverde</keyname><forenames>Agust&#xed; n</forenames></author></authors><title>Interpolation in Equilibrium Logic and Answer Set Programming: the
  Propositional Case</title><categories>cs.LO cs.AI</categories><comments>ASPOCP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interpolation is an important property of classical and many non classical
logics that has been shown to have interesting applications in computer science
and AI. Here we study the Interpolation Property for the propositional version
of the non-monotonic system of equilibrium logic, establishing weaker or
stronger forms of interpolation depending on the precise interpretation of the
inference relation. These results also yield a form of interpolation for ground
logic programs under the answer sets semantics. For disjunctive logic programs
we also study the property of uniform interpolation that is closely related to
the concept of variable forgetting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3951</identifier>
 <datestamp>2014-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3951</id><created>2010-12-17</created><authors><author><keyname>Litman</keyname><forenames>Roee</forenames></author><author><keyname>Bronstein</keyname><forenames>Alex M.</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author></authors><title>Diffusion-geometric maximally stable component detection in deformable
  shapes</title><categories>cs.CV</categories><acm-class>I.4.7; I.4.8</acm-class><doi>10.1016/j.cag.2011.03.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximally stable component detection is a very popular method for feature
analysis in images, mainly due to its low computation cost and high
repeatability. With the recent advance of feature-based methods in geometric
shape analysis, there is significant interest in finding analogous approaches
in the 3D world. In this paper, we formulate a diffusion-geometric framework
for stable component detection in non-rigid 3D shapes, which can be used for
geometric feature detection and description. A quantitative evaluation of our
method on the SHREC'10 feature detection benchmark shows its potential as a
source of high-quality features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3953</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3953</id><created>2010-12-17</created><authors><author><keyname>Montes</keyname><forenames>Esther</forenames></author><author><keyname>Isea</keyname><forenames>Raul</forenames></author><author><keyname>Mayo</keyname><forenames>Rafael</forenames></author></authors><title>PhyloGrid: a development for a workflow in Phylogeny</title><categories>cs.CE q-bio.OT</categories><comments>6 pages, ISBN: 978-84-9745-288-5</comments><journal-ref>Iberian Grid Infrastructure Conf. Proceeding (2008) Vol. 2, pp.
  378-387</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this work we present the development of a workflow based on Taverna which
is going to be implemented for calculations in Phylogeny by means of the
MrBayes tool. It has a friendly interface developed with the Gridsphere
framework. The user is able to define the parameters for doing the Bayesian
calculation, determine the model of evolution, check the accuracy of the
results in the intermediate stages as well as do a multiple alignment of the
sequences previously to the final result. To do this, no knowledge from his/her
side about the computational procedure is required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3956</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3956</id><created>2010-12-17</created><authors><author><keyname>Hern&#xe1;ndez</keyname><forenames>Vicente</forenames></author><author><keyname>Blanquer</keyname><forenames>Ignacio</forenames></author><author><keyname>Aparicio</keyname><forenames>Gabriel</forenames></author><author><keyname>Isea</keyname><forenames>Raul</forenames></author><author><keyname>Chav&#xe9;s</keyname><forenames>Juan Luis</forenames></author><author><keyname>Hern&#xe1;ndez</keyname><forenames>&#xc1;lvaro</forenames></author><author><keyname>Mora</keyname><forenames>Henry Ricardo</forenames></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Manuel</forenames></author><author><keyname>Acero</keyname><forenames>Alicia</forenames></author><author><keyname>Montes</keyname><forenames>Esther</forenames></author><author><keyname>Mayo</keyname><forenames>Rafael</forenames></author></authors><title>Advances in the Biomedical Applications of the EELA Project</title><categories>cs.CE q-bio.OT</categories><comments>5 pages</comments><journal-ref>Proceedings of the NETTAB Conference (2007). Vol. 7, pp. 145-156</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the last years an increasing demand for Grid Infrastructures has resulted
in several international collaborations. This is the case of the EELA Project,
which has brought together collaborating groups of Latin America and Europe.
One year ago we presented this e-infrastructure used, among others, by the
Biomedical groups for the studies of oncological analysis, neglected diseases,
sequence alignments and computation phylogenetics. After this period, the
achieved advances are summarised in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.3962</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.3962</id><created>2010-12-17</created><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Liu</keyname><forenames>Bo</forenames></author></authors><title>Quotient Complexity of Star-Free Languages</title><categories>cs.FL</categories><comments>15 pages. 6 figures. 1 Table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quotient complexity, also known as state complexity, of a regular
language is the number of distinct left quotients of the language. The quotient
complexity of an operation is the maximal quotient complexity of the language
resulting from the operation, as a function of the quotient complexities of the
operands. The class of star-free languages is the smallest class containing the
finite languages and closed under boolean operations and concatenation. We
prove that the tight bounds on the quotient complexities of union,
intersection, difference, symmetric difference, concatenation, and star for
star-free languages are the same as those for regular languages, with some
small exceptions, whereas the bound for reversal is 2^n-1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4017</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4017</id><created>2010-12-17</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>A Note on Solid Coloring of Pure Simplicial Complexes</title><categories>cs.DM</categories><comments>11 pages, 6 figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a simple generalization of a known result in the plane. The
simplices in any pure simplicial complex in R^d may be colored with d+1 colors
so that no two simplices that share a (d-1)-facet have the same color. In R^2
this says that any planar map all of whose faces are triangles may be
3-colored, and in R^3 it says that tetrahedra in a collection may be &quot;solid
4-colored&quot; so that no two glued face-to-face receive the same color.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4019</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4019</id><created>2010-12-17</created><updated>2011-07-15</updated><authors><author><keyname>Childs</keyname><forenames>Andrew M.</forenames></author><author><keyname>Jao</keyname><forenames>David</forenames></author><author><keyname>Soukharev</keyname><forenames>Vladimir</forenames></author></authors><title>Constructing elliptic curve isogenies in quantum subexponential time</title><categories>quant-ph cs.CC math.NT</categories><comments>v1: 25 pages; v2: 23 pages, improved presentation</comments><journal-ref>J. Math. Cryptol., 8(1):1-29, 2014</journal-ref><doi>10.1515/jmc-2012-0016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two elliptic curves over a finite field having the same cardinality and
endomorphism ring, it is known that the curves admit an isogeny between them,
but finding such an isogeny is believed to be computationally difficult. The
fastest known classical algorithm takes exponential time, and prior to our work
no faster quantum algorithm was known. Recently, public-key cryptosystems based
on the presumed hardness of this problem have been proposed as candidates for
post-quantum cryptography. In this paper, we give a subexponential-time quantum
algorithm for constructing isogenies, assuming the Generalized Riemann
Hypothesis (but with no other assumptions). Our algorithm is based on a
reduction to a hidden shift problem, together with a new subexponential-time
algorithm for evaluating isogenies from kernel ideals (under only GRH), and
represents the first nontrivial application of Kuperberg's quantum algorithm
for the hidden shift problem. This result suggests that isogeny-based
cryptosystems may be uncompetitive with more mainstream quantum-resistant
cryptosystems such as lattice-based cryptosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4032</identifier>
 <datestamp>2012-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4032</id><created>2010-12-17</created><updated>2012-07-30</updated><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames></author><author><keyname>D&#xed;az-Caro</keyname><forenames>Alejandro</forenames></author><author><keyname>Valiron</keyname><forenames>Beno&#xee;t</forenames></author></authors><title>A Type System for the Vectorial Aspect of the Linear-Algebraic
  Lambda-Calculus</title><categories>cs.LO</categories><comments>In Proceedings DCM 2011, arXiv:1207.6821</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 88, 2012, pp. 1-15</journal-ref><doi>10.4204/EPTCS.88.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a type system for the linear-algebraic lambda-calculus. The type
system accounts for the part of the language emulating linear operators and
vectors, i.e. it is able to statically describe the linear combinations of
terms resulting from the reduction of programs. This gives rise to an original
type theory where types, in the same way as terms, can be superposed into
linear combinations. We show that the resulting typed lambda-calculus is
strongly normalizing and features a weak subject-reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4045</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4045</id><created>2010-12-17</created><authors><author><keyname>Anderson</keyname><forenames>George</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author><author><keyname>Nelwamondo</keyname><forenames>Fulufhelo Vincent</forenames></author></authors><title>Application of Global and One-Dimensional Local Optimization to
  Operating System Scheduler Tuning</title><categories>cs.OS</categories><comments>Proceedings of the Twenty-First Annual Symposium of the Pattern
  Recognition Association of South Africa 22-23 November 2010 Stellenbosch,
  South Africa, pp. 7-11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a study of comparison of global and one-dimensional
local optimization methods to operating system scheduler tuning. The operating
system scheduler we use is the Linux 2.6.23 Completely Fair Scheduler (CFS)
running in simulator (LinSched). We have ported the Hackbench scheduler
benchmark to this simulator and use this as the workload. The global
optimization approach we use is Particle Swarm Optimization (PSO). We make use
of Response Surface Methodology (RSM) to specify optimal parameters for our PSO
implementation. The one-dimensional local optimization approach we use is the
Golden Section method. In order to use this approach, we convert the scheduler
tuning problem from one involving setting of three parameters to one involving
the manipulation of one parameter. Our results show that the global
optimization approach yields better response but the one- dimensional
optimization approach converges to a solution faster than the global
optimization approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4046</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4046</id><created>2010-12-17</created><authors><author><keyname>Xing</keyname><forenames>Bo</forenames></author><author><keyname>Gao</keyname><forenames>Wen-Jing</forenames></author><author><keyname>Battle</keyname><forenames>Kimberly</forenames></author><author><keyname>Marwala</keyname><forenames>Tshildzi</forenames></author><author><keyname>Nelwamondo</keyname><forenames>Fulufhelo V.</forenames></author></authors><title>Artificial Intelligence in Reverse Supply Chain Management: The State of
  the Art</title><categories>cs.AI</categories><comments>Proceedings of the Twenty-First Annual Symposium of the Pattern
  Recognition Association of South Africa 22-23 November 2010 Stellenbosch,
  South Africa, pp. 305-310</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Product take-back legislation forces manufacturers to bear the costs of
collection and disposal of products that have reached the end of their useful
lives. In order to reduce these costs, manufacturers can consider reuse,
remanufacturing and/or recycling of components as an alternative to disposal.
The implementation of such alternatives usually requires an appropriate reverse
supply chain management. With the concepts of reverse supply chain are gaining
popularity in practice, the use of artificial intelligence approaches in these
areas is also becoming popular. As a result, the purpose of this paper is to
give an overview of the recent publications concerning the application of
artificial intelligence techniques to reverse supply chain with emphasis on
certain types of product returns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4050</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4050</id><created>2010-12-17</created><authors><author><keyname>Srivastava</keyname><forenames>Abhishek</forenames></author></authors><title>Motif Analysis in the Amazon Product Co-Purchasing Network</title><categories>cs.SI physics.soc-ph</categories><comments>5 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Online stores like Amazon and Ebay are growing by the day. Fewer people go to
departmental stores as opposed to the convenience of purchasing from stores
online. These stores may employ a number of techniques to advertise and
recommend the appropriate product to the appropriate buyer profile. This
article evaluates various 3-node and 4-node motifs occurring in such networks.
Community structures are evaluated too.These results may provide interesting
insights into user behavior and a better understanding of marketing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4051</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4051</id><created>2010-12-17</created><authors><author><keyname>Zhu</keyname><forenames>Zeyuan Allen</forenames></author></authors><title>Survey &amp; Experiment: Towards the Learning Accuracy</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To attain the best learning accuracy, people move on with difficulties and
frustrations. Though one can optimize the empirical objective using a given set
of samples, its generalization ability to the entire sample distribution
remains questionable. Even if a fair generalization guarantee is offered, one
still wants to know what is to happen if the regularizer is removed, and/or how
well the artificial loss (like the hinge loss) relates to the accuracy.
  For such reason, this report surveys four different trials towards the
learning accuracy, embracing the major advances in supervised learning theory
in the past four years. Starting from the generic setting of learning, the
first two trials introduce the best optimization and generalization bounds for
convex learning, and the third trial gets rid of the regularizer. As an
innovative attempt, the fourth trial studies the optimization when the
objective is exactly the accuracy, in the special case of binary
classification. This report also analyzes the last trial through experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4062</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4062</id><created>2010-12-18</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Makarychev</keyname><forenames>Konstantin</forenames></author></authors><title>Improved Approximation for the Directed Spanner Problem</title><categories>cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the size of the sparsest directed k-spanner of a graph can be
approximated in polynomial time to within a factor of $\tilde{O}(\sqrt{n})$,
for all k &gt;= 3. This improves the $\tilde{O}(n^{2/3})$-approximation recently
shown by Dinitz and Krauthgamer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4066</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4066</id><created>2010-12-18</created><updated>2012-02-16</updated><authors><author><keyname>Schaffrath</keyname><forenames>Gregor</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author><author><keyname>Feldmann</keyname><forenames>Anja</forenames></author></authors><title>Generalized and Resource-Efficient VNet Embeddings with Migrations</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper attends to the problem of embedding flexibly specified CloudNets,
virtual networks connecting cloud resources (such as storage or computation).
We attend to a scenario where customers can request CloudNets at short notice,
and an infrastructure provider (or a potential itermediate broker or reseller)
first embeds the CloudNet fast (e.g., using a simple heuristic). Later,
however, long-lived CloudNets embeddings are optimized by migrating them to
more suitable locations, whose precise definition depends on a given objective
function. For instance, such migrations can be useful to reduce the peak
resource loads in the network by spreading CloudNets across the infrastructure,
to save energy by moving CloudNets together and switching off unused
components, or for maintenance purposes.
  We present a very generic algorithm to compute optimal embeddings of
CloudNets: It allows for different objective functions (such as load
minimization or energy conservation), supports cost-aware migration, and can
deal with all link types that arise in practice (e.g., full-duplex or even
wireless or wired broadcast links with multiple endpoints). Our evaluation
shows that such a rigorous optimization is even feasible in order to optimize a
moderate-size CloudNet of full flexibility (e.g., a router site, a small
physical infrastructure or virtual provider network).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4072</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4072</id><created>2010-12-18</created><updated>2012-02-26</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Kim</keyname><forenames>Dongku</forenames></author></authors><title>Stochastic Control of Event-Driven Feedback in Multi-Antenna
  Interference Channels</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Trans. on Signal Proc., vol. 59, no. 12, pp. 6112 - 6126,
  Dec. 2011</journal-ref><doi>10.1109/TSP.2011.2165063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial interference avoidance is a simple and effective way of mitigating
interference in multi-antenna wireless networks. The deployment of this
technique requires channel-state information (CSI) feedback from each receiver
to all interferers, resulting in substantial network overhead. To address this
issue, this paper proposes the method of distributive control that
intelligently allocates CSI bits over multiple feedback links and adapts
feedback to channel dynamics. For symmetric channel distributions, it is
optimal for each receiver to equally allocate the average sum-feedback rate for
different feedback links, thereby decoupling their control. Using the criterion
of minimum sum-interference power, the optimal feedback-control policy is shown
using stochastic-optimization theory to exhibit opportunism. Specifically, a
specific feedback link is turned on only when the corresponding transmit-CSI
error is significant or interference-channel gain large, and the optimal number
of feedback bits increases with this gain. For high mobility and considering
the sphere-cap-quantized-CSI model, the optimal feedback-control policy is
shown to perform water-filling in time, where the number of feedback bits
increases logarithmically with the corresponding interference-channel gain.
Furthermore, we consider asymmetric channel distributions with heterogeneous
path losses and high mobility, and prove the existence of a unique optimal
policy for jointly controlling multiple feedback links. Given the
sphere-cap-quantized-CSI model, this policy is shown to perform water-filling
over feedback links. Finally, simulation demonstrates that feedback-control
yields significant throughput gains compared with the conventional
differential-feedback method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4074</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4074</id><created>2010-12-18</created><authors><author><keyname>Loh</keyname><forenames>Woong-Kee</forenames></author><author><keyname>Moon</keyname><forenames>Yang-Sae</forenames></author><author><keyname>Lee</keyname><forenames>Wookey</forenames></author></authors><title>A fast divide-and-conquer algorithm for indexing human genome sequences</title><categories>cs.DB</categories><comments>8 pages, 9 figures</comments><doi>10.1587/transinf.E94.D.1369</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the release of human genome sequences, one of the most important
research issues is about indexing the genome sequences, and the suffix tree is
most widely adopted for that purpose. The traditional suffix tree construction
algorithms have severe performance degradation due to the memory bottleneck
problem. The recent disk-based algorithms also have limited performance
improvement due to random disk accesses. Moreover, they do not fully utilize
the recent CPUs with multiple cores. In this paper, we propose a fast algorithm
based on 'divide-and-conquer' strategy for indexing the human genome sequences.
Our algorithm almost eliminates random disk accesses by accessing the disk in
the unit of contiguous chunks. In addition, our algorithm fully utilizes the
multi-core CPUs by dividing the genome sequences into multiple partitions and
then assigning each partition to a different core for parallel processing.
Experimental results show that our algorithm outperforms the previous fastest
DIGEST algorithm by up to 3.5 times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4079</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4079</id><created>2010-12-18</created><authors><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author></authors><title>Non Abelian Bent Functions</title><categories>cs.CR math.RT</categories><comments>Soumis \`a la revue &quot;Cryptographie and communications&quot;</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perfect nonlinear functions from a finite group $G$ to another one $H$ are
those functions $f: G \rightarrow H$ such that for all nonzero $\alpha \in G$,
the derivative $d_{\alpha}f: x \mapsto f(\alpha x) f(x)^{-1}$ is balanced. In
the case where both $G$ and $H$ are Abelian groups, $f: G \rightarrow H$ is
perfect nonlinear if and only if $f$ is bent i.e for all nonprincipal character
$\chi$ of $H$, the (discrete) Fourier transform of $\chi \circ f$ has a
constant magnitude equals to $|G|$. In this paper, using the theory of linear
representations, we exhibit similar bentness-like characterizations in the
cases where $G$ and/or $H$ are (finite) non Abelian groups. Thus we extend the
concept of bent functions to the framework of non Abelian groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4084</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4084</id><created>2010-12-18</created><updated>2011-07-23</updated><authors><author><keyname>Habib</keyname><forenames>Michel</forenames></author><author><keyname>To</keyname><forenames>Thu-Hien</forenames></author></authors><title>Structure and Recognition of 3,4-leaf Powers of Galled Phylogenetic
  Networks in Polynomial Time</title><categories>cs.DM q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is a $k$-leaf power of a tree $T$ if its vertices are leaves of $T$
and two vertices are adjacent in $T$ if and only if their distance in $T$ is at
most $k$. Then $T$ is a $k$-leaf root of $G$. This notion was introduced by
Nishimura, Ragde, and Thilikos [2002] motivated by the search for underlying
phylogenetic trees. We study here an extension of the $k$-leaf power graph
recognition problem. This extension is motivated by a new biological question
for the evaluation of the latteral gene transfer on a population of viruses. We
allow the host graph to slightly differs from a tree and allow some cycles. In
fact we study phylogenetic galled networks in which cycles are pairwise vertex
disjoint. We show some structural results and propose polynomial algorithms for
the cases $k=3$ and $k=4$. As a consequence, squares of galled networks can
also be recognized in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4088</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4088</id><created>2010-12-18</created><authors><author><keyname>Fan</keyname><forenames>Chao</forenames></author><author><keyname>Guo</keyname><forenames>Jin-Li</forenames></author><author><keyname>Zha</keyname><forenames>Yi-Long</forenames></author></authors><title>Fractal Analysis on Human Behaviors Dynamics</title><categories>physics.soc-ph cs.SI</categories><comments>22 pages, 7 figures</comments><journal-ref>Physica A 391 (2012) 6617-6625</journal-ref><doi>10.1016/j.physa.2012.06.063</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The study of human dynamics has attracted much interest from many fields
recently. In this paper, the fractal characteristic of human behaviors is
investigated from the perspective of time series constructed with the amount of
library loans. The Hurst exponents and length of non-periodic cycles calculated
through Rescaled Range Analysis indicate that the time series of human
behaviors is fractal with long-range correlation. Then the time series are
converted to complex networks by visibility graph algorithm. The topological
properties of the networks, such as scale-free property, small-world effect and
hierarchical structure imply that close relationships exist between the amounts
of repetitious actions performed by people during certain periods of time,
especially for some important days. Finally, the networks obtained are verified
to be not fractal and self-similar using box-counting method. Our work implies
the intrinsic regularity shown in human collective repetitious behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4113</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4113</id><created>2010-12-18</created><authors><author><keyname>Dridi</keyname><forenames>Khaled</forenames></author><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author><author><keyname>Djouani</keyname><forenames>Karim</forenames></author><author><keyname>Daachi</keyname><forenames>Boubaker</forenames></author></authors><title>Performance Study of IEEE802.11e QoS in EDCF-Contention-based Static and
  Dynamic Scenarios</title><categories>cs.NI</categories><comments>4 Pages</comments><journal-ref>2nd IEEE International Conference on Electronics, Circuits, and
  Systems (ICECS)2009, Tunis</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we carry-out a study of the Quality of Service (QoS) mechanism
in IEEE802.11e Enhanced Distribution Coordination Function (EDCF) and how it is
achieved by providing traffics with different priorities. It can perform the
access to the radio channel or just simply it can considerably be declined
subsequently to a variation of network dynamicity. The results of the proposed
analysis show that the EDCF scheduler looses the ability of the traffic
differentiation and becomes insensitive to the QoS priority requirements.
Consequently, it goes away from the region of stability and EDCF doesn't offer
better performance than the conventional DCF scheme. Therefore, traffic
specifications are weakly applied only for the channel occupation time
distribution. During the handoff between the Base Stations (BS's), the response
time of the data rate application within the roaming process grows to the
initial throughput level. Performance metrics at the MAC layer, like
throughput, End-2-End delay, and packet loss have been evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4116</identifier>
 <datestamp>2015-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4116</id><created>2010-12-18</created><updated>2014-01-13</updated><authors><author><keyname>Lerman</keyname><forenames>Gilad</forenames></author><author><keyname>Zhang</keyname><forenames>Teng</forenames></author></authors><title>lp-Recovery of the Most Significant Subspace among Multiple Subspaces
  with Outliers</title><categories>stat.ML cs.CV math.FA</categories><comments>This is a revised version of the part of 1002.1994 that deals with
  single subspace recovery. V3: Improved estimates (in particular for Lemma 3.1
  and for estimates relying on it), asymptotic dependence of probabilities and
  constants on D and d and further clarifications; for simplicity it assumes
  uniform distributions on spheres. V4: minor revision for the published
  version</comments><journal-ref>Constructive Approximation, December 2014, Volume 40, Issue 3, pp
  329-385</journal-ref><doi>10.1007/s00365-014-9242-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We assume data sampled from a mixture of d-dimensional linear subspaces with
spherically symmetric distributions within each subspace and an additional
outlier component with spherically symmetric distribution within the ambient
space (for simplicity we may assume that all distributions are uniform on their
corresponding unit spheres). We also assume mixture weights for the different
components. We say that one of the underlying subspaces of the model is most
significant if its mixture weight is higher than the sum of the mixture weights
of all other subspaces. We study the recovery of the most significant subspace
by minimizing the lp-averaged distances of data points from d-dimensional
subspaces, where p&gt;0. Unlike other lp minimization problems, this minimization
is non-convex for all p&gt;0 and thus requires different methods for its analysis.
We show that if 0&lt;p&lt;=1, then for any fraction of outliers the most significant
subspace can be recovered by lp minimization with overwhelming probability
(which depends on the generating distribution and its parameters). We show that
when adding small noise around the underlying subspaces the most significant
subspace can be nearly recovered by lp minimization for any 0&lt;p&lt;=1 with an
error proportional to the noise level. On the other hand, if p&gt;1 and there is
more than one underlying subspace, then with overwhelming probability the most
significant subspace cannot be recovered or nearly recovered. This last result
does not require spherically symmetric outliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4117</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4117</id><created>2010-12-18</created><updated>2011-10-25</updated><authors><author><keyname>Gagarin</keyname><forenames>Andrei</forenames></author><author><keyname>Zverovich</keyname><forenames>Vadim</forenames></author></authors><title>Upper bounds for the bondage number of graphs on topological surfaces</title><categories>math.CO cs.DM</categories><comments>10 pages; Updated version (April 2011); Presented at the 7th ECCC,
  Wolfville (Nova Scotia, Canada), May 4-6, 2011, and the 23rd BCC, Exeter
  (England, UK), July 3-8, 2011</comments><msc-class>05C69, 05C10, 57M15, 90B10, 90B25</msc-class><journal-ref>Discrete Math. 313 (2013), no. 11, pp. 1132-1137</journal-ref><doi>10.1016/j.disc.2011.10.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bondage number b(G) of a graph G is the smallest number of edges of G
whose removal from G results in a graph having the domination number larger
than that of G. We show that, for a graph G having the maximum vertex degree
$\Delta(G)$ and embeddable on an orientable surface of genus h and a
non-orientable surface of genus k, $b(G)\le \min\{\Delta(G)+h+2,
\Delta(G)+k+1\}$. This generalizes known upper bounds for planar and toroidal
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4126</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4126</id><created>2010-12-18</created><authors><author><keyname>Luttrell</keyname><forenames>Stephen</forenames></author></authors><title>Self-Organising Stochastic Encoders</title><categories>cs.NE cs.CV</categories><comments>23 pages, 23 figures</comments><acm-class>I.2.6; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The processing of mega-dimensional data, such as images, scales linearly with
image size only if fixed size processing windows are used. It would be very
useful to be able to automate the process of sizing and interconnecting the
processing windows. A stochastic encoder that is an extension of the standard
Linde-Buzo-Gray vector quantiser, called a stochastic vector quantiser (SVQ),
includes this required behaviour amongst its emergent properties, because it
automatically splits the input space into statistically independent subspaces,
which it then separately encodes. Various optimal SVQs have been obtained, both
analytically and numerically. Analytic solutions which demonstrate how the
input space is split into independent subspaces may be obtained when an SVQ is
used to encode data that lives on a 2-torus (e.g. the superposition of a pair
of uncorrelated sinusoids). Many numerical solutions have also been obtained,
using both SVQs and chains of linked SVQs: (1) images of multiple independent
targets (encoders for single targets emerge), (2) images of multiple correlated
targets (various types of encoder for single and multiple targets emerge), (3)
superpositions of various waveforms (encoders for the separate waveforms emerge
- this is a type of independent component analysis (ICA)), (4) maternal and
foetal ECGs (another example of ICA), (5) images of textures (orientation maps
and dominance stripes emerge). Overall, SVQs exhibit a rich variety of
self-organising behaviour, which effectively discovers the internal structure
of the training data. This should have an immediate impact on &quot;intelligent&quot;
computation, because it reduces the need for expert human intervention in the
design of data processing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4136</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4136</id><created>2010-12-18</created><authors><author><keyname>Zhang</keyname><forenames>Zhenghao</forenames></author><author><keyname>Hu</keyname><forenames>Wei</forenames></author><author><keyname>Xie</keyname><forenames>Jin</forenames></author></authors><title>Employing Coded Relay in Multi-hop Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study Coded relay (Crelay) in multi-hop wireless networks.
Crelay exploits both partial packets and overhearing capabilities of the
wireless nodes, and uses Forward Error Correction code in packet forwarding.
When a node overhears a partial packet from an upstream node, it informs the
upstream node about the number of parity bytes needed to correct the errors,
such that the upstream node need only send a small amount of parity bytes
instead of the complete packet, hence improving the network efficiency. Our
main contributions include the following. First, we propose an efficient
network protocol that can exploit partial packets and overhearing. Second, we
study the routing problem in networks with Crelay and propose a greedy
algorithm for finding the paths. Third, we propose an error ratio estimator,
called AMPS, that can estimate the number of byte errors in a received frame
with good accuracy at a low overhead of only 8 bytes per frame, where the
estimator is needed for a node to find the number of needed parity bytes.
Fourth, we implement the proposed protocol and algorithm within the Click
modular router, and our experiments show that Crelay can significantly improve
the performance of wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4161</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4161</id><created>2010-12-19</created><authors><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author></authors><title>Lattice Code Design for the Rayleigh Fading Wiretap Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown recently that coding for the Gaussian Wiretap Channel can
be done with nested lattices. A fine lattice intended to the legitimate user
must be designed as a usual lattice code for the Gaussian Channel, while a
coarse lattice is added to introduce confusion at the eavesdropper, whose theta
series must be minimized. We present a design criterion for both the fine and
coarse lattice to obtain wiretap lattice codes for the Rayleigh fading Wiretap
Channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4169</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4169</id><created>2010-12-19</created><authors><author><keyname>Frosini</keyname><forenames>Patrizio</forenames></author></authors><title>Stable comparison of multidimensional persistent homology groups with
  torsion</title><categories>math.AT cs.CG</categories><comments>10 pages, 3 figures</comments><msc-class>Primary 55N35, Secondary 68U05</msc-class><acm-class>I.2.10; I.3.5; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present lack of a stable method to compare persistent homology groups
with torsion is a relevant problem in current research about Persistent
Homology and its applications in Pattern Recognition. In this paper we
introduce a pseudo-distance d_T that represents a possible solution to this
problem. Indeed, d_T is a pseudo-distance between multidimensional persistent
homology groups with coefficients in an Abelian group, hence possibly having
torsion. Our main theorem proves the stability of the new pseudo-distance with
respect to the change of the filtering function, expressed both with respect to
the max-norm and to the natural pseudo-distance between topological spaces
endowed with vector-valued filtering functions. Furthermore, we prove a result
showing the relationship between d_T and the matching distance in the
1-dimensional case, when the homology coefficients are taken in a field and
hence the comparison can be made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4170</identifier>
 <datestamp>2012-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4170</id><created>2010-12-19</created><updated>2012-11-26</updated><authors><author><keyname>Jacobs</keyname><forenames>Naomi</forenames></author><author><keyname>Amos</keyname><forenames>Martyn</forenames></author></authors><title>Removing Barriers to Interdisciplinary Research</title><categories>cs.GL</categories><comments>Superceded by 1211.5508</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significant amount of high-impact contemporary scientific research occurs
where biology, computer science, engineering and chemistry converge. Although
programmes have been put in place to support such work, the complex dynamics of
interdisciplinarity are still poorly understood. In this paper we interrogate
the nature of interdisciplinary research and how we might measure its
&quot;success&quot;, identify potential barriers to its implementation, and suggest
possible mechanisms for removing these impediments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4173</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4173</id><created>2010-12-19</created><authors><author><keyname>Luttrell</keyname><forenames>S P</forenames></author></authors><title>A Self-Organising Neural Network for Processing Data from Multiple
  Sensors</title><categories>cs.NE cs.CV</categories><comments>30 pages, 10 figures</comments><acm-class>I.2.6; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows how a folded Markov chain network can be applied to the
problem of processing data from multiple sensors, with an emphasis on the
special case of 2 sensors. It is necessary to design the network so that it can
transform a high dimensional input vector into a posterior probability, for
which purpose the partitioned mixture distribution network is ideally suited.
The underlying theory is presented in detail, and a simple numerical simulation
is given that shows the emergence of ocular dominance stripes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4194</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4194</id><created>2010-12-19</created><authors><author><keyname>Siettos</keyname><forenames>Constantinos</forenames></author></authors><title>Equation-Free Multiscale Computational Analysis of Individual-Based
  Epidemic Dynamics on Networks</title><categories>math.NA cs.SI nlin.AO physics.soc-ph</categories><journal-ref>Applied Mathematics and Computation, 218, 324-336, 2011</journal-ref><doi>10.1016/j.amc.2011.05.067</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The surveillance, analysis and ultimately the efficient long-term prediction
and control of epidemic dynamics appear to be one of the major challenges
nowadays. Detailed atomistic mathematical models play an important role towards
this aim. In this work it is shown how one can exploit the Equation Free
approach and optimization methods such as Simulated Annealing to bridge
detailed individual-based epidemic simulation with coarse-grained,
systems-level, analysis. The methodology provides a systematic approach for
analyzing the parametric behavior of complex/ multi-scale epidemic simulators
much more efficiently than simply simulating forward in time. It is shown how
steady state and (if required) time-dependent computations, stability
computations, as well as continuation and numerical bifurcation analysis can be
performed in a straightforward manner. The approach is illustrated through a
simple individual-based epidemic model deploying on a random regular connected
graph. Using the individual-based microscopic simulator as a black box
coarse-grained timestepper and with the aid of Simulated Annealing I compute
the coarse-grained equilibrium bifurcation diagram and analyze the stability of
the stationary states sidestepping the necessity of obtaining explicit closures
at the macroscopic level under a pairwise representation perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4204</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4204</id><created>2010-12-19</created><updated>2010-12-21</updated><authors><author><keyname>Menke</keyname><forenames>Niels</forenames></author><author><keyname>Reinhard</keyname><forenames>Kai</forenames></author></authors><title>Compliance of POLYAS with the Common Criteria Protection Profile</title><categories>cs.CR</categories><comments>10 pages</comments><journal-ref>Electronic Voting 2010: 109-118</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2008, the German Federal Office for Information Security issued the common
criteria protection profile for Online Voting Products (PP-0037). Accord-
ingly, we evaluated the Polyas electronic voting system, which is used for
legally binding elections in several international organizations (German
Gesellschaft for Informatik, GI, among others), for compliance with the common
criteria protection profile and worked toward fulfilling the given
requirements. In this article we pre- sent the findings of the process of
creating a compliant security target, necessary restrictions and assumptions to
the system design as well as the workings of the committee, and architectural
and procedural changes made necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4225</identifier>
 <datestamp>2014-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4225</id><created>2010-12-19</created><updated>2014-07-23</updated><authors><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author><author><keyname>Meron</keyname><forenames>Eado</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author></authors><title>Delay and Redundancy in Lossless Source Coding</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The penalty incurred by imposing a finite delay constraint in lossless source
coding of a memoryless source is investigated. It is well known that for the
so-called block-to-variable and variable-to-variable codes, the redundancy
decays at best polynomially with the delay, where in this case the delay is
identified with the source block length or maximal source phrase length,
respectively. In stark contrast, it is shown that for sequential codes (e.g., a
delay-limited arithmetic code) the redundancy can be made to decay
exponentially with the delay constraint. The corresponding redundancy-delay
exponent is shown to be at least as good as the R\'enyi entropy of order 2 of
the source, but (for almost all sources) not better than a quantity depending
on the minimal source symbol probability and the alphabet size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4231</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4231</id><created>2010-12-19</created><authors><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>Computation in Large-Scale Scientific and Internet Data Applications is
  a Focus of MMDS 2010</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 2010 Workshop on Algorithms for Modern Massive Data Sets (MMDS 2010) was
held at Stanford University, June 15--18. The goals of MMDS 2010 were (1) to
explore novel techniques for modeling and analyzing massive, high-dimensional,
and nonlinearly-structured scientific and Internet data sets; and (2) to bring
together computer scientists, statisticians, applied mathematicians, and data
analysis practitioners to promote cross-fertilization of ideas. MMDS 2010
followed on the heels of two previous MMDS workshops. The first, MMDS 2006,
addressed the complementary perspectives brought by the numerical linear
algebra and theoretical computer science communities to matrix algorithms in
modern informatics applications; and the second, MMDS 2008, explored more
generally fundamental algorithmic and statistical challenges in modern
large-scale data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4240</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4240</id><created>2010-12-20</created><authors><author><keyname>Schimpf</keyname><forenames>Joachim</forenames></author><author><keyname>Shen</keyname><forenames>Kish</forenames></author></authors><title>ECLiPSe - from LP to CLP</title><categories>cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ECLiPSe is a Prolog-based programming system, aimed at the development and
deployment of constraint programming applications. It is also used for teaching
most aspects of combinatorial problem solving, e.g. problem modelling,
constraint programming, mathematical programming, and search techniques. It
uses an extended Prolog as its high-level modelling and control language,
complemented by several constraint solver libraries, interfaces to third-party
solvers, an integrated development environment and interfaces for embedding
into host environments. This paper discusses language extensions,
implementation aspects, components and tools that we consider relevant on the
way from Logic Programming to Constraint Logic Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4241</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4241</id><created>2010-12-20</created><authors><author><keyname>Katugampola</keyname><forenames>Udita N.</forenames></author></authors><title>A New Technique for Text Data Compression</title><categories>cs.CR cs.IT math.IT</categories><comments>Submitted to IJKEDM</comments><msc-class>68P25</msc-class><journal-ref>2012 International Symposium on Computer, Consumer and Control,
  2012, pp.405-409</journal-ref><doi>10.1109/IS3C.2012.109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we use ternary representation of numbers for compressing text
data. We use a binary map for ternary digits and introduce a way to use the
binary 11-pair, which has never been use for coding data before, and we futher
use 4-Digits ternary representation of alphabet with lowercase and uppercase
with some extra symbols that are most commonly used in day to day life. We find
a way to minimize the length of the bits string, which is only possible in
ternary representation thus drastically reducing the length of the code. We
also find some connection between this technique of coding dat and Fibonacci
numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4249</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4249</id><created>2010-12-20</created><authors><author><keyname>Sevlian</keyname><forenames>Raffi</forenames></author><author><keyname>Rajagopal</keyname><forenames>Ram</forenames></author></authors><title>Travel Time Estimation Using Floating Car Data</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report explores the use of machine learning techniques to accurately
predict travel times in city streets and highways using floating car data
(location information of user vehicles on a road network). The aim of this
report is twofold, first we present a general architecture of solving this
problem, then present and evaluate few techniques on real floating car data
gathered over a month on a 5 Km highway in New Delhi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4250</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4250</id><created>2010-12-20</created><authors><author><keyname>Alvim</keyname><forenames>M&#xe1;rio S.</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Chatzikokolakis</keyname><forenames>Konstantinos</forenames><affiliation>TUE</affiliation></author><author><keyname>Degano</keyname><forenames>Pierpaolo</forenames><affiliation>DI</affiliation></author><author><keyname>Palamidessi</keyname><forenames>Catuscia</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author></authors><title>Differential Privacy versus Quantitative Information Flow</title><categories>cs.IT cs.CR cs.DB math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a notion of privacy that has become very popular in
the database community. Roughly, the idea is that a randomized query mechanism
provides sufficient privacy protection if the ratio between the probabilities
of two different entries to originate a certain answer is bound by e^\epsilon.
In the fields of anonymity and information flow there is a similar concern for
controlling information leakage, i.e. limiting the possibility of inferring the
secret information from the observables. In recent years, researchers have
proposed to quantify the leakage in terms of the information-theoretic notion
of mutual information. There are two main approaches that fall in this
category: One based on Shannon entropy, and one based on R\'enyi's min entropy.
The latter has connection with the so-called Bayes risk, which expresses the
probability of guessing the secret. In this paper, we show how to model the
query system in terms of an information-theoretic channel, and we compare the
notion of differential privacy with that of mutual information. We show that
the notion of differential privacy is strictly stronger, in the sense that it
implies a bound on the mutual information, but not viceversa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4263</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4263</id><created>2010-12-20</created><authors><author><keyname>Gog</keyname><forenames>Simon</forenames></author><author><keyname>Ohlebusch</keyname><forenames>Enno</forenames></author></authors><title>Lightweight LCP-Array Construction in Linear Time</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The suffix tree is a very important data structure in string processing, but
it suffers from a huge space consumption. In large-scale applications,
compressed suffix trees (CSTs) are therefore used instead. A CST consists of
three (compressed) components: the suffix array, the LCP-array, and data
structures for simulating navigational operations on the suffix tree. The
LCP-array stores the lengths of the longest common prefixes of
lexicographically adjacent suffixes, and it can be computed in linear time. In
this paper, we present new LCP-array construction algorithms that are fast and
very space efficient. In practice, our algorithms outperform the currently best
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4290</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4290</id><created>2010-12-20</created><authors><author><keyname>Mennucci</keyname><forenames>Andrea C. G.</forenames></author></authors><title>Bit recycling for scaling random number generators</title><categories>cs.IT math.IT math.NA math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many Random Number Generators (RNG) are available nowadays; they are divided
in two categories, hardware RNG, that provide &quot;true&quot; random numbers, and
algorithmic RNG, that generate pseudo random numbers (PRNG). Both types usually
generate random numbers (X_n) as independent uniform samples in a range
0...2^b-1, with b = 8, 16, 32 or b = 64. In applications, it is instead
sometimes desirable to draw random numbers as independent uniform samples (Y_n)
in a range 1, . . . M, where moreover M may change between drawings.
Transforming the sequence (X_n) to (Y_n) is sometimes known as scaling. We
discuss different methods for scaling the RNG, both in term of mathematical
efficiency and of computational speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4307</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4307</id><created>2010-12-20</created><updated>2011-07-12</updated><authors><author><keyname>Zubair</keyname><forenames>Hisham bin</forenames></author><author><keyname>Reps</keyname><forenames>Bram</forenames></author><author><keyname>Vanroose</keyname><forenames>Wim</forenames></author></authors><title>A preconditioned iterative solver for the scattering solutions of the
  Schr\&quot;odinger equation</title><categories>cs.NA</categories><comments>Accepted in Communications in Computational Physics</comments><journal-ref>Comm. Comput. Phys. 11 p 415-434 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Schr\&quot;odinger equation defines the dynamics of quantum particles which
has been an area of unabated interest in physics. We demonstrate how simple
transformations of the Schr\&quot;odinger equation leads to a coupled linear system,
whereby each diagonal block is a high frequency Helmholtz problem. Based on
this model, we derive indefinite Helmholtz model problems with strongly varying
wavenumbers. We employ the iterative approach for their solution. In
particular, we develop a preconditioner that has its spectrum restricted to a
quadrant (of the complex plane) thereby making it easily invertible by
multigrid methods with standard components. This multigrid preconditioner is
used in conjuction with suitable Krylov-subspace methods for solving the
indefinite Helmholtz model problems. The aim of this study is to report the
feasbility of this preconditioner for the model problems. We compare this idea
with the other prevalent preconditioning ideas, and discuss its merits. Results
of numerical experiments are presented, which complement the proposed ideas,
and show that this preconditioner may be used in an automatic setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4327</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4327</id><created>2010-12-20</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN, DIE</affiliation></author><author><keyname>Ma</keyname><forenames>Ruina</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Using virtual human for an interactive customer-oriented constrained
  environment design</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>IDMME / Virtual Concept, Bordeaux : France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For industrial product design, it is very important to take into account
assembly/disassembly and maintenance operations during the conceptual and
prototype design stage. For these operations or other similar operations in a
constrained environment, trajectory planning is always a critical and difficult
issue for evaluating the design or for the users' convenience. In this paper, a
customer-oriented approach is proposed to partially solve ergonomic issues
encountered during the design stage of a constrained environment. A single
objective optimization based method is taken from the literature to generate
the trajectory in a constrained environment automatically. A motion capture
based method assists to guide the trajectory planning interactively if a local
minimum is encountered within the single objective optimization. At last, a
multi-objective evaluation method is proposed to evaluate the operations
generated by the algorithm
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4349</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4349</id><created>2010-12-20</created><authors><author><keyname>Gavalas</keyname><forenames>Damianos</forenames></author><author><keyname>Greenwood</keyname><forenames>Dominic</forenames></author><author><keyname>Ghanbari</keyname><forenames>Mohammed</forenames></author><author><keyname>O'Mahony</keyname><forenames>Mike</forenames></author></authors><title>A Progressive Network Management Architecture Enabled By Java Technology</title><categories>cs.NI cs.SE</categories><comments>12 pages, 7 figures, 1st International Conference and Exhibition on
  the Practical Applications of Java (PA-Java'99), ISBN: 1-902426-03-07, pp.
  61-72, London, UK, 21-23 April 1999</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a framework based completely on Java technology. The
advantages brought about by the use of Java in network management answer some
critical problems existing in current systems. With this work we address
several factors concerning interoperability and security in heterogeneous
network environments. Specifically, we present a manager application and a
multithreaded agent engine that make use of a lightweight communication
mechanism for message exchange. A MIB parser is introduced to accelerate
handling of incoming management requests, and the RSA public-key cryptosystem
is implemented to provide both encryption and authentication features. Results,
measured in terms of response time, compare favourably with other published
work and standard management frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4374</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4374</id><created>2010-12-20</created><authors><author><keyname>Vautrin</keyname><forenames>Denis</forenames><affiliation>Institut de Recherche en Communications et Cybern&#xe9;tique de Nantes</affiliation></author><author><keyname>Voorons</keyname><forenames>Matthieu</forenames><affiliation>&#xc9;cole Polytechnique de Montr&#xe9;al</affiliation></author><author><keyname>Idier</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>Institut de Recherche en Communications et Cybern&#xe9;tique de Nantes</affiliation></author><author><keyname>Goussard</keyname><forenames>Yves</forenames><affiliation>&#xc9;cole Polytechnique de Montr&#xe9;al</affiliation></author></authors><title>R\'egularisation et optimisation pour l'imagerie sismique des fondations
  de pyl\^ones</title><categories>cs.CE</categories><comments>80 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research report summarizes the progress of work carried out jointly by
the IRCCyN and the \'Ecole Polytechnique de Montr\'eal about the resolution of
the inverse problem for the seismic imaging of transmission overhead line
structure foundations. Several methods aimed at mapping the underground medium
are considered. More particularly, we focus on methods based on a bilinear
formulation of the forward problem on one hand (CSI, modified gradient, etc.)
and on methods based on a &quot;primal&quot; formulation on the other hand. The
performances of these methods are compared using synthetic data. This work was
partially funded by RTE (R\'eseau de Transport d'\'Electricit\'e), which has
initiated the project, and was carried out in collaboration with EDF R&amp;D
(\'Electricit\'e de France - Recherche et D\'eveloppement).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4396</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4396</id><created>2010-12-20</created><authors><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author><author><keyname>Amblard</keyname><forenames>Frederic</forenames></author></authors><title>Selection in Scientific Networks</title><categories>cs.SI cs.CY cs.DL nlin.AO physics.soc-ph</categories><comments>17 pages, 8 Figure, social network analysis, evolving structures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most interesting scientific challenges nowadays deals with the
analysis and the understanding of complex networks' dynamics. A major issue is
the definition of new frameworks for the exploration of the dynamics at play in
real dynamic networks. Here, we focus on scientific communities by analyzing
the &quot;social part&quot; of Science through a descriptive approach that aims at
identifying the social determinants (e.g. goals and potential interactions
among individuals) behind the emergence and the resilience of scientific
communities. We consider that scientific communities are at the same time
communities of practice (through co-authorship) and that they exist also as
representations in the scientists' mind, since references to other scientists'
works is not merely an objective link to a relevant work, but it reveals social
objects that one manipulates and refers to. In this paper we identify the
patterns about the evolution of a scientific field by analyzing a portion of
the arXiv repository covering a period of 10 years of publications in physics.
As a citation represents a deliberative selection related to the relevance of a
work in its scientific domain, our analysis approaches the co-existence between
co-authorship and citation behaviors in a community by focusing on the most
proficient and cited authors interactions patterns. We focus in turn, on how
these patterns are affected by the selection process of citations. Such a
selection a) produces self-organization because it is played by a group of
individuals which act, compete and collaborate in a common environment in order
to advance Science and b) determines the success (emergence) of both topics and
scientists working on them. The dataset is analyzed a) at a global level, e.g.
the network evolution, b) at the meso-level, e.g. communities emergence, and c)
at a micro-level, e.g. nodes' aggregation patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4401</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4401</id><created>2010-12-20</created><authors><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author></authors><title>A Note on a Characterization of R\'enyi Measures and its Relation to
  Composite Hypothesis Testing</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The R\'enyi information measures are characterized in terms of their Shannon
counterparts, and properties of the former are recovered from first principle
via the associated properties of the latter. Motivated by this
characterization, a two-sensor composite hypothesis testing problem is
presented, and the optimal worst case miss-detection exponent is obtained in
terms of a R\'enyi divergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4404</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4404</id><created>2010-12-20</created><authors><author><keyname>Brunetti</keyname><forenames>Sara</forenames></author><author><keyname>Lodi</keyname><forenames>Elena</forenames></author><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author></authors><title>Multicolored Dynamos on Toroidal Meshes</title><categories>cs.DC cs.CC cs.DS cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting on a graph the presence of the minimum number of nodes (target set)
that will be able to &quot;activate&quot; a prescribed number of vertices in the graph is
called the target set selection problem (TSS) proposed by Kempe, Kleinberg, and
Tardos. In TSS's settings, nodes have two possible states (active or
non-active) and the threshold triggering the activation of a node is given by
the number of its active neighbors. Dealing with fault tolerance in a majority
based system the two possible states are used to denote faulty or non-faulty
nodes, and the threshold is given by the state of the majority of neighbors.
Here, the major effort was in determining the distribution of initial faults
leading the entire system to a faulty behavior. Such an activation pattern,
also known as dynamic monopoly (or shortly dynamo), was introduced by Peleg in
1996. In this paper we extend the TSS problem's settings by representing nodes'
states with a &quot;multicolored&quot; set. The extended version of the problem can be
described as follows: let G be a simple connected graph where every node is
assigned a color from a finite ordered set C = {1, . . ., k} of colors. At each
local time step, each node can recolor itself, depending on the local
configurations, with the color held by the majority of its neighbors. Given G,
we study the initial distributions of colors leading the system to a k
monochromatic configuration in toroidal meshes, focusing on the minimum number
of initial k-colored nodes. We find upper and lower bounds to the size of a
dynamo, and then special classes of dynamos, outlined by means of a new
approach based on recoloring patterns, are characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4427</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4427</id><created>2010-12-20</created><updated>2011-09-06</updated><authors><author><keyname>Ito</keyname><forenames>Tsuyoshi</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Watrous</keyname><forenames>John</forenames></author></authors><title>Quantum interactive proofs with weak error bounds</title><categories>quant-ph cs.CC</categories><comments>18 pages. v3: improved presentation, corrected minor errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proves that the computational power of quantum interactive proof
systems, with a double-exponentially small gap in acceptance probability
between the completeness and soundness cases, is precisely characterized by
EXP, the class of problems solvable in exponential time by deterministic Turing
machines. This fact, and our proof of it, has implications concerning quantum
and classical interactive proof systems in the setting of unbounded error that
include the following:
  * Quantum interactive proof systems are strictly more powerful than their
classical counterparts in the unbounded-error setting unless PSPACE=EXP, as
even unbounded error classical interactive proof systems can be simulated in
PSPACE.
  * The recent proof of Jain, Ji, Upadhyay, and Watrous (STOC 2010)
establishing QIP=PSPACE relies heavily on the fact that the quantum interactive
proof systems defining the class QIP have bounded error. Our result implies
that some nontrivial assumption on the error bounds for quantum interactive
proofs is unavoidable to establish this result (unless PSPACE=EXP).
  * To prove our result, we give a quantum interactive proof system for EXP
with perfect completeness and soundness error 1-2^{-2^poly}, for which the
soundness error bound is provably tight. This establishes another respect in
which quantum and classical interactive proof systems differ, because such a
bound cannot hold for any classical interactive proof system: distinct
acceptance probabilities for classical interactive proof systems must be
separated by a gap that is at least (single-)exponentially small.
  We also study the computational power of a few other related unbounded-error
complexity classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4452</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4452</id><created>2010-12-20</created><authors><author><keyname>Reddy</keyname><forenames>Rohith Singi</forenames></author></authors><title>Encryption of Binary and Non-Binary Data Using Chained Hadamard
  Transforms</title><categories>cs.CR</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new chaining technique for the use of Hadamard
transforms for encryption of both binary and non-binary data. The lengths of
the input and output sequence need not be identical. The method may be used
also for hashing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4485</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4485</id><created>2010-12-20</created><authors><author><keyname>Gavalas</keyname><forenames>Damianos</forenames></author></authors><title>An Experimental Approach for Optimising Mobile Agent Migrations</title><categories>cs.NI cs.MA</categories><comments>8 pages, 7 figures</comments><journal-ref>Mediterranean Journal of Computers and Networks, 1(1), pp. 47-56,
  SoftMotor Ltd., ISSN: 1744-2397, July 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of mobile agent (MA) technology has been intensively researched
during the past few years, resulting in the phenomenal proliferation of
available MA platforms, all sharing several common design characteristics.
Research projects have mainly focused on identifying applications where the
employment of MAs is preferable compared to centralised or alternative
distributed computing models. Very little work has been made on examining how
MA platforms design can be optimised so as the network traffic and latency
associated with MA transfers are minimised. The work presented in this paper
addresses these issues by investigating the effect of several optimisation
ideas applied on our MA platform prototype. Furthermore, we discuss the results
of a set of timing experiments that offers a better understanding of the agent
migration process and recommend new techniques for reducing MA transfers delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4487</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4487</id><created>2010-12-20</created><authors><author><keyname>Zafeiri</keyname><forenames>Konstantina</forenames></author><author><keyname>Gavalas</keyname><forenames>Damianos</forenames></author><author><keyname>Balla</keyname><forenames>Aikaterini</forenames></author></authors><title>Selling Culture: Implementation of e-Commerce and WAP-based Prototypes</title><categories>cs.NI cs.SE</categories><comments>9 pages, 8 figures</comments><journal-ref>International Review on Computers and Software (ISSN: 1828-6003),
  1(1), pp 68-76, Praise Worthy Prize, July 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Museum stores represent integral parts of the museums that have also a lot to
benefit from a successful presence on the web arena. In addition to traditional
web sites, carefully designed electronic commerce (e-commerce) sites may
increase the potential of museum stores offering possibilities for on-line
shopping and other commercial functions. In parallel, the recent convergence of
the traditionally separate technologies of the Internet and mobile telephony
has brought the concept of 'wireless Internet' into the spotlight. Within this
context, 'mobile commerce' (m-commerce) is a relatively new trend that
represents a natural extension of e-commerce into the wireless world.
M-commerce refers to electronic business transactions and differentiates from
e-commerce since it involves the use of mobile devices and wireless medium
rather than wired. The unique characteristics of mobile computing bring forward
new challenges and opportunities for museum stores. This article presents the
design and implementation of an e-commerce and an m-commerce museum shop
application. The aim is to evaluate and compare the two applications in terms
of several parameters, such as available technologies, strengths and
limitations, design requirements, usability, interaction speed, usage cost, etc
and also to identify ways for enhancing the potential of such applications and
designing successful and profitable business models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4519</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4519</id><created>2010-12-20</created><updated>2011-05-31</updated><authors><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>Belief-propagation-based joint channel estimation and decoding for
  spectrally efficient communication over unknown sparse channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider spectrally-efficient communication over a Rayleigh N-block-fading
channel with a K- sparse L-length discrete-time impulse response (for 0&lt;K&lt;L&lt;N),
where neither the transmitter nor receiver know the channel's coefficients nor
its support. Since the high-SNR ergodic capacity of this channel has been shown
to obey C(SNR) = (1-K/N)log2(SNR)+O(1), any pilot-aided scheme that sacrifices
more than K dimensions per fading block to pilots will be spectrally
inefficient. This causes concern about the conventional &quot;compressed channel
sensing&quot; approach, which uses O(K polylog L) pilots. In this paper, we
demonstrate that practical spectrally-efficient communication is indeed
possible. For this, we propose a novel belief-propagation-based reception
scheme to use with a standard bit- interleaved coded orthogonal frequency
division multiplexing (OFDM) transmitter. In particular, we leverage the
&quot;relaxed belief propagation&quot; methodology, which allows us to perform joint
sparse-channel estimation and data decoding with only O(LN) complexity.
Empirical results show that our receiver achieves the desired capacity pre-log
factor of 1 - K/N and performs near genie-aided bounds at both low and high
SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4521</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4521</id><created>2010-12-20</created><authors><author><keyname>Keys</keyname><forenames>Aaron S.</forenames></author><author><keyname>Iacovella</keyname><forenames>Christopher R.</forenames></author><author><keyname>Glotzer</keyname><forenames>Sharon C.</forenames></author></authors><title>Characterizing Structure Through Shape Matching and Applications to Self
  Assembly</title><categories>cond-mat.soft cs.CV</categories><comments>19 pages, 9 figures</comments><journal-ref>Annual Review of Condensed Matter Physics, Vol. 2 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structural quantities such as order parameters and correlation functions are
often employed to gain insight into the physical behavior and properties of
condensed matter systems. While standard quantities for characterizing
structure exist, often they are insufficient for treating problems in the
emerging field of nano and microscale self-assembly, where the structures
encountered may be complex and unusual. The computer science field of &quot;shape
matching&quot; offers a robust solution to this problem by defining diverse methods
for quantifying the similarity between arbitrarily complex shapes. Most order
parameters and correlation functions used in condensed matter apply a specific
measure of structural similarity within the context of a broader scheme. By
substituting shape matching quantities for traditional quantities, we retain
the essence of the broader scheme, but extend its applicability to more complex
structures. Here we review some standard shape matching techniques and discuss
how they might be used to create highly flexible structural metrics for diverse
systems such as self-assembled matter. We provide three proof-of-concept
example problems applying shape matching methods to identifying local and
global structures, and tracking structural transitions in complex assembled
systems. The shape matching methods reviewed here are applicable to a wide
range of condensed matter systems, both simulated and experimental, provided
particle positions are known or can be accurately imaged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4524</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4524</id><created>2010-12-20</created><authors><author><keyname>Reichardt</keyname><forenames>Joerg</forenames></author><author><keyname>Alamino</keyname><forenames>Roberto</forenames></author><author><keyname>Saad</keyname><forenames>David</forenames></author></authors><title>The interplay of microscopic and mesoscopic structure in complex
  networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph q-bio.MN</categories><doi>10.1371/journal.pone.0021282</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Not all nodes in a network are created equal. Differences and similarities
exist at both individual node and group levels. Disentangling single node from
group properties is crucial for network modeling and structural inference.
Based on unbiased generative probabilistic exponential random graph models and
employing distributive message passing techniques, we present an efficient
algorithm that allows one to separate the contributions of individual nodes and
groups of nodes to the network structure. This leads to improved detection
accuracy of latent class structure in real world data sets compared to models
that focus on group structure alone. Furthermore, the inclusion of hitherto
neglected group specific effects in models used to assess the statistical
significance of small subgraph (motif) distributions in networks may be
sufficient to explain most of the observed statistics. We show the predictive
power of such generative models in forecasting putative gene-disease
associations in the Online Mendelian Inheritance in Man (OMIM) database. The
approach is suitable for both directed and undirected uni-partite as well as
for bipartite networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4527</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4527</id><created>2010-12-20</created><authors><author><keyname>Keys</keyname><forenames>Aaron S.</forenames></author><author><keyname>Iacovella</keyname><forenames>Christopher R.</forenames></author><author><keyname>Glotzer</keyname><forenames>Sharon C.</forenames></author></authors><title>Harmonic Order Parameters for Characterizing Complex Particle
  Morphologies</title><categories>cond-mat.soft cs.CV physics.chem-ph</categories><comments>13 pages, 9 figures, J. Chem. Phys., submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Order parameters based on spherical harmonics and Fourier coefficients
already play a significant role in condensed matter research in the context of
systems of spherical or point particles. Here, we extend these types of order
parameter to more complex shapes, such as those encountered in nanoscale
self-assembly applications. To do so, we build on a powerful set of techniques
that originate in the computer science field of &quot;shape matching.&quot; We
demonstrate how shape matching techniques can be applied to identify unknown
structures and create highly-specialized \textit{ad hoc} order parameters.
Additionally, we investigate the special symmetry properties of harmonic
descriptors, and demonstrate how they can be exploited to provide optimal
solutions to certain classes of problems. Our techniques can be applied to
particle systems in general, both simulated and experimental, provided the
particle positions are known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4542</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4542</id><created>2010-12-20</created><authors><author><keyname>Geng</keyname><forenames>Chunhua</forenames></author><author><keyname>Pei</keyname><forenames>Yukui</forenames></author><author><keyname>Zhang</keyname><forenames>Jiaqi</forenames></author><author><keyname>Ge</keyname><forenames>Ning</forenames></author></authors><title>Impact of Mistiming on the Achievable Information Rate of Rake Receivers
  in DS-UWB Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 7 figures, submitted to IEEE VTC 2011 spring in Sept.2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we investigate the impact of mistiming on the performance of
Rake receivers in direct-sequence ultra-wideband (DS-UWB) systems from the
perspective of the achievable information rate. A generalized expression for
the performance degradation due to mistiming is derived. Monte Carlo
simulations based on this expression are then conducted, which demonstrate that
the performance loss has little relationship with the target achievable
information rate, but varies significantly with the system bandwidth and the
multipath diversity order, which reflects design trade-offs among the system
timing requirement, the bandwidth and the implementation complexity. In
addition, the performance degradations of Rake receivers with different
multipath component selection schemes and combining techniques are compared.
Among these receivers, the widely used maximal ratio combining (MRC)
selective-Rake (S-Rake) suffers the largest performance loss in the presence of
mistiming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4552</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4552</id><created>2010-12-21</created><updated>2011-06-06</updated><authors><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>On the Throughput Cost of Physical Layer Security in Decentralized
  Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the throughput of large-scale decentralized wireless
networks with physical layer security constraints. In particular, we are
interested in the question of how much throughput needs to be sacrificed for
achieving a certain level of security. We consider random networks where the
legitimate nodes and the eavesdroppers are distributed according to independent
two-dimensional Poisson point processes. The transmission capacity framework is
used to characterize the area spectral efficiency of secure transmissions with
constraints on both the quality of service (QoS) and the level of security.
This framework illustrates the dependence of the network throughput on key
system parameters, such as the densities of legitimate nodes and eavesdroppers,
as well as the QoS and security constraints. One important finding is that the
throughput cost of achieving a moderate level of security is quite low, while
throughput must be significantly sacrificed to realize a highly secure network.
We also study the use of a secrecy guard zone, which is shown to give a
significant improvement on the throughput of networks with high security
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4554</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4554</id><created>2010-12-21</created><authors><author><keyname>Fernandez</keyname><forenames>Maribel</forenames><affiliation>King's College London</affiliation></author></authors><title>Proceedings 24th International Workshop on Unification</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 42, 2010</journal-ref><doi>10.4204/EPTCS.42</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains selected papers presented at the 24th International
Workshop on Unification, UNIF2010, which was held in Edinburgh on the 14th July
2010, as part of FLoC 2010 (Federated Logic Conferences).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4555</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4555</id><created>2010-12-21</created><authors><author><keyname>Bove</keyname><forenames>Ana</forenames><affiliation>Chalmers University of Technology</affiliation></author><author><keyname>Komendantskaya</keyname><forenames>Ekaterina</forenames><affiliation>University of Dundee</affiliation></author><author><keyname>Niqui</keyname><forenames>Milad</forenames><affiliation>CWI</affiliation></author></authors><title>Proceedings Workshop on Partiality and Recursion in Interactive Theorem
  Provers</title><categories>cs.LO</categories><proxy>EPTCS</proxy><acm-class>F.3.1; F.4.1; D.2.4</acm-class><journal-ref>EPTCS 43, 2010</journal-ref><doi>10.4204/EPTCS.43</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Workshop on Partiality and
Recursion in Interactive Theorem Provers (PAR 2010) which took place on July 15
in Edinburgh, UK. This workshop was held as a satellite workshop of the
International Conference on Interactive Theorem Proving (ITP 2010), itself part
of the Federated Logic Conference 2010 (FLoC 2010).
  This workshop is a venue for researchers working on new approaches to cope
with partial functions and terminating general (co)recursion in theorem
provers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4556</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4556</id><created>2010-12-21</created><authors><author><keyname>Geng</keyname><forenames>Chunhua</forenames></author><author><keyname>Pei</keyname><forenames>Yukui</forenames></author><author><keyname>Ge</keyname><forenames>Ning</forenames></author></authors><title>Selective Multipath Interference Canceller with Linear Equalization for
  DS-UWB Systems with Low Spreading Factor</title><categories>cs.NI</categories><comments>6 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In high rate DS-UWB systems with low spreading factor, the selective
multipath interference canceller with linear equalization (SMPIC-LE) is
developed to alleviate severe multipath interferences induced by the poor
orthogonality of spreading codes. The SMPIC iteratively mitigates the strongest
inter-path interference, inter-chip interference and inter-symbol interference,
while the former two are unresolvable in conventional RAKE-decision feedback
equalizer (DFE) receivers. The numerical results and complexity analysis
demonstrate that SMPIC-LE with proper parameters provides an attractive overall
advantage in performance and computational complexity compared with RAKE-DFE.
In addition, it approaches the matched filter bound well as the RAKE finger in
SMPIC increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4559</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4559</id><created>2010-12-21</created><authors><author><keyname>Eades</keyname><forenames>Peter</forenames></author><author><keyname>Huang</keyname><forenames>Weidong</forenames></author><author><keyname>Hong</keyname><forenames>Seok-Hee</forenames></author></authors><title>A Force-Directed Method for Large Crossing Angle Graph Drawing</title><categories>cs.HC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recent empirical research has indicated that human graph reading performance
improves when crossing angles increase. However, crossing angle has not been
used as an aesthetic criterion for graph drawing algorithms so far. In this
paper, we introduce a force-directed method that aims to construct graph
drawings with large crossing angles. Experiments indicate that our method
significantly increases crossing angles. Surprisingly, the experimental results
further demonstrate that the resulting drawings produced by our method have
fewer edge crossings, a shorter total edge length and more uniform edge
lengths, compared to classical spring algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4560</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4560</id><created>2010-12-21</created><authors><author><keyname>Ponty</keyname><forenames>Yann</forenames><affiliation>INRIA Saclay - Ile de France, LIX</affiliation></author></authors><title>Non-redundant random generation from weighted context-free languages</title><categories>cs.DS cs.FL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the non-redundant random generation of k words of length n from a
context-free language. Additionally, we want to avoid a predefined set of
words. We study the limits of a rejection-based approach, whose time complexity
is shown to grow exponentially in k in some cases. We propose an alternative
recursive algorithm, whose careful implementation allows for a non-redundant
generation of k words of size n in O(kn log n) arithmetic operations after the
precomputation of O(n) numbers. The overall complexity is therefore dominated
by the generation of k words, and the non-redundancy comes at a negligible
cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4567</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4567</id><created>2010-12-21</created><authors><author><keyname>Kesting</keyname><forenames>Arne</forenames></author><author><keyname>Treiber</keyname><forenames>Martin</forenames></author></authors><title>Online traffic state estimation based on floating car data</title><categories>cs.OH physics.data-an</categories><comments>Appears in Proceedings of Traffic and Granular Flow '09 (TGF'09), see
  http://tgf09.shu.edu.cn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Besides the traditional data collection by stationary detectors, recent
advances in wireless and sensor technologies have promoted new potentials for a
vehicle-based data collection and local dissemination of information. By means
of microscopic traffic simulations we study the problem of online estimation of
the current traffic situation based on floating car data. Our focus is on the
estimation on the up- and downstream jam fronts determining the extension of
traffic congestion. We study the impact of delayed information transmission by
short-range communication via wireless LAN in contrast to instantaneous
information transmission to the roadside units by means of mobile radio. The
delayed information transmission leads to systematic estimation errors which
cannot be compensated for by a higher percentage of probe vehicles. Additional
flow measurements from stationary detectors allow for a model-based prediction
which is effective for much lower floating car percentages than 1%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4571</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4571</id><created>2010-12-21</created><authors><author><keyname>Sismanis</keyname><forenames>Yannis</forenames></author></authors><title>How I won the &quot;Chess Ratings - Elo vs the Rest of the World&quot; Competition</title><categories>cs.LG</categories><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article discusses in detail the rating system that won the kaggle
competition &quot;Chess Ratings: Elo vs the rest of the world&quot;. The competition
provided a historical dataset of outcomes for chess games, and aimed to
discover whether novel approaches can predict the outcomes of future games,
more accurately than the well-known Elo rating system. The winning rating
system, called Elo++ in the rest of the article, builds upon the Elo rating
system. Like Elo, Elo++ uses a single rating per player and predicts the
outcome of a game, by using a logistic curve over the difference in ratings of
the players. The major component of Elo++ is a regularization technique that
avoids overfitting these ratings. The dataset of chess games and outcomes is
relatively small and one has to be careful not to draw &quot;too many conclusions&quot;
out of the limited data. Many approaches tested in the competition showed signs
of such an overfitting. The leader-board was dominated by attempts that did a
very good job on a small test dataset, but couldn't generalize well on the
private hold-out dataset. The Elo++ regularization takes into account the
number of games per player, the recency of these games and the ratings of the
opponents. Finally, Elo++ employs a stochastic gradient descent scheme for
training the ratings, and uses only two global parameters (white's advantage
and regularization constant) that are optimized using cross-validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4583</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4583</id><created>2010-12-21</created><authors><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Gall</keyname><forenames>Fran&#xe7;ois Le</forenames></author><author><keyname>Nishimura</keyname><forenames>Harumichi</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>Constructing Quantum Network Coding Schemes from Classical Nonlinear
  Protocols</title><categories>quant-ph cs.IT math.IT</categories><comments>14 pages</comments><journal-ref>Proceedings 2011 IEEE International Symposium on Information
  Theory (ISIT 2011), pp. 109-113</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-pair problem in network coding theory asks to send k messages
simultaneously between k source-target pairs over a directed acyclic graph. In
a previous paper [ICALP 2009, Part I, pages 622--633] the present authors
showed that if a classical k-pair problem is solvable by means of a linear
coding scheme, then the quantum k-pair problem over the same graph is also
solvable, provided that classical communication can be sent for free between
any pair of nodes of the graph. Here we address the main case that remained
open in our previous work, namely whether nonlinear classical network coding
schemes can also give rise to quantum network coding schemes. This question is
motivated by the fact that there are networks for which there are no linear
solutions to the k-pair problem, whereas nonlinear solutions exist. In the
present paper we overcome the limitation to linear protocols and describe a new
communication protocol for perfect quantum network coding that improves over
the previous one as follows: (i) the new protocol does not put any condition on
the underlying classical coding scheme, that is, it can simulate nonlinear
communication protocols as well, and (ii) the amount of classical communication
sent in the protocol is significantly reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4620</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4620</id><created>2010-12-21</created><authors><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author><author><keyname>Wang</keyname><forenames>Qianxue</forenames></author><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author></authors><title>Improving random number generators by chaotic iterations. Application in
  data hiding</title><categories>cs.CR nlin.CD</categories><comments>6 pages, 8 figures, In ICCASM 2010, Int. Conf. on Computer
  Application and System Modeling, Taiyuan, China, pages ***--***, October 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new pseudo-random number generator (PRNG) based on chaotic
iterations is proposed. This method also combines the digits of two XORshifts
PRNGs. The statistical properties of this new generator are improved: the
generated sequences can pass all the DieHARD statistical test suite. In
addition, this generator behaves chaotically, as defined by Devaney. This makes
our generator suitable for cryptographic applications. An illustration in the
field of data hiding is presented and the robustness of the obtained data
hiding algorithm against attacks is evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4621</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4621</id><created>2010-12-21</created><authors><author><keyname>Zhuo</keyname><forenames>Zhao</forenames></author><author><keyname>Cai</keyname><forenames>Shi-Min</forenames></author><author><keyname>Fu</keyname><forenames>Zhong-Qian</forenames></author><author><keyname>Wang</keyname><forenames>Wen-Xu</forenames></author></authors><title>Self-organized Emergence of Navigability on Small-World Networks</title><categories>cs.SI physics.soc-ph</categories><comments>3 figures</comments><journal-ref>New Jour. Phys. 13, 053030 (2011)</journal-ref><doi>10.1088/1367-2630/13/5/053030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper mainly investigates why small-world networks are navigable and how
to navigate small-world networks. We find that the navigability can naturally
emerge from self-organization in the absence of prior knowledge about
underlying reference frames of networks. Through a process of information
exchange and accumulation on networks, a hidden metric space for navigation on
networks is constructed. Navigation based on distances between vertices in the
hidden metric space can efficiently deliver messages on small-world networks,
in which long range connections play an important role. Numerical simulations
further suggest that high cluster coefficient and low diameter are both
necessary for navigability. These interesting results provide profound insights
into scalable routing on the Internet due to its distributed and localized
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4623</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4623</id><created>2010-12-21</created><authors><author><keyname>Xu</keyname><forenames>Xin-Jian</forenames></author><author><keyname>Peng</keyname><forenames>Xiao-Long</forenames></author><author><keyname>Small</keyname><forenames>Michael</forenames></author><author><keyname>Fu</keyname><forenames>Xin-Chu</forenames></author></authors><title>Fitness-driven deactivation in network evolution</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>IoP Style</comments><journal-ref>J. Stat. Mech. (2010) P12020</journal-ref><doi>10.1088/1742-5468/2010/12/P12020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Individual nodes in evolving real-world networks typically experience growth
and decay --- that is, the popularity and influence of individuals peaks and
then fades. In this paper, we study this phenomenon via an intrinsic nodal
fitness function and an intuitive aging mechanism. Each node of the network is
endowed with a fitness which represents its activity. All the nodes have two
discrete stages: active and inactive. The evolution of the network combines the
addition of new active nodes randomly connected to existing active ones and the
deactivation of old active nodes with possibility inversely proportional to
their fitnesses. We obtain a structured exponential network when the fitness
distribution of the individuals is homogeneous and a structured scale-free
network with heterogeneous fitness distributions. Furthermore, we recover two
universal scaling laws of the clustering coefficient for both cases, $C(k) \sim
k^{-1}$ and $C \sim n^{-1}$, where $k$ and $n$ refer to the node degree and the
number of active individuals, respectively. These results offer a new simple
description of the growth and aging of networks where intrinsic features of
individual nodes drive their popularity, and hence degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4626</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4626</id><created>2010-12-21</created><authors><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author><author><keyname>Wang</keyname><forenames>Qianxue</forenames></author><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author></authors><title>A Pseudo Random Numbers Generator Based on Chaotic Iterations.
  Application to Watermarking</title><categories>cs.CR nlin.CD</categories><comments>11 pages, 7 figures, In WISM 2010, Int. Conf. on Web Information
  Systems and Mining, volume 6318 of LNCS, Sanya, China, pages 202--211,
  October 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new chaotic pseudo-random number generator (PRNG) is
proposed. It combines the well-known ISAAC and XORshift generators with chaotic
iterations. This PRNG possesses important properties of topological chaos and
can successfully pass NIST and TestU01 batteries of tests. This makes our
generator suitable for information security applications like cryptography. As
an illustrative example, an application in the field of watermarking is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4668</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4668</id><created>2010-12-21</created><authors><author><keyname>Bajovic</keyname><forenames>Dragana</forenames></author><author><keyname>Jakovetic</keyname><forenames>Dusan</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author><author><keyname>Sinopoli</keyname><forenames>Bruno</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Distributed Detection over Random Networks: Large Deviations Performance
  Analysis</title><categories>cs.IT math.IT</categories><comments>30 pages, journal, submitted on December 3rd, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the large deviations performance, i.e., the exponential decay rate
of the error probability, of distributed detection algorithms over random
networks. At each time step $k$ each sensor: 1) averages its decision variable
with the neighbors' decision variables; and 2) accounts on-the-fly for its new
observation. We show that distributed detection exhibits a &quot;phase change&quot;
behavior. When the rate of network information flow (the speed of averaging) is
above a threshold, then distributed detection is asymptotically equivalent to
the optimal centralized detection, i.e., the exponential decay rate of the
error probability for distributed detection equals the Chernoff information.
When the rate of information flow is below a threshold, distributed detection
achieves only a fraction of the Chernoff information rate; we quantify this
achievable rate as a function of the network rate of information flow.
Simulation examples demonstrate our theoretical findings on the behavior of
distributed detection over random networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4688</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4688</id><created>2010-12-21</created><authors><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author><author><keyname>Javaid</keyname><forenames>Akmal</forenames></author><author><keyname>Khan</keyname><forenames>Imran Ali</forenames></author><author><keyname>Djouani</keyname><forenames>Karim</forenames></author></authors><title>Performance Study of ETX based Wireless Routing Metrics</title><categories>cs.NI</categories><comments>The 2nd IEEE International Conference on Computer, Control and
  Communication, 2009 (IEEE-IC4 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Being most popular and IETF standard metric, minimum hop count is
appropriately used by Ad hoc Networks, as new paths must rapidly be found in
the situations where quality paths could not be found in due time due to high
node mobility. There always has been a tradeoff between throughput and energy
consumption, but stationary topology of WMNs and high node density of WSN's
benefit the algorithms to consider quality-aware routing to choose the best
routes. In this paper, we analytically review ongoing research on wireless
routing metrics which are based on ETX (Expected Transmission Count) as it
performs better than minimum hop count under link availability. Performances
over ETX, target platforms and design requirements of these ETX based metrics
are high-lighted. Consequences of the criteria being adopted (in addition to
expected link layer transmissions &amp; retransmissions) in the form of
incremental: (1) performance overheads and computational complexity causing
inefficient use of network resources and instability of the routing algorithm,
(2) throughput gains achieved with better utilization of wireless medium
resources have been elaborated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4691</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4691</id><created>2010-12-21</created><authors><author><keyname>Godskesen</keyname><forenames>Steffen</forenames></author><author><keyname>Jensen</keyname><forenames>Thomas Sejr</forenames></author><author><keyname>Kjeldsen</keyname><forenames>Niels</forenames></author><author><keyname>Larsen</keyname><forenames>Rune</forenames></author></authors><title>Solving a real-life large-scale energy management problem</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a three-phase heuristic approach for a large-scale
energy management and maintenance scheduling problem. The problem is concerned
with scheduling maintenance and refueling for nuclear power plants up to five
years into the future, while handling a number of scenarios for future demand
and prices. The goal is to minimize the expected total production costs. The
first phase of the heuristic solves a simplified constraint programming model
of the problem, the second performs a local search, and the third handles
overproduction in a greedy fashion.
  This work was initiated in the context of the ROADEF/EURO Challenge 2010, a
competition organized jointly by the French Operational Research and Decision
Support Society, the European Operational Research Society, and the European
utility company Electricite de France. In the concluding phase of the
competition our team ranked second in the junior category and sixth overall.
  After correcting an implementation bug in the program that was submitted for
evaluation, our heuristic solves all ten real-life instances, and the solutions
obtained are all within 2.45% of the currently best known solutions. The
results given here would have ranked first in the original competition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4701</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4701</id><created>2010-12-21</created><updated>2013-09-26</updated><authors><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author></authors><title>Vertex Cover Kernelization Revisited: Upper and Lower Bounds for a
  Refined Parameter</title><categories>cs.DS cs.CC</categories><comments>Published in &quot;Theory of Computing Systems&quot; as an Open Access
  publication</comments><acm-class>F.2.2</acm-class><journal-ref>Theory Comput. Syst. 53(2): 263-299 (2013)</journal-ref><doi>10.1007/s00224-012-9393-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important result in the study of polynomial-time preprocessing shows that
there is an algorithm which given an instance (G,k) of Vertex Cover outputs an
equivalent instance (G',k') in polynomial time with the guarantee that G' has
at most 2k' vertices (and thus O((k')^2) edges) with k' &lt;= k. Using the
terminology of parameterized complexity we say that k-Vertex Cover has a kernel
with 2k vertices. There is complexity-theoretic evidence that both 2k vertices
and Theta(k^2) edges are optimal for the kernel size. In this paper we consider
the Vertex Cover problem with a different parameter, the size fvs(G) of a
minimum feedback vertex set for G. This refined parameter is structurally
smaller than the parameter k associated to the vertex covering number vc(G)
since fvs(G) &lt;= vc(G) and the difference can be arbitrarily large. We give a
kernel for Vertex Cover with a number of vertices that is cubic in fvs(G): an
instance (G,X,k) of Vertex Cover, where X is a feedback vertex set for G, can
be transformed in polynomial time into an equivalent instance (G',X',k') such
that |V(G')| &lt;= 2k and |V(G')| &lt;= O(|X'|^3). A similar result holds when the
feedback vertex set X is not given along with the input. In sharp contrast we
show that the Weighted Vertex Cover problem does not have a polynomial kernel
when parameterized by the cardinality of a given vertex cover of the graph
unless NP is in coNP/poly and the polynomial hierarchy collapses to the third
level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4712</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4712</id><created>2010-12-21</created><authors><author><keyname>Wang</keyname><forenames>Wenguang</forenames><affiliation>College of Information Systems and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Wang</keyname><forenames>Weiping</forenames><affiliation>College of Information Systems and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Zhu</keyname><forenames>Yifan</forenames><affiliation>College of Information Systems and Management, National University of Defense Technology, Changsha, China</affiliation></author><author><keyname>Li</keyname><forenames>Qun</forenames><affiliation>College of Information Systems and Management, National University of Defense Technology, Changsha, China</affiliation></author></authors><title>Service-Oriented Simulation Framework: An Overview and Unifying
  Methodology</title><categories>cs.SE cs.DC</categories><comments>23 pages, 4 figures, 13 tables, SIMULATION: Transactions of the
  Society for Modeling and Simulation International. first published on
  December 21, 2010. DOI: 10.1177/0037549710391838.
  http://sim.sagepub.com/content/early/2010/12/18/0037549710391838.abstract</comments><journal-ref>SIMULATION: Transactions of the Society for Modeling and
  Simulation International. first published on December 21, 2010. DOI:
  10.1177/0037549710391838.
  http://sim.sagepub.com/content/early/2010/12/18/0037549710391838.abstract</journal-ref><doi>10.1177/0037549710391838</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prevailing net-centric environment demands and enables modeling and
simulation to combine efforts from numerous disciplines. Software techniques
and methodology, in particular service-oriented architecture, provide such an
opportunity. Service-oriented simulation has been an emerging paradigm
following on from object- and process-oriented methods. However, the ad-hoc
frameworks proposed so far generally focus on specific domains or systems and
each has its pros and cons. They are capable of addressing different issues
within service-oriented simulation from different viewpoints. It is
increasingly important to describe and evaluate the progress of numerous
frameworks. In this paper, we propose a novel three-dimensional reference model
for a service-oriented simulation paradigm. The model can be used as a
guideline or an analytic means to find the potential and possible future
directions of the current simulation frameworks. In particular, the model
inspects the crossover between the disciplines of modeling and simulation,
service-orientation, and software/systems engineering. Based on the model, we
present a comprehensive survey on several classical service-oriented simulation
frameworks, including formalism-based, model-driven, interoperability protocol
based, eXtensible Modeling and Simulation Framework (XMSF), and Open Grid
Services Architecture (OGSA) based frameworks etc. The comparison of these
frameworks is also performed. Finally the significance both in academia and
practice are presented and future directions are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4715</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4715</id><created>2010-12-21</created><updated>2011-05-14</updated><authors><author><keyname>Khina</keyname><forenames>Anatoly</forenames></author><author><keyname>Kochman</keyname><forenames>Yuval</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>Joint Unitary Triangularization for MIMO Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Tran. Signal Processing. Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers communication networks where individual links can be
described as MIMO channels. Unlike orthogonal modulation methods (such as the
singular-value decomposition), we allow interference between sub-channels,
which can be removed by the receivers via successive cancellation. The degrees
of freedom earned by this relaxation are used for obtaining a basis which is
simultaneously good for more than one link. Specifically, we derive necessary
and sufficient conditions for shaping the ratio vector of sub-channel gains of
two broadcast-channel receivers. We then apply this to two scenarios: First, in
digital multicasting we present a practical capacity-achieving scheme which
only uses scalar codes and linear processing. Then, we consider the joint
source-channel problem of transmitting a Gaussian source over a two-user MIMO
channel, where we show the existence of non-trivial cases, where the optimal
distortion pair (which for high signal-to-noise ratios equals the optimal
point-to-point distortions of the individual users) may be achieved by
employing a hybrid digital-analog scheme over the induced equivalent channel.
These scenarios demonstrate the advantage of choosing a modulation basis based
upon multiple links in the network, thus we coin the approach &quot;network
modulation&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4739</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4739</id><created>2010-12-21</created><updated>2011-01-11</updated><authors><author><keyname>K</keyname><forenames>Phani Nandan</forenames></author><author><keyname>K</keyname><forenames>Pavan Kumar</forenames></author></authors><title>Software Oriented Data Monitoring System</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This project &quot;Software Oriented Data Monitoring System&quot; deals with real time
monitoring of patients' parameters like body temperature, heart rate etc. The
parameters are checked at regular intervals and Short Messaging Service (SMS)
is sent to concerned doctor regarding the measured values. If the obtained
parameters are above or below critical values, an alert SMS is also sent to the
concerned doctor. This system is very much useful in hospitals, which saves the
valuable time of the doctor who otherwise will have to monitor the patients
throughout the day. Here the analog data from the sensors is first converted
into digital form and is fed to the parallel port of the computer. This data
obtained is converted into useful parameters, which is monitored and checked
for safe limits. Appropriate SMS is sent to the doctor depending on whether the
request is from an alert or routine signal. This is possible by interfacing a
mobile phone (Siemens c35i) to the serial port of the computer. The SMS is sent
from the computer using proper AT commands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4752</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4752</id><created>2010-12-21</created><authors><author><keyname>Ding</keyname><forenames>Ying</forenames><affiliation>School of Library and Information Science, Indiana University Bloomington, IN, USA</affiliation></author></authors><title>Semantic Web: Who is who in the field - A bibliometric analysis</title><categories>cs.DL cs.IR</categories><comments>22 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Semantic Web is one of the main efforts aiming to enhance human and
machine interaction by representing data in an understandable way for machines
to mediate data and services. It is a fast-moving and multidisciplinary field.
This study conducts a thorough bibliometric analysis of the field by collecting
data from Web of Science (WOS) and Scopus for the period of 1960-2009. It
utilizes a total of 44,157 papers with 651,673 citations from Scopus, and
22,951 papers with 571,911 citations from WOS. Based on these papers and
citations, it evaluates the research performance of the Semantic Web (SW) by
identifying the most productive players, major scholarly communication media,
highly cited authors, influential papers and emerging stars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4755</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4755</id><created>2010-12-21</created><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author></authors><title>Mutual information, matroids and extremal dependencies</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, it is shown that the rank function of a matroid can be
represented by a &quot;mutual information function&quot; if and only if the matroid is
binary. The mutual information function considered is the one measuring the
amount of information between the inputs (binary uniform) and the output of a
multiple access channel (MAC). Moreover, it is shown that a MAC whose mutual
information function is integer valued is &quot;equivalent&quot; to a linear
deterministic MAC, in the sense that it essentially contains at the output no
more information than some linear forms of the inputs. These notes put emphasis
on the connection between mutual information functionals and rank functions in
matroid theory, without assuming prior knowledge on these two subjects. The
first section introduces mutual information functionals, the second section
introduces basic notions of matroid theory, and the third section connects
these two subjects. It is also shown that entropic matroids studied in the
literature correspond to specific cases of MAC matroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4759</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4759</id><created>2010-12-21</created><authors><author><keyname>Chen</keyname><forenames>Bin</forenames><affiliation>School of Informatics and Computing, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Wild</keyname><forenames>David J</forenames><affiliation>School of Informatics and Computing, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Zhu</keyname><forenames>Qian</forenames><affiliation>School of Informatics and Computing, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Ding</keyname><forenames>Ying</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Dong</keyname><forenames>Xiao</forenames><affiliation>School of Informatics and Computing, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Sankaranarayanan</keyname><forenames>Madhuvanthi</forenames><affiliation>School of Informatics and Computing, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Wang</keyname><forenames>Huijun</forenames><affiliation>School of Informatics and Computing, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Sun</keyname><forenames>Yuyin</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, USA</affiliation></author></authors><title>Chem2Bio2RDF: A Linked Open Data Portal for Chemical Biology</title><categories>cs.IR q-bio.OT</categories><comments>8 pages, 10 figures</comments><acm-class>D.2.12</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Chem2Bio2RDF portal is a Linked Open Data (LOD) portal for systems
chemical biology aiming for facilitating drug discovery. It converts around 25
different datasets on genes, compounds, drugs, pathways, side effects,
diseases, and MEDLINE/PubMed documents into RDF triples and links them to other
LOD bubbles, such as Bio2RDF, LODD and DBPedia. The portal is based on D2R
server and provides a SPARQL endpoint, but adds on few unique features like RDF
faceted browser, user-friendly SPARQL query generator, MEDLINE/PubMed cross
validation service, and Cytoscape visualization plugin. Three use cases
demonstrate the functionality and usability of this portal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4763</identifier>
 <datestamp>2012-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4763</id><created>2010-12-21</created><updated>2012-03-15</updated><authors><author><keyname>Hardt</keyname><forenames>Moritz</forenames></author><author><keyname>Ligett</keyname><forenames>Katrina</forenames></author><author><keyname>McSherry</keyname><forenames>Frank</forenames></author></authors><title>A simple and practical algorithm for differentially private data release</title><categories>cs.DS</categories><comments>rewritten, with much more extensive experimental validation than the
  previous version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new theoretical results on differentially private data release
useful with respect to any target class of counting queries, coupled with
experimental results on a variety of real world data sets.
  Specifically, we study a simple combination of the multiplicative weights
approach of [Hardt and Rothblum, 2010] with the exponential mechanism of
[McSherry and Talwar, 2007]. The multiplicative weights framework allows us to
maintain and improve a distribution approximating a given data set with respect
to a set of counting queries. We use the exponential mechanism to select those
queries most incorrectly tracked by the current distribution. Combing the two,
we quickly approach a distribution that agrees with the data set on the given
set of queries up to small error.
  The resulting algorithm and its analysis is simple, but nevertheless improves
upon previous work in terms of both error and running time. We also empirically
demonstrate the practicality of our approach on several data sets commonly used
in the statistical community for contingency table release.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4767</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4767</id><created>2010-12-21</created><updated>2010-12-28</updated><authors><author><keyname>Nussbaum</keyname><forenames>Yahav</forenames></author></authors><title>Multiple-source multiple-sink maximum flow in planar graphs</title><categories>cs.DM cs.DS</categories><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show an O(n^(3/2) log^2 n) time algorithm for finding a
maximum flow in a planar graph with multiple sources and multiple sinks. This
is the fastest algorithm whose running time depends only on the number of
vertices in the graph. For general (non-planar) graphs the multiple-source
multiple-sink version of the maximum flow problem is as difficult as the
standard single-source single-sink version. However, the standard reduction
does not preserve the planarity of the graph, and it is not known how to
generalize existing maximum flow algorithms for planar graphs to the
multiple-source multiple-sink maximum flow problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4776</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4776</id><created>2010-12-21</created><authors><author><keyname>Saunier</keyname><forenames>Nicolas</forenames></author><author><keyname>Midenet</keyname><forenames>Sophie</forenames></author></authors><title>Automatic Estimation of the Exposure to Lateral Collision in Signalized
  Intersections using Video Sensors</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intersections constitute one of the most dangerous elements in road systems.
Traffic signals remain the most common way to control traffic at high-volume
intersections and offer many opportunities to apply intelligent transportation
systems to make traffic more efficient and safe. This paper describes an
automated method to estimate the temporal exposure of road users crossing the
conflict zone to lateral collision with road users originating from a different
approach. This component is part of a larger system relying on video sensors to
provide queue lengths and spatial occupancy that are used for real time traffic
control and monitoring. The method is evaluated on data collected during a real
world experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4795</identifier>
 <datestamp>2010-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4795</id><created>2010-12-21</created><authors><author><keyname>Bochardt</keyname><forenames>Ottmar</forenames></author><author><keyname>Uhlmann</keyname><forenames>Jeffrey</forenames></author></authors><title>On the Equivalence of the General Covariance Union (GCU) and Minimum
  Enclosing Ellipsoid (MEE) Problems</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe General Covariance Union (GCU) and show that
solutions to GCU and the Minimum Enclosing Ellipsoid (MEE) problems are
equivalent. This is a surprising result because GCU is defined over positive
semidefinite (PSD) matrices with statistical interpretations while MEE involves
PSD matrices with geometric interpretations. Their equivalence establishes an
intersection between the seemingly disparate methodologies of covariance-based
(e.g., Kalman) filtering and bounded region approaches to data fusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4814</identifier>
 <datestamp>2012-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4814</id><created>2010-12-21</created><updated>2012-03-24</updated><authors><author><keyname>Renes</keyname><forenames>Joseph M.</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>Noisy channel coding via privacy amplification and information
  reconciliation</title><categories>quant-ph cs.IT math.IT</categories><comments>8 pages, 2 figures. v2: final version for publication</comments><journal-ref>IEEE Transactions on Information Theory 57, 7377 (2011)</journal-ref><doi>10.1109/TIT.2011.2162226</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that optimal protocols for noisy channel coding of public or private
information over either classical or quantum channels can be directly
constructed from two more primitive information-theoretic tools: privacy
amplification and information reconciliation, also known as data compression
with side information. We do this in the one-shot scenario of structureless
resources, and formulate our results in terms of the smooth min- and
max-entropy. In the context of classical information theory, this shows that
essentially all two-terminal protocols can be reduced to these two primitives,
which are in turn governed by the smooth min- and max-entropies, respectively.
In the context of quantum information theory, the recently-established duality
of these two protocols means essentially all two-terminal protocols can be
constructed using just a single primitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4815</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4815</id><created>2010-12-21</created><authors><author><keyname>Agrawal</keyname><forenames>Pranav</forenames></author><author><keyname>kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author><author><keyname>Panda</keyname><forenames>Manoj K.</forenames></author></authors><title>Analytical Modeling of Saturation Throughput in Power Save Mode of an
  IEEE 802.11 Infrastructure WLAN</title><categories>cs.NI</categories><comments>9 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a single station (STA) in the Power Save Mode (PSM) of an IEEE
802.11 infrastructure WLAN. This STA is assumed to be carrying uplink and
downlink traffic via the access point (AP). We assume that the transmission
queues of the AP and the STA are saturated, i.e., the AP and the STA always
have at least one packet to send. For this scenario, it is observed that uplink
and downlink throughputs achieved are different. The reason behind the
difference is the long term attempt rates of the STA and the AP due to the PSM
protocol. In this paper we first obtain the the long term attempt rates of the
STA and the AP and using these, we obtain the saturation throughputs of the AP
and the STA. We provide a validation of analytical results using the NS-2
simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4824</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4824</id><created>2010-12-21</created><authors><author><keyname>Abr&#xe3;o</keyname><forenames>Taufik</forenames></author><author><keyname>Oliveira</keyname><forenames>Leonardo D.</forenames></author><author><keyname>Angelico</keyname><forenames>Bruno A.</forenames></author><author><keyname>Jeszensky</keyname><forenames>Paul Jean E.</forenames></author></authors><title>Input Parameters Optimization in Swarm DS-CDMA Multiuser Detectors</title><categories>cs.AI math.CO stat.CO</categories><comments>21 pages, 15 figures, 4 tables, full paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the uplink direct sequence code division multiple access
(DS-CDMA) multiuser detection problem (MuD) is studied into heuristic
perspective, named particle swarm optimization (PSO). Regarding different
system improvements for future technologies, such as high-order modulation and
diversity exploitation, a complete parameter optimization procedure for the PSO
applied to MuD problem is provided, which represents the major contribution of
this paper. Furthermore, the performance of the PSO-MuD is briefly analyzed via
Monte-Carlo simulations. Simulation results show that, after convergence, the
performance reached by the PSO-MuD is much better than the conventional
detector, and somewhat close to the single user bound (SuB). Rayleigh flat
channel is initially considered, but the results are further extend to
diversity (time and spatial) channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4845</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4845</id><created>2010-12-21</created><authors><author><keyname>Zhang</keyname><forenames>Xiaolei</forenames></author><author><keyname>Shen</keyname><forenames>Yi</forenames></author><author><keyname>Wang</keyname><forenames>Zhenhua</forenames></author></authors><title>Directed factor graph based fault diagnosis model construction for mode
  switching satellite power system</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Satellite power system is a complex, highly interconnected hybrid system that
exhibit nonlinear and mode switching behaviors. Directed factor graph is an
inference model for fault diagnosis using probabilistic reasoning techniques. A
novel approach for constructing the directed factor graph structure based on
hybrid bond graph model is proposed. The system components status and their
fault symptoms are treated as hypothesis and evidences respectively. The
cause-effect relations between hypothesis and evidences are identified and
concluded though qualitative equations and causal path analysis on hybrid bond
graph model. A power supply module of a satellite power system is provided as
case study to show the feasibility and validity of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4855</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4855</id><created>2010-12-21</created><authors><author><keyname>Raunich</keyname><forenames>Salvatore</forenames></author><author><keyname>Rahm</keyname><forenames>Erhard</forenames></author></authors><title>Target-driven merging of Taxonomies</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of ontologies and taxonomies in many domains increasingly
demands the integration of multiple such ontologies. The goal of ontology
integration is to merge two or more given ontologies in order to provide a
unified view on the input ontologies while maintaining all information coming
from them. We propose a new taxonomy merging algorithm that, given as input two
taxonomies and an equivalence matching between them, can generate an integrated
taxonomy in a fully automatic manner. The approach is target-driven, i.e. we
merge a source taxonomy into the target taxonomy and preserve the structure of
the target ontology as much as possible. We also discuss how to extend the
merge algorithm providing auxiliary information, like additional relationships
between source and target concepts, in order to semantically improve the final
result. The algorithm was implemented in a working prototype and evaluated
using synthetic and real-world scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4862</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4862</id><created>2010-12-21</created><authors><author><keyname>Yan</keyname><forenames>Erjia</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN</affiliation></author><author><keyname>Ding</keyname><forenames>Ying</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN</affiliation></author></authors><title>Applying centrality measures to impact analysis: A coauthorship network
  analysis</title><categories>cs.DL</categories><comments>17 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many studies on coauthorship networks focus on network topology and network
statistical mechanics. This article takes a different approach by studying
micro-level network properties, with the aim to apply centrality measures to
impact analysis. Using coauthorship data from 16 journals in the field of
library and information science (LIS) with a time span of twenty years
(1988-2007), we construct an evolving coauthorship network and calculate four
centrality measures (closeness, betweenness, degree and PageRank) for authors
in this network. We find out that the four centrality measures are
significantly correlated with citation counts. We also discuss the usability of
centrality measures in author ranking, and suggest that centrality measures can
be useful indicators for impact analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4870</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4870</id><created>2010-12-21</created><authors><author><keyname>Yan</keyname><forenames>Erjia</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, United States</affiliation></author><author><keyname>Ding</keyname><forenames>Ying</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, United States</affiliation></author></authors><title>Discovering author impact: A PageRank perspective</title><categories>cs.DL</categories><comments>17 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article provides an alternative perspective for measuring author impact
by applying PageRank algorithm to a coauthorship network. A weighted PageRank
algorithm considering citation and coauthorship network topology is proposed.
We test this algorithm under different damping factors by evaluating author
impact in the informetrics research community. In addition, we also compare
this weighted PageRank with the h-index, citation, and program committee (PC)
membership of the International Society for Scientometrics and Informetrics
(ISSI) conferences. Findings show that this weighted PageRank algorithm
provides reliable results in measuring author impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4871</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4871</id><created>2010-12-21</created><authors><author><keyname>Ding</keyname><forenames>Ying</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Cronin</keyname><forenames>Blaise</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, USA</affiliation></author></authors><title>Popular and/or Prestigious? Measures of Scholarly Esteem</title><categories>cs.DL</categories><comments>26 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Citation analysis does not generally take the quality of citations into
account: all citations are weighted equally irrespective of source. However, a
scholar may be highly cited but not highly regarded: popularity and prestige
are not identical measures of esteem. In this study we define popularity as the
number of times an author is cited and prestige as the number of times an
author is cited by highly cited papers. Information Retrieval (IR) is the test
field. We compare the 40 leading researchers in terms of their popularity and
prestige over time. Some authors are ranked high on prestige but not on
popularity, while others are ranked high on popularity but not on prestige. We
also relate measures of popularity and prestige to date of Ph.D. award, number
of key publications, organizational affiliation, receipt of prizes/honors, and
gender.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4872</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4872</id><created>2010-12-21</created><authors><author><keyname>Ding</keyname><forenames>Ying</forenames></author><author><keyname>Yan</keyname><forenames>Erjia</forenames></author><author><keyname>Frazho</keyname><forenames>Arthur</forenames></author><author><keyname>Caverlee</keyname><forenames>James</forenames></author></authors><title>PageRank for ranking authors in co-citation networks</title><categories>cs.DL</categories><comments>19 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Google's PageRank has created a new synergy to information retrieval for a
better ranking of Web pages. It ranks documents depending on the topology of
the graphs and the weights of the nodes. PageRank has significantly advanced
the field of information retrieval and keeps Google ahead of competitors in the
search engine market. It has been deployed in bibliometrics to evaluate
research impact, yet few of these studies focus on the important impact of the
damping factor (d) for ranking purposes. This paper studies how varied damping
factors in the PageRank algorithm can provide additional insight into the
ranking of authors in an author co-citation network. Furthermore, we propose
weighted PageRank algorithms. We select 108 most highly cited authors in the
information retrieval (IR) area from the 1970s to 2008 to form the author
co-citation network. We calculate the ranks of these 108 authors based on
PageRank with damping factor ranging from 0.05 to 0.95. In order to test the
relationship between these different measures, we compare PageRank and weighted
PageRank results with the citation ranking, h-index, and centrality measures.
We found that in our author co-citation network, citation rank is highly
correlated with PageRank's with different damping factors and also with
different PageRank algorithms; citation rank and PageRank are not significantly
correlated with centrality measures; and h-index is not significantly
correlated with centrality measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4874</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4874</id><created>2010-12-21</created><authors><author><keyname>Zhang</keyname><forenames>Xiaoxin</forenames></author><author><keyname>Chen</keyname><forenames>Liang</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Zhao</keyname><forenames>Yuping</forenames></author></authors><title>Distributed and Optimal Reduced Primal-Dual Algorithm for Uplink OFDM
  Resource Allocation</title><categories>cs.NI cs.CC cs.DC</categories><comments>12 pages, 22 figures, and 5 tables</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Orthogonal Frequency Division Multiplexing (OFDM) is the key component of
many emerging broadband wireless access standards. The resource allocation in
OFDM uplink, however, is challenging due to heterogeneity of users' Quality of
Service requirements, channel conditions, and individual resource constraints.
We formulate the resource allocation problem as a non-strictly convex
optimization problem, which typically has multiple global optimal solutions. We
then propose a reduced primal-dual algorithm, which is distributed, low in
computational complexity, and probably globally convergent to a global optimal
solution. The performance of the algorithm is studied through a realistic OFDM
simulator. Compared with the previously proposed centralized optimal algorithm,
our algorithm not only significantly reduces the message overhead but also
requires less iterations to converge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4875</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4875</id><created>2010-12-21</created><authors><author><keyname>Ding</keyname><forenames>Ying</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Jacob</keyname><forenames>Elin K.</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Fried</keyname><forenames>Michael</forenames><affiliation>Institute of Computer Science, University of Innsbruck, Innsbruck, Austria</affiliation></author><author><keyname>Toma</keyname><forenames>Ioan</forenames><affiliation>Institute of Computer Science, University of Innsbruck, Innsbruck, Austria</affiliation></author><author><keyname>Yan</keyname><forenames>Erjia</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, IN, USA</affiliation></author><author><keyname>Foo</keyname><forenames>Schubert</forenames><affiliation>Division of Information Studies, Nanyang Technological University, Singapore</affiliation></author></authors><title>Upper Tag Ontology (UTO) For Integrating Social Tagging Data</title><categories>cs.IR cs.SI</categories><comments>31 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data integration and mediation have become central concerns of information
technology over the past few decades. With the advent of the Web and the rapid
increases in the amount of data and the number of Web documents and users,
researchers have focused on enhancing the interoperability of data through the
development of metadata schemes. Other researchers have looked to the wealth of
metadata generated by bookmarking sites on the Social Web. While several
existing ontologies capitalize on the semantics of metadata created by tagging
activities, the Upper Tag Ontology (UTO) emphasizes the structure of tagging
activities to facilitate modeling of tagging data and the integration of data
from different bookmarking sites as well as the alignment of tagging
ontologies. UTO is described and its utility in harvesting, modeling,
integrating, searching and analyzing data is demonstrated with metadata
harvested from three major social tagging systems (Delicious, Flickr and
YouTube).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4876</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4876</id><created>2010-12-21</created><authors><author><keyname>Yan</keyname><forenames>Erjia</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, USA</affiliation></author><author><keyname>Ding</keyname><forenames>Ying</forenames><affiliation>School of Library and Information Science, Indiana University, Bloomington, USA</affiliation></author></authors><title>Weighted citation: An indicator of an article's prestige</title><categories>cs.DL</categories><comments>17 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose using the technique of weighted citation to measure an article's
prestige. The technique allocates a different weight to each reference by
taking into account the impact of citing journals and citation time intervals.
Weighted citation captures prestige, whereas citation counts capture
popularity. We compare the value variances for popularity and prestige for
articles published in the Journal of the American Society for Information
Science and Technology from 1998 to 2007, and find that the majority have
comparable status.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4881</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4881</id><created>2010-12-22</created><authors><author><keyname>Sarioz</keyname><forenames>Deniz</forenames></author></authors><title>Generalized Delaunay Graphs with respect to any Convex Set are Plane
  Graphs</title><categories>cs.CG cs.DM math.CO</categories><comments>3 pages, 0 figures. Keywords: geometric graphs, Delaunay graphs,
  scaled translates, convex sets, planarity</comments><msc-class>68R10, 05C10, 52A10, 05C62, 65D18</msc-class><acm-class>F.2.2; G.2.2; I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two types of geometric graphs on point sets on the plane based on
a plane set C: one obtained by translates of C, another by positively scaled
translates (homothets) of C. For compact and convex C, graphs defined by scaled
translates of C, i.e., Delaunay graphs based on C, are known to be plane
graphs. We show that as long as C is convex, both types of graphs are plane
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4889</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4889</id><created>2010-12-22</created><authors><author><keyname>Jowhari</keyname><forenames>Hossein</forenames></author><author><keyname>Sa&#x11f;lam</keyname><forenames>Mert</forenames></author><author><keyname>Tardos</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Tight Bounds for Lp Samplers, Finding Duplicates in Streams, and Related
  Problems</title><categories>cs.DS cs.CC cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present near-optimal space bounds for Lp-samplers. Given a
stream of updates (additions and subtraction) to the coordinates of an
underlying vector x \in R^n, a perfect Lp sampler outputs the i-th coordinate
with probability |x_i|^p/||x||_p^p. In SODA 2010, Monemizadeh and Woodruff
showed polylog space upper bounds for approximate Lp-samplers and demonstrated
various applications of them. Very recently, Andoni, Krauthgamer and Onak
improved the upper bounds and gave a O(\epsilon^{-p} log^3 n) space \epsilon
relative error and constant failure rate Lp-sampler for p \in [1,2]. In this
work, we give another such algorithm requiring only O(\epsilon^{-p} log^2 n)
space for p \in (1,2). For p \in (0,1), our space bound is O(\epsilon^{-1}
log^2 n), while for the $p=1$ case we have an O(log(1/\epsilon)\epsilon^{-1}
log^2 n) space algorithm. We also give a O(log^2 n) bits zero relative error
L0-sampler, improving the O(log^3 n) bits algorithm due to Frahling, Indyk and
Sohler.
  As an application of our samplers, we give better upper bounds for the
problem of finding duplicates in data streams. In case the length of the stream
is longer than the alphabet size, L1 sampling gives us an O(log^2 n) space
algorithm, thus improving the previous O(log^3 n) bound due to Gopalan and
Radhakrishnan.
  In the second part of our work, we prove an Omega(log^2 n) lower bound for
sampling from 0, \pm 1 vectors (in this special case, the parameter p is not
relevant for Lp sampling). This matches the space of our sampling algorithms
for constant \epsilon &gt; 0. We also prove tight space lower bounds for the
finding duplicates and heavy hitters problems. We obtain these lower bounds
using reductions from the communication complexity problem augmented indexing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4890</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4890</id><created>2010-12-22</created><authors><author><keyname>Urban</keyname><forenames>Christian</forenames><affiliation>TU Munich, Germany</affiliation></author></authors><title>Nominal Unification Revisited</title><categories>cs.LO cs.PL</categories><comments>In Proceedings UNIF 2010, arXiv:1012.4554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 42, 2010, pp. 1-11</journal-ref><doi>10.4204/EPTCS.42.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nominal unification calculates substitutions that make terms involving
binders equal modulo alpha-equivalence. Although nominal unification can be
seen as equivalent to Miller's higher-order pattern unification, it has
properties, such as the use of first-order terms with names (as opposed to
alpha-equivalence classes) and that no new names need to be generated during
unification, which set it clearly apart from higher-order pattern unification.
The purpose of this paper is to simplify a clunky proof from the original paper
on nominal unification and to give an overview over some results about nominal
unification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4891</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4891</id><created>2010-12-22</created><authors><author><keyname>Kapur</keyname><forenames>Deepak</forenames><affiliation>University of New Mexico</affiliation></author><author><keyname>Marshall</keyname><forenames>Andrew</forenames><affiliation>University at Albany-SUNY</affiliation></author><author><keyname>Narendran</keyname><forenames>Paliath</forenames><affiliation>University at Albany-SUNY</affiliation></author></authors><title>Unification modulo a partial theory of exponentiation</title><categories>cs.SC cs.LO</categories><comments>In Proceedings UNIF 2010, arXiv:1012.4554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 42, 2010, pp. 12-23</journal-ref><doi>10.4204/EPTCS.42.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modular exponentiation is a common mathematical operation in modern
cryptography. This, along with modular multiplication at the base and exponent
levels (to different moduli) plays an important role in a large number of key
agreement protocols. In our earlier work, we gave many decidability as well as
undecidability results for multiple equational theories, involving various
properties of modular exponentiation. Here, we consider a partial subtheory
focussing only on exponentiation and multiplication operators. Two main results
are proved. The first result is positive, namely, that the unification problem
for the above theory (in which no additional property is assumed of the
multiplication operators) is decidable. The second result is negative: if we
assume that the two multiplication operators belong to two different abelian
groups, then the unification problem becomes undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4892</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4892</id><created>2010-12-22</created><authors><author><keyname>Kothari</keyname><forenames>Sunil</forenames><affiliation>University of Wyoming</affiliation></author><author><keyname>Caldwell</keyname><forenames>James</forenames><affiliation>University of Wyoming</affiliation></author></authors><title>A Machine Checked Model of Idempotent MGU Axioms For Lists of Equational
  Constraints</title><categories>cs.LO</categories><comments>In Proceedings UNIF 2010, arXiv:1012.4554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 42, 2010, pp. 24-38</journal-ref><doi>10.4204/EPTCS.42.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present formalized proofs verifying that the first-order unification
algorithm defined over lists of satisfiable constraints generates a most
general unifier (MGU), which also happens to be idempotent. All of our proofs
have been formalized in the Coq theorem prover. Our proofs show that finite
maps produced by the unification algorithm provide a model of the axioms
characterizing idempotent MGUs of lists of constraints. The axioms that serve
as the basis for our verification are derived from a standard set by extending
them to lists of constraints. For us, constraints are equalities between terms
in the language of simple types. Substitutions are formally modeled as finite
maps using the Coq library Coq.FSets.FMapInterface. Coq's method of functional
induction is the main proof technique used in proving many of the axioms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4893</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4893</id><created>2010-12-22</created><authors><author><keyname>Rau</keyname><forenames>Conrad</forenames></author><author><keyname>Schmidt-Schau&#xdf;</keyname><forenames>Manfred</forenames></author></authors><title>Towards Correctness of Program Transformations Through Unification and
  Critical Pair Computation</title><categories>cs.PL</categories><comments>In Proceedings UNIF 2010, arXiv:1012.4554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 42, 2010, pp. 39-53</journal-ref><doi>10.4204/EPTCS.42.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correctness of program transformations in extended lambda calculi with a
contextual semantics is usually based on reasoning about the operational
semantics which is a rewrite semantics. A successful approach to proving
correctness is the combination of a context lemma with the computation of
overlaps between program transformations and the reduction rules, and then of
so-called complete sets of diagrams. The method is similar to the computation
of critical pairs for the completion of term rewriting systems. We explore
cases where the computation of these overlaps can be done in a first order way
by variants of critical pair computation that use unification algorithms. As a
case study we apply the method to a lambda calculus with recursive
let-expressions and describe an effective unification algorithm to determine
all overlaps of a set of transformations with all reduction rules. The
unification algorithm employs many-sorted terms, the equational theory of
left-commutativity modelling multi-sets, context variables of different kinds
and a mechanism for compactly representing binding chains in recursive
let-expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4894</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4894</id><created>2010-12-22</created><authors><author><keyname>Narendran</keyname><forenames>Paliath</forenames><affiliation>University at Albany-SUNY</affiliation></author><author><keyname>Marshall</keyname><forenames>Andrew</forenames><affiliation>University at Albany-SUNY</affiliation></author><author><keyname>Mahapatra</keyname><forenames>Bibhu</forenames><affiliation>University at Albany-SUNY</affiliation></author></authors><title>On the Complexity of the Tiden-Arnborg Algorithm for Unification modulo
  One-Sided Distributivity</title><categories>cs.SC cs.LO</categories><comments>In Proceedings UNIF 2010, arXiv:1012.4554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 42, 2010, pp. 54-63</journal-ref><doi>10.4204/EPTCS.42.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the Tiden and Arnborg algorithm for equational unification
modulo one-sided distributivity is not polynomial time bounded as previously
thought. A set of counterexamples is developed that demonstrates that the
algorithm goes through exponentially many steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4895</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4895</id><created>2010-12-22</created><authors><author><keyname>Krauss</keyname><forenames>Alexander</forenames><affiliation>Technische Universit&#xe4;t M&#xfc;nchen</affiliation></author></authors><title>Recursive Definitions of Monadic Functions</title><categories>cs.LO</categories><comments>In Proceedings PAR 2010, arXiv:1012.4555</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 43, 2010, pp. 1-13</journal-ref><doi>10.4204/EPTCS.43.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using standard domain-theoretic fixed-points, we present an approach for
defining recursive functions that are formulated in monadic style. The method
works both in the simple option monad and the state-exception monad of
Isabelle/HOL's imperative programming extension, which results in a convenient
definition principle for imperative programs, which were previously hard to
define.
  For such monadic functions, the recursion equation can always be derived
without preconditions, even if the function is partial. The construction is
easy to automate, and convenient induction principles can be derived
automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4896</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4896</id><created>2010-12-22</created><authors><author><keyname>Abel</keyname><forenames>Andreas</forenames><affiliation>Ludwig-Maximilians-University Munich</affiliation></author></authors><title>MiniAgda: Integrating Sized and Dependent Types</title><categories>cs.PL cs.LO</categories><comments>In Proceedings PAR 2010, arXiv:1012.4555</comments><proxy>EPTCS</proxy><acm-class>F.4.1</acm-class><journal-ref>EPTCS 43, 2010, pp. 14-28</journal-ref><doi>10.4204/EPTCS.43.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sized types are a modular and theoretically well-understood tool for checking
termination of recursive and productivity of corecursive definitions. The
essential idea is to track structural descent and guardedness in the type
system to make termination checking robust and suitable for strong abstractions
like higher-order functions and polymorphism. To study the application of sized
types to proof assistants and programming languages based on dependent type
theory, we have implemented a core language, MiniAgda, with explicit handling
of sizes. New considerations were necessary to soundly integrate sized types
with dependencies and pattern matching, which was made possible by concepts
such as inaccessible patterns and parametric function spaces. This paper
provides an introduction to MiniAgda by example and informal explanations of
the underlying principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4897</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4897</id><created>2010-12-22</created><authors><author><keyname>Maamria</keyname><forenames>Issam</forenames><affiliation>University of Southampton</affiliation></author><author><keyname>Butler</keyname><forenames>Michael</forenames><affiliation>University of Southampton</affiliation></author></authors><title>Rewriting and Well-Definedness within a Proof System</title><categories>cs.LO</categories><comments>In Proceedings PAR 2010, arXiv:1012.4555</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 43, 2010, pp. 49-64</journal-ref><doi>10.4204/EPTCS.43.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Term rewriting has a significant presence in various areas, not least in
automated theorem proving where it is used as a proof technique. Many theorem
provers employ specialised proof tactics for rewriting. This results in an
interleaving between deduction and computation (i.e., rewriting) steps. If the
logic of reasoning supports partial functions, it is necessary that rewriting
copes with potentially ill-defined terms. In this paper, we provide a basis for
integrating rewriting with a deductive proof system that deals with
well-definedness. The definitions and theorems presented in this paper are the
theoretical foundations for an extensible rewriting-based prover that has been
implemented for the set theoretical formalism Event-B.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4898</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4898</id><created>2010-12-22</created><authors><author><keyname>Danielsson</keyname><forenames>Nils Anders</forenames><affiliation>University of Nottingham</affiliation></author></authors><title>Beating the Productivity Checker Using Embedded Languages</title><categories>cs.LO cs.PL</categories><comments>In Proceedings PAR 2010, arXiv:1012.4555</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 43, 2010, pp. 29-48</journal-ref><doi>10.4204/EPTCS.43.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some total languages, like Agda and Coq, allow the use of guarded corecursion
to construct infinite values and proofs. Guarded corecursion is a form of
recursion in which arbitrary recursive calls are allowed, as long as they are
guarded by a coinductive constructor. Guardedness ensures that programs are
productive, i.e. that every finite prefix of an infinite value can be computed
in finite time. However, many productive programs are not guarded, and it can
be nontrivial to put them in guarded form.
  This paper gives a method for turning a productive program into a guarded
program. The method amounts to defining a problem-specific language as a data
type, writing the program in the problem-specific language, and writing a
guarded interpreter for this language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4899</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4899</id><created>2010-12-22</created><authors><author><keyname>Coen</keyname><forenames>Claudio Sacerdoti</forenames><affiliation>Dipartimento di Scienze dell'Informazione, Universit&#xe0; di Bologna</affiliation></author><author><keyname>Valentini</keyname><forenames>Silvio</forenames><affiliation>Dipartimento di Matematica Pura e Applicata, Universit&#xe0; di Padova</affiliation></author></authors><title>General Recursion and Formal Topology</title><categories>cs.LO</categories><comments>In Proceedings PAR 2010, arXiv:1012.4555</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 43, 2010, pp. 65-75</journal-ref><doi>10.4204/EPTCS.43.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that general recursion cannot be expressed within
Martin-Loef's type theory and various approaches have been proposed to overcome
this problem still maintaining the termination of the computation of the
typable terms. In this work we propose a new approach to this problem based on
the use of inductively generated formal topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4900</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4900</id><created>2010-12-22</created><authors><author><keyname>Stump</keyname><forenames>Aaron</forenames><affiliation>The University of Iowa</affiliation></author><author><keyname>Sj&#xf6;berg</keyname><forenames>Vilhelm</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Weirich</keyname><forenames>Stephanie</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Termination Casts: A Flexible Approach to Termination with General
  Recursion</title><categories>cs.PL</categories><comments>In Proceedings PAR 2010, arXiv:1012.4555</comments><proxy>EPTCS</proxy><acm-class>D.3.1</acm-class><journal-ref>EPTCS 43, 2010, pp. 76-93</journal-ref><doi>10.4204/EPTCS.43.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a type-and-effect system called Teqt, which distinguishes
terminating terms and total functions from possibly diverging terms and partial
functions, for a lambda calculus with general recursion and equality types. The
central idea is to include a primitive type-form &quot;Terminates t&quot;, expressing
that term t is terminating; and then allow terms t to be coerced from possibly
diverging to total, using a proof of Terminates t. We call such coercions
termination casts, and show how to implement terminating recursion using them.
For the meta-theory of the system, we describe a translation from Teqt to a
logical theory of termination for general recursive, simply typed functions.
Every typing judgment of Teqt is translated to a theorem expressing the
appropriate termination property of the computational part of the Teqt term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4905</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4905</id><created>2010-12-22</created><authors><author><keyname>Curto</keyname><forenames>J. I. Iglesias</forenames></author><author><keyname>Porras</keyname><forenames>J. M. Mu&#xf1;oz</forenames></author><author><keyname>Mart&#xed;n</keyname><forenames>F. J. Plaza</forenames></author><author><keyname>Sotelo</keyname><forenames>G Serrano</forenames></author></authors><title>Convolutional Goppa codes defined on fibrations</title><categories>cs.IT math.IT</categories><comments>10 pages</comments><msc-class>14G50, 94B10, 11T71, 94B27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a new class of Convolutional Codes in terms of fibrations of
algebraic varieties generalizaing our previous constructions of Convolutional
Goppa Codes. Using this general construction we can give several examples of
Maximum Distance Separable (MDS) Convolutional Codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4909</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4909</id><created>2010-12-22</created><authors><author><keyname>Kesting</keyname><forenames>Arne</forenames></author><author><keyname>Treiber</keyname><forenames>Martin</forenames></author><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author></authors><title>Connectivity statistics of store-and-forward inter-vehicle communication</title><categories>cs.NI nlin.AO physics.soc-ph</categories><journal-ref>IEEE Transactions on Intelligent Transportation Systems 11(1),
  172-181 (2010)</journal-ref><doi>10.1109/TITS.2009.2037924</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inter-vehicle communication (IVC) enables vehicles to exchange messages
within a limited broadcast range and thus self-organize into dynamical
vehicular ad hoc networks. For the foreseeable future, however, a direct
connectivity between equipped vehicles in one direction is rarely possible. We
therefore investigate an alternative mode in which messages are stored by relay
vehicles traveling in the opposite direction, and forwarded to vehicles in the
original direction at a later time. The wireless communication consists of two
`transversal' message hops across driving directions. Since direct connectivity
for transversal hops and a successful message transmission to vehicles in the
destination region is only a matter of time, the quality of this IVC strategy
can be described in terms of the distribution function for the total
transmission time. Assuming a Poissonian distance distribution between equipped
vehicles, we derive analytical probability distributions for message
transmission times and related propagation speeds for a deterministic and a
stochastic model of the maximum range of direct communication. By means of
integrated microscopic simulations of communication and bi-directional traffic
flows, we validated the theoretical expectation for multi-lane roadways. We
found little deviation of the analytical result for multi-lane scenarios, but
significant deviations for a single-lane. This can be explained by vehicle
platooning. We demonstrate the efficiency of the transverse hopping mechanism
for a congestion-warning application in a microscopic traffic simulation
scenario. Messages are created on an event-driven basis by equipped vehicles
entering and leaving a traffic jam. This application is operative for
penetration levels as low as 1%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4924</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4924</id><created>2010-12-22</created><authors><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author></authors><title>Information-Theoretic Capacity and Error Exponents of Stationary Point
  Processes under Random Additive Displacements</title><categories>cs.IT math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the Shannon regime for the random displacement of
stationary point processes. Let each point of some initial stationary point
process in $\R^n$ give rise to one daughter point, the location of which is
obtained by adding a random vector to the coordinates of the mother point, with
all displacement vectors independently and identically distributed for all
points. The decoding problem is then the following one: the whole mother point
process is known as well as the coordinates of some daughter point; the
displacements are only known through their law; can one find the mother of this
daughter point? The Shannon regime is that where the dimension $n$ tends to
infinity and where the logarithm of the intensity of the point process is
proportional to $n$. We show that this problem exhibits a sharp threshold: if
the sum of the proportionality factor and of the differential entropy rate of
the noise is positive, then the probability of finding the right mother point
tends to 0 with $n$ for all point processes and decoding strategies. If this
sum is negative, there exist mother point processes, for instance Poisson, and
decoding strategies, for instance maximum likelihood, for which the probability
of finding the right mother tends to 1 with $n$. We then use large deviations
theory to show that in the latter case, if the entropy spectrum of the noise
satisfies a large deviation principle, then the error probability goes
exponentially fast to 0 with an exponent that is given in closed form in terms
of the rate function of the noise entropy spectrum. This is done for two
classes of mother point processes: Poisson and Mat\'ern. The practical interest
to information theory comes from the explicit connection that we also establish
between this problem and the estimation of error exponents in Shannon's
additive noise channel with power constraints on the codewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4928</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4928</id><created>2010-12-22</created><updated>2011-10-11</updated><authors><author><keyname>Parhizkar</keyname><forenames>Reza</forenames></author><author><keyname>Karbasi</keyname><forenames>Amin</forenames></author><author><keyname>Oh</keyname><forenames>Sewoong</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Calibration Using Matrix Completion with Application to Ultrasound
  Tomography</title><categories>cs.LG cs.IT math.IT</categories><comments>submitted to IEEE Transaction on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the calibration process in circular ultrasound tomography devices
where the sensor positions deviate from the circumference of a perfect circle.
This problem arises in a variety of applications in signal processing ranging
from breast imaging to sensor network localization. We introduce a novel method
of calibration/localization based on the time-of-flight (ToF) measurements
between sensors when the enclosed medium is homogeneous. In the presence of all
the pairwise ToFs, one can easily estimate the sensor positions using
multi-dimensional scaling (MDS) method. In practice however, due to the
transitional behaviour of the sensors and the beam form of the transducers, the
ToF measurements for close-by sensors are unavailable. Further, random
malfunctioning of the sensors leads to random missing ToF measurements. On top
of the missing entries, in practice an unknown time delay is also added to the
measurements. In this work, we incorporate the fact that a matrix defined from
all the ToF measurements is of rank at most four. In order to estimate the
missing ToFs, we apply a state-of-the-art low-rank matrix completion algorithm,
OPTSPACE . To find the correct positions of the sensors (our ultimate goal) we
then apply MDS. We show analytic bounds on the overall error of the whole
process in the presence of noise and hence deduce its robustness. Finally, we
confirm the functionality of our method in practice by simulations mimicking
the measurements of a circular ultrasound tomography device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4938</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4938</id><created>2010-12-22</created><authors><author><keyname>Georgiadis</keyname><forenames>Loukas</forenames></author><author><keyname>Nikolopoulos</keyname><forenames>Stavros D.</forenames></author><author><keyname>Palios</keyname><forenames>Leonidas</forenames></author></authors><title>Join-Reachability Problems in Directed Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a given collection G of directed graphs we define the join-reachability
graph of G, denoted by J(G), as the directed graph that, for any pair of
vertices a and b, contains a path from a to b if and only if such a path exists
in all graphs of G. Our goal is to compute an efficient representation of J(G).
In particular, we consider two versions of this problem. In the explicit
version we wish to construct the smallest join-reachability graph for G. In the
implicit version we wish to build an efficient data structure (in terms of
space and query time) such that we can report fast the set of vertices that
reach a query vertex in all graphs of G. This problem is related to the
well-studied reachability problem and is motivated by emerging applications of
graph-structured databases and graph algorithms. We consider the construction
of join-reachability structures for two graphs and develop techniques that can
be applied to both the explicit and the implicit problem. First we present
optimal and near-optimal structures for paths and trees. Then, based on these
results, we provide efficient structures for planar graphs and general directed
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4945</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4945</id><created>2010-12-22</created><authors><author><keyname>Alexandrovna</keyname><forenames>Kochetkova Nina</forenames></author></authors><title>Experience in applying remote technology in the secondary education
  institutions in Russia, located in rural areas (From the experience of
  Podolsky municipal district schools)</title><categories>cs.CY</categories><comments>Published in the proceedings of the XXI International Conference &quot;New
  Computer Technology in Educating&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article examines the experience of distance education technologies in
Podolsky municipal district, Moscow region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4962</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4962</id><created>2010-12-22</created><updated>2011-02-24</updated><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author></authors><title>Robust and MaxMin Optimization under Matroid and Knapsack Uncertainty
  Sets</title><categories>cs.DS</categories><comments>17 pages. Preliminary version combining this paper and
  http://arxiv.org/abs/0912.1045 appeared in ICALP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following problem: given a set system (U,I) and an edge-weighted
graph G = (U, E) on the same universe U, find the set A in I such that the
Steiner tree cost with terminals A is as large as possible: &quot;which set in I is
the most difficult to connect up?&quot; This is an example of a max-min problem:
find the set A in I such that the value of some minimization (covering) problem
is as large as possible.
  In this paper, we show that for certain covering problems which admit good
deterministic online algorithms, we can give good algorithms for max-min
optimization when the set system I is given by a p-system or q-knapsacks or
both. This result is similar to results for constrained maximization of
submodular functions. Although many natural covering problems are not even
approximately submodular, we show that one can use properties of the online
algorithm as a surrogate for submodularity.
  Moreover, we give stronger connections between max-min optimization and
two-stage robust optimization, and hence give improved algorithms for robust
versions of various covering problems, for cases where the uncertainty sets are
given by p-systems and q-knapsacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.4981</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.4981</id><created>2010-12-22</created><authors><author><keyname>Karandashev</keyname><forenames>Yakov</forenames></author><author><keyname>Kryzhanovsky</keyname><forenames>Boris</forenames></author><author><keyname>Litinskii</keyname><forenames>Leonid</forenames></author></authors><title>Local Minima of a Quadratic Binary Functional with a Quasi-Hebbian
  Connection Matrix</title><categories>cond-mat.dis-nn cs.NE</categories><comments>13 pages, 7 figures. Slightly extended version of the reports
  presented to IJCNN-2010 and ICANN-2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The local minima of a quadratic functional depending on binary variables are
discussed. An arbitrary connection matrix can be presented in the form of
quasi-Hebbian expansion where each pattern is supplied with its own individual
weight. For such matrices statistical physics methods allow one to derive an
equation describing local minima of the functional. A model where only one
weight differs from other ones is discussed in detail. In this case the
equation can be solved analytically. The critical values of the weight, for
which the energy landscape is reconstructed, are obtained. Obtained results are
confirmed by computer simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5024</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5024</id><created>2010-12-22</created><authors><author><keyname>Fekete</keyname><forenames>Sandor</forenames></author><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Stelzer</keyname><forenames>Michael</forenames></author></authors><title>Shortest Paths with Pairwise-Distinct Edge Labels: Finding Biochemical
  Pathways in Metabolic Networks</title><categories>cs.DS</categories><comments>9 pages, 5 figures</comments><acm-class>F.2.2; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A problem studied in Systems Biology is how to find shortest paths in
metabolic networks. Unfortunately, simple (i.e., graph theoretic) shortest
paths do not properly reflect biochemical facts. An approach to overcome this
issue is to use edge labels and search for paths with distinct labels.
  In this paper, we show that such biologically feasible shortest paths are
hard to compute. Moreover, we present solutions to find such paths in networks
in reasonable time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5030</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5030</id><created>2010-12-22</created><authors><author><keyname>Wimmer</keyname><forenames>Martin</forenames></author><author><keyname>Tr&#xe4;ff</keyname><forenames>Jesper Larsson</forenames></author></authors><title>Work-stealing for mixed-mode parallelism by deterministic team-building</title><categories>cs.DC</categories><report-no>TR-10-5</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to extend classical work-stealing to deal also with data parallel
tasks that can require any number of threads r &gt;= 1 for their execution. We
explain in detail the so introduced idea of work-stealing with deterministic
team-building which in a natural way generalizes classical work-stealing. A
prototype C++ implementation of the generalized work-stealing algorithm has
been given and is briefly described. Building on this, a serious, well-known
contender for a best parallel Quicksort algorithm has been implemented, which
naturally relies on both task and data parallelism. For instance, sorting
2^27-1 randomly generated integers we could improve the speed-up from 5.1 to
8.7 on a 32-core Intel Nehalem EX system, being consistently better than the
tuned, task-parallel Cilk++ system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5041</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5041</id><created>2010-12-22</created><authors><author><keyname>S&#xe1;nchez-Moreno</keyname><forenames>P.</forenames></author><author><keyname>Zarzo</keyname><forenames>A.</forenames></author><author><keyname>Dehesa</keyname><forenames>J. S.</forenames></author></authors><title>Jensen divergence based on Fisher's information</title><categories>cs.IT math.IT physics.data-an</categories><comments>8 pages, 8 figures</comments><journal-ref>J. Phys. A: Math. Theor. 45 (2012) 125305</journal-ref><doi>10.1088/1751-8113/45/12/125305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The measure of Jensen-Fisher divergence between probability distributions is
introduced and its theoretical grounds set up. This quantity, in contrast to
the remaining Jensen divergences, is very sensitive to the fluctuations of the
probability distributions because it is controlled by the (local) Fisher
information, which is a gradient functional of the distribution. So, it is
appropriate and informative when studying the similarity of distributions,
mainly for those having oscillatory character. The new Jensen-Fisher divergence
shares with the Jensen-Shannon divergence the following properties:
non-negativity, additivity when applied to an arbitrary number of probability
densities, symmetry under exchange of these densities, vanishing if and only if
all the densities are equal, and definiteness even when these densities present
non-common zeros. Moreover, the Jensen-Fisher divergence is shown to be
expressed in terms of the relative Fisher information as the Jensen-Shannon
divergence does in terms of the Kullback-Leibler or relative Shannon entropy.
Finally the Jensen-Shannon and Jensen-Fisher divergences are compared for the
following three large, non-trivial and qualitatively different families of
probability distributions: the sinusoidal, generalized gamma-like and
Rakhmanov-Hermite distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5059</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5059</id><created>2010-12-22</created><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Ponse</keyname><forenames>Alban</forenames></author></authors><title>On Hoare-McCarthy algebras</title><categories>cs.LO math.LO</categories><comments>29 pages, 1 table</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss an algebraic approach to propositional logic with side effects. To
this end, we use Hoare's conditional [1985], which is a ternary connective
comparable to if-then-else. Starting from McCarthy's notion of sequential
evaluation [1963] we discuss a number of valuation congruences and we introduce
Hoare-McCarthy algebras as the structures that characterize these congruences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5071</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5071</id><created>2010-12-22</created><updated>2010-12-27</updated><authors><author><keyname>Naiss</keyname><forenames>Iddo</forenames></author><author><keyname>Permuter</keyname><forenames>Haim</forenames></author></authors><title>Extension of the Blahut-Arimoto algorithm for maximizing directed
  information</title><categories>cs.IT math.IT</categories><comments>28 pages, 13 figures, 34 references</comments><msc-class>68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the Blahut-Arimoto algorithm for maximizing Massey's directed
information. The algorithm can be used for estimating the capacity of channels
with delayed feedback, where the feedback is a deterministic function of the
output. In order to do so, we apply the ideas from the regular Blahut-Arimoto
algorithm, i.e., the alternating maximization procedure, onto our new problem.
We provide both upper and lower bound sequences that converge to the optimum
value. Our main insight in this paper is that in order to find the maximum of
the directed information over causal conditioning probability mass function
(PMF), one can use a backward index time maximization combined with the
alternating maximization procedure. We give a detailed description of the
algorithm, its complexity, the memory needed, and several numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5074</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5074</id><created>2010-12-22</created><authors><author><keyname>Sampaio</keyname><forenames>Lucas Dias H.</forenames></author><author><keyname>Lima</keyname><forenames>Mois&#xe9;s F.</forenames></author><author><keyname>Proen&#xe7;a</keyname><forenames>Mario Lemes</forenames><suffix>Jr</suffix></author><author><keyname>Abr&#xe3;o</keyname><forenames>Taufik</forenames></author></authors><title>Power-Rate Allocation in DS/CDMA Based on Discretized Verhulst
  Equilibrium</title><categories>cs.CE</categories><comments>14 pages, 7 figures, 2 tables, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes to extend the discrete Verhulst power equilibrium
approach, previously suggested in [1], to the power-rate optimal allocation
problem. Multirate users associated to different types of traffic are
aggregated to distinct user' classes, with the assurance of minimum rate
allocation per user and QoS. Herein, Verhulst power allocation algorithm was
adapted to the single-input-single-output DS/CDMA jointly power-rate control
problem. The analysis was carried out taking into account the convergence time,
quality of solution, in terms of the normalized squared error (NSE), when
compared with the analytical solution based on interference matrix inverse, and
computational complexity. Numerical results demonstrate the validity of the
proposed resource allocation methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5113</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5113</id><created>2010-12-22</created><authors><author><keyname>Sloth</keyname><forenames>Christoffer</forenames></author><author><keyname>Wisniewski</keyname><forenames>Rafael</forenames></author></authors><title>Timed Game Abstraction of Control Systems</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method for abstracting control systems by timed game
automata, and is aimed at obtaining automatic controller synthesis.
  The proposed abstraction is based on partitioning the state space of a
control system using positive and negative invariant sets, generated by
Lyapunov functions. This partitioning ensures that the vector field of the
control system is transversal to the facets of the cells, which induces some
desirable properties of the abstraction. To allow a rich class of control
systems to be abstracted, the update maps of the timed game automaton are
extended.
  Conditions on the partitioning of the state space and the control are set up
to obtain sound abstractions. Finally, an example is provided to demonstrate
the method applied to a control problem related to navigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5123</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5123</id><created>2010-12-22</created><authors><author><keyname>Swift</keyname><forenames>Terrance</forenames></author><author><keyname>Warren</keyname><forenames>David S.</forenames></author></authors><title>XSB: Extending Prolog with Tabled Logic Programming</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paradigm of Tabled Logic Programming (TLP) is now supported by a number
of Prolog systems, including XSB, YAP Prolog, B-Prolog, Mercury, ALS, and Ciao.
The reasons for this are partly theoretical: tabling ensures termination and
optimal known complexity for queries to a large class of programs. However the
overriding reasons are practical. TLP allows sophisticated programs to be
written concisely and efficiently, especially when mechanisms such as tabled
negation and call and answer subsumption are supported. As a result TLP has now
been used in a variety of applications from program analysis to querying over
the semantic web. This paper provides a survey of TLP and its applications as
implemented in XSB Prolog, along with discussion of how XSB supports tabling
with dynamically changing code, and in a multi-threaded environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5130</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5130</id><created>2010-12-22</created><authors><author><keyname>Kamiyama</keyname><forenames>Naoyuki</forenames></author></authors><title>A Relation between the Protocol Partition Number and the Quasi-Additive
  Bound</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we show that the linear programming for computing the
quasi-additive bound of the formula size of a Boolean function presented by
Ueno [MFCS'10] is equivalent to the dual problem of the linear programming
relaxation of an integer programming for computing the protocol partition
number. Together with the result of Ueno [MFCS'10], our results imply that
there exists no gap between our integer programming for computing the protocol
partition number and its linear programming relaxation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5141</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5141</id><created>2010-12-22</created><updated>2011-04-13</updated><authors><author><keyname>Zhang</keyname><forenames>Shengyu</forenames></author></authors><title>Quantum Strategic Game Theory</title><categories>quant-ph cs.CC cs.GT</categories><comments>38 pages. Presented in QIP 2011. v2: more on background, our model
  and related work; a conjecture added; discussion added for CE generation with
  untrusted local operations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple yet rich model to extend the notions of Nash equilibria
and correlated equilibria of strategic games to the quantum setting, in which
we then study the relations between classical and quantum equilibria. Unlike
the previous work that focus on qualitative questions on specific games of
small sizes, we address the following fundamental and quantitative question for
general games:
  How much &quot;advantage&quot; can playing quantum strategies provide, if any?
  Two measures of the advantage are studied, summarized as follows.
  1. A natural measure is the increase of payoff. We consider natural mappings
between classical and quantum states, and study how well those mappings
preserve the equilibrium properties. Among other results, we exhibit correlated
equilibrium $p$ whose quantum superposition counterpart $\sum_s
\sqrt{p(s)}\ket{s}$ is far from being a quantum correlated equilibrium;
actually a player can increase her payoff from almost 0 to almost 1 in a
[0,1]-normalized game. We achieve this by a tensor product construction on
carefully designed base cases.
  2. For studying the hardness of generating correlated equilibria, we propose
to examine \emph{correlation complexity}, a new complexity measure for
correlation generation. We show that there are $n$-bit correlated equilibria
which can be generated by only one EPR pair followed by local operation
(without communication), but need at least $\log(n)$ classical shared random
bits plus communication. The randomized lower bound can be improved to $n$, the
best possible, assuming (even a much weaker version of) a recent conjecture in
linear algebra. We believe that the correlation complexity, as a
complexity-theoretical counterpart of the celebrated Bell's inequality, has
independent interest in both physics and computational complexity theory and
deserves more explorations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5173</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5173</id><created>2010-12-23</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Zvesper</keyname><forenames>Jonathan A.</forenames></author></authors><title>Public Announcements in Strategic Games with Arbitrary Strategy Sets</title><categories>cs.GT</categories><comments>11 pages; presented at LOFT 2010 (9th Conference on Logic and the
  Foundations of Game and Decision Theory) University of Toulouse,France, 5-7
  July, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [Van Benthem 2007] the concept of a public announcement is used to study
the effect of the iterated elimination of strictly dominated strategies. We
offer a simple generalisation of this approach to cover arbitrary strategic
games and many optimality notions. We distinguish between announcements of
optimality and announcements of rationality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5174</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5174</id><created>2010-12-23</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Ansari</keyname><forenames>Nirwan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>SNEED: Enhancing Network Security Services Using Network Coding and
  Joint Capacity</title><categories>cs.NI cs.CR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional network security protocols depend mainly on developing
cryptographic schemes and on using biometric methods. These have led to several
network security protocols that are unbreakable based on difficulty of solving
untractable mathematical problems such as factoring large integers.
  In this paper, Security of Networks Employing Encoding and Decoding (SNEED)
is developed to mitigate single and multiple link attacks. Network coding and
shared capacity among the working paths are used to provide data protection and
data integrity against network attackers and eavesdroppers.
  SNEED can be incorporated into various applications in on-demand TV,
satellite communications and multimedia security. Finally, It is shown that
SNEED can be implemented easily where there are k edge disjoint paths between
two core nodes (routers or switches) in an enterprize network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5187</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5187</id><created>2010-12-23</created><updated>2012-02-11</updated><authors><author><keyname>Ghosh</keyname><forenames>Subir Kumar</forenames></author><author><keyname>Goswami</keyname><forenames>Partha Pratim</forenames></author></authors><title>Unsolved Problems in Visibility Graphs of Points, Segments and Polygons</title><categories>cs.CG cs.DM math.CO</categories><comments>The preliminary version of this paper appeared in the Proceedings of
  India-Taiwan Conference on Discrete Mathematics, Taipei, pp. 44-54, 2009</comments><msc-class>68R10</msc-class><acm-class>G.2.2; A.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this survey paper, we present open problems and conjectures on visibility
graphs of points, segments and polygons along with necessary backgrounds for
understanding them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5197</identifier>
 <datestamp>2013-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5197</id><created>2010-12-21</created><updated>2013-12-05</updated><authors><author><keyname>Huang</keyname><forenames>Xiujie</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Lin</keyname><forenames>Lei</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author></authors><title>Accessible Capacity of Secondary Users</title><categories>cs.IT math.IT</categories><comments>42 pages, 12 figures, 2 tables; Submitted to IEEE Transactions on
  Information Theory on December, 2010, Revised on November, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new problem formulation is presented for the Gaussian interference channels
(GIFC) with two pairs of users, which are distinguished as primary users and
secondary users, respectively. The primary users employ a pair of encoder and
decoder that were originally designed to satisfy a given error performance
requirement under the assumption that no interference exists from other users.
In the scenario when the secondary users attempt to access the same medium, we
are interested in the maximum transmission rate (defined as {\em accessible
capacity}) at which secondary users can communicate reliably without affecting
the error performance requirement by the primary users under the constraint
that the primary encoder (not the decoder) is kept unchanged. By modeling the
primary encoder as a generalized trellis code (GTC), we are then able to treat
the secondary link and the cross link from the secondary transmitter to the
primary receiver as finite state channels (FSCs). Based on this, upper and
lower bounds on the accessible capacity are derived. The impact of the error
performance requirement by the primary users on the accessible capacity is
analyzed by using the concept of interference margin. In the case of
non-trivial interference margin, the secondary message is split into common and
private parts and then encoded by superposition coding, which delivers a lower
bound on the accessible capacity. For some special cases, these bounds can be
computed numerically by using the BCJR algorithm. Numerical results are also
provided to gain insight into the impacts of the GTC and the error performance
requirement on the accessible capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5199</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5199</id><created>2010-12-23</created><authors><author><keyname>van Raan</keyname><forenames>Anthony F. J.</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Thed N.</forenames></author><author><keyname>Visser</keyname><forenames>Martijn S.</forenames></author></authors><title>Severe Language Effect in University Rankings: Particularly Germany and
  France are wronged in citation-based rankings</title><categories>cs.DL physics.soc-ph</categories><comments>Short communication, 3 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We applied a set of standard bibliometric indicators to monitor the
scientific state-of-arte of 500 universities worldwide and constructed a
ranking on the basis of these indicators (Leiden Ranking 2010). We find a
dramatic and hitherto largely underestimated language effect in the
bibliometric, citation-based measurement of research performance when comparing
the ranking based on all Web of Science (WoS) covered publications and on only
English WoS covered publications, particularly for Germany and France.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5208</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5208</id><created>2010-12-23</created><authors><author><keyname>Baaziz</keyname><forenames>Nadia</forenames></author><author><keyname>Abahmane</keyname><forenames>Omar</forenames></author><author><keyname>Missaoui</keyname><forenames>Rokia</forenames></author></authors><title>Texture feature extraction in the spatial-frequency domain for
  content-based image retrieval</title><categories>cs.CV cs.IR cs.MM</categories><comments>19 pages, 11 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of large scale multimedia databases has led to great challenges in
content-based image retrieval (CBIR). Even though CBIR is considered an
emerging field of research, however it constitutes a strong background for new
methodologies and systems implementations. Therefore, many research
contributions are focusing on techniques enabling higher image retrieval
accuracy while preserving low level of computational complexity. Image
retrieval based on texture features is receiving special attention because of
the omnipresence of this visual feature in most real-world images. This paper
highlights the state-of-the-art and current progress relevant to texture-based
image retrieval and spatial-frequency image representations. In particular, it
gives an overview of statistical methodologies and techniques employed for
texture feature extraction using most popular spatial-frequency image
transforms, namely discrete wavelets, Gabor wavelets, dual-tree complex wavelet
and contourlets. Indications are also given about used similarity measurement
functions and most important achieved results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5210</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5210</id><created>2010-12-23</created><authors><author><keyname>Bertone</keyname><forenames>Cristina</forenames></author></authors><title>Modular absolute decomposition of equidimensional polynomial ideals</title><categories>math.AC cs.SC</categories><comments>27 pages, preliminary version, comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a modular strategy which describes key properties
of the absolute primary decomposition of an equidimensional polynomial ideal
defined by polynomials with rational coefficients. The algorithm we design is
based on the classical technique of elimination of variables and colon ideals
and uses a tricky choice of prime integers to work with. Thanks to this
technique, we can obtain the number of absolute irreducible components, their
degree, multiplicity and also the affine Hilbert function of the reduced
components (namely, their initial ideal w.r.t. a degree-compatible term
ordering) .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5224</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5224</id><created>2010-12-23</created><updated>2014-10-15</updated><authors><author><keyname>Riis</keyname><forenames>Soren</forenames></author><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author></authors><title>Max-Flow Min-Cut Theorems for Multi-User Communication Networks</title><categories>cs.IT cs.LO math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents four distinct new ideas and results for communication
networks:
  1) We show that relay-networks (i.e. communication networks where different
nodes use the same coding functions) can be used to model dynamic networks.
  2) We introduce {\em the term model}, which is a simple, graph-free symbolic
approach to communication networks.
  3) We state and prove variants of a theorem concerning the dispersion of
information in single-receiver communications.
  4) We show that the solvability of an abstract multi-user communication
problem is equivalent to the solvability of a single-target communication in a
suitable relay network.
  In the paper, we develop a number of technical ramifications of these ideas
and results. One technical result is a max-flow min-cut theorem for the R\'enyi
entropy with order less than one, given that the sources are equiprobably
distributed; conversely, we show that the max-flow min-cut theorem fails for
the R\'enyi entropy with order greater than one. We leave the status of the
theorem with regards to the ordinary Shannon Entropy measure (R\'enyi entropy
of order one and the limit case between validity or failure of the theorem) as
an open question. In non-dynamic static communication networks with a single
receiver, a simple application of Menger's theorem shows that the optimal
throughput can be achieved without proper use of network coding i.e. just by
using ordinary packet-switching. This fails dramatically in relay networks with
a single receiver. We show that even a powerful method like linear network
coding fails miserably for relay networks. With that in mind, it is noticeable
that our rather weak form of network coding (routing with dynamic headers) is
asymptotically sufficient to reach capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5240</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5240</id><created>2010-12-23</created><authors><author><keyname>Icking</keyname><forenames>Christian</forenames></author><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Klein</keyname><forenames>Rolf</forenames></author><author><keyname>Langetepe</keyname><forenames>Elmar</forenames></author></authors><title>Exploring Grid Polygons Online</title><categories>cs.CG cs.RO</categories><comments>49 pages, 45 figures</comments><report-no>TR-001</report-no><acm-class>F.2.2; I.3.5; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the exploration problem of a short-sighted mobile robot moving
in an unknown cellular room. To explore a cell, the robot must enter it. Once
inside, the robot knows which of the 4 adjacent cells exist and which are
boundary edges. The robot starts from a specified cell adjacent to the room's
outer wall; it visits each cell, and returns to the start. Our interest is in a
short exploration tour; that is, in keeping the number of multiple cell visits
small. For abitrary environments containing no obstacles we provide a strategy
producing tours of length S &lt;= C + 1/2 E - 3, and for environments containing
obstacles we provide a strategy, that is bound by S &lt;= C + 1/2 E + 3H + WCW -
2, where C denotes the number of cells-the area-, E denotes the number of
boundary edges-the perimeter-, and H is the number of obstacles, and WCW is a
measure for the sinuosity of the given environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5248</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5248</id><created>2010-12-23</created><authors><author><keyname>Petre</keyname><forenames>Ion</forenames></author><author><keyname>Verlan</keyname><forenames>Sergey</forenames></author></authors><title>Matrix Insertion-Deletion Systems</title><categories>cs.FL cs.CC cs.CL cs.DM</categories><msc-class>68Q05, 68Q10, 68Q17</msc-class><acm-class>F.4.3; F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we consider for the first time the operations of insertion
and deletion working in a matrix controlled manner. We show that, similarly as
in the case of context-free productions, the computational power is strictly
increased when using a matrix control: computational completeness can be
obtained by systems with insertion or deletion rules involving at most two
symbols in a contextual or in a context-free manner and using only binary
matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5253</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5253</id><created>2010-12-23</created><authors><author><keyname>Herrmann</keyname><forenames>Daniel</forenames></author><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Langetepe</keyname><forenames>Elmar</forenames></author></authors><title>Exploring Simple Triangular and Hexagonal Grid Polygons Online</title><categories>cs.CG cs.RO</categories><comments>37 pages, 25 figures</comments><report-no>TR-007</report-no><acm-class>F.2.2; I.3.5; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the online exploration problem (aka covering) of a
short-sighted mobile robot moving in an unknown cellular environment with
hexagons and triangles as types of cells. To explore a cell, the robot must
enter it. Once inside, the robot knows which of the 3 or 6 adjacent cells exist
and which are boundary edges. The robot's task is to visit every cell in the
given environment and to return to the start. Our interest is in a short
exploration tour; that is, in keeping the number of multiple cell visits small.
For arbitrary environments containing no obstacles we provide a strategy
producing tours of length S &lt;= C + 1/4 E - 2.5 for hexagonal grids, and S &lt;= C
+ E - 4 for triangular grids. C denotes the number of cells-the area-, E
denotes the number of boundary edges-the perimeter-of the given environment.
Further, we show that our strategy is 4/3-competitive in both types of grids,
and we provide lower bounds of 14/13 for hexagonal grids and 7/6 for triangular
grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5259</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5259</id><created>2010-12-23</created><authors><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Langetepe</keyname><forenames>Elmar</forenames></author></authors><title>Optimal competitive online ray search with an error-prone robot</title><categories>cs.CG</categories><comments>18 pages, 2 figures, short paper appeared in Proc. 4th Internat.
  Workshop Efficient Experim. Algorithms</comments><report-no>TR-003</report-no><acm-class>F.2.2; I.3.5; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding a door along a wall with a blind robot
that neither knows the distance to the door nor the direction towards of the
door. This problem can be solved with the well-known doubling strategy yielding
an optimal competitive factor of 9 with the assumption that the robot does not
make any errors during its movements. We study the case that the robot's
movement is erroneous. In this case the doubling strategy is no longer optimal.
We present optimal competitive strategies that take the error assumption into
account. The analysis technique can be applied to different error models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5270</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5270</id><created>2010-12-23</created><authors><author><keyname>Campos-Canton</keyname><forenames>I.</forenames></author><author><keyname>Pecina-Sanchez</keyname><forenames>J. A.</forenames></author><author><keyname>Campos-Canton</keyname><forenames>E.</forenames></author><author><keyname>Rosu</keyname><forenames>H. C.</forenames></author></authors><title>A simple circuit with dynamic logic architecture of basic logic gates</title><categories>cond-mat.other cs.OH</categories><comments>11 pages,5 figures,3 tables</comments><journal-ref>Int. J. Bif. Chaos 20(8) 2547-2551 (2010)</journal-ref><doi>10.1142/S0218127410027179</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report experimental results obtained with a circuit possessing dynamic
logic architecture based on one of the theoretical schemes proposed by H. Peng
and collaborators in 2008. The schematic diagram of the electronic circuit and
its implementation to get different basic logic gates are displayed and
discussed. In particular, we show explicitly how to get the electronic NOR,
NAND, and XOR gates. The proposed electronic circuit is easy to build because
it employs only resistors, operational amplifiers and comparators
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5306</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5306</id><created>2010-12-23</created><updated>2011-05-23</updated><authors><author><keyname>Zhang</keyname><forenames>Jiapu</forenames></author></authors><title>An optimization strategy on prion AGAAAAGA amyloid fibril molecular
  modeling</title><categories>cs.CE physics.bio-ph q-bio.BM q-bio.QM</categories><report-no>Central European Journal of Bioliogy (2012) DOI:
  10.2478/s11535-011-0088-7</report-no><journal-ref>Central European Journal of Bioliogy (2012) DOI:
  10.2478/s11535-011-0088-7</journal-ref><doi>10.2478/s11535-011-0088-7</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  X-ray crystallography and nuclear magnetic resonance (NMR) spectroscopy are
two powerful tools to determine the protein 3D structure. However, not all
proteins can be successfully crystallized, particularly for membrane proteins.
Although NMR spectroscopy is indeed very powerful in determining the 3D
structures of membrane proteins, same as X-ray crystallography, it is still
very time-consuming and expensive. Under many circumstances, due to the
noncrystalline and insoluble nature of some proteins, X-ray and NMR cannot be
used at all. Computational approaches, however, allow us to obtain a
description of the protein 3D structure at a submicroscopic level.
  To the best of the author's knowledge, there is little structural data
available to date on the AGAAAAGA palindrome in the hydrophobic region
(113--120) of prion proteins, which falls just within the N-terminal
unstructured region (1--123) of prion proteins. Many experimental studies have
shown that the AGAAAAGA region has amyloid fibril forming properties and plays
an important role in prion diseases. However, due to the noncrystalline and
insoluble nature of the amyloid fibril, little structural data on the AGAAAAGA
is available. This paper introduces a simple optimization strategy approach to
address the 3D atomic-resolution structure of prion AGAAAAGA amyloid fibrils.
Atomic-resolution structures of prion AGAAAAGA amyloid fibrils got in this
paper are useful for the drive to find treatments for prion diseases in the
field of medicinal chemistry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5314</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5314</id><created>2010-12-23</created><updated>2011-04-22</updated><authors><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author><author><keyname>Castellano</keyname><forenames>Claudio</forenames></author></authors><title>Rescaling citations of publications in physics</title><categories>cs.DL physics.soc-ph</categories><comments>8 pages, 10 figures, 1 table</comments><journal-ref>Phys. Rev. E 83, 046116 (2011)</journal-ref><doi>10.1103/PhysRevE.83.046116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the citation distributions of all papers published in Physical
Review journals between 1985 and 2009. The average number of citations received
by papers published in a given year and in a given field is computed. Large
variations are found, showing that it is not fair to compare citation numbers
across fields and years. However, when a rescaling procedure by the average is
used, it is possible to compare impartially articles across years and fields.
We make the rescaling factors available for use by the readers. We also show
that rescaling citation numbers by the number of publication authors has strong
effects and should therefore be taken into account when assessing the
bibliometric performance of researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5318</identifier>
 <datestamp>2010-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5318</id><created>2010-12-23</created><authors><author><keyname>Viznyuk</keyname><forenames>Sergei</forenames></author></authors><title>Condensation into ground state in binary string models</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ensemble of binary strings defined via strong-interaction model exhibits
enhanced condensation (collapse) into ground state below certain temperature.
The non-interaction model shows gradual accumulation into ground state as
temperature approaches zero
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5327</identifier>
 <datestamp>2011-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5327</id><created>2010-12-23</created><updated>2011-02-18</updated><authors><author><keyname>Urriza</keyname><forenames>Paulo</forenames></author><author><keyname>Rebeiz</keyname><forenames>Eric</forenames></author><author><keyname>Pawe&#x142;czak</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>&#x10c;abri&#x107;</keyname><forenames>Danijela</forenames></author></authors><title>Computationally Efficient Modulation Level Classification Based on
  Probability Distribution Distance Functions</title><categories>cs.IT cs.PF math.IT stat.ML</categories><comments>3 pages, resubmitted to IEEE Communication Letters (modified based on
  reviewer comments)</comments><doi>10.1109/LCOMM.2011.032811.110316</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel modulation level classification (MLC) method based on
probability distribution distance functions. The proposed method uses modified
Kuiper and Kolmogorov-Smirnov distances to achieve low computational complexity
and outperforms the state of the art methods based on cumulants and
goodness-of-fit tests. We derive the theoretical performance of the proposed
MLC method and verify it via simulations. The best classification accuracy,
under AWGN with SNR mismatch and phase jitter, is achieved with the proposed
MLC method using Kuiper distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5330</identifier>
 <datestamp>2011-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5330</id><created>2010-12-23</created><updated>2011-11-07</updated><authors><author><keyname>Fekete</keyname><forenames>Sandor</forenames></author><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Schweer</keyname><forenames>Nils</forenames></author><author><keyname>Tessars</keyname><forenames>Christopher</forenames></author><author><keyname>van der Veen</keyname><forenames>Jan C.</forenames></author><author><keyname>Angermeier</keyname><forenames>Josef</forenames></author><author><keyname>Koch</keyname><forenames>Dirk</forenames></author><author><keyname>Teich</keyname><forenames>Juergen</forenames></author></authors><title>No-Break Dynamic Defragmentation of Reconfigurable Devices</title><categories>cs.DS</categories><comments>18 pages, 13 figures, an earlier version appeared in the proceedings
  of the FPL 08</comments><acm-class>F.2.2; C.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method for defragmenting the module layout of a
reconfigurable device, enabled by a novel approach for dealing with
communication needs between relocated modules and with inhomogeneities found in
commonly used FPGAs. Our method is based on dynamic relocation of module
positions during runtime, with only very little reconfiguration overhead; the
objective is to maximize the length of contiguous free space that is available
for new modules. We describe a number of algorithmic aspects of good
defragmentation, and present an optimization method based on tabu search.
Experimental results indicate that we can improve the quality of module layout
by roughly 50 % over static layout. Among other benefits, this improvement
avoids unnecessary rejections of modules
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5337</identifier>
 <datestamp>2010-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5337</id><created>2010-12-23</created><authors><author><keyname>Kirchner</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>INRIA, France</affiliation></author><author><keyname>Mu&#xf1;oz</keyname><forenames>C&#xe9;sar</forenames><affiliation>NASA, USA</affiliation></author></authors><title>Proceedings International Workshop on Strategies in Rewriting, Proving,
  and Programming</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 44, 2010</journal-ref><doi>10.4204/EPTCS.44</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains selected papers from the proceedings of the First
International Workshop on Strategies in Rewriting, Proving, and Programming
(IWS 2010), which was held on July 9, 2010, in Edinburgh, UK. Strategies are
ubiquitous in programming languages, automated deduction and reasoning systems.
In the two communities of Rewriting and Programming on one side, and of
Deduction and Proof engines (Provers, Assistants, Solvers) on the other side,
workshops have been launched to make progress towards a deeper understanding of
the nature of strategies, their descriptions, their properties, and their
usage, in all kinds of computing and reasoning systems. Since more recently,
strategies are also playing an important role in rewrite-based programming
languages, verification tools and techniques like SAT/SMT engines or
termination provers. Moreover strategies have come to be viewed more generally
as expressing complex designs for control in computing, modeling, proof search,
program transformation, and access control. IWS 2010 was organized as a
satellite workshop of FLoC 2010. FLoC 2010 provided an excellent opportunity to
foster exchanges between the communities of Rewriting and Programming on one
side, and of Deduction and Proof engines on the other side. IWS2010 was a joint
follow-up of two series of worshops, held since 1997: the Strategies workshops
held by the CADE-IJCAR community and the Workshops on Reduction Strategies
(WRS) held by the RTA-RDP community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5339</identifier>
 <datestamp>2010-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5339</id><created>2010-12-23</created><authors><author><keyname>Zhou</keyname><forenames>Hongchao</forenames></author><author><keyname>Bruck</keyname><forenames>Jehoshua</forenames></author></authors><title>Efficient Generation of Random Bits from Finite State Markov Chains</title><categories>cs.IT math.IT</categories><comments>14 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of random number generation from an uncorrelated random source
(of unknown probability distribution) dates back to von Neumann's 1951 work.
Elias (1972) generalized von Neumann's scheme and showed how to achieve optimal
efficiency in unbiased random bits generation. Hence, a natural question is
what if the sources are correlated? Both Elias and Samuelson proposed methods
for generating unbiased random bits in the case of correlated sources (of
unknown probability distribution), specifically, they considered finite Markov
chains. However, their proposed methods are not efficient or have
implementation difficulties. Blum (1986) devised an algorithm for efficiently
generating random bits from degree-2 finite Markov chains in expected linear
time, however, his beautiful method is still far from optimality on
information-efficiency. In this paper, we generalize Blum's algorithm to
arbitrary degree finite Markov chains and combine it with Elias's method for
efficient generation of unbiased bits. As a result, we provide the first known
algorithm that generates unbiased random bits from an arbitrary finite Markov
chain, operates in expected linear time and achieves the information-theoretic
upper bound on efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5340</identifier>
 <datestamp>2010-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5340</id><created>2010-12-23</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Xu</keyname><forenames>Guangwu</forenames></author></authors><title>Relations between $\beta$ and $\delta$ for QP and LP in Compressed
  Sensing Computations</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many compressed sensing applications, linear programming (LP) has been
used to reconstruct a sparse signal. When observation is noisy, the LP
formulation is extended to allow an inequality constraint and the solution is
dependent on a parameter $\delta$, related to the observation noise level.
Recently, some researchers also considered quadratic programming (QP) for
compressed sensing signal reconstruction and the solution in this case is
dependent on a Lagrange multiplier $\beta$. In this work, we investigated the
relation between $\delta$ and $\beta$ and derived an upper and a lower bound on
$\beta$ in terms of $\delta$. For a given $\delta$, these bounds can be used to
approximate $\beta$. Since $\delta$ is a physically related quantity and easy
to determine for an application while there is no easy way in general to
determine $\beta$, our results can be used to set $\beta$ when the QP is used
for compressed sensing. Our results and experimental verification also provide
some insight into the solutions generated by compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5351</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5351</id><created>2010-12-24</created><updated>2013-08-07</updated><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author></authors><title>Quasirandom Rumor Spreading</title><categories>cs.DS cs.DC cs.DM</categories><comments>34 pages, to appear in ACM Transactions of Algorithms, parts of the
  results appeared in SODA'08 and ICALP'09</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and analyze a quasirandom analogue of the classical push model for
disseminating information in networks (&quot;randomized rumor spreading&quot;). In the
classical model, in each round each informed vertex chooses a neighbor at
random and informs it, if it was not informed before. It is known that this
simple protocol succeeds in spreading a rumor from one vertex to all others
within O(log n) rounds on complete graphs, hypercubes, random regular graphs,
Erdos-Renyi random graph and Ramanujan graphs with probability 1-o(1). In the
quasirandom model, we assume that each vertex has a (cyclic) list of its
neighbors. Once informed, it starts at a random position on the list, but from
then on informs its neighbors in the order of the list. Surprisingly,
irrespective of the orders of the lists, the above-mentioned bounds still hold.
In some cases, even better bounds than for the classical model can be shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5353</identifier>
 <datestamp>2010-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5353</id><created>2010-12-24</created><authors><author><keyname>Nakayama</keyname><forenames>Hiromasa</forenames></author><author><keyname>Takayama</keyname><forenames>Nobuki</forenames></author></authors><title>Computing Differential Equations for Integrals Associated to Smooth Fano
  Polytopes</title><categories>cs.SC</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an approximate algorithm of computing holonomic systems of linear
differential equations for definite integrals with parameters. We show that
this algorithm gives a correct answer in finite steps, but we have no general
stopping condition. We apply the approximate method to find differential
equations for integrals associated to smooth Fano polytopes. They are
interested in the study of K3 surfaces and the toric mirror symmetry. In this
class of integrals, we can apply Stienstra's rank formula to our algorithm,
which gives a stopping condition of the approximate algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5357</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5357</id><created>2010-12-24</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>K&#xfc;nnemann</keyname><forenames>Marvin</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author></authors><title>Quasirandom Rumor Spreading: An Experimental Analysis</title><categories>cs.DS cs.SI</categories><comments>14 pages, appeared in ALENEX'09</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We empirically analyze two versions of the well-known &quot;randomized rumor
spreading&quot; protocol to disseminate a piece of information in networks. In the
classical model, in each round each informed node informs a random neighbor. In
the recently proposed quasirandom variant, each node has a (cyclic) list of its
neighbors. Once informed, it starts at a random position of the list, but from
then on informs its neighbors in the order of the list. While for sparse random
graphs a better performance of the quasirandom model could be proven, all other
results show that, independent of the structure of the lists, the same
asymptotic performance guarantees hold as for the classical model. In this
work, we compare the two models experimentally. This not only shows that the
quasirandom model generally is faster, but also that the runtime is more
concentrated around the mean. This is surprising given that much fewer random
bits are used in the quasirandom process. These advantages are also observed in
a lossy communication model, where each transmission does not reach its target
with a certain probability, and in an asynchronous model, where nodes send at
random times drawn from an exponential distribution. We also show that
typically the particular structure of the lists has little influence on the
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5379</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5379</id><created>2010-12-24</created><updated>2013-05-08</updated><authors><author><keyname>Reps</keyname><forenames>Bram</forenames></author><author><keyname>Vanroose</keyname><forenames>Wim</forenames></author><author><keyname>Zubair</keyname><forenames>Hisham bin</forenames></author></authors><title>GMRES-based multigrid for the complex scaled preconditoner for the
  indefinite Helmholtz equation</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multigrid preconditioners and solvers for the indefinite Helmholtz equation
suffer from non-stability of the stationary smoothers due to the indefinite
spectrum of the operator. In this paper we explore GMRES as a replacement for
the stationary smoothers of the standard multigrid method. This results in a
robust and efficient solver for a complex shifted or stretched Helmholtz
problem that can be used as a preconditioner. Very few GMRES iterations are
required on each level to build a good multigrid method. The convergence
behavior is compared to a theoretically derived stable polynomial smoother. We
test this method on some benchmark problems and report on the observed
convergence behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5396</identifier>
 <datestamp>2010-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5396</id><created>2010-12-24</created><authors><author><keyname>Biryukov</keyname><forenames>Maria</forenames></author><author><keyname>Dong</keyname><forenames>Cailing</forenames></author></authors><title>Analysis of Computer Science Communities Based on DBLP</title><categories>cs.DL</categories><comments>9 pages, 7 figures, 6 tables</comments><journal-ref>The Fourteenth European Conference on Research and Advanced
  Technology for Digital Libraries (ECDL 2010)</journal-ref><doi>10.1007/978-3-642-15464-5_24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is popular nowadays to bring techniques from bibliometrics and
scientometrics into the world of digital libraries to analyze the collaboration
patterns and explore mechanisms which underlie community development. In this
paper we use the DBLP data to investigate the author's scientific career and
provide an in-depth exploration of some of the computer science communities. We
compare them in terms of productivity, population stability and collaboration
trends.Besides we use these features to compare the sets of topranked
conferences with their lower ranked counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5425</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5425</id><created>2010-12-24</created><updated>2010-12-28</updated><authors><author><keyname>Huang</keyname><forenames>Lei</forenames></author></authors><title>A new conception for computing gr\&quot;{o}bner basis and its applications</title><categories>cs.SC math.AC</categories><comments>22 pages</comments><msc-class>33F10, 68W30</msc-class><acm-class>F.2.1; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a conception for computing gr\&quot;{o}bner basis. We convert
some of gr\&quot;{o}bner-computing algorithms, e.g., F5, extended F5 and GWV
algorithms into a special type of algorithm. The new algorithm's finite
termination problem can be described by equivalent conditions, so all the above
algorithms can be determined when they terminate finitely. At last, a new
criterion is presented. It is an improvement for the Rewritten and Signature
Criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5430</identifier>
 <datestamp>2010-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5430</id><created>2010-12-24</created><authors><author><keyname>Anxiao</keyname><affiliation>Andrew</affiliation></author><author><keyname>Jiang</keyname></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author><author><keyname>Bruck</keyname><forenames>Jehoshua</forenames></author></authors><title>Trajectory Codes for Flash Memory</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flash memory is well-known for its inherent asymmetry: the flash-cell charge
levels are easy to increase but are hard to decrease. In a general rewriting
model, the stored data changes its value with certain patterns. The patterns of
data updates are determined by the data structure and the application, and are
independent of the constraints imposed by the storage medium. Thus, an
appropriate coding scheme is needed so that the data changes can be updated and
stored efficiently under the storage-medium's constraints.
  In this paper, we define the general rewriting problem using a graph model.
It extends many known rewriting models such as floating codes, WOM codes,
buffer codes, etc. We present a new rewriting scheme for flash memories, called
the trajectory code, for rewriting the stored data as many times as possible
without block erasures. We prove that the trajectory code is asymptotically
optimal in a wide range of scenarios.
  We also present randomized rewriting codes optimized for expected performance
(given arbitrary rewriting sequences). Our rewriting codes are shown to be
asymptotically optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5439</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5439</id><created>2010-12-24</created><updated>2012-06-23</updated><authors><author><keyname>Kara</keyname><forenames>Ahmet</forenames></author><author><keyname>Tan</keyname><forenames>Tony</forenames></author></authors><title>Extending B\&quot;uchi Automata with Constraints on Data Values</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently data trees and data words have received considerable amount of
attention in connection with XML reasoning and system verification. These are
trees or words that, in addition to labels from a finite alphabet, carry data
values from an infinite alphabet (data). In general it is rather hard to obtain
logics for data words and trees that are sufficiently expressive, but still
have reasonable complexity for the satisfiability problem. In this paper we
extend and study the notion of B\&quot;uchi automata for omega-words with data. We
prove that the emptiness problem for such extension is decidable in elementary
complexity. We then apply our result to show the decidability of two kinds of
logics for omega-words with data: the two-variable fragment of first-order
logic and some extensions of classical linear temporal logic for omega-words
with data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5444</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5444</id><created>2010-12-24</created><authors><author><keyname>Khugaev</keyname><forenames>Avas V.</forenames></author><author><keyname>Sultanov</keyname><forenames>Renat A.</forenames></author><author><keyname>Guster</keyname><forenames>D.</forenames></author></authors><title>Iteration Procedure for the N-Dimensional System of Linear Equations</title><categories>physics.comp-ph cs.NA math.NA</categories><comments>8 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple iteration methodology for the solution of a set of a linear
algebraic equations is presented. The explanation of this method is based on a
pure geometrical interpretation and pictorial representation. Convergence using
this method is obtained and a simple numerical example is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5454</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5454</id><created>2010-12-25</created><updated>2015-02-13</updated><authors><author><keyname>Qaseem</keyname><forenames>Syed</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq</forenames></author><author><keyname>Eltayeb</keyname><forenames>Mohammed</forenames></author><author><keyname>Bahrami</keyname><forenames>Hamid Reza</forenames></author></authors><title>Compressed Sensing for Feedback Reduction in MIMO Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a generalized feedback model and compressive sensing based
opportunistic feedback schemes for feedback resource reduction in MIMO
Broadcast Channels under the assumption that both uplink and downlink channels
undergo block Rayleigh fading. Feedback resources are shared and are
opportunistically accessed by users who are strong, i.e. users whose channel
quality information is above a certain fixed threshold. Strong users send the
same feedback information on all shared channels. They are identified by the
base station via compressive sensing. Both analog and digital feedbacks are
considered. The proposed analog &amp; digital opportunistic feedback schemes are
shown to achieve the same sum-rate throughput as that achieved by dedicated
feedback schemes, but with feedback channels growing only logarithmically with
number of users. Moreover, there is also a reduction in the feedback load. In
the analog feedback case, we show that the proposed scheme reduces the feedback
noise which eventually results in better throughput, whereas in the digital
feedback case the proposed scheme in a noisy scenario achieves almost the
throughput obtained in a noiseless dedicated feedback scenario. We also show
that for a given fixed budget of feedback bits, there exists a trade-off
between the number of shared channels and thresholds accuracy of the fed back
SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5464</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5464</id><created>2010-12-25</created><updated>2012-03-22</updated><authors><author><keyname>Harada</keyname><forenames>Masaaki</forenames></author><author><keyname>Munemasa</keyname><forenames>Akihiro</forenames></author></authors><title>Classification of self-dual codes of length 36</title><categories>math.CO cs.IT math.IT</categories><comments>10 pages, minor revision</comments><msc-class>94B05</msc-class><journal-ref>Advances Math. Communications 6 (2012), 229-235</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complete classification of binary self-dual codes of length 36 is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5477</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5477</id><created>2010-12-25</created><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>Generalized Linear Weights for Sharing Credits Among Multiple Authors</title><categories>cs.DL</categories><comments>7 pages, 2 figures, 5 tables</comments><msc-class>19K56, 74P05, 11B25, 34C60</msc-class><acm-class>H.3.1; H.3.2; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assignment of weights to multiple authors of a paper is a challenging task
due to its dependence on the conventions that may be different among different
fields of research and research groups. In this paper, we describe a scheme for
assignment of weights to multiple authors of a paper. In our scheme, weights
are assigned in a linearly decreasing/increasing fashion depending upon the
weight decrement/increment parameter. We call our scheme Arithmetic: Type-2
scheme as the weights follow an arithmetic series. We analyze the proposed
weight assignment scheme and compare it with the existing schemes such as
equal, arithmetic, geometric, and harmonic. We argue that the a positional
weight assignment scheme, called arithmetic scheme, which we refer to
Arithmetic: Type-1 in this paper, and the equal weight assignment scheme can be
treated as special cases of the proposed Arithmetic: Type-2 scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5484</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5484</id><created>2010-12-25</created><authors><author><keyname>Baboulin</keyname><forenames>Marc</forenames><affiliation>LRI</affiliation></author><author><keyname>Gratton</keyname><forenames>Serge</forenames><affiliation>CERFACS</affiliation></author></authors><title>A contribution to the conditioning of the total least squares problem</title><categories>cs.NA</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive closed formulas for the condition number of a linear function of
the total least squares solution. Given an over determined linear system Ax=b,
we show that this condition number can be computed using the singular values
and the right singular vectors of [A,b] and A. We also provide an upper bound
that requires the computation of the largest and the smallest singular value of
[A,b] and the smallest singular value of A. In numerical examples, we compare
these values and the resulting forward error bounds with existing error
estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5486</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5486</id><created>2010-12-25</created><authors><author><keyname>Bisi</keyname><forenames>Cinzia</forenames></author><author><keyname>Chiaselotti</keyname><forenames>Giampiero</forenames></author></authors><title>Extension results for boolean maps and a class of systems of linear
  inequalities</title><categories>math.CO cs.DM cs.FL</categories><comments>22 pages</comments><msc-class>05D05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce the notion of {\it core} for two specific classes
of boolean maps on finite involution posets (which are a generalization of the
boolean lattices) and we prove some extension results for such families of
boolean maps. Through the properties of the core, we provide a complete
characterization of such maps. The main purpose of such abstract results is
their application to the study of the compatibility of a particular class of
systems of linear inequalities related to a conjecture of Manickam, Mikl\&quot;os
and Singhi (\cite{ManSin88}, \cite{ManMik87}), still unsolved and that can be
considered dual to the theorem of Erd\&quot;os-Ko-Rado \cite{erd-ko-rad}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5494</identifier>
 <datestamp>2014-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5494</id><created>2010-12-25</created><updated>2014-04-19</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Contents of COMP6411 Summer 2010 Final Reports on Comparative Studies of
  Programming Languages</title><categories>cs.PL</categories><comments>an index</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This index covers the lecture notes and the final course project reports for
COMP6411 Summer 2010 at Concordia University, Montreal, Canada, Comparative
Study of Programming Languages by 4 teams trying compare a set of common
criteria and their applicability to about 10 distinct programming languages,
where 5 language choices were provided by the instructor and five were picked
by each team and each student individually compared two of the 10 and then the
team did a summary synthesis across all 10 languages. Their findings are posted
here for further reference, comparative studies, and analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5498</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5498</id><created>2010-12-26</created><authors><author><keyname>Jitman</keyname><forenames>Somphong</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Liu</keyname><forenames>Hongwei</forenames></author><author><keyname>Xie</keyname><forenames>Xiaoli</forenames></author></authors><title>Checkable Codes from Group Rings</title><categories>cs.IT math.AC math.IT</categories><comments>9 pages, 4 tables, Submitted to IEEE Transactions on Information
  Theory, December 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study codes with a single check element derived from group rings, namely,
checkable codes. The notion of a code-checkable group ring is introduced.
Necessary and sufficient conditions for a group ring to be code-checkable are
given in the case where the group is a finite abelian group and the ring is a
finite field. This characterization leads to many good examples, among which
two checkable codes and two shortened codes have minimum distance better than
the lower bound given in Grassl's online table. Furthermore, when a group ring
is code-checkable, it is shown that every code in such a group ring admits a
generator, and that its dual is also generated by an element which may be
deduced directly from a check element of the original code. These are analogous
to the generator and parity-check polynomials of cyclic codes. In addition, the
structures of reversible and complementary dual checkable codes are established
as generalizations of reversible and complementary dual cyclic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5499</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5499</id><created>2010-12-26</created><updated>2010-12-31</updated><authors><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Du</keyname><forenames>Wen-Bo</forenames></author><author><keyname>Cao</keyname><forenames>Xian-Bin</forenames></author><author><keyname>Zhang</keyname><forenames>Lian-Zhong</forenames></author></authors><title>Integrating neighborhoods in the evaluation of fitness promotes
  cooperation in the spatial prisoner's dilemma game</title><categories>physics.soc-ph cs.SI</categories><doi>10.1016/j.physa.2010.12.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental question of human society is the evolution of cooperation. Many
previous studies explored this question via setting spatial background, where
players obtain their payoffs by playing game with their nearest neighbors.
Another undoubted fact is that environment plays an important role in the
individual development. Inspired by these phenomena, we reconsider the
definition of individual fitness which integrates the environment, denoted by
the average payoff of all individual neighbors, with the traditional individual
payoffs by introducing a selection parameter $u$. Tuning $u$ equal to zero
returns the traditional version, while increasing $u$ bears the influence of
environment. We find that considering the environment, i.e. integrating
neighborhoods in the evaluation of fitness, promotes cooperation. If we enhance
the value of $u$, the invasion of defection could be resisted better. We also
provide quantitative explanations and complete phase diagrams presenting the
influence of environment on the evolution of cooperation. Finally, the
universality of this mechanism is testified for different neighborhood sizes,
different topology structures and different game models. Our work may shed a
light on the emergence and persistence of cooperation in our life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5506</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5506</id><created>2010-12-26</created><authors><author><keyname>Gonzalez-Beltran</keyname><forenames>Alejandra</forenames></author><author><keyname>Tagger</keyname><forenames>Ben</forenames></author><author><keyname>Finkelstein</keyname><forenames>Anthony</forenames></author></authors><title>Ontology-based Queries over Cancer Data</title><categories>cs.AI cs.DB cs.IR</categories><comments>in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott
  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on
  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,
  December 8-10, 2010</comments><report-no>SWAT4LS 2010</report-no><acm-class>J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ever-increasing amount of data in biomedical research, and in cancer
research in particular, needs to be managed to support efficient data access,
exchange and integration. Existing software infrastructures, such caGrid,
support access to distributed information annotated with a domain ontology.
However, caGrid's current querying functionality depends on the structure of
individual data resources without exploiting the semantic annotations. In this
paper, we present the design and development of an ontology-based querying
functionality that consists of: the generation of OWL2 ontologies from the
underlying data resources metadata and a query rewriting and translation
process based on reasoning, which converts a query at the domain ontology level
into queries at the software infrastructure level. We present a detailed
analysis of our approach as well as an extensive performance evaluation. While
the implementation and evaluation was performed for the caGrid infrastructure,
the approach could be applicable to other model and metadata-driven
environments for data sharing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5546</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5546</id><created>2010-12-26</created><authors><author><keyname>Gouider</keyname><forenames>Mohamed Salah</forenames></author><author><keyname>Farhat</keyname><forenames>Amine</forenames></author></authors><title>Mining Multi-Level Frequent Itemsets under Constraints</title><categories>cs.DB cs.AI cs.DS</categories><comments>20 pages</comments><msc-class>68P04, 68Q04, 68T04, 68U04</msc-class><acm-class>H.2.4; H.2.8; I.2.6; I.2.4; I.1.2</acm-class><journal-ref>Internatinal Journal of Database Theory and Application, Vol. 3,
  No. 4, PP. 15-35, December, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mining association rules is a task of data mining, which extracts knowledge
in the form of significant implication relation of useful items (objects) from
a database. Mining multilevel association rules uses concept hierarchies, also
called taxonomies and defined as relations of type 'is-a' between objects, to
extract rules that items belong to different levels of abstraction. These rules
are more useful, more refined and more interpretable by the user. Several
algorithms have been proposed in the literature to discover the multilevel
association rules. In this article, we are interested in the problem of
discovering multi-level frequent itemsets under constraints, involving the user
in the research process. We proposed a technique for modeling and
interpretation of constraints in a context of use of concept hierarchies. Three
approaches for discovering multi-level frequent itemsets under constraints were
proposed and discussed: Basic approach, &quot;Test and Generate&quot; approach and
Pruning based Approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5553</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5553</id><created>2010-12-26</created><updated>2011-06-23</updated><authors><author><keyname>Ordentlich</keyname><forenames>Or</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>Cyclic-Coded Integer-Forcing Equalization</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A discrete-time intersymbol interference channel with additive Gaussian noise
is considered, where only the receiver has knowledge of the channel impulse
response. An approach for combining decision-feedback equalization with channel
coding is proposed, where decoding precedes the removal of intersymbol
interference. This is accomplished by combining the recently proposed
integer-forcing equalization approach with cyclic block codes. The channel
impulse response is linearly equalized to an integer-valued response. This is
then utilized by leveraging the property that a cyclic code is closed under
(cyclic) integer-valued convolution. Explicit bounds on the performance of the
proposed scheme are also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5560</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5560</id><created>2010-12-27</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames><affiliation>King's College London</affiliation></author><author><keyname>Namet</keyname><forenames>Olivier</forenames><affiliation>King's College London</affiliation></author></authors><title>Strategic programming on graph rewriting systems</title><categories>cs.PL</categories><comments>In Proceedings IWS 2010, arXiv:1012.5337</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 44, 2010, pp. 1-20</journal-ref><doi>10.4204/EPTCS.44.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a strategy language to control the application of graph rewriting
rules, and show how this language can be used to write high-level declarative
programs in several application areas. This language is part of a graph-based
programming tool built within the port-graph transformation and visualisation
environment PORGY.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5561</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5561</id><created>2010-12-27</created><authors><author><keyname>Gerdes</keyname><forenames>Alex</forenames><affiliation>Open Universiteit Nederland</affiliation></author><author><keyname>Heeren</keyname><forenames>Bastiaan</forenames><affiliation>Open Universiteit Nederland</affiliation></author><author><keyname>Jeuring</keyname><forenames>Johan</forenames><affiliation>Utrecht University</affiliation></author></authors><title>Properties of Exercise Strategies</title><categories>cs.CY cs.LO</categories><comments>In Proceedings IWS 2010, arXiv:1012.5337</comments><proxy>EPTCS</proxy><acm-class>D.3.1</acm-class><journal-ref>EPTCS 44, 2010, pp. 21-34</journal-ref><doi>10.4204/EPTCS.44.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical learning environments give domain-specific and immediate
feedback to students solving a mathematical exercise. Based on a language for
specifying strategies, we have developed a feedback framework that
automatically calculates semantically rich feedback. We offer this feedback
functionality to mathematical learning environments via a set of web services.
Feedback is only effective when it is precise and to the point. The tests we
have performed give some confidence about the correctness of our feedback
services. To increase confidence in our services, we explicitly specify the
properties our feedback services should satisfy, and, if possible, prove them
correct. For this, we give a formal description of the concepts used in our
feedback framework services. The formalisation allows us to reason about these
concepts, and to state a number of desired properties of the concepts. Our
feedback services use exercise descriptions for their instances on domains such
as logic, algebra, and linear algebra. We formulate requirements these domain
descriptions should satisfy for the feedback services to react as expected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5562</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5562</id><created>2010-12-27</created><authors><author><keyname>Gramlich</keyname><forenames>Bernhard</forenames><affiliation>Vienna University of Technology</affiliation></author><author><keyname>Schernhammer</keyname><forenames>Felix</forenames><affiliation>Vienna University of Technology</affiliation></author></authors><title>Termination of Rewriting with and Automated Synthesis of Forbidden
  Patterns</title><categories>cs.LO</categories><comments>In Proceedings IWS 2010, arXiv:1012.5337</comments><proxy>EPTCS</proxy><acm-class>I.1.3</acm-class><journal-ref>EPTCS 44, 2010, pp. 35-50</journal-ref><doi>10.4204/EPTCS.44.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a modified version of the well-known dependency pair framework
that is suitable for the termination analysis of rewriting under forbidden
pattern restrictions. By attaching contexts to dependency pairs that represent
the calling contexts of the corresponding recursive function calls, it is
possible to incorporate the forbidden pattern restrictions in the (adapted)
notion of dependency pair chains, thus yielding a sound and complete approach
to termination analysis. Building upon this contextual dependency pair
framework we introduce a dependency pair processor that simplifies problems by
analyzing the contextual information of the dependency pairs. Moreover, we show
how this processor can be used to synthesize forbidden patterns suitable for a
given term rewriting system on-the-fly during the termination analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5563</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5563</id><created>2010-12-27</created><authors><author><keyname>Thiemann</keyname><forenames>Ren&#xe9;</forenames><affiliation>University of Innsbruck, Austria</affiliation></author><author><keyname>Sternagel</keyname><forenames>Christian</forenames><affiliation>University of Innsbruck, Austria</affiliation></author><author><keyname>Giesl</keyname><forenames>J&#xfc;rgen</forenames><affiliation>RWTH Aachen University, Germany</affiliation></author><author><keyname>Schneider-Kamp</keyname><forenames>Peter</forenames><affiliation>University of Southern Denmark, Denmark</affiliation></author></authors><title>Loops under Strategies ... Continued</title><categories>cs.LO cs.CC</categories><comments>In Proceedings IWS 2010, arXiv:1012.5337</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 44, 2010, pp. 51-65</journal-ref><doi>10.4204/EPTCS.44.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While there are many approaches for automatically proving termination of term
rewrite systems, up to now there exist only few techniques to disprove their
termination automatically. Almost all of these techniques try to find loops,
where the existence of a loop implies non-termination of the rewrite system.
However, most programming languages use specific evaluation strategies, whereas
loop detection techniques usually do not take strategies into account. So even
if a rewrite system has a loop, it may still be terminating under certain
strategies.
  Therefore, our goal is to develop decision procedures which can determine
whether a given loop is also a loop under the respective evaluation strategy.
In earlier work, such procedures were presented for the strategies of
innermost, outermost, and context-sensitive evaluation. In the current paper,
we build upon this work and develop such decision procedures for important
strategies like leftmost-innermost, leftmost-outermost,
(max-)parallel-innermost, (max-)parallel-outermost, and forbidden patterns
(which generalize innermost, outermost, and context-sensitive strategies). In
this way, we obtain the first approach to disprove termination under these
strategies automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5568</identifier>
 <datestamp>2011-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5568</id><created>2010-12-27</created><updated>2011-11-15</updated><authors><author><keyname>Manyem</keyname><forenames>Prabhu</forenames></author></authors><title>Duality Gap, Computational Complexity and NP Completeness: A Survey</title><categories>math.OC cs.CC</categories><msc-class>90C20, 90C22, 90C25, 90C26, 90C30, 90C46, 49N15, 65K05, 68Q15,
  68Q17, 68Q19, 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey research that studies the connection between the computational
complexity of optimization problems on the one hand, and the duality gap
between the primal and dual optimization problems on the other. To our
knowledge, this is the first survey that connects the two very important areas.
We further look at a similar phenomenon in finite model theory relating to
complexity and optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5573</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5573</id><created>2010-12-27</created><authors><author><keyname>Paul</keyname><forenames>Goutam</forenames></author><author><keyname>Mukherjee</keyname><forenames>Imon</forenames></author></authors><title>Image Sterilization to Prevent LSB-based Steganographic Transmission</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sterilization is a very popular word used in biomedical testing (like removal
of all microorganisms on surface of an article or in fluid using appropriate
chemical products). Motivated by this biological analogy, we, for the first
time, introduce the concept of sterilization of an image, i.e., removing any
steganographic information embedded in the image. Experimental results show
that our technique succeeded in sterilizing around 76% to 91% of stego pixels
in an image on average, where data is embedded using LSB-based steganography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5579</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5579</id><created>2010-12-27</created><updated>2011-02-14</updated><authors><author><keyname>Ariffin</keyname><forenames>Muhammad Rezal Kamel</forenames></author><author><keyname>Mandangan</keyname><forenames>Arif</forenames></author><author><keyname>Ghani</keyname><forenames>Aniza Abdul</forenames></author><author><keyname>Atan</keyname><forenames>Kamel Ariffin Mohd</forenames></author><author><keyname>Abu</keyname><forenames>Nor Azman</forenames></author></authors><title>The El-Gamal AA_{\beta} Public Key Cryptosystem - A new approach
  utilizing the subset sum problem in designing an asymmetric cryptosystem</title><categories>cs.CR</categories><comments>There is a major flaw within the arguments such that the results are
  compromised</comments><msc-class>94A60, 68P25, 11D45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The El-Gamal AA_{\beta} Public Key Cryptosystem is a new asymmetric
cryptosystem based on the piecewise AA_{\beta}-function. The
AA_{\beta}-function which is essentially a one way Boolean function was
motivated by the squaring and multiplying process while computing g^a (mod p)
in the Diffie Hellman key exchange procedure and also computing C \equiv M^e
(mod N) and M \equiv C^d (mod N) in the RSA cryptosystem. It was also motivated
by the add and double point operation E=kG in the elliptic curve cryptosystem.
The hard mathematical problem surrounding this newly designed asymmetric
cryptosystem is the NP-complete problem known as the subset sum problem. The
El-Gamal AA_{\beta} Public Key Cryptosystem mimics the El-Gamal Cryptosystem
and the Elliptic Curve Cryptosystem by sending a two parameter ciphertext to
the recipient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5585</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5585</id><created>2010-12-27</created><authors><author><keyname>januschowski</keyname><forenames>Tim</forenames></author><author><keyname>Smith</keyname><forenames>Barbara M.</forenames></author><author><keyname>van Dongen</keyname><forenames>M. R. C.</forenames></author></authors><title>Symmetry Breaking with Polynomial Delay</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A conservative class of constraint satisfaction problems CSPs is a class for
which membership is preserved under arbitrary domain reductions. Many
well-known tractable classes of CSPs are conservative. It is well known that
lexleader constraints may significantly reduce the number of solutions by
excluding symmetric solutions of CSPs. We show that adding certain lexleader
constraints to any instance of any conservative class of CSPs still allows us
to find all solutions with a time which is polynomial between successive
solutions. The time is polynomial in the total size of the instance and the
additional lexleader constraints. It is well known that for complete symmetry
breaking one may need an exponential number of lexleader constraints. However,
in practice, the number of additional lexleader constraints is typically
polynomial number in the size of the instance. For polynomially many lexleader
constraints, we may in general not have complete symmetry breaking but
polynomially many lexleader constraints may provide practically useful symmetry
breaking -- and they sometimes exclude super-exponentially many solutions. We
prove that for any instance from a conservative class, the time between finding
successive solutions of the instance with polynomially many additional
lexleader constraints is polynomial even in the size of the instance without
lexleaderconstraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5590</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5590</id><created>2010-12-27</created><authors><author><keyname>Armando</keyname><forenames>A.</forenames></author><author><keyname>Ranise</keyname><forenames>S.</forenames></author></authors><title>Automated Symbolic Analysis of ARBAC-Policies (Extended Version)</title><categories>cs.CR cs.LO</categories><comments>Long version of the paper entitled &quot;Automated Symbolic Analysis of
  ARBAC Policies&quot; published in Proc. of 6th Int. Workshop on Security and Trust
  Management (co-located with EUROPKI'10, CRITIS'10, and ESORICS'10), Athens,
  Sept. 23-24 (2010). Also, to appear in LNCS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most widespread framework for the management of access-control
policies is Administrative Role Based Access Control (ARBAC). Several automated
analysis techniques have been proposed to help maintaining desirable security
properties of ARBAC policies. One limitation of many available techniques is
that the sets of users and roles are bounded. In this paper, we propose a
symbolic framework to overcome this difficulty. We design an automated security
analysis technique, parametric in the number of users and roles, by adapting
recent methods for model checking infinite state systems that use first-order
logic and state-of-the-art theorem proving techniques. Preliminary experiments
with a prototype implementations seem to confirm the scalability of our
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5594</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5594</id><created>2010-12-27</created><authors><author><keyname>Agrawal</keyname><forenames>Kush</forenames></author></authors><title>The Ethics of Robotics</title><categories>cs.AI cs.RO</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The three laws of Robotics first appeared together in Isaac Asimov's story
'Runaround' after being mentioned in some form or the other in previous works
by Asimov. These three laws commonly known as the three laws of robotics are
the earliest forms of depiction for the needs of ethics in Robotics. In
simplistic language Isaac Asimov is able to explain what rules a robot must
confine itself to in order to maintain societal sanctity. However, even though
they are outdated they still represent some of our innate fears which are
beginning to resurface in present day 21st Century. Our society is on the
advent of a new revolution; a revolution led by advances in Computer Science,
Artificial Intelligence &amp; Nanotechnology. Some of our advances have been so
phenomenal that we surpassed what was predicted by the Moore's law. With these
advancements comes the fear that our future may be at the mercy of these
androids. Humans today are scared that we, ourselves, might create something
which we cannot control. We may end up creating something which can not only
learn much faster than anyone of us can, but also evolve faster than what the
theory of evolution has allowed us to. The greatest fear is not only that we
might lose our jobs to these intelligent beings, but that these beings might
end up replacing us at the top of the cycle. The public hysteria has been
heightened more so by a number of cultural works which depict annihilation of
the human race by robots. Right from Frankenstein to I, Robot mass media has
also depicted such issues. This paper is an effort to understand the need for
ethics in Robotics or simply termed as Roboethics. This is achieved by the
study of artificial beings and the thought being put behind them. By the end of
the paper, however, it is concluded that there isn't a need for ethical robots
but more so ever a need for ethical roboticists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5597</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5597</id><created>2010-12-27</created><authors><author><keyname>Gur</keyname><forenames>Eran</forenames></author><author><keyname>Zalevsky</keyname><forenames>Zeev</forenames></author></authors><title>Manipulating Multistage Interconnection Networks Using Fundamental
  Arrangements</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Science and Information
  Technology (IJCSIT), Vol. 2 (6), December 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimizing interconnection networks is a prime object in switching schemes.
In this work the authors present a novel approach for obtaining a required
channel arrangement in a multi-stage interconnection network, using a new
concept - a fundamental arrangement. The fundamental arrangement is an initial
N-1 stage switch arrangement that allows obtaining any required output channel
arrangement given an input arrangement, using N/2 binary switches at each
stage. The paper demonstrates how a fundamental arrangement can be achieved and
how, once this is done, any required arrangement may be obtained within 2(N-1)
steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5625</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5625</id><created>2010-12-27</created><authors><author><keyname>Magrassi</keyname><forenames>Paolo</forenames></author></authors><title>Free and Open-Source Software is not an Emerging Property but Rather the
  Result of Studied Design</title><categories>cs.CY cs.SI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Free and open source software (FOSS) is considered by many, along with
Wikipedia, the proof of an ongoing paradigm shift from hierarchically-managed
and market-driven production of knowledge to heterarchical, collaborative and
commons-based production styles. In such perspective, it has become common
place to refer to FOSS as a manifestation of collective intelligence where
deliverables and artefacts emerge by virtue of mere cooperation, with no need
for supervising leadership. The paper argues that this assumption is based on
limited understanding of the software development process, and may lead to
wrong conclusions as to the potential of peer production. The development of a
less than trivial piece of software, irrespective of whether it be FOSS or
proprietary, is a complex cooperative effort requiring the participation of
many (often thousands of) individuals. A subset of the participants always play
the role of leading system and subsystem designers, determining architecture
and functionality; the rest of the people work &quot;underneath&quot; them in a logical,
functional sense. While new and powerful forces, including FOSS, are clearly at
work in the post-industrial, networked econ-omy, the currently ingenuous stage
of research in the field of collective intelligence and networked cooperation
must give way to a deeper level of consciousness, which requires an
understanding of the software development process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5659</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5659</id><created>2010-12-27</created><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author></authors><title>Non-negative Weighted #CSPs: An Effective Complexity Dichotomy</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a complexity dichotomy theorem for all non-negative weighted
counting Constraint Satisfaction Problems (CSP). This caps a long series of
important results on counting problems including unweighted and weighted graph
homomorphisms and the celebrated dichotomy theorem for unweighted #CSP. Our
dichotomy theorem gives a succinct criterion for tractability. If a set F of
constraint functions satisfies the criterion, then the counting CSP problem
defined by F is solvable in polynomial time; if it does not satisfy the
criterion, then the problem is #P-hard. We furthermore show that the question
of whether F satisfies the criterion is decidable in NP.
  Surprisingly, our tractability criterion is simpler than the previous
criteria for the more restricted classes of problems, although when specialized
to those cases, they are logically equivalent. Our proof mainly uses Linear
Algebra, and represents a departure from Universal Algebra, the dominant
methodology in recent years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5664</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5664</id><created>2010-12-27</created><updated>2011-09-26</updated><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>Schulz</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Sheffer</keyname><forenames>Adam</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>Csaba D.</forenames></author></authors><title>Bounds on the maximum multiplicity of some common geometric graphs</title><categories>cs.DM cs.CG</categories><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain new lower and upper bounds for the maximum multiplicity of some
weighted and, respectively, non-weighted common geometric graphs drawn on n
points in the plane in general position (with no three points collinear):
perfect matchings, spanning trees, spanning cycles (tours), and triangulations.
  (i) We present a new lower bound construction for the maximum number of
triangulations a set of n points in general position can have. In particular,
we show that a generalized double chain formed by two almost convex chains
admits {\Omega}(8.65^n) different triangulations. This improves the bound
{\Omega}(8.48^n) achieved by the double zig-zag chain configuration studied by
Aichholzer et al.
  (ii) We present a new lower bound of {\Omega}(12.00^n) for the number of
non-crossing spanning trees of the double chain composed of two convex chains.
The previous bound, {\Omega}(10.42^n), stood unchanged for more than 10 years.
  (iii) Using a recent upper bound of 30^n for the number of triangulations,
due to Sharir and Sheffer, we show that n points in the plane in general
position admit at most O(68.62^n) non-crossing spanning cycles.
  (iv) We derive lower bounds for the number of maximum and minimum weighted
geometric graphs (matchings, spanning trees, and tours). We show that the
number of shortest non-crossing tours can be exponential in n. Likewise, we
show that both the number of longest non-crossing tours and the number of
longest non-crossing perfect matchings can be exponential in n. Moreover, we
show that there are sets of n points in convex position with an exponential
number of longest non-crossing spanning trees. For points in convex position we
obtain tight bounds for the number of longest and shortest tours. We give a
combinatorial characterization of the longest tours, which leads to an O(nlog
n) time algorithm for computing them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5693</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5693</id><created>2010-12-27</created><authors><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author><author><keyname>Anderson</keyname><forenames>Brian DO</forenames></author></authors><title>On the Asymptotic Connectivity of Random Networks under the Random
  Connection Model</title><categories>cs.NI cs.IT math.IT</categories><comments>9 pages, to appear in IEEE INFOCOM 2011, Shanghai, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a network where all nodes are distributed on a unit square following
a Poisson distribution with known density $\rho$ and a pair of nodes separated
by an Euclidean distance $x$ are directly connected with probability
$g(\frac{x}{r_{\rho}})$, where $g:[0,\infty)\rightarrow[0,1]$ satisfies three
conditions: rotational invariance, non-increasing monotonicity and integral
boundedness, $r_{\rho}=\sqrt{\frac{\log\rho+b}{C\rho}}$,
$C=\int_{\Re^{2}}g(\Vert \boldsymbol{x}\Vert)d\boldsymbol{x}$ and $b$ is a
constant, independent of the event that another pair of nodes are directly
connected. In this paper, we analyze the asymptotic distribution of the number
of isolated nodes in the above network using the Chen-Stein technique and the
impact of the boundary effect on the number of isolated nodes as
$\rho\rightarrow\infty$. On that basis we derive a necessary condition for the
above network to be asymptotically almost surely connected. These results form
an important link in expanding recent results on the connectivity of the random
geometric graphs from the commonly used unit disk model to the more generic and
more practical random connection model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5695</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5695</id><created>2010-12-27</created><authors><author><keyname>Baskaran</keyname><forenames>Santhi</forenames></author><author><keyname>Thambidurai</keyname><forenames>P.</forenames></author></authors><title>Dynamic Scheduling of Skippable Periodic Tasks with Energy Efficiency in
  Weakly Hard Real-Time System</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy consumption is a critical design issue in real-time systems,
especially in battery- operated systems. Maintaining high performance, while
extending the battery life between charges is an interesting challenge for
system designers. Dynamic Voltage Scaling (DVS) allows a processor to
dynamically change speed and voltage at run time, thereby saving energy by
spreading run cycles into idle time. Knowing when to use full power and when
not, requires the cooperation of the operating system scheduler. Usually,
higher processor voltage and frequency leads to higher system throughput while
energy reduction can be obtained using lower voltage and frequency. Instead of
lowering processor voltage and frequency as much as possible, energy efficient
real-time scheduling adjusts voltage and frequency according to some
optimization criteria, such as low energy consumption or high throughput, while
it meets the timing constraints of the real-time tasks. As the quantity and
functional complexity of battery powered portable devices continues to raise,
energy efficient design of such devices has become increasingly important. Many
real-time scheduling algorithms have been developed recently to reduce energy
consumption in the portable devices that use DVS capable processors. Three
algorithms namely Red Tasks Only (RTO), Blue When Possible (BWP) and Red as
Late as Possible (RLP) are proposed in the literature to schedule the real-time
tasks in Weakly-hard real-time systems. This paper proposes optimal slack
management algorithms to make the above existing weakly hard real-time
scheduling algorithms energy efficient using DVS and DPD techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5696</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5696</id><created>2010-12-27</created><authors><author><keyname>Maneth</keyname><forenames>Sebastian</forenames></author><author><keyname>Sebastian</keyname><forenames>Tom</forenames></author></authors><title>Fast and Tiny Structural Self-Indexes for XML</title><categories>cs.DB</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML document markup is highly repetitive and therefore well compressible
using dictionary-based methods such as DAGs or grammars. In the context of
selectivity estimation, grammar-compressed trees were used before as synopsis
for structural XPath queries. Here a fully-fledged index over such grammars is
presented. The index allows to execute arbitrary tree algorithms with a
slow-down that is comparable to the space improvement. More interestingly,
certain algorithms execute much faster over the index (because no decompression
occurs). E.g., for structural XPath count queries, evaluating over the index is
faster than previous XPath implementations, often by two orders of magnitude.
The index also allows to serialize XML results (including texts) faster than
previous systems, by a factor of ca. 2-3. This is due to efficient copy
handling of grammar repetitions, and because materialization is totally
avoided. In order to compare with twig join implementations, we implemented a
materializer which writes out pre-order numbers of result nodes, and show its
competitiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5699</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5699</id><created>2010-12-28</created><updated>2011-08-23</updated><authors><author><keyname>McKague</keyname><forenames>Matthew</forenames></author></authors><title>Interactive proofs with efficient quantum prover for recursive Fourier
  sampling</title><categories>quant-ph cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the recursive Fourier sampling problem (RFS), and show that there
exists an interactive proof for RFS with an efficient classical verifier and
efficient quantum prover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5705</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5705</id><created>2010-12-28</created><authors><author><keyname>Abdullah</keyname><forenames>Wan Ahmad Tajuddin Wan</forenames></author></authors><title>Looking for plausibility</title><categories>cs.AI</categories><comments>6 pages, invited paper presented at the International Conference on
  Advanced Computer Science and Information Systems 2010 (ICACSIS2010), Bali,
  Indonesia, 20-22 November 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the interpretation of experimental data, one is actually looking for
plausible explanations. We look for a measure of plausibility, with which we
can compare different possible explanations, and which can be combined when
there are different sets of data. This is contrasted to the conventional
measure for probabilities as well as to the proposed measure of possibilities.
We define what characteristics this measure of plausibility should have.
  In getting to the conception of this measure, we explore the relation of
plausibility to abductive reasoning, and to Bayesian probabilities. We also
compare with the Dempster-Schaefer theory of evidence, which also has its own
definition for plausibility. Abduction can be associated with biconditionality
in inference rules, and this provides a platform to relate to the
Collins-Michalski theory of plausibility. Finally, using a formalism for wiring
logic onto Hopfield neural networks, we ask if this is relevant in obtaining
this measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5723</identifier>
 <datestamp>2011-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5723</id><created>2010-12-28</created><updated>2011-06-21</updated><authors><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author><author><keyname>Anderson</keyname><forenames>Brian DO</forenames></author></authors><title>Towards a Better Understanding of Large Scale Network Models</title><categories>cs.NI cs.IT math.IT</categories><comments>This is an extended version of a paper with the same title that has
  been accepted for publication at IEEE/ACM Transactions on Networking (Proof
  of Theorem 4 was not included in the paper.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connectivity and capacity are two fundamental properties of wireless
multi-hop networks. The scalability of these properties has been a primary
concern for which asymptotic analysis is a useful tool. Three related but
logically distinct network models are often considered in asymptotic analyses,
viz. the dense network model, the extended network model and the infinite
network model, which consider respectively a network deployed in a fixed finite
area with a sufficiently large node density, a network deployed in a
sufficiently large area with a fixed node density, and a network deployed in
$\Re^{2}$ with a sufficiently large node density. The infinite network model
originated from continuum percolation theory and asymptotic results obtained
from the infinite network model have often been applied to the dense and
extended networks. In this paper, through two case studies related to network
connectivity on the expected number of isolated nodes and on the vanishing of
components of finite order k&gt;1 respectively, we demonstrate some subtle but
important differences between the infinite network model and the dense and
extended network models. Therefore extra scrutiny has to be used in order for
the results obtained from the infinite network model to be applicable to the
dense and extended network models. Asymptotic results are also obtained on the
expected number of isolated nodes, the vanishingly small impact of the boundary
effect on the number of isolated nodes and the vanishing of components of
finite order k&gt;1 in the dense and extended network models using a generic
random connection model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5735</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5735</id><created>2010-12-28</created><updated>2011-05-01</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>&quot;Structuration&quot; by Intellectual Organization: The Configuration of
  Knowledge in Relations among Structural Components in Networks of Science</title><categories>cs.DL nlin.AO physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using aggregated journal-journal citation networks, the measurement of the
knowledge base in empirical systems is factor-analyzed in two cases of
interdisciplinary developments during the period 1995-2005: (i) the development
of nanotechnology in the natural sciences and (ii) the development of
communication studies as an interdiscipline between social psychology and
political science. The results are compared with a case of stable development:
the citation networks of core journals in chemistry. These citation networks
are intellectually organized by networks of expectations in the knowledge base
at the specialty (that is, above-journal) level. This &quot;structuration&quot; of
structural components (over time) can be measured as configurational
information. The latter is compared with the Shannon-type information generated
in the interactions among structural components: the difference between these
two measures provides us with a measure for the redundancy generated by the
specification of a model in the knowledge base of the system. This knowledge
base incurs (against the entropy law) to variable extents on the knowledge
infrastructures provided by the observable networks of relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5739</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5739</id><created>2010-12-28</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>van Vlijmen</keyname><forenames>S. F. M.</forenames></author></authors><title>Business Mereology: Imaginative Definitions of Insourcing and
  Outsourcing Transformations</title><categories>cs.SE</categories><acm-class>K.6.0; J.4; H.4.0; D.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outsourcing, the passing on of tasks by organizations to other organizations,
often including the personnel and means to perform these tasks, has become an
important IT-business strategy over the past decades.
  We investigate imaginative definitions for outsourcing relations and
outsourcing transformations. Abstract models of an extreme and unrealistic
simplicity are considered in order to investigate possible definitions of
outsourcing. Rather than covering all relevant practical cases an imaginative
definition of a concept provides obvious cases of its instantiation from which
more refined or liberal definitions may be derived.
  A definition of outsourcing induces to a complementary definition of
insourcing. Outsourcing and insourcing have more complex variations in which
multiple parties are involved. All of these terms both refer to state
transformations and to state descriptions pertaining to the state obtained
after such transformations. We make an attempt to disambiguate the terminology
in that respect and we make an attempt to characterize the general concept of
sourcing which captures some representative cases.
  Because mereology is the most general theory of parthood relations we coin
business mereology as the general theory in business studies which concerns the
full variety of sourcing relations and transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5751</identifier>
 <datestamp>2014-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5751</id><created>2010-12-28</created><updated>2014-06-02</updated><authors><author><keyname>Shachar</keyname><forenames>Amir</forenames></author></authors><title>Applying Semi-discrete Operators to Calculus</title><categories>cs.DM math.CA</categories><comments>arXiv admin note: text overlap with arXiv:1001.4968 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce novel semi-discrete versions of the derivative's sign and the
line integral, discuss their relation to classical Calculus, and apply them to
generalize a version of the fundamental theorem of Calculus in the plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5752</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5752</id><created>2010-12-28</created><authors><author><keyname>Mei</keyname><forenames>Shan</forenames></author><author><keyname>Quax</keyname><forenames>Rick</forenames></author><author><keyname>van de Vijver</keyname><forenames>David</forenames></author><author><keyname>Zhu</keyname><forenames>Yifan</forenames></author><author><keyname>Boukhanovsky</keyname><forenames>A. V.</forenames></author><author><keyname>Sloot</keyname><forenames>P. M. A.</forenames></author></authors><title>Increasing risk behavior can outweigh the benefits of anti-retroviral
  drug treatment on the HIV incidence among men-having-sex-with-men in
  Amsterdam</title><categories>cs.SI physics.med-ph q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transmission through contacts among MSM (men who have sex with men) is
one of the dominating contributors to HIV prevalence in industrialized
countries. In Amsterdam, the capital of the Netherlands, the MSM risk group has
been traced for decades. This has motivated studies which provide detailed
information about MSM's risk behavior statistically, psychologically and
sociologically. Despite the era of potent antiretroviral therapy, the incidence
of HIV among MSM increases. In the long term the contradictory effects of risk
behavior and effective therapy are still poorly understood. Using a previously
presented Complex Agent Network model, we describe steady and casual
partnerships to predict the HIV spreading among MSM. Behavior-related
parameters and values, inferred from studies on Amsterdam MSM, are fed into the
model; we validate the model using historical yearly incidence data.
Subsequently, we study scenarios to assess the contradictory effects of risk
behavior and effective therapy, by varying corresponding values of parameters.
Finally, we conduct quantitative analysis based on the resulting incidence
data. The simulated incidence reproduces the ACS historical incidence well and
helps to predict the HIV epidemic among MSM in Amsterdam. Our results show that
in the long run the positive influence of effective therapy can be outweighed
by an increase in risk behavior of at least 30% for MSM. Conclusion: We
recommend, based on the model predictions, that lowering risk behavior is the
prominent control mechanism of HIV incidence even in the presence of effective
therapy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5754</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5754</id><created>2010-12-28</created><authors><author><keyname>Papatheocharous</keyname><forenames>Efi</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Harris</forenames></author><author><keyname>Andreou</keyname><forenames>Andreas S.</forenames></author></authors><title>Software Effort Estimation with Ridge Regression and Evolutionary
  Attribute Selection</title><categories>cs.SE cs.AI</categories><comments>3d Artificial Intelligence Techniques in Software Engineering
  Workshop, 7 October, 2010, Larnaca, Cyprus</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software cost estimation is one of the prerequisite managerial activities
carried out at the software development initiation stages and also repeated
throughout the whole software life-cycle so that amendments to the total cost
are made. In software cost estimation typically, a selection of project
attributes is employed to produce effort estimations of the expected human
resources to deliver a software product. However, choosing the appropriate
project cost drivers in each case requires a lot of experience and knowledge on
behalf of the project manager which can only be obtained through years of
software engineering practice. A number of studies indicate that popular
methods applied in the literature for software cost estimation, such as linear
regression, are not robust enough and do not yield accurate predictions.
Recently the dual variables Ridge Regression (RR) technique has been used for
effort estimation yielding promising results. In this work we show that results
may be further improved if an AI method is used to automatically select
appropriate project cost drivers (inputs) for the technique. We propose a
hybrid approach combining RR with a Genetic Algorithm, the latter evolving the
subset of attributes for approximating effort more accurately. The proposed
hybrid cost model has been applied on a widely known high-dimensional dataset
of software project samples and the results obtained show that accuracy may be
increased if redundant attributes are eliminated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5755</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5755</id><created>2010-12-28</created><authors><author><keyname>Kosti</keyname><forenames>Makrina Viola</forenames></author><author><keyname>Mittas</keyname><forenames>Nikolaos</forenames></author><author><keyname>Angelis</keyname><forenames>Lefteris</forenames></author></authors><title>DD-EbA: An algorithm for determining the number of neighbors in cost
  estimation by analogy using distance distributions</title><categories>cs.SE cs.AI</categories><comments>3d Artificial Intelligence Tecniques in Software Engineering
  Workshop,7 October,2010, Larnaca, Cyprus</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Case Based Reasoning and particularly Estimation by Analogy, has been used in
a number of problem-solving areas, such as cost estimation. Conventional
methods, despite the lack of a sound criterion for choosing nearest projects,
were based on estimation using a fixed and predetermined number of neighbors
from the entire set of historical instances. This approach puts boundaries to
the estimation ability of such algorithms, for they do not take into
consideration that every project under estimation is unique and requires
different handling. The notion of distributions of distances together with a
distance metric for distributions help us to adapt the proposed method (we call
it DD-EbA) each time to a specific case that is to be estimated without loosing
in prediction power or computational cost. The results of this paper show that
the proposed technique achieves the above idea in a very efficient way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5774</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5774</id><created>2010-12-28</created><updated>2011-05-14</updated><authors><author><keyname>Pang</keyname><forenames>Yimin</forenames></author><author><keyname>Honold</keyname><forenames>Thomas</forenames></author></authors><title>Towards the Capacity Region of Multiplicative Linear Operator Broadcast
  Channels</title><categories>cs.IT math.AG math.IT</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research indicates that packet transmission employing random linear
network coding can be regarded as transmitting subspaces over a linear operator
channel (LOC). In this paper we propose the framework of linear operator
broadcast channels (LOBCs) to model packet broadcasting over LOCs, and we do
initial work on the capacity region of constant-dimension multiplicative
LOBCs(CMLOBCs), a generalization of broadcast erasure channels. Two fundamental
problems regarding CMLOBCs are addressed-finding necessary and sufficient
conditions for degradation and deciding whether time sharing suffices to
achieve the boundary of the capacity region in the degraded case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5783</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5783</id><created>2010-12-28</created><authors><author><keyname>Frosini</keyname><forenames>Patrizio</forenames></author><author><keyname>Landi</keyname><forenames>Claudia</forenames></author></authors><title>Uniqueness of models in persistent homology: the case of curves</title><categories>math.AT cs.CG</categories><comments>15 pages, 7 figures</comments><msc-class>55N35, 53A04, 68U05</msc-class><doi>10.1088/0266-5611/27/12/124005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider generic curves in R^2, i.e. generic C^1 functions f from S^1 to
R^2. We analyze these curves through the persistent homology groups of a
filtration induced on S^1 by f. In particular, we consider the question whether
these persistent homology groups uniquely characterize f, at least up to
re-parameterizations of S^1. We give a partially positive answer to this
question. More precisely, we prove that f=goh, where h:S^1-&gt; S^1 is a
C^1-diffeomorphism, if and only if the persistent homology groups of sof and
sog coincide, for every s belonging to the group Sigma_2 generated by
reflections in the coordinate axes. Moreover, for a smaller set of generic
functions, we show that f and g are close to each other in the max-norm (up to
re-parameterizations) if and only if, for every s belonging to Sigma_2, the
persistent Betti numbers functions of sof and sog are close to each other, with
respect to a suitable distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5803</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5803</id><created>2010-12-28</created><updated>2011-03-20</updated><authors><author><keyname>Jules</keyname><forenames>Desharnais</forenames><affiliation>D'epartement d'informatique et de g'enie logiciel, Universit'e Laval, Quebec, C</affiliation></author><author><keyname>Moeller</keyname><forenames>Bernhard</forenames><affiliation>Institute for Informatics, University of Augsburg, Germany</affiliation></author><author><keyname>Georg</keyname><forenames>Struth</forenames><affiliation>Department of Computer Science, University of Sheffield, United Kingdom</affiliation></author></authors><title>Algebraic Notions of Termination</title><categories>cs.LO</categories><comments>29 pages</comments><proxy>LMCS</proxy><acm-class>F.3.1, F.3.2, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (February
  11, 2011) lmcs:777</journal-ref><doi>10.2168/LMCS-7(1:1)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Five algebraic notions of termination are formalised, analysed and compared:
wellfoundedness or Noetherity, L\&quot;ob's formula, absence of infinite iteration,
absence of divergence and normalisation. The study is based on modal semirings,
which are additively idempotent semirings with forward and backward modal
operators. To model infinite behaviours, idempotent semirings are extended to
divergence semirings, divergence Kleene algebras and omega algebras. The
resulting notions and techniques are used in calculational proofs of classical
theorems of rewriting theory. These applications show that modal semirings are
powerful tools for reasoning algebraically about the finite and infinite
dynamics of programs and transition systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5804</identifier>
 <datestamp>2012-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5804</id><created>2010-12-28</created><updated>2012-03-30</updated><authors><author><keyname>Maknickas</keyname><forenames>Algirdas Antano</forenames></author></authors><title>Finding of k in Fagin's R. Theorem 24</title><categories>cs.CC cs.LO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Analytical generation functions of higher order logic were used for finding
of k value in Fagin's R. Theorem 24.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5813</identifier>
 <datestamp>2012-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5813</id><created>2010-12-28</created><updated>2012-12-21</updated><authors><author><keyname>Sengupta</keyname><forenames>Sourav</forenames></author><author><keyname>Ghosh</keyname><forenames>Tamal</forenames></author><author><keyname>Dan</keyname><forenames>Pranab K</forenames></author><author><keyname>Chattopadhyay</keyname><forenames>Manojit</forenames></author></authors><title>Neural Network Influence in Group Technology: A Chronological Survey and
  Critical Analysis</title><categories>cs.AI nlin.AO</categories><comments>This paper has been withdrawn by the authors. Withdrawn because some
  critical directions are wrong</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article portrays a chronological review of the influence of Artificial
Neural Network in group technology applications in the vicinity of Cellular
Manufacturing Systems. The research trend is identified and the evolvement is
captured through a critical analysis of the literature accessible from the very
beginning of its practice in the early 90's till the 2010. Analysis of the
diverse ANN approaches, spotted research pattern, comparison of the clustering
efficiencies, the solutions obtained and the tools used make this study
exclusive in its class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5815</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5815</id><created>2010-12-28</created><updated>2011-05-11</updated><authors><author><keyname>Ghosh</keyname><forenames>Tamal</forenames></author><author><keyname>Modak</keyname><forenames>Mousumi</forenames></author><author><keyname>Dan</keyname><forenames>Pranab K</forenames></author></authors><title>SAPFOCS: a metaheuristic based approach to part family formation
  problems in group technology</title><categories>cs.AI</categories><comments>10 pages; 6 figures; 12 tables</comments><journal-ref>nternational Journal of Management Science International Journal
  of Management Science and Engineering Management, 6(3): 231-240, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article deals with Part family formation problem which is believed to be
moderately complicated to be solved in polynomial time in the vicinity of Group
Technology (GT). In the past literature researchers investigated that the part
family formation techniques are principally based on production flow analysis
(PFA) which usually considers operational requirements, sequences and time.
Part Coding Analysis (PCA) is merely considered in GT which is believed to be
the proficient method to identify the part families. PCA classifies parts by
allotting them to different families based on their resemblances in: (1) design
characteristics such as shape and size, and/or (2) manufacturing
characteristics (machining requirements). A novel approach based on simulated
annealing namely SAPFOCS is adopted in this study to develop effective part
families exploiting the PCA technique. Thereafter Taguchi's orthogonal design
method is employed to solve the critical issues on the subject of parameters
selection for the proposed metaheuristic algorithm. The adopted technique is
therefore tested on 5 different datasets of size 5 {\times} 9 to 27 {\times} 9
and the obtained results are compared with C-Linkage clustering technique. The
experimental results reported that the proposed metaheuristic algorithm is
extremely effective in terms of the quality of the solution obtained and has
outperformed C-Linkage algorithm in most instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5832</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5832</id><created>2010-12-28</created><updated>2012-01-12</updated><authors><author><keyname>Morrow</keyname><forenames>W. Ross</forenames></author><author><keyname>Skerlos</keyname><forenames>Steven J.</forenames></author></authors><title>On the Existence of Bertrand-Nash Equilibrium Prices Under Logit Demand</title><categories>q-fin.GN cs.GT</categories><comments>39 Pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This article presents a proof of the existence of Bertrand-Nash equilibrium
prices with multi-product firms and under the Logit model of demand that does
not rely on restrictive assumptions on product characteristics, firm
homogeneity or symmetry, product costs, or linearity of the utility function.
The proof is based on conditions for the indirect utility function, fixed-point
equations derived from the first-order conditions, and a direct analysis of the
second-order conditions resulting in the uniqueness of profit-maximizing
prices. Several subsequent results also demonstrate that price equilibrium
under the Logit model of demand cannot adequately describe multi-product
pricing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5834</identifier>
 <datestamp>2011-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5834</id><created>2010-12-28</created><updated>2011-06-15</updated><authors><author><keyname>Omiwade</keyname><forenames>Soji</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author></authors><title>Maximum Lifetime for Data Regeneration in Wireless Sensor Networks</title><categories>cs.DC</categories><comments>This paper has been withdrawn by the authors. This paper has been
  withdrawn due to the difficulty in understanding it</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust distributed storage systems dedicated to wireless sensor networks
utilize several nodes to redundantly store sensed data so that when some
storage nodes fail, the sensed data can still be reconstructed. For the same
level of redundancy, erasure coding based approaches are known to require less
data storage space than replication methods.
  To maintain the same level of redundancy when one storage node fails, erasure
coded data can be restored onto some other storage node by having this node
download respective pieces from other live storage nodes. Previous works showed
that the benefits in using erasure coding for robust storage over replication
are made unappealing by the complication in regenerating lost data. More recent
work has, however, shown that the bandwidth for erasure coded data can be
further reduced by proposing Regenerating Coding, making erasure codes again
desirable for robust data storage.
  But none of these works on regenerating coding consider how these codes will
perform for data regeneration in wireless sensor networks. We therefore propose
an analytical model to quantify the network lifetime gains of regenerating
coding over classical schemes. We also propose a distributed algorithm, TROY,
that determines which nodes and routes to use for data regeneration. Our
analytical studies show that for certain topologies, TROY achieves maximum
network lifetime. Our evaluation studies in real sensor network traces show
that TROY achieves near optimal lifetime and performs better than baseline
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5838</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5838</id><created>2010-12-28</created><authors><author><keyname>Vlad</keyname><forenames>Serban E.</forenames></author></authors><title>Universal regular autonomous asynchronous systems: omega-limit sets,
  invariance and basins of attraction</title><categories>cs.OH</categories><comments>accepted to be published in Mathematics and its Applications/Annals
  of the Academy of the Romanian Scientists</comments><msc-class>94C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The asynchronous systems are the non-deterministic real time-binary models of
the asynchronous circuits from electrical engineering. Autonomy means that the
circuits and their models have no input. Regularity means analogies with the
dynamical systems, thus such systems may be considered to be the real time
dynamical systems with a 'vector field' {\Phi}:{0,1}^2 \rightarrow {0,1}^2.
Universality refers to the case when the state space of the system is the
greatest possible in the sense of the inclusion. The purpose of the paper is
that of defining, by analogy with the dynamical systems theory, the
{\omega}-limit sets, the invariance and the basins of attraction of the
universal regular autonomous asynchronous systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5841</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5841</id><created>2010-12-28</created><authors><author><keyname>Vlad</keyname><forenames>Serban E.</forenames></author></authors><title>The dependence on the initial states and the transitivity of the regular
  autonomous asynchronous systems</title><categories>cs.OH math.DS</categories><comments>presented at ADEM May 19-21, 2010</comments><msc-class>94C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The asynchronous systems are non-deterministic real time, binary valued
models of the asynchronous circuits from electronics. Autonomy means that there
is no input and regularity means analogies with the (real) dynamical systems.
We introduce the concepts of dependence on the initial states and of
transitivity for these systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5842</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5842</id><created>2010-12-28</created><updated>2011-01-05</updated><authors><author><keyname>Vlad</keyname><forenames>Serban E.</forenames></author></authors><title>The model of the ideal rotary element of Morita</title><categories>cs.OH</categories><comments>presented at the 12-th Symposium of Mathematics and its Applications,
  &quot;Politehnica&quot; University of Timisoara, Timisoara, 2009</comments><msc-class>94C05, 94C10, 06E30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible computing is a concept reflecting physical reversibility. Until
now several reversible systems have been investigated. In a series of papers
Kenichi Morita defines the rotary element RE, that is a reversible logic
element. By reversibility, he understands that 'every computation process can
be traced backward uniquely from the end to the start. In other words, they are
backward deterministic systems'. He shows that any reversible Turing machine
can be realized as a circuit composed of RE's only. Our purpose in this paper
is to use the asynchronous systems theory and the real time for the modeling of
the ideal rotary element
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5846</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5846</id><created>2010-12-28</created><authors><author><keyname>Hodtani</keyname><forenames>Ghosheh Abed</forenames></author></authors><title>Improvement of the Han-Kobayashi Rate Region for General Interference
  Channel-v2</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory as version 2, on 28
  Dec.2010,presented in part at ICT 2010,April,Doha,Qatar and at IT
  workshop,June 2010,Sharif Univ. of Tech</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Allowing the input auxiliary random variables to be correlated and using the
binning scheme, the Han-Kobayashi (HK) rate region for general interference
channel is partially improved. The obtained partially new achievable rate
region (i) is compared to the HK region and its simplified description, i.e.,
Chong-Motani-Garg (CMG) region, in a detailed and favorable manner, by
considering different versions of the regions, and (ii) has an interesting and
easy interpretation: as expected, any rate in our region has generally two
additional terms in comparison with the HK region (one due to the input
correlation and the other as a result of the binning scheme). Keywords.
Interference channel, Input correlation, Binning scheme
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5847</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5847</id><created>2010-12-28</created><updated>2011-01-02</updated><authors><author><keyname>Gebser</keyname><forenames>Martin</forenames></author><author><keyname>Lee</keyname><forenames>Joohyung</forenames></author><author><keyname>Lierler</keyname><forenames>Yuliya</forenames></author></authors><title>On Elementary Loops of Logic Programs</title><categories>cs.AI</categories><comments>36 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the notion of an elementary loop, Gebser and Schaub refined the theorem
on loop formulas due to Lin and Zhao by considering loop formulas of elementary
loops only. In this article, we reformulate their definition of an elementary
loop, extend it to disjunctive programs, and study several properties of
elementary loops, including how maximal elementary loops are related to minimal
unfounded sets. The results provide useful insights into the stable model
semantics in terms of elementary loops. For a nondisjunctive program, using a
graph-theoretic characterization of an elementary loop, we show that the
problem of recognizing an elementary loop is tractable. On the other hand, we
show that the corresponding problem is {\sf coNP}-complete for a disjunctive
program. Based on the notion of an elementary loop, we present the class of
Head-Elementary-loop-Free (HEF) programs, which strictly generalizes the class
of Head-Cycle-Free (HCF) programs due to Ben-Eliyahu and Dechter. Like an HCF
program, an HEF program can be turned into an equivalent nondisjunctive program
in polynomial time by shifting head atoms into the body.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5862</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5862</id><created>2010-12-28</created><updated>2011-02-16</updated><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames></author><author><keyname>Xu</keyname><forenames>Yuedong</forenames></author></authors><title>Network Non-neutrality Debate: An Economic Analysis</title><categories>cs.NI cs.GT</categories><comments>15 pages, 10 figures</comments><doi>10.1007/978-3-642-20798-3_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the economic utilities and the quality of service (QoS) in
a two-sided non-neutral market where Internet service providers (ISPs) charge
content providers (CPs) for the content delivery. We propose new models on a
two-sided market which involves a CP, an ISP, end users and advertisers. The CP
may have either the subscription revenue model (charging end users) or the
advertisement revenue model (charging advertisers). We formulate the
interactions between the ISP and the CP as a noncooperative game problem for
the former and an optimization problem for the latter. Our analysis shows that
the revenue model of the CP plays a significant role in a non-neutral Internet.
With the subscription model, both the ISP and the CP receive better (or worse)
utilities as well as QoS in the presence of side payment at the same time.
However, with the advertisement model, the side payment impedes the CP from
investing on its contents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5870</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5870</id><created>2010-12-28</created><authors><author><keyname>Mozes</keyname><forenames>Shay</forenames></author></authors><title>Multiple-Source Multiple-Sink Maximum Flow in Directed Planar Graphs in
  $O(n^{1.5} \log n)$ Time</title><categories>cs.DM cs.DS</categories><comments>to be merged with 1) Yahav Nussbaum 1012.4767 2) Philip N. Klein and
  Shay Mozes 1008.5332 3) Glencora Borradaile and Christian Wulff-Nilsen
  1008.4966</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an $O(n^{1.5} \log n)$ algorithm that, given a directed planar graph
with arc capacities, a set of source nodes and a set of sink nodes, finds a
maximum flow from the sources to the sinks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5883</identifier>
 <datestamp>2011-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5883</id><created>2010-12-29</created><updated>2011-07-11</updated><authors><author><keyname>Dokuchaev</keyname><forenames>Nikolai</forenames></author></authors><title>On sub-ideal causal smoothing filters</title><categories>math.OC cs.SY math.CA math.SP</categories><msc-class>42A38, 93E11, 93E10, 42B30</msc-class><journal-ref>Signal Processing, Volume 92, Issue 1, January 2012, Pages 219-223</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smoothing causal linear time-invariant filters are studied for continuous
time processes. The paper suggests a family of causal filters with almost
exponential damping of the energy on the higher frequencies. These filters are
sub-ideal meaning that a faster decay of the frequency response would lead to
the loss of causality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5895</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5895</id><created>2010-12-29</created><authors><author><keyname>Mihaljevic</keyname><forenames>Miodrag J.</forenames></author><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Imai</keyname><forenames>Hideki</forenames></author></authors><title>Homophonic Coding Design for Communication Systems Employing the
  Encoding-Encryption Paradigm</title><categories>cs.CR</categories><comments>16 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the design of a dedicated homophonic coding for a class
of communication systems which, in order to provide both reliability and
security, first encode the data before encrypting it, which is referred to as
the encoding-encryption paradigm. The considered systems employ
error-correction coding for reliability, a stream cipher for encryption, and
homophonic coding to enhance the protection of the key used in the stream
cipher, on which relies the security of all the system transmissions. This
paper presents a security evaluation of such systems from a computational
complexity point of view, which serves as a source for establishing dedicated
homophonic code design criteria. The security evaluation shows that the
computational complexity of recovering the secret key, given all the
information an attacker could gather during passive attacks he can mount, is
lower bounded by the complexity of the related LPN (Learning Parity in Noise)
problem in both the average and worst case. This gives guidelines to construct
a dedicated homophonic encoder which maximizes the complexity of the underlying
LPN problem for a given encoding overhead. Finally, this paper proposes a
generic homophonic coding strategy that fulfills the proposed design criteria
and thus both enhances security while minimizing the induced overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5907</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5907</id><created>2010-12-29</created><updated>2011-04-24</updated><authors><author><keyname>Pach</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Sarioz</keyname><forenames>Deniz</forenames></author></authors><title>Small (2,s)-colorable graphs without 1-obstacle representations</title><categories>cs.DM cs.CG math.CO</categories><comments>14 pages, 13 figures, ancillary to: Janos Pach and Deniz Sarioz, &quot;On
  the structure of graphs with low obstacle number&quot;, Graphs and Combinatorics,
  Volume 27, Number 3, issue entitled &quot;The Japan Conference on Computational
  Geometry and Graphs (JCCGG2009)&quot;, 465-473, DOI: 10.1007/s00373-011-1027-0,
  Springer, 2011. URL: http://www.springerlink.com/content/131r0n307h488825/</comments><msc-class>05C62, 05C85, 68R10</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An obstacle representation of a graph G is a set of points on the plane
together with a set of polygonal obstacles that determine a visibility graph
isomorphic to G. The obstacle number of G is the minimum number of obstacles
over all obstacle representations of G. Alpert, Koch, and Laison gave a
12-vertex bipartite graph and proved that its obstacle number is two. We show
that a 10-vertex induced subgraph of this graph has obstacle number two. Alpert
et al. also constructed very large graphs with vertex set consisting of a
clique and an independent set in order to show that obstacle number is an
unbounded parameter. We specify a 70-vertex graph with vertex set consisting of
a clique and an independent set, and prove that it has obstacle number greater
than one. This is an ancillary document to our article in press. We conclude by
showing that a 10-vertex graph with vertex set consisting of two cliques has
obstacle number greater than one, improving on a result therein.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5911</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5911</id><created>2010-12-29</created><updated>2011-01-11</updated><authors><author><keyname>Lingas</keyname><forenames>Andrzej</forenames></author><author><keyname>Di</keyname><forenames>Cui</forenames></author></authors><title>Near approximation of maximum weight matching through efficient weight
  reduction</title><categories>cs.DS</categories><comments>A very preliminary version has been presented at SOFSEM Student
  Forum, January 2010</comments><msc-class>68W01, 68W40, 68Q25, 68R10, 05C50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be an edge-weighted hypergraph on n vertices, m edges of size \le s,
where the edges have real weights in an interval [1,W]. We show that if we can
approximate a maximum weight matching in G within factor alpha in time T(n,m,W)
then we can find a matching of weight at least (alpha-epsilon) times the
maximum weight of a matching in G in time (epsilon^{-1})^{O(1)}max_{1\le q \le
O(epsilon \frac {log {\frac n {epsilon}}} {log epsilon^{-1}})}
max_{m_1+...m_q=m}
sum_1^qT(min{n,sm_j},m_{j},(epsilon^{-1})^{O(epsilon^{-1})}). In particular, if
we combine our result with the recent (1-\epsilon)-approximation algorithm for
maximum weight matching in graphs due to Duan and Pettie whose time complexity
has a poly-logarithmic dependence on W then we obtain a
(1-\epsilon)-approximation algorithm for maximum weight matching in graphs
running in time (epsilon^{-1})^{O(1)}(m+n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5913</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5913</id><created>2010-12-29</created><authors><author><keyname>Gayo-Avello</keyname><forenames>Daniel</forenames></author></authors><title>All liaisons are dangerous when all your friends are known to us</title><categories>cs.SI cs.CY cs.DM</categories><comments>10 pages, 5 tables</comments><acm-class>G.2.2; I.5.2; K.4.1</acm-class><doi>10.1145/1995966.1995991</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online Social Networks (OSNs) are used by millions of users worldwide.
Academically speaking, there is little doubt about the usefulness of
demographic studies conducted on OSNs and, hence, methods to label unknown
users from small labeled samples are very useful. However, from the general
public point of view, this can be a serious privacy concern. Thus, both topics
are tackled in this paper: First, a new algorithm to perform user profiling in
social networks is described, and its performance is reported and discussed.
Secondly, the experiments --conducted on information usually considered
sensitive-- reveal that by just publicizing one's contacts privacy is at risk
and, thus, measures to minimize privacy leaks due to social graph data mining
are outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5920</identifier>
 <datestamp>2011-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5920</id><created>2010-12-29</created><updated>2011-11-15</updated><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Wu</keyname><forenames>Jian-Liang</forenames></author><author><keyname>Yan</keyname><forenames>Jin</forenames></author></authors><title>Degree conditions for the partition of a graph into triangles and
  quadrilaterals</title><categories>math.CO cs.DM</categories><msc-class>05C35, 05C38, 05C70</msc-class><journal-ref>Utilitas Mathmatica 86 (2011) 341-346</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For two positive integers $r$ and $s$ with $r\geq 2s-2$, if $G$ is a graph of
order $3r+4s$ such that $d(x)+d(y)\geq 4r+4s$ for every $xy\not\in E(G)$, then
$G$ independently contains $r$ triangles and $s$ quadrilaterals, which
partially prove the El-Zahar's Conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5921</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5921</id><created>2010-12-29</created><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Guizhen</forenames></author><author><keyname>Wu</keyname><forenames>Jian-Liang</forenames></author></authors><title>Edge Coloring of Triangle-Free 1-Planar Graphs</title><categories>math.CO cs.DM</categories><comments>Please cite this paper as X. Zhang, G. Liu and J.-L. Wu. Edge
  coloring of triangle-free 1-planar graphs. Journal of Shandong University
  (Natural Science), 45(6): 15-17, 2010</comments><msc-class>05C10, 05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  it is shown that each triangle-free 1-planar graph with maximum degree
$\Delta\geq7$ can be $\Delta$-colorable by Discharging Method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5929</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5929</id><created>2010-12-29</created><authors><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames><affiliation>Brussels University, U.L.B., Brussels, Belgium</affiliation></author><author><keyname>Yomsi</keyname><forenames>Patrick Meumeu</forenames><affiliation>F.N.R.S, Belgium</affiliation></author></authors><title>Exact Schedulability Test for global-EDF Scheduling of Periodic Hard
  Real-Time Tasks on Identical Multiprocessors</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the scheduling problem of hard real-time systems
composed of periodic constrained-deadline tasks upon identical multiprocessor
platforms. We assume that tasks are scheduled by using the global-EDF
scheduler. We establish an exact schedulability test for this scheduler by
exploiting on the one hand its predictability property and by providing on the
other hand a feasibility interval so that if it is possible to find a valid
schedule for all the jobs contained in this interval, then the whole system
will be stamped feasible. In addition, we show by means of a counterexample
that the feasibility interval, and thus the schedulability test, proposed by
Leung [Leung 1989] is incorrect and we show which arguments are actually
incorrect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5933</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5933</id><created>2010-12-29</created><authors><author><keyname>Raviv</keyname><forenames>Dan</forenames></author><author><keyname>Bronstein</keyname><forenames>Alexander M.</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author><author><keyname>Kimmel</keyname><forenames>Ron</forenames></author><author><keyname>Sochen</keyname><forenames>Nir</forenames></author></authors><title>Affine-invariant diffusion geometry for the analysis of deformable 3D
  shapes</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an (equi-)affine invariant diffusion geometry by which surfaces
that go through squeeze and shear transformations can still be properly
analyzed. The definition of an affine invariant metric enables us to construct
an invariant Laplacian from which local and global geometric structures are
extracted. Applications of the proposed framework demonstrate its power in
generalizing and enriching the existing set of tools for shape analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5936</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5936</id><created>2010-12-29</created><authors><author><keyname>Raviv</keyname><forenames>Dan</forenames></author><author><keyname>Bronstein</keyname><forenames>Alexander M.</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author><author><keyname>Kimmel</keyname><forenames>Ron</forenames></author><author><keyname>Sochen</keyname><forenames>Nir</forenames></author></authors><title>Affine-invariant geodesic geometry of deformable 3D shapes</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural objects can be subject to various transformations yet still preserve
properties that we refer to as invariants. Here, we use definitions of affine
invariant arclength for surfaces in R^3 in order to extend the set of existing
non-rigid shape analysis tools. In fact, we show that by re-defining the
surface metric as its equi-affine version, the surface with its modified metric
tensor can be treated as a canonical Euclidean object on which most classical
Euclidean processing and analysis tools can be applied. The new definition of a
metric is used to extend the fast marching method technique for computing
geodesic distances on surfaces, where now, the distances are defined with
respect to an affine invariant arclength. Applications of the proposed
framework demonstrate its invariance, efficiency, and accuracy in shape
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5947</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5947</id><created>2010-12-29</created><updated>2012-10-24</updated><authors><author><keyname>Li</keyname><forenames>Kezhi</forenames></author><author><keyname>Gan</keyname><forenames>Lu</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>Orthogonal symmetric Toeplitz matrices for compressed sensing:
  Statistical isometry property</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors due to an error. It will
  be replaced with a new paper shortly</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the statistical restricted isometry property (RIP) has been
formulated to analyze the performance of deterministic sampling matrices for
compressed sensing. In this paper, we propose the usage of orthogonal symmetric
Toeplitz matrices (OSTM) for compressed sensing and study their statistical RIP
by taking advantage of Stein's method. In particular, we derive the statistical
RIP performance bound in terms of the largest value of the sampling matrix and
the sparsity level of the input signal. Based on such connections, we show that
OSTM can satisfy the statistical RIP for an overwhelming majority of signals
with given sparsity level, if a Golay sequence used to generate the OSTM. Such
sensing matrices are deterministic, Toeplitz, and efficient to implement.
Simulation results show that OSTM can offer reconstruction performance similar
to that of random matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5956</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5956</id><created>2010-12-29</created><authors><author><keyname>Moon</keyname><forenames>Sunjoo</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>A New Noncoherent Decoder for Wireless Network Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work deals with the decoding aspect of wireless network coding in the
canonical two-way relay channel where two senders exchange messages via a
common relay and they receive the mixture of two messages. One of the recent
works on wireless network coding was well explained by Katti \textit{et al.} in
SIGCOMM'07. In this work, we analyze the issue with one of their decoders when
minimum-shift keying (MSK) is employed as the modulation format, and propose a
new noncoherent decoder in the presence of two interfering signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5960</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5960</id><created>2010-12-29</created><authors><author><keyname>Moratz</keyname><forenames>Reinhard</forenames></author></authors><title>Extending Binary Qualitative Direction Calculi with a Granular Distance
  Concept: Hidden Feature Attachment</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a method for extending binary qualitative
direction calculi with adjustable granularity like OPRAm or the star calculus
with a granular distance concept. This method is similar to the concept of
extending points with an internal reference direction to get oriented points
which are the basic entities in the OPRAm calculus. Even if the spatial objects
are from a geometrical point of view infinitesimal small points locally
available reference measures are attached. In the case of OPRAm, a reference
direction is attached. The same principle works also with local reference
distances which are called elevations. The principle of attaching references
features to a point is called hidden feature attachment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5961</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5961</id><created>2010-12-29</created><updated>2010-12-30</updated><authors><author><keyname>\cColak</keyname><forenames>Serdar</forenames></author><author><keyname>Lu\cs</keyname><forenames>Hilmi</forenames></author><author><keyname>At\ilgan</keyname><forenames>Ali Rana</forenames></author></authors><title>Vulnerability of Networks Against Critical Link Failures</title><categories>physics.soc-ph cond-mat.other cs.SI</categories><comments>10 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks are known to be prone to link failures. In this paper we set out to
investigate how networks of varying connectivity patterns respond to different
link failure schemes in terms of connectivity, clustering coefficient and
shortest path lengths. We then propose a measure, which we call the
vulnerability of a network, for evaluating the extent of the damage these
failures can cause. Accepting the disconnections of node pairs as a damage
indicator, vulnerability simply represents how quickly the failure of the
critical links cause the network to undergo a specified damage extent.
Analyzing the vulnerabilities under varying damage specifications shows that
scale free networks are relatively more vulnerable for small failures, but more
efficient; whereas Erd\&quot;os-R\'enyi networks are the least vulnerable despite
lacking any clustered structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5962</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5962</id><created>2010-12-29</created><updated>2010-12-30</updated><authors><author><keyname>Hernandez-Orallo</keyname><forenames>Jose</forenames></author></authors><title>Annotated English</title><categories>cs.CL</categories><comments>Keywords: English spelling, English pronunciation, Phonetic rules,
  Diacritics, Pronunciation without Respelling, Spelling Reform. 68 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This document presents Annotated English, a system of diacritical symbols
which turns English pronunciation into a precise and unambiguous process. The
annotations are defined and located in such a way that the original English
text is not altered (not even a letter), thus allowing for a consistent reading
and learning of the English language with and without annotations. The
annotations are based on a set of general rules that make the frequency of
annotations not dramatically high. This makes the reader easily associate
annotations with exceptions, and makes it possible to shape, internalise and
consolidate some rules for the English language which otherwise are weakened by
the enormous amount of exceptions in English pronunciation. The advantages of
this annotation system are manifold. Any existing text can be annotated without
a significant increase in size. This means that we can get an annotated version
of any document or book with the same number of pages and fontsize. Since no
letter is affected, the text can be perfectly read by a person who does not
know the annotation rules, since annotations can be simply ignored. The
annotations are based on a set of rules which can be progressively learned and
recognised, even in cases where the reader has no access or time to read the
rules. This means that a reader can understand most of the annotations after
reading a few pages of Annotated English, and can take advantage from that
knowledge for any other annotated document she may read in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5994</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5994</id><created>2010-12-29</created><authors><author><keyname>Glass</keyname><forenames>Kristin</forenames></author><author><keyname>Colbaugh</keyname><forenames>Richard</forenames></author></authors><title>Toward Emerging Topic Detection for Business Intelligence: Predictive
  Analysis of `Meme' Dynamics</title><categories>cs.SI</categories><comments>AAAI 2011 Spring Symposium, Stanford University, CA. 21-23 March 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting and characterizing emerging topics of discussion and consumer
trends through analysis of Internet data is of great interest to businesses.
This paper considers the problem of monitoring the Web to spot emerging memes -
distinctive phrases which act as &quot;tracers&quot; for topics - as a means of early
detection of new topics and trends. We present a novel methodology for
predicting which memes will propagate widely, appearing in hundreds or
thousands of blog posts, and which will not, thereby enabling discovery of
significant topics. We begin by identifying measurables which should be
predictive of meme success. Interestingly, these metrics are not those
traditionally used for such prediction but instead are subtle measures of meme
dynamics. These metrics form the basis for learning a classifier which
predicts, for a given meme, whether or not it will propagate widely. The
utility of the prediction methodology is demonstrated through analysis of memes
that emerged online during the second half of 2008.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5995</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5995</id><created>2010-12-29</created><authors><author><keyname>Gupta</keyname><forenames>S. K.</forenames></author><author><keyname>Singla</keyname><forenames>Sahil</forenames></author><author><keyname>Khandelwal</keyname><forenames>Akash</forenames></author><author><keyname>Tiwari</keyname><forenames>Apurv</forenames></author><author><keyname>Srilekha</keyname></author></authors><title>Exhaustive Verification of Weak Reconstruction For Self Complementary
  Graphs</title><categories>cs.DM cs.DS</categories><comments>9 pages, 4 figures, Submitted to Special Issue of Cochin in Discrete
  Mathematics</comments><journal-ref>Presented as a poster in ICRTGC 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an exhaustive approach for verification of the weak
reconstruction of Self Complementary Graphs up to 17 vertices. It describes the
general problem of the Reconstruction Conjecture, explaining the complexity
involved in checking deck-isomorphism between two graphs. In order to improve
the computation time, various pruning techniques have been employed to reduce
the number of graph-isomorphism comparisons. These techniques offer great help
in proceeding with a reconstructive approach. An analysis of the numbers
involved is provided, along with the various limitations of this approach. A
list enumerating the number of SC graphs up till 101 vertices is also appended.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.5997</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.5997</id><created>2010-12-29</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Ansari</keyname><forenames>Nirwan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Walid</keyname><forenames>Anwar I.</forenames></author></authors><title>Protection Over Asymmetric Channels, S-MATE: Secure Multipath Adaptive
  Traffic Engineering</title><categories>cs.IT cs.CR cs.NI math.IT</categories><comments>4 figures, 9 pages, journal paper of S-MATE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several approaches have been proposed to the problem of provisioning traffic
engineering between core network nodes in Internet Service Provider (ISP)
networks. Such approaches aim to minimize network delay, increase capacity, and
enhance security services between two core (relay) network nodes, an ingress
node and an egress node. MATE (Multipath Adaptive Traffic Engineering) has been
proposed for multipath adaptive traffic engineering between an ingress node
(source) and an egress node (destination) to distribute the network flow among
multiple disjoint paths. Its novel idea is to avoid network congestion and
attacks that might exist in edge and node disjoint paths between two core
network nodes.
  This paper proposes protection schemes over asymmetric channels. Precisely,
the paper aims to develop an adaptive, robust, and reliable traffic engineering
scheme to improve performance and reliability of communication networks. This
scheme will also provision Quality of Server (QoS) and protection of traffic
engineering to maximize network efficiency. Specifically, S-MATE (secure MATE)
is proposed to protect the network traffic between two core nodes (routers,
switches, etc.) in a cloud network. S-MATE secures against a single link
attack/failure by adding redundancy in one of the operational redundant paths
between the sender and receiver nodes. It is also extended to secure against
multiple attacked links. The proposed scheme can be applied to secure core
networks such as optical and IP networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.6009</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.6009</id><created>2010-12-29</created><authors><author><keyname>Sembiring</keyname><forenames>Rahmat Widia</forenames></author><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author></authors><title>Cluster Evaluation of Density Based Subspace Clustering</title><categories>cs.DB</categories><comments>6 pages, 15 figures</comments><journal-ref>Journal of Computing, Volume 2, Issue 11, November 2010, ISSN
  2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering real world data often faced with curse of dimensionality, where
real world data often consist of many dimensions. Multidimensional data
clustering evaluation can be done through a density-based approach. Density
approaches based on the paradigm introduced by DBSCAN clustering. In this
approach, density of each object neighbours with MinPoints will be calculated.
Cluster change will occur in accordance with changes in density of each object
neighbours. The neighbours of each object typically determined using a distance
function, for example the Euclidean distance. In this paper SUBCLU, FIRES and
INSCY methods will be applied to clustering 6x1595 dimension synthetic
datasets. IO Entropy, F1 Measure, coverage, accurate and time consumption used
as evaluation performance parameters. Evaluation results showed SUBCLU method
requires considerable time to process subspace clustering; however, its value
coverage is better. Meanwhile INSCY method is better for accuracy comparing
with two other methods, although consequence time calculation was longer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.6012</identifier>
 <datestamp>2012-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.6012</id><created>2010-12-29</created><updated>2012-11-25</updated><authors><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author><author><keyname>Wigger</keyname><forenames>Michele</forenames></author></authors><title>On the Capacity of the Discrete Memoryless Broadcast Channel with
  Feedback</title><categories>cs.IT math.IT</categories><comments>Accepted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A coding scheme for the discrete memoryless broadcast channel with
{noiseless, noisy, generalized} feedback is proposed, and the associated
achievable region derived. The scheme is based on a block-Markov strategy
combining the Marton scheme and a lossy version of the Gray-Wyner scheme with
side-information. In each block the transmitter sends fresh data and update
information that allows the receivers to improve the channel outputs observed
in the previous block. For a generalization of Dueck's broadcast channel our
scheme achieves the noiseless-feedback capacity, which is strictly larger than
the no-feedback capacity. For a generalization of Blackwell's channel and when
the feedback is noiseless our new scheme achieves rate points that are outside
the no-feedback capacity region. It follows by a simple continuity argument
that for both these channels and when the feedback noise is sufficiently low,
our scheme improves on the no-feedback capacity even when the feedback is
noisy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.6018</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.6018</id><created>2010-12-29</created><authors><author><keyname>Tenc&#xe9;</keyname><forenames>Fabien</forenames><affiliation>LISYC</affiliation></author><author><keyname>Buche</keyname><forenames>C&#xe9;dric</forenames><affiliation>LISYC</affiliation></author><author><keyname>De Loor</keyname><forenames>Pierre</forenames><affiliation>LISYC</affiliation></author><author><keyname>Marc</keyname><forenames>Olivier</forenames><affiliation>LISYC</affiliation></author></authors><title>Learning a Representation of a Believable Virtual Character's
  Environment with an Imitation Algorithm</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>GAMEON-ARABIA'10, Egypt (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In video games, virtual characters' decision systems often use a simplified
representation of the world. To increase both their autonomy and believability
we want those characters to be able to learn this representation from human
players. We propose to use a model called growing neural gas to learn by
imitation the topology of the environment. The implementation of the model, the
modifications and the parameters we used are detailed. Then, the quality of the
learned representations and their evolution during the learning are studied
using different measures. Improvements for the growing neural gas to give more
information to the character's model are given in the conclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1012.6035</identifier>
 <datestamp>2011-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1012.6035</id><created>2010-12-29</created><updated>2011-12-03</updated><authors><author><keyname>Miszczak</keyname><forenames>J. A.</forenames></author></authors><title>Models of quantum computation and quantum programming languages</title><categories>cs.PL quant-ph</categories><comments>23 pages, 10 figures, 9 listings</comments><journal-ref>Bull. Pol. Acad. Sci.-Tech. Sci., Vol. 59, No. 3 (2011), pp.
  305-324</journal-ref><doi>10.2478/v10175-011-0039-5</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The goal of the presented paper is to provide an introduction to the basic
computational models used in quantum information theory. We review various
models of quantum Turing machine, quantum circuits and quantum random access
machine (QRAM) along with their classical counterparts. We also provide an
introduction to quantum programming languages, which are developed using the
QRAM model. We review the syntax of several existing quantum programming
languages and discuss their features and limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0011</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0011</id><created>2010-12-29</created><authors><author><keyname>Dua</keyname><forenames>Aditya</forenames></author><author><keyname>Bambos</keyname><forenames>Nicholas</forenames></author></authors><title>Packet Scheduling in Switches with Target Outflow Profiles</title><categories>cs.NI cs.MM cs.SY</categories><comments>33 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of packet scheduling for traffic streams with target outflow
profiles traversing input queued switches is formulated in this paper. Target
outflow profiles specify the desirable inter-departure times of packets leaving
the switch from each traffic stream. The goal of the switch scheduler is to
dynamically select service configurations of the switch, so that actual outflow
streams (&quot;pulled&quot; through the switch) adhere to their desired target profiles
as accurately as possible. Dynamic service controls (schedules) are developed
to minimize deviation of actual outflow streams from their targets and suppress
stream &quot;distortion&quot;. Using appropriately selected subsets of service
configurations of the switch, efficient schedules are designed, which deliver
high performance at relatively low complexity. Some of these schedules are
provably shown to achieve 100% pull-throughput. Moreover, simulations
demonstrate that for even substantial contention of streams through the switch,
due to stringent/intense target outflow profiles, the proposed schedules
achieve closely their target profiles and suppress stream distortion. The
switch model investigated here deviates from the classical switching paradigm.
In the latter, the goal of packet scheduling is primarily to &quot;push&quot; as much
traffic load through the switch as possible, while controlling delay to
traverse the switch and keeping congestion/backlogs from exploding. In the
model presented here, however, the goal of packet scheduling is to &quot;pull&quot;
traffic streams through the switch, maintaining desirable (target) outflow
profiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0021</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0021</id><created>2010-12-29</created><authors><author><keyname>Paluch</keyname><forenames>Katarzyna</forenames></author></authors><title>Popular b-matchings</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that each member of a set of agents has a preference list of a subset
of houses, possibly involving ties and each agent and house has their capacity
denoting the maximum number of correspondingly agents/houses that can be
matched to him/her/it. We want to find a matching $M$, for which there is no
other matching $M'$ such that more agents prefer $M'$ to $M$ than $M$ to $M'$.
(What it means that an agent prefers one matching to the other is explained in
the paper.) Popular matchings have been studied quite extensively, especially
in the one-to-one setting. We provide a characterization of popular b-matchings
for two defintions of popularity, show some $NP$-hardness results and for
certain versions describe polynomial algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0036</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0036</id><created>2010-12-30</created><authors><author><keyname>Charlier</keyname><forenames>Emilie</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>The growth function of S-recognizable sets</title><categories>cs.FL cs.DM math.NT</categories><comments>12 pages</comments><msc-class>68R01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set $X\subseteq\mathbb N$ is S-recognizable for an abstract numeration
system S if the set $\rep_S(X)$ of its representations is accepted by a finite
automaton. We show that the growth function of an S-recognizable set is always
either $\Theta((\log(n))^{c-df}n^f)$ where $c,d\in\mathbb N$ and $f\ge 1$, or
$\Theta(n^r \theta^{\Theta(n^q)})$, where $r,q\in\mathbb Q$ with $q\le 1$. If
the number of words of length n in the numeration language is bounded by a
polynomial, then the growth function of an S-recognizable set is $\Theta(n^r)$,
where $r\in \mathbb Q$ with $r\ge 1$. Furthermore, for every $r\in \mathbb Q$
with $r\ge 1$, we can provide an abstract numeration system S built on a
polynomial language and an S-recognizable set such that the growth function of
X is $\Theta(n^r)$. For all positive integers k and l, we can also provide an
abstract numeration system S built on a exponential language and an
S-recognizable set such that the growth function of X is $\Theta((\log(n))^k
n^l)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0039</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0039</id><created>2010-12-30</created><authors><author><keyname>Zhang</keyname><forenames>Jiapu</forenames></author></authors><title>A Brief Review on Results and Computational Algorithms for Minimizing
  the Lennard-Jones Potential</title><categories>physics.comp-ph cs.DS physics.chem-ph</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The Lennard-Jones (LJ) Potential Energy Problem is to construct the most
stable form of $N$ atoms of a molecule with the minimal LJ potential energy.
This problem has a simple mathematical form $f(x) = 4\sum_{i=1}^N
\sum_{j=1,j&lt;i}^N (\frac{1}{\tau_{ij}^6} - \frac{1}{\tau_{ij}^3} {subject to}
x\in \mathbb{R}^n$, where $\tau_{ij} = (x_{3i-2} - x_{3j-2})^2 + (x_{3i-1} -
x_{3j-1})^2 + (x_{3i} - x_{3j})^2$, $(x_{3i-2},x_{3i-1},x_{3i})$ is the
coordinates of atom $i$ in $\mathbb{R}^3$, $i,j=1,2,...,N(\geq 2 \quad
\text{integer})$, and $n=3N$; however it is a challenging and difficult problem
for many optimization methods when $N$ is larger. In this paper, a brief review
and a bibliography of important computational algorithms on minimizing the LJ
potential energy are introduced in Sections 1 and 2. Section 3 of this paper
illuminates many beautiful graphs (gotten by the author nearly 10 years ago)
for the three dimensional structures of molecules with minimal LJ potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0056</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0056</id><created>2010-12-30</created><authors><author><keyname>Singh</keyname><forenames>Jagbeer</forenames></author></authors><title>An Algorithm to Reduce the Time Complexity of Earliest Deadline First
  Scheduling Algorithm in Real-Time System</title><categories>cs.DS</categories><comments>(Nine)Pages, (Two)figure</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper I have study to Reduce the time Complexity of Earliest Deadline
First (EDF), a global scheduling scheme for Earliest Deadline First in Real
Time System tasks on a Multiprocessors system. Several admission control
algorithms for Earliest Deadline First (EDF) are presented, both for hard and
soft real-time tasks. The average performance of these admission control
algorithms is compared with the performance of known partitioning schemes. I
have applied some modification to the global Earliest Deadline First (EDF)
algorithms to decrease the number of task migration and also to add
predictability to its behavior. The Aim of this work is to provide a
sensitivity analysis for task deadline context of multiprocessor system by
using a new approach of EFDF (Earliest Feasible Deadline First) algorithm. In
order to decrease the number of migrations we prevent a job from moving one
processor to another processor if it is among the m higher priority jobs.
Therefore, a job will continue its execution on the same processor if possible
(processor affinity). The result of these comparisons outlines some situations
where one scheme is preferable over the other. Partitioning schemes are better
suited for hard real-time systems, while a global scheme is preferable for soft
real-time systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0057</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0057</id><created>2010-12-30</created><authors><author><keyname>Filiol</keyname><forenames>Eric</forenames></author></authors><title>PERSEUS Technology: New Trends in Information and Communication Security</title><categories>cs.CR</categories><comments>19 pages, 2 figures. Presented at the iAWACS 2010 conference in
  Paris, May 2010</comments><msc-class>94A60, 68P25</msc-class><acm-class>D.4.6; E.3; E.4; K.4.1; K.4.4; K.5.2; K.6.5</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Using cryptography to protect information and communication has bacically two
major drawbacks. First, the specific entropy profile of encrypted data makes
their detection very easy. Second, the use of cryptography can be more or less
regulated, not to say forbidden, according to the countries. If the right to
freely protect our personal and private data is a fundamental right, it must
not hinder the action of Nation States with respect to National security.
Allowing encryption to citizens holds for bad guys as well.
  In this paper we propose a new approach in information and communication
security that may solve all these issues, thus representing a rather
interesting trade-off between apparently opposite security needs. We introduce
the concept of scalable security based on computationnally hard problem of
coding theory with the PERSEUS technology.
  The core idea is to encode date with variable punctured convolutional codes
in such a way that any cryptanalytic attempt will require a time-consuming
encoder reconstruction in order to decode. By adding noise in a suitable way,
that reconstruction becomes untractable in practice except for Intelligence
services that however must use supercomputers during a significant, scalable
amount of time. Hence it limits naturally any will to unduly performs such
attacks (eg. against citizens' privacy).
  On the users' side, encoder and noise parameters are first exchanged through
an initial, short HTTPS session. The principles behind that approach have been
mathematically validated in 1997 and 2007. We present the PERSEUS library we
have developed under the triple GPL/LGPL/MPL licences. This library can be used
to protect any kind of data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0064</identifier>
 <datestamp>2013-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0064</id><created>2010-12-30</created><updated>2012-11-13</updated><authors><author><keyname>Tsurumaru</keyname><forenames>Toyohiro</forenames></author><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Dual universality of hash functions and its applications to quantum
  cryptography</title><categories>quant-ph cs.IT math.IT</categories><comments>18 pages, 2 figures; revised argument concerning the relation with
  the \delta-biased family</comments><journal-ref>IEEE Transactions on Information Theory, Volume 59, Issue 7, 4700
  - 4717 (2013)</journal-ref><doi>10.1109/TIT.2013.2250576</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the concept of dual universality of hash
functions and present its applications to quantum cryptography. We begin by
establishing the one-to-one correspondence between a linear function family
{\cal F} and a code family {\cal C}, and thereby defining \varepsilon-almost
dual universal_2 hash functions, as a generalization of the conventional
universal_2 hash functions. Then we show that this generalized (and thus
broader) class of hash functions is in fact sufficient for the security of
quantum cryptography. This result can be explained in two different formalisms.
First, by noting its relation to the \delta-biased family introduced by Dodis
and Smith, we demonstrate that Renner's two-universal hashing lemma is
generalized to our class of hash functions. Next, we prove that the proof
technique by Shor and Preskill can be applied to quantum key distribution (QKD)
systems that use our generalized class of hash functions for privacy
amplification. While Shor-Preskill formalism requires an implementer of a QKD
system to explicitly construct a linear code of the Calderbank-Shor-Steane
type, this result removes the existing difficulty of the construction a linear
code of CSS code by replacing it by the combination of an ordinary classical
error correcting code and our proposed hash function. We also show that a
similar result applies to the quantum wire-tap channel. Finally we compare our
results in the two formalisms and show that, in typical QKD scenarios, the
Shor-Preskill--type argument gives better security bounds in terms of the trace
distance and Holevo information, than the method based on the \delta-biased
family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0076</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0076</id><created>2010-12-30</created><authors><author><keyname>Chandra</keyname><forenames>Shekhar</forenames></author><author><keyname>Svalbe</keyname><forenames>Imants</forenames></author><author><keyname>Guedon</keyname><forenames>Jeanpierre</forenames></author><author><keyname>Kingston</keyname><forenames>Andrew</forenames></author><author><keyname>Normand</keyname><forenames>Nicolas</forenames></author></authors><title>Recovering Missing Slices of the Discrete Fourier Transform using Ghosts</title><categories>math-ph cs.DM math.CO math.MP</categories><comments>10 pages, 18 figures (submitted to IEEE Image Proc.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Discrete Fourier Transform (DFT) underpins the solution to many inverse
problems commonly possessing missing or un-measured frequency information. This
incomplete coverage of Fourier space always produces systematic artefacts
called Ghosts. In this paper, a fast and exact method for de-convolving cyclic
artefacts caused by missing slices of the DFT is presented. The slices
discussed here originate from the exact partitioning of DFT space, under the
projective Discrete Radon Transform, called the Discrete Fourier Slice Theorem.
The method has a computational complexity of O(n log2 n) (where n = N^2) and is
constructed from a new Finite Ghost theory. This theory is also shown to unify
several aspects of work done on Ghosts over the past three decades. The paper
concludes with a significant application to fast, exact, non-iterative image
reconstruction from sets of discrete slices obtained for a limited range of
projection angles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0080</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0080</id><created>2010-12-30</created><updated>2011-01-09</updated><authors><author><keyname>Kishiue</keyname><forenames>Naoya</forenames></author><author><keyname>Nakahara</keyname><forenames>Masaya</forenames></author><author><keyname>Maruyama</keyname><forenames>Shirou</forenames></author><author><keyname>Sakamoto</keyname><forenames>Hiroshi</forenames></author></authors><title>A Searchable Compressed Edit-Sensitive Parsing</title><categories>cs.DS</categories><comments>16 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Practical data structures for the edit-sensitive parsing (ESP) are proposed.
Given a string S, its ESP tree is equivalent to a context-free grammar G
generating just S, which is represented by a DAG. Using the succinct data
structures for trees and permutations, G is decomposed to two LOUDS bit strings
and single array in (1+\epsilon)n\log n+4n+o(n) bits for any 0&lt;\epsilon &lt;1 and
the number n of variables in G. The time to count occurrences of P in S is in
O(\frac{1}{\epsilon}(m\log n+occ_c(\log m\log u)), whereas m = |P|, u = |S|,
and occ_c is the number of occurrences of a maximal common subtree in ESPs of P
and S. The efficiency of the proposed index is evaluated by the experiments
conducted on several benchmarks complying with the other compressed indexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0082</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0082</id><created>2010-12-30</created><authors><author><keyname>Vityaev</keyname><forenames>Evgenii</forenames></author><author><keyname>Kovalerchuk</keyname><forenames>Boris</forenames></author><author><keyname>Perlovsky</keyname><forenames>Leonid</forenames></author><author><keyname>Smerdov</keyname><forenames>Stanislav</forenames></author></authors><title>Probabilistic Dynamic Logic of Phenomena and Cognition</title><categories>cs.LO</categories><comments>6 pages, WCCI 2010 IEEE World Congress on Computational Intelligence
  July, 18-23, 2010 - CCIB, Barcelona, Spain, IJCNN, IEEE Catalog Number:
  CFP1OUS-DVD, ISBN: 978-1-4244-6917-8, pp. 3361-3366</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The purpose of this paper is to develop further the main concepts of
Phenomena Dynamic Logic (P-DL) and Cognitive Dynamic Logic (C-DL), presented in
the previous paper. The specific character of these logics is in matching
vagueness or fuzziness of similarity measures to the uncertainty of models.
These logics are based on the following fundamental notions: generality
relation, uncertainty relation, simplicity relation, similarity maximization
problem with empirical content and enhancement (learning) operator. We develop
these notions in terms of logic and probability and developed a Probabilistic
Dynamic Logic of Phenomena and Cognition (P-DL-PC) that relates to the scope of
probabilistic models of brain. In our research the effectiveness of suggested
formalization is demonstrated by approximation of the expert model of breast
cancer diagnostic decisions. The P-DL-PC logic was previously successfully
applied to solving many practical tasks and also for modelling of some
cognitive processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0085</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0085</id><created>2010-12-30</created><updated>2011-05-07</updated><authors><author><keyname>Appuswamy</keyname><forenames>Rathinakumar</forenames></author><author><keyname>Franceschetti</keyname><forenames>Massimo</forenames></author><author><keyname>Karamchandani</keyname><forenames>Nikhil</forenames></author><author><keyname>Zeger</keyname><forenames>Kenneth</forenames></author></authors><title>Linear Codes, Target Function Classes, and Network Computing Capacity</title><categories>cs.IT cs.DC math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the use of linear codes for network computing in single-receiver
networks with various classes of target functions of the source messages. Such
classes include reducible, injective, semi-injective, and linear target
functions over finite fields. Computing capacity bounds and achievability are
given with respect to these target function classes for network codes that use
routing, linear coding, or nonlinear coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0091</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0091</id><created>2010-12-30</created><authors><author><keyname>Schubert</keyname><forenames>Gerald</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Fehske</keyname><forenames>Holger</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>Parallel sparse matrix-vector multiplication as a test case for hybrid
  MPI+OpenMP programming</title><categories>cs.PF</categories><comments>12 pages, 6 figures</comments><doi>10.1109/IPDPS.2011.332</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We evaluate optimized parallel sparse matrix-vector operations for two
representative application areas on widespread multicore-based cluster
configurations. First the single-socket baseline performance is analyzed and
modeled with respect to basic architectural properties of standard multicore
chips. Going beyond the single node, parallel sparse matrix-vector operations
often suffer from an unfavorable communication to computation ratio. Starting
from the observation that nonblocking MPI is not able to hide communication
cost using standard MPI implementations, we demonstrate that explicit overlap
of communication and computation can be achieved by using a dedicated
communication thread, which may run on a virtual core. We compare our approach
to pure MPI and the widely used &quot;vector-like&quot; hybrid programming strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0093</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0093</id><created>2010-12-30</created><authors><author><keyname>Wittmann</keyname><forenames>Markus</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author></authors><title>Optimizing ccNUMA locality for task-parallel execution under OpenMP and
  TBB on multicore-based systems</title><categories>cs.DC</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Task parallelism as employed by the OpenMP task construct or some Intel
Threading Building Blocks (TBB) components, although ideal for tackling
irregular problems or typical producer/consumer schemes, bears some potential
for performance bottlenecks if locality of data access is important, which is
typically the case for memory-bound code on ccNUMA systems. We present a thin
software layer ameliorates adverse effects of dynamic task distribution by
sorting tasks into locality queues, each of which is preferably processed by
threads that belong to the same locality domain. Dynamic scheduling is fully
preserved inside each domain, and is preferred over possible load imbalance
even if nonlocal access is required, making this strategy well-suited for
typical multicore-mutisocket systems. The effectiveness of the approach is
demonstrated by using a blocked six-point stencil solver as a toy model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0104</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0104</id><created>2010-12-30</created><authors><author><keyname>K</keyname><forenames>Anjan</forenames></author><author><keyname>Abraham</keyname><forenames>Jibi</forenames></author><author><keyname>Jadhav</keyname><forenames>Mamatha</forenames><suffix>V</suffix></author></authors><title>Design of Transport Layer Based Hybrid Covert Channel Detection Engine</title><categories>cs.CR</categories><comments>8 pages, 4 figures, Journal</comments><doi>10.5121/ijasuc.2010.1409</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Computer network is unpredictable due to information warfare and is prone to
various attacks. Such attacks on network compromise the most important
attribute, the privacy. Most of such attacks are devised using special
communication channel called &quot;Covert Channel&quot;. The word &quot;Covert&quot; stands for
hidden or non-transparent. Network Covert Channel is a concealed communication
path within legitimate network communication that clearly violates security
policies laid down. The non-transparency in covert channel is also referred to
as trapdoor. A trapdoor is unintended design within legitimate communication
whose motto is to leak information. Subliminal channel, a variant of covert
channel works similarly except that the trapdoor is set in a cryptographic
algorithm. A composition of covert channel with subliminal channel is the
&quot;Hybrid Covert Channel&quot;. Hybrid covert channel is homogenous or heterogeneous
mixture of two or more variants of covert channels either active at same
instance or at different instances of time. Detecting such malicious channel
activity plays a vital role in removing threat to the legitimate network. In
this paper, we present a study of multi-trapdoor covert channels and introduce
design of a new detection engine for hybrid covert channel in transport layer
visualized in TCP and SSL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0105</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0105</id><created>2010-12-30</created><authors><author><keyname>Espa&#xf1;a</keyname><forenames>Sergio</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Arturo</forenames></author><author><keyname>Pastor</keyname><forenames>&#xd3;scar</forenames></author><author><keyname>Ruiz</keyname><forenames>Marcela</forenames></author></authors><title>Integration of Communication Analysis and the OO Method: Manual
  derivation of the Conceptual Model. The SuperStationery Co. lab demo</title><categories>cs.SE</categories><comments>100 pages, 82 figures</comments><report-no>ProS-TR-2011-01</report-no><msc-class>68N01</msc-class><acm-class>D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document presents a lab demo that exemplifies the manual derivation of
an OO Method conceptual model, taking as input a Communication Analysis
requirements model. In addition, it is described how the conceptual model is
created in the OLIVANOVA Modeler tool. The lab demo corresponds to part of the
business processes of a fictional small and medium enterprise named
SuperStationery Co. This company provides stationery and office material to its
clients. The company acts as a as intermediary: the company has a catalogue of
products that are bought from suppliers and sold to clients. This lab demo,
besides illustrating the derivation technique, demonstrates that the technique
is feasible in practice. Also, the results of this lab demo provide a valuable
feedback in order to improve the derivation technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0112</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0112</id><created>2010-12-30</created><updated>2013-04-01</updated><authors><author><keyname>Higuchi</keyname><forenames>Kojiro</forenames><affiliation>Tohoku University</affiliation></author><author><keyname>Pauly</keyname><forenames>Arno</forenames><affiliation>University of Cambridge</affiliation></author></authors><title>The degree structure of Weihrauch-reducibility</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 2 (April 2,
  2013) lmcs:1124</journal-ref><doi>10.2168/LMCS-9(2:2)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We answer a question by Vasco Brattka and Guido Gherardi by proving that the
Weihrauch-lattice is not a Brouwer algebra. The computable Weihrauch-lattice is
also not a Heyting algebra, but the continuous Weihrauch-lattice is. We further
investigate the existence of infinite infima and suprema, as well as embeddings
of the Medvedev-degrees into the Weihrauch-degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0114</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0114</id><created>2010-12-30</created><updated>2013-07-31</updated><authors><author><keyname>Toth</keyname><forenames>Herbert</forenames></author></authors><title>Behavioral subtyping through typed assertions</title><categories>cs.SE cs.LO</categories><comments>21 pages, 7 Tables</comments><msc-class>68N30</msc-class><acm-class>D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a critical discussion of popular approaches to ensure the
Liskov substitution principle in class hierarchies (e.g. Design by
Contract(TM), specification inheritance). It will be shown that they have some
deficiencies which are due to the way how effective constraints are calculated
for subclass methods. A new mechanism, called client conformance, is introduced
that takes the client's view on the program state into account more properly:
The client's static type determines the context in which reasoning about
program state is to be done. This is the context to which the runtime assertion
checking (RAC) of server methods must be adapted appropriately. In a stepwise
argumentation we show the improvements for RAC that can be reached following
this approach in a natural way, preserving the percolation pattern mechanism:
Clients will neither be confronted with unsafe or surprising executions, nor
with surprising failures of server methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0115</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0115</id><created>2010-12-30</created><authors><author><keyname>Kallas</keyname><forenames>Jakub</forenames></author><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author><author><keyname>Lauser</keyname><forenames>Alexander</forenames></author></authors><title>First-order Fragments with Successor over Infinite Words</title><categories>cs.FL cs.LO</categories><comments>Presented at STACS 2011</comments><report-no>Technical report no. 2010/08, Formal Methods in Computer Science
  (FMI), University of Stuttgart, Germany</report-no><acm-class>F.4.1; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider fragments of first-order logic and as models we allow finite and
infinite words simultaneously. The only binary relations apart from equality
are order comparison &lt; and the successor predicate +1. We give
characterizations of the fragments Sigma2 = Sigma2[&lt;,+1] and FO2 = FO2[&lt;,+1] in
terms of algebraic and topological properties. To this end we introduce the
factor topology over infinite words. It turns out that a language L is in the
intersection of FO2 and Sigma2 if and only if L is the interior of an FO2
language. Symmetrically, a language is in the intersection of FO2 and Pi2 if
and only if it is the topological closure of an FO2 language. The fragment
Delta2, which by definition is the intersection of Sigma2 and Pi2 contains
exactly the clopen languages in FO2. In particular, over infinite words Delta2
is a strict subclass of FO2. Our characterizations yield decidability of the
membership problem for all these fragments over finite and infinite words; and
as a corollary we also obtain decidability for infinite words. Moreover, we
give a new decidable algebraic characterization of dot-depth 3/2 over finite
words. Decidability of dot-depth 3/2 over finite words was first shown by
Gla{\ss}er and Schmitz in STACS 2000, and decidability of the membership
problem for FO2 over infinite words was shown 1998 by Wilke in his habilitation
thesis whereas decidability of Sigma2 over infinite words was not known before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0129</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0129</id><created>2010-12-30</created><authors><author><keyname>Morton</keyname><forenames>Jason</forenames></author></authors><title>Pfaffian Circuits</title><categories>math.CO cs.CC quant-ph</categories><comments>33 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It remains an open question whether the apparent additional power of quantum
computation derives inherently from quantum mechanics, or merely from the
flexibility obtained by &quot;lifting&quot; Boolean functions to linear operators and
evaluating their composition cleverly. Holographic algorithms provide a useful
avenue for exploring this question. We describe a new, simplified construction
of holographic algorithms in terms of Pfaffian circuits. Novel proofs of some
key results are provided, and we extend the approach of [34] to nonsymmetric,
odd, and homogenized signatures, circuits, and various models of execution
flow. This shows our approach is as powerful as the matchgate approach.
Holographic algorithms provide in general $O(n^{\omega_p})$ time algorithms,
where $\omega_p$ is the order of Pfaffian evaluation in the ring of interest
(with $1.19 \leq \omega_p \leq 3$ depending on the ring) and $n$ is the number
of inclusions of variables into clauses. Our approach often requires just the
evaluation of an $n \times n$ Pfaffian, and at most needs an additional two
rows per gate, whereas the matchgate approach is quartic in the arity of the
largest gate. We give examples (even before any change of basis) including
efficient algorithms for certain lattice path problems and an $O(n^{\omega_p})$
algorithm for evaluation of Tutte polynomials of lattice path matroids. Finally
we comment on some of the geometric considerations in analyzing Pfaffian
circuits under arbitrary basis change. Connections are made to the sum-product
algorithm, classical simulation of quantum computation, and SLOCC equivalent
entangled states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0133</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0133</id><created>2010-12-30</created><updated>2011-06-30</updated><authors><author><keyname>Rashmi</keyname><forenames>K. V.</forenames></author><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Enabling Node Repair in Any Erasure Code for Distributed Storage</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>IEEE International Symposium on Information Theory (ISIT) 2011 (to be
  presented)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Erasure codes are an efficient means of storing data across a network in
comparison to data replication, as they tend to reduce the amount of data
stored in the network and offer increased resilience in the presence of node
failures. The codes perform poorly though, when repair of a failed node is
called for, as they typically require the entire file to be downloaded to
repair a failed node. A new class of erasure codes, termed as regenerating
codes were recently introduced, that do much better in this respect. However,
given the variety of efficient erasure codes available in the literature, there
is considerable interest in the construction of coding schemes that would
enable traditional erasure codes to be used, while retaining the feature that
only a fraction of the data need be downloaded for node repair. In this paper,
we present a simple, yet powerful, framework that does precisely this. Under
this framework, the nodes are partitioned into two 'types' and encoded using
two codes in a manner that reduces the problem of node-repair to that of
erasure-decoding of the constituent codes. Depending upon the choice of the two
codes, the framework can be used to avail one or more of the following
advantages: simultaneous minimization of storage space and repair-bandwidth,
low complexity of operation, fewer disk reads at helper nodes during repair,
and error detection and correction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0139</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0139</id><created>2010-12-30</created><authors><author><keyname>Srivastava</keyname><forenames>Madhur</forenames></author><author><keyname>Katiyar</keyname><forenames>Prateek</forenames></author><author><keyname>Yashu</keyname><forenames>Yashwant</forenames></author><author><keyname>Singha</keyname><forenames>Satish K.</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author></authors><title>A Fast Statistical Method for Multilevel Thresholding in Wavelet Domain</title><categories>nlin.CD cs.CV</categories><comments>33 pages, 10 figures, 7 tables, written with double spacing and
  larger font</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm is proposed for the segmentation of image into multiple levels
using mean and standard deviation in the wavelet domain. The procedure provides
for variable size segmentation with bigger block size around the mean, and
having smaller blocks at the ends of histogram plot of each horizontal,
vertical and diagonal components, while for the approximation component it
provides for finer block size around the mean, and larger blocks at the ends of
histogram plot coefficients. It is found that the proposed algorithm has
significantly less time complexity, achieves superior PSNR and Structural
Similarity Measurement Index as compared to similar space domain algorithms[1].
In the process it highlights finer image structures not perceptible in the
original image. It is worth emphasizing that after the segmentation only 16 (at
threshold level 3) wavelet coefficients captures the significant variation of
image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0160</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0160</id><created>2010-12-30</created><authors><author><keyname>Barron-Romero</keyname><forenames>Carlos</forenames></author></authors><title>The Complexity of Euclidian 2 Dimension Travelling Salesman Problem
  versus General Assign Problem, NP is not P</title><categories>cs.DS cs.CC</categories><acm-class>F.4.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the differences between two NP problems. It focuses in
the Euclidian 2 Dimension Travelling Salesman Problems and General Assign
Problems. The main results are the triangle reduction to verify the solution in
polynomial time for the former and for the later the solution to the Noted
Conjecture of the NP-Class, NP is not P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0173</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0173</id><created>2010-12-30</created><authors><author><keyname>Oueslati</keyname><forenames>Sameh</forenames></author><author><keyname>Cherif</keyname><forenames>Adnane</forenames></author><author><keyname>Solaiman</keyname><forenames>Bassel</forenames></author></authors><title>Maximizing Strength of Digital Watermarks using Fuzzy Logic</title><categories>cs.CR</categories><comments>13 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel digital watermarking scheme in DCT domain
based fuzzy inference system and the human visual system to adapt the embedding
strength of different blocks. Firstly, the original image is divided into some
8 \times 8 blocks, and then fuzzy inference system according to different
textural features and luminance of each block decide adaptively different
embedding strengths. The watermark detection adopts correlation technology.
Experimental results show that the proposed scheme has good imperceptibility
and high robustness to common image processing operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0198</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0198</id><created>2010-12-30</created><authors><author><keyname>Jayanthi</keyname><forenames>S. K.</forenames></author><author><keyname>Sasikala</keyname><forenames>S.</forenames></author></authors><title>Link Spam Detection based on DBSpamClust with Fuzzy C-means Clustering</title><categories>cs.IR cs.IT cs.SI math.IT</categories><comments>10 PAGES 6 FIGURES</comments><journal-ref>International Journal of Next-Generation Networks (IJNGN) Vol.2,
  No.4, December 2010</journal-ref><doi>10.5121/ijngn.2010.2401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search engine became omnipresent means for ingoing to the web. Spamming
Search engine is the technique to deceiving the ranking in search engine and it
inflates the ranking. Web spammers have taken advantage of the vulnerability of
link based ranking algorithms by creating many artificial references or links
in order to acquire higher-than-deserved ranking n search engines' results.
Link based algorithms such as PageRank, HITS utilizes the structural details of
the hyperlinks for ranking the content in the web. In this paper an algorithm
DBSpamClust is proposed for link spam detection. As showing through experiments
such a method can filter out web spam effectively
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0203</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0203</id><created>2010-12-31</created><authors><author><keyname>Kumaar</keyname><forenames>A. A. Nippun</forenames></author><author><keyname>G</keyname><forenames>Kiran.</forenames></author><author><keyname>TSB</keyname><forenames>Sudarshan</forenames></author></authors><title>Intelligent Lighting System Using Wireless Sensor Networks</title><categories>cs.NI</categories><comments>10 pages,5 figures</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.1, No.4, December 2010, pp 17-27</journal-ref><doi>10.5121/ijasuc.2010.1402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the use of Wireless Sensor Networks interfaced with light
fittings to allow for daylight substitution techniques to reduce energy usage
in existing buildings. This creates a wire free system for existing buildings
with minimal disruption and cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0204</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0204</id><created>2010-12-31</created><updated>2011-11-03</updated><authors><author><keyname>Qian</keyname><forenames>Li Ping</forenames><affiliation>Angela</affiliation></author><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author></authors><title>Globally Optimal Distributed Power Control for Nonconcave Utility
  Maximization</title><categories>cs.NI</categories><comments>30 pages, 3 tables, and 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmit power control in wireless networks has long been recognized as an
effective mechanism to mitigate co-channel interference. Due to the highly
non-convex nature, optimal power control is known to be difficult to achieve if
a system utility is to be maximized. To date, there does not yet exist a
distributed power control algorithm that maximizes any form of system utility,
despite the importance of distributed implementation for the wireless
infrastructureless networks such as ad hoc and sensor networks. This paper
fills this gap by developing a Gibbs Sampling based Asynchronous distributed
power control algorithm (referred to as GLAD). The proposed algorithm quickly
converges to the global optimal solution regardless of the concavity,
continuity, differentiability and monotonicity of the utility function. Same as
other existing distributed power control algorithms, GLAD requires extensive
message passing among all users in the network, which leads to high signaling
overhead and high processing complexity. To address this issue, this paper
further proposes a variant of the GLAD algorithm, referred to as I-GLAD, where
the prefix &quot;I&quot; stands for infrequent message passing. The convergence of I-GLAD
can be proved regardless of the reduction in the message passing rate. To
further reduce the processing complexity at each transmitter, we develop an
enhanced version of I-GLAD, referred to as NI-GLAD, where only the control
messages from the neighboring links are processed. Our simulation results show
that I-GLAD approximately converges to the global optimal solution regardless
of the type of the system utility function. Meanwhile, the optimality of the
solution obtained by NI-GLAD depends on the selection of the neighborhood size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0209</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0209</id><created>2010-12-31</created><authors><author><keyname>Ramesh</keyname><forenames>V.</forenames></author><author><keyname>Subbaiah</keyname><forenames>P.</forenames></author><author><keyname>Rao</keyname><forenames>N. Koteswar</forenames></author><author><keyname>Subhashini</keyname><forenames>N.</forenames></author><author><keyname>D</keyname><forenames>Narayana.</forenames></author></authors><title>Performance Comparison and Analysis of Preemptive-DSR and TORA</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dynamic Source Routing protocol (DSR) is a simple and efficient routing
protocol designed specifically for use in multi-hop wireless ad hoc networks of
mobile nodes. Preemptive DSR(PDSR) is the modified version of DSR. The main
objective of this paper is to analyze and compare the performance of Preemptive
DSR and Temporarily Ordered Routing Algorithm(TORA).It discusses the effect of
variation in number of nodes and average speed on protocol performance.
Simulation results (provided by the instructor) are analyzed to get an insight
into the operation of TORA and PDSR in small/large sized networks with
slow/fast moving nodes. Results show that PDSR outperforms TORA in terms of the
number of MANET control packets used to maintain/erase routes. Also, it is
concluded that TORA is a better choice than PDSR for fast moving highly
connected set of nodes. It is also observed that DSR provides better data
throughput than TORA and that routes can be created faster in PDSR than in
TORA. This paper tries to explain the reasons behind the nature of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0211</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0211</id><created>2010-12-31</created><updated>2011-10-18</updated><authors><author><keyname>Jalan</keyname><forenames>Sarika</forenames></author><author><keyname>Zhu</keyname><forenames>Guimei</forenames></author><author><keyname>Li</keyname><forenames>Baowen</forenames></author></authors><title>Spectral Properties of Directed Random Networks with Modular Structure</title><categories>cond-mat.dis-nn cs.SI physics.soc-ph q-bio.MN</categories><comments>revised version as accepted in Phys. Rev. E (in press)</comments><journal-ref>Phys. Rev. E 84, 046107 (2011)</journal-ref><doi>10.1103/PhysRevE.84.046107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study spectra of directed networks with inhibitory and excitatory
couplings. We investigate in particular eigenvector localization properties of
various model networks for different value of correlation among their entries.
Spectra of random networks, with completely uncorrelated entries show a
circular distribution with delocalized eigenvectors, where as networks with
correlated entries have localized eigenvectors. In order to understand the
origin of localization we track the spectra as a function of connection
probability and directionality. As connections are made directed, eigenstates
start occurring in complex conjugate pairs and the eigenvalue distribution
combined with the localization measure shows a rich pattern. Moreover, for a
very well distinguished community structure, the whole spectrum is localized
except few eigenstates at boundary of the circular distribution. As the network
deviates from the community structure there is a sudden change in the
localization property for a very small value of deformation from the perfect
community structure. We search for this effect for the whole range of
correlation strengths and for different community configurations. Furthermore,
we investigate spectral properties of a metabolic network of zebrafish, and
compare them with those of the model networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0234</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0234</id><created>2010-12-31</created><authors><author><keyname>Gao</keyname><forenames>Ruoyun</forenames></author><author><keyname>Lew</keyname><forenames>Michael S.</forenames></author><author><keyname>Shao</keyname><forenames>Ling</forenames></author></authors><title>Dynamic Feature Description in Human Action Recognition</title><categories>cs.HC</categories><report-no>LML20090701</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work aims to present novel description methods for human action
recognition. Generally, a video sequence can be represented as a collection of
spatial temporal words by detecting space-time interest points and describing
the unique features around the detected points (Bag of Words representation).
Interest points as well as the cuboids around them are considered informative
for feature description in terms of both the structural distribution of
interest points and the information content inside the cuboids. Our proposed
description approaches are based on this idea and making the feature
descriptors more discriminative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0235</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0235</id><created>2010-12-31</created><authors><author><keyname>Steenbergen</keyname><forenames>Thomas</forenames></author><author><keyname>Lew</keyname><forenames>Michael S.</forenames></author></authors><title>Analysis of Using Browser-native Technology to Build Rich Internet
  Applications for Image Manipulation</title><categories>cs.HC</categories><report-no>LML20090901</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we investigate whether browser-native technologies can be used
to perform photo manipulation tasks e.g cropping, resizing or rotating an image
within the current mainstream browser. By the use of a case study we will
analyze problems that have occurred during the implementation of a prototype
web application that utilizes browser-native web technology in order to create
an online version of a real world photo scrapbook. Implementation of a
prototype will allows us to analyze the strengths and weaknesses of current web
technology when it comes to browser-based image manipulation. Furthermore we
explore the possibilities of the Ajax in combination Canvas, SVG and VML to
provide a more interactive graphical user interface to perform image
manipulation tasks on the web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0237</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0237</id><created>2010-12-31</created><authors><author><keyname>Gast</keyname><forenames>E. R.</forenames></author><author><keyname>Lew</keyname><forenames>Michael S.</forenames></author></authors><title>A Framework for Real-Time Face and Facial Feature Tracking using Optical
  Flow Pre-estimation and Template Tracking</title><categories>cs.CV</categories><report-no>LML20100401</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a framework for tracking head movements and capturing the
movements of the mouth and both the eyebrows in real-time. We present a head
tracker which is a combination of a optical flow and a template based tracker.
The estimation of the optical flow head tracker is used as starting point for
the template tracker which fine-tunes the head estimation. This approach
together with re-updating the optical flow points prevents the head tracker
from drifting. This combination together with our switching scheme, makes our
tracker very robust against fast movement and motion-blur. We also propose a
way to reduce the influence of partial occlusion of the head. In both the
optical flow and the template based tracker we identify and exclude occluded
points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0241</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0241</id><created>2010-12-31</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>An Intrusion Detection Architecture for Clustered Wireless Ad Hoc
  Networks</title><categories>cs.CR cs.NI</categories><comments>6 pages, 2 Figures, 2 tables. Second International Conference on
  Computational Intelligence, Communication Systems and Networks (CICSYSN
  2010), Liverpool, UK, July 28 - 30, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intrusion detection in wireless ad hoc networks is a challenging task because
these networks change their topologies dynamically, lack concentration points
where aggregated traffic can be analyzed, utilize infrastructure protocols that
are susceptible to manipulation, and rely on noisy, intermittent wireless
communications. Security remains a major challenge for these networks due their
features of open medium, dynamically changing topologies, reliance on
co-operative algorithms, absence of centralized monitoring points, and lack of
clear lines of defense. In this paper, we present a cooperative, distributed
intrusion detection architecture based on clustering of the nodes that
addresses the security vulnerabilities of the network and facilitates accurate
detection of attacks. The architecture is organized as a dynamic hierarchy in
which the intrusion data is acquired by the nodes and is incrementally
aggregated, reduced in volume and analyzed as it flows upwards to the
cluster-head. The cluster-heads of adjacent clusters communicate with each
other in case of cooperative intrusion detection. For intrusion related message
communication, mobile agents are used for their efficiency in lightweight
computation and suitability in cooperative intrusion detection. Simulation
results show effectiveness and efficiency of the proposed architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0242</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0242</id><created>2010-12-31</created><authors><author><keyname>Chen</keyname><forenames>Xiaojing</forenames></author><author><keyname>Lew</keyname><forenames>Michael S.</forenames></author></authors><title>Binary and nonbinary description of hypointensity in human brain MR
  images</title><categories>cs.CV</categories><report-no>LML20080101</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accumulating evidence has shown that iron is involved in the mechanism
underlying many neurodegenerative diseases, such as Alzheimer's disease,
Parkinson's disease and Huntington's disease. Abnormal (higher) iron
accumulation has been detected in the brains of most neurodegenerative
patients, especially in the basal ganglia region. Presence of iron leads to
changes in MR signal in both magnitude and phase. Accordingly, tissues with
high iron concentration appear hypo-intense (darker than usual) in MR
contrasts. In this report, we proposed an improved binary hypointensity
description and a novel nonbinary hypointensity description based on principle
components analysis. Moreover, Kendall's rank correlation coefficient was used
to compare the complementary and redundant information provided by the two
methods in order to better understand the individual descriptions of iron
accumulation in the brain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0243</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0243</id><created>2010-12-31</created><authors><author><keyname>Wang</keyname><forenames>Liang</forenames></author><author><keyname>Huijsmans</keyname><forenames>Nies</forenames></author><author><keyname>Lew</keyname><forenames>Michael S.</forenames></author><author><keyname>Tsymbala</keyname><forenames>Dan</forenames></author></authors><title>Across Browsers SVG Implementation</title><categories>cs.GR</categories><report-no>LML20090402</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work SVG will be translated into VML or HTML by using Javascript
based on Backbase Client Framework. The target of this project is to implement
SVG to be viewed in Internet Explorer without any plug-in and work together
with other Backbase Client Framework languages. The result of this project will
be added as an extension to the current Backbase Client Framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0244</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0244</id><created>2010-12-31</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Robust and Efficient Node Authentication Protocol for Mobile Ad Hoc
  Networks</title><categories>cs.CR</categories><comments>6 pages, 8 figures. Second International Conference on Computational
  Intelligence, Modeling and Simulation, Bali, Indonesia, September 28 - 30,
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mobile ad hoc network (MANET) is a collection of mobile nodes that
communicate with each other by forming a multi-hop radio network. Security
remains a major challenge for these networks due to their features of open
medium, dynamically changing topologies, reliance on cooperative algorithms,
absence of centralized monitoring points, and lack of clear lines of defense.
Design of an efficient and reliable node authentication protocol for such
networks is a particularly challenging task since the nodes are battery-driven
and resource constrained. This paper presents a robust and efficient key
exchange protocol for nodes authentication in a MANET based on multi-path
communication. Simulation results demonstrate that the protocol is effective
even in presence of large fraction of malicious nodes in the network. Moreover,
it has a minimal computation and communication overhead that makes it ideally
suitable for MANETs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0245</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0245</id><created>2010-12-31</created><authors><author><keyname>Chakraborty</keyname><forenames>Shubham</forenames></author></authors><title>Use of Python and Phoenix-M Interface in Robotics</title><categories>cs.RO cs.AI</categories><comments>10 pages, 3 figures, 10 tables, 4 program codes, SciPy.in 2010
  conference</comments><msc-class>68-06</msc-class><acm-class>I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I will show how to use Python programming with a computer
interface such as Phoenix-M 1 to drive simple robots. In my quest towards
Artificial Intelligence(AI) I am experimenting with a lot of different
possibilities in Robotics. This one will try to mimic the working of a simple
insect's nervous system using hard wiring and some minimal software usage. This
is the precursor to my advanced robotics and AI integration where I plan to use
a new paradigm of AI based on Machine Learning and Self Consciousness via
Knowledge Feedback and Update Process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0248</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0248</id><created>2010-12-31</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Robust and Fault-Tolerant Distributed Intrusion Detection System</title><categories>cs.CR</categories><comments>6 pages, 4 figures, 2 tables. First International Conference on
  Parallel, Distributed and Grid Computing (PDGC), Waknaghat, India, October 28
  -30, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since it is impossible to predict and identify all the vulnerabilities of a
network, and penetration into a system by malicious intruders cannot always be
prevented, intrusion detection systems (IDSs) are essential entities for
ensuring the security of a networked system. To be effective in carrying out
their functions, the IDSs need to be accurate, adaptive, and extensible. Given
these stringent requirements and the high level of vulnerabilities of the
current days' networks, the design of an IDS has become a very challenging
task. Although, an extensive research has been done on intrusion detection in a
distributed environment, distributed IDSs suffer from a number of drawbacks
e.g., high rates of false positives, low detection efficiency etc. In this
paper, the design of a distributed IDS is proposed that consists of a group of
autonomous and cooperating agents. In addition to its ability to detect
attacks, the system is capable of identifying and isolating compromised nodes
in the network thereby introducing fault-tolerance in its operations. The
experiments conducted on the system have shown that it has high detection
efficiency and low false positives compared to some of the currently existing
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0250</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0250</id><created>2010-12-31</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>An Adaptive and Multi-Service Routing Protocol for Wireless Sensor
  Networks</title><categories>cs.NI</categories><comments>6 pages, 8 figures. 16th IEEE Asia-Pacific Conference on
  Communications (APCC) 2010, Auckland, New Zealand, October 31 - November 3,
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) are highly distributed networks consisting of
a large number of tiny, low-cost, light-weight wireless nodes deployed to
monitor an environment or a system. Each node in a WSN consists of three
subsystems: the sensor subsystem which senses the environment, the processing
subsystem which performs local computations on the sensed data, and the
communication subsystem which is responsible for message exchange with
neighboring sensor nodes. While an individual sensor node has limited sensing
region, processing power, and energy, networking a large number of sensor nodes
give rise to a robust, reliable, and accurate sensor network covering a wide
region. Thus, routing in WSNs is a very important issue. This paper presents a
query-based routing protocol for a WSN that provides different levels of
Quality of Service (QoS): energy-efficiency, reliability, low latency and
fault-tolerance-under different application scenarios. The algorithm has low
computational complexity but can dynamically guarantee different QoS support
depending on the requirement of the applications. The novelty of the proposed
algorithm is its ability to provide multiple QoS support without
reconfiguration and redeployment of the sensor nodes. The algorithm is
implemented in network simulator ns-2 and its performance has been evaluated.
The results show that the algorithm is more efficient than some of the
currently existing routing algorithms for WSNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0255</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0255</id><created>2010-12-31</created><authors><author><keyname>Hosseini</keyname><forenames>Reza</forenames></author></authors><title>Conditional information and definition of neighbor in categorical random
  fields</title><categories>math.ST cs.LG stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the definition of neighbor in Markov random fields as defined by
Besag (1974) when the joint distribution of the sites is not positive is not
well-defined. In a random field with finite number of sites we study the
conditions under which giving the value at extra sites will change the belief
of an agent about one site. Also the conditions under which the information
from some sites is equivalent to giving the value at all other sites is
studied. These concepts provide an alternative to the concept of neighbor for
general case where the positivity condition of the joint does not hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0262</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0262</id><created>2010-12-31</created><authors><author><keyname>Kaur</keyname><forenames>Sugreev</forenames></author><author><keyname>Mehra</keyname><forenames>Rajesh</forenames></author></authors><title>High Speed and Area Efficient 2D DWT Processor based Image Compression&quot;
  Signal &amp; Image Processing</title><categories>cs.GR</categories><comments>10 Pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a high speed and area efficient DWT processor based
design for Image Compression applications. In this proposed design, pipelined
partially serial architecture has been used to enhance the speed along with
optimal utilization and resources available on target FPGA. The proposed model
has been designed and simulated using Simulink and System Generator blocks,
synthesized with Xilinx Synthesis tool (XST) and implemented on Spartan 2 and 3
based XC2S100-5tq144 and XC3S500E-4fg320 target device. The results show that
proposed design can operate at maximum frequency 231 MHz in case of Spartan 3
by consuming power of 117mW at 28 degree/c junction temperature. The result
comparison has shown an improvement of 15% in speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0270</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0270</id><created>2010-12-31</created><authors><author><keyname>Gerbracht</keyname><forenames>Eberhard H. -A.</forenames></author></authors><title>&quot;On the engineers' new toolbox&quot; or Analog Circuit Design, using Symbolic
  Analysis, Computer Algebra, and Elementary Network Transformations</title><categories>cs.SC cs.CE cs.DM</categories><comments>V1: documentclass IEEEtran, 7 pages, 6 figures. Re-release of the
  printed version, with some minor typographical errors corrected</comments><msc-class>94C05 (Primary), 94C15, 68W30, 13P10, 05C85 (Secondary)</msc-class><acm-class>I.1; J.2; G.2.2</acm-class><journal-ref>Proceedings of the Xth International Workshop on Symbolic and
  Numerical Methods, Modeling and Applications to Circuit Design (SM2ACD'08),
  Erfurt, Germany, October 07-08, 2008; pp. 127-134</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, by way of three examples - a fourth order low pass active RC
filter, a rudimentary BJT amplifier, and an LC ladder - we show, how the
algebraic capabilities of modern computer algebra systems can, or in the last
example, might be brought to use in the task of designing analog circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0272</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0272</id><created>2010-12-31</created><updated>2011-03-05</updated><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Social Norms for Online Communities</title><categories>cs.SI cs.NI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sustaining cooperation among self-interested agents is critical for the
proliferation of emerging online social communities, such as online communities
formed through social networking services. Providing incentives for cooperation
in social communities is particularly challenging because of their unique
features: a large population of anonymous agents interacting infrequently,
having asymmetric interests, and dynamically joining and leaving the community;
operation errors; and low-cost reputation whitewashing. In this paper, taking
these features into consideration, we propose a framework for the design and
analysis of a class of incentive schemes based on a social norm, which consists
of a reputation scheme and a social strategy. We first define the concept of a
sustainable social norm under which every agent has an incentive to follow the
social strategy given the reputation scheme. We then formulate the problem of
designing an optimal social norm, which selects a social norm that maximizes
overall social welfare among all sustainable social norms. Using the proposed
framework, we study the structure of optimal social norms and the impacts of
punishment lengths and whitewashing on optimal social norms. Our results show
that optimal social norms are capable of sustaining cooperation, with the
amount of cooperation varying depending on the community characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0275</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0275</id><created>2010-12-31</created><updated>2011-06-09</updated><authors><author><keyname>Torbatian</keyname><forenames>Mehdi</forenames></author><author><keyname>Najafi</keyname><forenames>Hossein</forenames></author><author><keyname>Damen</keyname><forenames>Mohamed Oussama</forenames></author></authors><title>Asynchronous Interference Alignment</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A constant K-user interference channel in which the users are not
symbol-synchronous is considered. It is shown that the asynchronism among the
users facilitates aligning interfering signals at each receiver node while it
does not affect the total number of degrees of freedom (DoF) of the channel. To
achieve the total K/2 DoF of the channel when single antenna nodes are used, a
novel practical interference alignment scheme is proposed wherein the alignment
task is performed with the help of asynchronous delays which inherently exist
among the received signals at each receiver node. When each node is equipped
with M &gt; 1 antennas, it is argued that the same alignment scheme is sufficient
to achieve the total MK/2 DoF of the medium when all links between collocated
antennas experience the same asynchronous delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0287</identifier>
 <datestamp>2014-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0287</id><created>2010-12-31</created><updated>2014-01-27</updated><authors><author><keyname>Hammerich</keyname><forenames>Edwin</forenames></author></authors><title>On the Capacity of the Heat Channel, Waterfilling in the Time-Frequency
  Plane, and a C-NODE Relationship</title><categories>cs.IT math.IT</categories><comments>37 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The heat channel is defined by a linear time-varying (LTV) filter with
additive white Gaussian noise (AWGN) at the filter output. The continuous-time
LTV filter is related to the heat kernel of the quantum mechanical harmonic
oscillator, so the name of the channel. The channel's capacity is given in
closed form by means of the Lambert W function. Also a waterfilling theorem in
the time-frequency plane for the capacity is derived. It relies on a specific
Szego theorem for which an essentially self-contained proof is provided.
Similarly, the rate distortion function for a related nonstationary source is
given in closed form and a (reverse) waterfilling theorem in the time-frequency
plane is derived. Finally, a second closed-form expression for the capacity of
the heat channel based on the detected perturbed filter output signals is
presented. In this context, a precise differential connection between channel
capacity and the normalized optimal detection error (NODE) is revealed. This
C-NODE relationship is compared with the well-known I-MMSE relationship
connecting mutual information with the minimum mean-square error (MMSE) of
estimation theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0294</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0294</id><created>2010-12-31</created><updated>2013-08-10</updated><authors><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Virtual Full Duplex Wireless Broadcasting via Compressed Sensing</title><categories>cs.IT cs.NI math.IT</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel solution is proposed to undertake a frequent task in wireless
networks, which is to let all nodes broadcast information to and receive
information from their respective one-hop neighboring nodes. The contribution
is two-fold. First, as each neighbor selects one message-bearing codeword from
its unique codebook for transmission, it is shown that decoding their messages
based on a superposition of those codewords through the multiaccess channel is
fundamentally a problem of compressed sensing. In the case where each message
consists of a small number of bits, an iterative algorithm based on belief
propagation is developed for efficient decoding. Second, to satisfy the
half-duplex constraint, each codeword consists of randomly distributed on-slots
and off-slots. A node transmits during its on-slots, and listens to its
neighbors only through its own off-slots. Over one frame interval, each node
broadcasts a message to neighbors and simultaneously decodes neighbors'
messages based on the superposed signals received through its own off-slots.
Thus the solution fully exploits the multiaccess nature of the wireless medium
and addresses the half-duplex constraint at the fundamental level. In a network
consisting of Poisson distributed nodes, numerical results demonstrate that the
proposed scheme often achieves several times the rate of slotted ALOHA and CSMA
with the same packet error rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0301</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0301</id><created>2010-12-31</created><authors><author><keyname>Brand</keyname><forenames>Matthew</forenames></author></authors><title>Specular holography</title><categories>cs.GR cs.CG physics.optics</categories><comments>7 pages, 1 figure</comments><doi>10.1364/AO.50.005042</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By tooling an spot-illuminated surface to control the flow of specular glints
under motion, one can produce holographic view-dependent imagery. This paper
presents the differential equation that governs the shape of the specular
surfaces, and illustrates how solutions can be constructed for different kinds
of motion, lighting, host surface geometries, and fabrication constraints,
leading to some novel forms of holography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0302</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0302</id><created>2010-12-31</created><authors><author><keyname>Atar</keyname><forenames>Rami</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Mutual Information, Relative Entropy, and Estimation in the Poisson
  Channel</title><categories>cs.IT math.IT</categories><comments>24 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $X$ be a non-negative random variable and let the conditional
distribution of a random variable $Y$, given $X$, be ${Poisson}(\gamma \cdot
X)$, for a parameter $\gamma \geq 0$. We identify a natural loss function such
that: 1) The derivative of the mutual information between $X$ and $Y$ with
respect to $\gamma$ is equal to the \emph{minimum} mean loss in estimating $X$
based on $Y$, regardless of the distribution of $X$. 2) When $X \sim P$ is
estimated based on $Y$ by a mismatched estimator that would have minimized the
expected loss had $X \sim Q$, the integral over all values of $\gamma$ of the
excess mean loss is equal to the relative entropy between $P$ and $Q$.
  For a continuous time setting where $X^T = \{X_t, 0 \leq t \leq T \}$ is a
non-negative stochastic process and the conditional law of $Y^T=\{Y_t, 0\le
t\le T\}$, given $X^T$, is that of a non-homogeneous Poisson process with
intensity function $\gamma \cdot X^T$, under the same loss function: 1) The
minimum mean loss in \emph{causal} filtering when $\gamma = \gamma_0$ is equal
to the expected value of the minimum mean loss in \emph{non-causal} filtering
(smoothing) achieved with a channel whose parameter $\gamma$ is uniformly
distributed between 0 and $\gamma_0$. Bridging the two quantities is the mutual
information between $X^T$ and $Y^T$. 2) This relationship between the mean
losses in causal and non-causal filtering holds also in the case where the
filters employed are mismatched, i.e., optimized assuming a law on $X^T$ which
is not the true one. Bridging the two quantities in this case is the sum of the
mutual information and the relative entropy between the true and the mismatched
distribution of $Y^T$. Thus, relative entropy quantifies the excess estimation
loss due to mismatch in this setting.
  These results parallel those recently found for the Gaussian channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0305</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0305</id><created>2010-12-31</created><updated>2011-04-02</updated><authors><author><keyname>Bickel</keyname><forenames>David R.</forenames></author></authors><title>Measuring support for a hypothesis about a random parameter without
  estimating its unknown prior</title><categories>math.ST cs.IT math.IT q-bio.QM stat.ME stat.TH</categories><comments>Errors in the first version were corrected, and the methodology is
  now applied to more interesting data</comments><journal-ref>D. R. Bickel, Minimax-optimal strength of statistical evidence for
  a composite alternative hypothesis, International Statistical Review 81,
  188-206 (2013)</journal-ref><doi>10.1111/insr.12008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For frequentist settings in which parameter randomness represents variability
rather than uncertainty, the ideal measure of the support for one hypothesis
over another is the difference in the posterior and prior log odds. For
situations in which the prior distribution cannot be accurately estimated, that
ideal support may be replaced by another measure of support, which may be any
predictor of the ideal support that, on a per-observation basis, is
asymptotically unbiased. Two qualifying measures of support are defined. The
first is minimax optimal with respect to the population and is equivalent to a
particular Bayes factor. The second is worst-sample minimax optimal and is
equivalent to the normalized maximum likelihood. It has been extended by
likelihood weights for compatibility with more general models.
  One such model is that of two independent normal samples, the standard
setting for gene expression microarray data analysis. Applying that model to
proteomics data indicates that support computed from data for a single protein
can closely approximate the estimated difference in posterior and prior odds
that would be available with the data for 20 proteins. This suggests the
applicability of random-parameter models to other situations in which the
parameter distribution cannot be reliably estimated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0306</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0306</id><created>2010-12-31</created><updated>2011-12-22</updated><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>The Degrees of Freedom Regions of Two-User and Certain Three-User MIMO
  Broadcast Channels with Delayed CSIT</title><categories>cs.IT math.IT</categories><comments>27 pages, 6 figures; submitted to IEEE Trans. on Information Theory,
  Dec. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degrees of freedom (DoF) region of the fast-fading MIMO (multiple-input
multiple-output) Gaussian broadcast channel (BC) is studied when there is
delayed channel state information at the transmitter (CSIT). In this setting,
the channel matrices are assumed to vary independently across time and the
transmitter is assumed to know the channel matrices with some arbitrary finite
delay. An outer-bound to the DoF region of the general $K$-user MIMO BC (with
an arbitrary number of antennas at each terminal) is derived. This outer-bound
is then shown to be tight for two classes of MIMO BCs, namely, (a) the two-user
MIMO BC with arbitrary number of antennas at all terminals, and (b) for certain
three-user MIMO BCs where all three receivers have an equal number of antennas
and the transmitter has no more than twice the number of antennas present at
each receivers. The achievability results are obtained by developing an
interference alignment scheme that optimally accounts for multiple, and
possibly distinct, number of antennas at the receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0309</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0309</id><created>2010-12-31</created><authors><author><keyname>Grefenstette</keyname><forenames>Edward</forenames></author><author><keyname>Sadrzadeh</keyname><forenames>Mehrnoosh</forenames></author><author><keyname>Clark</keyname><forenames>Stephen</forenames></author><author><keyname>Coecke</keyname><forenames>Bob</forenames></author><author><keyname>Pulman</keyname><forenames>Stephen</forenames></author></authors><title>Concrete Sentence Spaces for Compositional Distributional Models of
  Meaning</title><categories>cs.CL cs.AI cs.IR</categories><comments>10 pages, presented at the International Conference on Computational
  Semantics 2011 (IWCS'11), to be published in proceedings</comments><msc-class>68T50</msc-class><acm-class>G.1.3; H.3.1; H.3.3</acm-class><journal-ref>Proceedings of the 9th International Conference on Computational
  Semantics (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coecke, Sadrzadeh, and Clark (arXiv:1003.4394v1 [cs.CL]) developed a
compositional model of meaning for distributional semantics, in which each word
in a sentence has a meaning vector and the distributional meaning of the
sentence is a function of the tensor products of the word vectors. Abstractly
speaking, this function is the morphism corresponding to the grammatical
structure of the sentence in the category of finite dimensional vector spaces.
In this paper, we provide a concrete method for implementing this linear
meaning map, by constructing a corpus-based vector space for the type of
sentence. Our construction method is based on structured vector spaces whereby
meaning vectors of all sentences, regardless of their grammatical structure,
live in the same vector space. Our proposed sentence space is the tensor
product of two noun spaces, in which the basis vectors are pairs of words each
augmented with a grammatical role. This enables us to compare meanings of
sentences by simply taking the inner product of their vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0327</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0327</id><created>2011-01-01</created><authors><author><keyname>Seyfi</keyname><forenames>Mehdi</forenames><affiliation>Hakam</affiliation></author><author><keyname>Sami</keyname><affiliation>Hakam</affiliation></author><author><keyname>Muhaidat</keyname></author><author><keyname>Liang</keyname><forenames>Jie</forenames></author></authors><title>On the Performance of Selection Cooperation with Imperfect Channel
  Estimation</title><categories>cs.IT math.IT</categories><comments>32 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the performance of selection cooperation in the
presence of imperfect channel estimation. In particular, we consider a
cooperative scenario with multiple relays and amplify-and- forward protocol
over frequency flat fading channels. In the selection scheme, only the &quot;best&quot;
relay which maximizes the effective signal-to-noise ratio (SNR) at the receiver
end is selected. We present lower and upper bounds on the effective SNR and
derive closed-form expressions for the average symbol error rate (ASER), outage
probability and average capacity per bandwidth of the received signal in the
presence of channel estimation errors. A simulation study is presented to
corroborate the analytical results and to demonstrate the performance of relay
selection with imperfect channel estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0339</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0339</id><created>2011-01-01</created><updated>2011-10-04</updated><authors><author><keyname>Abediseid</keyname><forenames>Walid</forenames></author><author><keyname>Damen</keyname><forenames>Mohamed Oussama</forenames></author></authors><title>Lattice Sequential Decoding for LAST Coded MIMO Channels: Achievable
  Rate, DMT, and Complexity Analysis</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the asymptotic performance of the lattice sequential decoder
for LAttice Space-Time (LAST) coded MIMO channel is analyzed. We determine the
rates achievable by lattice coding and sequential decoding applied to such a
channel. The diversity-multiplexing tradeoff (DMT) under lattice sequential
decoding is derived as a function of its parameter---the bias term, which is
critical for controlling the amount of computations required at the decoding
stage. Achieving low decoding complexity requires increasing the value of the
bias term. However, this is done at the expense of losing the optimal tradeoff
of the channel. In this work, we derive the tail distribution of the decoder's
computational complexity in the high signal-to-noise ratio regime. Our analysis
reveals that the tail distribution of such a low complexity decoder is
dominated by the outage probability of the channel for the underlying coding
scheme. Also, the tail exponent of the complexity distribution is shown to be
equivalent to the DMT achieved by lattice coding and lattice sequential
decoding schemes. We derive the asymptotic average complexity of the sequential
decoder as a function of the system parameters. In particular, we show that
there exists a cut-off multiplexing gain for which the average computational
complexity of the decoder remains bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0340</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0340</id><created>2011-01-01</created><authors><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author></authors><title>A Round-Robin Tournament of the Iterated Prisoner's Dilemma with
  Complete Memory-Size-Three Strategies</title><categories>cs.GT physics.soc-ph</categories><comments>submitted revised version to Complex Systems</comments><journal-ref>in Complex Systems 19(4) pp. 363-389 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the results of a simulation of a prisoner's dilemma robin-round
tournament are presented. In the tournament each participating strategy plays
an iterated prisoner's dilemma against each other strategy (round-robin) and as
a variant also against itself. The participants of a tournament are all
strategies that are deterministic and have the same size of memory with regard
to their own and their opponent's past actions: up to three most recent actions
of their opponent and up to two most recent actions of their own. A focus is
set on the investigation of the influence of the number of iterations, details
of the payoff matrix, and the influence of memory size. The main result is that
for the tournament as carried out here, different strategies emerge as winners
for different payoff matrices, even for different payoff matrices being similar
judged on if they fulfill relations T + S = P + R or 2R &gt; T + S. As a
consequence of this result it is suggested that whenever the iterated
prisoner's dilemma is used to model a real system that does not explicitly fix
the payoff matrix, one should check if conclusions remain valid, when a
different payoff matrix is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0345</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0345</id><created>2011-01-01</created><updated>2011-03-11</updated><authors><author><keyname>Dan</keyname><forenames>Yuya</forenames></author></authors><title>Diffusion of Confidential Information on Networks</title><categories>cs.SI physics.soc-ph</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a natural generalization of the previous work by Dan, &quot;Modeling and
Simulation of Diffusion Phenomena on Social Networks,&quot; to appear in The
proceedings of 2011 Third International Conference on Computer Modeling and
Simulation. In this paper, we consider the diffusion phenomena of personal or
secret information on the variety of networks, such as complete, random,
stochastic and scale-free networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0350</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0350</id><created>2011-01-01</created><authors><author><keyname>Pavlo</keyname><forenames>Andrew</forenames></author><author><keyname>Shi</keyname><forenames>Ning</forenames></author></authors><title>Graffiti Networks: A Subversive, Internet-Scale File Sharing Model</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of peer-to-peer (P2P) file sharing protocols is due to
their efficient and scalable methods for data dissemination to numerous users.
But many of these networks have no provisions to provide users with long term
access to files after the initial interest has diminished, nor are they able to
guarantee protection for users from malicious clients that wish to implicate
them in incriminating activities. As such, users may turn to supplementary
measures for storing and transferring data in P2P systems. We present a new
file sharing paradigm, called a Graffiti Network, which allows peers to harness
the potentially unlimited storage of the Internet as a third-party
intermediary. Our key contributions in this paper are (1) an overview of a
distributed system based on this new threat model and (2) a measurement of its
viability through a one-year deployment study using a popular web-publishing
platform. The results of this experiment motivate a discussion about the
challenges of mitigating this type of file sharing in a hostile network
environment and how web site operators can protect their resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0357</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0357</id><created>2011-01-01</created><authors><author><keyname>Sobie</keyname><forenames>R. J.</forenames></author><author><keyname>Agarwal</keyname><forenames>A.</forenames></author><author><keyname>Anderson</keyname><forenames>M.</forenames></author><author><keyname>Armstrong</keyname><forenames>P.</forenames></author><author><keyname>Fransham</keyname><forenames>K.</forenames></author><author><keyname>Gable</keyname><forenames>I.</forenames></author><author><keyname>Harris</keyname><forenames>D.</forenames></author><author><keyname>Leavett-Brown</keyname><forenames>C.</forenames></author><author><keyname>Paterson</keyname><forenames>M.</forenames></author><author><keyname>Penfold-Brown</keyname><forenames>D.</forenames></author><author><keyname>Vliet</keyname><forenames>M.</forenames></author><author><keyname>Charbonneau</keyname><forenames>A.</forenames></author><author><keyname>Impey</keyname><forenames>R.</forenames></author><author><keyname>Podaima</keyname><forenames>W.</forenames></author></authors><title>Data Intensive High Energy Physics Analysis in a Distributed Cloud</title><categories>cs.DC</categories><comments>6 pages, 4 figures, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that distributed Infrastructure-as-a-Service (IaaS) compute clouds
can be effectively used for the analysis of high energy physics data. We have
designed a distributed cloud system that works with any application using large
input data sets requiring a high throughput computing environment. The system
uses IaaS-enabled science and commercial clusters in Canada and the United
States. We describe the process in which a user prepares an analysis virtual
machine (VM) and submits batch jobs to a central scheduler. The system boots
the user-specific VM on one of the IaaS clouds, runs the jobs and returns the
output to the user. The user application accesses a central database for
calibration data during the execution of the application. Similarly, the data
is located in a central location and streamed by the running application. The
system can easily run one hundred simultaneous jobs in an efficient manner and
should scale to many hundreds and possibly thousands of user jobs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0362</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0362</id><created>2011-01-01</created><authors><author><keyname>Hota</keyname><forenames>Ashish Ranjan</forenames></author><author><keyname>Pat</keyname><forenames>Ankit</forenames></author></authors><title>An Adaptive Quantum-inspired Differential Evolution Algorithm for 0-1
  Knapsack Problem</title><categories>cs.NE</categories><comments>6 Pages, 8 figures</comments><acm-class>I.2.8</acm-class><doi>10.1109/NABIC.2010.5716320</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential evolution (DE) is a population based evolutionary algorithm
widely used for solving multidimensional global optimization problems over
continuous spaces. However, the design of its operators makes it unsuitable for
many real-life constrained combinatorial optimization problems which operate on
binary space. On the other hand, the quantum inspired evolutionary algorithm
(QEA) is very well suitable for handling such problems by applying several
quantum computing techniques such as Q-bit representation and rotation gate
operator, etc. This paper extends the concept of differential operators with
adaptive parameter control to the quantum paradigm and proposes the adaptive
quantum-inspired differential evolution algorithm (AQDE). The performance of
AQDE is found to be significantly superior as compared to QEA and a discrete
version of DE on the standard 0-1 knapsack problem for all the considered test
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0376</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0376</id><created>2011-01-01</created><authors><author><keyname>Liu</keyname><forenames>Benyuan</forenames></author><author><keyname>Dousse</keyname><forenames>Olivier</forenames></author><author><keyname>Nain</keyname><forenames>Philippe</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author></authors><title>Dynamic Coverage of Mobile Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the dynamic aspects of the coverage of a mobile sensor
network resulting from continuous movement of sensors. As sensors move around,
initially uncovered locations are likely to be covered at a later time. A
larger area is covered as time continues, and intruders that might never be
detected in a stationary sensor network can now be detected by moving sensors.
However, this improvement in coverage is achieved at the cost that a location
is covered only part of the time, alternating between covered and not covered.
We characterize area coverage at specific time instants and during time
intervals, as well as the time durations that a location is covered and
uncovered. We further characterize the time it takes to detect a randomly
located intruder. For mobile intruders, we take a game theoretic approach and
derive optimal mobility strategies for both sensors and intruders. Our results
show that sensor mobility brings about unique dynamic coverage properties not
present in a stationary sensor network, and that mobility can be exploited to
compensate for the lack of sensors to improve coverage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0377</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0377</id><created>2011-01-01</created><updated>2011-10-17</updated><authors><author><keyname>Jo</keyname><forenames>Hang-Hyun</forenames></author><author><keyname>Karsai</keyname><forenames>M&#xe1;rton</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author></authors><title>Circadian pattern and burstiness in mobile phone communication</title><categories>physics.soc-ph cs.SI</categories><comments>17 pages, 12 figures</comments><journal-ref>New Journal of Physics 14, 013055 (2012)</journal-ref><doi>10.1088/1367-2630/14/1/013055</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The temporal communication patterns of human individuals are known to be
inhomogeneous or bursty, which is reflected as the heavy tail behavior in the
inter-event time distribution. As the cause of such bursty behavior two main
mechanisms have been suggested: a) Inhomogeneities due to the circadian and
weekly activity patterns and b) inhomogeneities rooted in human task execution
behavior. Here we investigate the roles of these mechanisms by developing and
then applying systematic de-seasoning methods to remove the circadian and
weekly patterns from the time-series of mobile phone communication events of
individuals. We find that the heavy tails in the inter-event time distributions
remain robustly with respect to this procedure, which clearly indicates that
the human task execution based mechanism is a possible cause for the remaining
burstiness in temporal mobile phone communication patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0380</identifier>
 <datestamp>2011-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0380</id><created>2011-01-01</created><updated>2011-06-28</updated><authors><author><keyname>Ostilli</keyname><forenames>M.</forenames></author><author><keyname>Ferreira</keyname><forenames>A. L.</forenames></author><author><keyname>Mendes</keyname><forenames>J. F. F.</forenames></author></authors><title>Critical behavior and correlations on scale-free small-world networks.
  Application to network design</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>23 pages, 4 figures, added 2 Tables</comments><journal-ref>Phys. Rev. E 83, 061149 (2011)</journal-ref><doi>10.1103/PhysRevE.83.061149</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze critical phenomena on networks generated as the union of hidden
variables models (networks with any desired degree sequence) with arbitrary
graphs. The resulting networks are general small-worlds similar to those a` la
Watts and Strogatz but with a heterogeneous degree distribution. We prove that
the critical behavior (thermal or percolative) remains completely unchanged by
the presence of finite loops (or finite clustering). Then, we show that, in
large but finite networks, correlations of two given spins may be strong, i.e.,
approximately power law like, at any temperature. Quite interestingly, if
$\gamma$ is the exponent for the power law distribution of the vertex degree,
for $\gamma\leq 3$ and with or without short-range couplings, such strong
correlations persist even in the thermodynamic limit, contradicting the common
opinion that in mean-field models correlations always disappear in this limit.
Finally, we provide the optimal choice of rewiring under which percolation
phenomena in the rewired network are best performed; a natural criterion to
reach best communication features, at least in non congested regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0382</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0382</id><created>2011-01-01</created><updated>2011-01-29</updated><authors><author><keyname>Borno</keyname><forenames>Mazen Al</forenames></author></authors><title>Reduction in Solving Some Integer Least Squares Problems</title><categories>math.OC cs.DS cs.NA cs.SY math.NA</categories><comments>109 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving an integer least squares (ILS) problem usually consists of two
stages: reduction and search. This thesis is concerned with the reduction
process for the ordinary ILS problem and the ellipsoid-constrained ILS problem.
For the ordinary ILS problem, we dispel common misconceptions on the reduction
stage in the literature and show what is crucial to the efficiency of the
search process. The new understanding allows us to design a new reduction
algorithm which is more efficient than the well-known LLL reduction algorithm.
Numerical stability is taken into account in designing the new reduction
algorithm. For the ellipsoid-constrained ILS problem, we propose a new
reduction algorithm which, unlike existing algorithms, uses all the available
information. Simulation results indicate that new algorithm can greatly reduce
the computational cost of the search process when the measurement noise is
large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0384</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0384</id><created>2011-01-01</created><authors><author><keyname>Doukim</keyname><forenames>Chelsia Amy</forenames></author><author><keyname>Dargham</keyname><forenames>Jamal Ahmad</forenames></author><author><keyname>Chekima</keyname><forenames>Ali</forenames></author><author><keyname>Omatu</keyname><forenames>Sigeru</forenames></author></authors><title>Combining Neural Networks for Skin Detection</title><categories>cs.CV</categories><comments>11 pages, journal articles; ISSN 0976 - 710X, Academy &amp; Industry
  Research Collaboration Center, December 2010 available at
  http://www.airccse.org/journal/sipij/currentissue.html</comments><journal-ref>Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.1, No.2, PP. 1-11</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two types of combining strategies were evaluated namely combining skin
features and combining skin classifiers. Several combining rules were applied
where the outputs of the skin classifiers are combined using binary operators
such as the AND and the OR operators, &quot;Voting&quot;, &quot;Sum of Weights&quot; and a new
neural network. Three chrominance components from the YCbCr colour space that
gave the highest correct detection on their single feature MLP were selected as
the combining parameters. A major issue in designing a MLP neural network is to
determine the optimal number of hidden units given a set of training patterns.
Therefore, a &quot;coarse to fine search&quot; method to find the number of neurons in
the hidden layer is proposed. The strategy of combining Cb/Cr and Cr features
improved the correct detection by 3.01% compared to the best single feature MLP
given by Cb-Cr. The strategy of combining the outputs of three skin classifiers
using the &quot;Sum of Weights&quot; rule further improved the correct detection by 4.38%
compared to the best single feature MLP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0395</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0395</id><created>2011-01-02</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author></authors><title>Improving the Performance of K-Means for Color Quantization</title><categories>cs.GR</categories><comments>26 pages, 4 figures, 13 tables</comments><acm-class>I.4.1</acm-class><journal-ref>Image and Vision Computing 29 (2011) 260-271</journal-ref><doi>10.1016/j.imavis.2010.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Color quantization is an important operation with many applications in
graphics and image processing. Most quantization methods are essentially based
on data clustering algorithms. However, despite its popularity as a general
purpose clustering algorithm, k-means has not received much respect in the
color quantization literature because of its high computational requirements
and sensitivity to initialization. In this paper, we investigate the
performance of k-means as a color quantizer. We implement fast and exact
variants of k-means with several initialization schemes and then compare the
resulting quantizers to some of the most popular quantizers in the literature.
Experiments on a diverse set of images demonstrate that an efficient
implementation of k-means with an appropriate initialization strategy can in
fact serve as a very effective color quantizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0403</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0403</id><created>2011-01-02</created><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author></authors><title>Impossibility of Succinct Quantum Proofs for Collision-Freeness</title><categories>quant-ph cs.CC</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any quantum algorithm to decide whether a function f:[n]-&gt;[n] is
a permutation or far from a permutation must make Omega(n^{1/3}/w) queries to
f, even if the algorithm is given a w-qubit quantum witness in support of f
being a permutation. This implies that there exists an oracle A such that SZK^A
is not contained in QMA^A, answering an eight-year-old open question of the
author. Indeed, we show that relative to some oracle, SZK is not in the
counting class A0PP defined by Vyalyi. The proof is a fairly simple extension
of the quantum lower bound for the collision problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0407</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0407</id><created>2011-01-02</created><authors><author><keyname>Xu</keyname><forenames>Xiu-Lian</forenames></author><author><keyname>Qu</keyname><forenames>Yan-Qin</forenames></author><author><keyname>Guan</keyname><forenames>Shan</forenames></author><author><keyname>Jiang</keyname><forenames>Yu-Mei</forenames></author><author><keyname>He</keyname><forenames>Da-Ren</forenames></author></authors><title>Interconnecting bilayer networks</title><categories>physics.soc-ph cs.SI</categories><comments>9 pages</comments><doi>10.1209/0295-5075/93/68002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A typical complex system should be described by a supernetwork or a network
of networks, in which the networks are coupled to some other networks. As the
first step to understanding the complex systems on such more systematic level,
scientists studied interdependent multilayer networks. In this letter, we
introduce a new kind of interdependent multilayer networks, i.e.,
interconnecting networks, for which the component networks are coupled each
other by sharing some common nodes. Based on the empirical investigations, we
revealed a common feature of such interconnecting networks, namely, the
networks with smaller averaged topological differences of the interconnecting
nodes tend to share more nodes. A very simple node sharing mechanism is
proposed to analytically explain the observed feature of the interconnecting
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0427</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0427</id><created>2011-01-02</created><authors><author><keyname>Alp&#xe1;r</keyname><forenames>Gergely</forenames></author><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author><author><keyname>Siljee</keyname><forenames>Johanneke</forenames></author></authors><title>The Identity Crisis. Security, Privacy and Usability Issues in Identity
  Management</title><categories>cs.CR</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the current &quot;identity crisis&quot; caused by the substantial
security, privacy and usability shortcomings encountered in existing systems
for identity management. Some of these issues are well known, while others are
much less understood. This paper brings them together in a single,
comprehensive study and proposes recommendations to resolve or to mitigate the
problems. Some of these problems cannot be solved without substantial research
and development effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0428</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0428</id><created>2011-01-02</created><authors><author><keyname>Fairbank</keyname><forenames>Michael</forenames></author><author><keyname>Alonso</keyname><forenames>Eduardo</forenames></author></authors><title>The Local Optimality of Reinforcement Learning by Value Gradients, and
  its Relationship to Policy Gradient Learning</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this theoretical paper we are concerned with the problem of learning a
value function by a smooth general function approximator, to solve a
deterministic episodic control problem in a large continuous state space. It is
shown that learning the gradient of the value-function at every point along a
trajectory generated by a greedy policy is a sufficient condition for the
trajectory to be locally extremal, and often locally optimal, and we argue that
this brings greater efficiency to value-function learning. This contrasts to
traditional value-function learning in which the value-function must be learnt
over the whole of state space.
  It is also proven that policy-gradient learning applied to a greedy policy on
a value-function produces a weight update equivalent to a value-gradient weight
update, which provides a surprising connection between these two alternative
paradigms of reinforcement learning, and a convergence proof for control
problems with a value function represented by a general smooth function
approximator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0457</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0457</id><created>2011-01-03</created><authors><author><keyname>Mollah</keyname><forenames>Ayatullah Faruk</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author></authors><title>Segmentation of Camera Captured Business Card Images for Mobile Devices</title><categories>cs.CV</categories><journal-ref>International Journal of Computer Science and Applications, Vol.
  1, Issue 1, pp. 33-37, June 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to huge deformation in the camera captured images, variety in nature of
the business cards and the computational constraints of the mobile devices,
design of an efficient Business Card Reader (BCR) is challenging to the
researchers. Extraction of text regions and segmenting them into characters is
one of such challenges. In this paper, we have presented an efficient character
segmentation technique for business card images captured by a cell-phone
camera, designed in our present work towards developing an efficient BCR. At
first, text regions are extracted from the card images and then the skewed ones
are corrected using a computationally efficient skew correction technique. At
last, these skew corrected text regions are segmented into lines and characters
based on horizontal and vertical histogram. Experiments show that the present
technique is efficient and applicable for mobile devices, and the mean
segmentation accuracy of 97.48% is achieved with 3 mega-pixel (500-600 dpi)
images. It takes only 1.1 seconds for segmentation including all the
preprocessing steps on a moderately powerful notebook (DualCore T2370, 1.73
GHz, 1GB RAM, 1MB L2 Cache).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0461</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0461</id><created>2011-01-03</created><updated>2011-01-05</updated><authors><author><keyname>Chen</keyname><forenames>Junting</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Cheng</keyname><forenames>Yong</forenames></author></authors><title>Distributive Network Utility Maximization (NUM) over Time-Varying Fading
  Channels</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Signal Processing, vol. 59, no. 5, pp.
  2395-2404, 2011</journal-ref><doi>10.1109/TSP.2011.2106124</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed network utility maximization (NUM) has received an increasing
intensity of interest over the past few years. Distributed solutions (e.g., the
primal-dual gradient method) have been intensively investigated under fading
channels. As such distributed solutions involve iterative updating and explicit
message passing, it is unrealistic to assume that the wireless channel remains
unchanged during the iterations. Unfortunately, the behavior of those
distributed solutions under time-varying channels is in general unknown. In
this paper, we shall investigate the convergence behavior and tracking errors
of the iterative primal-dual scaled gradient algorithm (PDSGA) with dynamic
scaling matrices (DSC) for solving distributive NUM problems under time-varying
fading channels. We shall also study a specific application example, namely the
multi-commodity flow control and multi-carrier power allocation problem in
multi-hop ad hoc networks. Our analysis shows that the PDSGA converges to a
limit region rather than a single point under the finite state Markov chain
(FSMC) fading channels. We also show that the order of growth of the tracking
errors is given by O(T/N), where T and N are the update interval and the
average sojourn time of the FSMC, respectively. Based on this analysis, we
derive a low complexity distributive adaptation algorithm for determining the
adaptive scaling matrices, which can be implemented distributively at each
transmitter. The numerical results show the superior performance of the
proposed dynamic scaling matrix algorithm over several baseline schemes, such
as the regular primal-dual gradient algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0510</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0510</id><created>2011-01-03</created><authors><author><keyname>Hansen</keyname><forenames>Lars Kai</forenames></author><author><keyname>Arvidsson</keyname><forenames>Adam</forenames></author><author><keyname>Nielsen</keyname><forenames>Finn &#xc5;rup</forenames></author><author><keyname>Colleoni</keyname><forenames>Elanor</forenames></author><author><keyname>Etter</keyname><forenames>Michael</forenames></author></authors><title>Good Friends, Bad News - Affect and Virality in Twitter</title><categories>cs.SI cs.CL physics.soc-ph</categories><comments>14 pages, 1 table. Submitted to The 2011 International Workshop on
  Social Computing, Network, and Services (SocialComNet 2011)</comments><msc-class>1D30</msc-class><acm-class>H.4.3; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The link between affect, defined as the capacity for sentimental arousal on
the part of a message, and virality, defined as the probability that it be sent
along, is of significant theoretical and practical importance, e.g. for viral
marketing. A quantitative study of emailing of articles from the NY Times finds
a strong link between positive affect and virality, and, based on psychological
theories it is concluded that this relation is universally valid. The
conclusion appears to be in contrast with classic theory of diffusion in news
media emphasizing negative affect as promoting propagation. In this paper we
explore the apparent paradox in a quantitative analysis of information
diffusion on Twitter. Twitter is interesting in this context as it has been
shown to present both the characteristics social and news media. The basic
measure of virality in Twitter is the probability of retweet. Twitter is
different from email in that retweeting does not depend on pre-existing social
relations, but often occur among strangers, thus in this respect Twitter may be
more similar to traditional news media. We therefore hypothesize that negative
news content is more likely to be retweeted, while for non-news tweets positive
sentiments support virality. To test the hypothesis we analyze three corpora: A
complete sample of tweets about the COP15 climate summit, a random sample of
tweets, and a general text corpus including news. The latter allows us to train
a classifier that can distinguish tweets that carry news and non-news
information. We present evidence that negative sentiment enhances virality in
the news segment, but not in the non-news segment. We conclude that the
relation between affect and virality is more complex than expected based on the
findings of Berger and Milkman (2010), in short 'if you want to be cited: Sweet
talk your friends or serve bad news to the public'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0511</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0511</id><created>2011-01-03</created><authors><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author></authors><title>FORM development</title><categories>hep-ph cs.SC</categories><comments>Talk given at the 3rd Computational Particle Physics Workshop,
  Tsukuba, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I give an overview of FORM development based on a few pilot projects,
explaining how they have influenced the FORM capabilities. Next I explain what
is happnening right now in the field of Open Sourcing and the FORM Forum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0523</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0523</id><created>2011-01-03</created><authors><author><keyname>Klauck</keyname><forenames>Hartmut</forenames></author></authors><title>On Arthur Merlin Games in Communication Complexity</title><categories>cs.CC quant-ph</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show several results related to interactive proof modes of communication
complexity. First we show lower bounds for the QMA-communication complexity of
the functions Inner Product and Disjointness. We describe a general method to
prove lower bounds for QMA-communication complexity, and show how one can
'transfer' hardness under an analogous measure in the query complexity model to
the communication model using Sherstov's pattern matrix method. Combining a
result by Vereshchagin and the pattern matrix method we find a communication
problem with AM-communication complexity $O(\log n)$, PP-communication
complexity $\Omega(n^{1/3})$, and QMA-communication complexity
$\Omega(n^{1/6})$. Hence in the world of communication complexity
noninteractive quantum proof systems are not able to efficiently simulate
co-nondeterminism or interaction. These results imply that the related
questions in Turing machine complexity theory cannot be resolved by
'algebrizing' techniques. Finally we show that in MA-protocols there is an
exponential gap between one-way protocols and two-way protocols (this refers to
the interaction between Alice and Bob). This is in contrast to
nondeterministic, AM-, and QMA-protocols, where one-way communication is
essentially optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0529</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0529</id><created>2011-01-03</created><authors><author><keyname>Valipour</keyname><forenames>Mehrdad</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author></authors><title>Channel Optimized Distributed Multiple Description Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transaction on Signal Processing</comments><doi>10.1109/TSP.2011.2180903</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, channel optimized distributed multiple description vector
quantization (CDMD) schemes are presented for distributed source coding in
symmetric and asymmetric settings. The CDMD encoder is designed using a
deterministic annealing approach over noisy channels with packet loss. A
minimum mean squared error asymmetric CDMD decoder is proposed for effective
reconstruction of a source, utilizing the side information (SI) and its
corresponding received descriptions. The proposed iterative symmetric CDMD
decoder jointly reconstructs the symbols of multiple correlated sources. Two
types of symmetric CDMD decoders, namely the estimated-SI and the soft-SI
decoders, are presented which respectively exploit the reconstructed symbols
and a posteriori probabilities of other sources as SI in iterations. In a
multiple source CDMD setting, for reconstruction of a source, three methods are
proposed to select another source as its SI during the decoding. The methods
operate based on minimum physical distance (in a wireless sensor network
setting), maximum mutual information and minimum end-to-end distortion. The
performance of the proposed systems and algorithms are evaluated and compared
in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0530</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0530</id><created>2011-01-03</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>Coordinates for a new triangular tiling of the hyperbolic plane</title><categories>cs.FL</categories><comments>15 pages, 8 figures, 3 tables</comments><msc-class>68R05</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we define an infinite family of triangular tilings of the
hyperbolic plane defined by two parameters ranging in the natural nummbers and
we give a uniform way to define coordinates for locating the triangles of the
tiling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0552</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0552</id><created>2011-01-03</created><authors><author><keyname>Broek</keyname><forenames>Fabian van den</forenames></author></authors><title>Eavesdropping on GSM: state-of-affairs</title><categories>cs.CR</categories><comments>5th Benelux Workshop on Information and System Security (WISSec
  2010), November 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the almost 20 years since GSM was deployed several security problems have
been found, both in the protocols and in the - originally secret -
cryptography. However, practical exploits of these weaknesses are complicated
because of all the signal processing involved and have not been seen much
outside of their use by law enforcement agencies.
  This could change due to recently developed open-source equipment and
software that can capture and digitize signals from the GSM frequencies. This
might make practical attacks against GSM much simpler to perform.
  Indeed, several claims have recently appeared in the media on successfully
eavesdropping on GSM. When looking at these claims in depth the conclusion is
often that more is claimed than what they are actually capable of. However, it
is undeniable that these claims herald the possibilities to eavesdrop on GSM
using publicly available equipment.
  This paper evaluates the claims and practical possibilities when it comes to
eavesdropping on GSM, using relatively cheap hardware and open source
initiatives which have generated many headlines over the past year. The basis
of the paper is extensive experiments with the USRP (Universal Software Radio
Peripheral) and software projects for this hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0562</identifier>
 <datestamp>2015-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0562</id><created>2011-01-03</created><authors><author><keyname>Li</keyname><forenames>Tianji</forenames></author><author><keyname>Leith</keyname><forenames>Douglas</forenames></author><author><keyname>Malone</keyname><forenames>David</forenames></author></authors><title>Buffer Sizing for 802.11 Based Networks</title><categories>cs.NI</categories><comments>14 pages, to appear on IEEE/ACM Transactions on Networking</comments><journal-ref>IEEE/ACM Transactions on Networking Vol 19, Issue 1, 156--169,
  2011</journal-ref><doi>10.1109/TNET.2010.2089992</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the sizing of network buffers in 802.11 based networks. Wireless
networks face a number of fundamental issues that do not arise in wired
networks. We demonstrate that the use of fixed size buffers in 802.11 networks
inevitably leads to either undesirable channel under-utilization or unnecessary
high delays. We present two novel dynamic buffer sizing algorithms that achieve
high throughput while maintaining low delay across a wide range of network
conditions. Experimental measurements demonstrate the utility of the proposed
algorithms in a production WLAN and a lab testbed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0564</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0564</id><created>2011-01-03</created><authors><author><keyname>Bisson</keyname><forenames>Gaetan</forenames></author><author><keyname>Sutherland</keyname><forenames>Andrew V.</forenames></author></authors><title>A low-memory algorithm for finding short product representations in
  finite groups</title><categories>math.NT cs.CR math.GR</categories><comments>12 pages</comments><journal-ref>Designs Codes and Cryptography 63 (2012), 1-13</journal-ref><doi>10.1007/s10623-011-9527-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a space-efficient algorithm for solving a generalization of the
subset sum problem in a finite group G, using a Pollard-rho approach. Given an
element z and a sequence of elements S, our algorithm attempts to find a
subsequence of S whose product in G is equal to z. For a random sequence S of
length d log_2 n, where n=#G and d &gt;= 2 is a constant, we find that its
expected running time is O(sqrt(n) log n) group operations (we give a rigorous
proof for d &gt; 4), and it only needs to store O(1) group elements. We consider
applications to class groups of imaginary quadratic fields, and to finding
isogenies between elliptic curves over a finite field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0565</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0565</id><created>2011-01-03</created><updated>2012-06-29</updated><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Korman</keyname><forenames>Matias</forenames></author></authors><title>Coloring Planar Homothets and Three-Dimensional Hypergraphs</title><categories>cs.CG</categories><comments>Preliminary version of this paper appeared in Latin 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The inclusion relation between simple objects in the plane may be used to
define geometric set systems, or hypergraphs. Properties of various types of
colorings of these hypergraphs have been the subject of recent investigations,
with applications to wireless networking.
  We first prove that every set of homothetic copies of a given convex body in
the plane can be colored with four colors so that any point covered by at least
two copies is covered by two copies with distinct colors. This generalizes a
previous result from Smorodinsky [18]. As a corollary, we find improvements to
well studied variations of the coloring problem such as conflict-free
colorings, k-strong (conflict-free) colorings and choosability. We also show a
relation between our proof and Schnyder's characterization of planar graphs.
Then we show that for any k &gt;1, every three-dimensional hypergraph can be
colored with 6(k - 1) colors so that every hyperedge e contains min{|e|, k}
vertices with mutually distinct colors. Furthermore, we also show that at least
2k colors might be necessary. This refines a previous result from Aloupis et
al. [2].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0578</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0578</id><created>2011-01-03</created><authors><author><keyname>Cie&#x15b;li&#x144;ski</keyname><forenames>Jan L.</forenames></author></authors><title>Locally exact modifications of numerical integrators</title><categories>math.NA cs.NA</categories><comments>33 pages, 0 figures</comments><msc-class>65P10, 65L12, 34K28</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new class of exponential integrators for ordinary differential
equations. They are locally exact, i.e., they preserve the linearization of the
original system at every point. Their construction consists in modifying
existing numerical schemes in order to make them locally exact. The resulting
schemes preserve all fixed points and are A-stable. The most promising results
concern the discrete gradient method (modified implicit midpoint rule) where we
succeeded to preserve essential geometric properties and the final results have
a relatively simple form. In the case of one-dimensional Hamiltonian systems
numerical experiments show that our modifications can increase the accuracy by
several orders of magnitude. The main result of this paper is the construction
of energy-preserving locally exact discrete gradient schemes for arbitrary
multidimensional Hamiltonian systems in canonical coordinates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0605</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0605</id><created>2011-01-03</created><authors><author><keyname>Groen</keyname><forenames>Derek</forenames><affiliation>Leiden University</affiliation></author><author><keyname>Zwart</keyname><forenames>Simon Portegies</forenames><affiliation>Leiden University</affiliation></author><author><keyname>Ishiyama</keyname><forenames>Tomoaki</forenames><affiliation>NAOJ, Tokyo</affiliation></author><author><keyname>Makino</keyname><forenames>Junichiro</forenames><affiliation>NAOJ, Tokyo</affiliation></author></authors><title>High Performance Gravitational N-body Simulations on a Planet-wide
  Distributed Supercomputer</title><categories>cs.DC astro-ph.CO</categories><comments>30 pages, 11 figures, accepted by Comp. Science and Discovery</comments><msc-class>68M14 (primary), 68M20, 85-08, 85A40 (secondary)</msc-class><acm-class>C.2.4; C.2.5</acm-class><journal-ref>Comput. Sci. Disc. 4 (2011) 015001</journal-ref><doi>10.1088/1749-4699/4/1/015001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on the performance of our cold-dark matter cosmological N-body
simulation which was carried out concurrently using supercomputers across the
globe. We ran simulations on 60 to 750 cores distributed over a variety of
supercomputers in Amsterdam (the Netherlands, Europe), in Tokyo (Japan, Asia),
Edinburgh (UK, Europe) and Espoo (Finland, Europe). Regardless the network
latency of 0.32 seconds and the communication over 30.000 km of optical network
cable we are able to achieve about 87% of the performance compared to an equal
number of cores on a single supercomputer. We argue that using widely
distributed supercomputers in order to acquire more compute power is
technically feasible, and that the largest obstacle is introduced by local
scheduling and reservation policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0613</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0613</id><created>2011-01-03</created><authors><author><keyname>Bogen</keyname><forenames>Paul Logasa</forenames><suffix>II</suffix></author><author><keyname>Shipman</keyname><forenames>Frank</forenames></author><author><keyname>Furuta</keyname><forenames>Richard</forenames></author></authors><title>Distributed Collections of Web Pages in the Wild</title><categories>cs.DL cs.HC cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the Distributed Collection Manager's work on building tools to support
users maintaining collections of changing web-based resources has progressed,
questions about the characteristics of people's collections of web pages have
arisen. Simultaneously, work in the areas of social bookmarking, social news,
and subscription-based technologies have been taking the existence, usage, and
utility of this data for granted with neither investigation into what people
are doing with their collections nor how they are trying to maintain them. In
order to address these concerns, we performed an online user study of 125
individuals from a variety of online and offline communities, such as the
reddit social news user community and the graduate student body in our
department. From this study we were able to examine a user's needs for a system
to manage their web-based distributed collections, how their current tools
affect their ability to maintain their collections, and what the
characteristics of their current practices and problems in maintaining their
web-based collections were. We also present extensions and improvements being
made to the system both in order to adapt DCM for usage in the Ensemble project
and to meet the requirements found by our user study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0640</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0640</id><created>2011-01-03</created><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author></authors><title>A note on outer bounds for broadcast channel</title><categories>cs.IT math.IT</categories><comments>This was presented in the International Zurich Seminar 2010. This is
  just for a documented proof of the result</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we establish two facts concerning the so-called {\em New-Jersey}
outer bound. We show that this outer bound is equivalent to a much simpler {\em
computable} region; and secondly we show that in the absence of private
information this bound is exactly same as the $UV$-outerbound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0653</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0653</id><created>2011-01-04</created><authors><author><keyname>Seyfi</keyname><forenames>Mehdi</forenames></author><author><keyname>Muhaidat</keyname><forenames>Sami</forenames></author><author><keyname>Liang</keyname><forenames>Jie</forenames></author></authors><title>On the Performance of Selection Cooperation with Outdated CSI and
  Channel Estimation Errors</title><categories>cs.IT math.IT</categories><comments>11 pages and 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the performance of selection cooperation in the
presence of imperfect channel estimation. In particular, we consider a
cooperative scenario with multiple relays and amplify-and-forward protocol over
frequency flat fading channels. In the selection scheme, only the &quot;best&quot; relay
which maximizes the effective signal-to-noise ratio (SNR) at the receiver end
is selected. We present lower and upper bounds on the effective SNR and derive
closed-form expressions for the average symbol error rate (ASER), outage
probability and average capacity per bandwidth of the received signal in the
presence of channel estimation errors. A simulation study is presented to
corroborate the analytical results and to demonstrate the performance of relay
selection with imperfect channel estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0654</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0654</id><created>2011-01-04</created><authors><author><keyname>Stewar</keyname><forenames>Avar&#xe9;</forenames><affiliation>L3S Research Center / LUH. Hannover, Germany</affiliation></author><author><keyname>Lage</keyname><forenames>Ricardo</forenames><affiliation>Aalborg University. Aalborg, Denmark</affiliation></author><author><keyname>Diaz-Aviles</keyname><forenames>Ernesto</forenames><affiliation>L3S Research Center / LUH. Hannover, Germany</affiliation></author><author><keyname>Dolog</keyname><forenames>Peter</forenames><affiliation>Aalborg University. Aalborg, Denmark</affiliation></author></authors><title>Personalized Event-Based Surveillance and Alerting Support for the
  Assessment of Risk</title><categories>cs.CY</categories><comments>International Meeting on Emerging Diseases and Surveillance. IMED
  2011 - Poster Session - Vienna, Austria. February 4-7, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a typical Event-Based Surveillance setting, a stream of web documents is
continuously monitored for disease reporting. A structured representation of
the disease reporting events is extracted from the raw text, and the events are
then aggregated to produce signals, which are intended to represent early
warnings against potential public health threats.
  To public health officials, these warnings represent an overwhelming list of
&quot;one-size-fits-all&quot; information for risk assessment. To reduce this overload,
two techniques are proposed. First, filtering signals according to the user's
preferences (e.g., location, disease, symptoms, etc.) helps reduce the
undesired noise. Second, re-ranking the filtered signals, according to an
individual's feedback and annotation, allows a user-specific, prioritized
ranking of the most relevant warnings.
  We introduce an approach that takes into account this two-step process of: 1)
filtering and 2) re-ranking the results of reporting signals. For this,
Collaborative Filtering and Personalization are common techniques used to
support users in dealing with the large amount of information that they face.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0656</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0656</id><created>2011-01-04</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Cao</keyname><forenames>Xian-Bin</forenames></author><author><keyname>Du</keyname><forenames>Wen-Bo</forenames></author><author><keyname>Cai</keyname><forenames>Kai-Quan</forenames></author></authors><title>Evolution of Chinese airport network</title><categories>stat.AP cs.SI physics.soc-ph</categories><comments>10 pages, 10 figures, Physica A 389 (2010) 3922-3931</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of economy and the accelerated globalization
process, the aviation industry plays more and more critical role in today's
world, in both developed and developing countries. As the infrastructure of
aviation industry, the airport network is one of the most important indicators
of economic growth. In this paper, we investigate the evolution of Chinese
airport network (CAN) via complex network theory. It is found that although the
topology of CAN remains steady during the past several years, there are many
dynamic switchings inside the network, which changes the relative relevance of
airports and airlines. Moreover, we investigate the evolution of traffic flow
(passengers and cargoes) on CAN. It is found that the traffic keeps growing in
an exponential form and it has evident seasonal fluctuations. We also found
that cargo traffic and passenger traffic are positively related but the
correlations are quite different for different kinds of cities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0663</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0663</id><created>2011-01-04</created><authors><author><keyname>Song</keyname><forenames>Miao</forenames></author></authors><title>The Role of Computer Graphics in Documentary Film Production</title><categories>cs.GR cs.HC</categories><comments>35 pages; 7 figures; an April 2009 research paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a topic on the role of computer graphics in the production of
documentaries, which is often ignored in favor of other topics. Typically,
except for some rare occasions, documentary producers and computer scientists
or digital artists that do computer graphics are relatively far apart in their
domains and rarely intercommunicate to have a joint production; yet it happens,
and perhaps more so in the present and the future.
  We attempt to classify the documentaries on the amount and techniques of
computer graphics used for documentaries. We come up with the initial
categories such as &quot;plain&quot; (no graphics), &quot;in-between&quot;, &quot;all-out&quot; -- nearly
100% of the documentary consisting of computer-generated imagery. Computer
graphics can be used to enhance the scenery, fill in the gaps in the missing
storyline pieces, or animate between scenes. It can incorporate stereoscopic
effects for higher viewer impression as well as interactivity aspects. It can
also be used simply in old archived image and film restoration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0664</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0664</id><created>2011-01-04</created><authors><author><keyname>Tarnavsky</keyname><forenames>G. A.</forenames></author><author><keyname>Vorozhtsov</keyname><forenames>E. V.</forenames></author></authors><title>Computer Simulation Center in Internet</title><categories>cs.DC</categories><comments>12 pages, 8 figures</comments><msc-class>68U01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The general description of infrastructure and content of SciShop.ru computer
simulation center is given. This resource is a new form of knowledge generation
and remote education using modern Cloud Computing technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0679</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0679</id><created>2011-01-04</created><authors><author><keyname>Coulais</keyname><forenames>A.</forenames><affiliation>LERMA, Obs. de Paris, ENS, UPMC, UCP, CNRS, Paris, France</affiliation></author><author><keyname>Schellens</keyname><forenames>M.</forenames><affiliation>Goddard Space Flight Center, Greenbelt, MD, USA</affiliation></author><author><keyname>Gales</keyname><forenames>J.</forenames><affiliation>Goddard Space Flight Center, Greenbelt, MD, USA</affiliation></author><author><keyname>Arabas</keyname><forenames>S.</forenames><affiliation>Institute of Geophysics, Faculty of Physics, University of Warsaw, Poland</affiliation></author><author><keyname>Boquien</keyname><forenames>M.</forenames><affiliation>University of Massachusetts, Dep. of Astronomy, Amherst, MA, USA</affiliation></author><author><keyname>Chanial</keyname><forenames>P.</forenames><affiliation>Tech-X GmbH, Zurich, Switzerland, Tech-X Corp, Boulder, CO, USA</affiliation></author><author><keyname>Messmer</keyname><forenames>P.</forenames><affiliation>Colorado Div</affiliation></author><author><keyname>Fillmore</keyname><forenames>D.</forenames><affiliation>Tech-X GmbH, Zurich, Switzerland, Tech-X Corp, Boulder, CO, USA</affiliation></author><author><keyname>Poplawski</keyname><forenames>O.</forenames><affiliation>Colorado Div</affiliation></author><author><keyname>Maret</keyname><forenames>S.</forenames><affiliation>LAOG, Obs. de Grenoble, UJF, CNRS, Grenoble, France</affiliation></author><author><keyname>Marchal</keyname><forenames>G.</forenames><affiliation>LERMA, Obs. de Paris, ENS, UPMC, UCP, CNRS, Paris, France</affiliation></author><author><keyname>Galmiche</keyname><forenames>N.</forenames><affiliation>LERMA, Obs. de Paris, ENS, UPMC, UCP, CNRS, Paris, France</affiliation></author><author><keyname>Mermet</keyname><forenames>T.</forenames><affiliation>LERMA, Obs. de Paris, ENS, UPMC, UCP, CNRS, Paris, France</affiliation></author></authors><title>Status of GDL - GNU Data Language</title><categories>astro-ph.IM cs.CE</categories><comments>talk given at ADASS-XIX; to appear in ASP Conference Series; 4 pages,
  no figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GNU Data Language (GDL) is an open-source interpreted language aimed at
numerical data analysis and visualisation. It is a free implementation of the
Interactive Data Language (IDL) widely used in Astronomy. GDL has a full syntax
compatibility with IDL, and includes a large set of library routines targeting
advanced matrix manipulation, plotting, time-series and image analysis,
mapping, and data input/output including numerous scientific data formats. We
will present the current status of the project, the key accomplishments, and
the weaknesses - areas where contributions are welcome !
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0698</identifier>
 <datestamp>2011-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0698</id><created>2011-01-04</created><updated>2011-06-23</updated><authors><author><keyname>Gans</keyname><forenames>Gerhard de Koning</forenames></author><author><keyname>Verheul</keyname><forenames>Eric R.</forenames></author></authors><title>Best Effort and Practice Activation Codes</title><categories>cs.CR cs.CE</categories><comments>15 pages, 3 figures, TrustBus 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Activation Codes are used in many different digital services and known by
many different names including voucher, e-coupon and discount code. In this
paper we focus on a specific class of ACs that are short, human-readable,
fixed-length and represent value. Even though this class of codes is
extensively used there are no general guidelines for the design of Activation
Code schemes. We discuss different methods that are used in practice and
propose BEPAC, a new Activation Code scheme that provides both authenticity and
confidentiality. The small message space of activation codes introduces some
problems that are illustrated by an adaptive chosen-plaintext attack (CPA-2) on
a general 3-round Feis- tel network of size 2^(2n) . This attack recovers the
complete permutation from at most 2^(n+2) plaintext-ciphertext pairs. For this
reason, BEPAC is designed in such a way that authenticity and confidentiality
are in- dependent properties, i.e. loss of confidentiality does not imply loss
of authenticity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0764</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0764</id><created>2011-01-04</created><updated>2011-07-03</updated><authors><author><keyname>Presman</keyname><forenames>Noam</forenames></author><author><keyname>Shapira</keyname><forenames>Ofer</forenames></author><author><keyname>Litsyn</keyname><forenames>Simon</forenames></author></authors><title>Binary Polar Code Kernels from Code Decompositions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code decompositions (a.k.a code nestings) are used to design good binary
polar code kernels. The proposed kernels are in general non-linear and show a
better rate of polarization under successive cancelation decoding, than the
ones suggested by Korada et al., for the same kernel dimensions. In particular,
kernels of sizes 14, 15 and 16 are constructed and shown to provide
polarization rates better than any binary kernel of such sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0766</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0766</id><created>2011-01-04</created><authors><author><keyname>Paruchuri</keyname><forenames>Venkata Ravinder</forenames></author></authors><title>Information Retrieval of Jumbled Words</title><categories>cs.IR</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that humans can easily read words where the letters have been
jumbled in a certain way. This paper examines this problem by associating a
distance measure with the jumbling process. Modifications to text were
generated according to the Damerau-Levenshtein distance and it was checked if
the users are able to read it. Graphical representations of the results are
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0768</identifier>
 <datestamp>2012-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0768</id><created>2011-01-04</created><updated>2012-02-23</updated><authors><author><keyname>Clifford</keyname><forenames>Raphael</forenames></author><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author></authors><title>Tight Cell-Probe Bounds for Online Integer Multiplication and
  Convolution</title><categories>cs.DS cs.CC</categories><comments>15 pages, 2 figures</comments><acm-class>F.2.2; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show tight bounds for both online integer multiplication and convolution
in the cell-probe model with word size w. For the multiplication problem, one
pair of digits, each from one of two n digit numbers that are to be multiplied,
is given as input at step i. The online algorithm outputs a single new digit
from the product of the numbers before step i+1. We give a Theta((d/w)*log n)
bound on average per output digit for this problem where 2^d is the maximum
value of a digit. In the convolution problem, we are given a fixed vector V of
length n and we consider a stream in which numbers arrive one at a time. We
output the inner product of V and the vector that consists of the last n
numbers of the stream. We show a Theta((d/w)*log n) bound for the number of
probes required per new number in the stream. All the bounds presented hold
under randomisation and amortisation. Multiplication and convolution are
central problems in the study of algorithms which also have the widest range of
practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0776</identifier>
 <datestamp>2013-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0776</id><created>2011-01-04</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Johannsen</keyname><forenames>Daniel</forenames></author><author><keyname>Winzen</keyname><forenames>Carola</forenames></author></authors><title>Multiplicative Drift Analysis</title><categories>cs.NE</categories><comments>Contains results from our GECCO 2010 and CEC 2010 conference paper</comments><journal-ref>Algorithmica, 2012, Volume 64, Issue 4, pp 673-697</journal-ref><doi>10.1007/s00453-012-9622-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce multiplicative drift analysis as a suitable way to
analyze the runtime of randomized search heuristics such as evolutionary
algorithms.
  We give a multiplicative version of the classical drift theorem. This allows
easier analyses in those settings where the optimization progress is roughly
proportional to the current distance to the optimum.
  To display the strength of this tool, we regard the classical problem how the
(1+1) Evolutionary Algorithm optimizes an arbitrary linear pseudo-Boolean
function. Here, we first give a relatively simple proof for the fact that any
linear function is optimized in expected time $O(n \log n)$, where $n$ is the
length of the bit string. Afterwards, we show that in fact any such function is
optimized in expected time at most ${(1+o(1)) 1.39 \euler n\ln (n)}$, again
using multiplicative drift analysis. We also prove a corresponding lower bound
of ${(1-o(1))e n\ln(n)}$ which actually holds for all functions with a unique
global optimum.
  We further demonstrate how our drift theorem immediately gives natural proofs
(with better constants) for the best known runtime bounds for the (1+1)
Evolutionary Algorithm on combinatorial problems like finding minimum spanning
trees, shortest paths, or Euler tours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0777</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0777</id><created>2011-01-04</created><authors><author><keyname>Schoenemann</keyname><forenames>Thomas</forenames></author><author><keyname>Masnou</keyname><forenames>Simon</forenames></author><author><keyname>Cremers</keyname><forenames>Daniel</forenames></author></authors><title>On a linear programming approach to the discrete Willmore boundary value
  problem and generalizations</title><categories>cs.CG cs.NA math.NA math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding (possibly non connected) discrete surfaces
spanning a finite set of discrete boundary curves in the three-dimensional
space and minimizing (globally) a discrete energy involving mean curvature.
Although we consider a fairly general class of energies, our main focus is on
the Willmore energy, i.e. the total squared mean curvature Our purpose is to
address the delicate task of approximating global minimizers of the energy
under boundary constraints.
  The main contribution of this work is to translate the nonlinear boundary
value problem into an integer linear program, using a natural formulation
involving pairs of elementary triangles chosen in a pre-specified dictionary
and allowing self-intersection.
  Our work focuses essentially on the connection between the integer linear
program and its relaxation. We prove that: - One cannot guarantee the total
unimodularity of the constraint matrix, which is a sufficient condition for the
global solution of the relaxed linear program to be always integral, and
therefore to be a solution of the integer program as well; - Furthermore, there
are actually experimental evidences that, in some cases, solving the relaxed
problem yields a fractional solution. Due to the very specific structure of the
constraint matrix here, we strongly believe that it should be possible in the
future to design ad-hoc integer solvers that yield high-definition
approximations to solutions of several boundary value problems involving mean
curvature, in particular the Willmore boundary value problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0788</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0788</id><created>2011-01-04</created><updated>2011-01-11</updated><authors><author><keyname>Thomas</keyname><forenames>Andrew C.</forenames></author><author><keyname>Blitzstein</keyname><forenames>Joseph K.</forenames></author></authors><title>Valued Ties Tell Fewer Lies: Why Not To Dichotomize Network Edges With
  Thresholds</title><categories>stat.AP cs.SI physics.soc-ph</categories><comments>36 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to conduct analyses of networked systems where connections between
individuals take on a range of values - counts, continuous strengths or ordinal
rankings - a common technique is to dichotomize the data according to their
positions with respect to a threshold value. However, there are two issues to
consider: how the results of the analysis depend on the choice of threshold,
and what role the presence of noise has on a system with respect to a fixed
threshold value. We show that while there are principled criteria of keeping
information from the valued graph in the dichotomized version, they produce
such a wide range of binary graphs that only a fraction of the relevant
information will be kept. Additionally, while dichotomization of predictors in
linear models has a known asymptotic efficiency loss, the same process applied
to network edges in a time series model will lead to an efficiency loss that
grows larger as the network increases in size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0792</identifier>
 <datestamp>2012-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0792</id><created>2011-01-04</created><updated>2011-10-02</updated><authors><author><keyname>Brattka</keyname><forenames>Vasco</forenames></author><author><keyname>Gherardi</keyname><forenames>Guido</forenames></author><author><keyname>Marcone</keyname><forenames>Alberto</forenames></author></authors><title>The Bolzano-Weierstrass Theorem is the Jump of Weak K\&quot;onig's Lemma</title><categories>math.LO cs.LO</categories><comments>48 pages</comments><journal-ref>Annals of Pure and Applied Logic 163:6 (2012) 623--655</journal-ref><doi>10.1016/j.apal.2011.10.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We classify the computational content of the Bolzano-Weierstrass Theorem and
variants thereof in the Weihrauch lattice. For this purpose we first introduce
the concept of a derivative or jump in this lattice and we show that it has
some properties similar to the Turing jump. Using this concept we prove that
the derivative of closed choice of a computable metric space is the cluster
point problem of that space. By specialization to sequences with a relatively
compact range we obtain a characterization of the Bolzano-Weierstrass Theorem
as the derivative of compact choice. In particular, this shows that the
Bolzano-Weierstrass Theorem on real numbers is the jump of Weak K\&quot;onig's
Lemma. Likewise, the Bolzano-Weierstrass Theorem on the binary space is the
jump of the lesser limited principle of omniscience LLPO and the
Bolzano-Weierstrass Theorem on natural numbers can be characterized as the jump
of the idempotent closure of LLPO. We also introduce the compositional product
of two Weihrauch degrees f and g as the supremum of the composition of any two
functions below f and g, respectively. We can express the main result such that
the Bolzano-Weierstrass Theorem is the compositional product of Weak K\&quot;onig's
Lemma and the Monotone Convergence Theorem. We also study the class of weakly
limit computable functions, which are functions that can be obtained by
composition of weakly computable functions with limit computable functions. We
prove that the Bolzano-Weierstrass Theorem on real numbers is complete for this
class. Likewise, the unique cluster point problem on real numbers is complete
for the class of functions that are limit computable with finitely many mind
changes. We also prove that the Bolzano-Weierstrass Theorem on real numbers
and, more generally, the unbounded cluster point problem on real numbers is
uniformly low limit computable. Finally, we also discuss separation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0820</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0820</id><created>2010-12-27</created><authors><author><keyname>Tarasenko</keyname><forenames>Sergey</forenames></author></authors><title>Emotionally Colorful Reflexive Games</title><categories>cs.MA</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study addresses the matter of reflexive control of the emotional states
by means of Reflexive Game Theory (RGT). It is shown how to build a bridge
between RGT and emotions. For this purpose the Pleasure-Arousal-Dominance (PAD)
model is adopted. The major advantages of RGT are its ability to predict human
behavior and unfold the entire spectra of reflexion in the human mind. On the
other hand, PAD provides ultimate approach to model emotions. It is illustrated
that emotions are reflexive processes and, consequently, RGT fused with PAD
model is natural solution to model emotional interactions between people. The
fusion of RGT and PAD, called Emotional Reflexive Games (ERG), inherits the key
features of both components. Using ERG, we show how reflexive control can be
successfully applied to model human emotional states. Up to date, EGR is a
unique methodology capable of modeling human reflexive processes and emotional
aspects simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0823</identifier>
 <datestamp>2011-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0823</id><created>2011-01-04</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Convex Polyhedra Realizing Given Face Areas</title><categories>cs.DM</categories><comments>6 pages, 3 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given n &gt;= 4 positive real numbers, we prove in this note that they are the
face areas of a convex polyhedron if and only if the largest number is not more
than the sum of the others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0827</identifier>
 <datestamp>2011-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0827</id><created>2011-01-04</created><authors><author><keyname>Machado</keyname><forenames>P&#xe9;ricles Lopes</forenames></author></authors><title>O Algoritmo usado no programa de criptografia PASME</title><categories>cs.CR math.NT</categories><comments>2 p\'aginas</comments><msc-class>11Z05</msc-class><acm-class>D.4.6</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This work present the main encryption's algorithm of the PASME tool. This
software allows encrypt and hide an information in various types of files. The
algorithm uses the fact that factoring large numbers is a difficult issue in
terms of computational performing to make the main steps of the encryption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0833</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0833</id><created>2011-01-04</created><updated>2011-04-14</updated><authors><author><keyname>Galatolo</keyname><forenames>Stefano</forenames></author><author><keyname>Hoyrup</keyname><forenames>Mathieu</forenames></author><author><keyname>Rojas</keyname><forenames>Crist&#xf3;bal</forenames></author></authors><title>Dynamical systems, simulation, abstract computation</title><categories>math.DS cs.CE nlin.CD</categories><msc-class>37M25 37M05 03D78</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey an area of recent development, relating dynamics to theoretical
computer science. We discuss the theoretical limits of simulation and
computation of interesting quantities in dynamical systems. We will focus on
central objects of the theory of dynamics, as invariant measures and invariant
sets, showing that even if they can be computed with arbitrary precision in
many interesting cases, there exists some cases in which they can not. We also
explain how it is possible to compute the speed of convergence of ergodic
averages (when the system is known exactly) and how this entails the
computation of arbitrarily good approximations of points of the space having
typical statistical behaviour (a sort of constructive version of the pointwise
ergodic theorem).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0854</identifier>
 <datestamp>2011-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0854</id><created>2011-01-04</created><authors><author><keyname>Hui</keyname><forenames>Bing</forenames></author><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>Improved Achievable Rates for Regularized Tomlinson-Harashima Precoding
  in Multiuser MIMO Downlink</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures [The 20th Personal, Indoor and Mobile Radio
  Communications Symposium 2009 (PIMRC-09)]</comments><journal-ref>The 20th Personal, Indoor and Mobile Radio Communications
  Symposium 2009 (PIMRC-09)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tomlinson-Harashima precoding (THP) is considered as a prominent precoding
scheme due to its capability to efficiently cancel out the known interference
at the transmitter side. Therefore, the information rates achieved by THP are
superior to those achieved by conventional linear precoding schemes. In this
paper, a new lower bound on the achievable information rate for the regularized
THP scheme under additive white Gaussian noise (AWGN) channel with multiuser
interference is derived. Analytical results show that the lower bound derived
in this paper is tighter than the original lower bound particularly for a low
SNR range, while all lower bounds converge to 0.5xlog2(6SNR/{\pi}e) as SNR
approaches infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0855</identifier>
 <datestamp>2011-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0855</id><created>2011-01-04</created><authors><author><keyname>An</keyname><forenames>HongSun</forenames></author><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>Lattice Reduction Aided Precoding for Multiuser MIMO using Seysen's
  Algorithm</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, [The 20th Personal, Indoor and Mobile Radio
  Communications Symposium 2009 (PIMRC-09)]</comments><journal-ref>The 20th Personal, Indoor and Mobile Radio Communications
  Symposium 2009 (PIMRC-09)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lenstra-Lenstra-Lovasz (LLL) algorithm, which is one of the lattice reduction
(LR) techniques, has been extensively used to obtain better basis of the
channel matrix. In this paper, we jointly apply Seysen's lattice reduction
algorithm (SA), instead of LLL, with the conventional linear precoding
algorithms. Since SA obtains more orthogonal lattice basis compared to that
obtained by LLL, lattice reduction aided (LRA) precoding based on SA algorithm
outperforms the LRA precoding with LLL. Simulation results demonstrate that a
gain of 0.5dB at target BER of 10^-5 is achieved when SA is used instead of LLL
for the LR stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0858</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0858</id><created>2011-01-04</created><updated>2011-01-17</updated><authors><author><keyname>Balister</keyname><forenames>Paul</forenames></author><author><keyname>Bollob&#xe1;s</keyname><forenames>B&#xe9;la</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Willsky</keyname><forenames>Alan</forenames></author></authors><title>Energy-Latency Tradeoff for In-Network Function Computation in Random
  Networks</title><categories>cs.NI math.CO</categories><comments>A shorter version appears in Proc. of IEEE INFOCOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of designing policies for in-network function computation with
minimum energy consumption subject to a latency constraint is considered. The
scaling behavior of the energy consumption under the latency constraint is
analyzed for random networks, where the nodes are uniformly placed in growing
regions and the number of nodes goes to infinity. The special case of sum
function computation and its delivery to a designated root node is considered
first. A policy which achieves order-optimal average energy consumption in
random networks subject to the given latency constraint is proposed. The
scaling behavior of the optimal energy consumption depends on the path-loss
exponent of wireless transmissions and the dimension of the Euclidean region
where the nodes are placed. The policy is then extended to computation of a
general class of functions which decompose according to maximal cliques of a
proximity graph such as the $k$-nearest neighbor graph or the geometric random
graph. The modified policy achieves order-optimal energy consumption albeit for
a limited range of latency constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0869</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0869</id><created>2011-01-04</created><updated>2011-01-19</updated><authors><author><keyname>Ma</keyname><forenames>Tengyu</forenames></author><author><keyname>Sun</keyname><forenames>Xiaoming</forenames></author><author><keyname>Yu</keyname><forenames>Huacheng</forenames></author></authors><title>A New Variation of Hat Guessing Games</title><categories>math.CO cs.DM</categories><comments>9 pages; The main theorem was improved</comments><msc-class>00A08 97A20 94B05 05C70</msc-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Several variations of hat guessing games have been popularly discussed in
recreational mathematics. In a typical hat guessing game, after initially
coordinating a strategy, each of $n$ players is assigned a hat from a given
color set. Simultaneously, each player tries to guess the color of his/her own
hat by looking at colors of hats worn by other players. In this paper, we
consider a new variation of this game, in which we require at least $k$ correct
guesses and no wrong guess for the players to win the game, but they can choose
to &quot;pass&quot;.
  A strategy is called {\em perfect} if it can achieve the simple upper bound
$\frac{n}{n+k}$ of the winning probability. We present sufficient and necessary
condition on the parameters $n$ and $k$ for the existence of perfect strategy
in the hat guessing games. In fact for any fixed parameter $k$, the existence
of perfect strategy can be determined for every sufficiently large $n$.
  In our construction we introduce a new notion: $(d_1,d_2)$-regular partition
of the boolean hypercube, which is worth to study in its own right. For
example, it is related to the $k$-dominating set of the hypercube. It also
might be interesting in coding theory. The existence of $(d_1,d_2)$-regular
partition is explored in the paper and the existence of perfect $k$-dominating
set follows as a corollary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0892</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0892</id><created>2011-01-05</created><authors><author><keyname>Luo</keyname><forenames>Jun</forenames></author><author><keyname>He</keyname><forenames>Ying</forenames></author></authors><title>GeoQuorum: Load Balancing and Energy Efficient Data Access in Wireless
  Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When data productions and consumptions are heavily unbalanced and when the
origins of data queries are spatially and temporally distributed, the so called
in-network data storage paradigm supersedes the conventional data collection
paradigm in wireless sensor networks (WSNs). In this paper, we first introduce
geometric quorum systems (along with their metrics) to incarnate the idea of
in-network data storage. These quorum systems are &quot;geometric&quot; because curves
(rather than discrete node sets) are used to form quorums. We then propose
GeoQuorum as a new quorum system, for which the quorum forming curves are
parameterized. Though our proposal stems from the existing work on using curves
to guide data replication and retrieval in dense WSNs, we significantly expand
this design methodology, by endowing GeoQuorum with a great flexibility to
fine-tune itself towards different application requirements. In particular, the
tunability allows GeoQuorum to substantially improve the load balancing
performance and to remain competitive in energy efficiency. Both our analysis
and simulations confirm the performance enhancement brought by GeoQuorum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0906</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0906</id><created>2011-01-05</created><authors><author><keyname>Abouei</keyname><forenames>Jamshid</forenames></author><author><keyname>Brown</keyname><forenames>J. David</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author><author><keyname>Pasupathy</keyname><forenames>Subbarayan</forenames></author></authors><title>Energy Efficiency and Reliability in Wireless Biomedical Implant Systems</title><categories>cs.IT math.IT</categories><comments>12 Pages, The paper has been accepted for publication in IEEE
  Transaction on Information Technology in Biomedicine, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of wireless implant technology requires correct delivery of the vital
physiological signs of the patient along with the energy management in
power-constrained devices. Toward these goals, we present an augmentation
protocol for the physical layer of the Medical Implant Communications Service
(MICS) with focus on the energy efficiency of deployed devices over the MICS
frequency band. The present protocol uses the rateless code with the Frequency
Shift Keying (FSK) modulation scheme to overcome the reliability and power cost
concerns in tiny implantable sensors due to the considerable attenuation of
propagated signals across the human body. In addition, the protocol allows a
fast start-up time for the transceiver circuitry. The main advantage of using
rateless codes is to provide an inherent adaptive duty-cycling for power
management, due to the flexibility of the rateless code rate. Analytical
results demonstrate that an 80% energy saving is achievable with the proposed
protocol when compared to the IEEE 802.15.4 physical layer standard with the
same structure used for wireless sensor networks. Numerical results show that
the optimized rateless coded FSK is more energy efficient than that of the
uncoded FSK scheme for deep tissue (e.g., digestive endoscopy) applications,
where the optimization is performed over modulation and coding parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0964</identifier>
 <datestamp>2011-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0964</id><created>2011-01-05</created><authors><author><keyname>Otachi</keyname><forenames>Yota</forenames></author><author><keyname>Suda</keyname><forenames>Ryohei</forenames></author></authors><title>Bandwidth and pathwidth of three-dimensional grids</title><categories>cs.DM</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the bandwidth and the pathwidth of multi-dimensional grids. It can
be shown for grids, that these two parameters are equal to a more basic graph
parameter, the vertex boundary width. Using this fact, we determine the
bandwidth and the pathwidth of three-dimensional grids, which were known only
for the cubic case. As a by-product, we also determine the two parameters of
multi-dimensional grids with relatively large maximum factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0968</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0968</id><created>2011-01-05</created><updated>2011-01-24</updated><authors><author><keyname>Roux</keyname><forenames>Cody</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Refinement Types as Higher Order Dependency Pairs</title><categories>cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Refinement types are a well-studied manner of performing in-depth analysis on
functional programs. The dependency pair method is a very powerful method used
to prove termination of rewrite systems; however its extension to higher order
rewrite systems is still the object of active research. We observe that a
variant of refinement types allow us to express a form of higher-order
dependency pair criterion that only uses information at the type level, and we
prove the correctness of this criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.0970</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.0970</id><created>2011-01-05</created><updated>2011-05-30</updated><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>Asymmetric Quantizers Are Better at Low SNR</title><categories>cs.IT math.IT</categories><comments>5 pages. To be presented at the 2011 IEEE International Symposium on
  Information Theory (ISIT) in Saint Petersburg, Russia. Replaced with version
  that will appear in the proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the behavior of channel capacity when a one-bit quantizer is
employed at the output of the discrete-time average-power-limited Gaussian
channel. We focus on the low signal-to-noise ratio regime, where communication
at very low spectral efficiencies takes place, as in Spread-Spectrum and
Ultra-Wideband communications. It is well know that, in this regime, a
symmetric one-bit quantizer reduces capacity by 2/pi, which translates to a
power loss of approximately two decibels. Here we show that if an asymmetric
one-bit quantizer is employed, and if asymmetric signal constellations are
used, then these two decibels can be recovered in full.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1001</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1001</id><created>2011-01-05</created><authors><author><keyname>Dharmawansa</keyname><forenames>Prathapasinghe</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author></authors><title>Extreme Eigenvalue Distributions of Some Complex Correlated Non-Central
  Wishart and Gamma-Wishart Random Matrices</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Accepted for publication in Journal of Multivariate Analysis</comments><msc-class>60B20, 62H10, 33C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathbf{W}$ be a correlated complex non-central Wishart matrix defined
through $\mathbf{W}=\mathbf{X}^H\mathbf{X}$, where $\mathbf{X}$ is $n\times m
\, (n\geq m)$ complex Gaussian with non-zero mean $\boldsymbol{\Upsilon}$ and
non-trivial covariance $\boldsymbol{\Sigma}$. We derive exact expressions for
the cumulative distribution functions (c.d.f.s) of the extreme eigenvalues
(i.e., maximum and minimum) of $\mathbf{W}$ for some particular cases. These
results are quite simple, involving rapidly converging infinite series, and
apply for the practically important case where $\boldsymbol{\Upsilon}$ has rank
one. We also derive analogous results for a certain class of gamma-Wishart
random matrices, for which $\boldsymbol{\Upsilon}^H\boldsymbol{\Upsilon}$
follows a matrix-variate gamma distribution. The eigenvalue distributions in
this paper have various applications to wireless communication systems, and
arise in other fields such as econometrics, statistical physics, and
multivariate statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1007</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1007</id><created>2011-01-05</created><updated>2011-06-20</updated><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>de Keijzer</keyname><forenames>Bart</forenames></author></authors><title>Complexity of coalition structure generation</title><categories>cs.GT cs.DS</categories><comments>17 pages</comments><acm-class>F.2; I.2.11; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the coalition structure generation problem in which the goal is to
partition the players into exhaustive and disjoint coalitions so as to maximize
the social welfare. One of our key results is a general polynomial-time
algorithm to solve the problem for all coalitional games provided that player
types are known and the number of player types is bounded by a constant. As a
corollary, we obtain a polynomial-time algorithm to compute an optimal
partition for weighted voting games with a constant number of weight values and
for coalitional skill games with a constant number of skills. We also consider
well-studied and well-motivated coalitional games defined compactly on
combinatorial domains. For these games, we characterize the complexity of
computing an optimal coalition structure by presenting polynomial-time
algorithms, approximation algorithms, or NP-hardness and inapproximability
lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1022</identifier>
 <datestamp>2014-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1022</id><created>2011-01-05</created><updated>2014-10-05</updated><authors><author><keyname>Habert</keyname><forenames>Luc</forenames></author><author><keyname>Pocchiola</keyname><forenames>Michel</forenames></author></authors><title>LR characterization of chirotopes of finite planar families of pairwise
  disjoint convex bodies</title><categories>math.CO cs.CG math.MG</categories><comments>100 pages, 73 figures; accepted manuscript version</comments><msc-class>52C30, 52C20, 05C62, 05A05</msc-class><journal-ref>Discrete Comput. Geom., 50 (3): 552-648, 2013</journal-ref><doi>10.1007/s00454-013-9532-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the classical LR characterization of chirotopes of finite planar
families of points to chirotopes of finite planar families of pairwise disjoint
convex bodies: a map \c{hi} on the set of 3-subsets of a finite set I is a
chirotope of finite planar families of pairwise disjoint convex bodies if and
only if for every 3-, 4-, and 5-subset J of I the restriction of \c{hi} to the
set of 3-subsets of J is a chirotope of finite planar families of pairwise
disjoint convex bodies. Our main tool is the polarity map, i.e., the map that
assigns to a convex body the set of lines missing its interior, from which we
derive the key notion of arrangements of double pseudolines, introduced for the
first time in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1038</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1038</id><created>2011-01-05</created><updated>2012-04-13</updated><authors><author><keyname>Morandi</keyname><forenames>Benjamin</forenames></author><author><keyname>Nanz</keyname><forenames>Sebastian</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>A comprehensive operational semantics of the SCOOP programming model</title><categories>cs.DC cs.PL</categories><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Operational semantics has established itself as a flexible but rigorous means
to describe the meaning of programming languages. Oftentimes, it is felt
necessary to keep a semantics small, for example to facilitate its use for
model checking by avoiding state space explosion. However, omitting many
details in a semantics typically makes results valid for a limited core
language only, leaving a wide gap towards any real implementation. In this
paper we present a full-fledged semantics of the concurrent object-oriented
programming language SCOOP (Simple Concurrent Object-Oriented Programming). The
semantics has been found detailed enough to guide an implementation of the
SCOOP compiler and runtime system, and to detect and correct a variety of
errors and ambiguities in the original informal specification and prototype
implementation. In our formal specification, we use abstract data types with
preconditions and axioms to describe the state, and introduce a number of
special run-time operations to model the runtime system with our inference
rules. This approach allows us to make our large formal specification
manageable, providing a first step towards reference documents for specifying
object-oriented languages based on operational semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1042</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1042</id><created>2011-01-05</created><updated>2011-06-27</updated><authors><author><keyname>Wu</keyname><forenames>Lingfei</forenames></author></authors><title>The Accelerating Growth of Online Tagging Systems</title><categories>cs.IR cs.SI physics.soc-ph</categories><comments>8 pages, 3 figures</comments><doi>10.1140/epjb/e2011-20187-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research on the growth of online tagging systems not only is interesting in
its own right, but also yields insights for website management and semantic web
analysis. Traditional models that describing the growth of online systems can
be divided between linear and nonlinear versions. Linear models, including the
BA model (Brabasi and Albert, 1999), assume that the average activity of users
is a constant independent of population. Hence the total activity is a linear
function of population. On the contrary, nonlinear models suggest that the
average activity is affected by the size of the population and the total
activity is a nonlinear function of population. In the current study,
supporting evidences for the nonlinear growth assumption are obtained from data
on Internet users' tagging behavior. A power law relationship between the
number of new tags (F) and the population (P), which can be expressed as F ~ P
^ gamma (gamma &gt; 1), is found. I call this pattern accelerating growth and find
it relates the to time-invariant heterogeneity in individual activities. I also
show how a greater heterogeneity leads to a faster growth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1043</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1043</id><created>2011-01-05</created><updated>2011-07-01</updated><authors><author><keyname>Goulart</keyname><forenames>Paul</forenames></author><author><keyname>Chernyshenko</keyname><forenames>Sergei</forenames></author></authors><title>Global Stability Analysis of Fluid Flows using Sum-of-Squares</title><categories>math.OC cs.SY math.AP math.DS</categories><doi>10.1016/j.physd.2011.12.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new method for proving global stability of fluid
flows through the construction of Lyapunov functionals. For finite dimensional
approximations of fluid systems, we show how one can exploit recently developed
optimization methods based on sum-of-squares decomposition to construct a
polynomial Lyapunov function. We then show how these methods can be extended to
infinite dimensional Navier-Stokes systems using robust optimization
techniques. Crucially, this extension requires only the solution of
infinite-dimensional linear eigenvalue problems and finite-dimensional
sum-of-squares optimization problems.
  We further show that subject to minor technical constraints, a general
polynomial Lyapunov function is always guaranteed to provide better results
than the classical energy methods in determining a lower-bound on the maximum
Reynolds number for which a flow is globally stable, if the flow does remain
globally stable for Reynolds numbers at least slightly beyond the energy
stability limit. Such polynomial functions can be searched for efficiently
using the SOS technique we propose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1045</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1045</id><created>2011-01-05</created><authors><author><keyname>Haviv</keyname><forenames>Ishay</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>Beating the Gilbert-Varshamov Bound for Online Channels</title><categories>cs.IT math.IT</categories><comments>14 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the online channel coding model, a sender wishes to communicate a message
to a receiver by transmitting a codeword x =(x_1,...,x_n) in {0,1}^n bit by bit
via a channel limited to at most pn corruptions. The channel is online in the
sense that at the ith step the channel decides whether to flip the ith bit or
not and its decision is based only on the bits transmitted so far, i.e.,
(x_1,...,x_i). This is in contrast to the classical adversarial channel in
which the corruption is chosen by a channel that has full knowledge on the sent
codeword x. The best known lower bound on the capacity of both the online
channel and the classical adversarial channel is the well-known
Gilbert-Varshamov bound. In this paper we prove a lower bound on the capacity
of the online channel which beats the Gilbert-Varshamov bound for any positive
p such that H(2p) &lt; 0.5 (where H is the binary entropy function). To do so, we
prove that for any such p, a code chosen at random combined with the nearest
neighbor decoder achieves with high probability a rate strictly higher than the
Gilbert-Varshamov bound (for the online channel).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1057</identifier>
 <datestamp>2013-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1057</id><created>2011-01-05</created><updated>2013-04-12</updated><authors><author><keyname>Gerchinovitz</keyname><forenames>S&#xe9;bastien</forenames><affiliation>DMA, INRIA Paris - Rocquencourt</affiliation></author></authors><title>Sparsity regret bounds for individual sequences in online linear
  regression</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>Published in Journal of Machine Learning Research at
  http://www.jmlr.org/papers/volume14/gerchinovitz13a/gerchinovitz13a.pdf</comments><proxy>ccsd</proxy><report-no>RR-7504</report-no><journal-ref>Journal of Machine Learning Research 14 (2011) 729-769</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of online linear regression on arbitrary
deterministic sequences when the ambient dimension d can be much larger than
the number of time rounds T. We introduce the notion of sparsity regret bound,
which is a deterministic online counterpart of recent risk bounds derived in
the stochastic setting under a sparsity scenario. We prove such regret bounds
for an online-learning algorithm called SeqSEW and based on exponential
weighting and data-driven truncation. In a second part we apply a
parameter-free version of this algorithm to the stochastic setting (regression
model with random design). This yields risk bounds of the same flavor as in
Dalalyan and Tsybakov (2011) but which solve two questions left open therein.
In particular our risk bounds are adaptive (up to a logarithmic factor) to the
unknown variance of the noise if the latter is Gaussian. We also address the
regression model with fixed design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1070</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1070</id><created>2011-01-05</created><authors><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author></authors><title>From joint convexity of quantum relative entropy to a concavity theorem
  of Lieb</title><categories>cs.IT math.IT</categories><comments>3 pages</comments><msc-class>52A41</msc-class><journal-ref>Proc. Amer. Math. Soc., Vol. 140, num. 5, pp. 1757-1760, May 2012</journal-ref><doi>10.1090/S0002-9939-2011-11141-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note provides a succinct proof of a 1973 theorem of Lieb that
establishes the concavity of a certain trace function. The development relies
on a deep result from quantum information theory, the joint convexity of
quantum relative entropy, as well as a recent argument due to Carlen and Lieb.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1071</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1071</id><created>2011-01-05</created><authors><author><keyname>Rand</keyname><forenames>Alexander</forenames></author></authors><title>On the Non-Termination of Ruppert's Algorithm</title><categories>cs.CG</categories><comments>4 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A planar straight-line graph which causes the non-termination Ruppert's
algorithm for a minimum angle threshold larger than about 29.5 degrees is
given. The minimum input angle of this example is about 74.5 degrees meaning
that failure is not due to small input angles. Additionally, a similar
non-acute input is given for which Chew's second algorithm does not terminate
for a minimum angle threshold larger than about 30.7 degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1075</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1075</id><created>2011-01-05</created><updated>2011-01-07</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Laverdi&#xe8;re</keyname><forenames>Marc-Andr&#xe9;</forenames></author><author><keyname>Hatami</keyname><forenames>Nader</forenames></author><author><keyname>Benssam</keyname><forenames>Ali</forenames></author></authors><title>Cryptolysis v.0.0.1 - A Framework for Automated Cryptanalysis of
  Classical Ciphers</title><categories>cs.CR cs.SE</categories><comments>27 pages; 4 figures; preliminary results in aux; index; a 2005
  report; v2 fixes name spelling and revisions</comments><doi>10.1109/SERA.2010.44</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptolysis is a framework that includes a collection of automated attacks on
the classical ciphers based on the article by Clark Dawson on Optimisation
heuristics for the automated cryptanalysis of classical ciphers from the
Journal of Combinatorial Mathematics and Combinatorial Computing, 1998.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1110</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1110</id><created>2011-01-05</created><authors><author><keyname>Amsterdamer</keyname><forenames>Yael</forenames></author><author><keyname>Deutch</keyname><forenames>Daniel</forenames></author><author><keyname>Tannen</keyname><forenames>Val</forenames></author></authors><title>Provenance for Aggregate Queries</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study in this paper provenance information for queries with aggregation.
Provenance information was studied in the context of various query languages
that do not allow for aggregation, and recent work has suggested to capture
provenance by annotating the different database tuples with elements of a
commutative semiring and propagating the annotations through query evaluation.
We show that aggregate queries pose novel challenges rendering this approach
inapplicable. Consequently, we propose a new approach, where we annotate with
provenance information not just tuples but also the individual values within
tuples, using provenance to describe the values computation. We realize this
approach in a concrete construction, first for &quot;simple&quot; queries where the
aggregation operator is the last one applied, and then for arbitrary (positive)
relational algebra queries with aggregation; the latter queries are shown to be
more challenging in this context. Finally, we use aggregation to encode queries
with difference, and study the semantics obtained for such queries on
provenance annotated databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1118</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1118</id><created>2011-01-05</created><updated>2011-02-14</updated><authors><author><keyname>Pagani</keyname><forenames>Giuliano Andrea</forenames></author><author><keyname>Aiello</keyname><forenames>Marco</forenames></author></authors><title>Towards Decentralized Trading: A Topological Investigation of the Dutch
  Medium and Low Voltage Grids</title><categories>cs.CE cs.DM cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional Power Grid has been designed in a hierarchical fashion, with
Energy pushed from the large scale production facilities towards the end users.
But with the increasing availability of micro and medium scale generating
facilities, the situation is changing. Many end users can now produce energy
and share it over the Power Grid. Naturally, end users need to have incentives
to do so and might want to be able to act in an open decentralized energy
market. In the present work, we offer a novel analysis of the Medium and Low
Voltage Power Grids of the North Netherlands using statistical tools from the
Complex Network Analysis field. We use a weighted model based on actual Grid
data and propose a set of statistical measures to evaluate the adequacy of the
current infrastructure for a decentralized energy market. Further, we use the
insight gained by the analysis to propose parameters that tie the statistical
topological measures to economic factors that might influence the
attractiveness to the end users in participating in such a decentralized energy
market, thus identifying what are the important topological parameters to work
on to facilitate such open decentralized markets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1146</identifier>
 <datestamp>2012-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1146</id><created>2011-01-06</created><updated>2011-04-13</updated><authors><author><keyname>Ree</keyname><forenames>Suhan</forenames></author></authors><title>Opinion dynamics of random-walking agents on a lattice</title><categories>physics.soc-ph cs.SI</categories><comments>9 pages, 9 figures (Will appear in Phys. Rev. E)</comments><journal-ref>Phys. Rev. E. 83, 056110 (2011)</journal-ref><doi>10.1103/PhysRevE.83.056110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opinion dynamics of random-walking agents on finite two-dimensional lattices
is studied. In the model, the opinion is continuous, and both the lattice and
the opinion can be either periodic or non-periodic. At each time step, all
agents move randomly on the lattice, and update their opinions based on those
of neighbors with whom the differences of opinions are not greater than a given
threshold. Due to the effect of repeated averaging, opinions first converge
locally, and eventually reach steady states. Like other models with bounded
confidence, steady states in general are those with one or more opinion groups,
in which all agents have the same opinion. When both the lattice and the
opinion are periodic, however, metastable states, in which the whole spectrum
of location-dependent opinions can coexist, can emerge. This result shows that,
when a set of continuous opinions forms a structure like a circle, other that a
typically-used linear opinions, rich dynamic behavior can arise. When there are
geographical restrictions in reality, a complete consensus is rarely reached,
and metastable states here can be one of the explanations for these situations,
especially when opinions are not linear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1165</identifier>
 <datestamp>2011-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1165</id><created>2011-01-06</created><authors><author><keyname>Ferreira</keyname><forenames>Silvio C.</forenames></author><author><keyname>Martins</keyname><forenames>Marcelo M.</forenames></author></authors><title>Critical behavior of the contact process in a multiscale network</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><journal-ref>Phys. Rev. E 76, 036112 (2007)</journal-ref><doi>10.1103/PhysRevE.76.036112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by dengue and yellow fever epidemics, we investigated the contact
process (CP) in a multiscale network constituted by one-dimensional chains
connected through a Barab\'asi-Albert scale-free network. In addition to the CP
dynamics inside the chains, the exchange of individuals between connected
chains (travels) occurs at a constant rate. A finite epidemic threshold and an
epidemic mean lifetime diverging exponentially in the subcritical phase,
concomitantly with a power law divergence of the outbreak's duration, were
found. A generalized scaling function involving both regular and SF components
was proposed for the quasistationary analysis and the associated critical
exponents determined, demonstrating that the CP on this hybrid network and
nonvanishing travel rates establishes a new universality class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1169</identifier>
 <datestamp>2011-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1169</id><created>2011-01-06</created><authors><author><keyname>Chien</keyname><forenames>Steve</forenames></author><author><keyname>Harsha</keyname><forenames>Prahladh</forenames></author><author><keyname>Sinclair</keyname><forenames>Alistair</forenames></author><author><keyname>Srinivasan</keyname><forenames>Srikanth</forenames></author></authors><title>Almost Settling the Hardness of Noncommutative Determinant</title><categories>cs.CC</categories><comments>20 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the complexity of computing the determinant of a
matrix over a non-commutative algebra. In particular, we ask the question,
&quot;over which algebras, is the determinant easier to compute than the permanent?&quot;
Towards resolving this question, we show the following hardness and easiness of
noncommutative determinant computation.
  * [Hardness] Computing the determinant of an n \times n matrix whose entries
are themselves 2 \times 2 matrices over a field is as hard as computing the
permanent over the field. This extends the recent result of Arvind and
Srinivasan, who proved a similar result which however required the entries to
be of linear dimension.
  * [Easiness] Determinant of an n \times n matrix whose entries are themselves
d \times d upper triangular matrices can be computed in poly(n^d) time.
  Combining the above with the decomposition theorem of finite dimensional
algebras (in particular exploiting the simple structure of 2 \times 2 matrix
algebras), we can extend the above hardness and easiness statements to more
general algebras as follows. Let A be a finite dimensional algebra over a
finite field with radical R(A).
  * [Hardness] If the quotient A/R(A) is non-commutative, then computing the
determinant over the algebra A is as hard as computing the permanent.
  * [Easiness] If the quotient A/R(A) is commutative and furthermore, R(A) has
nilpotency index d (i.e., the smallest d such that R(A)d = 0), then there
exists a poly(n^d)-time algorithm that computes determinants over the algebra
A.
  In particular, for any constant dimensional algebra A over a finite field,
since the nilpotency index of R(A) is at most a constant, we have the following
dichotomy theorem: if A/R(A) is commutative, then efficient determinant
computation is feasible and otherwise determinant is as hard as permanent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1172</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1172</id><created>2011-01-06</created><updated>2011-08-05</updated><authors><author><keyname>Blackburn</keyname><forenames>Simon R</forenames></author></authors><title>The existence of k-radius sequences</title><categories>math.CO cs.DM</categories><comments>8 pages. More papers cited, and a minor reorganisation of the last
  section, since last version. Typo corrected in the statement of Theorem 4</comments><msc-class>94A55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $n$ and $k$ be positive integers, and let $F$ be an alphabet of size $n$.
A sequence over $F$ of length $m$ is a \emph{$k$-radius sequence} if any two
distinct elements of $F$ occur within distance $k$ of each other somewhere in
the sequence. These sequences were introduced by Jaromczyk and Lonc in 2004, in
order to produce an efficient caching strategy when computing certain functions
on large data sets such as medical images.
  Let $f_k(n)$ be the length of the shortest $n$-ary $k$-radius sequence. The
paper shows, using a probabilistic argument, that whenever $k$ is fixed and
$n\rightarrow\infty$ \[ f_k(n)\sim \frac{1}{k}\binom{n}{2}. \]
  The paper observes that the same argument generalises to the situation when
we require the following stronger property for some integer $t$ such that
$2\leq t\leq k+1$: any $t$ distinct elements of $F$ must simultaneously occur
within a distance $k$ of each other somewhere in the sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1232</identifier>
 <datestamp>2011-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1232</id><created>2011-01-06</created><authors><author><keyname>Haldar</keyname><forenames>Rishin</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author></authors><title>Levenshtein Distance Technique in Dictionary Lookup Methods: An Improved
  Approach</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dictionary lookup methods are popular in dealing with ambiguous letters which
were not recognized by Optical Character Readers. However, a robust dictionary
lookup method can be complex as apriori probability calculation or a large
dictionary size increases the overhead and the cost of searching. In this
context, Levenshtein distance is a simple metric which can be an effective
string approximation tool. After observing the effectiveness of this method, an
improvement has been made to this method by grouping some similar looking
alphabets and reducing the weighted difference among members of the same group.
The results showed marked improvement over the traditional Levenshtein distance
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1237</identifier>
 <datestamp>2011-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1237</id><created>2011-01-06</created><authors><author><keyname>Ghiassi-Farrokhfal</keyname><forenames>Yashar</forenames></author><author><keyname>Liebeherr</keyname><forenames>Jorg</forenames></author><author><keyname>Burchard</keyname><forenames>Almut</forenames></author></authors><title>Statistical Analysis of Link Scheduling on Long Paths</title><categories>cs.NI cs.PF</categories><comments>20 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study how the choice of packet scheduling algorithms influences end-to-end
performance on long network paths. Taking a network calculus approach, we
consider both deterministic and statistical performance metrics. A key enabling
contribution for our analysis is a significantly sharpened method for computing
a statistical bound for the service given to a flow by the network as a whole.
For a suitably parsimonious traffic model we develop closed-form expressions
for end-to-end delays, backlog, and output burstiness. The deterministic
versions of our bounds yield optimal bounds on end-to-end backlog and output
burstiness for some schedulers, and are highly accurate for end-to-end delay
bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1240</identifier>
 <datestamp>2011-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1240</id><created>2010-12-13</created><authors><author><keyname>Dong</keyname><forenames>Mian</forenames></author><author><keyname>Zhong</keyname><forenames>Lin</forenames></author></authors><title>Chameleon: A Color-Adaptive Web Browser for Mobile OLED Displays</title><categories>cs.GR cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Displays based on organic light-emitting diode (OLED) technology are
appearing on many mobile devices. Unlike liquid crystal displays (LCD), OLED
displays consume dramatically different power for showing different colors. In
particular, OLED displays are inefficient for showing bright colors. This has
made them undesirable for mobile devices because much of the web content is of
bright colors.
  To tackle this problem, we present the motivational studies, design, and
realization of Chameleon, a color adaptive web browser that renders web pages
with power-optimized color schemes under user-supplied constraints. Driven by
the findings from our motivational studies, Chameleon provides end users with
important options, offloads tasks that are not absolutely needed in real-time,
and accomplishes real-time tasks by carefully enhancing the codebase of a
browser engine. According to measure-ments with OLED smartphones, Chameleon is
able to re-duce average system power consumption for web browsing by 41% and
reduce display power consumption by 64% without introducing any noticeable
delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1252</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1252</id><created>2011-01-06</created><updated>2011-01-11</updated><authors><author><keyname>Devarakonda</keyname><forenames>Ranjeet</forenames></author><author><keyname>Palanisamy</keyname><forenames>Giri</forenames></author></authors><title>Scientific data searching, sharing and retrieval</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent years, there has been significant advancement in the areas of
scientific data management and retrieval techniques, especially in terms of
standards and protocols for archiving data. Oak Ridge National Laboratory
Distributed Data Archive Center for biogeochemical dynamics is making efforts
in building advanced toolsets for these purposes. Mercury is a web-based
metadata harvesting, data discovery and access system, built for researchers to
search for, share and obtain biogeochemical data. Originally developed for
single National Aeronautics and Space Administration (NASA) project, Mercury
now used over fourteen different projects across three US federal agencies.
Mercury renders various capabilities including metadata management, indexing,
searching, data sharing, and also software reusability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1256</identifier>
 <datestamp>2011-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1256</id><created>2011-01-06</created><authors><author><keyname>Cohen</keyname><forenames>Johanne</forenames></author><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Thang</keyname><forenames>Nguyen Kim</forenames></author></authors><title>Non-clairvoyant Scheduling Games</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a scheduling game, each player owns a job and chooses a machine to execute
it. While the social cost is the maximal load over all machines (makespan), the
cost (disutility) of each player is the completion time of its own job. In the
game, players may follow selfish strategies to optimize their cost and
therefore their behaviors do not necessarily lead the game to an equilibrium.
Even in the case there is an equilibrium, its makespan might be much larger
than the social optimum, and this inefficiency is measured by the price of
anarchy -- the worst ratio between the makespan of an equilibrium and the
optimum. Coordination mechanisms aim to reduce the price of anarchy by
designing scheduling policies that specify how jobs assigned to a same machine
are to be scheduled. Typically these policies define the schedule according to
the processing times as announced by the jobs. One could wonder if there are
policies that do not require this knowledge, and still provide a good price of
anarchy. This would make the processing times be private information and avoid
the problem of truthfulness. In this paper we study these so-called
non-clairvoyant policies. In particular, we study the RANDOM policy that
schedules the jobs in a random order without preemption, and the EQUI policy
that schedules the jobs in parallel using time-multiplexing, assigning each job
an equal fraction of CPU time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1266</identifier>
 <datestamp>2011-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1266</id><created>2011-01-06</created><authors><author><keyname>Jain</keyname><forenames>Brijnesh</forenames></author><author><keyname>Obermayer</keyname><forenames>Klaus</forenames></author></authors><title>Extending Bron Kerbosch for Solving the Maximum Weight Clique Problem</title><categories>cs.DS cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution extends the Bron Kerbosch algorithm for solving the maximum
weight clique problem, where continuous-valued weights are assigned to both,
vertices and edges. We applied the proposed algorithm to graph matching
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1291</identifier>
 <datestamp>2012-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1291</id><created>2011-01-06</created><updated>2011-02-03</updated><authors><author><keyname>Gruber</keyname><forenames>Hermann</forenames></author></authors><title>Bounding the Feedback Vertex Number of Digraphs in Terms of Vertex
  Degrees</title><categories>cs.DM math.CO</categories><comments>preprint submitted to Discrete Applied Mathematics; minor
  corrections, added doi (v2)</comments><msc-class>05C20</msc-class><acm-class>G.2.2</acm-class><journal-ref>Discrete Applied Mathematics, 159(8):872-875, 2011</journal-ref><doi>10.1016/j.dam.2011.01.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Turan bound is a famous result in graph theory, which relates the
independence number of an undirected graph to its edge density. Also the
Caro-Wei inequality, which gives a more refined bound in terms of the vertex
degree sequence of a graph, might be regarded today as a classical result. We
show how these statements can be generalized to directed graphs, thus yielding
a bound on directed feedback vertex number in terms of vertex outdegrees and in
terms of average outdegree, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1310</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1310</id><created>2011-01-06</created><updated>2013-05-02</updated><authors><author><keyname>Rahmati</keyname><forenames>Mojtaba</forenames></author><author><keyname>Duman</keyname><forenames>Tolga M.</forenames></author></authors><title>Bounds on the Capacity of Random Insertion and Deletion-Additive Noise
  Channels</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol.59, no.9,
  pp.5534,5546, Sept. 2013</journal-ref><doi>10.1109/TIT.2013.2262019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop several analytical lower bounds on the capacity of binary
insertion and deletion channels by considering independent uniformly
distributed (i.u.d.) inputs and computing lower bounds on the mutual
information between the input and output sequences. For the deletion channel,
we consider two different models: independent and identically distributed
(i.i.d.) deletion-substitution channel and i.i.d. deletion channel with
additive white Gaussian noise (AWGN). These two models are considered to
incorporate effects of the channel noise along with the synchronization errors.
For the insertion channel case we consider the Gallager's model in which the
transmitted bits are replaced with two random bits and uniform over the four
possibilities independently of any other insertion events. The general approach
taken is similar in all cases, however the specific computations differ.
Furthermore, the approach yields a useful lower bound on the capacity for a
wide range of deletion probabilities for the deletion channels, while it
provides a beneficial bound only for small insertion probabilities (less than
0.25) for the insertion model adopted. We emphasize the importance of these
results by noting that 1) our results are the first analytical bounds on the
capacity of deletion-AWGN channels, 2) the results developed are the best
available analytical lower bounds on the deletion-substitution case, 3) for the
Gallager insertion channel model, the new lower bound improves the existing
results for small insertion probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1325</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1325</id><created>2011-01-06</created><updated>2011-04-07</updated><authors><author><keyname>Levitin</keyname><forenames>Lev B</forenames></author><author><keyname>Toffoli</keyname><forenames>Tommaso</forenames></author></authors><title>Heat-to-work conversion by exploiting full or partial correlations of
  quantum particles</title><categories>quant-ph cs.IT math.IT</categories><comments>4 pp, 1 fig</comments><doi>10.1007/s10773-011-0886-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown how information contained in the pairwise correlations (in
general, partial) between atoms of a gas can be used to completely convert heat
taken from a thermostat into mechanical work in a process of relaxation of the
system to its thermal equilibrium state. Both classical correlations and
quantum correlations (entanglement) are considered. The amount of heat
converted into work is proportional to the entropy defect of the initial state
of the system. For fully correlated particles, in the case of entanglement the
amount of work obtained per particle is twice as large as in the case of
classical correlations. However, in the case of entanglement, the amount of
work does not depend on the degree of correlation, in contrast to the case of
classical correlations. The results explicitly demonstrate the equivalence
relation between information and work for the case of two-particle
correlations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1345</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1345</id><created>2011-01-06</created><updated>2011-01-14</updated><authors><author><keyname>Zeng</keyname><forenames>Weiliang</forenames></author><author><keyname>Xiao</keyname><forenames>Chengshan</forenames></author><author><keyname>Wang</keyname><forenames>Mingxi</forenames></author><author><keyname>Lu</keyname><forenames>Jianhua</forenames></author></authors><title>Linear Precoding for Relay Networks with Finite-Alphabet Constraints</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Int. Conf. Commun. (ICC), Kyoto, Japan, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the optimal precoding scheme for relay networks
with finite-alphabet constraints. We show that the previous work utilizing
various design criteria to maximize either the diversity order or the
transmission rate with the Gaussian-input assumption may lead to significant
loss for a practical system with finite constellation set constraint. A linear
precoding scheme is proposed to maximize the mutual information for relay
networks. We exploit the structure of the optimal precoding matrix and develop
a unified two-step iterative algorithm utilizing the theory of convex
optimization and optimization on the complex Stiefel manifold. Numerical
examples show that this novel iterative algorithm achieves significant gains
compared to its conventional counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1346</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1346</id><created>2011-01-06</created><authors><author><keyname>Jang</keyname><forenames>Dae-Sung</forenames></author><author><keyname>Kwon</keyname><forenames>Sun-Il</forenames></author></authors><title>Fast Approximation Algorithms for Art Gallery Problems in Simple
  Polygons</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present approximation algorithms with O(n^3) processing time for the
minimum vertex and edge guard problems in simple polygons. It is improved from
previous O(n^4) time algorithms of Ghosh. For simple polygon, there are O(n^3)
visibility regions, thus any approximation algorithm for the set covering
problem with approximation ratio of log(n) can be used for the approximation of
n vertex and edge guard problems with O(n^3) visibility sequence. We prove that
the visibility of all points in simple polygons is guaranteed by covering
O(n^2) sinks from vertices and edges : It comes to O(n^3) time bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1350</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1350</id><created>2011-01-06</created><updated>2011-10-04</updated><authors><author><keyname>Abediseid</keyname><forenames>Walid</forenames></author><author><keyname>Damen</keyname><forenames>Mohamed Oussama</forenames></author></authors><title>Time-Out Lattice Sequential Decoding for the MIMO ARQ Channel</title><categories>cs.IT math.IT</categories><comments>30 pages, 5 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal diversity-multiplexing-delay tradeoff for the multi-input
multi-output (MIMO) automatic repeat request (ARQ) channel can be achieved
using incremental redundancy lattice space-time codes coupled with a list
decoder for joint error detection and correction. Such a decoder is based on
the minimum mean-square error lattice decoding principle which is implemented
using sphere decoding algorithms. However, sphere decoders suffer from high
computational complexity for low-to-moderate signal-to-noise ratios, especially
for large signal dimensions. In this paper, we would like to construct a more
efficient decoder that is capable of achieving the optimal tradeoff with much
lower complexity. In particular, we will study the
throughput-performance-complexity tradeoffs in sequential decoding algorithms
and the effect of preprocessing and termination strategies. We show,
analytically and via simulation, that using the \textit{lattice sequential
decoder} that implements a time-out algorithm for joint error detection and
correction, the optimal tradeoff of the MIMO ARQ channel can be achieved with
significant reduction in decoding complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1379</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1379</id><created>2011-01-07</created><authors><author><keyname>Yang</keyname><forenames>Xiaoxiao</forenames></author></authors><title>A Probabilistic Variant of Projection Temporal Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose Probabilistic discrete-time Projection Temporal
Logic (PrPTL), which extends Projection Temporal Logic (PTL) with probability.
To this end, some useful formulas are derived and some logic laws are given.
Further, we define Time Normal Form (TNF) for PrPTL as the standard form and
prove that any PrPTL formulas can be rewritten to TNF. According to the TNF, we
construct the time normal form graph which can be used for the probabilistic
model checking on PrPTL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1449</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1449</id><created>2011-01-07</created><updated>2012-03-16</updated><authors><author><keyname>Cook</keyname><forenames>Stephen A</forenames><affiliation>University of Toronto</affiliation></author><author><keyname>Fontes</keyname><forenames>Lila A</forenames><affiliation>University of Toronto</affiliation></author></authors><title>Formal Theories for Linear Algebra</title><categories>cs.LO</categories><comments>This is a revised journal version of the paper &quot;Formal Theories for
  Linear Algebra&quot; (Computer Science Logic) for the journal Logical Methods in
  Computer Science</comments><proxy>LMCS</proxy><acm-class>F.4.0</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (March 16,
  2012) lmcs:716</journal-ref><doi>10.2168/LMCS-8(1:25)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce two-sorted theories in the style of [CN10] for the complexity
classes \oplusL and DET, whose complete problems include determinants over Z2
and Z, respectively. We then describe interpretations of Soltys' linear algebra
theory LAp over arbitrary integral domains, into each of our new theories. The
result shows equivalences of standard theorems of linear algebra over Z2 and Z
can be proved in the corresponding theory, but leaves open the interesting
question of whether the theorems themselves can be proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1466</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1466</id><created>2011-01-06</created><authors><author><keyname>Das</keyname><forenames>Sudipta</forenames></author><author><keyname>Jenkins</keyname><forenames>Lawrence</forenames></author><author><keyname>Sengupta</keyname><forenames>Debasis</forenames></author></authors><title>Comparison of Loss ratios of different scheduling algorithms</title><categories>cs.OS</categories><comments>8 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that in a firm real time system with a renewal arrival
process, exponential service times and independent and identically distributed
deadlines till the end of service of a job, the earliest deadline first (EDF)
scheduling policy has smaller loss ratio (expected fraction of jobs, not
completed) than any other service time independent scheduling policy, including
the first come first served (FCFS). Various modifications to the EDF and FCFS
policies have been proposed in the literature, with a view to improving
performance. In this article, we compare the loss ratios of these two policies
along with some of the said modifications, as well as their counterparts with
deterministic deadlines. The results include some formal inequalities and some
counter-examples to establish non-existence of an order. A few relations
involving loss ratios are posed as conjectures, and simulation results in
support of these are reported. These results lead to a complete picture of
dominance and non-dominance relations between pairs of scheduling policies, in
terms of loss ratios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1477</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1477</id><created>2011-01-07</created><updated>2011-06-20</updated><authors><author><keyname>Applebaum</keyname><forenames>Lorne</forenames></author><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Asynchronous Code-Division Random Access Using Convex Optimization</title><categories>cs.IT math.IT</categories><comments>Journal version of work presented at 2010 Allerton Conference on
  Communication, Control and Computing. Version 2 includes additional analysis
  of randomly distributed user delays as well as a comparison with a matched
  filter receiver</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many applications in cellular systems and sensor networks involve a random
subset of a large number of users asynchronously reporting activity to a base
station. This paper examines the problem of multiuser detection (MUD) in random
access channels for such applications. Traditional orthogonal signaling ignores
the random nature of user activity in this problem and limits the total number
of users to be on the order of the number of signal space dimensions.
Contention-based schemes, on the other hand, suffer from delays caused by
colliding transmissions and the hidden node problem. In contrast, this paper
presents a novel pairing of an asynchronous non-orthogonal code-division random
access scheme with a convex optimization-based MUD algorithm that overcomes the
issues associated with orthogonal signaling and contention-based methods. Two
key distinguishing features of the proposed MUD algorithm are that it does not
require knowledge of the delay or channel state information of every user and
it has polynomial-time computational complexity. The main analytical
contribution of this paper is the relationship between the performance of the
proposed MUD algorithm in the presence of arbitrary or random delays and two
simple metrics of the set of user codewords. The study of these metrics is then
focused on two specific sets of codewords, random binary codewords and
specially constructed algebraic codewords, for asynchronous random access. The
ensuing analysis confirms that the proposed scheme together with either of
these two codeword sets significantly outperforms the orthogonal
signaling-based random access in terms of the total number of users in the
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1507</identifier>
 <datestamp>2014-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1507</id><created>2011-01-07</created><updated>2014-10-07</updated><authors><author><keyname>Burke</keyname><forenames>Kyle</forenames></author><author><keyname>George</keyname><forenames>Olivia</forenames></author></authors><title>A PSPACE-complete Graph Nim</title><categories>cs.GT cs.CC math.CO</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We build off the game, NimG to create a version named Neighboring Nim. By
reducing from Geography, we show that this game is PSPACE-hard. The games
created by the reduction share strong similarities with Undirected (Vertex)
Geography and regular Nim, both of which are in P. We show how to construct
PSPACE-complete versions with nim heaps *1 and *2. This application of graphs
can be used as a form of game sum with any games, not only Nim.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1515</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1515</id><created>2011-01-07</created><authors><author><keyname>Huang</keyname><forenames>Chuan</forenames></author><author><keyname>Jiang</keyname><forenames>Jinhua</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>On the Achievable Rates of the Diamond Relay Channel with Conferencing
  Links</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a half-duplex diamond relay channel, which consists of one
source-destination pair and two relay nodes connected with two-way rate-limited
out-of-band conferencing links. Three basic schemes and their achievable rates
are studied: For the decode-and-forward (DF) scheme, we obtain the achievable
rate by letting the source send a common message and two private messages; for
the compress-and-forward (CF) scheme, we exploit the conferencing links to help
with the compression of the received signals, or to exchange messages intended
for the second hop to introduce certain cooperation; for the
amplify-and-forward (AF) scheme, we study the optimal combining strategy
between the received signals from the source and the conferencing link.
Moreover, we show that these schemes could achieve the capacity upper bound
under certain conditions. Finally, we evaluate the various rates for the
Gaussian case with numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1547</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1547</id><created>2011-01-07</created><updated>2011-07-02</updated><authors><author><keyname>Cadilhac</keyname><forenames>Micha&#xeb;l</forenames></author><author><keyname>Finkel</keyname><forenames>Alain</forenames></author><author><keyname>McKenzie</keyname><forenames>Pierre</forenames></author></authors><title>On the expressiveness of Parikh automata and related models</title><categories>cs.FL</categories><comments>16 pages, in NCMA11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Parikh finite word automaton (PA) was introduced and studied by Klaedtke
and Ruess in 2003. Natural variants of the PA arise from viewing a PA
equivalently as an automaton that keeps a count of its transitions and
semilinearly constrains their numbers. Here we adopt this view and define the
affine PA (APA), that extends the PA by having each transition induce an affine
transformation on the PA registers, and the PA on letters (LPA), that restricts
the PA by forcing any two transitions on same letter to affect the registers
equally. Then we report on the expressiveness, closure, and decidability
properties of such PA variants. We note that deterministic PA are strictly
weaker than deterministic reversal-bounded counter machines. We develop
pumping-style lemmas and identify an explicit PA language recognized by no
deterministic PA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1550</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1550</id><created>2011-01-07</created><authors><author><keyname>Guha</keyname><forenames>Saikat</forenames></author></authors><title>Structured optical receivers to attain superadditive capacity and the
  Holevo limit</title><categories>quant-ph cs.IT math.IT</categories><comments>4 pages, 4 figures</comments><journal-ref>Phys. Rev. Lett. 106, 240502 (2011)</journal-ref><doi>10.1103/PhysRevLett.106.240502</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When classical information is sent over a quantum channel, attaining the
ultimate limit to channel capacity requires the receiver to make joint
measurements over long codeword blocks. For a pure-state channel, we construct
a receiver that can attain the ultimate capacity by applying a single-shot
unitary transformation on the received quantum codeword followed by
simultaneous (but separable) projective measurements on the
single-modulation-symbol state spaces. We study the ultimate limits of
photon-information-efficient communications on a lossy bosonic channel. Based
on our general results for the pure-state quantum channel, we show some of the
first concrete examples of codes and structured joint-detection optical
receivers that can achieve fundamentally higher (superadditive) channel
capacity than conventional receivers that detect each modulation symbol
individually.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1577</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1577</id><created>2011-01-08</created><updated>2011-09-12</updated><authors><author><keyname>Dossal</keyname><forenames>Charles</forenames><affiliation>IMB</affiliation></author><author><keyname>Chabanol</keyname><forenames>Marie-Line</forenames><affiliation>IMB</affiliation></author><author><keyname>Peyr&#xe9;</keyname><forenames>Gabriel</forenames><affiliation>CEREMADE</affiliation></author><author><keyname>Fadili</keyname><forenames>Jalal</forenames><affiliation>GREYC</affiliation></author></authors><title>Sharp Support Recovery from Noisy Random Measurements by L1 minimization</title><categories>cs.IT math.IT math.NA</categories><comments>Applied and Computational Harmonic Analysis (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the theoretical guarantees of penalized $\lun$
minimization (also called Basis Pursuit Denoising or Lasso) in terms of
sparsity pattern recovery (support and sign consistency) from noisy
measurements with non-necessarily random noise, when the sensing operator
belongs to the Gaussian ensemble (i.e. random design matrix with i.i.d.
Gaussian entries). More precisely, we derive sharp non-asymptotic bounds on the
sparsity level and (minimal) signal-to-noise ratio that ensure support
identification for most signals and most Gaussian sensing matrices by solving
the Lasso problem with an appropriately chosen regularization parameter. Our
first purpose is to establish conditions allowing exact sparsity pattern
recovery when the signal is strictly sparse. Then, these conditions are
extended to cover the compressible or nearly sparse case. In these two results,
the role of the minimal signal-to-noise ratio is crucial. Our third main result
gets rid of this assumption in the strictly sparse case, but this time, the
Lasso allows only partial recovery of the support. We also provide in this case
a sharp $\ell_2$-consistency result on the coefficient vector. The results of
the present work have several distinctive features compared to previous ones.
One of them is that the leading constants involved in all the bounds are sharp
and explicit. This is illustrated by some numerical experiments where it is
indeed shown that the sharp sparsity level threshold identified by our
theoretical results below which sparsistency of the Lasso is guaranteed meets
that empirically observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1597</identifier>
 <datestamp>2011-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1597</id><created>2011-01-08</created><updated>2011-12-05</updated><authors><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author><author><keyname>Welker</keyname><forenames>Volkmar</forenames></author></authors><title>Commutative Algebra of Statistical Ranking</title><categories>math.AC cs.DM math.ST stat.TH</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model for statistical ranking is a family of probability distributions
whose states are orderings of a fixed finite set of items. We represent the
orderings as maximal chains in a graded poset. The most widely used ranking
models are parameterized by rational function in the model parameters, so they
define algebraic varieties. We study these varieties from the perspective of
combinatorial commutative algebra. One of our models, the Plackett-Luce model,
is non-toric. Five others are toric: the Birkhoff model, the ascending model,
the Csiszar model, the inversion model, and the Bradley-Terry model. For these
models we examine the toric algebra, its lattice polytope, and its Markov
basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1602</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1602</id><created>2011-01-08</created><authors><author><keyname>Jusoh</keyname><forenames>Nor Amizam</forenames></author><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author></authors><title>Application of Freeman Chain Codes: An Alternative Recognition Technique
  for Malaysian Car Plates</title><categories>cs.CV</categories><comments>6 pages, 8 figures</comments><journal-ref>International Journal of Computer Science and Network Security,
  Vol. 9 No. 11 pp. 222-227, November 2009, ISSN 1738-7906</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various applications of car plate recognition systems have been developed
using various kinds of methods and techniques by researchers all over the
world. The applications developed were only suitable for specific country due
to its standard specification endorsed by the transport department of
particular countries. The Road Transport Department of Malaysia also has
endorsed a specification for car plates that includes the font and size of
characters that must be followed by car owners. However, there are cases where
this specification is not followed. Several applications have been developed in
Malaysia to overcome this problem. However, there is still problem in achieving
100% recognition accuracy. This paper is mainly focused on conducting an
experiment using chain codes technique to perform recognition for different
types of fonts used in Malaysian car plates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1603</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1603</id><created>2011-01-08</created><authors><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author><author><keyname>Clarke</keyname><forenames>Malcolm</forenames></author></authors><title>Reversible Region of Non-Interest (RONI) Watermarking for Authentication
  of DICOM Images</title><categories>cs.CR</categories><comments>9 pages, 13 figures</comments><journal-ref>International Journal of Computer Science and Network Security,
  Vol. 7 No. 9 pp. 19-27 September 2007, ISSN 1738-7906</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces current watermarking techniques available from the
literatures. Requirements for medical watermarking will be discussed. We then
propose a watermarking scheme that can recover the original image from the
watermarked one. The purpose is to verify the integrity and authenticity of
DICOM images. We used ultrasound (US) images in our experiment. SHA-256 of the
whole image is embedded in the least significant bits of the RONI (Region of
Non-Interest). If the image has not been altered, the watermark will be
extracted and the original image will be recovered. SHA-256 of the recovered
image will be compared with the extracted watermark for authentication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1606</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1606</id><created>2011-01-08</created><authors><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author><author><keyname>Tey</keyname><forenames>Mengkar</forenames></author><author><keyname>Goh</keyname><forenames>Yingsoon</forenames></author></authors><title>Probing a Self-Developed Aesthetics Measurement Application (SDA) in
  Measuring Aesthetics of Mandarin Learning Web Page Interfaces</title><categories>cs.HC cs.CY</categories><comments>10 pages, 6 figures</comments><journal-ref>International Journal of Computer Science and Network Security,
  Vol. 8 No. 1 pp. 31-40 January 2008, ISSN 1738-7906</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes the accurateness of our application namely
Self-Developed Aesthetics Measurement Application (SDA) in measuring the
aesthetics aspect by comparing the results of our application and users'
perceptions in measuring the aesthetics of the web page interfaces. For this
research, the positions of objects, images element and texts element are
defined as objects in a web page interface. Mandarin learning web pages are
used in this research. These learning web pages comprised of main pages,
learning pages and exercise pages, on the first author's E-portfolio web site.
The objects of the web pages were manipulated in order to produce the desired
aesthetic values. The six aesthetics related elements used are balance,
equilibrium, symmetry, sequence, rhythm, as well as order and complexity.
Results from the research showed that the ranking of the aesthetics values of
the web page interfaces measured of the users were congruent with the expected
perceptions of our designed Mandarin learning web page interfaces (reported
also in [18]). Thus, it implies that the subjectivity of aesthetics can be
measured in an objective manner. For further understanding on our effort in
doing aesthetics measurement, we discussed in details the object modelling used
as well as the process in developing this application. We also explained the
steps on how to run our application. Additionally, the strength and the
weakness of our SDA application shared in this paper suggest that there is
still room for the improvement for aesthetics measurement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1608</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1608</id><created>2011-01-08</created><authors><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author><author><keyname>Tey</keyname><forenames>Mengkar</forenames></author><author><keyname>Goh</keyname><forenames>Yingsoon</forenames></author></authors><title>Does Aesthetics of Web Page Interface Matters to Mandarin Learning?</title><categories>cs.HC cs.CY</categories><comments>9 pages, 1 figure, 9 tables</comments><journal-ref>International Journal of Computer Science and Network Security,
  Vol. 7 No. 8 pp. 43-51 August 2007, ISSN 1738-7906</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aesthetics of web page refers to how attractive a web page is in which it
catches the attention of the user to read through the information. In addition,
the visual appearance is important in getting attentions of the users.
Moreover, it was found that those screens, which were perceived as
aesthetically pleasing, were having a better usability. Usability might be a
strong basic in relating to the applicability for learning, and in this study
pertaining to Mandarin learning. It was also found that aesthetically pleasing
layouts of web page would motivate students in Mandarin learning The Mandarin
Learning web pages were manipulated according to the desired aesthetic
measurements. GUI aesthetic measuring method was used for this purpose. The
Aesthetics-Measurement Application (AMA) accomplished with six aesthetic
measures was developed and used. On top of it, questionnaires were distributed
to the users to gather information on the students' perceptions on the
aesthetic aspects and learning aspects. Respondents for this study were
students taking Mandarin course level I at UiTM Terengganu. A significant
correlation of the aesthetic aspect was found with its relevance to Mandarin
learning. In summary, aesthetics should not be ignored or overlooked in
designing effective learning interfaces for educational purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1633</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1633</id><created>2011-01-09</created><updated>2011-01-11</updated><authors><author><keyname>Meier</keyname><forenames>Dominic</forenames></author><author><keyname>Pignolet</keyname><forenames>Yvonne Anne</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author><author><keyname>Wattenhofer</keyname><forenames>Roger</forenames></author></authors><title>On the Windfall and Price of Friendship: Inoculation Strategies on
  Social Networks</title><categories>cs.GT</categories><comments>Preliminary version appeared at ACM EC conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article investigates selfish behavior in games where players are
embedded in a social context. A framework is presented which allows us to
measure the Windfall of Friendship, i.e., how much players benefit (compared to
purely selfish environments) if they care about the welfare of their friends in
the social network graph. As a case study, a virus inoculation game is
examined. We analyze the corresponding Nash equilibria and show that the
Windfall of Friendship can never be negative. However, we find that if the
valuation of a friend is independent of the total number of friends, the social
welfare may not increase monotonically with the extent to which players care
for each other; intriguingly, in the corresponding scenario where the relative
importance of a friend declines, the Windfall is monotonic again. This article
also studies convergence of best-response sequences. It turns out that in
social networks, convergence times are typically higher and hence constitute a
price of friendship. While such phenomena may be known on an anecdotal level,
our framework allows us to quantify these effects analytically. Our formal
insights on the worst case equilibria are complemented by simulations shedding
light onto the structure of other equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1637</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1637</id><created>2011-01-09</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author><author><keyname>Mutschke</keyname><forenames>Peter</forenames></author></authors><title>A Science Model Driven Retrieval Prototype</title><categories>cs.IR cs.DL</categories><comments>8 pages, 4 figures, Cologne Conference on Interoperability and
  Semantics in Knowledge Organization</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper is about a better understanding on the structure and dynamics of
science and the usage of these insights for compensating the typical problems
that arises in metadata-driven Digital Libraries. Three science model driven
retrieval services are presented: co-word analysis based query expansion,
re-ranking via Bradfordizing and author centrality. The services are evaluated
with relevance assessments from which two important implications emerge: (1)
precision values of the retrieval service are the same or better than the
tf-idf retrieval baseline and (2) each service retrieved a disjoint set of
documents. The different services each favor quite other - but still relevant -
documents than pure term-frequency based rankings. The proposed models and
derived retrieval services therefore open up new viewpoints on the scientific
knowledge space and provide an alternative framework to structure scholarly
information systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1638</identifier>
 <datestamp>2015-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1638</id><created>2011-01-09</created><updated>2013-06-02</updated><authors><author><keyname>Guo</keyname><forenames>Jin-Li</forenames></author><author><keyname>Fan</keyname><forenames>Chao</forenames></author><author><keyname>Ji</keyname><forenames>Ya-Li</forenames></author></authors><title>Universality of competitive networks for weighted networks</title><categories>physics.soc-ph cs.SI</categories><comments>18 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:cond-mat/0406238 by other authors</comments><journal-ref>J. Syst. Sci. Complex. 2015, 28, 546, 558</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we propose a new model that allows us to investigate this
competitive aspect of real networks in quantitative terms. Through theoretical
analysis and numerical simulations, we find that the competitive network have
the universality for a weighted network. The relation between parameters in the
weighted network and the competitiveness in the competitive network is
obtained. So we can use the expression of the degree distribution of the
competitive model to calculate that and the strength of the weighted network
directly. The analytical solution reveals that the degree distribution of the
weighted network is correlated with the increment and initial value of edge
weights, which is verified by numerical simulations. Moreover, the evolving
pattern of a clustering coefficient along with network parameters such as the
size of a network, an updating coefficient, an initial weight and the
competitiveness are obtained by further simulations. Specially, it is necessary
to point out that the initial weight plays equally significant role as updating
coefficient in influencing the topological characteristics of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1639</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1639</id><created>2011-01-09</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Mutschke</keyname><forenames>Peter</forenames></author><author><keyname>Petras</keyname><forenames>Vivien</forenames></author><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author><author><keyname>Sure</keyname><forenames>York</forenames></author></authors><title>Applying Science Models for Search</title><categories>cs.IR cs.DL</categories><comments>14 pages, 3 figures, ISI 2011</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The paper proposes three different kinds of science models as value-added
services that are integrated in the retrieval process to enhance retrieval
quality. The paper discusses the approaches Search Term Recommendation,
Bradfordizing and Author Centrality on a general level and addresses
implementation issues of the models within a real-life retrieval environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1640</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1640</id><created>2011-01-09</created><updated>2011-05-23</updated><authors><author><keyname>Schluter</keyname><forenames>Natalie</forenames></author></authors><title>Restarting Automata with Auxiliary Symbols and Small Lookahead</title><categories>cs.FL</categories><comments>Full version of the paper accepted to LATA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a study on lookahead hierarchies for restarting automata with
auxiliary symbols and small lookahead. In particular, we show that there are
just two different classes of languages recognised RRWW automata, through the
restriction of lookahead size. We also show that the respective (left-)
monotone restarting automaton models characterise the context-free languages
and that the respective right-left-monotone restarting automata characterise
the linear languages both with just lookahead length 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1643</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1643</id><created>2011-01-09</created><authors><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Multi-Relay Selection Design and Analysis for Multi-Stream Cooperative
  Communications</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of multi-relay selection for
multi-stream cooperative MIMO systems with $M$ relay nodes. Traditionally,
relay selection approaches are primarily focused on selecting one relay node to
improve the transmission reliability given a single-antenna destination node.
As such, in the cooperative phase whereby both the source and the selected
relay nodes transmit to the destination node, it is only feasible to exploit
cooperative spatial diversity (for example by means of distributed space time
coding). For wireless systems with a multi-antenna destination node, in the
cooperative phase it is possible to opportunistically transmit multiple data
streams to the destination node by utilizing multiple relay nodes. Therefore,
we propose a low overhead multi-relay selection protocol to support
multi-stream cooperative communications. In addition, we derive the asymptotic
performance results at high SNR for the proposed scheme and discuss the
diversity-multiplexing tradeoff as well as the throughput-reliability tradeoff.
From these results, we show that the proposed multi-stream cooperative
communication scheme achieves lower outage probability compared to existing
baseline schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1667</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1667</id><created>2011-01-09</created><updated>2011-03-01</updated><authors><author><keyname>Charlier</keyname><forenames>E.</forenames></author><author><keyname>Domaratzki</keyname><forenames>M.</forenames></author><author><keyname>Harju</keyname><forenames>T.</forenames></author><author><keyname>Shallit</keyname><forenames>J.</forenames></author></authors><title>Finite Orbits of Language Operations</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a set of natural operations on languages, and prove that the
orbit of any language L under the monoid generated by this set is finite and
bounded, independently of L. This generalizes previous results about
complement, Kleene closure, and positive closure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1680</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1680</id><created>2011-01-09</created><authors><author><keyname>Herman</keyname><forenames>Ted</forenames></author></authors><title>Safe Register Token Transfer in a Ring</title><categories>cs.DC</categories><comments>22 pages</comments><report-no>TR-11-01</report-no><acm-class>H.3.4; D.1.3; D.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A token ring is an arrangement of N processors that take turns engaging in an
activity which must be controlled. A token confers the right to engage in the
controlled activity. Processors communicate with neighbors in the ring to
obtain and release a token. The communication mechanism investigated in this
paper is the safe register abstraction, which may arbitrarily corrupt a value
that a processor reads when the operation reading a register is concurrent with
an write operation on that register by a neighboring processor. The main
results are simple protocols for quasi-atomic communication, constructed from
safe registers. A quasi-atomic register behaves atomically except that a
special undefined value may be returned in the case of concurrent read and
write operations. Under certain conditions that constrain the number of writes
and registers, quasi-atomic protocols are adequate substitutes for atomic
protocols. The paper demonstrates how quasi-atomic protocols can be used to
implement a self-stabilizing token ring, either by using two safe registers
between neighboring processors or by using O(lg N) safe registers between
neighbors, which lowers read complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1682</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1682</id><created>2011-01-09</created><authors><author><keyname>Baghai-Ravary</keyname><forenames>Ladan</forenames></author><author><keyname>Grau</keyname><forenames>Sergio</forenames></author><author><keyname>Kochanski</keyname><forenames>Greg</forenames></author></authors><title>Detecting gross alignment errors in the Spoken British National Corpus</title><categories>cs.SD</categories><comments>Four pages, 3 figures. Presented at &quot;New Tools and Methods for
  Very-Large-Scale Phonetics Research&quot;, University of Pennsylvania, January
  28-31, 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The paper presents methods for evaluating the accuracy of alignments between
transcriptions and audio recordings. The methods have been applied to the
Spoken British National Corpus, which is an extensive and varied corpus of
natural unscripted speech. Early results show good agreement with human ratings
of alignment accuracy. The methods also provide an indication of the location
of likely alignment problems; this should allow efficient manual examination of
large corpora. Automatic checking of such alignments is crucial when analysing
any very large corpus, since even the best current speech alignment systems
will occasionally make serious errors. The methods described here use a hybrid
approach based on statistics of the speech signal itself, statistics of the
labels being evaluated, and statistics linking the two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1688</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1688</id><created>2011-01-09</created><updated>2012-01-05</updated><authors><author><keyname>El-Halabi</keyname><forenames>Mustafa</forenames><affiliation>Shitz</affiliation></author><author><keyname>Liu</keyname><forenames>Tie</forenames><affiliation>Shitz</affiliation></author><author><keyname>Georghiades</keyname><forenames>Costas</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Secret Writing on Dirty Paper: A Deterministic View</title><categories>cs.IT math.IT</categories><comments>Removed the section on writing on fading paper; improved the gap
  result from $(1/2)\log3$ bits to half a bit; added a section on secret-key
  agreement via dirty-paper coding; revised version submitted to the IEEE
  Transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently there has been a lot of success in using the deterministic approach
to provide approximate characterization of Gaussian network capacity. In this
paper, we take a deterministic view and revisit the problem of wiretap channel
with side information. A precise characterization of the secrecy capacity is
obtained for a linear deterministic model, which naturally suggests a coding
scheme which we show to achieve the secrecy capacity of the degraded Gaussian
model (dubbed as &quot;secret writing on dirty paper&quot;) to within half a bit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1703</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1703</id><created>2011-01-09</created><updated>2011-08-02</updated><authors><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author><author><keyname>Fan</keyname><forenames>Ying</forenames></author></authors><title>Detecting Important Nodes to Community Structure Using the Spectrum of
  the Graph</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages,7 gigures</comments><doi>10.1371/journal.pone.0027418</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Many complex systems can be represented as networks, and how a network breaks
up into subnetworks or communities is of wide interest. However, the
development of a method to detect nodes important to communities that is both
fast and accurate is a very challenging and open problem. In this manuscript,
we introduce a new approach to characterize the node importance to communities.
First, a centrality metric is proposed to measure the importance of network
nodes to community structure using the spectrum of the adjacency matrix. We
define the node importance to communities as the relative change in the
eigenvalues of the network adjacency matrix upon their removal. Second, we also
propose an index to distinguish two kinds of important nodes in communities,
i.e., &quot;community core&quot; and &quot;bridge&quot;. Our indices are only relied on the
spectrum of the graph matrix. They are applied in many artificial networks as
well as many real-world networks. This new methodology gives us a basic
approach to solve this challenging problem and provides a realistic result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1710</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1710</id><created>2011-01-10</created><updated>2011-12-05</updated><authors><author><keyname>Bhaskara</keyname><forenames>Aditya</forenames></author><author><keyname>Charikar</keyname><forenames>Moses</forenames></author><author><keyname>Manokaran</keyname><forenames>Rajsekar</forenames></author><author><keyname>Vijayaraghavan</keyname><forenames>Aravindan</forenames></author></authors><title>On Quadratic Programming with a Ratio Objective</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quadratic Programming (QP) is the well-studied problem of maximizing over
{-1,1} values the quadratic form \sum_{i \ne j} a_{ij} x_i x_j. QP captures
many known combinatorial optimization problems, and assuming the unique games
conjecture, semidefinite programming techniques give optimal approximation
algorithms. We extend this body of work by initiating the study of Quadratic
Programming problems where the variables take values in the domain {-1,0,1}.
The specific problems we study are
  QP-Ratio : \max_{\{-1,0,1\}^n} \frac{\sum_{i \not = j} a_{ij} x_i x_j}{\sum
x_i^2}, and Normalized QP-Ratio : \max_{\{-1,0,1\}^n} \frac{\sum_{i \not = j}
a_{ij} x_i x_j}{\sum d_i x_i^2}, where d_i = \sum_j |a_{ij}|
  We consider an SDP relaxation obtained by adding constraints to the natural
eigenvalue (or SDP) relaxation for this problem. Using this, we obtain an
$\tilde{O}(n^{1/3})$ algorithm for QP-ratio. We also obtain an
$\tilde{O}(n^{1/4})$ approximation for bipartite graphs, and better algorithms
for special cases. As with other problems with ratio objectives (e.g. uniform
sparsest cut), it seems difficult to obtain inapproximability results based on
P!=NP. We give two results that indicate that QP-Ratio is hard to approximate
to within any constant factor. We also give a natural distribution on instances
of QP-Ratio for which an n^\epsilon approximation (for \epsilon roughly 1/10)
seems out of reach of current techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1712</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1712</id><created>2011-01-10</created><authors><author><keyname>Urgaonkar</keyname><forenames>Rahul</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Network Capacity Region and Minimum Energy Function for a Delay-Tolerant
  Mobile Ad Hoc Network</title><categories>cs.NI cs.IT math.IT</categories><comments>Extended version of IEEE/ACM Transactions on Networking article</comments><doi>10.1109/TNET.2010.2103367</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate two quantities of interest in a delay-tolerant mobile ad hoc
network: the network capacity region and the minimum energy function. The
network capacity region is defined as the set of all input rates that the
network can stably support considering all possible scheduling and routing
algorithms. Given any input rate vector in this region, the minimum energy
function establishes the minimum time average power required to support it. In
this work, we consider a cell-partitioned model of a delay-tolerant mobile ad
hoc network with general Markovian mobility. This simple model incorporates the
essential features of locality of wireless transmissions as well as node
mobility and enables us to exactly compute the corresponding network capacity
and minimum energy function. Further, we propose simple schemes that offer
performance guarantees that are arbitrarily close to these bounds at the cost
of an increased delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1715</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1715</id><created>2011-01-10</created><updated>2011-07-11</updated><authors><author><keyname>Pe&#xf1;a</keyname><forenames>Jose M.</forenames></author></authors><title>Finding Consensus Bayesian Network Structures</title><categories>stat.ML cs.AI math.ST stat.TH</categories><comments>Changes from v3 to v4: Section 1 has been extended with more
  motivation and a review of the literature. Theorem 3 proves that CONSENSUS is
  not only NP-hard but NP-complete. A flaw in Theorem 4 has been fixed. The
  proof of Theorem 5 has been re-written from scratch. Now, it is
  self-contained, i.e. it does not rely upon the algorithm by Chickering (2004)</comments><journal-ref>Journal of Artificial Intelligence Research, 42, 661-687, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that multiple experts (or learning algorithms) provide us with
alternative Bayesian network (BN) structures over a domain, and that we are
interested in combining them into a single consensus BN structure.
Specifically, we are interested in that the consensus BN structure only
represents independences all the given BN structures agree upon and that it has
as few parameters associated as possible. In this paper, we prove that there
may exist several non-equivalent consensus BN structures and that finding one
of them is NP-hard. Thus, we decide to resort to heuristics to find an
approximated consensus BN structure. In this paper, we consider the heuristic
proposed in
\citep{MatzkevichandAbramson1992,MatzkevichandAbramson1993a,MatzkevichandAbramson1993b}.
This heuristic builds upon two algorithms, called Methods A and B, for
efficiently deriving the minimal directed independence map of a BN structure
relative to a given node ordering. Methods A and B are claimed to be correct
although no proof is provided (a proof is just sketched). In this paper, we
show that Methods A and B are not correct and propose a correction of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1718</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1718</id><created>2011-01-10</created><authors><author><keyname>Singh</keyname><forenames>Jagbeer</forenames></author></authors><title>Precise Schedulability Analysis for unfeasible to notify separately for
  comprehensive - EDF Scheduling of interrupted Hard Real-Time Tasks on the
  similar Multiprocessors</title><categories>cs.SE</categories><comments>9 pages,1 figure</comments><msc-class>Earliest-deadline first, feasibility analysis, fixed-task-priority,
  fixed-job-priority, worst case execution</msc-class><acm-class>F.2.2; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Real-time system, utilization based schedulability test is a common
approach to determine whether or not tasks can be admitted without violating
deadline requirements. The exact problem has previously been proven intractable
even upon single processors; sufficient conditions are presented here for
determining whether a given periodic task system will meet all deadlines if
scheduled non-preemptively upon a multiprocessor platform using the
earliest-deadline first scheduling algorithm. Many real-time scheduling
algorithms have been developed recently to reduce affinity in the portable
devices that use processors. Extensive power aware scheduling techniques have
been published for energy reduction, but most of them have been focused solely
on reducing the processor affinity. The non-preemptive scheduling of periodic
task systems upon processing platforms comprised of several same processors is
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1727</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1727</id><created>2011-01-10</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames><affiliation>IST Austria</affiliation></author><author><keyname>Fijalkow</keyname><forenames>Nathana&#xeb;l</forenames><affiliation>IST Austria, ENS Cachan</affiliation></author></authors><title>Finitary languages</title><categories>cs.FL</categories><proxy>ccsd</proxy><doi>10.1007/978-3-642-21254-3_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The class of omega-regular languages provides a robust specification language
in verification. Every omega-regular condition can be decomposed into a safety
part and a liveness part. The liveness part ensures that something good happens
&quot;eventually&quot;. Finitary liveness was proposed by Alur and Henzinger as a
stronger formulation of liveness. It requires that there exists an unknown,
fixed bound b such that something good happens within b transitions. In this
work we consider automata with finitary acceptance conditions defined by
finitary Buchi, parity and Streett languages. We study languages expressible by
such automata: we give their topological complexity and present a
regular-expression characterization. We compare the expressive power of
finitary automata and give optimal algorithms for classical decisions
questions. We show that the finitary languages are Sigma 2-complete; we present
a complete picture of the expressive power of various classes of automata with
finitary and infinitary acceptance conditions; we show that the languages
defined by finitary parity automata exactly characterize the star-free fragment
of omega B-regular languages; and we show that emptiness is NLOGSPACE-complete
and universality as well as language inclusion are PSPACE-complete for finitary
parity and Streett automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1731</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1731</id><created>2011-01-10</created><authors><author><keyname>Cristau</keyname><forenames>Julien</forenames><affiliation>LIAFA</affiliation></author></authors><title>Automata and temporal logic over arbitrary linear time</title><categories>cs.LO cs.FL</categories><proxy>ccsd</proxy><journal-ref>Foundations of Software Technology and Theoretical Computer
  Science, Kanpur : France (2009)</journal-ref><doi>10.4230/LIPIcs.FSTTCS.2009.2313</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear temporal logic was introduced in order to reason about reactive
systems. It is often considered with respect to infinite words, to specify the
behaviour of long-running systems. One can consider more general models for
linear time, using words indexed by arbitrary linear orderings. We investigate
the connections between temporal logic and automata on linear orderings, as
introduced by Bruy\`ere and Carton. We provide a doubly exponential procedure
to compute from any LTL formula with Until, Since, and the Stavi connectives an
automaton that decides whether that formula holds on the input word. In
particular, since the emptiness problem for these automata is decidable, this
transformation gives a decision procedure for the satisfiability of the logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1740</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1740</id><created>2011-01-10</created><updated>2011-02-04</updated><authors><author><keyname>de Saporta</keyname><forenames>Beno&#xee;te</forenames></author><author><keyname>Dufour</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Zhang</keyname><forenames>Huilong</forenames></author><author><keyname>Elegbede</keyname><forenames>Charles</forenames></author></authors><title>Optimal stopping for the predictive maintenance of a structure subject
  to corrosion</title><categories>math.PR cs.SY math.OC</categories><report-no>This work was partially funded by the ARPEGE program of National
  Agency for Research (ANR), project FauToCoES, ANR-09-004-SEGI</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a numerical method to compute the optimal maintenance time for a
complex dynamic system applied to an example of maintenance of a metallic
structure subject to corrosion. An arbitrarily early intervention may be
uselessly costly, but a late one may lead to a partial/complete failure of the
system, which has to be avoided. One must therefore find a balance between
these too simple maintenance policies. To achieve this aim, we model the system
by a stochastic hybrid process. The maintenance problem thus corresponds to an
optimal stopping problem. We propose a numerical method to solve the optimal
stopping problem and optimize the maintenance time for this kind of processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1784</identifier>
 <datestamp>2014-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1784</id><created>2011-01-10</created><updated>2014-06-26</updated><authors><author><keyname>Berth&#xe9;</keyname><forenames>Val&#xe9;rie</forenames></author><author><keyname>Jolivet</keyname><forenames>Timo</forenames></author><author><keyname>Siegel</keyname><forenames>Anne</forenames></author></authors><title>Connectedness of fractals associated with Arnoux-Rauzy substitutions</title><categories>math.CO cs.DM</categories><comments>15 pages, v2 includes minor corrections to match the published
  version</comments><journal-ref>RAIRO Theoretical Informatics and Applications 48 (2014), no. 3,
  249-266</journal-ref><doi>10.1051/ita/2014008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rauzy fractals are compact sets with fractal boundary that can be associated
with any unimodular Pisot irreducible substitution. These fractals can be
defined as the Hausdorff limit of a sequence of compact sets, where each set is
a renormalized projection of a finite union of faces of unit cubes. We exploit
this combinatorial definition to prove the connectedness of the Rauzy fractal
associated with any finite product of three-letter Arnoux-Rauzy substitutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1798</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1798</id><created>2011-01-10</created><authors><author><keyname>Coleman</keyname><forenames>Rodney</forenames><affiliation>LJK</affiliation></author></authors><title>On Krawtchouk polynomials</title><categories>math.CA cs.IT math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Krawtchouk polynomials play an important role in coding theory and are also
useful in graph theory and number theory. Although the basic properties of
these polynomials are to some extent known, there is, to my knowledge, no
detailed development available. My aim in writing this article is to fill in
this gap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1803</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1803</id><created>2011-01-10</created><authors><author><keyname>Bernal</keyname><forenames>Jos&#xe9; Joaqu&#xed;n</forenames></author><author><keyname>Sim&#xf3;n</keyname><forenames>Juan Jacobo</forenames></author></authors><title>Information sets from defining sets in abelian codes</title><categories>cs.IT math.IT</categories><comments>10 pages, 2 figures</comments><msc-class>94B05, 94B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a technique to construct a set of check positions (and hence an
information set) for every abelian code solely in terms of its defining set.
This generalizes that given by Imai in \cite{Imai} in the case of binary TDC
codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1814</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1814</id><created>2011-01-10</created><authors><author><keyname>Lal</keyname><forenames>Suvansh</forenames></author></authors><title>A Logic Programming Approach for Formal Verification of NetBill Security
  and Transactions Protocol</title><categories>cs.CR</categories><comments>ICSCI-09, Hyderabad. India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Use of formal techniques for verifying the security features of electronic
commerce protocols would facilitate, the enhancement of reliability of such
protocols, thereby increasing their usability. This paper projects the
application of logic programming techniques for formal verification of a well
referred security and transactions protocol, the NetBill. The paper uses ALSP
(Action Language for Security Protocols) as an efficient formal specification
language and SMODELS a model generator to formally analyze and plan attacks on
the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1815</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1815</id><created>2011-01-10</created><authors><author><keyname>Lal</keyname><forenames>Suvansh</forenames></author><author><keyname>Jain</keyname><forenames>Mohit</forenames></author><author><keyname>Chaplot</keyname><forenames>Vikrant</forenames></author></authors><title>Approaches to Formal Verification of Security Protocols</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In recent times, many protocols have been proposed to provide security for
various information and communication systems. Such protocols must be tested
for their functional correctness before they are used in practice. Application
of formal methods for verification of security protocols would enhance their
reliability thereby, increasing the usability of systems that employ them.
Thus, formal verification of security protocols has become a key issue in
computer and communications security. In this paper we present, analyze and
compare some prevalent approaches towards verification of secure systems. We
follow the notion of - same goal through different approaches - as we formally
analyze the Needham Schroeder Public Key protocol for Lowe's attack using each
of our presented approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1826</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1826</id><created>2011-01-10</created><authors><author><keyname>Yazdani</keyname><forenames>A.</forenames></author><author><keyname>Nassehi</keyname><forenames>V.</forenames></author></authors><title>Finite element solution of multi-scale transport problems using the
  least squares based bubble function enrichment</title><categories>math-ph cs.NA math.AP math.MP physics.flu-dyn</categories><comments>12 pages, 2 figures</comments><msc-class>76R05, 76R50, 35Q35, 65N30</msc-class><journal-ref>International Journal of Modeling, Simulation, and Scientific
  Computing (IJMSSC), Volume 3 Number 4, Article 1250019, 2012</journal-ref><doi>10.1142/S1793962312500195</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an optimum technique based on the least squares method
for the derivation of the bubble functions to enrich the standard linear finite
elements employed in the formulation of Galerkin weighted-residual statements.
The element-level linear shape functions are enhanced with supplementary
polynomial bubble functions with undetermined coefficients. The best least
squares minimization of the residual functional obtained from the insertion of
these trial functions into model equations results in an algebraic system of
equations whose solution provides the unknown coefficients in terms of
element-level nodal values. The normal finite element procedures for the
construction of stiffness matrices may then be followed with no extra degree of
freedom incurred as a result of such enrichment. The performance of the
proposed method has been tested on a number of benchmark linear transport
equations with the results compared against the exact and standard linear
element solutions. It has been observed that low order bubble enriched elements
produce more accurate approximations than the standard linear elements with no
extra computational cost despite employing relatively crude mesh. However, for
the solution of strongly convection or reaction dominated problems
significantly higher order enrichments as well as extra mesh refinements will
be required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1841</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1841</id><created>2011-01-10</created><updated>2011-01-11</updated><authors><author><keyname>Karmarkar</keyname><forenames>Hrishikesh</forenames></author><author><keyname>Chakraborty</keyname><forenames>Supratik</forenames></author></authors><title>Determinization of $\omega$-automata unified</title><categories>cs.FL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a uniform construction for converting $\omega$-automata with
arbitrary acceptance conditions (based on the notion of infinity sets i.e. the
set of states visited infinitely often in a run of the automaton) to equivalent
deterministic parity automata (DPW). Given a non-deterministic automaton with
$n$ states, our construction gives a DPW with at most $2^{O(n^2 \log n)}$
states and $O(n^2)$ parity indices. The corresponding bounds when the original
automaton is deterministic are O(n!) and O(n), respectively. Our algorithm
gives better asymptotic bounds on the number of states and parity indices
vis-a-vis the best known technique when determinizing Rabin or Streett automata
with $\Omega{(2^n)}$ acceptance pairs, where $n &gt; 1$. We demonstrate this by
describing a family of Streett (and Rabin) automata with $2^{n}$ non-redundant
acceptance pairs, for which the best known determinization technique gives a
DPW with at least $\Omega{(2^{(n^3)})}$ states, while our construction
constructs a DRW/DPW with $2^{O(n^2\log n)}$ states. An easy corollary of our
construction is that an $\omega$-language with Rabin index $k$ cannot be
recognized by any $\omega$-automaton (deterministic or non-deterministic) with
fewer than $O(\sqrt{k})$ states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1846</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1846</id><created>2011-01-10</created><authors><author><keyname>Hissoiny</keyname><forenames>S.</forenames></author><author><keyname>Despr&#xe9;s</keyname><forenames>P.</forenames></author><author><keyname>Ozell</keyname><forenames>B.</forenames></author></authors><title>Using graphics processing units to generate random numbers</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The future of high-performance computing is aligning itself towards the
efficient use of highly parallel computing environments. One application where
the use of massive parallelism comes instinctively is Monte Carlo simulations,
where a large number of independent events have to be simulated. At the core of
the Monte Carlo simulation lies the Random Number Generator (RNG). In this
paper, the massively parallel implementation of a collection of pseudo-random
number generators on a graphics processing unit (GPU) is presented. The results
of the GPU implementation, in terms of samples/s, effective bandwidth and
operations per second, are presented. A comparison with other implementations
on different hardware platforms, in terms of samples/s, power efficiency and
cost-benefit, is also presented. Random numbers generation throughput of up to
~18MSamples/s have been achieved on the graphics hardware used. Efficient
hardware utilization, in terms of operations per second, has reached ~98% of
the possible integer operation throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1895</identifier>
 <datestamp>2011-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1895</id><created>2011-01-10</created><updated>2011-09-01</updated><authors><author><keyname>Sol&#xe9;</keyname><forenames>Patrick</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Constructive spherical codes near the Shannon bound</title><categories>cs.IT math.IT</categories><comments>11 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shannon gave a lower bound in 1959 on the binary rate of spherical codes of
given minimum Euclidean distance $\rho$. Using nonconstructive codes over a
finite alphabet, we give a lower bound that is weaker but very close for small
values of $\rho$. The construction is based on the Yaglom map combined with
some finite sphere packings obtained from nonconstructive codes for the
Euclidean metric. Concatenating geometric codes meeting the TVZ bound with a
Lee metric BCH code over $GF(p),$ we obtain spherical codes that are polynomial
time constructible. Their parameters outperform those obtained by Lachaud and
Stern in 1994. At very high rate they are above 98 per cent of the Shannon
bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1902</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1902</id><created>2011-01-10</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Sitchinava</keyname><forenames>Nodari</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author></authors><title>Sorting, Searching, and Simulation in the MapReduce Framework</title><categories>cs.DC</categories><comments>16 pages</comments><acm-class>F.1.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the MapReduce framework from an algorithmic
standpoint and demonstrate the usefulness of our approach by designing and
analyzing efficient MapReduce algorithms for fundamental sorting, searching,
and simulation problems. This study is motivated by a goal of ultimately
putting the MapReduce framework on an equal theoretical footing with the
well-known PRAM and BSP parallel models, which would benefit both the theory
and practice of MapReduce algorithms. We describe efficient MapReduce
algorithms for sorting, multi-searching, and simulations of parallel algorithms
specified in the BSP and CRCW PRAM models. We also provide some applications of
these results to problems in parallel computational geometry for the MapReduce
framework, which result in efficient MapReduce algorithms for sorting, 2- and
3-dimensional convex hulls, and fixed-dimensional linear programming. For the
case when mappers and reducers have a memory/message-I/O size of
$M=\Theta(N^\epsilon)$, for a small constant $\epsilon&gt;0$, all of our MapReduce
algorithms for these applications run in a constant number of rounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1915</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1915</id><created>2011-01-10</created><authors><author><keyname>Galli</keyname><forenames>Stefano</forenames></author></authors><title>A Novel Approach to the Statistical Modeling of Wireline Channels</title><categories>cs.IT math.IT</categories><comments>14 pages, 7 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report here that channel power gain and Root-Mean-Square Delay Spread
(RMS-DS) in Low/Medium Voltage power line channels are negatively correlated
lognormal random variables. Further analysis of other wireline channels allows
us to report a strong similarity between some properties observed in power line
channels and the ones observed in other wireline channels, e.g. coaxial cables
and phone lines. For example, it is here reported that channel power gain and
logarithm of the RMS-DS in DSL links are \textit{linearly} correlated random
variables. Exploiting these results, we here propose a statistical wireline
channel model where tap amplitudes and delays are generated in order to reflect
these physical properties. Although wireline channels are considered
deterministic as their impulse response can be readily calculated once the link
topology is known, a statistical wireline channel model is useful because the
variability of link topologies and wiring practices give rise to a stochastic
aspect of wireline communications that has not been well characterized in the
literature. Finally, we also point out that alternative channel models that
normalize impulse responses to a common (often unitary) power gain may be
misleading when assessing the performance of equalization schemes since this
normalization artificially removes the correlation between channel power gain
and RMS-DS and, thus, Inter-Symbol Interference (ISI).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1920</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1920</id><created>2011-01-10</created><updated>2011-02-06</updated><authors><author><keyname>Vaezi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>Superposition Coding-Based Bounds and Capacity for the Cognitive
  Z-Interference Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Inf. Theory. (The capacity result is
  extended to $|a| \geq \sqrt{1 + P_1}$)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the cognitive interference channel (CIC) with two
transmitters and two receivers, in which the cognitive transmitter non-causally
knows the message and codeword of the primary transmitter. We first introduce a
discrete memoryless more capable CIC, which is an extension to the more capable
broadcast channel (BC). Using superposition coding, we propose an inner bound
and an outer bound on its capacity region. The outer bound is also valid when
the primary user is under strong interference. For the Gaussian CIC, this outer
bound applies for $|a| \geq 1 $, where $a$ is the gain of interference link
from secondary user to primary receiver. These capacity inner and outer bounds
are then applied to the Gaussian cognitive Z-interference channel (GCZIC) where
only the primary receiver suffers interference. Upon showing that jointly
Gaussian input maximizes these bounds for the GCZIC, we evaluate the bounds for
this channel. The new outer bound is strictly tighter than other outer bounds
on the capacity of the GCZIC at strong interference ($a^2 \geq 1 $).
Especially, the outer bound coincides with the inner bound for $|a| \geq
\sqrt{1 + P_1}$ and thus, establishes the capacity of the GCZIC at this range.
For such a large $a$, superposition encoding at the cognitive transmitter and
successive decoding at the primary receiver are capacity-achieving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1932</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1932</id><created>2011-01-10</created><authors><author><keyname>Taylor</keyname><forenames>Washington</forenames></author><author><keyname>Leonard</keyname><forenames>Jud</forenames></author><author><keyname>Stewart</keyname><forenames>Lawrence C.</forenames></author></authors><title>Efficient tilings of de Bruijn and Kautz graphs</title><categories>cs.DC</categories><comments>29 pages, 11 figures</comments><report-no>MIT-CTP-4202</report-no><acm-class>C.1.4; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kautz and de Bruijn graphs have a high degree of connectivity which makes
them ideal candidates for massively parallel computer network topologies. In
order to realize a practical computer architecture based on these graphs, it is
useful to have a means of constructing a large-scale system from smaller,
simpler modules. In this paper we consider the mathematical problem of
uniformly tiling a de Bruijn or Kautz graph. This can be viewed as a
generalization of the graph bisection problem. We focus on the problem of graph
tilings by a set of identical subgraphs. Tiles should contain a maximal number
of internal edges so as to minimize the number of edges connecting distinct
tiles. We find necessary and sufficient conditions for the construction of
tilings. We derive a simple lower bound on the number of edges which must leave
each tile, and construct a class of tilings whose number of edges leaving each
tile agrees asymptotically in form with the lower bound to within a constant
factor. These tilings make possible the construction of large-scale computing
systems based on de Bruijn and Kautz graph topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1934</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1934</id><created>2011-01-10</created><updated>2012-12-17</updated><authors><author><keyname>Nakiboglu</keyname><forenames>Baris</forenames></author><author><keyname>Gorantla</keyname><forenames>Siva K.</forenames></author><author><keyname>Zheng</keyname><forenames>Lizhong</forenames></author><author><keyname>Coleman</keyname><forenames>Todd P.</forenames></author></authors><title>Bit-wise Unequal Error Protection for Variable Length Block Codes with
  Feedback</title><categories>cs.IT math.IT</categories><comments>41 pages, 3 figures</comments><doi>10.1109/TIT.2012.2227671</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bit-wise unequal error protection problem, for the case when the number
of groups of bits $\ell$ is fixed, is considered for variable length block
codes with feedback. An encoding scheme based on fixed length block codes with
erasures is used to establish inner bounds to the achievable performance for
finite expected decoding time. A new technique for bounding the performance of
variable length block codes is used to establish outer bounds to the
performance for a given expected decoding time. The inner and the outer bounds
match one another asymptotically and characterize the achievable region of
rate-exponent vectors, completely. The single message message-wise unequal
error protection problem for variable length block codes with feedback is also
solved as a necessary step on the way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.1941</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.1941</id><created>2011-01-10</created><authors><author><keyname>Karloff</keyname><forenames>Howard</forenames></author><author><keyname>Korn</keyname><forenames>Flip</forenames></author><author><keyname>Makarychev</keyname><forenames>Konstantin</forenames></author><author><keyname>Rabani</keyname><forenames>Yuval</forenames></author></authors><title>On Parsimonious Explanations for 2-D Tree- and Linearly-Ordered Data</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the &quot;explanation problem&quot; for tree- and linearly-ordered
array data, a problem motivated by database applications and recently solved
for the one-dimensional tree-ordered case. In this paper, one is given a matrix
A whose rows and columns have semantics: special subsets of the rows and
special subsets of the columns are meaningful, others are not. A submatrix in A
is said to be meaningful if and only if it is the cross product of a meaningful
row subset and a meaningful column subset, in which case we call it an &quot;allowed
rectangle.&quot; The goal is to &quot;explain&quot; A as a sparse sum of weighted allowed
rectangles. Specifically, we wish to find as few weighted allowed rectangles as
possible such that, for all i,j, a_{ij} equals the sum of the weights of all
rectangles which include cell (i,j).
  In this paper we consider the natural cases in which the matrix dimensions
are tree-ordered or linearly-ordered. In the tree-ordered case, we are given a
rooted tree T1 whose leaves are the rows of A and another, T2, whose leaves are
the columns. Nodes of the trees correspond in an obvious way to the sets of
their leaf descendants. In the linearly-ordered case, a set of rows or columns
is meaningful if and only if it is contiguous.
  For tree-ordered data, we prove the explanation problem NP-Hard and give a
randomized 2-approximation algorithm for it. For linearly-ordered data, we
prove the explanation problem NP-Hard and give a 2.56-approximation algorithm.
To our knowledge, these are the first results for the problem of sparsely and
exactly representing matrices by weighted rectangles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2002</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2002</id><created>2011-01-10</created><updated>2012-08-17</updated><authors><author><keyname>Karimadini</keyname><forenames>Mohammad</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Cooperative Tasking for Deterministic Specification Automata</title><categories>cs.SY cs.MA</categories><comments>Preprint, Submitted for publication</comments><report-no>Technical Report: NUS-ACT-12-001-Ver.3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our previous work [1], a divide-and-conquer approach was proposed for
cooperative tasking among multi-agent systems. The basic idea is to decompose a
requested global specification into subtasks for individual agents such that
the fulfillment of these subtasks by each individual agent leads to the
satisfaction of the global specification as a team. It was shown that not all
tasks can be decomposed. Furthermore, a necessary and sufficient condition was
proposed for the decomposability of a task automaton between two cooperative
agents. The current paper continues the results in [1] and proposes necessary
and sufficient conditions for task decomposability with respect to arbitrary
finite number of agents. It is further shown that the fulfillment of local
specifications can guarantee the satisfaction of the global specification. This
work provides hints for the designers on how to rule out the indecomposable
task automata and enforce the decomposability conditions. The result therefore
may pave the way towards a new perspective for decentralized cooperative
control of multi-agent systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2003</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2003</id><created>2011-01-10</created><updated>2011-04-17</updated><authors><author><keyname>Karimadini</keyname><forenames>Mohammad</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Fault-tolerant Cooperative Tasking for Multi-agent Systems</title><categories>cs.SY cs.MA math.OC</categories><comments>Preprint, Submitted for publication</comments><report-no>Technical Report: NUS-ACT-11-001-Ver.2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural way for cooperative tasking in multi-agent systems is through a
top-down design by decomposing a global task into sub-tasks for each individual
agent such that the accomplishments of these sub-tasks will guarantee the
achievement of the global task. In our previous works [1], [2] we presented
necessary and sufficient conditions on the decomposability of a global task
automaton between cooperative agents. As a follow-up work, this paper deals
with the robustness issues of the proposed top-down design approach with
respect to event failures in the multi-agent systems. The main concern under
event failure is whether a previously decomposable task can still be achieved
collectively by the agents, and if not, we would like to investigate that under
what conditions the global task could be robustly accomplished. This is
actually the fault-tolerance issue of the top-down design, and the results
provide designers with hints on which events are fragile with respect to
failures, and whether redundancies are needed. The main objective of this paper
is to identify necessary and sufficient conditions on failed events under which
a decomposable global task can still be achieved successfully. For such a
purpose, a notion called passivity is introduced to characterize the type of
event failures. The passivity is found to reflect the redundancy of
communication links over shared events, based on which necessary and sufficient
conditions for the reliability of cooperative tasking under event failures are
derived, followed by illustrative examples and remarks for the derived
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2005</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2005</id><created>2011-01-10</created><updated>2011-10-02</updated><authors><author><keyname>Ragnarsson</keyname><forenames>Stefan</forenames></author><author><keyname>Van Loan</keyname><forenames>Charles F.</forenames></author></authors><title>Block Tensor Unfoldings</title><categories>math.NA cs.NA</categories><msc-class>15A69</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the field of numerical multilinear algebra, block tensors are
increasingly important. Accordingly, it is appropriate to develop an
infrastructure that supports reasoning about block tensor computation. In this
paper we establish concise notation that is suitable for the analysis and
development of block tensor algorithms, prove several useful block tensor
identities, and make precise the notion of a block tensor unfolding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2007</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2007</id><created>2011-01-10</created><authors><author><keyname>Liu</keyname><forenames>Ruoheng</forenames><affiliation>Shitz</affiliation></author><author><keyname>Liu</keyname><forenames>Tie</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>New Results on Multiple-Input Multiple-Output Broadcast Channels with
  Confidential Messages</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, 11 pages, 5
  figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents two new results on multiple-input multiple-output (MIMO)
Gaussian broadcast channels with confidential messages. First, the problem of
the MIMO Gaussian wiretap channel is revisited. A matrix characterization of
the capacity-equivocation region is provided, which extends the previous result
on the secrecy capacity of the MIMO Gaussian wiretap channel to the general,
possibly imperfect secrecy setting. Next, the problem of MIMO Gaussian
broadcast channels with two receivers and three independent messages: a common
message intended for both receivers, and two confidential messages each
intended for one of the receivers but needing to be kept asymptotically
perfectly secret from the other, is considered. A precise characterization of
the capacity region is provided, generalizing the previous results which
considered only two out of three possible messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2018</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2018</id><created>2011-01-10</created><updated>2013-11-10</updated><authors><author><keyname>Liao</keyname><forenames>Ruijia</forenames></author></authors><title>The Complexity of 3SAT_N and the P versus NP Problem</title><categories>cs.CC</categories><comments>26 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We introduce the NP-complete problem 3SAT_N and extend Tovey's results to a
classification theorem for this problem. This theorem leads us to generalize
the concept of truth assignments for SAT to aggressive truth assignments for
3SAT_N. We introduce the concept of a set compatible with the P and NP problem,
and prove that all aggressive truth assignments are pseudo-algorithms. We
combine algorithm, pseudo-algorithm and diagonalization method to study the
complexity of 3SAT_N and the P versus NP problem. The main result is P != NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2057</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2057</id><created>2011-01-11</created><authors><author><keyname>Bashan</keyname><forenames>Amir</forenames></author><author><keyname>Parshani</keyname><forenames>Roni</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author></authors><title>Percolation in networks composed of connectivity and dependency links</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>8 pages, 7 figures</comments><doi>10.1103/PhysRevE.83.051127</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks composed from both connectivity and dependency links were found to
be more vulnerable compared to classical networks with only connectivity links.
Their percolation transition is usually of a first order compared to the second
order transition found in classical networks. We analytically analyze the
effect of different distributions of dependencies links on the robustness of
networks. For a random Erd$\ddot{o}$s-R$\acute{e}$nyi (ER) network with average
degree $k$ that is divided into dependency clusters of size $s$, the fraction
of nodes that belong to the giant component, $P_\infty$, is given by $
P_\infty=p^{s-1} [1-\exp{(-kpP_\infty)}]^s $ where $1-p$ is the initial
fraction of removed nodes. Our general result coincides with the known
Erd$\ddot{o}$s-R$\acute{e}$nyi equation for random networks for $s=1$ and with
the result of Parshani et al (PNAS, in press, 2011) for $s=2$. For networks
with Poissonian distribution of dependency links we find that $P_\infty$ is
given by $P_\infty = f_{k,p}(P_\infty) e^{(&lt;s&gt;-1)(pf_{k,p}(P_\infty)-1)}$ where
$f_{k,p}(P_\infty) \equiv 1-\exp{(-kpP_\infty)}$ and $&lt;s&gt;$ is the mean value of
the size of dependency clusters. For networks with Gaussian distribution of
dependency links we show how the average and width of the distribution affect
the robustness of the networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2061</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2061</id><created>2011-01-11</created><authors><author><keyname>Naves</keyname><forenames>Guyslain</forenames><affiliation>LIX</affiliation></author><author><keyname>Jost</keyname><forenames>Vincent</forenames><affiliation>LIX</affiliation></author></authors><title>The graphs with the max-Mader-flow-min-multiway-cut property</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are given a graph $G$, an independant set $\mathcal{S} \subset V(G)$ of
\emph{terminals}, and a function $w:V(G) \to \mathbb{N}$. We want to know if
the maximum $w$-packing of vertex-disjoint paths with extremities in
$\mathcal{S}$ is equal to the minimum weight of a vertex-cut separating
$\mathcal{S}$. We call \emph{Mader-Mengerian} the graphs with this property for
each independant set $\mathcal{S}$ and each weight function $w$. We give a
characterization of these graphs in term of forbidden minors, as well as a
recognition algorithm and a simple algorithm to find maximum packing of paths
and minimum multicuts in those graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2096</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2096</id><created>2011-01-11</created><authors><author><keyname>Karjee</keyname><forenames>Jyotirmoy</forenames></author><author><keyname>Jamadagni</keyname><forenames>H. S</forenames></author></authors><title>Data Accuracy Estimation for Cluster with Spatially Correlated Data in
  Wireless Sensor Networks</title><categories>cs.NI</categories><comments>ICISCI 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective-The main purpose of this paper is to construct a data accuracy
model for the maximal set of sensor nodes that sense a point event and forms a
cluster with fully connected network between them. We determine the minimal set
of sensor nodes that are sufficient to give approximately the same data
accuracy achieve by the maximal set of sensor nodes. Design
approach/Procedure-L set of sensor nodes are randomly deployed over a region Z.
Since a point event S has occurred in the region Z, M maximal set of sensor
nodes wake up and start sensing the point event. The set of M sensor nodes
forms a cluster with fully connected network and remaining set of sensor nodes
continue to be in sleep mode. One sensor node is elected randomly as a cluster
head (CH) node which can estimate the data accuracy for the cluster before data
aggregation and finally send the data to the sink node. Findings - Since we
simulate the data accuracy for the cluster (M set of sensor nodes) at CH node,
there exist P minimal set of sensor nodes which give approximately the same
data accuracy level achieve by M set of sensor nodes .Moreover we find that as
the distance from the point event to the number of sensor nodes increases, the
data accuracy also get decreases. Design Limitation -This model is only
applicable to estimate data accuracy for the point event where the sensed data
are assumed to be spatially correlated with approximately same variations.
Practical implementation-Detect point event e.g. fire in forest.
Inventive/Novel idea - This is the first time that a data accuracy model is
performed for the cluster before data aggregation at the CH node which can
reduce data redundancy and communication overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2098</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2098</id><created>2011-01-11</created><authors><author><keyname>Karjee</keyname><forenames>Jyotirmoy</forenames></author><author><keyname>Jamadagni</keyname><forenames>H. S</forenames></author></authors><title>Data Accuracy Estimation for Spatially Correlated Data in Wireless
  Sensor Networks under Distributed Clustering</title><categories>cs.NI</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective-The main purpose of this paper is to construct a distributed
clustering algorithm such that each distributed cluster can perform the data
accuracy at their respective cluster head node before data aggregation and
transmit the data to the sink node. Design approach/Procedure - We investigate
that the data are spatially correlated among the sensor nodes which form the
clusters in the spatial domain. Due to high correlation of data, these clusters
of sensor nodes are overlapped in the spatial domain. To overcome this problem,
we construct a distributed clustering algorithm with non-overlapping irregular
clusters in the spatial domain. Then each distributed cluster can perform data
accuracy at the cluster head node and finally send the data to the sink node.
Findings- Simulation result shows the associate sensor nodes of each
distributed cluster and clarifies their data accuracy profile in the spatial
domain. We demonstrate the simulation results for a single cluster to verify
that their exist an optimal cluster which give approximately the same data
accuracy level achieve by the single cluster. Moreover we find that as the
distance from the tracing point to the number of sensor node increases the data
accuracy decreases. Design Limitations - This model is only applicable to
estimate data accuracy for distributed clusters where the sensed data are
assumed to be spatially correlated with approximately same variations.
Practical implementation - Measure the moisture content in the distributed
agricultural field. Inventive/Novel idea- This is the first time that a data
accuracy model is performed for the distributed clusters before data
aggregation at the cluster head node which can reduce data redundancy and
communication overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2123</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2123</id><created>2011-01-11</created><authors><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Kroeller</keyname><forenames>Alexander</forenames></author><author><keyname>Lorek</keyname><forenames>Martin</forenames></author><author><keyname>Pfetsch</keyname><forenames>Marc</forenames></author></authors><title>Disruption Management with Rescheduling of Trips and Vehicle
  Circulations</title><categories>math.OC cs.DS</categories><comments>14 pages, 4 figures, to appear in the 5th ASME/ASCE/IEEE Joint Rail
  Conference 2011 (JRC 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a combined approach for the recovery of a timetable by
rescheduling trips and vehicle circulations for a rail-based transportation
system subject to disruptions. We propose a novel event-based integer
programming (IP) model. Features include shifting and canceling of trips as
well as modifying the vehicle schedules by changing or truncating the
circulations. The objective maximizes the number of recovered trips, possibly
with delay, while guaranteeing a conflict-free new timetable for the estimated
time window of the disruption. We demonstrate the usefulness of our approach
through experiments for real-life test instances of relevant size, arising from
the subway system of Vienna. We focus on scenarios in which one direction of
one track is blocked, and trains have to be scheduled through this bottleneck.
Solving these instances is made possible by contracting parts of the underlying
event-activity graph; this allows a significant size reduction of the IP.
Usually, the solutions found within one minute are of good quality and can be
used as good estimates of recovery plans in an online context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2135</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2135</id><created>2011-01-11</created><updated>2011-12-15</updated><authors><author><keyname>Malarz</keyname><forenames>Krzysztof</forenames></author><author><keyname>Kulakowski</keyname><forenames>Krzysztof</forenames></author></authors><title>Bounded confidence model: addressed information maintain diversity of
  opinions</title><categories>physics.soc-ph cs.SI</categories><comments>3 pages, 4 figures, RevTeX 4.1, presented at the 5th Polish Symposium
  on Econo- and Sociophysics, Nov. 25-27, 2010, Warsaw (PL)</comments><journal-ref>Acta Phys. Pol. A 121 (2-B), B-86 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A community of agents is subject to a stream of messages, which are
represented as points on a plane of issues. Messages are sent by media and by
agents themselves. Messages from media shape the public opinion. They are
unbiased, i.e. positive and negative opinions on a given issue appear with
equal frequencies. In our previous work, the only criterion to receive a
message by an agent is if the distance between this message and the ones
received earlier does not exceed the given value of the tolerance parameter.
Here we introduce a possibility to address a message to a given neighbour. We
show that this option reduces the unanimity effect, what improves the
collective performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2146</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2146</id><created>2011-01-11</created><authors><author><keyname>Caballero</keyname><forenames>Rafael</forenames></author><author><keyname>Rodr&#xed;guez-Artalejo</keyname><forenames>Mario</forenames></author><author><keyname>Romero-D&#xed;az</keyname><forenames>Carlos A.</forenames></author></authors><title>A Generic Scheme for Qualified Constraint Functional Logic Progamming</title><categories>cs.PL cs.LO</categories><comments>36 pages, 5 figures, extended version with full proofs of Qualified
  Computations in Functional Logic Programming, in P.M. Hill and D.S. Warren
  (Eds.), ICLP 2009, LNCS 5649, pp. 449-463, 2009</comments><report-no>SIC-1-09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Qualification has been recently introduced as a generalization of uncertainty
in the field of Logic Programming. In this report we investigate a more
expressive language for First-Order Functional Logic Programming with
Constraints and Qualification. We present a Rewriting Logic which characterizes
the intended semantics of programs, and a prototype implementation based on a
semantically correct program transformation. Potential applications of the
resulting language include flexible information retrieval. As a concrete
illustration, we show how to write program rules to compute qualified answers
for user queries concerning the books available in a given library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2162</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2162</id><created>2011-01-11</created><updated>2012-04-23</updated><authors><author><keyname>Berger</keyname><forenames>Ulrich</forenames><affiliation>Swansea University</affiliation></author></authors><title>From coinductive proofs to exact real arithmetic: theory and
  applications</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>03F60</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 24,
  2011) lmcs:1109</journal-ref><doi>10.2168/LMCS-7(1:8)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on a new coinductive characterization of continuous functions we
extract certified programs for exact real number computation from constructive
proofs. The extracted programs construct and combine exact real number
algorithms with respect to the binary signed digit representation of real
numbers. The data type corresponding to the coinductive definition of
continuous functions consists of finitely branching non-wellfounded trees
describing when the algorithm writes and reads digits. We discuss several
examples including the extraction of programs for polynomials up to degree two
and the definite integral of continuous maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2170</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2170</id><created>2011-01-11</created><updated>2011-03-28</updated><authors><author><keyname>Bonet</keyname><forenames>Maria Luisa</forenames></author><author><keyname>Linz</keyname><forenames>Simone</forenames></author><author><keyname>John</keyname><forenames>Katherine St.</forenames></author></authors><title>The Complexity of Finding Multiple Solutions to Betweenness and Quartet
  Compatibility</title><categories>q-bio.PE cs.CC cs.DS</categories><comments>25 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that two important problems that have applications in computational
biology are ASP-complete, which implies that, given a solution to a problem, it
is NP-complete to decide if another solution exists. We show first that a
variation of Betweenness, which is the underlying problem of questions related
to radiation hybrid mapping, is ASP-complete. Subsequently, we use that result
to show that Quartet Compatibility, a fundamental problem in phylogenetics that
asks whether a set of quartets can be represented by a parent tree, is also
ASP-complete. The latter result shows that Steel's \sc Quartet Challenge, which
asks whether a solution to Quartet Compatibility is unique, is coNP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2172</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2172</id><created>2011-01-11</created><authors><author><keyname>Wood</keyname><forenames>Lloyd</forenames></author><author><keyname>Smith</keyname><forenames>Charles</forenames></author><author><keyname>Eddy</keyname><forenames>Wesley M.</forenames></author><author><keyname>Ivancic</keyname><forenames>Will</forenames></author><author><keyname>Jackson</keyname><forenames>Chris</forenames></author></authors><title>Taking Saratoga from Space-Based Ground Sensors to Ground-Based Space
  Sensors</title><categories>astro-ph.IM cs.NI</categories><comments>Preprint of peer-reviewed conference paper accepted by and to appear
  at the IEEE Aerospace 2011 conference, Big Sky, Montana, March 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Saratoga transfer protocol was developed by Surrey Satellite Technology
Ltd (SSTL) for its Disaster Monitoring Constellation (DMC) satellites. In over
seven years of operation, Saratoga has provided efficient delivery of
remote-sensing Earth observation imagery, across private wireless links, from
these seven low-orbit satellites to ground stations, using the Internet
Protocol (IP). Saratoga is designed to cope with high bandwidth-delay products,
constrained acknowledgement channels, and high loss while streaming or
delivering extremely large files. An implementation of this protocol has now
been developed at the Australian Commonwealth Scientific and Industrial
Research Organisation (CSIRO) for wider use and testing. This is intended to
prototype delivery of data across dedicated astronomy radio telescope networks
on the ground, where networked sensors in Very Long Baseline Interferometer
(VLBI) instruments generate large amounts of data for processing and can send
that data across private IP- and Ethernet-based links at very high rates. We
describe this new Saratoga implementation, its features and focus on high
throughput and link utilization, and lessons learned in developing this
protocol for sensor-network applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2173</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2173</id><created>2011-01-11</created><authors><author><keyname>Gleich</keyname><forenames>David F.</forenames></author><author><keyname>Greif</keyname><forenames>Chen</forenames></author><author><keyname>Varah</keyname><forenames>James M.</forenames></author></authors><title>The power and Arnoldi methods in an algebra of circulants</title><categories>cs.NA</categories><comments>25 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Circulant matrices play a central role in a recently proposed formulation of
three-way data computations. In this setting, a three-way table corresponds to
a matrix where each &quot;scalar&quot; is a vector of parameters defining a circulant.
This interpretation provides many generalizations of results from matrix or
vector-space algebra. We derive the power and Arnoldi methods in this algebra.
In the course of our derivation, we define inner products, norms, and other
notions. These extensions are straightforward in an algebraic sense, but the
implications are dramatically different from the standard matrix case. For
example, a matrix of circulants has a polynomial number of eigenvalues in its
dimension; although, these can all be represented by a carefully chosen
canonical set of eigenvalues and vectors. These results and algorithms are
closely related to standard decoupling techniques on block-circulant matrices
using the fast Fourier transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2182</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2182</id><created>2011-01-11</created><updated>2012-04-20</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Whiting</keyname><forenames>Phil</forenames></author></authors><title>The Degrees of Freedom of Compute-and-Forward</title><categories>cs.IT math.IT</categories><comments>32 pages, to appear in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 58, pp. 5214 - 5232
  , August 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the asymptotic behavior of compute-and-forward relay networks in
the regime of high signal-to-noise ratios. We consider a section of such a
network consisting of K transmitters and K relays. The aim of the relays is to
reliably decode an invertible function of the messages sent by the
transmitters. An upper bound on the capacity of this system can be obtained by
allowing full cooperation among the transmitters and among the relays,
transforming the network into a K times K multiple-input multiple-output (MIMO)
channel. The number of degrees of freedom of compute-and-forward is hence at
most K. In this paper, we analyze the degrees of freedom achieved by the
lattice coding implementation of compute-and-forward proposed recently by Nazer
and Gastpar. We show that this lattice implementation achieves at most
2/(1+1/K)\leq 2 degrees of freedom, thus exhibiting a very different asymptotic
behavior than the MIMO upper bound. This raises the question if this gap of the
lattice implementation to the MIMO upper bound is inherent to
compute-and-forward in general. We answer this question in the negative by
proposing a novel compute-and-forward implementation achieving K degrees of
freedom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2190</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2190</id><created>2011-01-11</created><updated>2011-03-08</updated><authors><author><keyname>Venkatesan</keyname><forenames>R. C.</forenames></author><author><keyname>Plastino</keyname><forenames>A.</forenames></author></authors><title>Scaled Bregman divergences in a Tsallis scenario</title><categories>cond-mat.stat-mech cs.IT math-ph math.IT math.MP</categories><comments>18 pages. Iterative corrections</comments><doi>10.1016/j.physa.2011.03.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There exist two different versions of the Kullback-Leibler divergence (K-Ld)
in Tsallis statistics, namely the usual generalized K-Ld and the generalized
Bregman K-Ld. Problems have been encountered in trying to reconcile them. A
condition for consistency between these two generalized K-Ld-forms by recourse
to the additive duality of Tsallis statistics is derived. It is also shown that
the usual generalized K-Ld subjected to this additive duality, known as the
dual generalized K-Ld, is a scaled Bregman divergence. This leads to an
interesting conclusion: the dual generalized mutual information is a scaled
Bregman information. The utility and implications of these results are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2192</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2192</id><created>2011-01-11</created><authors><author><keyname>Belmega</keyname><forenames>E. V.</forenames></author><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author></authors><title>Power Allocation Games in Interference Relay Channels: Existence
  Analysis of Nash Equilibria</title><categories>cs.IT math.IT</categories><comments>To appear in EURASIP Journal on Wireless Communications and
  Networking (JWCN)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a network composed of two interfering point-to-point links where
the two transmitters can exploit one common relay node to improve their
individual transmission rate. Communications are assumed to be multi-band and
transmitters are assumed to selfishly allocate their resources to optimize
their individual transmission rate. The main objective of this paper is to show
that this conflicting situation (modeled by a non-cooperative game) has some
stable outcomes, namely Nash equilibria. This result is proved for three
different types of relaying protocols: decode-and-forward,
estimate-and-forward, and amplify-and-forward. We provide additional results on
the problems of uniqueness, efficiency of the equilibrium, and convergence of a
best-response based dynamics to the equilibrium. These issues are analyzed in a
special case of the amplify-and-forward protocol and illustrated by simulations
in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2219</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2219</id><created>2011-01-05</created><authors><author><keyname>Eidelman</keyname><forenames>Elizaveta</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Alchymical Mirror: Real-time Interactive Sound- and Simple
  Motion-Tracking Set of Jitter/Max/MSP Patches</title><categories>cs.MM</categories><comments>13 pages; a December 2005 report; video is not included into the
  arXiv submission; Jitter language patches are not replicated in this version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document supplements an experimental Jitter / Max/MSP collection of
implementation patches that set its goal to simulate an alchemical process for
a person standing in front of a mirror-like screen while interacting with it.
The work involved takes some patience and has three stages to go through. At
the final stage the &quot;alchemist&quot; in the mirror wearing sharp-colored gloves (for
motion tracking) is to extract the final ultimate shining sparkle (FFT-based
visualization) in the nexus of the hands. The more the hands are apart, the
large the sparkle should be. Moving hands around should make the sparkle
follow. To achieve the desired visual effect and the feedback mechanism, the
Jitter lattice-based intensional programming model is used to work on
4-dimensional (A+R+G+B) video matrices and sound signals in order to apply some
well-known alchemical techniques to the video at real-time to get a mirror
effect and accompanying transmutation and transformation stages of the video
based on the stability of the sound produced for some duration of time in
real-time. There is an accompanying video of the result with the interaction
with the tool and the corresponding programming patches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2220</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2220</id><created>2011-01-11</created><authors><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Savla</keyname><forenames>Ketan</forenames></author><author><keyname>Acemoglu</keyname><forenames>Daron</forenames></author><author><keyname>Dahleh</keyname><forenames>Munther A.</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>Stability Analysis of Transportation Networks with Multiscale Driver
  Decisions</title><categories>math.DS cs.GT cs.SY math.OC nlin.AO</categories><comments>21 pages, 2 figures, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stability of Wardrop equilibria is analyzed for dynamical transportation
networks in which the drivers' route choices are influenced by information at
multiple temporal and spatial scales. The considered model involves a continuum
of indistinguishable drivers commuting between a common origin/destination pair
in an acyclic transportation network. The drivers' route choices are affected
by their, relatively infrequent, perturbed best responses to global information
about the current network congestion levels, as well as their instantaneous
local observation of the immediate surroundings as they transit through the
network. A novel model is proposed for the drivers' route choice behavior,
exhibiting local consistency with their preference toward globally less
congested paths as well as myopic decisions in favor of locally less congested
paths. The simultaneous evolution of the traffic congestion on the network and
of the aggregate path preference is modeled by a system of coupled ordinary
differential equations. The main result shows that, if the frequency of updates
of path preferences is sufficiently small as compared to the frequency of the
traffic flow dynamics, then the state of the transportation network ultimately
approaches a neighborhood of the Wardrop equilibrium. The presented results may
be read as a further evidence in support of Wardrop's postulate of equilibrium,
showing robustness of it with respect to non-persistent perturbations. The
proposed analysis combines techniques from singular perturbation theory,
evolutionary game theory, and cooperative dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2228</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2228</id><created>2011-01-11</created><authors><author><keyname>Thomas</keyname><forenames>Andrew C.</forenames></author><author><keyname>Blitzstein</keyname><forenames>Joseph K.</forenames></author></authors><title>Valued Ties Tell Fewer Lies, II: Why Not To Dichotomize Network Edges
  With Bounded Outdegrees</title><categories>stat.AP cs.SI physics.soc-ph</categories><comments>15 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various methods have been proposed for creating a binary version of a complex
network with valued ties. Rather than the default method of choosing a single
threshold value about which to dichotomize, we consider a method of choosing
the highest k outbound arcs from each person and assigning a binary tie, as
this has the advantage of minimizing the isolation of nodes that may otherwise
be weakly connected. However, simulations and real data sets establish that
this method is worse than the default thresholding method and should not be
generally considered to deal with valued networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2229</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2229</id><created>2011-01-11</created><updated>2011-06-01</updated><authors><author><keyname>Khor</keyname><forenames>Susan</forenames></author></authors><title>Why aren't the small worlds of protein contact networks smaller</title><categories>q-bio.MN cs.SI physics.bio-ph physics.soc-ph q-bio.BM</categories><comments>v2 accepted by European Conference on Artifical Life 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer experiments are performed to investigate why protein contact
networks (networks induced by spatial contacts between amino acid residues of a
protein) do not have shorter average shortest path lengths in spite of their
importance to protein folding. We find that shorter average inter-nodal
distances is no guarantee of finding a global optimum more easily. Results from
the experiments also led to observations which parallel an existing view that
neither short-range nor long-range interactions dominate the protein folding
process. Nonetheless, runs where there was a slight delay in the use of
long-range interactions yielded the best search performance. We incorporate
this finding into the optimization function by giving more weight to
short-range links. This produced results showing that randomizing long-range
links does not yield better search performance than protein contact networks au
natural even though randomizing long-range links significantly reduces average
path lengths and retains much of the clustering and positive degree-degree
correlation inherent in protein contact networks. Hence there can be
explanations, other than the excluded volume argument, beneath the topological
limits of protein contact networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2242</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2242</id><created>2010-12-31</created><authors><author><keyname>Kumar</keyname><forenames>Aripirala Manoj</forenames></author><author><keyname>Reddy</keyname><forenames>G. Bharath</forenames></author><author><keyname>Reddy</keyname><forenames>G. Krishna Chaitanya</forenames></author></authors><title>Modelling to study its non-linear effects on Communication System's
  performance with BER as performance measure</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a study of non-linear effects of RF Amplifiers on Communication
Systems Performance. High speed data communication is made possible by
Multilevel Modulation schemes. This paper presents a study of these non linear
effects on multilevel Modulation schemes like MPSK and MQAM. We make use of Bit
Error Ratio (BER) as performance measure. BER vs SNR (Signal-to-Noise Ratio)
curves provide comparison between the non linear effects caused by Gain
Compression in particular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2243</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2243</id><created>2010-12-12</created><authors><author><keyname>Lu</keyname><forenames>Chenguang</forenames></author></authors><title>Illustrating Color Evolution and Color Blindness by the Decoding Model
  of Color Vision</title><categories>cs.CV</categories><comments>11 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A symmetrical model of color vision, the decoding model as a new version of
zone model, was introduced. The model adopts new continuous-valued logic and
works in a way very similar to the way a 3-8 decoder in a numerical circuit
works. By the decoding model, Young and Helmholtz's tri-pigment theory and
Hering's opponent theory are unified more naturally; opponent process, color
evolution, and color blindness are illustrated more concisely. According to the
decoding model, we can obtain a transform from RGB system to HSV system, which
is formally identical to the popular transform for computer graphics provided
by Smith (1978). Advantages, problems, and physiological tests of the decoding
model are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2245</identifier>
 <datestamp>2015-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2245</id><created>2011-01-11</created><updated>2015-10-03</updated><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author></authors><title>Invertible Bloom Lookup Tables</title><categories>cs.DS cs.DB</categories><comments>contains 4 figures, showing experimental performance</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a version of the Bloom filter data structure that supports not
only the insertion, deletion, and lookup of key-value pairs, but also allows a
complete listing of its contents with high probability, as long the number of
key-value pairs is below a designed threshold. Our structure allows the number
of key-value pairs to greatly exceed this threshold during normal operation.
Exceeding the threshold simply temporarily prevents content listing and reduces
the probability of a successful lookup. If later entries are deleted to return
the structure below the threshold, everything again functions appropriately. We
also show that simple variations of our structure are robust to certain
standard errors, such as the deletion of a key without a corresponding
insertion or the insertion of two distinct values for a key. The properties of
our structure make it suitable for several applications, including database and
networking applications that we highlight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2249</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2249</id><created>2011-01-11</created><authors><author><keyname>Mohaisen</keyname><forenames>Manar</forenames></author><author><keyname>Chang</keyname><forenames>KyungHi</forenames></author></authors><title>Fixed-complexity Sphere Encoder for Multi-user MIMO Systems</title><categories>cs.IT math.IT</categories><comments>7 pages, 7 figures. Accepted by Journal of Communications and
  Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a fixed-complexity sphere encoder (FSE) for
multi-user MIMO (MU-MIMO) systems. The proposed FSE accomplishes a scalable
tradeoff between performance and complexity. Also, because it has a parallel
tree-search structure, the proposed encoder can be easily pipelined, leading to
a tremendous reduction in the precoding latency. The complexity of the proposed
encoder is also analyzed, and we propose two techniques that reduce it.
Simulation and analytical results demonstrate that in a 4 by 4 MU-MIMO system,
the proposed FSE requires only 11.5% of the computational complexity needed by
the conventional QRD-M encoder (QRDM-E). Also, the encoding throughput of the
proposed encoder is 7.5 times that of the QRDM-E with tolerable degradation in
the BER performance, while achieving the optimum diversity order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2268</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2268</id><created>2011-01-11</created><authors><author><keyname>Fagiolini</keyname><forenames>Adriano</forenames></author><author><keyname>Arisumi</keyname><forenames>Hitoshi</forenames></author><author><keyname>Bicchi</keyname><forenames>Antonio</forenames></author></authors><title>Casting Robotic End-effectors To Reach Faraway Moving Objects</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we address the problem of catching objects that move at a
relatively large distance from the robot, of the order of tens of times the
size of the robot itself. To this purpose, we adopt casting manipulation and
visual-based feedback control. Casting manipulation is a technique to deploy a
robotic end-effector far from the robot's base, by throwing the end-effector
and controlling its ballistic flight using forces transmitted through a light
tether connected to the end-effector itself. The tether cable can then be used
to retrieve the end- effector to exert forces on the robot's environment. In
previous work, planar casting manipulation was demon- strated to aptly catch
static objects placed at a distant, known position, thus proving it suitable
for applications such as sample acquisition and return, rescue, etc. In this
paper we propose an extension of the idea to controlling the position of the
end- effector to reach moving targets in 3D. The goal is achieved by an
innovative design of the casting mechanism, and by closing a real-time control
loop on casting manipulation using visual feedback of moving targets. To
achieve this result, simplified yet accurate models of the system suitable for
real-time computation are developed, along with a suitable visual feedback
scheme for the flight phase. Effectiveness of the visual feedback controller is
demonstrated through experiments with a 2D casting robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2270</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2270</id><created>2011-01-11</created><authors><author><keyname>Marino</keyname><forenames>Dario</forenames></author><author><keyname>Fagiolini</keyname><forenames>Adriano</forenames></author><author><keyname>Pallottino</keyname><forenames>Lucia</forenames></author></authors><title>Distributed Collision-free Protocol for AGVs in Industrial Environments</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a decentralized coordina- tion algorithm for safe
and efficient management of a group of mobile robots following predefined paths
in a dynamic industrial environment. The proposed algorithm is based on a
shared resources protocol and a replanning strategy. It is proved to guarantee
ordered traffic flows avoiding collisions, deadlocks (stall situations) and
livelock (agents move without reaching final destinations). Mutual access to
resources has been proved for the proposed approach while condition on the
maximum number of AGVs is given to ensure the absence of deadlocks during
system evolutions. Finally conditions to verify a local livelocks will also be
proposed. In consistency with the model of distributed robotic systems (DRS),
no centralized mechanism, synchronized clock, shared memory or ground support
is needed. A local inter-robot communication, based on sign-boards, is
considered among a small number of spatially adjacent robotic units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2272</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2272</id><created>2011-01-11</created><authors><author><keyname>Fagiolini</keyname><forenames>Adriano</forenames></author><author><keyname>Bicchi</keyname><forenames>Antonio</forenames></author></authors><title>Logical Consensus for Distributed and Robust Intrusion Detection</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a novel consensus mech- anism where agents of a
network are able to share logical values, or Booleans, representing their local
opinions on e.g. the presence of an intruder or of a fire within an indoor
environment. We first formulate the logical consensus problem, and then we
review relevant results in the literature on cellular automata and convergence
of finite-state iteration maps. Under suitable joint conditions on the
visibility of agents and their communication capability, we provide an
algorithm for generating a logical linear consensus system that is globally
stable. The solution is optimal in terms of the number of messages to be
exchanged and the time needed to reach a consensus. Moreover, to cope with
possible sensor failure, we propose a second design approach that produces
robust logical nonlinear consensus systems tolerating a given maximum number of
faults. Finally, we show applicability of the agreement mechanism to a case
study consisting of a distributed Intrusion Detection System (IDS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2273</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2273</id><created>2011-01-12</created><authors><author><keyname>Fagiolini</keyname><forenames>Adriano</forenames></author><author><keyname>Dini</keyname><forenames>Gianluca</forenames></author><author><keyname>Bicchi</keyname><forenames>Antonio</forenames></author></authors><title>Distributed Intrusion Detection for the Security of Societies of Robots</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of detecting possible intruders in a group
of autonomous robots, which coexist in a shared environment and interact with
each other according to a set of &quot;social behaviors&quot;, or common rules. Such
rules specify what actions each robot is allowed to perform in the pursuit of
its individual goals: rules are distributed, i.e. they can evaluated based only
on the state of the individual robot, and on information that can be sensed
directly or through communication with immediate neighbors. We consider
intruders as robots which misbehave, i.e. do not follow the rules, because of
either spontaneous failures or malicious reprogramming. Our goal is to detect
intruders by observing the congruence of their behavior with the social rules
as applied to the current state of the overall system. Moreover, in accordance
with the fully distributed nature of the problem, the detection itself must be
peformed by individual robots, based only on local information. The paper
introduces a formalism that allows to model uniformly a large variety of
possible robot societies. The main contribution consists in the proposal of an
Intrusion Detection System, i.e. a protocol that, under suitabkle conditions,
allows individual robots to detect possible misbehaving robots in their
vicinity, and trigger possible further actions to secure the society. It is
worth noting that the generality of the protocol formalism makes so that local
monitors can be automatically generated once the cooperation rules and the
robot dynamics are specified. The effectiveness of the proposed technique is
shown through application to examples of automated robotic systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2275</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2275</id><created>2011-01-12</created><authors><author><keyname>Fagiolini</keyname><forenames>Adriano</forenames></author><author><keyname>Dubbini</keyname><forenames>Nevio</forenames></author><author><keyname>Bicchi</keyname><forenames>Antonio</forenames></author></authors><title>Distributed Consensus on Set-valued Information</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the convergence of infor- mation in distributed systems
of agents communicating over a network. The information on which the
convergence is sought is not represented by real numbers, rather by sets of
real numbers, whose possible dynamics are given by the class of so-called
Boolean maps, involving only unions, intersections, and complements of sets.
Based on a notion of contractivity, a necessary and sufficient condition
ensuring the global and local convergence toward an equilibrium point is
presented. In particular the analysis of global convergence recovers results
already obtained by the authors, but the more general approach used in this
paper allows analogue results to be found to characterize the local
convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2279</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2279</id><created>2011-01-12</created><authors><author><keyname>Nguyen</keyname><forenames>Tuan</forenames></author><author><keyname>Do</keyname><forenames>Minh</forenames></author><author><keyname>Gerevini</keyname><forenames>Alfonso</forenames></author><author><keyname>Serina</keyname><forenames>Ivan</forenames></author><author><keyname>Srivastava</keyname><forenames>Biplav</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author></authors><title>Planning with Partial Preference Models</title><categories>cs.AI</categories><comments>38 pages, submitted to Artificial Intelligence Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current work in planning with preferences assume that the user's preference
models are completely specified and aim to search for a single solution plan.
In many real-world planning scenarios, however, the user probably cannot
provide any information about her desired plans, or in some cases can only
express partial preferences. In such situations, the planner has to present not
only one but a set of plans to the user, with the hope that some of them are
similar to the plan she prefers. We first propose the usage of different
measures to capture quality of plan sets that are suitable for such scenarios:
domain-independent distance measures defined based on plan elements (actions,
states, causal links) if no knowledge of the user's preferences is given, and
the Integrated Convex Preference measure in case the user's partial preference
is provided. We then investigate various heuristic approaches to find set of
plans according to these measures, and present empirical results demonstrating
the promise of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2286</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2286</id><created>2011-01-12</created><updated>2012-04-15</updated><authors><author><keyname>Mallat</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Group Invariant Scattering</title><categories>math.FA cs.CV</categories><comments>78 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper constructs translation invariant operators on L2(R^d), which are
Lipschitz continuous to the action of diffeomorphisms. A scattering propagator
is a path ordered product of non-linear and non-commuting operators, each of
which computes the modulus of a wavelet transform. A local integration defines
a windowed scattering transform, which is proved to be Lipschitz continuous to
the action of diffeomorphisms. As the window size increases, it converges to a
wavelet scattering transform which is translation invariant. Scattering
coefficients also provide representations of stationary processes. Expected
values depend upon high order moments and can discriminate processes having the
same power spectrum. Scattering operators are extended on L2 (G), where G is a
compact Lie group, and are invariant under the action of G. Combining a
scattering on L2(R^d) and on Ld (SO(d)) defines a translation and rotation
invariant scattering on L2(R^d).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2288</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2288</id><created>2011-01-12</created><authors><author><keyname>Liu</keyname><forenames>Feng</forenames><affiliation>Angela</affiliation></author><author><keyname>Chan</keyname><forenames>Chung</forenames><affiliation>Angela</affiliation></author><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author></authors><title>On the Degree of Freedom for Multi-Source Multi-Destination Wireless
  Network with Multi-layer Relays</title><categories>cs.IT math.IT</categories><comments>15 pages, 2 figures</comments><msc-class>94A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Degree of freedom (DoF) region provides an approximation of capacity region
in high signal-to-noise ratio (SNR) regime, while sum DoF gives the scaling
factor. In this correspondence, we analyse the DoF region and sum DoF for
unicast layered multi-hop relay wireless networks with arbitrary number of
source/destination/relay nodes, arbitrary number of hops and arbitrary number
of antennas at each node. The result is valid for quite a few message
topologies. We reveal the limitation on capacity of multi-hop network due to
the concatenation structure and show the similarity with capacitor network.
From the analysis on bound gap and optimality condition, the ultimate capacity
of multi-hop network is shown to be strictly inferior to that of single-hop
network. Linear scaling law can be established when the number of hops is
fixed. At cost of channel state information at transmitters (CSIT) for each
component single-hop network, our achievable scheme avoids routing and
simplifies scheduling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2301</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2301</id><created>2011-01-12</created><authors><author><keyname>Mehrmand</keyname><forenames>Arash</forenames></author><author><keyname>Feldt</keyname><forenames>Robert</forenames></author></authors><title>A Factorial Experiment on Scalability of Search Based Software Testing</title><categories>cs.SE cs.AI</categories><comments>3d Artificial Intelligence Techniques in Software Engineering
  Workshop, 7 October, 2010, Larnaca, Cyprus</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software testing is an expensive process, which is vital in the industry.
Construction of the test-data in software testing requires the major cost and
to decide which method to use in order to generate the test data is important.
This paper discusses the efficiency of search-based algorithms (preferably
genetic algorithm) versus random testing, in soft- ware test-data generation.
This study di?ers from all previous studies due to sample programs (SUTs) which
are used. Since we want to in- crease the complexity of SUTs gradually, and the
program generation is automatic as well, Grammatical Evolution is used to guide
the program generation. SUTs are generated according to the grammar we provide,
with di?erent levels of complexity. SUTs will first undergo genetic al- gorithm
and then random testing. Based on the test results, this paper recommends one
method to use for automation of software testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2312</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2312</id><created>2011-01-12</created><authors><author><keyname>Urban</keyname><forenames>Jan</forenames></author></authors><title>Automatic segmentation of HeLa cell images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the possibilities for segmentation of cells from their
background and each other in digital image were tested, combined and improoved.
Lot of images with young, adult and mixture cells were able to prove the
quality of described algorithms. Proper segmentation is one of the main task of
image analysis and steps order differ from work to work, depending on input
images. Reply for biologicaly given question was looking for in this work,
including filtration, details emphasizing, segmentation and sphericity
computing. Order of algorithms and way to searching for them was also
described. Some questions and ideas for further work were mentioned in the
conclusion part.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2317</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2317</id><created>2011-01-12</created><authors><author><keyname>Tanahashi</keyname><forenames>Makoto</forenames></author><author><keyname>Ochiai</keyname><forenames>Hideki</forenames></author></authors><title>A Generalized MMSE Detection with Reduced Complexity for Spatially
  Multiplexed MIMO Signals</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multiple-input multiple-output (MIMO) spatially multiplexing (SM) systems,
achievable error rate performance is determined by signal detection strategy.
The optimal maximum-likelihood detection (MLD) that exhaustively examines all
symbol candidates has exponential complexity and may not be applicable in many
practical systems. In this paper, we consider a generalized minimum mean square
error (MMSE) detection derived from conditional mean estimation, which in
principle behaves equivalently to MLD but also includes a linear MMSE detection
as a special case. Motivated by this fact, we propose a low-complexity
detection which significantly reduces the number of examined symbol candidates
without significant error rate performance degradation from MLD. Our approach
is to approximate the probability density function (pdf) of modulated symbols
that appears in the exact conditional mean expression such that the decision
metric can be cast into a partially closed form. It is found that uniform ring
approximation in combination with phase shift keying (PSK) and amplitude phase
shift keying (APSK) is promising, as it can achieve a performance even
comparable to MLD, while its complexity is linear when the number of transmit
antennas is two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2320</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2320</id><created>2011-01-12</created><authors><author><keyname>Belanche</keyname><forenames>L. A.</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>F. F.</forenames></author></authors><title>Review and Evaluation of Feature Selection Algorithms in Synthetic
  Problems</title><categories>cs.AI cs.LG</categories><comments>13 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main purpose of Feature Subset Selection is to find a reduced subset of
attributes from a data set described by a feature set. The task of a feature
selection algorithm (FSA) is to provide with a computational solution motivated
by a certain definition of relevance or by a reliable evaluation measure. In
this paper several fundamental algorithms are studied to assess their
performance in a controlled experimental scenario. A measure to evaluate FSAs
is devised that computes the degree of matching between the output given by a
FSA and the known optimal solutions. An extensive experimental study on
synthetic problems is carried out to assess the behaviour of the algorithms in
terms of solution accuracy and size as a function of the relevance,
irrelevance, redundancy and size of the data samples. The controlled
experimental conditions facilitate the derivation of better-supported and
meaningful conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2337</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2337</id><created>2011-01-12</created><authors><author><keyname>Fischer</keyname><forenames>Katharina</forenames></author></authors><title>Equilibria in Quitting Games - Basics</title><categories>math.PR cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quitting games are one of the simplest stochastic games in which at any stage
each player has only two possible actions, continue and quit. The game ends as
soon as at least one player chooses to quit. The players then receive a payoff,
which depends on the set of players that did choose to quit. If the game never
ends, the payoff to each player is zero. For analysis of quitting games the so
called one-step games are used. Important properties of the expected payoff and
of equilibria in one-step games are stated. Furthermore some relations between
equilibria in one-step games and equilibria in quitting games are considered.
This analysis of the structure of quitting games and the related one-step games
should provide a basis for an implementation of an algorithm that detect
equilibria in Quitting Games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2360</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2360</id><created>2011-01-12</created><authors><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Mitchell</keyname><forenames>Joseph S. B.</forenames></author><author><keyname>Schmidt</keyname><forenames>Christiane</forenames></author></authors><title>Minimum Covering with Travel Cost</title><categories>cs.DS cs.CG</categories><comments>17 pages, 12 figures; extended abstract appears in ISAAC 2009, full
  version to appear in Journal of Combinatorial Optimization</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a polygon and a visibility range, the Myopic Watchman Problem with
Discrete Vision (MWPDV) asks for a closed path P and a set of scan points S,
such that (i) every point of the polygon is within visibility range of a scan
point; and (ii) path length plus weighted sum of scan number along the tour is
minimized. Alternatively, the bicriteria problem (ii') aims at minimizing both
scan number and tour length. We consider both lawn mowing (in which tour and
scan points may leave P) and milling (in which tour, scan points and visibility
must stay within P) variants for the MWPDV; even for simple special cases,
these problems are NP-hard.
  We show that this problem is NP-hard, even for the special cases of
rectilinear polygons and L_\infty scan range 1, and negligible small travel
cost or negligible travel cost. For rectilinear MWPDV milling in grid polygons
we present a 2.5-approximation with unit scan range; this holds for the
bicriteria version, thus for any linear combination of travel cost and scan
cost. For grid polygons and circular unit scan range, we describe a bicriteria
4-approximation. These results serve as stepping stones for the general case of
circular scans with scan radius r and arbitrary polygons of feature size a, for
which we extend the underlying ideas to a pi(r/a}+(r+1)/2) bicriteria
approximation algorithm. Finally, we describe approximation schemes for MWPDV
lawn mowing and milling of grid polygons, for fixed ratio between scan cost and
travel cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2378</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2378</id><created>2011-01-12</created><authors><author><keyname>Selke</keyname><forenames>Joachim</forenames></author><author><keyname>Balke</keyname><forenames>Wolf-Tilo</forenames></author></authors><title>Extracting Features from Ratings: The Role of Factor Models</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performing effective preference-based data retrieval requires detailed and
preferentially meaningful structurized information about the current user as
well as the items under consideration. A common problem is that representations
of items often only consist of mere technical attributes, which do not resemble
human perception. This is particularly true for integral items such as movies
or songs. It is often claimed that meaningful item features could be extracted
from collaborative rating data, which is becoming available through social
networking services. However, there is only anecdotal evidence supporting this
claim; but if it is true, the extracted information could very valuable for
preference-based data retrieval. In this paper, we propose a methodology to
systematically check this common claim. We performed a preliminary
investigation on a large collection of movie ratings and present initial
evidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2389</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2389</id><created>2011-01-12</created><updated>2011-01-13</updated><authors><author><keyname>Basher</keyname><forenames>Uria</forenames></author><author><keyname>Shirazi</keyname><forenames>Avihay</forenames></author><author><keyname>Permuter</keyname><forenames>Haim</forenames></author></authors><title>Capacity Region of Finite State Multiple-Access Channel with Delayed
  State Information at the Transmitters</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single-letter characterization is provided for the capacity region of
finite-state multiple access channels. The channel state is a Markov process,
the transmitters have access to delayed state information, and channel state
information is available at the receiver. The delays of the channel state
information are assumed to be asymmetric at the transmitters. We apply the
result to obtain the capacity region for a finite-state Gaussian MAC, and for a
finite-state multiple-access fading channel. We derive power control strategies
that maximize the capacity region for these channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2395</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2395</id><created>2011-01-12</created><authors><author><keyname>Vabishchevich</keyname><forenames>Petr N.</forenames></author></authors><title>Domain decomposition schemes for evolutionary equations of first order
  with not self-adjoint operators</title><categories>cs.NA</categories><msc-class>65N06 65M06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domain decomposition methods are essential in solving applied problems on
parallel computer systems. For boundary value problems for evolutionary
equations the implicit schemes are in common use to solve problems at a new
time level employing iterative methods of domain decomposition. An alternative
approach is based on constructing iteration-free methods based on special
schemes of splitting into subdomains. Such regionally-additive schemes are
constructed using the general theory of additive operator-difference schemes.
There are employed the analogues of classical schemes of alternating direction
method, locally one-dimensional schemes, factorization methods, vector and
regularized additive schemes. The main results were obtained here for
time-dependent problems with self-adjoint elliptic operators of second order.
  The paper discusses the Cauchy problem for the first order evolutionary
equations with a nonnegative not self-adjoint operator in a finite-dimensional
Hilbert space. Based on the partition of unit, we have constructed the
operators of decomposition which preserve nonnegativity for the individual
operator terms of splitting. Unconditionally stable additive schemes of domain
decomposition were constructed using the regularization principle for
operator-difference schemes. Vector additive schemes were considered, too. The
results of our work are illustrated by a model problem for the two-dimensional
parabolic equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2405</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2405</id><created>2011-01-12</created><authors><author><keyname>Dan</keyname><forenames>Lilin</forenames></author><author><keyname>Xiao</keyname><forenames>Yue</forenames></author><author><keyname>NI</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Shaoqian</forenames></author></authors><title>Improved Peak Cancellation for PAPR Reduction in OFDM Systems</title><categories>cs.IT math.IT</categories><comments>11 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter presents an improved peak cancellation (PC) scheme for
peak-to-average power ratio (PAPR) reduction in orthogonal frequency division
multiplexing (OFDM) systems. The main idea is based on a serial peak
cancellation (SPC) mode for alleviating the peak regrowth of the conventional
schemes. Based on the SPC mode, two particular algorithms are developed with
different tradeoff between PAPR and computational complexity. Simulation shows
that the proposed scheme has a better tradeoff among PAPR, complexity and
signal distortion than the conventional schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2416</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2416</id><created>2011-01-12</created><updated>2011-01-14</updated><authors><author><keyname>Belabbas</keyname><forenames>M. -A.</forenames></author></authors><title>Decentralized Formation Control Part I: Geometric Aspects</title><categories>math.OC cs.MA cs.SY</categories><comments>Part 1 of 2 parts paper. Preprint. To be submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop new methods for the analysis of decentralized
control systems and we apply them to formation control problems. The basic
set-up consists of a system with multiple agents corresponding to the nodes of
a graph whose edges encode the information that is available to the agents. We
address the question of whether the information flow defined by the graph is
sufficient for the agents to accomplish a given task. Formation control is
concerned with problems in which agents are required to stabilize at a given
distance from other agents. In this context, the graph of a formation encodes
both the information flow and the distance constraints, by fixing the lengths
of the edges. A formation is said to be rigid if it cannot be continuously
deformed with the distance constraints satisfied; a formation is minimally
rigid if no distance constraint can be omitted without the formation losing its
rigidity. Hence, the graph underlying minimally rigid formation provides just
enough constraints to yield a rigid formation. An open question we will settle
is whether the information flow afforded by a minimally rigid graph is
sufficient to insure global stability. We show that the answer is negative in
the case of directed information flow. In this first part, we establish basic
properties of formation control in the plane. Formations and the associated
control problems are defined modulo rigid transformations. This fact has strong
implications on the geometry of the space of formations and on the feedback
laws, since they need to respect this invariance. We study both aspects here.
We show that the space of frameworks of n agents is CP(n-2) x (0,\infty). We
then illustrate how the non-trivial topology of this space relates to the
parametrization of the formation by inter-agent distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2421</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2421</id><created>2011-01-12</created><updated>2011-01-14</updated><authors><author><keyname>Belabbas</keyname><forenames>M. -A.</forenames></author></authors><title>Decentralized Formation Control Part II: Algebraic aspects of
  information flow and singularities</title><categories>math.OC cs.MA cs.SY</categories><comments>Part 2 of a 2 parts paper. Preprint. To be submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an ensemble of autonomous agents and a task to achieve cooperatively,
how much do the agents need to know about the state of the ensemble and about
the task in order to achieve it? We introduce new methods to understand these
aspects of decentralized control. Precisely, we introduce a framework to
capture what agents with partial information can achieve by cooperating and
illustrate its use by deriving results about global stabilization of directed
formations. This framework underscores the need to differentiate the knowledge
an agent has about the task to accomplish from the knowledge an agent has about
the current state of the system. The control of directed formations has proven
to be more difficult than initially thought, as is exemplified by the lack of
global result for formations with n \geq 4 agents. We established in part I
that the space of planar formations has a non-trivial global topology. We
propose here an extension of the notion of global stability which, because it
acknowledges this non-trivial topology, can be applied to the study of
formation control. We then develop a framework that reduces the question of
whether feedback with partial information can stabilize the system to whether
two sets of functions intersect. We apply this framework to the study of a
directed formation with n = 4 agents and show that the agents do not have
enough information to implement locally stabilizing feedback laws.
Additionally, we show that feedback laws that respect the information flow
cannot stabilize a target configuration without stabilizing other, unwanted
configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2427</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2427</id><created>2011-01-12</created><authors><author><keyname>Valle</keyname><forenames>Eduardo</forenames></author><author><keyname>de Avila</keyname><forenames>Sandra</forenames></author><author><keyname>Luz</keyname><forenames>Antonio da</forenames><suffix>Jr.</suffix></author><author><keyname>de Souza</keyname><forenames>Fillipe</forenames></author><author><keyname>Coelho</keyname><forenames>Marcelo</forenames></author><author><keyname>Ara&#xfa;jo</keyname><forenames>Arnaldo</forenames></author></authors><title>Content-Based Filtering for Video Sharing Social Networks</title><categories>cs.CV cs.SI</categories><acm-class>I.5.4; I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we compare the use of several features in the task of content
filtering for video social networks, a very challenging task, not only because
the unwanted content is related to very high-level semantic concepts (e.g.,
pornography, violence, etc.) but also because videos from social networks are
extremely assorted, preventing the use of constrained a priori information. We
propose a simple method, able to combine diverse evidence, coming from
different features and various video elements (entire video, shots, frames,
keyframes, etc.). We evaluate our method in three social network applications,
related to the detection of unwanted content - pornographic videos, violent
videos, and videos posted to artificially manipulate popularity scores. Using
challenging test databases, we show that this simple scheme is able to obtain
good results, provided that adequate features are chosen. Moreover, we
establish a representation using codebooks of spatiotemporal local descriptors
as critical to the success of the method in all three contexts. This is
consequential, since the state-of-the-art still relies heavily on static
features for the tasks addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2428</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2428</id><created>2011-01-12</created><authors><author><keyname>Ardila</keyname><forenames>Federico</forenames></author><author><keyname>Owen</keyname><forenames>Megan</forenames></author><author><keyname>Sullivant</keyname><forenames>Seth</forenames></author></authors><title>Geodesics in CAT(0) Cubical Complexes</title><categories>math.CO cs.CG cs.DM math.MG</categories><comments>27 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm to compute the geodesics in an arbitrary CAT(0)
cubical complex. A key tool is a correspondence between cubical complexes of
global non-positive curvature and posets with inconsistent pairs. This
correspondence also gives an explicit realization of such a complex as the
state complex of a reconfigurable system, and a way to embed any interval in
the integer lattice cubing of its dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2435</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2435</id><created>2011-01-12</created><updated>2012-01-30</updated><authors><author><keyname>Zlatic</keyname><forenames>Vinko</forenames></author><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author><author><keyname>Caldarelli</keyname><forenames>Guido</forenames></author></authors><title>Networks with arbitrary edge multiplicities</title><categories>physics.soc-ph cs.SI physics.data-an</categories><journal-ref>EPL 97, 28005 (2012)</journal-ref><doi>10.1209/0295-5075/97/28005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main characteristics of real-world networks is their large
clustering. Clustering is one aspect of a more general but much less studied
structural organization of networks, i.e. edge multiplicity, defined as the
number of triangles in which edges, rather than vertices, participate. Here we
show that the multiplicity distribution of real networks is in many cases
scale-free, and in general very broad. Thus, besides the fact that in real
networks the number of edges attached to vertices often has a scale-free
distribution, we find that the number of triangles attached to edges can have a
scale-free distribution as well. We show that current models, even when they
generate clustered networks, systematically fail to reproduce the observed
multiplicity distributions. We therefore propose a generalized model that can
reproduce networks with arbitrary distributions of vertex degrees and edge
multiplicities, and study many of its properties analytically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2478</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2478</id><created>2011-01-12</created><updated>2011-01-13</updated><authors><author><keyname>Li</keyname><forenames>Chih-ping</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Delay and Power-Optimal Control in Multi-Class Queueing Systems</title><categories>math.OC cs.SY</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider optimizing average queueing delay and average power consumption
in a nonpreemptive multi-class M/G/1 queue with dynamic power control that
affects instantaneous service rates. Four problems are studied: (1) satisfying
per-class average delay constraints; (2) minimizing a separable convex function
of average delays subject to per-class delay constraints; (3) minimizing
average power consumption subject to per-class delay constraints; (4)
minimizing a separable convex function of average delays subject to an average
power constraint. Combining an achievable region approach in queueing systems
and the Lyapunov optimization theory suitable for optimizing dynamic systems
with time average constraints, we propose a unified framework to solve the
above problems. The solutions are variants of dynamic $c\mu$ rules, and
implement weighted priority policies in every busy period, where weights are
determined by past queueing delays in all job classes. Our solutions require
limited statistical knowledge of arrivals and service times, and no statistical
knowledge is needed in the first problem. Overall, we provide a new set of
tools for stochastic optimization and control over multi-class queueing systems
with time average constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2483</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2483</id><created>2011-01-12</created><updated>2011-02-06</updated><authors><author><keyname>Razaghi</keyname><forenames>Peyman</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>On Achievability of Gaussian Interference Channel Capacity to within One
  Bit</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors due to a flaw in the
  argument as described in the updated abstract</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the earlier version of this paper, it was wrongly claimed that
time-sharing is required to achieve the capacity region of the Gaussian
interference channel to within one bit, especially at corner points. The flaw
in the argument of the earlier version lies in fixing the decoding paradigm for
a fixed common/private message splitting encoding strategy. More specifically,
the additional constraints (7b) and (7d) in the earlier version arise if we
force the common messages to be always decoded at unintended receivers.
However, (7b) and (7d) can be eliminated by allowing the decoders to ignore
unintended common messages, particularly at corner points of the rate region,
without resorting to time-sharing at the transmit side, as suggested in the
earlier version. For these reasons, our earlier claim is invalid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2491</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2491</id><created>2011-01-12</created><authors><author><keyname>Dongre</keyname><forenames>V J</forenames></author><author><keyname>Mankar</keyname><forenames>V H</forenames></author></authors><title>A Review of Research on Devnagari Character Recognition</title><categories>cs.CV</categories><comments>8 pages, 1 Figure, 8 Tables, Journal paper</comments><journal-ref>International Journal of Computer Applications (0975 - 8887)
  Volume 12- No.2, November 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  English Character Recognition (CR) has been extensively studied in the last
half century and progressed to a level, sufficient to produce technology driven
applications. But same is not the case for Indian languages which are
complicated in terms of structure and computations. Rapidly growing
computational power may enable the implementation of Indic CR methodologies.
Digital document processing is gaining popularity for application to office and
library automation, bank and postal services, publishing houses and
communication technology. Devnagari being the national language of India,
spoken by more than 500 million people, should be given special attention so
that document retrieval and analysis of rich ancient and modern Indian
literature can be effectively done. This article is intended to serve as a
guide and update for the readers, working in the Devnagari Optical Character
Recognition (DOCR) area. An overview of DOCR systems is presented and the
available DOCR techniques are reviewed. The current status of DOCR is discussed
and directions for future research are suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2516</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2516</id><created>2011-01-13</created><authors><author><keyname>Karmakar</keyname><forenames>Sanjay</forenames></author><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Maximum Rate of Unitary-Weight, Single-Symbol Decodable STBCs</title><categories>cs.IT math.IT</categories><comments>accepted for publication in the IEEE Transactions on Information
  Theory, 9 pages, 1 figure, 1 Table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the Space-time Block Codes (STBCs) from Complex
orthogonal designs (CODs) are single-symbol decodable/symbol-by-symbol
decodable (SSD). The weight matrices of the square CODs are all unitary and
obtainable from the unitary matrix representations of Clifford Algebras when
the number of transmit antennas $n$ is a power of 2. The rate of the square
CODs for $n = 2^a$ has been shown to be $\frac{a+1}{2^a}$ complex symbols per
channel use. However, SSD codes having unitary-weight matrices need not be
CODs, an example being the Minimum-Decoding-Complexity STBCs from
Quasi-Orthogonal Designs. In this paper, an achievable upper bound on the rate
of any unitary-weight SSD code is derived to be $\frac{a}{2^{a-1}}$ complex
symbols per channel use for $2^a$ antennas, and this upper bound is larger than
that of the CODs. By way of code construction, the interrelationship between
the weight matrices of unitary-weight SSD codes is studied. Also, the coding
gain of all unitary-weight SSD codes is proved to be the same for QAM
constellations and conditions that are necessary for unitary-weight SSD codes
to achieve full transmit diversity and optimum coding gain are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2524</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2524</id><created>2011-01-13</created><updated>2011-04-01</updated><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Generalized Silver Codes</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in the IEEE Transactions on Information
  Theory. This revised version has 30 pages, 7 figures and Section III has been
  completely revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an $n_t$ transmit, $n_r$ receive antenna system ($n_t \times n_r$
system), a {\it{full-rate}} space time block code (STBC) transmits $n_{min} =
min(n_t,n_r)$ complex symbols per channel use. The well known Golden code is an
example of a full-rate, full-diversity STBC for 2 transmit antennas. Its
ML-decoding complexity is of the order of $M^{2.5}$ for square $M$-QAM. The
Silver code for 2 transmit antennas has all the desirable properties of the
Golden code except its coding gain, but offers lower ML-decoding complexity of
the order of $M^2$. Importantly, the slight loss in coding gain is negligible
compared to the advantage it offers in terms of lowering the ML-decoding
complexity. For higher number of transmit antennas, the best known codes are
the Perfect codes, which are full-rate, full-diversity, information lossless
codes (for $n_r \geq n_t$) but have a high ML-decoding complexity of the order
of $M^{n_tn_{min}}$ (for $n_r &lt; n_t$, the punctured Perfect codes are
considered). In this paper, a scheme to obtain full-rate STBCs for $2^a$
transmit antennas and any $n_r$ with reduced ML-decoding complexity of the
order of $M^{n_t(n_{min}-(3/4))-0.5}$, is presented. The codes constructed are
also information lossless for $n_r \geq n_t$, like the Perfect codes and allow
higher mutual information than the comparable punctured Perfect codes for $n_r
&lt; n_t$. These codes are referred to as the {\it generalized Silver codes},
since they enjoy the same desirable properties as the comparable Perfect codes
(except possibly the coding gain) with lower ML-decoding complexity, analogous
to the Silver-Golden codes for 2 transmit antennas. Simulation results of the
symbol error rates for 4 and 8 transmit antennas show that the generalized
Silver codes match the punctured Perfect codes in error performance while
offering lower ML-decoding complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2533</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2533</id><created>2011-01-13</created><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Low ML-decoding Complexity, Full-diversity, Full-rate MIMO Precoder</title><categories>cs.IT math.IT</categories><comments>33 pages, 7 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precoding for multiple-input, multiple-output (MIMO) antenna systems is
considered with perfect channel knowledge available at both the transmitter and
the receiver. For 2 transmit antennas and QAM constellations, an approximately
optimal (with respect to the minimum Euclidean distance between points in the
received signal space) real-valued precoder based on the singular value
decomposition (SVD) of the channel is proposed, and it is shown to offer a
maximum-likelihood (ML)-decoding complexity of $\mathcal{O}(\sqrt{M})$ for
square $M$-QAM. The proposed precoder is obtainable easily for arbitrary QAM
constellations, unlike the known complex-valued optimal precoder by Collin et
al. for 2 transmit antennas, which is in existence for 4-QAM alone with an
ML-decoding complexity of $\mathcal{O}(M\sqrt{M})$ (M=4) and is extremely hard
to obtain for larger QAM constellations. The proposed precoder's loss in error
performance for 4-QAM in comparison with the complex-valued optimal precoder is
only marginal. Our precoding scheme is extended to higher number of transmit
antennas on the lines of the E-$d_{min}$ precoder for 4-QAM by Vrigneau et al.
which is an extension of the complex-valued optimal precoder for 4-QAM.
Compared with the recently proposed $X-$ and $Y-$precoders, the error
performance of our precoder is significantly better. It is shown that our
precoder provides full-diversity for QAM constellations and this is supported
by simulation plots of the word error probability for $2\times2$, $4\times4$
and $8\times8$ systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2549</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2549</id><created>2011-01-13</created><authors><author><keyname>Guly&#xe1;s</keyname><forenames>L&#xe1;szl&#xf3;</forenames></author><author><keyname>Horv&#xe1;th</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Cs&#xe9;ri</keyname><forenames>Tam&#xe1;s</forenames></author><author><keyname>Kampis</keyname><forenames>George</forenames></author></authors><title>An Estimation of the Shortest and Largest Average Path Length in Graphs
  of Given Density</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real world networks (graphs) are observed to be 'small worlds', i.e.,
the average path length among nodes is small. On the other hand, it is somewhat
unclear what other average path length values networks can produce. In
particular, it is not known what the maximum and the minimum average path
length values are. In this paper we provide a lower estimation for the shortest
average path length (l) values in connected networks, and the largest possible
average path length values in networks with given size and density. To the
latter end, we construct a special family of graphs and calculate their average
path lengths. We also demonstrate the correctness of our estimation by
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2569</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2569</id><created>2011-01-13</created><authors><author><keyname>Simoens</keyname><forenames>Koen</forenames></author><author><keyname>Bringer</keyname><forenames>Julien</forenames></author><author><keyname>Chabanne</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Seys</keyname><forenames>Stefaan</forenames></author></authors><title>Analysis of Biometric Authentication Protocols in the Blackbox Model</title><categories>cs.CR</categories><comments>10 pages, 1 figures, submitted to IEEE Transactions on Information
  Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyze different biometric authentication protocols
considering an internal adversary. Our contribution takes place at two levels.
On the one hand, we introduce a new comprehensive framework that encompasses
the various schemes we want to look at. On the other hand, we exhibit actual
attacks on recent schemes such as those introduced at ACISP 2007, ACISP 2008,
and SPIE 2010, and some others. We follow a blackbox approach in which we
consider components that perform operations on the biometric data they contain
and where only the input/output behavior of these components is analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2573</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2573</id><created>2011-01-13</created><authors><author><keyname>Bansal</keyname><forenames>Sanjay</forenames></author><author><keyname>Pandey</keyname><forenames>Nirved</forenames></author></authors><title>An Overview of Portable Distributed Techniques</title><categories>cs.DC</categories><comments>International Journal of Computer Science Issues online at
  http://www.ijcsi.org</comments><journal-ref>IJCSI, Volume 7, Issue 3, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we reviewed of several portable parallel programming paradigms
for use in a distributed programming environment. The Techniques reviewed here
are portable. These are mainly distributing computing using MPI pure java
based, MPI native java based (JNI) and PVM. We will discuss architecture and
utilities of each technique based on our literature review. We explored these
portable distributed techniques in four important characteristics scalability,
fault tolerance, load balancing and performance. We have identified the various
factors and issues for improving these four important characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2575</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2575</id><created>2011-01-11</created><authors><author><keyname>Agrell</keyname><forenames>Erik</forenames></author></authors><title>Errata list for &quot;Error Control Coding&quot; by Lin and Costello</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This documents lists some errors found in the second edition of Error Control
Coding by Shu Lin and Daniel J. Costello.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2577</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2577</id><created>2011-01-13</created><authors><author><keyname>Prabhu</keyname><forenames>D.</forenames><affiliation>Dept of Information Technology, Mailam Engineering College, Mailam</affiliation></author><author><keyname>Adimoolam</keyname><forenames>M.</forenames><affiliation>Lecturer, Dept of Information Technology, Christ College of Engineering and Technology</affiliation></author></authors><title>Bi-serial DNA Encryption Algorithm(BDEA)</title><categories>cs.CR math.NT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vast parallelism, exceptional energy efficiency and extraordinary
information inherent in DNA molecules are being explored for computing, data
storage and cryptography. DNA cryptography is a emerging field of cryptography.
In this paper a novel encryption algorithm is devised based on number
conversion, DNA digital coding, PCR amplification, which can effectively
prevent attack. Data treatment is used to transform the plain text into cipher
text which provides excellent security
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2591</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2591</id><created>2011-01-13</created><authors><author><keyname>Heimeriks</keyname><forenames>Gaston</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Emerging Search Regimes: Measuring Co-evolutions among Research,
  Science, and Society</title><categories>nlin.AO cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scientometric data is used to investigate empirically the emergence of search
regimes in Biotechnology, Genomics, and Nanotechnology. Complex regimes can
emerge when three independent sources of variance interact. In our model,
researchers can be considered as the nodes that carry the science system.
Research is geographically situated with site-specific skills, tacit knowledge
and infrastructures. Second, the emergent science level refers to the formal
communication of codified knowledge published in journals. Third, the
socio-economic dynamics indicate the ways in which knowledge production relates
to society. Although Biotechnology, Genomics, and Nanotechnology can all be
characterised by rapid growth and divergent dynamics, the regimes differ in
terms of self-organization among these three sources of variance. The scope of
opportunities for researchers to contribute within the constraints of the
existing body of knowledge are different in each field. Furthermore, the
relevance of the context of application contributes to the knowledge dynamics
to various degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2604</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2604</id><created>2011-01-13</created><updated>2011-06-20</updated><authors><author><keyname>Li</keyname><forenames>Ninghui</forenames></author><author><keyname>Qardaji</keyname><forenames>Wahbeh</forenames></author><author><keyname>Su</keyname><forenames>Dong</forenames></author></authors><title>On Sampling, Anonymization, and Differential Privacy: Or,
  k-Anonymization Meets Differential Privacy</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims at answering the following two questions in
privacy-preserving data analysis and publishing: What formal privacy guarantee
(if any) does $k$-anonymization provide? How to benefit from the adversary's
uncertainty about the data? We have found that random sampling provides a
connection that helps answer these two questions, as sampling can create
uncertainty. The main result of the paper is that $k$-anonymization, when done
&quot;safely&quot;, and when preceded with a random sampling step, satisfies
$(\epsilon,\delta)$-differential privacy with reasonable parameters. This
result illustrates that &quot;hiding in a crowd of $k$&quot; indeed offers some privacy
guarantees. This result also suggests an alternative approach to output
perturbation for satisfying differential privacy: namely, adding a random
sampling step in the beginning and pruning results that are too sensitive to
change of a single tuple. Regarding the second question, we provide both
positive and negative results. On the positive side, we show that adding a
random-sampling pre-processing step to a differentially-private algorithm can
greatly amplify the level of privacy protection. Hence, when given a dataset
resulted from sampling, one can utilize a much large privacy budget. On the
negative side, any privacy notion that takes advantage of the adversary's
uncertainty likely does not compose. We discuss what these results imply in
practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2613</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2613</id><created>2011-01-13</created><updated>2011-05-05</updated><authors><author><keyname>Bernecker</keyname><forenames>Thomas</forenames></author><author><keyname>Emrich</keyname><forenames>Tobias</forenames></author><author><keyname>Kriegel</keyname><forenames>Hans-Peter</forenames></author><author><keyname>Mamoulis</keyname><forenames>Nikos</forenames></author><author><keyname>Renz</keyname><forenames>Matthias</forenames></author><author><keyname>Zuefle</keyname><forenames>Andreas</forenames></author></authors><title>A Novel Probabilistic Pruning Approach to Speed Up Similarity Queries in
  Uncertain Databases</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel, effective and efficient probabilistic
pruning criterion for probabilistic similarity queries on uncertain data. Our
approach supports a general uncertainty model using continuous probabilistic
density functions to describe the (possibly correlated) uncertain attributes of
objects. In a nutshell, the problem to be solved is to compute the PDF of the
random variable denoted by the probabilistic domination count: Given an
uncertain database object B, an uncertain reference object R and a set D of
uncertain database objects in a multi-dimensional space, the probabilistic
domination count denotes the number of uncertain objects in D that are closer
to R than B. This domination count can be used to answer a wide range of
probabilistic similarity queries. Specifically, we propose a novel geometric
pruning filter and introduce an iterative filter-refinement strategy for
conservatively and progressively estimating the probabilistic domination count
in an efficient way while keeping correctness according to the possible world
semantics. In an experimental evaluation, we show that our proposed technique
allows to acquire tight probability bounds for the probabilistic domination
count quickly, even for large uncertain databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2619</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2619</id><created>2011-01-13</created><authors><author><keyname>Walters</keyname><forenames>Mark</forenames></author></authors><title>Small components in k-nearest neighbour graphs</title><categories>math.PR cs.CG math.CO</categories><comments>15 pages, 2 figures</comments><msc-class>60K35, 82B43</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G=G_{n,k}$ denote the graph formed by placing points in a square of area
$n$ according to a Poisson process of density 1 and joining each point to its
$k$ nearest neighbours. Balister, Bollob\'as, Sarkar and Walters proved that if
$k&lt;0.3043\log n$ then the probability that $G$ is connected tends to 0, whereas
if $k&gt;0.5139\log n$ then the probability that $G$ is connected tends to 1.
  We prove that, around the threshold for connectivity, all vertices near the
boundary of the square are part of the (unique) giant component. This shows
that arguments about the connectivity of $G$ do not need to consider `boundary'
effects.
  We also improve the upper bound for the threshold for connectivity of $G$ to
$k=0.4125\log n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2637</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2637</id><created>2011-01-13</created><authors><author><keyname>Datta</keyname><forenames>Samir</forenames></author><author><keyname>Prakriya</keyname><forenames>Gautam</forenames></author></authors><title>Planarity Testing Revisited</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planarity Testing is the problem of determining whether a given graph is
planar while planar embedding is the corresponding construction problem. The
bounded space complexity of these problems has been determined to be exactly
Logspace by Allender and Mahajan with the aid of Reingold's result.
Unfortunately, the algorithm is quite daunting and generalizing it to say, the
bounded genus case seems a tall order.
  In this work, we present a simple planar embedding algorithm running in
logspace. We hope this algorithm will be more amenable to generalization. The
algorithm is based on the fact that 3-connected planar graphs have a unique
embedding, a variant of Tutte's criterion on conflict graphs of cycles and an
explicit change of cycle basis.% for planar graphs.
  We also present a logspace algorithm to find obstacles to planarity, viz. a
Kuratowski minor, if the graph is non-planar. To the best of our knowledge this
is the first logspace algorithm for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2642</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2642</id><created>2011-01-13</created><authors><author><keyname>Bastani</keyname><forenames>Osbert</forenames></author><author><keyname>Hillar</keyname><forenames>Christopher J.</forenames></author><author><keyname>Popov</keyname><forenames>Dimitar</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author></authors><title>Randomization, Sums of Squares, and Faster Real Root Counting for
  Tetranomials and Beyond</title><categories>math.AG cs.CC</categories><comments>20 pages, 5 figures, submitted to a refereed conference proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose f is a real univariate polynomial of degree D with exactly 4 monomial
terms. We present an algorithm, with complexity polynomial in log D on average
(relative to the stable log-uniform measure), for counting the number of real
roots of f. The best previous algorithms had complexity super-linear in D. We
also discuss connections to sums of squares and A-discriminants, including
explicit obstructions to expressing positive definite sparse polynomials as
sums of squares of few sparse polynomials. Our key tool is the introduction of
efficiently computable chamber cones, bounding regions in coefficient space
where the number of real roots of f can be computed easily. Much of our theory
extends to n-variate (n+3)-nomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2678</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2678</id><created>2011-01-13</created><authors><author><keyname>Cecilia</keyname><forenames>Jose M.</forenames></author><author><keyname>Garcia</keyname><forenames>Jose M.</forenames></author><author><keyname>Ujaldon</keyname><forenames>Manuel</forenames></author><author><keyname>Nisbet</keyname><forenames>Andy</forenames></author><author><keyname>Amos</keyname><forenames>Martyn</forenames></author></authors><title>Parallelization Strategies for Ant Colony Optimisation on GPUs</title><categories>cs.DC cs.MA</categories><comments>Accepted by 14th International Workshop on Nature Inspired
  Distributed Computing (NIDISC 2011), held in conjunction with the 25th
  IEEE/ACM International Parallel and Distributed Processing Symposium (IPDPS
  2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ant Colony Optimisation (ACO) is an effective population-based meta-heuristic
for the solution of a wide variety of problems. As a population-based
algorithm, its computation is intrinsically massively parallel, and it is
there- fore theoretically well-suited for implementation on Graphics Processing
Units (GPUs). The ACO algorithm comprises two main stages: Tour construction
and Pheromone update. The former has been previously implemented on the GPU,
using a task-based parallelism approach. However, up until now, the latter has
always been implemented on the CPU. In this paper, we discuss several
parallelisation strategies for both stages of the ACO algorithm on the GPU. We
propose an alternative data-based parallelism scheme for Tour construction,
which fits better on the GPU architecture. We also describe novel GPU
programming strategies for the Pheromone update stage. Our results show a total
speed-up exceeding 28x for the Tour construction stage, and 20x for Pheromone
update, and suggest that ACO is a potentially fruitful area for future research
in the GPU domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2705</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2705</id><created>2011-01-13</created><authors><author><keyname>Wehr</keyname><forenames>Dustin</forenames></author></authors><title>Lower bound for deterministic semantic-incremental branching programs
  solving GEN</title><categories>cs.CC</categories><comments>9 pages</comments><msc-class>68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We answer a problem posed in (G\'al, Kouck\'y, McKenzie 2008) regarding a
restricted model of small-space computation, tailored for solving the GEN
problem. They define two variants of &quot;incremental branching programs&quot;, the
syntactic variant defined by a restriction on the graph-theoretic paths in the
program, and the more-general semantic variant in which the same restriction is
enforced only on the consistent paths - those that are followed by at least one
input. They show that exponential size is required for the syntactic variant,
but leave open the problem of superpolynomial lower bounds for the semantic
variant. Here we give an exponential lower bound for the semantic variant by
generalizing lower bound arguments, from earlier work, for a similar restricted
model tailored for solving a special case of GEN called Tree Evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2711</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2711</id><created>2011-01-13</created><authors><author><keyname>Romero-Torres</keyname><forenames>Mauricio</forenames></author><author><keyname>Tejada</keyname><forenames>Maria Alejandra</forenames></author><author><keyname>Acosta</keyname><forenames>Alberto</forenames></author></authors><title>A Proposal to Classify Latinamerican Scientific Journals using Citation
  Indicators: Case Study in Colombia</title><categories>cs.DL</categories><comments>27 pages, 8 tables</comments><msc-class>68</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colombian scientific journals are poorly represented in international digital
libraries; however, through Google Scholar (GS) it is possible to determine
their use by the community. Between the years of 2003 and 2007 a classification
of 185 Colombian journals indexed in the Colombian National Bibliographical
Index (IBNP) was performed using the information provided by GS, basing
categorization on size indicators, indexation and citation. The indicators were
analyzed by grouping the journals in two general areas: sciences and social
sciences. In each area, the indicators provided by the digital libraries
Scopus, Redalyc and Scielo were compared. Additionally, the indicators provided
by IBNP journals categories (A1, A2, B and C) were also compared. The sciences
and social sciences had a similar pattern in their indicators. The existence of
positive correlations was established between some indicators and they
predicted that the number of citations per journal in GS and the h index
depends on its visibility in GS and Scopus. We put forward that the current
IBNP categories (A1, A2, B or C) faintly reflect the use of journals by the
community and we propose a classification based on the h index as an infometric
indicator, which reflects not only its visibility in Google Scholar, but also
its inclusion in certain international digital libraries, particularly Scopus.
Our results may be applied to the creation of public policies regarding science
and technology in Colombia and in developing countries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2713</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2713</id><created>2011-01-13</created><updated>2012-07-12</updated><authors><author><keyname>Eftekhari</keyname><forenames>Armin</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author><author><keyname>Wakin</keyname><forenames>Michael B.</forenames></author></authors><title>Matched Filtering from Limited Frequency Samples</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory on January
  13, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study a simple correlation-based strategy for estimating
the unknown delay and amplitude of a signal based on a small number of noisy,
randomly chosen frequency-domain samples. We model the output of this
&quot;compressive matched filter&quot; as a random process whose mean equals the scaled,
shifted autocorrelation function of the template signal. Using tools from the
theory of empirical processes, we prove that the expected maximum deviation of
this process from its mean decreases sharply as the number of measurements
increases, and we also derive a probabilistic tail bound on the maximum
deviation. Putting all of this together, we bound the minimum number of
measurements required to guarantee that the empirical maximum of this random
process occurs sufficiently close to the true peak of its mean function. We
conclude that for broad classes of signals, this compressive matched filter
will successfully estimate the unknown delay (with high probability, and within
a prescribed tolerance) using a number of random frequency-domain samples that
scales inversely with the signal-to-noise ratio and only logarithmically in the
in the observation bandwidth and the possible range of delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2715</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2715</id><created>2011-01-13</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Novel Mechanism for Detection of Distributed Denial of Service Attacks</title><categories>cs.NI</categories><comments>11 pages, 5 tables. In Proceedings of the First International
  Conference on Computer Science and Information Technology (CCSIT 2011).
  Springer CCIS Series Vol 133, Advanced Computing, Part 3, pp. 247-257,
  Bangalore, 2011, India</comments><doi>10.1007/978-3-642-17881-8_24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing popularity of web-based applications has led to several
critical services being provided over the Internet. This has made it imperative
to monitor the network traffic so as to prevent malicious attackers from
depleting the resources of the network and denying services to legitimate
users. This paper has presented a mechanism for protecting a web-server against
a distributed denial of service (DDoS) attack. Incoming traffic to the server
is continuously monitored and any abnormal rise in the inbound traffic is
immediately detected. The detection algorithm is based on a statistical
analysis of the inbound traffic on the server and a robust hypothesis testing
framework. While the detection process is on, the sessions from the legitimate
sources are not disrupted and the load on the server is restored to the normal
level by blocking the traffic from the attacking sources. To cater to different
scenarios, the detection algorithm has various modules with varying level of
computational and memory overheads for their execution. While the approximate
modules are fast in detection and involve less overhead, they have lower
detection accuracy. The accurate modules involve complex detection logic and
hence involve more overhead for their execution, but they have very high
detection accuracy. Simulations carried out on the proposed mechanism have
produced results that demonstrate effectiveness of the scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2717</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2717</id><created>2011-01-14</created><authors><author><keyname>Bhaumik</keyname><forenames>Sourjya</forenames></author><author><keyname>Chuck</keyname><forenames>David</forenames></author><author><keyname>Narlikar</keyname><forenames>Girija</forenames></author><author><keyname>Wilfong</keyname><forenames>Gordon</forenames></author></authors><title>Energy-Efficient Design and Optimization of Wireline Access Networks</title><categories>cs.NI</categories><comments>Techinal Report of the paper accepted in INFOCOM Mini Conference 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Access networks, in particular, Digital Subscriber Line (DSL) equipment, are
a significant source of energy consumption for wireline operators. Replacing
large monolithic DSLAMs with smaller remote DSLAM units closer to customers can
reduce the energy consumption as well as increase the reach of the access
network. This paper attempts to formalize the design and optimization of the
&quot;last mile&quot; wireline access network with energy as one of the costs to be
minimized. In particular, the placement of remote DSLAM units needs to be
optimized. We propose solutions for two scenarios. For the scenario where an
existing all-copper network from the central office to the customers is to be
transformed into a fiber-copper network with remote DSLAM units, we present
optimal polynomial-time solutions. In the green-field scenario, both the access
network layout and the placement of remote DSLAM units must be determined. We
show that this problem is NP-complete. We present an optimal ILP formulation
and also design an efficient heuristic-based approach to build a
power-and-cost-optimized access network. Our heuristic-based approach yields
results that are very close to optimal. We show how the power consumption of
the access network can be reduced by carefully laying the access network and
introducing remote DSLAM units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2719</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2719</id><created>2011-01-14</created><authors><author><keyname>Yu</keyname><forenames>Yao</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>CSSF MIMO RADAR: Low-Complexity Compressive Sensing Based MIMO Radar
  That Uses Step Frequency</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach is proposed, namely CSSF MIMO radar, which applies the
technique of step frequency (SF) to compressive sensing (CS) based multi-input
multi-output (MIMO) radar. The proposed approach enables high resolution range,
angle and Doppler estimation, while transmitting narrowband pulses. The problem
of joint angle-Doppler-range estimation is first formulated to fit the CS
framework, i.e., as an L1 optimization problem. Direct solution of this problem
entails high complexity as it employs a basis matrix whose construction
requires discretization of the angle-Doppler-range space. Since high resolution
requires fine space discretization, the complexity of joint range, angle and
Doppler estimation can be prohibitively high. For the case of slowly moving
targets, a technique is proposed that achieves significant complexity reduction
by successively estimating angle-range and Doppler in a decoupled fashion and
by employing initial estimates obtained via matched filtering to further reduce
the space that needs to be digitized. Numerical results show that the
combination of CS and SF results in a MIMO radar system that has superior
resolution and requires far less data as compared to a system that uses a
matched filter with SF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2721</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2721</id><created>2011-01-14</created><updated>2011-01-25</updated><authors><author><keyname>Zakhour</keyname><forenames>Randa</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Optimized data sharing in multicell MIMO with finite backhaul capacity</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2011.2165949</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses cooperation in a multicell environment where base
stations (BSs) wish to jointly serve multiple users, under a
constrained-capacity backhaul. We point out that for finite backhaul capacity a
trade-off between sharing user data, which allows for full MIMO cooperation,
and not doing so, which reduces the setup to an interference channel but also
requires less overhead, emerges. We optimize this trade-off by formulating a
rate splitting approach in which non-shared data (private to each transmitter)
and shared data are superposed. We derive the corresponding achievable rate
region and obtain the optimal beamforming design for both shared and private
symbols. We show how the capacity of the backhaul can be used to determine how
much of the user data is worth sharing across multiple BSs, particularly
depending on how strong the interference is.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2728</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2728</id><created>2011-01-14</created><authors><author><keyname>Dau</keyname><forenames>Son Hoang</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author></authors><title>Index Coding and Error Correction</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A problem of index coding with side information was first considered by Y.
Birk and T. Kol (IEEE INFOCOM, 1998). In the present work, a generalization of
index coding scheme, where transmitted symbols are subject to errors, is
studied. Error-correcting methods for such a scheme, and their parameters, are
investigated. In particular, the following question is discussed: given the
side information hypergraph of index coding scheme and the maximal number of
erroneous symbols $\delta$, what is the shortest length of a linear index code,
such that every receiver is able to recover the required information? This
question turns out to be a generalization of the problem of finding a
shortest-length error-correcting code with a prescribed error-correcting
capability in the classical coding theory. The Singleton bound and two other
bounds, referred to as the $\alpha$-bound and the $\kappa$-bound, for the
optimal length of a linear error-correcting index code (ECIC) are established.
For large alphabets, a construction based on concatenation of an optimal index
code with an MDS classical code, is shown to attain the Singleton bound. For
smaller alphabets, however, this construction may not be optimal. A random
construction is also analyzed. It yields another inexplicit bound on the length
of an optimal linear ECIC. Finally, the decoding of linear ECIC's is discussed.
The syndrome decoding is shown to output the exact message if the weight of the
error vector is less or equal to the error-correcting capability of the
corresponding ECIC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2753</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2753</id><created>2011-01-14</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>An Efficient and User Privacy-Preserving Routing Protocol for Wireless
  Mesh Networks</title><categories>cs.CR</categories><comments>14 pages, 10 figures, i table</comments><journal-ref>International Journal of Scalable Computing: Practice and
  Experience. Vol. 11, No. 4, pp. 345-358, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless mesh networks (WMNs) have emerged as a key technology for next
generation wireless broadband networks showing rapid progress and inspiring
numerous compelling applications. A WMN comprises of a set of mesh routers
(MRs) and mesh clients (MCs), where MRs are connected to the Internet backbone
through the Internet gateways (IGWs). The MCs are wireless devices and
communicate among themselves over possibly multi-hop paths with or without the
involvement of MRs. User privacy and security have been primary concerns in
WMNs due to their peer-to-peer network topology, shared wireless medium,
stringent resource constraints, and highly dynamic environment. Moreover, to
support real-time applications, WMNs must also be equipped with robust,
reliable and efficient routing protocols so as to minimize the end-to-end
latency. Design of a secure and efficient routing protocol for WMNs, therefore,
is of paramount importance. In this paper, we propose an efficient and reliable
routing protocol that also provides user anonymity in WMNs. The protocol is
based on an accurate estimation of the available bandwidth in the wireless
links and a robust estimation of the end-to-end delay in a routing path, and
minimization of control message overhead. The user anonymity, authentication
and data privacy is achieved by application of a novel protocol that is based
on Rivest's ring signature scheme. Simulations carried out on the proposed
protocol demonstrate that it is more efficient than some of the existing
routing protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2759</identifier>
 <datestamp>2013-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2759</id><created>2011-01-14</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>Routing Security Issues in Wireless Sensor Networks: Attacks and
  Defenses</title><categories>cs.NI</categories><comments>32 pages, 5 figures, 4 tables 4. arXiv admin note: substantial text
  overlap with arXiv:1011.1529</comments><journal-ref>Book Chapter in Sustainable Wireless Sensor Networks, Yen Kheng
  Tan (Ed.), ISBN: 978-953-307-297-5, INTECH Publishers, Croatia, December
  2010. Chapter 12, pp. 279 - 309</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) are rapidly emerging as an important new area
in wireless and mobile computing research. Applications of WSNs are numerous
and growing, and range from indoor deployment scenarios in the home and office
to outdoor deployment scenarios in adversary's territory in a tactical
battleground (Akyildiz et al., 2002). For military environment, dispersal of
WSNs into an adversary's territory enables the detection and tracking of enemy
soldiers and vehicles. For home/office environments, indoor sensor networks
offer the ability to monitor the health of the elderly and to detect intruders
via a wireless home security system. In each of these scenarios, lives and
livelihoods may depend on the timeliness and correctness of the sensor data
obtained from dispersed sensor nodes. As a result, such WSNs must be secured to
prevent an intruder from obstructing the delivery of correct sensor data and
from forging sensor data. To address the latter problem, end-to-end data
integrity checksums and post-processing of senor data can be used to identify
forged sensor data (Estrin et al., 1999; Hu et al., 2003a; Ye et al., 2004).
The focus of this chapter is on routing security in WSNs. Most of the currently
existing routing protocols for WSNs make an optimization on the limited
capabilities of the nodes and the application-specific nature of the network,
but do not any the security aspects of the protocols. Although these protocols
have not been designed with security as a goal, it is extremely important to
analyze their security properties. When the defender has the liabilities of
insecure wireless communication, limited node capabilities, and possible
insider threats, and the adversaries can use powerful laptops with high energy
and long range communication to attack the network, designing a secure routing
protocol for WSNs is obviously a non-trivial task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2770</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2770</id><created>2011-01-14</created><authors><author><keyname>Bessas</keyname><forenames>Apostolos</forenames></author><author><keyname>Kontogiannis</keyname><forenames>Spyros</forenames></author><author><keyname>Zaroliagis</keyname><forenames>Christos</forenames></author></authors><title>Robust Line Planning in case of Multiple Pools and Disruptions</title><categories>cs.GT</categories><comments>To appear in TAPAS 2011</comments><doi>10.1007/978-3-642-19754-3_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the line planning problem in public transportation, under a
robustness perspective. We present a mechanism for robust line planning in the
case of multiple line pools, when the line operators have a different utility
function per pool. We conduct an experimental study of our mechanism on both
synthetic and real-world data that shows fast convergence to the optimum. We
also explore a wide range of scenarios, varying from an arbitrary initial state
(to be solved) to small disruptions in a previously optimal solution (to be
recovered). Our experiments with the latter scenario show that our mechanism
can be used as an online recovery scheme causing the system to re-converge to
its optimum extremely fast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2777</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2777</id><created>2011-01-14</created><updated>2011-04-11</updated><authors><author><keyname>Goncharov</keyname><forenames>Sergey</forenames></author><author><keyname>Schr&#xf6;der</keyname><forenames>Lutz</forenames></author></authors><title>Powermonads and Tensors of Unranked Effects</title><categories>cs.LO</categories><comments>extended version; first 10 pages are to appear on LICS'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In semantics and in programming practice, algebraic concepts such as monads
or, essentially equivalently, (large) Lawvere theories are a well-established
tool for modelling generic side-effects. An important issue in this context are
combination mechanisms for such algebraic effects, which allow for the modular
design of programming languages and verification logics. The most basic
combination operators are sum and tensor: while the sum of effects is just
their non-interacting union, the tensor imposes commutation of effects.
However, for effects with unbounded arity, such as continuations or unbounded
nondeterminism, it is not a priori clear whether these combinations actually
exist in all cases. Here, we introduce the class of uniform effects, which
includes unbounded nondeterminism and continuations, and prove that the tensor
does always exist if one of the component effects is uniform, thus in
particular improving on previous results on tensoring with continuations. We
then treat the case of nondeterminism in more detail, and give an
order-theoretic characterization of effects for which tensoring with
nondeterminism is conservative, thus enabling nondeterministic arguments such
as a generic version of the Fischer-Ladner encoding of control operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2785</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2785</id><created>2011-01-14</created><authors><author><keyname>Ling</keyname><forenames>K. V.</forenames></author><author><keyname>Maciejowski</keyname><forenames>J. M.</forenames></author><author><keyname>Richards</keyname><forenames>A. G.</forenames></author><author><keyname>Wu</keyname><forenames>B-F.</forenames></author></authors><title>Multiplexed Model Predictive Control</title><categories>cs.SY math.OC</categories><comments>University of Cambridge, Department of Engineering, Technical Report</comments><report-no>CUED/F-INFENG/TR.657</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a form of MPC in which the control variables are moved
asynchronously. This contrasts with most MIMO control schemes, which assume
that all variables are updated simultaneously. MPC outperforms other control
strategies through its ability to deal with constraints. This requires on-line
optimization, hence computational complexity can become an issue when applying
MPC to complex systems with fast response times. The multiplexed MPC scheme
described in this paper solves the MPC problem for each subsystem sequentially,
and updates subsystem controls as soon as the solution is available, thus
distributing the control moves over a complete update cycle. The resulting
computational speed-up allows faster response to disturbances, which may result
in improved performance, despite finding sub-optimal solutions to the original
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2798</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2798</id><created>2011-01-11</created><authors><author><keyname>Abubakr</keyname><forenames>Mohammed</forenames></author></authors><title>On Logical Extension of Algebraic Division</title><categories>cs.LO</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Basic arithmetic is the cornerstone of mathematics and computer sciences. In
arithmetic, 'division by zero' is an undefined operation and any attempt at
extending logic for algebraic division to incorporate division by zero has
resulted in paradoxes and fallacies. However, there is no proven theorem or
mathematical logic that suggests that, defining logic for division by zero
would result in break-down of theory. Basing on this motivation, in this paper,
we attempt at logically defining a solution for 'division by zero' problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2803</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2803</id><created>2011-01-14</created><authors><author><keyname>Kauers</keyname><forenames>Manuel</forenames></author><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author></authors><title>A Refined Denominator Bounding Algorithm for Multivariate Linear
  Difference Equations</title><categories>cs.SC</categories><acm-class>I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue to investigate which polynomials can possibly occur as factors in
the denominators of rational solutions of a given partial linear difference
equation.
  In an earlier article we had introduced the distinction between periodic and
aperiodic factors in the denominator, and we gave an algorithm for predicting
the aperiodic ones. Now we extend this technique towards the periodic case and
present a refined algorithm which also finds most of the periodic factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2804</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2804</id><created>2011-01-14</created><authors><author><keyname>Mukherjee</keyname><forenames>Animesh</forenames></author><author><keyname>Tria</keyname><forenames>Francesca</forenames></author><author><keyname>Baronchelli</keyname><forenames>Andrea</forenames></author><author><keyname>Puglisi</keyname><forenames>Andrea</forenames></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author></authors><title>Aging in language dynamics</title><categories>physics.soc-ph cond-mat.stat-mech cs.CL cs.MA</categories><comments>15 pages, 6 figures. Accepted for publication in PLoS ONE</comments><journal-ref>PLoS ONE 6(2): e16677, 2011</journal-ref><doi>10.1371/journal.pone.0016677</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human languages evolve continuously, and a puzzling problem is how to
reconcile the apparent robustness of most of the deep linguistic structures we
use with the evidence that they undergo possibly slow, yet ceaseless, changes.
Is the state in which we observe languages today closer to what would be a
dynamical attractor with statistically stationary properties or rather closer
to a non-steady state slowly evolving in time? Here we address this question in
the framework of the emergence of shared linguistic categories in a population
of individuals interacting through language games. The observed emerging
asymptotic categorization, which has been previously tested - with success -
against experimental data from human languages, corresponds to a metastable
state where global shifts are always possible but progressively more unlikely
and the response properties depend on the age of the system. This aging
mechanism exhibits striking quantitative analogies to what is observed in the
statistical mechanics of glassy systems. We argue that this can be a general
scenario in language dynamics where shared linguistic conventions would not
emerge as attractors, but rather as metastable states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2812</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2812</id><created>2011-01-14</created><authors><author><keyname>Gawlitza</keyname><forenames>Thomas Martin</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>VERIMAG - IMAG</affiliation></author></authors><title>Improving Strategies via SMT Solving</title><categories>cs.PL cs.CC cs.LO math.OC</categories><proxy>ccsd</proxy><doi>10.1007/978-3-642-19718-5_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing numerical invariants of programs by
abstract interpretation. Our method eschews two traditional sources of
imprecision: (i) the use of widening operators for enforcing convergence within
a finite number of iterations (ii) the use of merge operations (often, convex
hulls) at the merge points of the control flow graph. It instead computes the
least inductive invariant expressible in the domain at a restricted set of
program points, and analyzes the rest of the code en bloc. We emphasize that we
compute this inductive invariant precisely. For that we extend the strategy
improvement algorithm of [Gawlitza and Seidl, 2007]. If we applied their method
directly, we would have to solve an exponentially sized system of abstract
semantic equations, resulting in memory exhaustion. Instead, we keep the system
implicit and discover strategy improvements using SAT modulo real linear
arithmetic (SMT). For evaluating strategies we use linear programming. Our
algorithm has low polynomial space complexity and performs for contrived
examples in the worst case exponentially many strategy improvement steps; this
is unsurprising, since we show that the associated abstract reachability
problem is Pi-p-2-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2819</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2819</id><created>2011-01-14</created><authors><author><keyname>Tschantz</keyname><forenames>Michael Carl</forenames></author><author><keyname>Kaynar</keyname><forenames>Dilsun</forenames></author><author><keyname>Datta</keyname><forenames>Anupam</forenames></author></authors><title>Formal Verification of Differential Privacy for Interactive Systems</title><categories>cs.CR</categories><comments>65 pages with 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a promising approach to privacy preserving data
analysis with a well-developed theory for functions. Despite recent work on
implementing systems that aim to provide differential privacy, the problem of
formally verifying that these systems have differential privacy has not been
adequately addressed. This paper presents the first results towards automated
verification of source code for differentially private interactive systems. We
develop a formal probabilistic automaton model of differential privacy for
systems by adapting prior work on differential privacy for functions. The main
technical result of the paper is a sound proof technique based on a form of
probabilistic bisimulation relation for proving that a system modeled as a
probabilistic automaton satisfies differential privacy. The novelty lies in the
way we track quantitative privacy leakage bounds using a relation family
instead of a single relation. We illustrate the proof technique on a
representative automaton motivated by PINQ, an implemented system that is
intended to provide differential privacy. To make our proof technique easier to
apply to realistic systems, we prove a form of refinement theorem and apply it
to show that a refinement of the abstract PINQ automaton also satisfies our
differential privacy definition. Finally, we begin the process of automating
our proof technique by providing an algorithm for mechanically checking a
restricted class of relations from the proof technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2834</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2834</id><created>2011-01-14</created><updated>2011-01-17</updated><authors><author><keyname>Caruso</keyname><forenames>Fabrizio</forenames></author><author><keyname>Giuffrida</keyname><forenames>Giovanni</forenames></author><author><keyname>Zarba</keyname><forenames>Calogero</forenames></author></authors><title>Subjective Collaborative Filtering</title><categories>cs.IR cs.SI</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an item-based approach for collaborative filtering. We determine a
list of recommended items for a user by considering their previous purchases.
Additionally other features of the users could be considered such as page
views, search queries, etc... In particular we address the problem of
efficiently comparing items. Our algorithm can efficiently approximate an
estimate of the similarity between two items. As measure of similarity we use
an approximation of the Jaccard similarity that can be computed by constant
time operations and one bitwise OR. Moreover we improve the accuracy of the
similarity by introducing the concept of user preference for a given product,
which both takes into account multiple purchases and purchases of related
items. The product of the user preference and the Jaccard measure (or its
approximation) is used as a score for deciding whether a given product has to
be recommended.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2883</identifier>
 <datestamp>2011-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2883</id><created>2011-01-14</created><authors><author><keyname>Immorlica</keyname><forenames>Nicole</forenames></author><author><keyname>Kalai</keyname><forenames>Adam Tauman</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Moitra</keyname><forenames>Ankur</forenames></author><author><keyname>Postlewaite</keyname><forenames>Andrew</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Dueling Algorithms</title><categories>cs.GT cs.DS</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit classic algorithmic search and optimization problems from the
perspective of competition. Rather than a single optimizer minimizing expected
cost, we consider a zero-sum game in which an optimization problem is presented
to two players, whose only goal is to outperform the opponent. Such games are
typically exponentially large zero-sum games, but they often have a rich
combinatorial structure. We provide general techniques by which such structure
can be leveraged to find minmax-optimal and approximate minmax-optimal
strategies. We give examples of ranking, hiring, compression, and binary search
duels, among others. We give bounds on how often one can beat the classic
optimization algorithms in such duels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2913</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2913</id><created>2011-01-14</created><authors><author><keyname>Biswal</keyname><forenames>Punyashloka</forenames></author></authors><title>Hypercontractivity and its applications</title><categories>cs.DM</categories><comments>Submitted for UW Quals in February 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Hypercontractive inequalities are a useful tool in dealing with extremal
questions in the geometry of high-dimensional discrete and continuous spaces.
In this survey we trace a few connections between different manifestations of
hypercontractivity, and also present some relatively recent applications of
these techniques in computer science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2926</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2926</id><created>2011-01-14</created><updated>2011-04-20</updated><authors><author><keyname>Lorenz</keyname><forenames>Jan</forenames></author></authors><title>Convergence to consensus in multiagent systems and the lengths of
  inter-communication intervals</title><categories>math.OC cs.MA math.DS</categories><comments>19 pages, 2 figures, This paper has been withdrawn, because
  Proposition 5 and consequently Proposition 6 turned out to be wrong. The text
  about the remaining results have to be untangled from relations to the the
  wrong results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A theorem on (partial) convergence to consensus of multiagent systems is
presented. It is proven with tools studying the convergence properties of
products of row stochastic matrices with positive diagonals which are infinite
to the left. Thus, it can be seen as a switching linear system in discrete
time. It is further shown that the result is strictly more general than results
of Moreau (IEEE Transactions on Automatic Control, vol. 50, no. 2, 2005),
although Moreau's results are formulated for generally nonlinear updating maps.
This is shown by demonstrating the existence of an appropriate switching linear
system which mimics the nonlinear updating maps. Further on, an example system
is given for which convergence to consensus can be shown by using the theorem.
In this system the lengths of intercommunication intervals in the switching
communication topology grows without bound. This makes other theorems not
applicable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2937</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2937</id><created>2011-01-14</created><authors><author><keyname>Yazdi</keyname><forenames>S. M. Sadegh Tabatabaei</forenames></author><author><keyname>Savari</keyname><forenames>Serap A.</forenames></author></authors><title>A Deterministic Polynomial--Time Algorithm for Constructing a Multicast
  Coding Scheme for Linear Deterministic Relay Networks</title><categories>cs.IT math.IT</categories><comments>12 pages, 2 figures, submitted to CISS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new way to construct a multicast coding scheme for linear
deterministic relay networks. Our construction can be regarded as a
generalization of the well-known multicast network coding scheme of Jaggi et
al. to linear deterministic relay networks and is based on the notion of flow
for a unicast session that was introduced by the authors in earlier work. We
present randomized and deterministic polynomial--time versions of our algorithm
and show that for a network with $g$ destinations, our deterministic algorithm
can achieve the capacity in $\left\lceil \log(g+1)\right\rceil $ uses of the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2940</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2940</id><created>2011-01-14</created><authors><author><keyname>Kulik</keyname><forenames>Ariel</forenames></author><author><keyname>Shachnai</keyname><forenames>Hadas</forenames></author><author><keyname>Tamir</keyname><forenames>Tami</forenames></author></authors><title>Approximations for Monotone and Non-monotone Submodular Maximization
  with Knapsack Constraints</title><categories>cs.DS cs.DM</categories><comments>A preliminary version of this paper appeared in the Proceedings of
  the 20th Annual ACM-SIAM Symposium on Discrete Algorithms, New York, January
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Submodular maximization generalizes many fundamental problems in discrete
optimization, including Max-Cut in directed/undirected graphs, maximum
coverage, maximum facility location and marketing over social networks.
  In this paper we consider the problem of maximizing any submodular function
subject to $d$ knapsack constraints, where $d$ is a fixed constant. We
establish a strong relation between the discrete problem and its continuous
relaxation, obtained through {\em extension by expectation} of the submodular
function. Formally, we show that, for any non-negative submodular function, an
$\alpha$-approximation algorithm for the continuous relaxation implies a
randomized $(\alpha - \eps)$-approximation algorithm for the discrete problem.
We use this relation to improve the best known approximation ratio for the
problem to $1/4- \eps$, for any $\eps &gt; 0$, and to obtain a nearly optimal
$(1-e^{-1}-\eps)-$approximation ratio for the monotone case, for any $\eps&gt;0$.
We further show that the probabilistic domain defined by a continuous solution
can be reduced to yield a polynomial size domain, given an oracle for the
extension by expectation. This leads to a deterministic version of our
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2964</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2964</id><created>2011-01-15</created><authors><author><keyname>K&#xe1;sa</keyname><forenames>Zolt&#xe1;n</forenames></author><author><keyname>T&#xe2;mbulea</keyname><forenames>Leoan</forenames></author></authors><title>Binary trees and number of states in buddy systems</title><categories>cs.DM</categories><msc-class>68R10, 68R05, 68M99</msc-class><acm-class>G.2.2; G.2.1; D.4.2</acm-class><journal-ref>Annales Univ. Sci. Budapestinensis Sectio Computatorica, vol 7,
  1987, pp. 3-10</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper are computed: the number of binary trees with n nodes and k
leaves; the number of leaves in the set of all binary trees with n nodes. These
are used to compute the number of states in the buddy system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2973</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2973</id><created>2011-01-15</created><updated>2016-02-29</updated><authors><author><keyname>Fadaei</keyname><forenames>Salman</forenames></author><author><keyname>Fazli</keyname><forenames>MohammadAmin</forenames></author><author><keyname>Safari</keyname><forenames>MohammadAli</forenames></author></authors><title>Maximizing Non-monotone Submodular Set Functions Subject to Different
  Constraints: Combined Algorithms</title><categories>cs.DS</categories><comments>There was an older version of the paper on arXiv. We update it to the
  latest version. In particular, there was an error in the proof of Theorem 2.
  We fixed it. The approximation remains the same as before</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of maximizing constrained non-monotone submodular
functions and provide approximation algorithms that improve existing algorithms
in terms of either the approximation factor or simplicity. Our algorithms
combine existing local search and greedy based algorithms. Different
constraints that we study are exact cardinality and multiple knapsack
constraints. For the multiple-knapsack constraints we achieve a
$(0.25-2\epsilon)$-factor algorithm.
  We also show, as our main contribution, how to use the continuous greedy
process for non-monotone functions and, as a result, obtain a $0.13$-factor
approximation algorithm for maximization over any solvable down-monotone
polytope. The continuous greedy process has been previously used for maximizing
smooth monotone submodular function over a down-monotone polytope
\cite{CCPV08}. This implies a 0.13-approximation for several discrete problems,
such as maximizing a non-negative submodular function subject to a matroid
constraint and/or multiple knapsack constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2985</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2985</id><created>2011-01-15</created><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>Resequencing: A Method for Conforming to Conventions for Sharing Credits
  Among Multiple Authors</title><categories>cs.DL cs.CY cs.IR</categories><comments>3 pages, 2 figures</comments><msc-class>68M20</msc-class><acm-class>H.3.1; H.3.3; H.3.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Devising an appropriate scheme that assigns the weights to share credits
among multiple authors of a paper is a challenging task. This challenge comes
from the fact that different types of conventions might be followed among
different research discipline or research groups. In this paper, we discuss
that for the purpose of evaluating the quality of research produced by authors,
one can resequence either authors or weights and can apply a weight assignment
policy which the evaluator deems fit for the particular research discipline or
research group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2987</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2987</id><created>2011-01-15</created><authors><author><keyname>Pal</keyname><forenames>Mahesh</forenames></author></authors><title>Support vector machines/relevance vector machine for remote sensing
  classification: A review</title><categories>cs.CV cs.LG</categories><comments>19 pages</comments><journal-ref>Proceeding of the Workshop on Application of advanced soft
  computing Techniques in Geo-spatial Data Analysis. Department of Civil
  Engineering, IIT Bombay, Sept. 22-23,2008, 211-227</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel-based machine learning algorithms are based on mapping data from the
original input feature space to a kernel feature space of higher dimensionality
to solve a linear problem in that space. Over the last decade, kernel based
classification and regression approaches such as support vector machines have
widely been used in remote sensing as well as in various civil engineering
applications. In spite of their better performance with different datasets,
support vector machines still suffer from shortcomings such as
visualization/interpretation of model, choice of kernel and kernel specific
parameter as well as the regularization parameter. Relevance vector machines
are another kernel based approach being explored for classification and
regression with in last few years. The advantages of the relevance vector
machines over the support vector machines is the availability of probabilistic
predictions, using arbitrary kernel functions and not requiring setting of the
regularization parameter. This paper presents a state-of-the-art review of SVM
and RVM in remote sensing and provides some details of their use in other civil
engineering application also.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.2999</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.2999</id><created>2011-01-15</created><authors><author><keyname>Papadopoulos</keyname><forenames>Basil K.</forenames></author><author><keyname>Syropoulos</keyname><forenames>Apostolos</forenames></author></authors><title>Generalizing Topology via Chu Spaces</title><categories>cs.LO</categories><comments>This is paper that was written in 1999</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By using the representational power of Chu spaces we define the notion of a
generalized topological space (or GTS, for short), i.e., a mathematical
structure that generalizes the notion of a topological space. We demonstrate
that these topological spaces have as special cases known topological spaces.
Furthermore, we develop the various topological notions and concepts for GTS.
Moreover, since the logic of Chu spaces is linear logic, we give an
interpretation of most linear logic connectives as operators that yield
topological spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3051</identifier>
 <datestamp>2015-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3051</id><created>2011-01-16</created><authors><author><keyname>Ghahabi</keyname><forenames>Omid</forenames></author><author><keyname>Savoji</keyname><forenames>Mohammad H.</forenames></author></authors><title>Adaptive Variable Degree-k Zero-Trees for Re-Encoding of Perceptually
  Quantized Wavelet-Packet Transformed Audio and High Quality Speech</title><categories>cs.IT math.IT</categories><comments>30 pages (Double space), 15 figures, 5 tables, ISRN Signal Processing
  (in Press)</comments><doi>10.5402/2011/145758</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fast, efficient and scalable algorithm is proposed, in this paper, for
re-encoding of perceptually quantized wavelet-packet transform (WPT)
coefficients of audio and high quality speech and is called &quot;adaptive variable
degree-k zero-trees&quot; (AVDZ). The quantization process is carried out by taking
into account some basic perceptual considerations, and achieves good subjective
quality with low complexity. The performance of the proposed AVDZ algorithm is
compared with two other zero-tree-based schemes comprising: 1- Embedded
Zero-tree Wavelet (EZW) and 2- The set partitioning in hierarchical trees
(SPIHT). Since EZW and SPIHT are designed for image compression, some
modifications are incorporated in these schemes for their better matching to
audio signals. It is shown that the proposed modifications can improve their
performance by about 15-25%. Furthermore, it is concluded that the proposed
AVDZ algorithm outperforms these modified versions in terms of both output
average bit-rates and computation times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3052</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3052</id><created>2011-01-16</created><updated>2011-07-16</updated><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>The Theory of Intervention Games for Resource Sharing in Wireless
  Communications</title><categories>cs.GT</categories><comments>29 pages, 1 table, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a game-theoretic framework for the design and analysis of
a new class of incentive schemes called intervention schemes. We formulate
intervention games, propose a solution concept of intervention equilibrium, and
prove its existence in a finite intervention game. We apply our framework to
resource sharing scenarios in wireless communications, whose non-cooperative
outcomes without intervention yield suboptimal performance. We derive
analytical results and analyze illustrative examples in the cases of imperfect
and perfect monitoring. In the case of imperfect monitoring, intervention
schemes can improve the suboptimal performance of non-cooperative equilibrium
when the intervention device has a sufficiently accurate monitoring technology,
although it may not be possible to achieve the best feasible performance. In
the case of perfect monitoring, the best feasible performance can be obtained
with an intervention scheme when the intervention device has a sufficiently
strong intervention capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3067</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3067</id><created>2011-01-16</created><authors><author><keyname>Baumgartner</keyname><forenames>Tobias</forenames></author><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Koninis</keyname><forenames>Christos</forenames></author><author><keyname>Kroeller</keyname><forenames>Alexander</forenames></author><author><keyname>Pyrgelis</keyname><forenames>Apostolos</forenames></author></authors><title>Wiselib: A Generic Algorithm Library for Heterogeneous Sensor Networks</title><categories>cs.NI cs.SE</categories><comments>16 pages, 1 figure, 7 tables. Appears in European Conference on
  Wireless Sensor Networks (EWSN 2010)</comments><acm-class>F.2.2; D.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One unfortunate consequence of the success story of wireless sensor networks
(WSNs) in separate research communities is an ever-growing gap between theory
and practice. Even though there is a increasing number of algorithmic methods
for WSNs, the vast majority has never been tried in practice; conversely, many
practical challenges are still awaiting efficient algorithmic solutions. The
main cause for this discrepancy is the fact that programming sensor nodes still
happens at a very technical level. We remedy the situation by introducing
Wiselib, our algorithm library that allows for simple implementations of
algorithms onto a large variety of hardware and software. This is achieved by
employing advanced C++ techniques such as templates and inline functions,
allowing to write generic code that is resolved and bound at compile time,
resulting in virtually no memory or computation overhead at run time.
  The Wiselib runs on different host operating systems, such as Contiki, iSense
OS, and ScatterWeb. Furthermore, it runs on virtual nodes simulated by Shawn.
For any algorithm, the Wiselib provides data structures that suit the specific
properties of the target platform. Algorithm code does not contain any
platform-specific specializations, allowing a single implementation to run
natively on heterogeneous networks.
  In this paper, we describe the building blocks of the Wiselib, and analyze
the overhead. We demonstrate the effectiveness of our approach by showing how
routing algorithms can be implemented. We also report on results from
experiments with real sensor-node hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3068</identifier>
 <datestamp>2011-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3068</id><created>2011-01-16</created><updated>2011-10-30</updated><authors><author><keyname>Ke</keyname><forenames>Lei</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author><author><keyname>Yin</keyname><forenames>Huarui</forenames></author></authors><title>Degrees of Freedom Region for an Interference Network with General
  Message Demands</title><categories>cs.IT math.IT</categories><comments>26 pages, 5 figures, revised version, submitted to IEEE Transactions
  on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a single hop interference network with $K$ transmitters and $J$
receivers, all having $M$ antennas. Each transmitter emits an independent
message and each receiver requests an arbitrary subset of the messages. This
generalizes the well-known $K$-user $M$-antenna interference channel, where
each message is requested by a unique receiver. For our setup, we derive the
degrees of freedom (DoF) region. The achievability scheme generalizes the
interference alignment schemes proposed by Cadambe and Jafar. In particular, we
achieve general points in the DoF region by using multiple base vectors and
aligning all interferers at a given receiver to the interferer with the largest
DoF. As a byproduct, we obtain the DoF region for the original interference
channel. We also discuss extensions of our approach where the same region can
be achieved by considering a reduced set of interference alignment constraints,
thus reducing the time-expansion duration needed. The DoF region for the
considered system depends only on a subset of receivers whose demands meet
certain characteristics. The geometric shape of the DoF region is also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3070</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3070</id><created>2011-01-16</created><updated>2012-04-16</updated><authors><author><keyname>Ostrowski</keyname><forenames>Marcin</forenames></author></authors><title>Information and the arrow of time</title><categories>physics.pop-ph cs.IT math.IT</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a discussion about the relationship between time and
information. We argue that the direction of arrow of time is related to the
directivity of information copying that occurs in Nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3076</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3076</id><created>2011-01-16</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Robust and Secure Aggregation Protocol for Wireless Sensor Networks</title><categories>cs.CR cs.NI</categories><comments>6 pages, 3 figures, 1 table. In Proceedings of the 6th International
  Symposium on Electronic Design, Test and Applications (DELTA 2011),
  Queenstown, New Zealand, 17 - 19 January 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of a wireless sensor network (WSN) is to provide the users with
access to the information of interest from data gathered by spatially
distributed sensors. Generally the users require only certain aggregate
functions of this distributed data. Computation of this aggregate data under
the end-to-end information flow paradigm by communicating all the relevant data
to a central collector node is a highly inefficient solution for this purpose.
An alternative proposition is to perform in-network computation. This, however,
raises questions such as: what is the optimal way to compute an aggregate
function from a set of statistically correlated values stored in different
nodes; what is the security of such aggregation as the results sent by a
compromised or faulty node in the network can adversely affect the accuracy of
the computed result. In this paper, we have presented an energy-efficient
aggregation algorithm for WSNs that is secure and robust against malicious
insider attack by any compromised or faulty node in the network. In contrast to
the traditional snapshot aggregation approach in WSNs, a node in the proposed
algorithm instead of unicasting its sensed information to its parent node,
broadcasts its estimate to all its neighbors. This makes the system more
fault-tolerant and increase the information availability in the network. The
simulations conducted on the proposed algorithm have produced results that
demonstrate its effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3085</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3085</id><created>2011-01-16</created><authors><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author><author><keyname>Conte</keyname><forenames>Rosaria</forenames></author><author><keyname>Lodi</keyname><forenames>Elena</forenames></author></authors><title>Simulating Opinion Dynamics in Heterogeneous Communication</title><categories>cs.SI cs.MA physics.soc-ph</categories><comments>15 Pages. Eccs 2010 Special Mension</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the information available is fundamental for our perceptions and
opinions, we are interested in understanding the conditions allowing for a good
information to be disseminated. This paper explores opinion dynamics by means
of multi-agent based simulations when agents get informed by different sources
of information. The scenario implemented includes three main streams of
information acquisition, differing in both the contents and the perceived
reliability of the messages spread. Agents' internal opinion is updated either
by accessing one of the information sources, namely media and experts, or by
exchanging information with one another. They are also endowed with cognitive
mechanisms to accept, reject or partially consider the acquired information. We
expect that peer-to--peer communication and reliable information sources are
able both to reduce biased perceptions and to inhibit information cheating,
possibly performed by the media as stated by the agenda-setting theory. In the
paper, after having shortly presented both the hypotheses and the model, the
simulation design will be specified and results will be discussed with respect
to the hypotheses. Some considerations and ideas for future studies will
conclude the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3091</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3091</id><created>2011-01-16</created><updated>2011-03-16</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author></authors><title>Detecting genus in vertex links for the fast enumeration of 3-manifold
  triangulations</title><categories>math.GT cs.CG math.CO</categories><comments>16 pages, 7 figures, 3 tables; v2: minor revisions; to appear in
  ISSAC 2011</comments><acm-class>G.2.1; G.4; I.1.2</acm-class><journal-ref>ISSAC 2011: Proceedings of the 36th International Symposium on
  Symbolic and Algebraic Computation, ACM, 2011, pp. 59-66</journal-ref><doi>10.1145/1993886.1993901</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enumerating all 3-manifold triangulations of a given size is a difficult but
increasingly important problem in computational topology. A key difficulty for
enumeration algorithms is that most combinatorial triangulations must be
discarded because they do not represent topological 3-manifolds. In this paper
we show how to preempt bad triangulations by detecting genus in
partially-constructed vertex links, allowing us to prune the enumeration tree
substantially.
  The key idea is to manipulate the boundary edges surrounding partial vertex
links using expected logarithmic time operations. Practical testing shows the
resulting enumeration algorithm to be significantly faster, with up to 249x
speed-ups even for small problems where comparisons are feasible. We also
discuss parallelisation, and describe new data sets that have been obtained
using high-performance computing facilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3098</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3098</id><created>2011-01-16</created><updated>2011-09-08</updated><authors><author><keyname>Weis</keyname><forenames>Stephan</forenames></author></authors><title>Quantum Convex Support</title><categories>math-ph cs.IT math.IT math.MP quant-ph</categories><comments>27 pages, 5 figures, minor errors corrected, font changed from small
  to normal</comments><msc-class>Primary 81P16, 62B10, 52A20 Secondary 94A17, 90C22, 90C30</msc-class><journal-ref>Linear Algebra and its Applications 435 (2011) 3168-3188,
  correction: 436 xvi (2012)</journal-ref><doi>10.1016/j.laa.2011.06.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convex support, the mean values of a set of random variables, is central in
information theory and statistics. Equally central in quantum information
theory are mean values of a set of observables in a finite-dimensional
C*-algebra A, which we call (quantum) convex support. The convex support can be
viewed as a projection of the state space of A and it is a projection of a
spectrahedron.
  Spectrahedra are increasingly investigated at least since the 1990's boom in
semidefinite programming. We recall the geometry of the positive semi-definite
cone and of the state space. We write a convex duality for general self-dual
convex cones. This restricts to projections of state spaces and connects them
to results on spectrahedra.
  Really new in this article is an analysis of the face lattice of convex
support by mapping this lattice to a lattice of orthogonal projections, using
natural isomorphisms. The result encodes the face lattice of the convex support
into a set of projections in A and enables the integration of convex geometry
with matrix calculus or algebraic techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3099</identifier>
 <datestamp>2014-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3099</id><created>2011-01-16</created><authors><author><keyname>Ben-Shimon</keyname><forenames>Sonny</forenames></author><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author><author><keyname>Sudakov</keyname><forenames>Benny</forenames></author></authors><title>On the resilience of Hamiltonicity and optimal packing of Hamilton
  cycles in random graphs</title><categories>math.CO cs.DM math.PR</categories><comments>20 pages</comments><journal-ref>SIAM Journal on Discrete Mathematics, 25(3):1176--1193, 2011</journal-ref><doi>10.1137/110821299</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\bk=(k_1,...,k_n)$ be a sequence of $n$ integers. For an increasing
monotone graph property $\mP$ we say that a base graph $G=([n],E)$ is
\emph{$\bk$-resilient} with respect to $\mP$ if for every subgraph $H\subseteq
G$ such that $d_H(i)\leq k_i$ for every $1\leq i\leq n$ the graph $G-H$
possesses $\mP$. This notion naturally extends the idea of the \emph{local
resilience} of graphs recently initiated by Sudakov and Vu. In this paper we
study the $\bk$-resilience of a typical graph from $\GNP$ with respect to the
Hamiltonicity property where we let $p$ range over all values for which the
base graph is expected to be Hamiltonian. In particular, we prove that for
every $\epsilon&gt;0$ and $p\geq\frac{\ln n+\ln\ln n +\omega(1)}{n}$ if a graph is
sampled from $\GNP$ then with high probability removing from each vertex of
&quot;small&quot; degree all incident edges but two and from any other vertex at most a
$(\frac{1}{3}-\epsilon)$-fraction of the incident edges will result in a
Hamiltonian graph.
  Considering this generalized approach to the notion of resilience allows to
establish several corollaries which improve on the best known bounds of
Hamiltonicity related questions. It implies that for every positive
$\epsilon&gt;0$ and large enough values of $K$, if $p&gt;\frac{K\ln n}{n}$ then with
high probability the local resilience of $\GNP$ with respect to being
Hamiltonian is at least $(1-\epsilon)np/3$, improving on the previous bound for
this range of $p$. Another implication is a result on optimal packing of edge
disjoint Hamilton cycles in a random graph. We prove that if
$p\leq\frac{1.02\ln n}{n}$ then with high probability a graph $G$ sampled from
$\GNP$ contains $\lfloor\frac{\delta(G)}{2}\rfloor$ edge disjoint Hamilton
cycles, extending the previous range of $p$ for which this was known to hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3102</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3102</id><created>2011-01-16</created><updated>2011-04-08</updated><authors><author><keyname>Maas</keyname><forenames>Dustin</forenames></author><author><keyname>Patwari</keyname><forenames>Neal</forenames></author><author><keyname>Wasden</keyname><forenames>Daryl</forenames></author><author><keyname>Kasera</keyname><forenames>Sneha</forenames></author><author><keyname>Jensen</keyname><forenames>Michael</forenames></author></authors><title>Experimental Performance Evaluation of Location Distinction for MIMO
  Channels</title><categories>cs.NI</categories><comments>15 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location distinction is defined as determining whether or not the position of
a device has changed. We introduce methods and metrics for performing location
distinction in multiple-input multiple-output (MIMO) wireless networks. Using
MIMO channel measurements from two different testbeds, we evaluate the
performance of temporal signature-based location distinction with varying
system parameters, and show that it can be applied to MIMO channels with
favorable results. In particular, a 2x2 MIMO channel with a bandwidth of 80 MHz
allows a 64-fold reduction in miss rate over the SISO channel for a fixed false
alarm rate, achieving as small as 4 x 10^-4 probability of false alarm for a
2.4 x 10^-4 probability of missed detection. The very high reliability of MIMO
location distinction enables location distinction systems to detect the change
in position of a transmitter even when using a single receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3122</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3122</id><created>2011-01-16</created><updated>2011-05-19</updated><authors><author><keyname>Hisakado</keyname><forenames>Masato</forenames></author><author><keyname>Mori</keyname><forenames>Shintaro</forenames></author></authors><title>Digital herders and phase transition in a voting model</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>26 pages, 10 figures</comments><doi>10.1088/1751-8113/44/27/275204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discuss a voting model with two candidates, C_1 and C_2. We
set two types of voters--herders and independents. The voting of independent
voters is based on their fundamental values; on the other hand, the voting of
herders is based on the number of votes. Herders always select the majority of
the previous $r$ votes, which is visible to them. We call them digital herders.
We can accurately calculate the distribution of votes for special cases. When
r&gt;=3, we find that a phase transition occurs at the upper limit of t, where t
is the discrete time (or number of votes). As the fraction of herders
increases, the model features a phase transition beyond which a state where
most voters make the correct choice coexists with one where most of them are
wrong. On the other hand, when r&lt;3, there is no phase transition. In this case,
the herders' performance is the same as that of the independent voters.
Finally, we recognize the behavior of human beings by conducting simple
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3124</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3124</id><created>2011-01-17</created><authors><author><keyname>Xing</keyname><forenames>Xinyu</forenames></author><author><keyname>Liang</keyname><forenames>Yu-Li</forenames></author><author><keyname>Cheng</keyname><forenames>Hanqiang</forenames></author><author><keyname>Dang</keyname><forenames>Jianxun</forenames></author><author><keyname>Huang</keyname><forenames>Sui</forenames></author><author><keyname>Han</keyname><forenames>Richard</forenames></author><author><keyname>Liu</keyname><forenames>Xue</forenames></author><author><keyname>Lv</keyname><forenames>Qin</forenames></author><author><keyname>Mishra</keyname><forenames>Shivakant</forenames></author></authors><title>SafeVchat: Detecting Obscene Content and Misbehaving Users in Online
  Video Chat Services</title><categories>cs.CR cs.CV cs.HC</categories><comments>The 20th International World Wide Web Conference (WWW 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online video chat services such as Chatroulette, Omegle, and vChatter that
randomly match pairs of users in video chat sessions are fast becoming very
popular, with over a million users per month in the case of Chatroulette. A key
problem encountered in such systems is the presence of flashers and obscene
content. This problem is especially acute given the presence of underage minors
in such systems. This paper presents SafeVchat, a novel solution to the problem
of flasher detection that employs an array of image detection algorithms. A key
contribution of the paper concerns how the results of the individual detectors
are fused together into an overall decision classifying the user as misbehaving
or not, based on Dempster-Shafer Theory. The paper introduces a novel,
motion-based skin detection method that achieves significantly higher recall
and better precision. The proposed methods have been evaluated over real world
data and image traces obtained from Chatroulette.com.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3126</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3126</id><created>2011-01-17</created><authors><author><keyname>Chen</keyname><forenames>Lily</forenames></author><author><keyname>Li</keyname><forenames>Xueliang</forenames></author><author><keyname>Shi</keyname><forenames>Yongtang</forenames></author></authors><title>The complexity of determining the rainbow vertex-connection of graphs</title><categories>math.CO cs.DM</categories><comments>7 pages</comments><msc-class>05C15, 05C40, 68Q25, 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A vertex-colored graph is {\it rainbow vertex-connected} if any two vertices
are connected by a path whose internal vertices have distinct colors, which was
introduced by Krivelevich and Yuster. The {\it rainbow vertex-connection} of a
connected graph $G$, denoted by $rvc(G)$, is the smallest number of colors that
are needed in order to make $G$ rainbow vertex-connected. In this paper, we
study the computational complexity of vertex-rainbow connection of graphs and
prove that computing $rvc(G)$ is NP-Hard. Moreover, we show that it is already
NP-Complete to decide whether $rvc(G)=2$. We also prove that the following
problem is NP-Complete: given a vertex-colored graph $G$, check whether the
given coloring makes $G$ rainbow vertex-connected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3132</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3132</id><created>2011-01-17</created><authors><author><keyname>Regenboog</keyname><forenames>Chris</forenames></author></authors><title>Reactive Valuations</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sequential logic there is an order in which the atomic propositions in an
expression are evaluated. This order allows the same atomic proposition to have
different values depending on which atomic propositions have already been
evaluated. In the sequential propositional logic discussed in this thesis, such
valuations are called &quot;reactive&quot; valuations, in contrast to &quot;static&quot; valuations
as are common in e.g. ordinary propositional logic. There are many classes of
these reactive valuations e.g., we can define a class of reactive valuations
such that the value for each atomic proposition remains the same until another
atomic proposition is evaluated. This Master of Logic thesis consists of a
study of some of the properties of this logic. We take a closer look at some of
the classes of reactive valuations. We particularly focus on the relation
between the axiomatization and the semantics. Consequently, the main part of
this thesis focuses on proving soundness and completeness. Furthermore, we show
that the axioms in the provided axiomatizations are independent i.e., there are
no redundant axioms present. Finally, we show {\omega}-completeness for two
classes of reactive valuations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3140</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3140</id><created>2011-01-17</created><authors><author><keyname>Mantzaflaris</keyname><forenames>Angelos</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Deflation and Certified Isolation of Singular Zeros of Polynomial
  Systems</title><categories>cs.SC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new symbolic-numeric algorithm for the certification of singular
isolated points, using their associated local ring structure and certified
numerical computations. An improvement of an existing method to compute inverse
systems is presented, which avoids redundant computation and reduces the size
of the intermediate linear systems to solve. We derive a one-step deflation
technique, from the description of the multiplicity structure in terms of
differentials. The deflated system can be used in Newton-based iterative
schemes with quadratic convergence. Starting from a polynomial system and a
small-enough neighborhood, we obtain a criterion for the existence and
uniqueness of a singular root of a given multiplicity structure, applying a
well-chosen symbolic perturbation. Standard verification methods, based eg. on
interval arithmetic and a fixed point theorem, are employed to certify that
there exists a unique perturbed system with a singular root in the domain.
Applications to topological degree computation and to the analysis of real
branches of an implicit curve illustrate the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3149</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3149</id><created>2011-01-17</created><updated>2011-01-20</updated><authors><author><keyname>Zhao</keyname><forenames>Ming</forenames></author><author><keyname>Zhou</keyname><forenames>Changsong</forenames></author><author><keyname>L&#xfc;</keyname><forenames>Jinhu</forenames></author><author><keyname>Lai</keyname><forenames>Choy Heng</forenames></author></authors><title>Competition between Intra-community and Inter-community Synchronization</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the effects of external links on the synchronization
performance of community networks, especially on the competition between
individual community and the whole network, are studied in detail. The study is
organized from two aspects: the number or portion of external links and the
connecting strategy of external links between different communities. It is
found that increasing the number of external links will enhance the global
synchronizability but degrade the ynchronization performance of individual
community before some critical point. After that the individual community will
synchronize better and better as part of the whole network because the
community structure is not so prominent. Among various connection strategies,
connecting nodes belonging to different communities randomly rather than
connecting nodes with larger degrees is the most efficient way to enhance
global synchronization of the network. However, a preferential connection
scheme linking most of the hubs from the communities will allow rather
efficient global synchronization while maintaining strong dynamical clustering
of the communities. Interestingly, the observations are found to be relevant in
a realistic network of cat cortex. The synchronization state is just at the
critical point, which shows a reasonable combination of segregated function in
individual communities and coordination among them. Our work sheds light on
principles underlying the emergence of modular architectures in real network
systems and provides guidance for the manipulation of synchronization in
community networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3161</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3161</id><created>2011-01-17</created><authors><author><keyname>Bentivegna</keyname><forenames>Eloisa</forenames></author><author><keyname>Allen</keyname><forenames>Gabrielle</forenames></author><author><keyname>Korobkin</keyname><forenames>Oleg</forenames></author><author><keyname>Schnetter</keyname><forenames>Erik</forenames></author></authors><title>Ensuring Correctness at the Application Level: a Software Framework
  Approach</title><categories>cs.SE cs.DC</categories><comments>11 pages, 5 figures, presented at the 2009 Workshop on
  Component-Based High Performance Computing (CBHPC 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As scientific applications extend to the simulation of more and more complex
systems, they involve an increasing number of abstraction levels, at each of
which errors can emerge and across which they can propagate; tools for
correctness evaluation and enforcement at every level (from the code level to
the application level) are therefore necessary. Whilst code-level debugging
tools are already a well established standard, application-level tools are
lagging behind, possibly due to their stronger dependence on the application's
details. In this paper, we describe the programming model introduced by the
Cactus framework, review the High Performance Computing (HPC) challenges that
Cactus is designed to address, and illustrate the correctness strategies that
are currently available in Cactus at the code, component, and application
level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3182</identifier>
 <datestamp>2011-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3182</id><created>2011-01-17</created><updated>2011-11-14</updated><authors><author><keyname>Hlineny</keyname><forenames>Petr</forenames></author><author><keyname>Moris</keyname><forenames>Ondrej</forenames></author></authors><title>Multi-Stage Improved Route Planning Approach: theoretical foundations</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach to the static route planning problem, based on a multi-staging
concept and a \emph{scope} notion, is presented. The main goal (besides implied
efficiency of planning) of our approach is to address---with a solid
theoretical foundation---the following two practically motivated aspects: a
\emph{route comfort} and a very \emph{limited storage} space of a small
navigation device, which both do not seem to be among the chief objectives of
many other studies. We show how our novel idea can tackle both these seemingly
unrelated aspects at once, and may also contribute to other established route
planning approaches with which ours can be naturally combined. We provide a
theoretical proof that our approach efficiently computes exact optimal routes
within this concept, as well as we demonstrate with experimental results on
publicly available road networks of the US the good practical performance of
the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3186</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3186</id><created>2011-01-17</created><authors><author><keyname>South</keyname><forenames>David M.</forenames></author></authors><title>Data Preservation in High Energy Physics</title><categories>hep-ex cs.DL physics.data-an</categories><comments>Proceedings of plenary talk given at the 18th International
  Conference on Computing in High Energy and Nuclear Physics (CHEP 2010). 10
  pages, 9 figures</comments><report-no>CHEP 2010</report-no><doi>10.1088/1742-6596/331/1/012005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data from high-energy physics (HEP) experiments are collected with
significant financial and human effort and are in many cases unique. At the
same time, HEP has no coherent strategy for data preservation and re-use, and
many important and complex data sets are simply lost. In a period of a few
years, several important and unique experimental programs will come to an end,
including those at HERA, the b-factories and at the Tevatron. An
inter-experimental study group on HEP data preservation and long-term analysis
(DPHEP) was formed and a series of workshops were held to investigate this
issue in a systematic way. The physics case for data preservation and the
preservation models established by the group are presented, as well as a
description of the transverse global projects and strategies already in place.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3188</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3188</id><created>2011-01-17</created><authors><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>A note on triangle-free graphs</title><categories>cs.DM</categories><comments>4 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that if $G$ is a simple triangle-free graph with $n\geq 3$ vertices,
without a perfect matching, and having a minimum degree at least
$\frac{n-1}{2}$, then $G$ is isomorphic either to $C_5$ or to
$K_{\frac{n-1}{2},\frac{n+1}{2}}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3198</identifier>
 <datestamp>2014-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3198</id><created>2011-01-17</created><updated>2014-09-04</updated><authors><author><keyname>Stein</keyname><forenames>Manuel</forenames></author></authors><title>Towards Optimal Schemes for the Half-Duplex Two-Way Relay Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A restricted two-way communication problem in a small fully-connected network
is investigated. The network consists of three nodes, all having access to a
common channel with half-duplex constraint. Two nodes want to establish a
dialog while the third node can assist in the bi-directional transmission
process. All nodes have agreed on a transmission protocol a priori and the
problem is restricted to the dialog encoders not being allowed to establish a
cooperation by the use of previous receive signals. The channel is referred to
as the restricted half-duplex two-way relay channel. Here the channel is
defined and an outer bound on the achievable rates is derived by the
application of the cut-set theorem. This shows that the problem consists of six
parts. We propose a transmission protocol which takes into account all possible
transmit-receive configurations of the network and performs partial decoding of
the messages at the relay as well as sequential decoding at the dialog nodes.
By the use of random codes and suboptimal decoders, two inner bound on the
achievable rates are derived. Restricting to the suggested strategies and fixed
input distributions it is argued to be possible to determine optimal
transmission schemes with respect to various reasonable objectives at low
complexity. In comparison to two-way communication without relay, simulations
for an AWGN channel model then show that it is possible to simultaneously
increase the communication rates of both dialog messages and to outperform
relaying strategies that ignore an available direct path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3212</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3212</id><created>2011-01-17</created><updated>2011-08-19</updated><authors><author><keyname>Karelsky</keyname><forenames>K. V.</forenames></author><author><keyname>Petrosyan</keyname><forenames>A. S.</forenames></author><author><keyname>Slavin</keyname><forenames>A. G.</forenames></author></authors><title>Quasi-two-layer finite-volume scheme for modeling shallow water flows
  with the presence of external forces</title><categories>physics.flu-dyn cs.NA math-ph math.MP physics.ao-ph physics.comp-ph</categories><comments>47 pages, submited to Computers and Fluids, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite-volume numerical method for study shallow water flows over an
arbitrary bed profile in the presence of external force is proposed. This
method uses the quasi-two-layer model of hydrodynamic flows over a stepwise
boundary with advanced consideration of the flow features near the step. A
distinctive feature of the suggested model is a separation of a studied flow
into two layers in calculating flow quantities near each step, and improving by
this means approximation of depth-averaged solutions of the initial
three-dimensional Euler equations. We are solving the shallow-water equations
for one layer, introducing the fictitious lower layer only as an auxiliary
structure in setting up the appropriate Riemann problems for the upper layer.
Besides quasi-two-layer approach leads to appearance of additional terms in
one-layer finite-difference representation of balance equations. These terms
provide the mechanical work made by nonhomogeneous bed interacting with flow. A
notable advantage of the proposed method is the consideration of the properties
of the process of the waterfall, namely the fluid flow on the step in which the
fluid does not wet part of the vertical wall of the step. The presence of dry
zones in the vertical part of the step indicates violation of the conditions of
hydrostatic flow. The quasi-two-layer approach determines the size of the dry
zone of the vertical component of the step. Consequently it gives an
opportunity to figure out the amount of flow kinetic energy dissipation on
complex boundary. Numerical simulations are performed based on the proposed
algorithm of various physical phenomena, such as a breakdown of the rectangular
fluid column over an inclined plane, large-scale motion of fluid in the gravity
field in the presence of Coriolis force over an mounted obstacle on underlying
surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3214</identifier>
 <datestamp>2012-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3214</id><created>2011-01-17</created><updated>2011-05-27</updated><authors><author><keyname>Sabato</keyname><forenames>Giovanni</forenames></author><author><keyname>Molkaraie</keyname><forenames>Mehdi</forenames></author></authors><title>Generalized Belief Propagation for the Noiseless Capacity and
  Information Rates of Run-Length Limited Constraints</title><categories>cs.IT math.IT stat.CO</categories><comments>8 pages, 11 figures</comments><journal-ref>IEEE Transactions on Communications, Volume 60, March 2012, pages
  669 - 675</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of the generalized belief propagation algorithm for computing
the noiseless capacity and mutual information rates of finite-size
two-dimensional and three-dimensional run-length limited constraints is
investigated. For each constraint, a method is proposed to choose the basic
regions and to construct the region graph. Simulation results for the capacity
of different constraints as a function of the size of the channel and mutual
information rates of different constraints as a function of signal-to-noise
ratio are reported. Convergence to the Shannon capacity is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3218</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3218</id><created>2011-01-17</created><updated>2013-12-10</updated><authors><author><keyname>Belkhir</keyname><forenames>Walid</forenames></author><author><keyname>Giorgetti</keyname><forenames>Alain</forenames></author><author><keyname>Lenczner</keyname><forenames>Michel</forenames></author></authors><title>A Symbolic Transformation Language and its Application to a Multiscale
  Method</title><categories>cs.SC cs.MS</categories><comments>36 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The context of this work is the design of a software, called MEMSALab,
dedicated to the automatic derivation of multiscale models of arrays of micro-
and nanosystems. In this domain a model is a partial differential equation.
Multiscale methods approximate it by another partial differential equation
which can be numerically simulated in a reasonable time. The challenge consists
in taking into account a wide range of geometries combining thin and periodic
structures with the possibility of multiple nested scales.
  In this paper we present a transformation language that will make the
development of MEMSALab more feasible. It is proposed as a Maple package for
rule-based programming, rewriting strategies and their combination with
standard Maple code. We illustrate the practical interest of this language by
using it to encode two examples of multiscale derivations, namely the two-scale
limit of the derivative operator and the two-scale model of the stationary heat
equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3220</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3220</id><created>2011-01-17</created><authors><author><keyname>Schenk</keyname><forenames>Andreas</forenames></author><author><keyname>Fischer</keyname><forenames>Robert F. H.</forenames></author></authors><title>Decision-Feedback Differential Detection in Impulse-Radio Ultra-Wideband
  Systems</title><categories>cs.IT math.IT</categories><comments>Preprint of manuscript accepted for presentation in &quot;IEEE
  Transactions on Communications&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present decision-feedback differential detection (DF-DD)
schemes for autocorrelation-based detection in impulse-radio ultra-wideband
(IR-UWB) systems, a signaling scheme regarded as a promising candidate in
particular for low-complexity wireless sensor networks. To this end, we first
discuss ideal noncoherent sequence estimation and approximations thereof based
on block-wise multiple-symbol differential detection (MSDD) and the Viterbi
algorithm (VA) from the perspective of tree-search/trellis decoding. Exploiting
relations well-known from tree-search decoding, we are able to derive the novel
decision-feedback differential detection (DF-DD) schemes. A comprehensive
comparison with respect to performance and complexity of the presented schemes
in a typical IR-UWB scenario reveals---along with novel insights in techniques
for complexity reduction of the sphere decoder applied for MSDD---that sorted
DF-DD achieves close-to-optimum performance at very low, and in particular
constant receiver complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3262</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3262</id><created>2011-01-17</created><updated>2011-03-31</updated><authors><author><keyname>Bengtson</keyname><forenames>Jesper</forenames><affiliation>Uppsala University, Sweden</affiliation></author><author><keyname>Johansson</keyname><forenames>Magnus</forenames><affiliation>Uppsala University, Sweden</affiliation></author><author><keyname>Parrow</keyname><forenames>Joachim</forenames><affiliation>Uppsala University, Sweden</affiliation></author><author><keyname>Victor</keyname><forenames>Bj&#xc3;&#xb6;rn</forenames><affiliation>Uppsala University, Sweden</affiliation></author></authors><title>Psi-calculi: a framework for mobile processes with nominal data and
  logic</title><categories>cs.LO</categories><comments>44 pages</comments><proxy>LMCS</proxy><acm-class>F.1.2, F.3.1, F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 29,
  2011) lmcs:696</journal-ref><doi>10.2168/LMCS-7(1:11)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The framework of psi-calculi extends the pi-calculus with nominal datatypes
for data structures and for logical assertions and conditions. These can be
transmitted between processes and their names can be statically scoped as in
the standard pi-calculus. Psi-calculi can capture the same phenomena as other
proposed extensions of the pi-calculus such as the applied pi-calculus, the
spi-calculus, the fusion calculus, the concurrent constraint pi-calculus, and
calculi with polyadic communication channels or pattern matching. Psi-calculi
can be even more general, for example by allowing structured channels,
higher-order formalisms such as the lambda calculus for data structures, and
predicate logic for assertions. We provide ample comparisons to related calculi
and discuss a few significant applications. Our labelled operational semantics
and definition of bisimulation is straightforward, without a structural
congruence. We establish minimal requirements on the nominal data and logic in
order to prove general algebraic properties of psi-calculi, all of which have
been checked in the interactive theorem prover Isabelle. Expressiveness of
psi-calculi significantly exceeds that of other formalisms, while the purity of
the semantics is on par with the original pi-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3267</identifier>
 <datestamp>2014-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3267</id><created>2011-01-17</created><authors><author><keyname>Hemmecke</keyname><forenames>Raymond</forenames></author><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author><author><keyname>Romanchuk</keyname><forenames>Lyubov</forenames></author></authors><title>N-fold integer programming in cubic time</title><categories>math.OC cs.DM cs.DS math.CO</categories><msc-class>05A, 15A, 51M, 52A, 52B, 52C, 62H, 68Q, 68R, 68U, 68W, 90B, 90C</msc-class><journal-ref>Mathematical Programming, 137:325--341, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  N-fold integer programming is a fundamental problem with a variety of natural
applications in operations research and statistics. Moreover, it is universal
and provides a new, variable-dimension, parametrization of all of integer
programming. The fastest algorithm for $n$-fold integer programming predating
the present article runs in time $O(n^{g(A)}L)$ with $L$ the binary length of
the numerical part of the input and $g(A)$ the so-called Graver complexity of
the bimatrix $A$ defining the system. In this article we provide a drastic
improvement and establish an algorithm which runs in time $O(n^3 L)$ having
cubic dependency on $n$ regardless of the bimatrix $A$. Our algorithm can be
extended to separable convex piecewise affine objectives as well, and also to
systems defined by bimatrices with variable entries. Moreover, it can be used
to define a hierarchy of approximations for any integer programming problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3285</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3285</id><created>2011-01-17</created><updated>2011-01-24</updated><authors><author><keyname>Huang</keyname><forenames>Shurui</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author></authors><title>A note on the multiple unicast capacity of directed acyclic networks</title><categories>cs.IT math.IT</categories><comments>ICC, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the multiple unicast problem under network coding over directed
acyclic networks with unit capacity edges. There is a set of n source-terminal
(s_i - t_i) pairs that wish to communicate at unit rate over this network. The
connectivity between the s_i - t_i pairs is quantified by means of a
connectivity level vector, [k_1 k_2 ... k_n] such that there exist k_i
edge-disjoint paths between s_i and t_i. Our main aim is to characterize the
feasibility of achieving this for different values of n and [k_1 ... k_n]. For
3 unicast connections (n = 3), we characterize several achievable and
unachievable values of the connectivity 3-tuple. In addition, in this work, we
have found certain network topologies, and capacity characterizations that are
useful in understanding the case of general n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3291</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3291</id><created>2011-01-17</created><authors><author><keyname>Bhagat</keyname><forenames>Smriti</forenames></author><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Node Classification in Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>To appear in Social Network Data Analytics (Springer) Ed. Charu
  Aggarwal, March 2011</comments><doi>10.1007/978-1-4419-8462-3_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When dealing with large graphs, such as those that arise in the context of
online social networks, a subset of nodes may be labeled. These labels can
indicate demographic values, interest, beliefs or other characteristics of the
nodes (users). A core problem is to use this information to extend the labeling
so that all nodes are assigned a label (or labels). In this chapter, we survey
classification techniques that have been proposed for this problem. We consider
two broad categories: methods based on iterative application of traditional
classifiers using graph information as features, and methods which propagate
the existing labels via random walks. We adopt a common perspective on these
methods to highlight the similarities between different approaches within and
across the two categories. We also describe some extensions and related
directions to the central problem of node classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3297</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3297</id><created>2011-01-17</created><updated>2011-02-16</updated><authors><author><keyname>King</keyname><forenames>James</forenames></author></authors><title>Fast Vertex Guarding for Polygons</title><categories>cs.CG</categories><comments>18 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a polygon P with n vertices, the vertex guarding problem asks for the
minimum subset G of P's vertices such that every point in P is seen by at least
one point in G. This problem is NP-complete and APX-hard. The first
approximation algorithm (Ghosh, 1987) involves decomposing P into O(n^4) cells
that are equivalence classes for visibility from the vertices of P. This
discretized problem can then be treated as an instance of set cover and solved
in O(n^5) time with a greedy O(log n)-approximation algorithm. Ghosh (2010)
recently revisited the algorithm, noting that minimum visibility decompositions
for simple polygons (Bose et al., 2000) have only O(n^3) cells, improving the
running time of the algorithm to O(n^4) for simple polygons.
  In this paper we show that, since minimum visibility decompositions for
simple polygons have only O(n^2) cells of minimal visibility (Bose et al.,
2000), the running time of the algorithm can be further improved to O(n^3).
This result was obtained independently by Jang and Kwon (2011). We extend the
result of Bose et al. to polygons with holes, showing that a minimum visibility
decomposition of a polygon with h holes has only O((h+1)n^3) cells and only
O((h+1)^2 n^2) cells of minimal visibility. We exploit this result to obtain a
faster algorithm for vertex guarding polygons with holes. We then show that, in
the same time complexity, we can attain approximation factors of O(log
log(opt)) for simple polygons and O((1+\log((h+1))) log(opt)) for polygons with
holes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3341</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3341</id><created>2011-01-17</created><authors><author><keyname>Basso</keyname><forenames>Alessandro</forenames></author><author><keyname>Milanesio</keyname><forenames>Marco</forenames></author><author><keyname>Panisson</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Ruffo</keyname><forenames>Giancarlo</forenames></author></authors><title>Collaborative Filtering without Explicit Feedbacks for Digital Recorders</title><categories>cs.IR cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommendation is usually reduced to a prediction problem over the function
$r(u_a, e_i)$ that returns the expected rating of element $e_i$ for user $u_a$.
In the IPTV domain, we deal with an environment where the definitions of all
the parameters involved in this function (i.e., user profiles, feedback ratings
and elements) are controversial. To our knowledge, this paper represents the
first attempt to run collaborative filtering algorithms without inner
assumptions: we start our analysis from an unstructured set of recordings,
before performing a data pre-processing phase in order to extract useful
information. Hence, we experiment with a real Digital Video Recorder system
where EPG have not been provided to the user for selecting event timings and
where explicit feedbacks were not collected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3348</identifier>
 <datestamp>2011-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3348</id><created>2011-01-17</created><updated>2011-07-11</updated><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author><author><keyname>Pham</keyname><forenames>Hoa Vin</forenames></author></authors><title>Structured sublinear compressive sensing via belief propagation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) is a sampling technique designed for reducing the
complexity of sparse data acquisition. One of the major obstacles for practical
deployment of CS techniques is the signal reconstruction time and the high
storage cost of random sensing matrices. We propose a new structured
compressive sensing scheme, based on codes of graphs, that allows for a joint
design of structured sensing matrices and logarithmic-complexity reconstruction
algorithms. The compressive sensing matrices can be shown to offer
asymptotically optimal performance when used in combination with Orthogonal
Matching Pursuit (OMP) methods. For more elaborate greedy reconstruction
schemes, we propose a new family of list decoding belief propagation
algorithms, as well as reinforced- and multiple-basis belief propagation
algorithms. Our simulation results indicate that reinforced BP CS schemes offer
very good complexity-performance tradeoffs for very sparse signal vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3352</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3352</id><created>2011-01-17</created><authors><author><keyname>Bobkov</keyname><forenames>Sergey</forenames></author><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author></authors><title>Dimensional behaviour of entropy and information</title><categories>math.FA cs.IT math.IT math.PR</categories><comments>6 pages</comments><journal-ref>C. R. Acad. Sci. Paris, Ser. I 349 (2011), pp. 201--204</journal-ref><doi>10.1016/j.crma.2011.01.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an information-theoretic perspective on some questions in convex
geometry, providing for instance a new equipartition property for log-concave
probability measures, some Gaussian comparison results for log-concave
measures, an entropic formulation of the hyperplane conjecture, and a new
reverse entropy power inequality for log-concave measures analogous to V.
Milman's reverse Brunn-Minkowski inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3354</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3354</id><created>2011-01-17</created><authors><author><keyname>O'Hara</keyname><forenames>Stephen</forenames></author><author><keyname>Draper</keyname><forenames>Bruce A.</forenames></author></authors><title>Introduction to the Bag of Features Paradigm for Image Classification
  and Retrieval</title><categories>cs.CV cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past decade has seen the growing popularity of Bag of Features (BoF)
approaches to many computer vision tasks, including image classification, video
search, robot localization, and texture recognition. Part of the appeal is
simplicity. BoF methods are based on orderless collections of quantized local
image descriptors; they discard spatial information and are therefore
conceptually and computationally simpler than many alternative methods. Despite
this, or perhaps because of this, BoF-based systems have set new performance
standards on popular image classification benchmarks and have achieved
scalability breakthroughs in image retrieval. This paper presents an
introduction to BoF image representations, describes critical design choices,
and surveys the BoF literature. Emphasis is placed on recent techniques that
mitigate quantization errors, improve feature detection, and speed up image
retrieval. At the same time, unresolved issues and fundamental challenges are
raised. Among the unresolved issues are determining the best techniques for
sampling images, describing local image features, and evaluating system
performance. Among the more fundamental challenges are how and whether BoF
methods can contribute to localizing objects in complex images, or to
associating high-level semantics with natural images. This survey should be
useful both for introducing new investigators to the field and for providing
existing researchers with a consolidated reference to related work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3356</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3356</id><created>2011-01-17</created><updated>2011-01-19</updated><authors><author><keyname>Shafarenko</keyname><forenames>Alex</forenames></author><author><keyname>Kirner</keyname><forenames>Raimund</forenames></author></authors><title>CAL: A Language for Aggregating Functional and Extrafunctional
  Constraints in Streaming Networks</title><categories>cs.PL cs.DC</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present the {\em Constraint Aggregation Language} (CAL), a
declarative language for describing properties of stateless program components
that interact by exchanging messages. CAL allows one to describe functional as
well as extra-functional behaviours, such as computation latency. The CAL
language intention is to be able to describe the behaviour of so-called boxes
in the context of S-Net. However, the language would find application in other
coordination models based on stateless components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3381</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3381</id><created>2011-01-17</created><authors><author><keyname>Bromberg</keyname><forenames>Facundo</forenames></author><author><keyname>Schl&#xfc;ter</keyname><forenames>Federico</forenames></author></authors><title>Efficient Independence-Based MAP Approach for Robust Markov Networks
  Structure Discovery</title><categories>cs.AI cs.CV</categories><comments>28 pages, 8 figures and 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work introduces the IB-score, a family of independence-based score
functions for robust learning of Markov networks independence structures.
Markov networks are a widely used graphical representation of probability
distributions, with many applications in several fields of science. The main
advantage of the IB-score is the possibility of computing it without the need
of estimation of the numerical parameters, an NP-hard problem, usually solved
through an approximate, data-intensive, iterative optimization. We derive a
formal expression for the IB-score from first principles, mainly maximum a
posteriori and conditional independence properties, and exemplify several
instantiations of it, resulting in two novel algorithms for structure learning:
IBMAP-HC and IBMAP-TS. Experimental results over both artificial and real world
data show these algorithms achieve important error reductions in the learnt
structures when compared with the state-of-the-art independence-based structure
learning algorithm GSMN, achieving increments of more than 50% in the amount of
independencies they encode correctly, and in some cases, learning correctly
over 90% of the edges that GSMN learnt incorrectly. Theoretical analysis shows
IBMAP-HC proceeds efficiently, achieving these improvements in a time
polynomial to the number of random variables in the domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3382</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3382</id><created>2011-01-17</created><updated>2011-02-21</updated><authors><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Dingkang</forenames></author></authors><title>A Generalized Criterion for Signature Related Gr\&quot;obner Basis Algorithms</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalized criterion for signature related algorithms to compute Gr\&quot;obner
basis is proposed in this paper. Signature related algorithms are a popular
kind of algorithms for computing Gr\&quot;obner basis, including the famous F5
algorithm, the extended F5 algorithm and the GVW algorithm. The main purpose of
current paper is to study in theory what kind of criteria is correct in
signature related algorithms and provide a generalized method to develop new
criteria. For this purpose, a generalized criterion is proposed. The
generalized criterion only relies on a general partial order defined on a set
of polynomials. When specializing the partial order to appropriate specific
orders, the generalized criterion can specialize to almost all existing
criteria of signature related algorithms. For {\em admissible} partial orders,
a complete proof of the correctness of the algorithm based on this generalized
criterion is also presented. This proof has no extra requirements on the
computing order of critical pairs, and is also valid for non-homogeneous
polynomial systems. More importantly, the partial orders implied by existing
criteria are admissible. Besides, one can also check whether a new criterion is
correct in signature related algorithms or even develop new criteria by using
other admissible partial orders in the generalized criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3391</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3391</id><created>2011-01-18</created><authors><author><keyname>Riess</keyname><forenames>Thorsten</forenames></author><author><keyname>Dietz</keyname><forenames>Christian</forenames></author><author><keyname>Tomas</keyname><forenames>Martin</forenames></author><author><keyname>Ferrando-May</keyname><forenames>Elisa</forenames></author><author><keyname>Merhof</keyname><forenames>Dorit</forenames></author></authors><title>Automated Image Processing for the Analysis of DNA Repair Dynamics</title><categories>cs.CV q-bio.QM</categories><msc-class>68U10</msc-class><acm-class>J.3; I.4.6; I.4.7; I.4.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficient repair of cellular DNA is essential for the maintenance and
inheritance of genomic information. In order to cope with the high frequency of
spontaneous and induced DNA damage, a multitude of repair mechanisms have
evolved. These are enabled by a wide range of protein factors specifically
recognizing different types of lesions and finally restoring the normal DNA
sequence. This work focuses on the repair factor XPC (xeroderma pigmentosum
complementation group C), which identifies bulky DNA lesions and initiates
their removal via the nucleotide excision repair pathway. The binding of XPC to
damaged DNA can be visualized in living cells by following the accumulation of
a fluorescent XPC fusion at lesions induced by laser microirradiation in a
fluorescence microscope. In this work, an automated image processing pipeline
is presented which allows to identify and quantify the accumulation reaction
without any user interaction. The image processing pipeline comprises a
preprocessing stage where the image stack data is filtered and the nucleus of
interest is segmented. Afterwards, the images are registered to each other in
order to account for movements of the cell, and then a bounding box enclosing
the XPC-specific signal is automatically determined. Finally, the
time-dependent relocation of XPC is evaluated by analyzing the intensity change
within this box. Comparison of the automated processing results with the manual
evaluation yields qualitatively similar results. However, the automated
analysis provides more accurate, reproducible data with smaller standard
errors. The image processing pipeline presented in this work allows for an
efficient analysis of large amounts of experimental data with no user
interaction required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3393</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3393</id><created>2011-01-18</created><authors><author><keyname>Hayashi</keyname><forenames>Yukio</forenames></author><author><keyname>Ono</keyname><forenames>Yasumasa</forenames></author></authors><title>Traffic properties for stochastic routings on scale-free networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>12 pages, 10 figures, 6 tables</comments><journal-ref>IEICE Trans. on Communication, Vol.E94-B, No.5, pp.1311-1322, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For realistic scale-free networks, we investigate the traffic properties of
stochastic routing inspired by a zero-range process known in statistical
physics. By parameters $\alpha$ and $\delta$, this model controls
degree-dependent hopping of packets and forwarding of packets with higher
performance at more busy nodes. Through a theoretical analysis and numerical
simulations, we derive the condition for the concentration of packets at a few
hubs. In particular, we show that the optimal $\alpha$ and $\delta$ are
involved in the trade-off between a detour path for $\alpha &lt; 0$ and long wait
at hubs for $\alpha &gt; 0$; In the low-performance regime at a small $\delta$,
the wandering path for $\alpha &lt; 0$ better reduces the mean travel time of a
packet with high reachability. Although, in the high-performance regime at a
large $\delta$, the difference between $\alpha &gt; 0$ and $\alpha &lt; 0$ is small,
neither the wandering long path with short wait trapped at nodes ($\alpha =
-1$), nor the short hopping path with long wait trapped at hubs ($\alpha = 1$)
is advisable. A uniformly random walk ($\alpha = 0$) yields slightly better
performance. We also discuss the congestion phenomena in a more complicated
situation with packet generation at each time step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3396</identifier>
 <datestamp>2013-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3396</id><created>2011-01-18</created><authors><author><keyname>Dridi</keyname><forenames>Imen Harbaoui</forenames><affiliation>LAGIS, ACS</affiliation></author><author><keyname>Kammarti</keyname><forenames>Ryan</forenames><affiliation>ACS</affiliation></author><author><keyname>Borne</keyname><forenames>Pierre</forenames><affiliation>LAGIS</affiliation></author><author><keyname>Ksouri</keyname><forenames>Mekki</forenames><affiliation>ACS</affiliation></author></authors><title>Multi-objective Optimization For The Dynamic Multi-Pickup and Delivery
  Problem with Time Windows</title><categories>cs.DS</categories><comments>arXiv admin note: text overlap with arXiv:1101.3396</comments><proxy>ccsd</proxy><journal-ref>META'2010, Tunisia (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The PDPTW is an optimization vehicles routing problem which must meet
requests for transport between suppliers and customers satisfying precedence,
capacity and time constraints. We present, in this paper, a genetic algorithm
for multi-objective optimization of a dynamic multi pickup and delivery problem
with time windows (Dynamic m-PDPTW). We propose a brief literature review of
the PDPTW, present our approach based on Pareto dominance method and lower
bounds, to give a satisfying solution to the Dynamic m-PDPTW minimizing the
compromise between total travel cost and total tardiness time. Computational
results indicate that the proposed algorithm gives good results with a total
tardiness equal to zero with a tolerable cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3398</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3398</id><created>2011-01-18</created><authors><author><keyname>Ma</keyname><forenames>Wenping</forenames></author></authors><title>New Quadriphase Sequences families with Larger Linear Span and Size</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, new families of quadriphase sequences with larger linear span
and size have been proposed and studied. In particular, a new family of
quadriphase sequences of period $2^n-1$ for a positive integer $n=em$ with an
even positive factor $m$ is presented, the cross-correlation function among
these sequences has been explicitly calculated. Another new family of
quadriphase sequences of period $2(2^n-1)$ for a positive integer $n=em$ with
an even positive factor $m$ is also presented, a detailed analysis of the
cross-correlation function of proposed sequences has also been presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3400</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3400</id><created>2011-01-18</created><authors><author><keyname>Caruso</keyname><forenames>Fabrizio</forenames></author><author><keyname>Giuffrida</keyname><forenames>Giovanni</forenames></author><author><keyname>Zarba</keyname><forenames>Calogero</forenames></author></authors><title>Behavioral On-Line Advertising</title><categories>cs.IR</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm for behavioral targeting of banner advertisements.
We record different user's actions such as clicks, search queries and page
views. We use the collected information on the user to estimate in real time
the probability of a click on a banner. A banner is displayed if it either has
the highest probability of being clicked or if it is the one that generates the
highest average profit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3417</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3417</id><created>2011-01-18</created><updated>2011-05-31</updated><authors><author><keyname>Duval</keyname><forenames>Dominique</forenames></author><author><keyname>Echahed</keyname><forenames>Rachid</forenames></author><author><keyname>Prost</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author></authors><title>Categorical Abstract Rewriting Systems and Functoriality of Graph
  Transformation</title><categories>cs.LO</categories><msc-class>97P20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rewriting systems are often defined as binary relations over a given set of
objects. This simple definition is used to describe various properties of
rewriting such as termination, confluence, normal forms etc. In this paper, we
introduce a new notion of abstract rewriting in the framework of categories.
Then, we define the functoriality property of rewriting systems. This property
is sometimes called vertical composition. We show that most of graph
transformation systems are functorial and provide a counter-example of graph
transformation systems which is not functorial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3443</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3443</id><created>2011-01-18</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>Borel Hierarchy and Omega Context Free Languages</title><categories>cs.LO math.LO</categories><proxy>ccsd</proxy><journal-ref>Theoretical Computer Science 290 (3) (2003) 1385-1405</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give in this paper additional answers to questions of Lescow and Thomas
[Logical Specifications of Infinite Computations, In:&quot;A Decade of Concurrency&quot;,
Springer LNCS 803 (1994), 583-621], proving new topological properties of omega
context free languages : there exist some omega-CFL which are non Borel sets.
And one cannot decide whether an omega-CFL is a Borel set. We give also an
answer to questions of Niwinski and Simonnet about omega powers of finitary
languages, giving an example of a finitary context free language L such that
L^omega is not a Borel set. Then we prove some recursive analogues to preceding
properties: in particular one cannot decide whether an omega-CFL is an
arithmetical set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3444</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3444</id><created>2011-01-18</created><updated>2012-04-25</updated><authors><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author><author><keyname>Sarikaya</keyname><forenames>Yunus</forenames></author></authors><title>Control of Wireless Networks with Secrecy</title><categories>cs.IT cs.DC math.IT</categories><comments>To appear in IEEE/ACM Transactions on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of cross-layer resource allocation in time-varying
cellular wireless networks, and incorporate information theoretic secrecy as a
Quality of Service constraint. Specifically, each node in the network injects
two types of traffic, private and open, at rates chosen in order to maximize a
global utility function, subject to network stability and secrecy constraints.
The secrecy constraint enforces an arbitrarily low mutual information leakage
from the source to every node in the network, except for the sink node. We
first obtain the achievable rate region for the problem for single and
multi-user systems assuming that the nodes have full CSI of their neighbors.
Then, we provide a joint flow control, scheduling and private encoding scheme,
which does not rely on the knowledge of the prior distribution of the gain of
any channel. We prove that our scheme achieves a utility, arbitrarily close to
the maximum achievable utility. Numerical experiments are performed to verify
the analytical results, and to show the efficacy of the dynamic control
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3448</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3448</id><created>2011-01-18</created><authors><author><keyname>Fischer</keyname><forenames>Johannes</forenames></author></authors><title>Inducing the LCP-Array</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to modify the linear-time construction algorithm for suffix
arrays based on induced sorting (Nong et al., DCC'09) such that it computes the
array of longest common prefixes (LCP-array) as well. Practical tests show that
this outperforms recent LCP-array construction algorithms (Gog and Ohlebusch,
ALENEX'11).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3453</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3453</id><created>2011-01-18</created><authors><author><keyname>Malacaria</keyname><forenames>Pasquale</forenames></author></authors><title>Algebraic Foundations for Information Theoretical, Probabilistic and
  Guessability measures of Information Flow</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several mathematical ideas have been investigated for Quantitative
Information Flow. Information theory, probability, guessability are the main
ideas in most proposals. They aim to quantify how much information is leaked,
how likely is to guess the secret and how long does it take to guess the secret
respectively. In this paper, we show how the Lattice of Information provides a
valuable foundation for all these approaches; not only it provides an elegant
algebraic framework for the ideas, but also to investigate their relationship.
In particular we will use this lattice to prove some results establishing order
relation correspondences between the different quantitative approaches. The
implications of these results w.r.t. recent work in the community is also
investigated. While this work concentrates on the foundational importance of
the Lattice of Information its practical relevance has been recently proven,
notably with the quantitative analysis of Linux kernel vulnerabilities. Overall
we believe these works set the case for establishing the Lattice of Information
as one of the main reference structure for Quantitative Information Flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3457</identifier>
 <datestamp>2014-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3457</id><created>2011-01-18</created><authors><author><keyname>Balado</keyname><forenames>F&#xe9;lix</forenames></author></authors><title>Capacity of DNA Data Embedding Under Substitution Mutations</title><categories>cs.IT math.IT q-bio.PE q-bio.QM</categories><comments>22 pages, 13 figures; preliminary versions of this work were
  presented at the SPIE Media Forensics and Security XII conference (January
  2010) and at the IEEE ICASSP conference (March 2010)</comments><doi>10.1109/TIT.2012.2219495</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of methods have been proposed over the last decade for encoding
information using deoxyribonucleic acid (DNA), giving rise to the emerging area
of DNA data embedding. Since a DNA sequence is conceptually equivalent to a
sequence of quaternary symbols (bases), DNA data embedding (diversely called
DNA watermarking or DNA steganography) can be seen as a digital communications
problem where channel errors are tantamount to mutations of DNA bases.
Depending on the use of coding or noncoding DNA hosts, which, respectively,
denote DNA segments that can or cannot be translated into proteins, DNA data
embedding is essentially a problem of communications with or without side
information at the encoder. In this paper the Shannon capacity of DNA data
embedding is obtained for the case in which DNA sequences are subject to
substitution mutations modelled using the Kimura model from molecular evolution
studies. Inferences are also drawn with respect to the biological implications
of some of the results presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3465</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3465</id><created>2011-01-17</created><updated>2011-01-19</updated><authors><author><keyname>Gluskin</keyname><forenames>Emanuel</forenames></author></authors><title>The &quot;psychological map of the brain&quot;, as a personal information card
  (file), - a project for the student of the 21st century</title><categories>cs.AI</categories><comments>This is an unusual work, not easy for classification. I beg the
  readers' pardon for the excessive topical originality, but I tried to close
  the gap between the &quot;accelerating&quot; specialization causing one to forget the
  true Educational Side/Meaning that still can be found behind the modern
  science and technology. There are a lot of points to be developed, - one more
  disadvantage. 4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest a procedure that is relevant both to electronic performance and
human psychology, so that the creative logic and the respect for human nature
appear in a good agreement. The idea is to create an electronic card containing
basic information about a person's psychological behavior in order to make it
possible to quickly decide about the suitability of one for another. This
&quot;psychological electronics&quot; approach could be tested via student projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3500</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3500</id><created>2011-01-18</created><authors><author><keyname>Sun</keyname><forenames>Yajuan</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author><author><keyname>Liu</keyname><forenames>Fuchun</forenames></author></authors><title>Computation for Supremal Simulation-Based Controllable and Strong
  Observable Subautomata</title><categories>cs.SY</categories><comments>22 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bisimulation relation has been successfully applied to computer science and
control theory. In our previous work, simulation-based controllability and
simulation-based observability are proposed, under which the existence of
bisimilarity supervisor is guaranteed. However, a given specification automaton
may not satisfy these conditions, and a natural question is how to compute a
maximum permissive subspecification. This paper aims to answer this question
and investigate the computation of the supremal simulation-based controllable
and strong observable subautomata with respect to given specifications by the
lattice theory. In order to achieve the supremal solution, three monotone
operators, namely simulation operator, controllable operator and strong
observable operator, are proposed upon the established complete lattice. Then,
inequalities based on these operators are formulated, whose solution is the
simulation-based controllable and strong observable set. In particular, a
su?cient condition is presented to guarantee the existence of the supremal
simulation-based controllable and strong observable subautomata. Furthermore,
an algorithm is proposed to compute such subautomata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3520</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3520</id><created>2011-01-18</created><authors><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author></authors><title>Error-Free Multi-Valued Consensus with Byzantine Failures</title><categories>cs.DC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an efficient deterministic algorithm for consensus
in presence of Byzantine failures. Our algorithm achieves consensus on an
$L$-bit value with communication complexity $O(nL + n^4 L^{0.5} + n^6)$ bits,
in a network consisting of $n$ processors with up to $t$ Byzantine failures,
such that $t&lt;n/3$. For large enough $L$, communication complexity of the
proposed algorithm approaches $O(nL)$ bits. In other words, for large $L$, the
communication complexity is linear in the number of processors in the network.
This is an improvement over the work of Fitzi and Hirt (from PODC 2006), who
proposed a probabilistically correct multi-valued Byzantine consensus algorithm
with a similar complexity for large $L$. In contrast to the algorithm by Fitzi
and Hirt, our algorithm is guaranteed to be always error-free. Our algorithm
require no cryptographic technique, such as authentication, nor any secret
sharing mechanism. To the best of our knowledge, we are the first to show that,
for large $L$, error-free multi-valued Byzantine consensus on an $L$-bit value
is achievable with $O(nL)$ bits of communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3521</identifier>
 <datestamp>2013-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3521</id><created>2011-01-18</created><updated>2013-03-19</updated><authors><author><keyname>Hagar</keyname><forenames>Amit</forenames></author><author><keyname>Sergioli</keyname><forenames>Giuseppe</forenames></author></authors><title>Counting Steps: A New Approach to Objective Probability in Physics</title><categories>quant-ph cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new interpretation of objective deterministic chances in
statistical physics based on physical computational complexity. This notion
applies to a single physical system (be it an experimental set--up in the lab,
or a subsystem of the universe), and quantifies (1) the difficulty to realize a
physical state given another, (2) the `distance' (in terms of physical
resources) of a physical state from another, and (3) the size of the set of
time--complexity functions that are compatible with the physical resources
required to reach a physical state from another. This view (a) exorcises
&quot;ignorance&quot; from statistical physics, and (b) underlies a new interpretation to
non--relativistic quantum mechanics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3574</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3574</id><created>2011-01-18</created><authors><author><keyname>Liu</keyname><forenames>Xi</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>A Game-Theoretic View of the Interference Channel: Impact of
  Coordination and Bargaining</title><categories>cs.IT math.IT</categories><comments>43 pages, 11 figures, to appear on Special Issue of the IEEE
  Transactions on Information Theory on Interference Networks, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers coordination and bargaining between two selfish users
over a Gaussian interference channel. The usual information theoretic approach
assumes full cooperation among users for codebook and rate selection. In the
scenario investigated here, each user is willing to coordinate its actions only
when an incentive exists and benefits of cooperation are fairly allocated. The
users are first allowed to negotiate for the use of a simple Han-Kobayashi type
scheme with fixed power split. Conditions for which users have incentives to
cooperate are identified. Then, two different approaches are used to solve the
associated bargaining problem. First, the Nash Bargaining Solution (NBS) is
used as a tool to get fair information rates and the operating point is
obtained as a result of an optimization problem. Next, a dynamic
alternating-offer bargaining game (AOBG) from bargaining theory is introduced
to model the bargaining process and the rates resulting from negotiation are
characterized. The relationship between the NBS and the equilibrium outcome of
the AOBG is studied and factors that may affect the bargaining outcome are
discussed. Finally, under certain high signal-to-noise ratio regimes, the
bargaining problem for the generalized degrees of freedom is studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3578</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3578</id><created>2011-01-18</created><updated>2011-01-26</updated><authors><author><keyname>McKubre-Jordens</keyname><forenames>Maarten</forenames></author><author><keyname>Wilson</keyname><forenames>Phillip L.</forenames></author></authors><title>Infinity in computable probability</title><categories>math.LO cs.CL cs.LO</categories><comments>This paper has been withdrawn by the authors due to the sum of the
  lengths of the intervals not converging constructively</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we show, contrary to the classical supposition, that a process for
generating symbols according to some probability distribution need not, with
any likelihood, produce a given finite text in any finite time, even if it is
guaranteed to produce the text in infinite time. The result extends to
target-free text generation and has implications for simulations of
probabilistic processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3589</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3589</id><created>2011-01-18</created><updated>2011-06-11</updated><authors><author><keyname>Eder</keyname><forenames>Christian</forenames></author><author><keyname>Perry</keyname><forenames>John</forenames></author></authors><title>Signature-based algorithms to compute Groebner bases</title><categories>math.AC cs.SC</categories><comments>appears in Proceedings of ISSAC 2011; includes minor revisions (a
  number of typos which make Section 2.2 difficult to follow)</comments><msc-class>13P10 (primary), 68W30</msc-class><acm-class>I.1.2; F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a Buchberger-style algorithm to compute a Groebner basis
of a polynomial ideal, allowing for a selection strategy based on &quot;signatures&quot;.
We explain how three recent algorithms can be viewed as different strategies
for the new algorithm, and how other selection strategies can be formulated. We
describe a fourth as an example. We analyze the strategies both theoretically
and empirically, leading to some surprising results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3594</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3594</id><created>2011-01-18</created><updated>2012-01-05</updated><authors><author><keyname>Yan</keyname><forenames>Donghui</forenames></author><author><keyname>Gong</keyname><forenames>Peng</forenames></author><author><keyname>Chen</keyname><forenames>Aiyou</forenames></author><author><keyname>Zhong</keyname><forenames>Liheng</forenames></author></authors><title>Classification under Data Contamination with Application to Remote
  Sensing Image Mis-registration</title><categories>stat.ME cs.LG stat.ML</categories><comments>23 pages, 10 figures</comments><acm-class>I.2.6; I.5.1; I.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is motivated by the problem of image mis-registration in remote
sensing and we are interested in determining the resulting loss in the accuracy
of pattern classification. A statistical formulation is given where we propose
to use data contamination to model and understand the phenomenon of image
mis-registration. This model is widely applicable to many other types of errors
as well, for example, measurement errors and gross errors etc. The impact of
data contamination on classification is studied under a statistical learning
theoretical framework. A closed-form asymptotic bound is established for the
resulting loss in classification accuracy, which is less than
$\epsilon/(1-\epsilon)$ for data contamination of an amount of $\epsilon$. Our
bound is sharper than similar bounds in the domain adaptation literature and,
unlike such bounds, it applies to classifiers with an infinite
Vapnik-Chervonekis (VC) dimension. Extensive simulations have been conducted on
both synthetic and real datasets under various types of data contamination,
including label flipping, feature swapping and the replacement of feature
values with data generated from a random source such as a Gaussian or Cauchy
distribution. Our simulation results show that the bound we derive is fairly
tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3603</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3603</id><created>2011-01-18</created><authors><author><keyname>Cheng</keyname><forenames>Jin-San</forenames></author><author><keyname>Gao</keyname><forenames>Xiao-Shan</forenames></author></authors><title>Multiplicity Preserving Triangular Set Decomposition of Two Polynomials</title><categories>cs.SC</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a multiplicity preserving triangular set decomposition
algorithm is proposed for a system of two polynomials. The algorithm decomposes
the variety defined by the polynomial system into unmixed components
represented by triangular sets, which may have negative multiplicities. In the
bivariate case, we give a complete algorithm to decompose the system into
multiplicity preserving triangular sets with positive multiplicities. We also
analyze the complexity of the algorithm in the bivariate case. We implement our
algorithm and show the effectiveness of the method with extensive experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3620</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3620</id><created>2011-01-19</created><updated>2011-05-27</updated><authors><author><keyname>Voevodski</keyname><forenames>Konstantin</forenames></author><author><keyname>Balcan</keyname><forenames>Maria-Florina</forenames></author><author><keyname>Roglin</keyname><forenames>Heiko</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author><author><keyname>Xia</keyname><forenames>Yu</forenames></author></authors><title>Clustering Protein Sequences Given the Approximation Stability of the
  Min-Sum Objective Function</title><categories>cs.DS cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of efficiently clustering protein sequences in a limited
information setting. We assume that we do not know the distances between the
sequences in advance, and must query them during the execution of the
algorithm. Our goal is to find an accurate clustering using few queries. We
model the problem as a point set $S$ with an unknown metric $d$ on $S$, and
assume that we have access to \emph{one versus all} distance queries that given
a point $s \in S$ return the distances between $s$ and all other points. Our
one versus all query represents an efficient sequence database search program
such as BLAST, which compares an input sequence to an entire data set. Given a
natural assumption about the approximation stability of the \emph{min-sum}
objective function for clustering, we design a provably accurate clustering
algorithm that uses few one versus all queries. In our empirical study we show
that our method compares favorably to well-established clustering algorithms
when we compare computationally derived clusterings to gold-standard manual
classifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3638</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3638</id><created>2011-01-19</created><authors><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author></authors><title>Sparsity Equivalence of Anisotropic Decompositions</title><categories>math.FA cs.NA math.NA</categories><comments>20 pages, 4 figures</comments><msc-class>42C40 (Primary), 42C15, 65T60, 94A08 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anisotropic decompositions using representation systems such as curvelets,
contourlet, or shearlets have recently attracted significantly increased
attention due to the fact that they were shown to provide optimally sparse
approximations of functions exhibiting singularities on lower dimensional
embedded manifolds. The literature now contains various direct proofs of this
fact and of related sparse approximation results. However, it seems quite
cumbersome to prove such a canon of results for each system separately, while
many of the systems exhibit certain similarities. In this paper, with the
introduction of the concept of sparsity equivalence, we aim to provide a
framework which allows categorization of the ability for sparse approximations
of representation systems. This framework, in particular, enables transferring
results on sparse approximations from one system to another. We demonstrate
this concept for the example of curvelets and shearlets, and discuss how this
viewpoint immediately leads to novel results for both systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3682</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3682</id><created>2011-01-19</created><updated>2011-04-03</updated><authors><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames></author><author><keyname>Roche</keyname><forenames>Daniel S.</forenames></author></authors><title>Diversification improves interpolation</title><categories>cs.SC cs.DS cs.MS</categories><comments>26 pages, pdfLaTeX. Preliminary version to appear at ISSAC 2011</comments><acm-class>F.2.1; G.1.1; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of interpolating an unknown multivariate polynomial
with coefficients taken from a finite field or as numerical approximations of
complex numbers. Building on the recent work of Garg and Schost, we improve on
the best-known algorithm for interpolation over large finite fields by
presenting a Las Vegas randomized algorithm that uses fewer black box
evaluations. Using related techniques, we also address numerical interpolation
of sparse polynomials with complex coefficients, and provide the first provably
stable algorithm (in the sense of relative error) for this problem, at the cost
of modestly more evaluations. A key new technique is a randomization which
makes all coefficients of the unknown polynomial distinguishable, producing
what we call a diverse polynomial. Another departure from most previous
approaches is that our algorithms do not rely on root finding as a subroutine.
We show how these improvements affect the practical performance with trial
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3684</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3684</id><created>2011-01-19</created><authors><author><keyname>Soos</keyname><forenames>Sandor</forenames></author><author><keyname>Kampis</keyname><forenames>George</forenames></author></authors><title>Bio-inspired Methods for Dynamic Network Analysis in Science Mapping</title><categories>cs.DL cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply bio-inspired methods for the analysis of different dynamic
bibliometric networks (linking papers by citation, authors, and keywords,
respectively). Biological species are clusters of individuals defined by widely
different criteria and in the biological perspective it is natural to (1) use
different categorizations on the same entities (2) to compare the different
categorizations and to analyze the dissimilarities, especially as they change
over time. We employ the same methodology to comparisons of bibliometric
classifications. We constructed them as analogs of three species concepts:
cladistic or lineage based, similarity based, and &quot;biological species&quot; (based
on co-reproductive ability). We use the Rand and Jaccard indexes to compare
classifications in different time intervals. The experiment is aimed to address
the classic problem of science mapping, as to what extent the various
techniques based on different bibliometric indicators, such as citations,
keywords or authors are able to detect convergent structures in the
litrerature, that is, to identify coherent specialities or research directions
and their dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3694</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3694</id><created>2011-01-19</created><updated>2011-03-27</updated><authors><author><keyname>Chen</keyname><forenames>Taolue</forenames><affiliation>University of Twente</affiliation></author><author><keyname>Han</keyname><forenames>Tingting</forenames><affiliation>RWTH Aachen University</affiliation></author><author><keyname>Katoen</keyname><forenames>Joost-Pieter</forenames><affiliation>RWTH Aachen University</affiliation></author><author><keyname>Mereacre</keyname><forenames>Alexandru</forenames><affiliation>RWTH Aachen University</affiliation></author></authors><title>Model Checking of Continuous-Time Markov Chains Against Timed Automata
  Specifications</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>D.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 29,
  2011) lmcs:697</journal-ref><doi>10.2168/LMCS-7(1:12)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the verification of a finite continuous-time Markov chain (CTMC) C
against a linear real-time specification given as a deterministic timed
automaton (DTA) A with finite or Muller acceptance conditions. The central
question that we address is: what is the probability of the set of paths of C
that are accepted by A, i.e., the likelihood that C satisfies A? It is shown
that under finite acceptance criteria this equals the reachability probability
in a finite piecewise deterministic Markov process (PDP), whereas for Muller
acceptance criteria it coincides with the reachability probability of terminal
strongly connected components in such a PDP. Qualitative verification is shown
to amount to a graph analysis of the PDP. Reachability probabilities in our
PDPs are then characterized as the least solution of a system of Volterra
integral equations of the second type and are shown to be approximated by the
solution of a system of partial differential equations. For single-clock DTA,
this integral equation system can be transformed into a system of linear
equations where the coefficients are solutions of ordinary differential
equations. As the coefficients are in fact transient probabilities in CTMCs,
this result implies that standard algorithms for CTMC analysis suffice to
verify single-clock DTA specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3698</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3698</id><created>2011-01-17</created><authors><author><keyname>Wang</keyname><forenames>Ni-Chun</forenames></author><author><keyname>Biglieri</keyname><forenames>Ezio</forenames></author><author><keyname>Yao</keyname><forenames>Kung</forenames></author></authors><title>Systolic Arrays for Lattice-Reduction-Aided MIMO Detection</title><categories>cs.AR</categories><comments>13 pages, to be appeared in journal of communications and networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-input, multiple-output (MIMO) technology provides high data rate and
enhanced QoS for wireless com- munications. Since the benefits from MIMO result
in a heavy computational load in detectors, the design of low-complexity
sub-optimum receivers is currently an active area of research.
Lattice-reduction-aided detection (LRAD) has been shown to be an effective
low-complexity method with near-ML performance. In this paper we advocate the
use of systolic array architectures for MIMO receivers, and in particular we
exhibit one of them based on LRAD. The &quot;LLL lattice reduction algorithm&quot; and
the ensuing linear detections or successive spatial-interference cancellations
can be located in the same array, which is con- siderably hardware-efficient.
Since the conventional form of the LLL algorithm is not immediately suitable
for parallel processing, two modified LLL algorithms are considered here for
the systolic array. LLL algorithm with full-size reduction (FSR-LLL) is one of
the versions more suitable for parallel processing. Another variant is the
all-swap lattice-reduction (ASLR) algorithm for complex-valued lattices, which
processes all lattice basis vectors simultaneously within one iteration. Our
novel systolic array can operate both algorithms with different external logic
controls. In order to simplify the systolic array design, we replace the
Lov\'asz condition in the definition of LLL-reduced lattice with the looser
Siegel condition. Simulation results show that for LR- aided linear detections,
the bit-error-rate performance is still maintained with this relaxation.
Comparisons between the two algorithms in terms of bit-error-rate performance,
and average FPGA processing time in the systolic array are made, which shows
that ASLR is a better choice for a systolic architecture, especially for
systems with a large number of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3719</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3719</id><created>2010-11-18</created><authors><author><keyname>Veneziano</keyname><forenames>Daniele</forenames></author><author><keyname>Gonzalez</keyname><forenames>Marta C.</forenames></author></authors><title>Trip Length Distribution Under Multiplicative Spatial Models of Supply
  and Demand: Theory and Sensitivity Analysis</title><categories>physics.data-an cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose new probabilistic models for the spatial distribution of supply
and demand and use the models to determine how the trip length distribution is
affected by the relative shortage or excess of supply, the spatial clustering
of supply and demand, and the degree of attraction or repulsion between supply
and demand at different spatial scales. The models have a multiplicative
structure and in certain cases possess scale invariance properties. Using
detailed population data in metropolitan US regions validates the demand model.
The trip length distribution, evaluated under destination choice models of the
intervening opportunities type, has quasi-analytic form.We take advantage of
this feature to study the sensitivity of the trip length distribution to
parameters of the demand, supply and destination choice models. We find that
trip length is affected in important but different ways by the spatial density
of potential destinations, the dependence among their attractiveness levels,
and the correlation between supply and demand at different spatial scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3724</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3724</id><created>2010-12-26</created><updated>2011-01-19</updated><authors><author><keyname>Swapna</keyname><forenames>B. T.</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Throughput-Delay Analysis of Random Linear Network Coding for Wireless
  Broadcasting</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an unreliable single-hop broadcast network setting, we investigate the
throughput and decoding-delay performance of random linear network coding as a
function of the coding window size and the network size. Our model consists of
a source transmitting packets of a single flow to a set of $n$ users over
independent erasure channels. The source performs random linear network coding
(RLNC) over $k$ (coding window size) packets and broadcasts them to the users.
We note that the broadcast throughput of RLNC must vanish with increasing $n$,
for any fixed $k.$ Hence, in contrast to other works in the literature, we
investigate how the coding window size $k$ must scale for increasing $n$. Our
analysis reveals that the coding window size of $\Theta(\ln(n))$ represents a
phase transition rate, below which the throughput converges to zero, and above
which it converges to the broadcast capacity. Further, we characterize the
asymptotic distribution of decoding delay and provide approximate expressions
for the mean and variance of decoding delay for the scaling regime of
$k=\omega(\ln(n)).$ These asymptotic expressions reveal the impact of channel
correlations on the throughput and delay performance of RLNC. We also show how
our analysis can be extended to other rateless block coding schemes such as the
LT codes. Finally, we comment on the extension of our results to the cases of
dependent channels across users and asymmetric channel model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3735</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3735</id><created>2011-01-19</created><authors><author><keyname>Lusseau</keyname><forenames>David</forenames></author><author><keyname>Barrett</keyname><forenames>Louise</forenames></author><author><keyname>Henzi</keyname><forenames>S. Peter</forenames></author></authors><title>Formalising the multidimensional nature of social networks</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>16 pages, 4 figures</comments><journal-ref>2012: Philosophical Transactions of the Royal Society of London B
  367(1599):2108-2118</journal-ref><doi>10.1098/rstb.2012.0113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Individuals interact with conspecifics in a number of behavioural contexts or
dimensions. Here, we formalise this by considering a social network between n
individuals interacting in b behavioural dimensions as a nxnxb multidimensional
object. In addition, we propose that the topology of this object is driven by
individual needs to reduce uncertainty about the outcomes of interactions in
one or more dimension. The proposal grounds social network dynamics and
evolution in individual selection processes and allows us to define the
uncertainty of the social network as the joint entropy of its constituent
interaction networks. In support of these propositions we use simulations and
natural 'knock-outs' in a free-ranging baboon troop to show (i) that such an
object can display a small-world state and (ii) that, as predicted, changes in
interactions after social perturbations lead to a more certain social network,
in which the outcomes of interactions are easier for members to predict. This
new formalisation of social networks provides a framework within which to
predict network dynamics and evolution under the assumption that it is driven
by individuals seeking to reduce the uncertainty of their social environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3755</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3755</id><created>2011-01-19</created><updated>2012-06-19</updated><authors><author><keyname>Sinha</keyname><forenames>Shriprakash</forenames></author></authors><title>Transductive-Inductive Cluster Approximation Via Multivariate Chebyshev
  Inequality</title><categories>cs.CV cs.AI</categories><comments>16 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximating adequate number of clusters in multidimensional data is an open
area of research, given a level of compromise made on the quality of acceptable
results. The manuscript addresses the issue by formulating a transductive
inductive learning algorithm which uses multivariate Chebyshev inequality.
Considering clustering problem in imaging, theoretical proofs for a particular
level of compromise are derived to show the convergence of the reconstruction
error to a finite value with increasing (a) number of unseen examples and (b)
the number of clusters, respectively. Upper bounds for these error rates are
also proved. Non-parametric estimates of these error from a random sample of
sequences empirically point to a stable number of clusters. Lastly, the
generalization of algorithm can be applied to multidimensional data sets from
different fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3761</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3761</id><created>2011-01-19</created><authors><author><keyname>Aiello</keyname><forenames>Luca Maria</forenames></author><author><keyname>Milanesio</keyname><forenames>Marco</forenames></author><author><keyname>Ruffo</keyname><forenames>Giancarlo</forenames></author><author><keyname>Schifanella</keyname><forenames>Rossano</forenames></author></authors><title>Tagging with DHARMA, a DHT-based Approach for Resource Mapping through
  Approximation</title><categories>cs.DC cs.SI</categories><comments>8 pages, 8 figures</comments><journal-ref>HOTP2P '10 : 7th International Workshop on Hot Topics in
  Peer-to-Peer Systems, Atlanta, Georgia, April 19-23, 2010</journal-ref><doi>10.1109/IPDPSW.2010.5470931</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce collaborative tagging and faceted search on structured P2P
systems. Since a trivial and brute force mapping of an entire folksonomy over a
DHT-based system may reduce scalability, we propose an approximated graph
maintenance approach. Evaluations on real data coming from Last.fm prove that
such strategies reduce vocabulary noise (i.e., representation's overfitting
phenomena) and hotspots issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3773</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3773</id><created>2011-01-19</created><updated>2011-01-20</updated><authors><author><keyname>Keszegh</keyname><forenames>Bal&#xe1;zs</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author></authors><title>Octants are Cover Decomposable</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that octants are cover-decomposable, i.e., any 12-fold covering of
any subset of the space with a finite number of translates of a given octant
can be decomposed into two coverings. As a corollary, we obtain that any
12-fold covering of any subset of the plane with a finite number of homothetic
copies of a given triangle can be decomposed into two coverings. We also show
that any 12-fold covering of the whole plane with open triangles can be
decomposed into two coverings. However, we exhibit an indecomposable 3-fold
covering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3774</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3774</id><created>2011-01-19</created><authors><author><keyname>Korzhik</keyname><forenames>Valery</forenames></author><author><keyname>Yakovlev</keyname><forenames>Viktor</forenames></author><author><keyname>Morales-Luna</keyname><forenames>Guillermo</forenames></author><author><keyname>Kovajkin</keyname><forenames>Yuri</forenames></author></authors><title>Secret Key Agreement Over Multipath Channels Exploiting a
  Variable-Directional Antenna</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an approach of key distribution protocol (KDP) proposed recently
by T. Aono et al. A more general mathematical model based on the use of
Variable-Directional Antenna (VDA) under the condition of multipath wave
propagation is proposed. Statistical characteristics of VDA were investigated
by simulation, that allows us to specify model parameters. The security of the
considered KDP is estimated in terms of Shannon's information leaking to an
eavesdropper depending on the mutual locations of the legal users and the
eavesdropper.
  Antenna diversity is proposed as a mean to enhance the KDP security. In order
to provide a better agreement of the shared keys it is investigated the use of
error-correcting codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3804</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3804</id><created>2011-01-19</created><authors><author><keyname>Das</keyname><forenames>Abhimanyu</forenames></author><author><keyname>Kempe</keyname><forenames>David</forenames></author></authors><title>Estimating the Average of a Lipschitz-Continuous Function from One
  Sample</title><categories>cs.DS math.CO</categories><journal-ref>European Symposium on Algorithms 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of estimating the average of a Lipschitz continuous
function $f$ defined over a metric space, by querying $f$ at only a single
point. More specifically, we explore the role of randomness in drawing this
sample. Our goal is to find a distribution minimizing the expected estimation
error against an adversarially chosen Lipschitz continuous function. Our work
falls into the broad class of estimating aggregate statistics of a function
from a small number of carefully chosen samples. The general problem has a wide
range of practical applications in areas as diverse as sensor networks, social
sciences and numerical analysis. However, traditional work in numerical
analysis has focused on asymptotic bounds, whereas we are interested in the
\emph{best} algorithm. For arbitrary discrete metric spaces of bounded doubling
dimension, we obtain a PTAS for this problem. In the special case when the
points lie on a line, the running time improves to an FPTAS. Both algorithms
are based on approximately solving a linear program with an infinite set of
constraints, by using an approximate separation oracle. For
Lipschitz-continuous functions over $[0,1]$, we calculate the precise
achievable error as $1-\frac{\sqrt{3}}{2} \approx 0.134$, which improves upon
the \quarter which is best possible for deterministic algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3824</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3824</id><created>2011-01-20</created><authors><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Baccelli</keyname><forenames>Francois</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Series Expansion for Interference in Wireless Networks</title><categories>cs.IT math.IT math.PR stat.AP</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spatial correlations in transmitter node locations introduced by common
multiple access protocols makes the analysis of interference, outage, and other
related metrics in a wireless network extremely difficult. Most works therefore
assume that nodes are distributed either as a Poisson point process (PPP) or a
grid, and utilize the independence properties of the PPP (or the regular
structure of the grid) to analyze interference, outage and other metrics.
But,the independence of node locations makes the PPP a dubious model for
nontrivial MACs which intentionally introduce correlations, e.g. spatial
separation, while the grid is too idealized to model real networks. In this
paper, we introduce a new technique based on the factorial moment expansion of
functionals of point processes to analyze functions of interference, in
particular outage probability. We provide a Taylor-series type expansion of
functions of interference, wherein increasing the number of terms in the series
provides a better approximation at the cost of increased complexity of
computation. Various examples illustrate how this new approach can be used to
find outage probability in both Poisson and non-Poisson wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3835</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3835</id><created>2011-01-20</created><authors><author><keyname>Naveen</keyname><forenames>K. P.</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Relay Selection with Partial Information in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>43 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work is motivated by geographical forwarding of sporadic alarm packets to
a base station in a wireless sensor network (WSN), where the nodes are
sleep-wake cycling periodically and asynchronously. When a node (referred to as
the source) gets a packet to forward, either by detecting an event or from an
upstream node, it has to wait for its neighbors in a forwarding set (referred
to as relays) to wake-up. Each of the relays is associated with a random reward
(e.g., the progress made towards the sink) that is iid. To begin with, the
source is uncertain about the number of relays, their wake-up times and the
reward values, but knows their distributions. At each relay wake-up instant,
when a relay reveals its reward value, the source's problem is to forward the
packet or to wait for further relays to wake-up. In this setting, we seek to
minimize the expected waiting time at the source subject to a lower bound on
the average reward. In terms of the operations research literature, our work
can be considered as a variant of the asset selling problem. We formulate the
relay selection problem as a partially observable Markov decision process
(POMDP), where the unknown state is the number of relays. We begin by
considering the case where the source knows the number of relays. For the
general case, where the source only knows a pmf on the number of relays, it has
to maintain a posterior pmf on the number of relays and forward the packet iff
the pmf is in an optimum stopping set. We show that the optimum stopping set is
convex and obtain inner and outer bounds to this set. The computational
complexity of the above policies motivates us to formulate an alternative
simplified model, the optimal policy for which is a simple threshold rule. We
provide simulation results to compare the performance of the various one-hop
and end-to-end forwarding policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3836</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3836</id><created>2011-01-20</created><authors><author><keyname>Vladoiu</keyname><forenames>Monica</forenames></author><author><keyname>Constantinescu</keyname><forenames>Zoran</forenames></author></authors><title>U-Learning Within A Context-Aware Multiagent Environment</title><categories>cs.HC</categories><comments>15 pages, 3 figures</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Vol. 3, No. 1, January 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New technological developments have made it possible to interact with
computer systems and applications anywhere and anytime. It is vital that these
applications are able to adapt to the user, as a person, and to its current
situation, whatever that is. Therefore, the premises for evolution towards a
learning society and a knowledge economy are present. Hence, there is a
stringent demand for new learner-centred frameworks that allow active
participation of learners in knowledge creation within communities,
organizations, territories and society, at large. This paper presents the
multi-agent architecture of our context-aware system and the learning scenarios
within ubiquitous learning environments that the system provides support for.
This architecture is the outcome of our endeavour to develop ePH, a system for
sharing public interest information and knowledge, which is accessible through
always-on, context-aware services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3837</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3837</id><created>2011-01-20</created><updated>2011-08-16</updated><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author></authors><title>Superiority of exact quantum automata for promise problems</title><categories>cs.CC cs.FL quant-ph</categories><comments>A completely new version. 6 pages. (The previous version contains
  some errata.)</comments><journal-ref>Information Processing Letters, Volume 112, Issue 7, 31 March
  2012, Pages 289-291</journal-ref><doi>10.1016/j.ipl.2012.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we present an infinite family of promise problems which can be
solved exactly by just tuning transition amplitudes of a two-state quantum
finite automata operating in realtime mode, whereas the size of the
corresponding classical automata grow without bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3838</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3838</id><created>2011-01-20</created><authors><author><keyname>Jung</keyname><forenames>Alexander</forenames></author><author><keyname>Schmutzhard</keyname><forenames>Sebastian</forenames></author><author><keyname>Hlawatsch</keyname><forenames>Franz</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames><suffix>III</suffix></author></authors><title>Performance Bounds for Sparse Parametric Covariance Estimation in
  Gaussian Models</title><categories>cs.IT math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider estimation of a sparse parameter vector that determines the
covariance matrix of a Gaussian random vector via a sparse expansion into known
&quot;basis matrices&quot;. Using the theory of reproducing kernel Hilbert spaces, we
derive lower bounds on the variance of estimators with a given mean function.
This includes unbiased estimation as a special case. We also present a
numerical comparison of our lower bounds with the variance of two standard
estimators (hard-thresholding estimator and maximum likelihood estimator).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3859</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3859</id><created>2011-01-20</created><authors><author><keyname>Sqalli</keyname><forenames>Mohammed H.</forenames></author><author><keyname>Sait</keyname><forenames>Sadiq M.</forenames></author><author><keyname>Asadullah</keyname><forenames>Syed</forenames></author></authors><title>OSPF Weight Setting Optimization for Single Link Failures</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), pp:168-183, Vol. 3, No. 1, January 2011</journal-ref><doi>10.5121/ijcnc.2011.3111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In operational networks, nodes are connected via multiple links for load
sharing and redundancy. This is done to make sure that a failure of a link does
not disconnect or isolate some parts of the network. However, link failures
have an effect on routing, as the routers find alternate paths for the traffic
originally flowing through the link which has failed. This effect is severe in
case of failure of a critical link in the network, such as backbone links or
the links carrying higher traffic loads. When routing is done using the Open
Shortest Path First (OSPF) routing protocol, the original weight selection for
the normal state topology may not be as efficient for the failure state. In
this paper, we investigate the single link failure issue with an objective to
find a weight setting which results in efficient routing in normal and failure
states. We engineer Tabu Search Iterative heuristic using two different
implementation strategies to solve the OSPF weight setting problem for link
failure scenarios. We evaluate these heuristics and show through experimental
results that both heuristics efficiently handle weight setting for the failure
state. A comparison of both strategies is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3863</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3863</id><created>2011-01-20</created><updated>2011-06-19</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Mutz</keyname><forenames>R&#xfc;diger</forenames></author><author><keyname>Opthof</keyname><forenames>Tobias</forenames></author></authors><title>Turning the tables in citation analysis one more time: Principles for
  comparing sets of documents</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We submit newly developed citation impact indicators based not on arithmetic
averages of citations but on percentile ranks. Citation distributions are-as a
rule-highly skewed and should not be arithmetically averaged. With percentile
ranks, the citation of each paper is rated in terms of its percentile in the
citation distribution. The percentile ranks approach allows for the formulation
of a more abstract indicator scheme that can be used to organize and/or
schematize different impact indicators according to three degrees of freedom:
the selection of the reference sets, the evaluation criteria, and the choice of
whether or not to define the publication sets as independent. Bibliometric data
of seven principal investigators (PIs) of the Academic Medical Center of the
University of Amsterdam is used as an exemplary data set. We demonstrate that
the proposed indicators [R(6), R(100), R(6,k), R(100,k)] are an improvement of
averages-based indicators because one can account for the shape of the
distributions of citations over papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3884</identifier>
 <datestamp>2012-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3884</id><created>2011-01-20</created><authors><author><keyname>Gharibian</keyname><forenames>Sevag</forenames></author><author><keyname>Kempe</keyname><forenames>Julia</forenames></author></authors><title>Approximation algorithms for QMA-complete problems</title><categories>quant-ph cs.CC</categories><comments>22 pages, comments welcome</comments><journal-ref>SIAM Journal on Computing 41(4): 1028-1050, 2012</journal-ref><doi>10.1137/110842272</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximation algorithms for classical constraint satisfaction problems are
one of the main research areas in theoretical computer science. Here we define
a natural approximation version of the QMA-complete local Hamiltonian problem
and initiate its study. We present two main results. The first shows that a
non-trivial approximation ratio can be obtained in the class NP using product
states. The second result (which builds on the first one), gives a polynomial
time (classical) algorithm providing a similar approximation ratio for dense
instances of the problem. The latter result is based on an adaptation of the
&quot;exhaustive sampling method&quot; by Arora et al. [J. Comp. Sys. Sci. 58, p.193
(1999)] to the quantum setting, and might be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3885</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3885</id><created>2011-01-20</created><authors><author><keyname>Agustini</keyname><forenames>Edson</forenames></author><author><keyname>Costa</keyname><forenames>Sueli I. R.</forenames></author></authors><title>An Upper Bound for Signal Transmission Error Probability in Hyperbolic
  Spaces</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and discuss the concept of Gaussian probability density function
(pdf) for the n-dimensional hyperbolic space which has been proposed as an
environment for coding and decoding signals. An upper bound for the error
probability of signal transmission associated with the hyperbolic distance is
established. The pdf and the upper bound were developed using Poincare models
for the hyperbolic spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3891</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3891</id><created>2011-01-20</created><authors><author><keyname>Marcu</keyname><forenames>Patricia</forenames></author><author><keyname>Hommel</keyname><forenames>Wolfgang</forenames></author></authors><title>Inter-organizational fault management: Functional and organizational
  core aspects of management architectures</title><categories>cs.NI cs.DC</categories><comments>International Journal of Computer Networks &amp; Communications (IJCNC)</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Editor: AIRCC, January 2011, Volume 3. Number 1, pages:101-117,
  ISSN-Online: 0974 - 9322,ISSN-Print: 0975- 2293</journal-ref><doi>10.5121/ijcnc.2011.3107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outsourcing -- successful, and sometimes painful -- has become one of the
hottest topics in IT service management discussions over the past decade. IT
services are outsourced to external service provider in order to reduce the
effort required for and overhead of delivering these services within the own
organization. More recently also IT services providers themselves started to
either outsource service parts or to deliver those services in a
non-hierarchical cooperation with other providers. Splitting a service into
several service parts is a non-trivial task as they have to be implemented,
operated, and maintained by different providers. One key aspect of such
inter-organizational cooperation is fault management, because it is crucial to
locate and solve problems, which reduce the quality of service, quickly and
reliably. In this article we present the results of a thorough use case based
requirements analysis for an architecture for inter-organizational fault
management (ioFMA). Furthermore, a concept of the organizational respective
functional model of the ioFMA is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3896</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3896</id><created>2011-01-20</created><authors><author><keyname>Marcu</keyname><forenames>Patricia</forenames></author><author><keyname>Schmitz</keyname><forenames>David</forenames></author><author><keyname>Fritz</keyname><forenames>Wolfgang</forenames></author><author><keyname>Yampolskiy</keyname><forenames>Mark</forenames></author><author><keyname>Hommel</keyname><forenames>Wolfgang</forenames></author></authors><title>Integrated monitoring of multi-domain backbone connections --
  Operational experience in the LHC optical private network</title><categories>cs.NI cs.DC</categories><comments>International Journal of Computer Networks &amp; Communications (IJCNC)</comments><journal-ref>Intl.J.Comput.Net.Commun.3:82-99,2011</journal-ref><doi>10.5121/ijcnc.2011.3106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Novel large scale research projects often require cooperation between various
different project partners that are spread among the entire world. They do not
only need huge computing resources, but also a reliable network to operate on.
The Large Hadron Collider (LHC) at CERN is a representative example for such a
project. Its experiments result in a vast amount of data, which is interesting
for researchers around the world. For transporting the data from CERN to 11
data processing and storage sites, an optical private network (OPN) has been
constructed. As the experiment data is highly valuable, LHC defines very high
requirements to the underlying network infrastructure. In order to fulfil those
requirements, the connections have to be managed and monitored permanently. In
this paper, we present the integrated monitoring solution developed for the
LHCOPN. We first outline the requirements and show how they are met on the
single network layers. After that, we describe, how those single measurements
can be combined into an integrated view. We cover design concepts as well as
tool implementation highlights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3929</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3929</id><created>2011-01-20</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Weaver</keyname><forenames>Elizabeth A.</forenames></author></authors><title>Characteristic Generators and Dualization for Tail-Biting Trellises</title><categories>cs.IT math.IT</categories><comments>26 pages</comments><msc-class>94B05, 94B12, 68R10, 93B20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on dualizing tail-biting trellises, particularly
KV-trellises. These trellises are based on characteristic generators, as
introduced by Koetter/Vardy (2003), and may be regarded as a natural
generalization of minimal conventional trellises, even though they are not
necessarily minimal. Two dualization techniques will be investigated: the local
dualization, introduced by Forney (2001) for general normal graphs, and a
linear algebra based dualization tailored to the specific class of tail-biting
BCJR-trellises, introduced by Nori/Shankar (2006). It turns out that, in
general, the BCJR-dual is a subtrellis of the local dual, while for
KV-trellises these two coincide. Furthermore, making use of both the
BCJR-construction and the local dualization, it will be shown that for each
complete set of characteristic generators of a code there exists a complete set
of characteristic generators of the dual code such that their resulting
KV-trellises are dual to each other if paired suitably. This proves a stronger
version of a conjecture formulated by Koetter/Vardy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3953</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3953</id><created>2011-01-20</created><authors><author><keyname>Frederickson</keyname><forenames>Greg N.</forenames></author><author><keyname>Wittman</keyname><forenames>Barry</forenames></author></authors><title>Two Multivehicle Routing Problems with Unit-Time Windows</title><categories>cs.DS</categories><comments>7 pages</comments><msc-class>68W25 (Primary) 90C27, 90C35 (Secondary)</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two multivehicle routing problems are considered in the framework that a
visit to a location must take place during a specific time window in order to
be counted and all time windows are the same length. In the first problem, the
goal is to visit as many locations as possible using a fixed number of
vehicles. In the second, the goal is to visit all locations using the smallest
number of vehicles possible. For the first problem, we present an approximation
algorithm whose output path collects a reward within a constant factor of
optimal for any fixed number of vehicles. For the second problem, our algorithm
finds a 6-approximation to the problem on a tree metric, whenever a single
vehicle could visit all locations during their time windows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3960</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3960</id><created>2011-01-20</created><authors><author><keyname>Frederickson</keyname><forenames>Greg N.</forenames></author><author><keyname>Wittman</keyname><forenames>Barry</forenames></author></authors><title>Speedup in the Traveling Repairman Problem with Constrained Time Windows</title><categories>cs.DS</categories><comments>28 pages, 3 figures</comments><msc-class>68W25, 68Q25 (Primary) 90C35, 90C27 (Secondary)</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A bicriteria approximation algorithm is presented for the unrooted traveling
repairman problem, realizing increased profit in return for increased speedup
of repairman motion. The algorithm generalizes previous results from the case
in which all time windows are the same length to the case in which their
lengths can range between l and 2. This analysis can extend to any range of
time window lengths, following our earlier techniques. This relationship
between repairman profit and speedup is applicable over a range of values that
is dependent on the cost of putting the input in an especially desirable form,
involving what are called &quot;trimmed windows.&quot; For time windows with lengths
between 1 and 2, the range of values for speedup $s$ for which our analysis
holds is $1 \leq s \leq 6$. In this range, we establish an approximation ratio
that is constant for any specific value of $s$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3970</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3970</id><created>2011-01-20</created><updated>2011-06-03</updated><authors><author><keyname>M&#xfc;ller</keyname><forenames>Sebastian</forenames></author><author><keyname>Tzameret</keyname><forenames>Iddo</forenames></author></authors><title>Short Propositional Refutations for Dense Random 3CNF Formulas</title><categories>cs.CC</categories><comments>62 pages; improved introduction and abstract, and a changed title.
  Fixed some typos</comments><msc-class>03F20, 68Q17, 68Q15, 03F30</msc-class><acm-class>F.2.2; F.4.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random 3CNF formulas constitute an important distribution for measuring the
average-case behavior of propositional proof systems. Lower bounds for random
3CNF refutations in many propositional proof systems are known. Most notably
are the exponential-size resolution refutation lower bounds for random 3CNF
formulas with $\Omega(n^{1.5-\epsilon}) $ clauses [Chvatal and Szemeredi
(1988), Ben-Sasson and Wigderson (2001)]. On the other hand, the only known
non-trivial upper bound on the size of random 3CNF refutations in a
non-abstract propositional proof system is for resolution with
$\Omega(n^{2}/\log n) $ clauses, shown by Beame et al. (2002). In this paper we
show that already standard propositional proof systems, within the hierarchy of
Frege proofs, admit short refutations for random 3CNF formulas, for
sufficiently large clause-to-variable ratio. Specifically, we demonstrate
polynomial-size propositional refutations whose lines are $TC^0$ formulas
(i.e., $TC^0$-Frege proofs) for random 3CNF formulas with $ n $ variables and $
\Omega(n^{1.4}) $ clauses.
  The idea is based on demonstrating efficient propositional correctness proofs
of the random 3CNF unsatisfiability witnesses given by Feige, Kim and Ofek
(2006). Since the soundness of these witnesses is verified using spectral
techniques, we develop an appropriate way to reason about eigenvectors in
propositional systems. To carry out the full argument we work inside weak
formal systems of arithmetic and use a general translation scheme to
propositional proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3973</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3973</id><created>2011-01-20</created><updated>2011-09-22</updated><authors><author><keyname>Pasqualetti</keyname><forenames>Fabio</forenames></author><author><keyname>Franchi</keyname><forenames>Antonio</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>On cooperative patrolling: optimal trajectories, complexity analysis,
  and approximation algorithms</title><categories>math.CO cs.DS cs.SY math.OC</categories><comments>Preprint submitted to IEEE Transaction on Robotics</comments><journal-ref>IEEE Transaction on Robotics, vol. 28, issue 3, pp. 592-606,
  06/2012</journal-ref><doi>10.1109/TRO.2011.2179580</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subject of this work is the patrolling of an environment with the aid of
a team of autonomous agents. We consider both the design of open-loop
trajectories with optimal properties, and of distributed control laws
converging to optimal trajectories. As performance criteria, the refresh time
and the latency are considered, i.e., respectively, time gap between any two
visits of the same region, and the time necessary to inform every agent about
an event occurred in the environment. We associate a graph with the
environment, and we study separately the case of a chain, tree, and cyclic
graph. For the case of chain graph, we first describe a minimum refresh time
and latency team trajectory, and we propose a polynomial time algorithm for its
computation. Then, we describe a distributed procedure that steers the robots
toward an optimal trajectory. For the case of tree graph, a polynomial time
algorithm is developed for the minimum refresh time problem, under the
technical assumption of a constant number of robots involved in the patrolling
task. Finally, we show that the design of a minimum refresh time trajectory for
a cyclic graph is NP-hard, and we develop a constant factor approximation
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.3979</identifier>
 <datestamp>2011-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.3979</id><created>2011-01-20</created><authors><author><keyname>Cleju</keyname><forenames>Nicolae</forenames></author><author><keyname>Thomos</keyname><forenames>Nikolaos</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Selection of network coding nodes for minimal playback delay in
  streaming overlays</title><categories>cs.MM cs.IT cs.NI math.IT</categories><comments>submitted to IEEE Transactions on Multimedia, January 18th 2011</comments><report-no>EPFL report TR-LTS-2011-001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding permits to deploy distributed packet delivery algorithms that
locally adapt to the network availability in media streaming applications.
However, it may also increase delay and computational complexity if it is not
implemented efficiently. We address here the effective placement of nodes that
implement randomized network coding in overlay networks, so that the goodput is
kept high while the delay for decoding stays small in streaming applications.
We first estimate the decoding delay at each client, which depends on the
innovative rate in the network. This estimation permits to identify the nodes
that have to perform coding for a reduced decoding delay. We then propose two
iterative algorithms for selecting the nodes that should perform network
coding. The first algorithm relies on the knowledge of the full network
statistics. The second algorithm uses only local network statistics at each
node. Simulation results show that large performance gains can be achieved with
the selection of only a few network coding nodes. Moreover, the second
algorithm performs very closely to the central estimation strategy, which
demonstrates that the network coding nodes can be selected efficiently in a
distributed manner. Our scheme shows large gains in terms of achieved
throughput, delay and video quality in realistic overlay networks when compared
to methods that employ traditional streaming strategies as well as random
network nodes selection algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4003</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4003</id><created>2011-01-20</created><updated>2011-07-30</updated><authors><author><keyname>Santos</keyname><forenames>Matilde</forenames></author><author><keyname>H.</keyname><forenames>Jose Antonio Martin</forenames></author><author><keyname>Lopez</keyname><forenames>Victoria</forenames></author><author><keyname>Botella</keyname><forenames>Guillermo</forenames></author></authors><title>Dyna-H: a heuristic planning reinforcement learning algorithm applied to
  role-playing-game strategy decision systems</title><categories>cs.AI cs.LG cs.SY math.OC</categories><msc-class>68T05</msc-class><acm-class>I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a Role-Playing Game, finding optimal trajectories is one of the most
important tasks. In fact, the strategy decision system becomes a key component
of a game engine. Determining the way in which decisions are taken (online,
batch or simulated) and the consumed resources in decision making (e.g.
execution time, memory) will influence, in mayor degree, the game performance.
When classical search algorithms such as A* can be used, they are the very
first option. Nevertheless, such methods rely on precise and complete models of
the search space, and there are many interesting scenarios where their
application is not possible. Then, model free methods for sequential decision
making under uncertainty are the best choice. In this paper, we propose a
heuristic planning strategy to incorporate the ability of heuristic-search in
path-finding into a Dyna agent. The proposed Dyna-H algorithm, as A* does,
selects branches more likely to produce outcomes than other branches. Besides,
it has the advantages of being a model-free online reinforcement learning
algorithm. The proposal was evaluated against the one-step Q-Learning and
Dyna-Q algorithms obtaining excellent experimental results: Dyna-H
significantly overcomes both methods in all experiments. We suggest also, a
functional analogy between the proposed sampling from worst trajectories
heuristic and the role of dreams (e.g. nightmares) in human behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4028</identifier>
 <datestamp>2011-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4028</id><created>2011-01-20</created><updated>2011-02-10</updated><authors><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author></authors><title>Who is the best player ever? A complex network analysis of the history
  of professional tennis</title><categories>physics.soc-ph cs.SI physics.pop-ph</categories><comments>10 pages, 4 figures, 4 tables</comments><journal-ref>PLoS ONE 6, e17249 (2011)</journal-ref><doi>10.1371/journal.pone.0017249</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider all matches played by professional tennis players between 1968
and 2010, and, on the basis of this data set, construct a directed and weighted
network of contacts. The resulting graph shows complex features, typical of
many real networked systems studied in literature. We develop a diffusion
algorithm and apply it to the tennis contact network in order to rank
professional players. Jimmy Connors is identified as the best player of the
history of tennis according to our ranking procedure. We perform a complete
analysis by determining the best players on specific playing surfaces as well
as the best ones in each of the years covered by the data set. The results of
our technique are compared to those of two other well established methods. In
general, we observe that our ranking method performs better: it has a higher
predictive power and does not require the arbitrary introduction of external
criteria for the correct assessment of the quality of players. The present work
provides a novel evidence of the utility of tools and methods of network theory
in real applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4034</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4034</id><created>2011-01-20</created><authors><author><keyname>Kaaniche</keyname><forenames>Heni</forenames></author><author><keyname>Louati</keyname><forenames>Fatma</forenames></author><author><keyname>Frikha</keyname><forenames>Mounir</forenames></author><author><keyname>Kamoun</keyname><forenames>Farouk</forenames></author></authors><title>A QoS Routing Protocol based on Available Bandwidth Estimation for
  Wireless Ad Hoc Networks</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC),Vol. 3, No. 1, pp 219-239, January 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At the same time as the emergence of multimedia in mobile Ad hoc networks,
research for the introduction of the quality of service (QoS) has received much
attention. However, when designing a QoS solution, the estimation of the
available resources still represents one of the main issues. This paper
suggests an approach to estimate available resources on a node. This approach
is based on the estimation of the busy ratio of the shared canal. We consider
in our estimation the several constraints related to the Ad hoc transmission
mode such as Interference phenomena. This approach is implemented on the AODV
routing protocol. We call AODVwithQOS our new routing protocol. We also
performed a performance evaluation by simulations using NS2 simulator. The
results confirm that AODVwithQoS provides QoS support in ad hoc wireless
networks with good performance and low overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4036</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4036</id><created>2011-01-20</created><updated>2011-05-24</updated><authors><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Secure Multiplex Coding with a Common Message</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, no figure, IEEEtran.sty, final version to appear in Proc.
  ISIT 2011</comments><journal-ref>Proc. 2011 IEEE ISIT, pp. 1965-1969, Saint Petersburg, Russia,
  July 31-August 5, 2011</journal-ref><doi>10.1109/ISIT.2011.6033896</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the capacity region of the secure multiplex coding with a common
message, and evaluate the mutual information and the equivocation rate of a
collection of secret messages to the second receiver (eavesdropper), which were
not evaluated by Yamamoto et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4063</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4063</id><created>2011-01-20</created><authors><author><keyname>Xiao</keyname><forenames>Hongda</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>The Impact of Incomplete Information on Games in Parallel Relay Networks</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the impact of incomplete information on incentives for node
cooperation in parallel relay networks with one source node, one destination
node, and multiple relay nodes. All nodes are selfish and strategic, interested
in maximizing their own profit instead of the social welfare. We consider the
practical situation where the channel state on any given relay path is not
observable to the source or to the other relays. We examine different
bargaining relationships between the source and the relays, and propose a
framework for analyzing the efficiency loss induced by incomplete information.
We analyze the source of the efficiency loss, and quantify the amount of
inefficiency which results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4065</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4065</id><created>2011-01-20</created><authors><author><keyname>Kreft</keyname><forenames>Sebastian</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author></authors><title>Self-Index Based on LZ77</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the first self-index based on the Lempel-Ziv 1977 compression
format (LZ77). It is particularly competitive for highly repetitive text
collections such as sequence databases of genomes of related species, software
repositories, versioned document collections, and temporal text databases. Such
collections are extremely compressible but classical self-indexes fail to
capture that source of compressibility. Our self-index takes in practice a few
times the space of the text compressed with LZ77 (as little as 2.6 times),
extracts 1--2 million characters of the text per second, and finds patterns at
a rate of 10--50 microseconds per occurrence. It is smaller (up to one half)
than the best current self-index for repetitive collections, and faster in many
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4068</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4068</id><created>2011-01-20</created><authors><author><keyname>Durocher</keyname><forenames>Stephane</forenames></author><author><keyname>Morrison</keyname><forenames>Jason</forenames></author></authors><title>Linear-Space Data Structures for Range Mode Query in Arrays</title><categories>cs.DS</categories><comments>13 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mode of a multiset $S$ is an element $a \in S$ of maximum multiplicity;
that is, $a$ occurs at least as frequently as any other element in $S$. Given a
list $A[1:n]$ of $n$ items, we consider the problem of constructing a data
structure that efficiently answers range mode queries on $A$. Each query
consists of an input pair of indices $(i, j)$ for which a mode of $A[i:j]$ must
be returned. We present an $O(n^{2-2\epsilon})$-space static data structure
that supports range mode queries in $O(n^\epsilon)$ time in the worst case, for
any fixed $\epsilon \in [0,1/2]$. When $\epsilon = 1/2$, this corresponds to
the first linear-space data structure to guarantee $O(\sqrt{n})$ query time. We
then describe three additional linear-space data structures that provide
$O(k)$, $O(m)$, and $O(|j-i|)$ query time, respectively, where $k$ denotes the
number of distinct elements in $A$ and $m$ denotes the frequency of the mode of
$A$. Finally, we examine generalizing our data structures to higher dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4075</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4075</id><created>2011-01-21</created><authors><author><keyname>Lan</keyname><forenames>Pang-Chang</forenames></author><author><keyname>Wu</keyname><forenames>Chih-Yao</forenames></author><author><keyname>Lee</keyname><forenames>Chia-Han</forenames></author><author><keyname>Yeh</keyname><forenames>Ping-Cheng</forenames></author><author><keyname>Cheng</keyname><forenames>Chen-Mou</forenames></author></authors><title>PMI-based MIMO OFDM PHY Integrated Key Exchange (P-MOPI) Scheme</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures, topic on physical layer security in information
  theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the literature, J.-P. Cheng et al. have proposed the MIMO-OFDM PHY
integrated (MOPI) scheme for achieving physical-layer security in practice
without using any cryptographic ciphers. The MOPI scheme uses channel sounding
and physical-layer network coding (PNC) to prevent eavesdroppers from learning
the channel state information (CSI). Nevertheless, due to the use of multiple
antennas for PNC at transmitter and beamforming at receiver, it is not possible
to have spatial multiplexing nor use space-time codes in our previous MOPI
scheme. In this paper, we propose a variant of the MOPI scheme, called P-MOPI,
that works with a cryptographic cipher and utilizes precoding matrix index
(PMI) as an efficient key-exchange mechanism. With channel sounding, the PMI is
only known between the transmitter and the legal receiver. The shared key can
then be used, e.g., as the seed to generate pseudo random bit sequences for
securing subsequent transmissions using a stream cipher. By applying the same
techniques at independent subcarriers of the OFDM system, the P-MOPI scheme
easily allows two communicating parties to exchange over 100 secret bits. As a
result, not only secure communication but also the MIMO gain can be guaranteed
by using the P-MOPI scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4100</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4100</id><created>2011-01-21</created><updated>2011-10-10</updated><authors><author><keyname>Lexa</keyname><forenames>Michael A.</forenames></author><author><keyname>Davies</keyname><forenames>Mike E.</forenames></author><author><keyname>Thompson</keyname><forenames>John S.</forenames></author></authors><title>Reconciling Compressive Sampling Systems for Spectrally-sparse
  Continuous-time Signals</title><categories>cs.IT math.IT</categories><comments>Corrected typos, updated Section 4.3, 30 pages, 8 figures</comments><doi>10.1109/TSP.2011.2169408</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Random Demodulator (RD) and the Modulated Wideband Converter (MWC) are
two recently proposed compressed sensing (CS) techniques for the acquisition of
continuous-time spectrally-sparse signals. They extend the standard CS paradigm
from sampling discrete, finite dimensional signals to sampling continuous and
possibly infinite dimensional ones, and thus establish the ability to capture
these signals at sub-Nyquist sampling rates. The RD and the MWC have remarkably
similar structures (similar block diagrams), but their reconstruction
algorithms and signal models strongly differ. To date, few results exist that
compare these systems, and owing to the potential impacts they could have on
spectral estimation in applications like electromagnetic scanning and cognitive
radio, we more fully investigate their relationship in this paper. We show that
the RD and the MWC are both based on the general concept of random filtering,
but employ significantly different sampling functions. We also investigate
system sensitivities (or robustness) to sparse signal model assumptions.
Lastly, we show that &quot;block convolution&quot; is a fundamental aspect of the MWC,
allowing it to successfully sample and reconstruct block-sparse (multiband)
signals. Based on this concept, we propose a new acquisition system for
continuous-time signals whose amplitudes are block sparse. The paper includes
detailed time and frequency domain analyses of the RD and the MWC that differ,
sometimes substantially, from published results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4101</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4101</id><created>2011-01-21</created><authors><author><keyname>Antunes</keyname><forenames>Bruno</forenames></author><author><keyname>Correia</keyname><forenames>Francisco</forenames></author><author><keyname>Gomes</keyname><forenames>Paulo</forenames></author></authors><title>Context Capture in Software Development</title><categories>cs.SE cs.AI</categories><comments>3d Artificial Intelligence Techniques in Software Engineering
  Workshop, 7 October, 2010, Larnaca, Cyprus</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The context of a software developer is something hard to define and capture,
as it represents a complex network of elements across different dimensions that
are not limited to the work developed on an IDE. We propose the definition of a
software developer context model that takes into account all the dimensions
that characterize the work environment of the developer. We are especially
focused on what the software developer context encompasses at the project level
and how it can be captured. The experimental work done so far show that useful
context information can be extracted from project management tools. The
extraction, analysis and availability of this context information can be used
to enrich the work environment of the developer with additional knowledge to
support her/his work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4103</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4103</id><created>2011-01-21</created><authors><author><keyname>Whitacre</keyname><forenames>James M</forenames></author><author><keyname>Rohlfshagen</keyname><forenames>Philipp</forenames></author><author><keyname>Bender</keyname><forenames>Axel</forenames></author><author><keyname>Yao</keyname><forenames>Xin</forenames></author></authors><title>Evolutionary Mechanics: new engineering principles for the emergence of
  flexibility in a dynamic and uncertain world</title><categories>nlin.AO cs.AI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Engineered systems are designed to deftly operate under predetermined
conditions yet are notoriously fragile when unexpected perturbations arise. In
contrast, biological systems operate in a highly flexible manner; learn quickly
adequate responses to novel conditions, and evolve new routines/traits to
remain competitive under persistent environmental change. A recent theory on
the origins of biological flexibility has proposed that degeneracy - the
existence of multi-functional components with partially overlapping functions -
is a primary determinant of the robustness and adaptability found in evolved
systems. While degeneracy's contribution to biological flexibility is well
documented, there has been little investigation of degeneracy design principles
for achieving flexibility in systems engineering. Actually, the conditions that
can lead to degeneracy are routinely eliminated in engineering design.
  With the planning of transportation vehicle fleets taken as a case study,
this paper reports evidence that degeneracy improves robustness and
adaptability of a simulated fleet without incurring costs to efficiency. We
find degeneracy dramatically increases robustness of a fleet to unpredicted
changes in the environment while it also facilitates robustness to anticipated
variations. When we allow a fleet's architecture to be adapted in response to
environmental change, we find degeneracy can be selectively acquired, leading
to faster rates of design adaptation and ultimately to better designs. Given
the range of conditions where favorable short-term and long-term performance
outcomes are observed, we propose that degeneracy design principles
fundamentally alter the propensity for adaptation and may be useful within
several engineering and planning contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4104</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4104</id><created>2011-01-21</created><authors><author><keyname>Pimentel</keyname><forenames>Elaine</forenames><affiliation>University of Minas Gerais - Brazil</affiliation></author><author><keyname>Venneri</keyname><forenames>Betti</forenames><affiliation>University of Firenze - Italy</affiliation></author><author><keyname>Wells</keyname><forenames>Joe</forenames><affiliation>Heriot-Watt University - UK</affiliation></author></authors><title>Proceedings Fifth Workshop on Intersection Types and Related Systems</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><acm-class>F.4.1, D.3.1</acm-class><journal-ref>EPTCS 45, 2011</journal-ref><doi>10.4204/EPTCS.45</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Fifth International Workshop on
Intersection Types and Related Systems (ITRS 2010). The workshop was held in
Edinburgh, Scotland, on July 9th 2010, as part of FLoC 2010 and affiliated with
LICS 2010.
  The ITRS workshop series aim at bringing together researchers working on both
the theory and practical applications of systems based on intersection types
and related approaches (e.g., union types, refinement types, behavioral types).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4116</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4116</id><created>2011-01-21</created><updated>2011-09-06</updated><authors><author><keyname>Murri</keyname><forenames>Riccardo</forenames></author><author><keyname>Kunszt</keyname><forenames>Peter Z.</forenames></author><author><keyname>Maffioletti</keyname><forenames>Sergio</forenames></author><author><keyname>Tschopp</keyname><forenames>Valery</forenames></author></authors><title>GridCertLib: a Single Sign-on Solution for Grid Web Applications and
  Portals</title><categories>cs.DC</categories><comments>18 pages, 1 figure; final manuscript accepted for publication by the
  &quot;Journal of Grid Computing&quot;</comments><acm-class>C.2.4; D.4.6; H.3.5</acm-class><doi>10.1007/s10723-011-9195-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the design and implementation of GridCertLib, a Java
library leveraging a Shibboleth-based authentication infrastructure and the
SLCS online certificate signing service, to provide short-lived X.509
certificates and Grid proxies. The main use case envisioned for GridCertLib, is
to provide seamless and secure access to Grid/X.509 certificates and proxies in
web applications and portals: when a user logs in to the portal using
Shibboleth authentication, GridCertLib can automatically obtain a Grid/X.509
certificate from the SLCS service and generate a VOMS proxy from it. We give an
overview of the architecture of GridCertLib and briefly describe its
programming model. Its application to some deployment scenarios is outlined, as
well as a report on practical experience integrating GridCertLib into portals
for Bioinformatics and Computational Chemistry applications, based on the
popular P-GRADE and Django softwares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4152</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4152</id><created>2011-01-21</created><updated>2011-04-01</updated><authors><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author><author><keyname>Lauser</keyname><forenames>Alexander</forenames></author></authors><title>Languages of Dot-depth One over Infinite Words</title><categories>cs.FL cs.LO</categories><comments>Presented at LICS 2011</comments><msc-class>03D05, 68Q45</msc-class><acm-class>F.4.1; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over finite words, languages of dot-depth one are expressively complete for
alternation-free first-order logic. This fragment is also known as the Boolean
closure of existential first-order logic. Here, the atomic formulas comprise
order, successor, minimum, and maximum predicates. Knast (1983) has shown that
it is decidable whether a language has dot-depth one. We extend Knast's result
to infinite words. In particular, we describe the class of languages definable
in alternation-free first-order logic over infinite words, and we give an
effective characterization of this fragment. This characterization has two
components. The first component is identical to Knast's algebraic property for
finite words and the second component is a topological property, namely being a
Boolean combination of Cantor sets.
  As an intermediate step we consider finite and infinite words simultaneously.
We then obtain the results for infinite words as well as for finite words as
special cases. In particular, we give a new proof of Knast's Theorem on
languages of dot-depth one over finite words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4170</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4170</id><created>2011-01-21</created><authors><author><keyname>Martin</keyname><forenames>Victorin</forenames></author><author><keyname>Lasgouttes</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Furtlehner</keyname><forenames>Cyril</forenames></author></authors><title>The Role of Normalization in the Belief Propagation Algorithm</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important part of problems in statistical physics and computer science can
be expressed as the computation of marginal probabilities over a Markov Random
Field. The belief propagation algorithm, which is an exact procedure to compute
these marginals when the underlying graph is a tree, has gained its popularity
as an efficient way to approximate them in the more general case. In this
paper, we focus on an aspect of the algorithm that did not get that much
attention in the literature, which is the effect of the normalization of the
messages. We show in particular that, for a large class of normalization
strategies, it is possible to focus only on belief convergence. Following this,
we express the necessary and sufficient conditions for local stability of a
fixed point in terms of the graph structure and the beliefs values at the fixed
point. We also explicit some connexion between the normalization constants and
the underlying Bethe Free Energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4193</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4193</id><created>2011-01-21</created><updated>2011-02-12</updated><authors><author><keyname>Butelle</keyname><forenames>Franck</forenames></author><author><keyname>Coti</keyname><forenames>Camille</forenames></author></authors><title>A Model for Coherent Distributed Memory For Race Condition Detection</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new model for distributed shared memory systems, based on remote
data accesses. Such features are offered by network interface cards that allow
one-sided operations, remote direct memory access and OS bypass. This model
leads to new interpretations of distributed algorithms allowing us to propose
an innovative detection technique of race conditions only based on logical
clocks. Indeed, the presence of (data) races in a parallel program makes it
hard to reason about and is usually considered as a bug.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4204</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4204</id><created>2011-01-21</created><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Kr&#x10d;&#xe1;l</keyname><forenames>Jan</forenames></author><author><keyname>K&#x159;et&#xed;nsk&#xfd;</keyname><forenames>Jan</forenames></author><author><keyname>Ku&#x10d;era</keyname><forenames>Anton&#xed;n</forenames></author><author><keyname>&#x158;eh&#xe1;k</keyname><forenames>Vojt&#x11b;ch</forenames></author></authors><title>Measuring Performance of Continuous-Time Stochastic Processes using
  Timed Automata</title><categories>cs.SY cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose deterministic timed automata (DTA) as a model-independent language
for specifying performance and dependability measures over continuous-time
stochastic processes. Technically, these measures are defined as limit
frequencies of locations (control states) of a DTA that observes computations
of a given stochastic process. Then, we study the properties of DTA measures
over semi-Markov processes in greater detail. We show that DTA measures over
semi-Markov processes are well-defined with probability one, and there are only
finitely many values that can be assumed by these measures with positive
probability. We also give an algorithm which approximates these values and the
associated probabilities up to an arbitrarily small given precision. Thus, we
obtain a general and effective framework for analysing DTA measures over
semi-Markov processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4207</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4207</id><created>2011-01-21</created><updated>2012-03-01</updated><authors><author><keyname>Abdallah</keyname><forenames>Saeed</forenames></author><author><keyname>Psaromiligkos</keyname><forenames>Ioannis N.</forenames></author></authors><title>Blind Channel Estimation for Amplify-and-Forward Two-Way Relay Networks
  Employing M-PSK Modulation</title><categories>cs.IT math.IT stat.OT</categories><comments>29 pages, 8 figures</comments><doi>10.1109/TSP.2012.2193577</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of channel estimation for amplify-and-forward (AF)
two-way relay networks (TWRNs). Most works on this problem focus on pilot-based
approaches which impose a significant training overhead that reduces the
spectral efficiency of the system. To avoid such losses, this work proposes
blind channel estimation algorithms for AF TWRNs that employ constant-modulus
(CM) signaling. Our main algorithm is based on the deterministic maximum
likelihood (DML) approach. Assuming M-PSK modulation, we show that the
resulting estimator is consistent and approaches the true channel with high
probability at high SNR for modulation orders higher than 2. For BPSK, however,
the DML performs poorly and we propose an alternative algorithm that performs
much better by taking into account the BPSK structure of the data symbols. For
comparative purposes, we also investigate the Gaussian maximum-likelihood (GML)
approach which treats the data symbols as Gaussian-distributed nuisance
parameters. We derive the Cramer-Rao bound and use Monte-Carlo simulations to
investigate the mean squared error (MSE) performance of the proposed
algorithms. We also compare the symbol-error rate (SER) performance of the DML
algorithm with that of the training-based least-squares (LS) algorithm and
demonstrate that the DML offers a superior tradeoff between accuracy and
spectral efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4211</identifier>
 <datestamp>2012-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4211</id><created>2011-01-21</created><updated>2012-06-13</updated><authors><author><keyname>Ji</keyname><forenames>Bo</forenames></author><author><keyname>Joo</keyname><forenames>Changhee</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Throughput-optimal Scheduling in Multi-hop Wireless Networks without
  Per-flow Information</title><categories>cs.NI cs.IT cs.PF math.IT</categories><comments>To appear in IEEE/ACM Transactions on Networking. A preliminary
  version of this work was presented at IEEE WiOpt 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of link scheduling in multi-hop
wireless networks under general interference constraints. Our goal is to design
scheduling schemes that do not use per-flow or per-destination information,
maintain a single data queue for each link, and exploit only local information,
while guaranteeing throughput optimality. Although the celebrated back-pressure
algorithm maximizes throughput, it requires per-flow or per-destination
information. It is usually difficult to obtain and maintain this type of
information, especially in large networks, where there are numerous flows.
Also, the back-pressure algorithm maintains a complex data structure at each
node, keeps exchanging queue length information among neighboring nodes, and
commonly results in poor delay performance. In this paper, we propose
scheduling schemes that can circumvent these drawbacks and guarantee throughput
optimality. These schemes use either the readily available hop-count
information or only the local information for each link. We rigorously analyze
the performance of the proposed schemes using fluid limit techniques via an
inductive argument and show that they are throughput-optimal. We also conduct
simulations to validate our theoretical results in various settings, and show
that the proposed schemes can substantially improve the delay performance in
most scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4222</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4222</id><created>2011-01-21</created><authors><author><keyname>Thapliyal</keyname><forenames>Himanshu</forenames></author><author><keyname>Ranganathan</keyname><forenames>Nagarajan</forenames></author></authors><title>Reversible Logic Based Concurrent Error Detection Methodology For
  Emerging Nanocircuits</title><categories>cs.AR quant-ph</categories><comments>H. Thapliyal and N.Ranganathan, &quot;Reversible Logic Based Concurrent
  Error Detection Methodology For Emerging Nanocircuits&quot;, Proceedings of the
  10th IEEE International Conference on Nanotechnology, Seoul, Korea, Aug 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic has promising applications in emerging nanotechnologies,
such as quantum computing, quantum dot cellular automata and optical computing,
etc. Faults in reversible logic circuits that result in multi-bit error at the
outputs are very tough to detect, and thus in literature, researchers have only
addressed the problem of online testing of faults that result single-bit error
at the outputs based on parity preserving logic. In this work, we propose a
methodology for the concurrent error detection in reversible logic circuits to
detect faults that can result in multi-bit error at the outputs. The
methodology is based on the inverse property of reversible logic and is termed
as 'inverse and compare' method. By using the inverse property of reversible
logic, all the inputs can be regenerated at the outputs. Thus, by comparing the
original inputs with the regenerated inputs, the faults in reversible circuits
can be detected. Minimizing the garbage outputs is one of the main goals in
reversible logic design and synthesis. We show that the proposed methodology
results in 'garbageless' reversible circuits. A design of reversible full adder
that can be concurrently tested for multi-bit error at the outputs is
illustrated as the application of the proposed scheme. Finally, we showed the
application of the proposed scheme of concurrent error detection towards fault
detection in quantum dot cellular automata (QCA) emerging nanotechnology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4223</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4223</id><created>2011-01-21</created><updated>2011-05-03</updated><authors><author><keyname>Staton</keyname><forenames>Sam</forenames><affiliation>Laboratoire PPS, Universit&#xe9; Paris 7</affiliation></author></authors><title>Relating coalgebraic notions of bisimulation</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.3.2, G.2.m</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 30,
  2011) lmcs:670</journal-ref><doi>10.2168/LMCS-7(1:13)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of coalgebras, for an endofunctor on a category, has been proposed
as a general theory of transition systems. We investigate and relate four
generalizations of bisimulation to this setting, providing conditions under
which the four different generalizations coincide. We study transfinite
sequences whose limits are the greatest bisimulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4227</identifier>
 <datestamp>2011-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4227</id><created>2011-01-21</created><updated>2011-10-30</updated><authors><author><keyname>Steeg</keyname><forenames>Greg Ver</forenames></author><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author><author><keyname>Allahverdyan</keyname><forenames>Armen E.</forenames></author></authors><title>Statistical Mechanics of Semi-Supervised Clustering in Sparse Graphs</title><categories>physics.data-an cond-mat.dis-nn cond-mat.stat-mech cs.LG</categories><comments>8 pages, 4 figures</comments><journal-ref>J. Stat. Mech. (2011) P08009</journal-ref><doi>10.1088/1742-5468/2011/08/P08009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We theoretically study semi-supervised clustering in sparse graphs in the
presence of pairwise constraints on the cluster assignments of nodes. We focus
on bi-cluster graphs, and study the impact of semi-supervision for varying
constraint density and overlap between the clusters. Recent results for
unsupervised clustering in sparse graphs indicate that there is a critical
ratio of within-cluster and between-cluster connectivities below which clusters
cannot be recovered with better than random accuracy. The goal of this paper is
to examine the impact of pairwise constraints on the clustering accuracy. Our
results suggests that the addition of constraints does not provide automatic
improvement over the unsupervised case. When the density of the constraints is
sufficiently small, their only impact is to shift the detection threshold while
preserving the criticality. Conversely, if the density of (hard) constraints is
above the percolation threshold, the criticality is suppressed and the
detection threshold disappears.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4236</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4236</id><created>2011-01-21</created><authors><author><keyname>Kothapalli</keyname><forenames>Yashwanth</forenames></author></authors><title>Indexing Properties of Primitive Pythagorean Triples for Cryptography
  Applications</title><categories>cs.CR</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new properties of Primitive Pythagorean Triples (PPT)
that have relevance in applications where events of different probability need
to be generated and in cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4260</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4260</id><created>2011-01-21</created><updated>2011-05-20</updated><authors><author><keyname>Shahriar</keyname><forenames>Nashid</forenames></author><author><keyname>Sharmin</keyname><forenames>Mahfuza</forenames></author><author><keyname>Ahmed</keyname><forenames>Reaz</forenames></author><author><keyname>Boutaba</keyname><forenames>Raouf</forenames></author></authors><title>Networking</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses an efficient approach to design and implement a highly
available peer- to-peer system irrespective of peer timing and churn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4264</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4264</id><created>2011-01-22</created><updated>2011-03-25</updated><authors><author><keyname>Horvath</keyname><forenames>Tamas</forenames></author><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Scheuer</keyname><forenames>Jacob</forenames></author></authors><title>Effective Privacy Amplification for Secure Classical Communications</title><categories>cs.CR quant-ph</categories><comments>11 pages, 3 figures</comments><journal-ref>EPL (formerly Europhysics Letters) 94 (2011) 28002-p1 - 28002-p6</journal-ref><doi>10.1209/0295-5075/94/28002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the practical effectiveness of privacy amplification for classical
key-distribution schemes. We find that in contrast to quantum key distribution
schemes, the high fidelity of the raw key generated in classical systems allow
the users to always sift a secure shorter key if they have an upper bound on
the eavesdropper probability to correctly guess the exchanged key-bits. The
number of privacy amplification iterations needed to achieve information leak
of 10^-8 in existing classical communicators is 2 or 3 resulting in a
corresponding slowdown 4 to 8. We analyze the inherent tradeoff between the
number of iterations and the security of the raw key. This property which is
unique to classical key distribution systems render them highly useful for
practical, especially for noisy channels where sufficiently low quantum bit
error ratios are difficult to achieve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4266</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4266</id><created>2011-01-22</created><authors><author><keyname>Legay</keyname><forenames>Axel</forenames><affiliation>INRIA, Rennes</affiliation></author><author><keyname>Caillaud</keyname><forenames>Beno&#xee;t</forenames><affiliation>INRIA, Rennes</affiliation></author></authors><title>Proceedings Foundations for Interface Technologies</title><categories>cs.LO cs.SE</categories><proxy>EPTCS</proxy><acm-class>D.2.2</acm-class><journal-ref>EPTCS 46, 2011</journal-ref><doi>10.4204/EPTCS.46</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  FIT stands for Foundations of Interface Technologies. Component-based design
is widely considered as a major approach to developing systems in a time and
cost effective way. Central in this approach is the notion of an interface.
Interfaces summarize the externally visible properties of a component and are
seen as a key to achieving component interoperability and to predict global
system behavior based on the component behavior. To capture the intricacy of
complex software products, rich interfaces have been proposed. These interfaces
do not only specify syntactic properties, such as the signatures of methods and
operations, but also take into account behavioral and extra-functional
properties, such as quality of service, security and dependability. Rich
interfaces have been proposed for describing, e.g., the legal sequences of
messages or method calls accepted by components, or the resource and timing
constraints in embedded software. The development of a rigorous framework for
the specification and analysis of rich interfaces is challenging. The aim of
this workshop is to bring together researchers who are interested in the formal
underpinnings of interface technologies
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4270</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4270</id><created>2011-01-22</created><authors><author><keyname>Sembiring</keyname><forenames>Rahmat Widia</forenames></author><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author><author><keyname>Embong</keyname><forenames>Abdullah</forenames></author></authors><title>A Comparative Agglomerative Hierarchical Clustering Method to Cluster
  Implemented Course</title><categories>cs.DB</categories><comments>6 pages, 10 figures, published on Journal of Computing, Volume 2,
  Issue 12, December 2010</comments><journal-ref>Journal of Computing, Volume 2, Issue 12, December 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many clustering methods, such as hierarchical clustering method.
Most of the approaches to the clustering of variables encountered in the
literature are of hierarchical type. The great majority of hierarchical
approaches to the clustering of variables are of agglomerative nature. The
agglomerative hierarchical approach to clustering starts with each observation
as its own cluster and then continually groups the observations into
increasingly larger groups. Higher Learning Institution (HLI) provides training
to introduce final-year students to the real working environment. In this
research will use Euclidean single linkage and complete linkage. MATLAB and HCE
3.5 software will used to train data and cluster course implemented during
industrial training. This study indicates that different method will create a
different number of clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4271</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4271</id><created>2011-01-22</created><authors><author><keyname>Bu</keyname><forenames>Lei</forenames></author><author><keyname>Chen</keyname><forenames>Xin</forenames></author><author><keyname>Wang</keyname><forenames>Linzhang</forenames></author><author><keyname>Li</keyname><forenames>Xuandong</forenames></author></authors><title>Online Verification of Control Parameter Calculations in Communication
  Based Train Control System</title><categories>cs.SE cs.LO</categories><comments>16 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication Based Train Control (CBTC) system is the state-of-the-art train
control system. In a CBTC system, to guarantee the safety of train operation,
trains communicate with each other intensively and adjust their control modes
autonomously by computing critical control parameters, e.g. velocity range,
according to the information they get. As the correctness of the control
parameters generated are critical to the safety of the system, a method to
verify these parameters is a strong desire in the area of train control system.
In this paper, we present our ideas of how to model and verify the control
parameter calculations in a CBTC system efficiently. - As the behavior of the
system is highly nondeterministic, it is difficult to build and verify the
complete behavior space model of the system online in advance. Thus, we propose
to model the system according to the ongoing behavior model induced by the
control parameters. - As the parameters are generated online and updated very
quickly, the verification result will be meaningless if it is given beyond the
time bound, since by that time the model will be changed already. Thus, we
propose a method to verify the existence of certain dangerous scenarios in the
model online quickly. To demonstrate the feasibility of these proposed
approaches, we present the composed linear hybrid automata with readable shared
variables as a modeling language to model the control parameters calculation
and give a path-oriented reachability analysis technique for the scenario-based
verification of this model. We demonstrate the model built for the CBTC system,
and show the performance of our technique in fast online verification. Last but
not least, as CBTC system is a typical CPS system, we also give a short
discussion of the potential directions for CPS verification in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4275</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4275</id><created>2011-01-22</created><updated>2012-05-25</updated><authors><author><keyname>Dvorak</keyname><forenames>Z.</forenames></author></authors><title>3-choosability of planar graphs with (&lt;=4)-cycles far apart</title><categories>math.CO cs.DM</categories><comments>59 pages, 7 figures; revised based on referee remarks</comments><msc-class>05C15</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is k-choosable if it can be colored whenever every vertex has a list
of at least k available colors. We prove that if cycles of length at most four
in a planar graph G are pairwise far apart, then G is 3-choosable. This is
analogous to the problem of Havel regarding 3-colorability of planar graphs
with triangles far apart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4279</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4279</id><created>2011-01-22</created><authors><author><keyname>Som</keyname><forenames>Pritam</forenames></author><author><keyname>Datta</keyname><forenames>Tanumay</forenames></author><author><keyname>Srinidhi</keyname><forenames>N.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Low-Complexity Detection/Equalization in Large-Dimension MIMO-ISI
  Channels Using Graphical Models</title><categories>cs.IT math.IT</categories><doi>10.1109/JSTSP.2011.2166950</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we deal with low-complexity near-optimal
detection/equalization in large-dimension multiple-input multiple-output
inter-symbol interference (MIMO-ISI) channels using message passing on
graphical models. A key contribution in the paper is the demonstration that
near-optimal performance in MIMO-ISI channels with large dimensions can be
achieved at low complexities through simple yet effective
simplifications/approximations, although the graphical models that represent
MIMO-ISI channels are fully/densely connected (loopy graphs). These include 1)
use of Markov Random Field (MRF) based graphical model with pairwise
interaction, in conjunction with {\em message/belief damping}, and 2) use of
Factor Graph (FG) based graphical model with {\em Gaussian approximation of
interference} (GAI). The per-symbol complexities are $O(K^2n_t^2)$ and
$O(Kn_t)$ for the MRF and the FG with GAI approaches, respectively, where $K$
and $n_t$ denote the number of channel uses per frame, and number of transmit
antennas, respectively. These low-complexities are quite attractive for large
dimensions, i.e., for large $Kn_t$. From a performance perspective, these
algorithms are even more interesting in large-dimensions since they achieve
increasingly closer to optimum detection performance for increasing $Kn_t$.
Also, we show that these message passing algorithms can be used in an iterative
manner with local neighborhood search algorithms to improve the
reliability/performance of $M$-QAM symbol detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4283</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4283</id><created>2011-01-22</created><updated>2011-02-18</updated><authors><author><keyname>Sorge</keyname><forenames>Manuel</forenames></author></authors><title>On Making Directed Graphs Eulerian</title><categories>cs.DM</categories><comments>Revised version. Corrected typographic errors, corrected minor flaw,
  added many examples, schematics, and tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A directed graph is called Eulerian, if it contains a tour that traverses
every arc in the graph exactly once. We study the problem of Eulerian extension
(EE) where a directed multigraph G and a weight function is given and it is
asked whether G can be made Eulerian by adding arcs whose total weight does not
exceed a given threshold. This problem is motivated through applications in
vehicle routing and flowshop scheduling. However, EE is NP-hard and thus we use
the parameterized complexity framework to analyze it. In parameterized
complexity, the running time of algorithms is considered not only with respect
to input length, but also with respect to other properties of the input -
called &quot;parameters&quot;. Dorn et. al. proved that EE can be solved in O(4^k n^4)
time, where k denotes the parameter &quot;number of arcs that have to be added&quot;. In
this thesis, we analyze EE with respect to the (smaller) parameters &quot;number c
of connected components in the input graph&quot; and &quot;sum b over indeg(v) -
outdeg(v) for all vertices v in the input graph where this value is positive&quot;.
We prove that there is an algorithm for EE whose running time is polynomial
except for the term 4^(c log(bc^2)). To obtain this result, we make several
observations about the sets of arcs that have to be added to the input graph in
order to make it Eulerian. We build upon these observations to restate EE in a
matching context. This matching formulation of EE might be an important tool to
solve the question of whether EE can be solved within running time whose
superpolynomial part depends only on c. We also consider polynomial time
preprocessing routines for EE and show that these routines cannot yield
instances whose size depends polynomially only on either of the parameters b,
c, k unless coNP is contained in NP/poly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4285</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4285</id><created>2011-01-22</created><updated>2011-06-02</updated><authors><author><keyname>Zhang</keyname><forenames>Lianming</forenames></author><author><keyname>Deng</keyname><forenames>Xiaoheng</forenames></author><author><keyname>Yu</keyname><forenames>Jianping</forenames></author><author><keyname>Wu</keyname><forenames>Xiangsheng</forenames></author></authors><title>Degree and connectivity of the Internet's scale-free topology</title><categories>cs.NI cs.SI physics.soc-ph</categories><comments>22 pages, 8 figures</comments><journal-ref>Chinese Physics B, Volume 20, Issue 4, pp. 048902 (2011)</journal-ref><doi>10.1088/1674-1056/20/4/048902</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we theoretically and empirically study the degree and
connectivity of the Internet's scale-free topology at the autonomous system
(AS) level. The basic features of the scale-free network have influence on the
normalization constant of the degree distribution p(k). We develop a
mathematics model of the Internet's scale-free topology. On this model we
theoretically get the formulas of the average degree, the ratios of the
kmin-degree (minimum degree) nodes and the kmax-degree (maximum degree) nodes,
the fraction of the degrees (or links) in the hands of the richer (top
best-connected) nodes. We find the average degree is larger for smaller
power-law exponent {\lambda} and larger minimum or maximum degree. The ratio of
the kmin-degree nodes is larger for larger {\lambda} and smaller kmin or kmax.
The ratio of the kmax-degree ones is larger for smaller {\lambda} and kmax or
larger kmin. The richer nodes hold most of the total degrees of the AS-level
Internet topology. In addition, we reveal the ratio of the kmin-degree nodes or
the rate of the increase of the average degree has power-law decay with the
increase of the kmin. The ratio of the kmax-degree nodes has power-law decay
with the increase of the kmax, and the fraction of the degrees in the hands of
the richer 27% nodes is about 73% (the '73/27 rule'). At last, we empirically
calculate, based on empirical data extracted from BGP, the average degree and
the ratio and fraction using our method and other methods, and find that our
method is rigorous and effective for the AS-level Internet topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4301</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4301</id><created>2011-01-22</created><authors><author><keyname>Kovnatsky</keyname><forenames>Artiom</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author><author><keyname>Bronstein</keyname><forenames>Alexander M.</forenames></author><author><keyname>Kimmel</keyname><forenames>Ron</forenames></author></authors><title>Diffusion framework for geometric and photometric data fusion in
  non-rigid shape analysis</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore the use of the diffusion geometry framework for the
fusion of geometric and photometric information in local and global shape
descriptors. Our construction is based on the definition of a diffusion process
on the shape manifold embedded into a high-dimensional space where the
embedding coordinates represent the photometric information. Experimental
results show that such data fusion is useful in coping with different
challenges of shape analysis where pure geometric and pure photometric methods
fail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4306</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4306</id><created>2011-01-22</created><authors><author><keyname>Li</keyname><forenames>Quan-Lin</forenames></author><author><keyname>Lui</keyname><forenames>John C. S.</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author></authors><title>A Matrix-Analytic Solution for Randomized Load Balancing Models with
  Phase-Type Service Times</title><categories>cs.NI math.AP</categories><comments>24 pages</comments><msc-class>60J75, 90B15, 90B18, 90B22, 94A05</msc-class><acm-class>C.1; C.2; C.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we provide a matrix-analytic solution for randomized load
balancing models (also known as \emph{supermarket models}) with phase-type (PH)
service times. Generalizing the service times to the phase-type distribution
makes the analysis of the supermarket models more difficult and challenging
than that of the exponential service time case which has been extensively
discussed in the literature. We first describe the supermarket model as a
system of differential vector equations, and provide a doubly exponential
solution to the fixed point of the system of differential vector equations.
Then we analyze the exponential convergence of the current location of the
supermarket model to its fixed point. Finally, we present numerical examples to
illustrate our approach and show its effectiveness in analyzing the randomized
load balancing schemes with non-exponential service requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4313</identifier>
 <datestamp>2013-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4313</id><created>2011-01-22</created><updated>2011-10-25</updated><authors><author><keyname>Boscain</keyname><forenames>Ugo</forenames><affiliation>CMAP, INRIA Saclay - Ile de France / CMAP Centre de Math&#xe9;matiques Appliqu&#xe9;es</affiliation></author><author><keyname>Caponigro</keyname><forenames>Marco</forenames><affiliation>IECN, INRIA Lorraine / IECN / MMAS</affiliation></author><author><keyname>Chambrion</keyname><forenames>Thomas</forenames><affiliation>IECN, INRIA Lorraine / IECN / MMAS</affiliation></author><author><keyname>Sigalotti</keyname><forenames>Mario</forenames><affiliation>INRIA Saclay - Ile de France / CMAP Centre de Math&#xe9;matiques Appliqu&#xe9;es</affiliation></author></authors><title>A weak spectral condition for the controllability of the bilinear
  Schr\&quot;odinger equation with application to the control of a rotating planar
  molecule</title><categories>math.OC cs.SY math.AP</categories><proxy>ccsd</proxy><journal-ref>Communications in Mathematical Physics 311, 2 (2012) 423-455</journal-ref><doi>10.1007/s00220-012-1441-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove an approximate controllability result for the bilinear
Schr\&quot;odinger equation. This result requires less restrictive non-resonance
hypotheses on the spectrum of the uncontrolled Schr\&quot;odinger operator than
those present in the literature. The control operator is not required to be
bounded and we are able to extend the controllability result to the density
matrices. The proof is based on fine controllability properties of the finite
dimensional Galerkin approximations and allows to get estimates for the $L^{1}$
norm of the control. The general controllability result is applied to the
problem of controlling the rotation of a bipolar rigid molecule confined on a
plane by means of two orthogonal external fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4318</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4318</id><created>2011-01-22</created><updated>2011-02-14</updated><authors><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>VALORIA</affiliation></author></authors><title>Discrete Time Elastic Vector Spaces</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose in this paper a framework dedicated to the construction of what we
call time elastic inner products that allows embedding sets of non-uniformly
sampled multivariate time series of varying lengths into vector space
structures. This framework is based on a recursive definition that covers the
case of multiple embedded time elastic dimensions. We prove that such inner
products exist in our framework and show how a simple instance of this inner
product class operates on some toy applications, while generalizing the
Euclidean inner product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4335</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4335</id><created>2011-01-22</created><authors><author><keyname>Al-Safadi</keyname><forenames>Ebrahim B.</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author></authors><title>Peak Reduction and Clipping Mitigation by Compressive Sensing</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><msc-class>94A12, 94A20</msc-class><doi>10.1109/TSP.2012.2193396</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work establishes the design, analysis, and fine-tuning of a
Peak-to-Average-Power-Ratio (PAPR) reducing system, based on compressed sensing
at the receiver of a peak-reducing sparse clipper applied to an OFDM signal at
the transmitter. By exploiting the sparsity of the OFDM signal in the time
domain relative to a pre-defined clipping threshold, the method depends on
partially observing the frequency content of extremely simple sparse clippers
to recover the locations, magnitudes, and phases of the clipped coefficients of
the peak-reduced signal. We claim that in the absence of optimization
algorithms at the transmitter that confine the frequency support of clippers to
a predefined set of reserved-tones, no other tone-reservation method can
reliably recover the original OFDM signal with such low complexity.
  Afterwards we focus on designing different clipping signals that can embed a
priori information regarding the support and phase of the peak-reducing signal
to the receiver, followed by modified compressive sensing techniques for
enhanced recovery. This includes data-based weighted {\ell} 1 minimization for
enhanced support recovery and phase-augmention for homogeneous clippers
followed by Bayesian techniques.
  We show that using such techniques for a typical OFDM signal of 256
subcarriers and 20% reserved tones, the PAPR can be reduced by approximately
4.5 dB with a significant increase in capacity compared to a system which uses
all its tones for data transmission and clips to such levels. The design is
hence appealing from both capacity and PAPR reduction aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4341</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4341</id><created>2011-01-22</created><authors><author><keyname>Nagaraj</keyname><forenames>Nithin</forenames></author><author><keyname>Kavalekalam</keyname><forenames>Mathew Shaji</forenames></author><author><keyname>T.</keyname><forenames>Arjun Venugopal</forenames></author><author><keyname>Krishnan</keyname><forenames>Nithin</forenames></author></authors><title>Lossless Compression and Complexity of Chaotic Sequences</title><categories>nlin.CD cs.CR</categories><comments>4 pages (revtex4 format), 3 figures, 2 tables. This paper is being
  presented at the Sixth National Conference on Nonlinear Systems and Dynamics
  (NCNSD - 2011) Center for Nonlinear Dynamics, School of Physics,
  Bharathidasan University Tiruchirappalli</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the complexity of short symbolic sequences of chaotic
dynamical systems by using lossless compression algorithms. In particular, we
study Non-Sequential Recursive Pair Substitution (NSRPS), a lossless
compression algorithm first proposed by W. Ebeling et al. [Math. Biosc. 52,
1980] and Jim\'{e}nez-Monta\~{n}o et al. [arXiv:cond-mat/0204134, 2002]) which
was subsequently shown to be optimal. NSPRS has also been used to estimate
Entropy of written English (P. Grassberger [arXiv:physics/0207023, 2002]). We
propose a new measure of complexity - defined as the number of iterations of
NSRPS required to transform the input sequence into a constant sequence. We
test this measure on symbolic sequences of the Logistic map for various values
of the bifurcation parameter. The proposed measure of complexity is easy to
compute and is observed to be highly correlated with the Lyapunov exponent of
the original non-linear time series, even for very short symbolic sequences (as
short as 50 samples). Finally, we construct symbolic sequences from the
Skew-Tent map which are incompressible by popular compression algorithms like
WinZip, WinRAR and 7-Zip, but compressible by NSRPS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4343</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4343</id><created>2011-01-23</created><authors><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Xu</keyname><forenames>Shugong</forenames></author><author><keyname>Li</keyname><forenames>Geoffrey Ye</forenames></author></authors><title>Fundamental Tradeoffs on Green Wireless Networks</title><categories>cs.IT math.IT</categories><comments>one column, 17 pages, 6 figures, accepted by IEEE Communications
  Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional design of mobile wireless networks mainly focuses on ubiquitous
access and large capacity. However, as energy saving and environmental
protection become a global demand and inevitable trend, wireless researchers
and engineers need to shift their focus to energy-efficiency oriented design,
that is, green radio. In this paper, we propose a framework for green radio
research and integrate the fundamental issues that are currently scattered. The
skeleton of the framework consists of four fundamental tradeoffs: deployment
efficiency - energy efficiency tradeoff, spectrum efficiency - energy
efficiency tradeoff, bandwidth - power tradeoff, and delay - power tradeoff.
With the help of the four fundamental tradeoffs, we demonstrate that key
network performance/cost indicators are all stringed together.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4351</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4351</id><created>2011-01-23</created><authors><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author><author><keyname>Salomon</keyname><forenames>Michel</forenames></author></authors><title>Building a Chaotic Proved Neural Network</title><categories>cs.AI cs.CR math.DS math.GN</categories><comments>6 pages, submitted to ICCANS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chaotic neural networks have received a great deal of attention these last
years. In this paper we establish a precise correspondence between the
so-called chaotic iterations and a particular class of artificial neural
networks: global recurrent multi-layer perceptrons. We show formally that it is
possible to make these iterations behave chaotically, as defined by Devaney,
and thus we obtain the first neural networks proven chaotic. Several neural
networks with different architectures are trained to exhibit a chaotical
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4355</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4355</id><created>2011-01-23</created><updated>2011-07-26</updated><authors><author><keyname>Mokhov</keyname><forenames>Oleg I.</forenames></author></authors><title>On Initial Data in the Problem of Consistency on Cubic Lattices for $3
  \times 3$ Determinants</title><categories>nlin.SI cs.CG cs.DM math-ph math.DS math.MP</categories><proxy>Sigma</proxy><journal-ref>SIGMA 7 (2011), 075, 19 pages</journal-ref><doi>10.3842/SIGMA.2011.075</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The paper is devoted to complete proofs of theorems on consistency on cubic
lattices for $3 \times 3$ determinants. The discrete nonlinear equations on
$\mathbb{Z}^2$ defined by the condition that the determinants of all $3 \times
3$ matrices of values of the scalar field at the points of the lattice
$\mathbb{Z}^2$ that form elementary $3 \times 3$ squares vanish are considered;
some explicit concrete conditions of general position on initial data are
formulated; and for arbitrary initial data satisfying these concrete conditions
of general position, theorems on consistency on cubic lattices (a consistency
&quot;around a cube&quot;) for the considered discrete nonlinear equations on
$\mathbb{Z}^2$ defined by $3 \times 3$ determinants are proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4356</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4356</id><created>2011-01-23</created><authors><author><keyname>Burato</keyname><forenames>Elisa</forenames></author><author><keyname>Cristani</keyname><forenames>Matteo</forenames></author><author><keyname>Vigan&#xf2;</keyname><forenames>Luca</forenames></author></authors><title>Meaning Negotiation as Inference</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meaning negotiation (MN) is the general process with which agents reach an
agreement about the meaning of a set of terms. Artificial Intelligence scholars
have dealt with the problem of MN by means of argumentations schemes, beliefs
merging and information fusion operators, and ontology alignment but the
proposed approaches depend upon the number of participants. In this paper, we
give a general model of MN for an arbitrary number of agents, in which each
participant discusses with the others her viewpoint by exhibiting it in an
actual set of constraints on the meaning of the negotiated terms. We call this
presentation of individual viewpoints an angle. The agents do not aim at
forming a common viewpoint but, instead, at agreeing about an acceptable common
angle. We analyze separately the process of MN by two agents (\emph{bilateral}
or \emph{pairwise} MN) and by more than two agents (\emph{multiparty} MN), and
we use game theoretic models to understand how the process develops in both
cases: the models are Bargaining Game for bilateral MN and English Auction for
multiparty MN. We formalize the process of reaching such an agreement by giving
a deduction system that comprises of rules that are consistent and adequate for
representing MN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4364</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4364</id><created>2011-01-23</created><updated>2011-04-20</updated><authors><author><keyname>Miquel</keyname><forenames>Alexandre</forenames><affiliation>LIP / ENS Lyon - PPS / Paris 7</affiliation></author></authors><title>Existential witness extraction in classical realizability and via a
  negative translation</title><categories>cs.LO</categories><comments>52 pages. Accepted in Logical Methods for Computer Science (LMCS),
  2010</comments><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (April 22,
  2011) lmcs:1068</journal-ref><doi>10.2168/LMCS-7(2:2)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to extract existential witnesses from classical proofs using
Krivine's classical realizability---where classical proofs are interpreted as
lambda-terms with the call/cc control operator. We first recall the basic
framework of classical realizability (in classical second-order arithmetic) and
show how to extend it with primitive numerals for faster computations. Then we
show how to perform witness extraction in this framework, by discussing several
techniques depending on the shape of the existential formula. In particular, we
show that in the Sigma01-case, Krivine's witness extraction method reduces to
Friedman's through a well-suited negative translation to intuitionistic
second-order arithmetic. Finally we discuss the advantages of using call/cc
rather than a negative translation, especially from the point of view of an
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4369</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4369</id><created>2011-01-23</created><updated>2011-05-09</updated><authors><author><keyname>Strzebonski</keyname><forenames>Adam</forenames></author><author><keyname>Tsigaridas</keyname><forenames>Elias</forenames></author></authors><title>Univariate real root isolation in an extension field</title><categories>cs.SC cs.MS cs.NA math.AG math.NA</categories><comments>16 pages</comments><acm-class>F.2; I.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithmic, complexity and implementation results for the problem
of isolating the real roots of a univariate polynomial in $B_{\alpha} \in
L[y]$, where $L=\QQ(\alpha)$ is a simple algebraic extension of the rational
numbers. We consider two approaches for tackling the problem. In the first
approach using resultant computations we perform a reduction to a polynomial
with integer coefficients. We compute separation bounds for the roots, and
using them we deduce that we can isolate the real roots of $B_{\alpha}$ in
$\sOB(N^{10})$, where $N$ is an upper bound on all the quantities (degree and
bitsize) of the input polynomials. In the second approach we isolate the real
roots working directly on the polynomial of the input. We compute improved
separation bounds for real roots and we prove that they are optimal, under mild
assumptions. For isolating the roots we consider a modified Sturm's algorithm,
and a modified version of \func{descartes}' algorithm introduced by Sagraloff.
For the former we prove a complexity bound of $\sOB(N^8)$ and for the latter a
bound of $\sOB(N^{7})$. We implemented the algorithms in \func{C} as part of
the core library of \mathematica and we illustrate their efficiency over
various data sets. Finally, we present complexity results for the general case
of the first approach, where the coefficients belong to multiple extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4372</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4372</id><created>2011-01-23</created><authors><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>Borokhovich</keyname><forenames>Michael</forenames></author><author><keyname>Censor-Hillel</keyname><forenames>Keren</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author></authors><title>Order Optimal Information Spreading Using Algebraic Gossip</title><categories>cs.IT cs.DC cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study gossip based information spreading with bounded
message sizes. We use algebraic gossip to disseminate $k$ distinct messages to
all $n$ nodes in a network. For arbitrary networks we provide a new upper bound
for uniform algebraic gossip of $O((k+\log n + D)\Delta)$ rounds with high
probability, where $D$ and $\Delta$ are the diameter and the maximum degree in
the network, respectively. For many topologies and selections of $k$ this bound
improves previous results, in particular, for graphs with a constant maximum
degree it implies that uniform gossip is \emph{order optimal} and the stopping
time is $\Theta(k + D)$.
  To eliminate the factor of $\Delta$ from the upper bound we propose a
non-uniform gossip protocol, TAG, which is based on algebraic gossip and an
arbitrary spanning tree protocol $\S$. The stopping time of TAG is $O(k+\log n
+d(\S)+t(\S))$, where $t(\S)$ is the stopping time of the spanning tree
protocol, and $d(\S)$ is the diameter of the spanning tree. We provide two
general cases in which this bound leads to an order optimal protocol. The first
is for $k=\Omega(n)$, where, using a simple gossip broadcast protocol that
creates a spanning tree in at most linear time, we show that TAG finishes after
$\Theta(n)$ rounds for any graph. The second uses a sophisticated, recent
gossip protocol to build a fast spanning tree on graphs with large weak
conductance. In turn, this leads to the optimally of TAG on these graphs for
$k=\Omega(\mathrm{polylog}(n))$. The technique used in our proofs relies on
queuing theory, which is an interesting approach that can be useful in future
gossip analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4373</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4373</id><created>2011-01-23</created><updated>2012-02-01</updated><authors><author><keyname>Frick</keyname><forenames>Klaus</forenames></author><author><keyname>Marnitz</keyname><forenames>Philipp</forenames></author><author><keyname>Munk</keyname><forenames>Axel</forenames></author></authors><title>Statistical Multiresolution Dantzig Estimation in Imaging: Fundamental
  Concepts and Algorithmic Framework</title><categories>stat.AP cs.CV cs.SY math.OC stat.CO</categories><journal-ref>Electron. J. Stat. 6 (2012) 231-268</journal-ref><doi>10.1214/12-EJS671</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we are concerned with fully automatic and locally adaptive
estimation of functions in a &quot;signal + noise&quot;-model where the regression
function may additionally be blurred by a linear operator, e.g. by a
convolution. To this end, we introduce a general class of statistical
multiresolution estimators and develop an algorithmic framework for computing
those. By this we mean estimators that are defined as solutions of convex
optimization problems with supremum-type constraints. We employ a combination
of the alternating direction method of multipliers with Dykstra's algorithm for
computing orthogonal projections onto intersections of convex sets and prove
numerical convergence. The capability of the proposed method is illustrated by
various examples from imaging and signal detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4378</identifier>
 <datestamp>2012-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4378</id><created>2011-01-23</created><authors><author><keyname>Galla</keyname><forenames>Tobias</forenames></author></authors><title>Cycles of cooperation and defection in imperfect learning</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>18 pages, 11 figures</comments><journal-ref>J. Stat. Mech. (2011) P08007</journal-ref><doi>10.1088/1742-5468/2011/08/P08007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When people play a repeated game they usually try to anticipate their
opponents' moves based on past observations, and then decide what action to
take next. Behavioural economics studies the mechanisms by which strategic
decisions are taken in these adaptive learning processes. We here investigate a
model of learning the iterated prisoner's dilemma game. Players have the choice
between three strategies, always defect (ALLD), always cooperate (ALLC) and
tit-for-tat (TFT). The only strict Nash equilibrium in this situation is ALLD.
When players learn to play this game convergence to the equilibrium is not
guaranteed, for example we find cooperative behaviour if players discount
observations in the distant past. When agents use small samples of observed
moves to estimate their opponent's strategy the learning process is stochastic,
and sustained oscillations between cooperation and defection can emerge. These
cycles are similar to those found in stochastic evolutionary processes, but the
origin of the noise sustaining the oscillations is different and lies in the
imperfect sampling of the opponent's strategy. Based on a systematic expansion
technique, we are able to predict the properties of these learning cycles,
providing an analytical tool with which the outcome of more general stochastic
adaptation processes can be characterised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4388</identifier>
 <datestamp>2015-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4388</id><created>2011-01-23</created><updated>2012-03-28</updated><authors><author><keyname>Song</keyname><forenames>Guohui</forenames></author><author><keyname>Zhang</keyname><forenames>Haizhang</forenames></author><author><keyname>Hickernell</keyname><forenames>Fred J.</forenames></author></authors><title>Reproducing Kernel Banach Spaces with the l1 Norm</title><categories>stat.ML cs.LG math.FA</categories><comments>28 pages, an extra section was added</comments><journal-ref>Appl. Comput. Harmon. Anal., 34:96-116, 2013</journal-ref><doi>10.1016/j.acha.2012.03.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Targeting at sparse learning, we construct Banach spaces B of functions on an
input space X with the properties that (1) B possesses an l1 norm in the sense
that it is isometrically isomorphic to the Banach space of integrable functions
on X with respect to the counting measure; (2) point evaluations are continuous
linear functionals on B and are representable through a bilinear form with a
kernel function; (3) regularized learning schemes on B satisfy the linear
representer theorem. Examples of kernel functions admissible for the
construction of such spaces are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4401</identifier>
 <datestamp>2012-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4401</id><created>2011-01-23</created><updated>2012-05-17</updated><authors><author><keyname>Arzi</keyname><forenames>Orit</forenames></author><author><keyname>Aumann</keyname><forenames>Yonatan</forenames></author><author><keyname>Dombb</keyname><forenames>Yair</forenames></author></authors><title>Throw One's Cake --- and Have It Too</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of fairly dividing a heterogeneous cake between a
number of players with different tastes. In this setting, it is known that
fairness requirements may result in a suboptimal division from the social
welfare standpoint. Here, we show that in some cases, discarding some of the
cake and fairly dividing only the remainder may be socially preferable to any
fair division of the entire cake. We study this phenomenon, providing
asymptotically-tight bounds on the social improvement achievable by such
discarding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4412</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4412</id><created>2011-01-23</created><authors><author><keyname>Deaconescu</keyname><forenames>R&#x103;zvan</forenames></author><author><keyname>Sandu-Popa</keyname><forenames>Marius</forenames></author><author><keyname>Dr&#x103;ghici</keyname><forenames>Adriana</forenames></author><author><keyname>T&#x103;pus</keyname><forenames>Nicolae</forenames></author></authors><title>BitTorrent Swarm Analysis through Automation and Enhanced Logging</title><categories>cs.NI</categories><comments>ISSN - [Online: 0974 - 9322; Print : 0975- 2293], pages 52-65</comments><acm-class>C.2.3; C.4</acm-class><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Volume 3, Number 1, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-Peer protocols currently form the most heavily used protocol class in
the Internet, with BitTorrent, the most popular protocol for content
distribution, as its flagship.
  A high number of studies and investigations have been undertaken to measure,
analyse and improve the inner workings of the BitTorrent protocol. Approaches
such as tracker message analysis, network probing and packet sniffing have been
deployed to understand and enhance BitTorrent's internal behaviour.
  In this paper we present a novel approach that aims to collect, process and
analyse large amounts of local peer information in BitTorrent swarms. We
classify the information as periodic status information able to be monitored in
real time and as verbose logging information to be used for subsequent
analysis. We have designed and implemented a retrieval, storage and
presentation infrastructure that enables easy analysis of BitTorrent protocol
internals. Our approach can be employed both as a comparison tool, as well as a
measurement system of how network characteristics and protocol implementation
influence the overall BitTorrent swarm performance.
  We base our approach on a framework that allows easy swarm creation and
control for different BitTorrent clients. With the help of a virtualized
infrastructure and a client-server software layer we are able to create,
command and manage large sized BitTorrent swarms. The framework allows a user
to run, schedule, start, stop clients within a swarm and collect information
regarding their behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4420</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4420</id><created>2011-01-23</created><authors><author><keyname>Pegden</keyname><forenames>Wesley</forenames></author></authors><title>A finite goal set in the plane which is not a Winner</title><categories>math.CO cs.GT</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  J. Beck has shown that if two players alternately select previously unchosen
points from the plane, Player 1 can always build a congruent copy of any given
finite goal set G, in spite of Player 2's efforts to stop him. We give a finite
goal set G (it has 5 points) which Player 1 cannot construct before Player 2 in
this achievement game played in the plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4423</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4423</id><created>2011-01-23</created><authors><author><keyname>Compagnoni</keyname><forenames>Adriana</forenames><affiliation>Stevens Institute of Technology</affiliation></author><author><keyname>Goguen</keyname><forenames>Healfdene</forenames><affiliation>Google, Inc.</affiliation></author></authors><title>Relating Church-Style and Curry-Style Subtyping</title><categories>cs.LO cs.PL</categories><comments>In Proceedings ITRS 2010, arXiv:1101.4104</comments><proxy>EPTCS</proxy><acm-class>F.4.1; F.3.2</acm-class><journal-ref>EPTCS 45, 2011, pp. 1-15</journal-ref><doi>10.4204/EPTCS.45.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Type theories with higher-order subtyping or singleton types are examples of
systems where computation rules for variables are affected by type information
in the context. A complication for these systems is that bounds declared in the
context do not interact well with the logical relation proof of completeness or
termination. This paper proposes a natural modification to the type syntax for
F-Omega-Sub, adding variable's bound to the variable type constructor, thereby
separating the computational behavior of the variable from the context. The
algorithm for subtyping in F-Omega-Sub can then be given on types without
context or kind information. As a consequence, the metatheory follows the
general approach for type systems without computational information in the
context, including a simple logical relation definition without Kripke-style
indexing by context. This new presentation of the system is shown to be
equivalent to the traditional presentation without bounds on the variable type
constructor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4424</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4424</id><created>2011-01-23</created><authors><author><keyname>Della Rocca</keyname><forenames>Simona Ronchi</forenames><affiliation>Universita' di Torino Dipartimento di Informatica Torino Italy</affiliation></author><author><keyname>Saurin</keyname><forenames>Alexis</forenames><affiliation>Laboratoire CNR PPS and INRIA Paris France</affiliation></author><author><keyname>Stavrinos</keyname><forenames>Yiorgos</forenames><affiliation>Department of Mathematics, University of Athens, Greece</affiliation></author><author><keyname>Veneti</keyname><forenames>Anastasia</forenames><affiliation>Department of Mathematics University of Athens Greece</affiliation></author></authors><title>Intersection Logic in sequent calculus style</title><categories>cs.LO cs.PL</categories><comments>In Proceedings ITRS 2010, arXiv:1101.4104</comments><proxy>EPTCS</proxy><acm-class>F.3.2; F.4.1</acm-class><journal-ref>EPTCS 45, 2011, pp. 16-30</journal-ref><doi>10.4204/EPTCS.45.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intersection type assignment system has been designed directly as
deductive system for assigning formulae of the implicative and conjunctive
fragment of the intuitionistic logic to terms of lambda-calculus. But its
relation with the logic is not standard. Between all the logics that have been
proposed as its foundation, we consider ISL, which gives a logical
interpretation of the intersection by splitting the intuitionistic conjunction
into two connectives, with a local and global behaviour respectively, being the
intersection the local one. We think ISL is a logic interesting by itself, and
in order to support this claim we give a sequent calculus formulation of it,
and we prove that it enjoys the cut elimination property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4425</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4425</id><created>2011-01-23</created><authors><author><keyname>van Bakel</keyname><forenames>Steffen</forenames><affiliation>Imperial College London</affiliation></author></authors><title>Sound and Complete Typing for lambda-mu</title><categories>cs.LO</categories><comments>In Proceedings ITRS 2010, arXiv:1101.4104</comments><proxy>EPTCS</proxy><acm-class>F.3.2</acm-class><journal-ref>EPTCS 45, 2011, pp. 31-44</journal-ref><doi>10.4204/EPTCS.45.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we define intersection and union type assignment for Parigot's
calculus lambda-mu. We show that this notion is complete (i.e. closed under
subject-expansion), and show also that it is sound (i.e. closed under
subject-reduction). This implies that this notion of intersection-union type
assignment is suitable to define a semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4426</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4426</id><created>2011-01-23</created><authors><author><keyname>Dezani-Ciancaglini</keyname><forenames>Mariangiola</forenames></author><author><keyname>Giannini</keyname><forenames>Paola</forenames></author><author><keyname>Zucca</keyname><forenames>Elena</forenames></author></authors><title>Intersection types for unbind and rebind</title><categories>cs.LO cs.PL</categories><comments>In Proceedings ITRS 2010, arXiv:1101.4104</comments><proxy>EPTCS</proxy><acm-class>F.3.2; F.4.1</acm-class><journal-ref>EPTCS 45, 2011, pp. 45-58</journal-ref><doi>10.4204/EPTCS.45.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a type system with intersection types for an extension of
lambda-calculus with unbind and rebind operators. In this calculus, a term with
free variables, representing open code, can be packed into an &quot;unbound&quot; term,
and passed around as a value. In order to execute inside code, an unbound term
should be explicitly rebound at the point where it is used. Unbinding and
rebinding are hierarchical, that is, the term can contain arbitrarily nested
unbound terms, whose inside code can only be executed after a sequence of
rebinds has been applied. Correspondingly, types are decorated with levels, and
a term has type decorated with k if it needs k rebinds in order to reduce to a
value. With intersection types we model the fact that a term can be used
differently in contexts providing different numbers of unbinds. In particular,
top-level terms, that is, terms not requiring unbinds to reduce to values,
should have a value type, that is, an intersection type where at least one
element has level 0. With the proposed intersection type system we get
soundness under the call-by-value strategy, an issue which was not resolved by
previous type systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4428</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4428</id><created>2011-01-23</created><authors><author><keyname>Dunfield</keyname><forenames>Joshua</forenames></author></authors><title>Untangling Typechecking of Intersections and Unions</title><categories>cs.PL</categories><comments>In Proceedings ITRS 2010, arXiv:1101.4104</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 45, 2011, pp. 59-70</journal-ref><doi>10.4204/EPTCS.45.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intersection and union types denote conjunctions and disjunctions of
properties. Using bidirectional typechecking, intersection types are relatively
straightforward, but union types present challenges. For union types, we can
case-analyze a subterm of union type when it appears in evaluation position
(replacing the subterm with a variable, and checking that term twice under
appropriate assumptions). This technique preserves soundness in a call-by-value
semantics.
  Sadly, there are so many choices of subterms that a direct implementation is
not practical. But carefully transforming programs into let-normal form
drastically reduces the number of choices. The key results are soundness and
completeness: a typing derivation (in the system with too many subterm choices)
exists for a program if and only if a derivation exists for the let-normalized
program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4429</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4429</id><created>2011-01-23</created><authors><author><keyname>Padovani</keyname><forenames>Luca</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Torino, Italy</affiliation></author></authors><title>Session Types = Intersection Types + Union Types</title><categories>cs.PL cs.DC</categories><comments>In Proceedings ITRS 2010, arXiv:1101.4104</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 45, 2011, pp. 71-89</journal-ref><doi>10.4204/EPTCS.45.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a semantically grounded theory of session types which relies on
intersection and union types. We argue that intersection and union types are
natural candidates for modeling branching points in session types and we show
that the resulting theory overcomes some important defects of related
behavioral theories. In particular, intersections and unions provide a native
solution to the problem of computing joins and meets of session types. Also,
the subtyping relation turns out to be a pre-congruence, while this is not
always the case in related behavioral theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4430</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4430</id><created>2011-01-23</created><authors><author><keyname>Sj&#xf6;berg</keyname><forenames>Vilhelm</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Stump</keyname><forenames>Aaron</forenames><affiliation>The University of Iowa</affiliation></author></authors><title>Equality, Quasi-Implicit Products, and Large Eliminations</title><categories>cs.PL</categories><comments>In Proceedings ITRS 2010, arXiv:1101.4104</comments><proxy>EPTCS</proxy><acm-class>D.3.1</acm-class><journal-ref>EPTCS 45, 2011, pp. 90-100</journal-ref><doi>10.4204/EPTCS.45.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a type theory with a form of equality reflection:
provable equalities can be used to coerce the type of a term. Coercions and
other annotations, including implicit arguments, are dropped during reduction
of terms. We develop the metatheory for an undecidable version of the system
with unannotated terms. We then devise a decidable system with annotated terms,
justified in terms of the unannotated system. Finally, we show how the approach
can be extended to account for large eliminations, using what we call
quasi-implicit products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4431</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4431</id><created>2011-01-23</created><authors><author><keyname>Huang</keyname><forenames>Huang</forenames></author><author><keyname>Yu</keyname><forenames>Changbin</forenames></author></authors><title>Parameter Optimization of Multi-Agent Formations based on LQR Design</title><categories>cs.SY cs.MA</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the optimal formation control of multiple agents whose
interaction parameters are adjusted upon a cost function consisting of both the
control energy and the geometrical performance. By optimizing the interaction
parameters and by the linear quadratic regulation(LQR) controllers, the upper
bound of the cost function is minimized. For systems with homogeneous agents
interconnected over sparse graphs, distributed controllers are proposed that
inherit the same underlying graph as the one among agents. For the more general
case, a relaxed optimization problem is considered so as to eliminate the
nonlinear constraints. Using the subgradient method, interaction parameters
among agents are optimized under the constraint of a sparse graph, and the
optimum of the cost function is a better result than the one when agents
interacted only through the control channel. Numerical examples are provided to
validate the effectiveness of the method and to illustrate the geometrical
performance of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4435</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4435</id><created>2011-01-23</created><authors><author><keyname>Fakoorian</keyname><forenames>S. Ali. A.</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Solutions for the MIMO Gaussian Wiretap Channel with a Cooperative
  Jammer</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2011.2161298</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study the Gaussian MIMO wiretap channel with a transmitter, a legitimate
receiver, an eavesdropper and an external helper, each equipped with multiple
antennas. The transmitter sends confidential messages to its intended receiver,
while the helper transmits jamming signals independent of the source message to
confuse the eavesdropper. The jamming signal is assumed to be treated as noise
at both the intended receiver and the eavesdropper. We obtain a closed-form
expression for the structure of the artificial noise covariance matrix that
guarantees no decrease in the secrecy capacity of the wiretap channel. We also
describe how to find specific realizations of this covariance matrix expression
that provide good secrecy rate performance, even when there is no non-trivial
null space between the helper and the intended receiver. Unlike prior work, our
approach considers the general MIMO case, and is not restricted to SISO or MISO
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4439</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4439</id><created>2011-01-23</created><updated>2011-01-27</updated><authors><author><keyname>Song</keyname><forenames>Guohui</forenames></author><author><keyname>Zhang</keyname><forenames>Haizhang</forenames></author></authors><title>Reproducing Kernel Banach Spaces with the l1 Norm II: Error Analysis for
  Regularized Least Square Regression</title><categories>stat.ML cs.LG math.FA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A typical approach in estimating the learning rate of a regularized learning
scheme is to bound the approximation error by the sum of the sampling error,
the hypothesis error and the regularization error. Using a reproducing kernel
space that satisfies the linear representer theorem brings the advantage of
discarding the hypothesis error from the sum automatically. Following this
direction, we illustrate how reproducing kernel Banach spaces with the l1 norm
can be applied to improve the learning rate estimate of l1-regularization in
machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4445</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4445</id><created>2011-01-24</created><authors><author><keyname>Singh</keyname><forenames>Santosh Kumar</forenames></author><author><keyname>Singh</keyname><forenames>Gajendra</forenames></author><author><keyname>Pathak</keyname><forenames>Vibhakar</forenames></author><author><keyname>Roy</keyname><forenames>Dr. Krishna Chandra</forenames></author></authors><title>Spectrum Management for Cognitive Radio based on Genetics Algorithm</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum scarceness is one of the major challenges that the present world is
facing. The efficient use of existing licensed spectrum is becoming most
critical as growing demand of the radio spectrum. Different researches show
that the use of licensed are not utilized inefficiently. It has been also shown
that primary user does not use more than 70% of the licensed frequency band
most of the time. Many researchers are trying to found the techniques that
efficiently utilize the under-utilized licensed spectrum. One of the approaches
is the use of &quot;Cognitive Radio&quot;. This allows the radio to learn from its
environment, changing certain parameters. Based on this knowledge the radio can
dynamically exploit the spectrum holes in the licensed band of the spectrum.
This paper w i l l focus on the performance of spectrum allocation technique,
based on popular meta-heuristics Genetics Algorithm and analyzing the
performance of this technique using Mat Lab.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4446</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4446</id><created>2011-01-24</created><authors><author><keyname>Drucker</keyname><forenames>Andrew</forenames></author></authors><title>High-Confidence Predictions under Adversarial Uncertainty</title><categories>cs.DS</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the setting in which the bits of an unknown infinite binary sequence
x are revealed sequentially to an observer. We show that very limited
assumptions about x allow one to make successful predictions about unseen bits
of x. First, we study the problem of successfully predicting a single 0 from
among the bits of x. In our model we have only one chance to make a prediction,
but may do so at a time of our choosing. We describe and motivate this as the
problem of a frog who wants to cross a road safely.
  Letting N_t denote the number of 1s among the first t bits of x, we say that
x is &quot;eps-weakly sparse&quot; if lim inf (N_t/t) &lt;= eps. Our main result is a
randomized algorithm that, given any eps-weakly sparse sequence x, predicts a 0
of x with success probability as close as desired to 1 - \eps. Thus we can
perform this task with essentially the same success probability as under the
much stronger assumption that each bit of x takes the value 1 independently
with probability eps. We apply this result to show how to successfully predict
a bit (0 or 1) under a broad class of possible assumptions on the sequence x.
The assumptions are stated in terms of the behavior of a finite automaton M
reading the bits of x.
  We also propose and solve a variant of the well-studied &quot;ignorant
forecasting&quot; problem. For every eps &gt; 0, we give a randomized forecasting
algorithm S_eps that, given sequential access to a binary sequence x, makes a
prediction of the form: &quot;A p fraction of the next N bits will be 1s.&quot; (The
algorithm gets to choose p, N, and the time of the prediction.) For any fixed
sequence x, the forecast fraction p is accurate to within +-eps with
probability 1 - eps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4450</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4450</id><created>2011-01-24</created><authors><author><keyname>Golovin</keyname><forenames>Daniel</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Adaptive Submodular Optimization under Matroid Constraints</title><categories>cs.DS cs.AI</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many important problems in discrete optimization require maximization of a
monotonic submodular function subject to matroid constraints. For these
problems, a simple greedy algorithm is guaranteed to obtain near-optimal
solutions. In this article, we extend this classic result to a general class of
adaptive optimization problems under partial observability, where each choice
can depend on observations resulting from past choices. Specifically, we prove
that a natural adaptive greedy algorithm provides a $1/(p+1)$ approximation for
the problem of maximizing an adaptive monotone submodular function subject to
$p$ matroid constraints, and more generally over arbitrary $p$-independence
systems. We illustrate the usefulness of our result on a complex adaptive
match-making application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4458</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4458</id><created>2011-01-24</created><updated>2012-01-15</updated><authors><author><keyname>Mo</keyname><forenames>Qun</forenames></author><author><keyname>Shen</keyname><forenames>Yi</forenames></author></authors><title>Remarks on the Restricted Isometry Property in Orthogonal Matching
  Pursuit algorithm</title><categories>cs.IT math.IT</categories><comments>we have a new version</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper demonstrates theoretically that if the restricted isometry
constant $\delta_K$ of the compressed sensing matrix satisfies $$ \delta_{K+1}
&lt; \frac{1}{\sqrt{K}+1}, $$ then a greedy algorithm called Orthogonal Matching
Pursuit (OMP) can recover a signal with $K$ nonzero entries in $K$ iterations.
In contrast, matrices are also constructed with restricted isometry constant $$
\delta_{K+1} = \frac{1}{\sqrt{K}} $$ such that OMP can not recover $K$-sparse
$x$ in $K$ iterations. This result shows that the conjecture given by Dai and
Milenkovic is ture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4465</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4465</id><created>2011-01-24</created><authors><author><keyname>Bucciarelli</keyname><forenames>Antonio</forenames><affiliation>PPS</affiliation></author></authors><title>Extensional Collapse Situations I: non-termination and unrecoverable
  errors</title><categories>cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a simple model of higher order, functional computation over the
booleans. Then, we enrich the model in order to encompass non-termination and
unrecoverable errors, taken separately or jointly. We show that the models so
defined form a lattice when ordered by the extensional collapse situation
relation, introduced in order to compare models with respect to the amount of
&quot;intensional information&quot; that they provide on computation. The proofs are
carried out by exhibiting suitable applied {\lambda}-calculi, and by exploiting
the fundamental lemma of logical relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4474</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4474</id><created>2011-01-24</created><authors><author><keyname>Serban</keyname><forenames>Cristina</forenames></author><author><keyname>Maftei</keyname><forenames>Carmen</forenames></author></authors><title>Thermal Analysis of Climate Regions using Remote Sensing and Grid
  Computing</title><categories>cs.DC</categories><comments>16 pages; ISSN - [Online: 0974 - 9322 Print : 0975- 2293]</comments><msc-class>68U10</msc-class><acm-class>J.2</acm-class><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC),Vol.3, No.1, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of climate regions is very important for designers and
architects, because the increase in density and built up spaces and reduction
in open spaces and green lands induce the increase of heat, especially in an
urban area, deteriorating the environment and causing health problems. This
study analyzes the Land Surface Temperature (LST) differences in the region of
Dobrogea, Romania, and compares with the land use and land cover types using TM
and ETM+ data of 1989 and 2000. As the analysis is performed on large data
sets, we used Grid Computing to implement a service for using on Computational
Grids with a Web-based client interface, which will be greatly useful and
convenient for those who are studying the ground thermal environment and heat
island effects by using Landsat TM/ETM+ bands, and have typical workstations,
with no special computing and storing resources for computationally intensive
satellite image processing and no license for a commercial image processing
tool. Based on the satellite imagery, the paper also addresses a Supervised
Classification algorithm and the computation of two indices of great value in
water resources management, Normalized Difference Vegetation Index (NDVI),
respectively Land Surface Emissivity (LSE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4475</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4475</id><created>2011-01-24</created><updated>2011-06-10</updated><authors><author><keyname>Bollig</keyname><forenames>Benedikt</forenames><affiliation>LSV</affiliation></author></authors><title>An automaton over data words that captures EMSO logic</title><categories>cs.FL</categories><proxy>ccsd</proxy><doi>10.1007/978-3-642-23217-6_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a general framework for the specification and implementation of
systems whose executions are words, or partial orders, over an infinite
alphabet. As a model of an implementation, we introduce class register
automata, a one-way automata model over words with multiple data values. Our
model combines register automata and class memory automata. It has natural
interpretations. In particular, it captures communicating automata with an
unbounded number of processes, whose semantics can be described as a set of
(dynamic) message sequence charts. On the specification side, we provide a
local existential monadic second-order logic that does not impose any
restriction on the number of variables. We study the realizability problem and
show that every formula from that logic can be effectively, and in elementary
time, translated into an equivalent class register automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4477</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4477</id><created>2011-01-24</created><updated>2011-01-25</updated><authors><author><keyname>Akoum</keyname><forenames>Salam</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Limited Feedback Over Temporally Correlated Channels for the Downlink of
  a Femtocell Network</title><categories>cs.IT math.IT</categories><comments>24 pages, 7 figures. Submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous networks are a flexible deployment model that rely on low power
nodes to improve the user broadband experience in a cost effective manner.
Femtocells are an integral part of heterogeneous networks, whose main purpose
is to improve the indoor capacity. When restricting access to home users,
femtocells cause a substantial interference problem that cannot be mitigated
through coordination with the macrocell base station. In this paper, we analyze
multiple antenna communication on the downlink of a macrocell network, with
femtocell overlay. We evaluate the feasibility of limited feedback beamforming
given delay on the feedback channel, quantization error and uncoordinated
interference from the femtocells. We model the femtocell spatial distribution
as a Poisson point process and the temporal correlation of the channel
according to a Gauss-Markov model. We derive the probability of outage at the
macrocell users as a function of the temporal correlation, the femtocell
density, and the feedback rate. We propose rate backoff to maximize the average
achievable rate in the network. Simulation results show that limited feedback
beamforming is a viable solution for femtocell networks despite the CSI
inaccuracy and the interference. They illustrate how properly designed rate
backoff improves the achievable rate of the macrocell system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4479</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4479</id><created>2011-01-24</created><authors><author><keyname>Clarke</keyname><forenames>Daoud</forenames></author></authors><title>A Context-theoretic Framework for Compositionality in Distributional
  Semantics</title><categories>cs.CL cs.AI</categories><comments>Submitted to Computational Linguistics on 20th January 2010 for
  review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Techniques in which words are represented as vectors have proved useful in
many applications in computational linguistics, however there is currently no
general semantic formalism for representing meaning in terms of vectors. We
present a framework for natural language semantics in which words, phrases and
sentences are all represented as vectors, based on a theoretical analysis which
assumes that meaning is determined by context.
  In the theoretical analysis, we define a corpus model as a mathematical
abstraction of a text corpus. The meaning of a string of words is assumed to be
a vector representing the contexts in which it occurs in the corpus model.
Based on this assumption, we can show that the vector representations of words
can be considered as elements of an algebra over a field. We note that in
applications of vector spaces to representing meanings of words there is an
underlying lattice structure; we interpret the partial ordering of the lattice
as describing entailment between meanings. We also define the context-theoretic
probability of a string, and, based on this and the lattice structure, a degree
of entailment between strings.
  We relate the framework to existing methods of composing vector-based
representations of meaning, and show that our approach generalises many of
these, including vector addition, component-wise multiplication, and the tensor
product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4486</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4486</id><created>2011-01-24</created><updated>2011-01-27</updated><authors><author><keyname>Lee</keyname><forenames>Moon Ho</forenames></author><author><keyname>Guo</keyname><forenames>Ying</forenames></author></authors><title>High-rate Space-Time-Frequency Codes Achieving Full-Diversity with
  Partial Interference Cancellation Group Decoding</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The partial interference cancellation (PIC) group decoding has recently been
proposed to deal with the decoding complexity and code rate trade-off on the
basis of space-time block code (STBC) design criterion when full diversity is
achieved. It provides a framework to arrange the rate-complexity-performance
tradeoff by choosing a suitable size of information symbol groups. In this
paper, a simple design of a linear dispersive space-time-frequency (STF) code
is proposed with a design criterion to achieve high rate for
frequency-selective channels in terms of multipath when the PIC group decoding
is applied at receiver. With an appropriate grouping scheme as well as the PIC
group decoding, the proposed STF code is shown to obtain the similar diversity
gain as the maximum likelihood (ML) decoding, namely full-dimensional sphere
decoding, but have a low decoding complexity. It seems as an intermediate
decoding between the ML receiver and zero-forcing (ZF) receiver. The proposed
grouping design criterion for the PIC group decoding to achieve full diversity
deploying the orthogonal-frequency-division multiplexing (OFDM) technique is
also an intermediate condition between the loosest ML full rank criterion of
codewords and the strongest ZF linear independence condition of the column
vectors for the equivalent frequency-selective channel matrix. It can achieves
full diversity with the PIC group decoding for any number of sub-carriers and
the data rate can be made high. Several code design examples are illustrated
for the feasibility of this coding scheme. Simulation results show that the
proposed STF code can well address the rate-performance-complexity tradeoff of
the multiple-input multiple-output orthogonal frequency division multiplexing
(MIMO-OFDM) communication system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4491</identifier>
 <datestamp>2014-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4491</id><created>2011-01-24</created><updated>2014-01-30</updated><authors><author><keyname>Paul</keyname><forenames>Christophe</forenames></author><author><keyname>Perez</keyname><forenames>Anthony</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>Conflict Packing: an unifying technique to obtain polynomial kernels for
  editing problems on dense instances</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a technique that we call Conflict Packing in the context of
kernelization, obtaining (and improving) several polynomial kernels for editing
problems on dense instances. We apply this technique on several well-studied
problems: Feedback Arc Set in (Bipartite) Tournaments, Dense Rooted Triplet
Inconsistency and Betweenness in Tournaments. For the former, one is given a
(bipartite) tournament $T = (V,A)$ and seeks a set of at most $k$ arcs whose
reversal in $T$ results in an acyclic (bipartite) tournament. While a linear
vertex-kernel is already known for the first problem, using the Conflict
Packing allows us to find a so-called safe partition, the central tool of the
kernelization algorithm in, with simpler arguments. For the case of bipartite
tournaments, the same technique allows us to obtain a quadratic vertex-kernel.
Again, such a kernel was already known to exist, using the concept of so-called
bimodules. We believe however that providing an unifying technique to cope with
such problems is interesting. Regarding Dense Rooted Triplet Inconsistency, one
is given a set of vertices $V$ and a dense collection $\mathcal{R}$ of rooted
binary trees over three vertices of $V$ and seeks a rooted tree over $V$
containing all but at most $k$ triplets from $\mathcal{R}$. As a main
consequence of our technique, we prove that the Dense Rooted Triplet
Inconsistency problem admits a linear vertex-kernel. This result improves the
best known bound of $O(k^2)$ vertices for this problem. Finally, we use this
technique to obtain a linear vertex-kernel for Betweenness in Tournaments,
where one is given a set of vertices $V$ and a dense collection $\mathcal{R}$
of so-called betweenness triplets and seeks a linear ordering of the vertices
containing all but at most $k$ triplets from $\mathcal{R}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4497</identifier>
 <datestamp>2014-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4497</id><created>2011-01-24</created><updated>2014-03-01</updated><authors><author><keyname>Deneufch&#xe2;tel</keyname><forenames>Matthieu</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Minh</keyname><forenames>Vincel Hoang Ngoc</forenames><affiliation>LIPN</affiliation></author><author><keyname>Solomon</keyname><forenames>Allan I.</forenames><affiliation>LPTMC</affiliation></author></authors><title>Independence of hyperlogarithms over function fields via algebraic
  combinatorics</title><categories>math.CO cs.SC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a necessary and sufficient condition for the linear independence of
solutions of differential equations for hyperlogarithms. The key fact is that
the multiplier (i.e. the factor $M$ in the differential equation $dS=MS$) has
only singularities of first order (Fuchsian-type equations) and this implies
that they freely span a space which contains no primitive. We give direct
applications where we extend the property of linear independence to the largest
known ring of coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4505</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4505</id><created>2011-01-24</created><updated>2011-07-21</updated><authors><author><keyname>Calabrese</keyname><forenames>Francesco</forenames></author><author><keyname>Smoreda</keyname><forenames>Zbigniew</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author><author><keyname>Ratti</keyname><forenames>Carlo</forenames></author></authors><title>Interplay between telecommunications and face-to-face interactions - a
  study using mobile phone data</title><categories>physics.soc-ph cs.SI</categories><journal-ref>PLoS ONE 6(7): e20814, 2011</journal-ref><doi>10.1371/journal.pone.0020814</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this study we analyze one year of anonymized telecommunications data for
over one million customers from a large European cellphone operator, and we
investigate the relationship between people's calls and their physical
location. We discover that more than 90% of users who have called each other
have also shared the same space (cell tower), even if they live far apart.
Moreover, we find that close to 70% of users who call each other frequently (at
least once per month on average) have shared the same space at the same time -
an instance that we call co-location. Co-locations appear indicative of
coordination calls, which occur just before face-to-face meetings. Their number
is highly predictable based on the amount of calls between two users and the
distance between their home locations - suggesting a new way to quantify the
interplay between telecommunications and face-to-face interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4523</identifier>
 <datestamp>2011-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4523</id><created>2011-01-24</created><updated>2011-12-09</updated><authors><author><keyname>Feuillet</keyname><forenames>Mathieu</forenames></author><author><keyname>Jonckheere</keyname><forenames>Matthieu</forenames></author><author><keyname>Prabhu</keyname><forenames>Balakrishna J.</forenames></author></authors><title>Bandwidth sharing networks with priority scaling</title><categories>cs.PF cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multi-class communication networks, traffic surges due to one class of
users can significantly degrade the performance for other classes. During these
transient periods, it is thus of crucial importance to implement priority
mechanisms that conserve the quality of service experienced by the affected
classes, while ensuring that the temporarily unstable class is not entirely
neglected. In this paper, we examine the complex interaction occurring between
several classes of traffic when classes obtain bandwidth proportionally to
their incoming traffic.
  We characterize the evolution of the network from the moment the initial
surge takes place until the system reaches its equilibrium. Using an
appropriate scaling, we show that the trajectories of the temporarily unstable
class can be described by a differential equation, while those of the stable
classes retain their stochastic nature. A stochastic averaging phenomenon
occurs and the dynamics of the temporarily unstable and the stable classes
continue to influence one another. We further proceed to characterize the
obtained differential equations and the stability region under this scaling for
monotone networks. We illustrate these result on several toy examples and we
finally build a penalization rule using these results for a network integrating
streaming and elastic traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4554</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4554</id><created>2011-01-24</created><authors><author><keyname>Ricca</keyname><forenames>Francesco</forenames></author><author><keyname>Grasso</keyname><forenames>Giovanni</forenames></author><author><keyname>Alviano</keyname><forenames>Mario</forenames></author><author><keyname>Manna</keyname><forenames>Marco</forenames></author><author><keyname>Lio</keyname><forenames>Vincenzino</forenames></author><author><keyname>Iiritano</keyname><forenames>Salvatore</forenames></author><author><keyname>Leone</keyname><forenames>Nicola</forenames></author></authors><title>Team-building with Answer Set Programming in the Gioia-Tauro Seaport</title><categories>cs.LO</categories><comments>21 pages, 2 figures, to appear in Theory and Practice of Logic
  Programming (TPLP)</comments><msc-class>68T27</msc-class><acm-class>I.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (To appear in Theory and Practice of Logic Programming (TPLP).)
  The seaport of Gioia Tauro is the largest transshipment terminal of the
Mediterranean coast. A crucial management task for the companies operating in
the seaport is team building: the problem of properly allocating the available
personnel for serving the incoming ships. Teams have to be carefully arranged
in order to meet several constraints, such as allocation of the employees with
the appropriate skills, fair distribution of the working load, and turnover of
the heavy/dangerous roles. This makes team building a hard and expensive task
requiring several hours per day of manual preparation.
  In this paper we present a system based on Answer Set Programming (ASP) for
the automatic generation of the teams of employees in the seaport of Gioia
Tauro. The system is currently exploited in the Gioia Tauro seaport by ICO BLG,
a company specialized in automobile logistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4555</identifier>
 <datestamp>2011-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4555</id><created>2011-01-24</created><authors><author><keyname>Leung</keyname><forenames>Ming Lam</forenames></author><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Zhang</keyname><forenames>Shengyu</forenames></author></authors><title>Tight bounds on the randomized communication complexity of symmetric XOR
  functions in one-way and SMP models</title><categories>cs.CC</categories><journal-ref>TAMC11', Proceedings of the 8th Theory and Applications of Models
  of Computation Lecture Notes in Computer Science, 2011, Volume 6648/2011,
  pages 403-408</journal-ref><doi>10.1007/978-3-642-20877-5_39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the communication complexity of symmetric XOR functions, namely
functions $f: \{0,1\}^n \times \{0,1\}^n \rightarrow \{0,1\}$ that can be
formulated as $f(x,y)=D(|x\oplus y|)$ for some predicate $D: \{0,1,...,n\}
\rightarrow \{0,1\}$, where $|x\oplus y|$ is the Hamming weight of the bitwise
XOR of $x$ and $y$. We give a public-coin randomized protocol in the
Simultaneous Message Passing (SMP) model, with the communication cost matching
the known lower bound for the \emph{quantum} and \emph{two-way} model up to a
logarithm factor. As a corollary, this closes a quadratic gap between quantum
lower bound and randomized upper bound for the one-way model, answering an open
question raised in Shi and Zhang \cite{SZ09}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4564</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4564</id><created>2011-01-24</created><updated>2011-08-25</updated><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>A Set and Collection Lemma</title><categories>cs.DM math.CO</categories><comments>7 pages, 3 figures</comments><msc-class>05C69, 05C70 (Primary) 05A20(Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set S is independent if no two vertices from S are adjacent. In this paper
we prove that if F is a collection of maximum independent sets of a graph, then
there is a matching from S-{intersection of all members of F} into {union of
all members of F}-S, for every independent set S. Based on this finding we give
alternative proofs for a number of well-known lemmata, as the &quot;Maximum Stable
Set Lemma&quot; due to Claude Berge and the &quot;Clique Collection Lemma&quot; due to
Andr\'as Hajnal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4573</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4573</id><created>2011-01-24</created><authors><author><keyname>Bailly-Bechet</keyname><forenames>M.</forenames></author><author><keyname>Borgs</keyname><forenames>C.</forenames></author><author><keyname>Braunstein</keyname><forenames>A.</forenames></author><author><keyname>Chayes</keyname><forenames>J.</forenames></author><author><keyname>Dagkessamanskaia</keyname><forenames>A.</forenames></author><author><keyname>Fran&#xe7;ois</keyname><forenames>J. -M.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Finding undetected protein associations in cell signaling by belief
  propagation</title><categories>q-bio.MN cond-mat.stat-mech cs.AI cs.CE</categories><comments>6 pages, 3 figures, 1 table, Supporting Information</comments><journal-ref>Published online before print December 27, 2010, doi:
  10.1073/pnas.1004751108 PNAS January 11, 2011 vol. 108 no. 2 882-887</journal-ref><doi>10.1073/pnas.1004751108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  External information propagates in the cell mainly through signaling cascades
and transcriptional activation, allowing it to react to a wide spectrum of
environmental changes. High throughput experiments identify numerous molecular
components of such cascades that may, however, interact through unknown
partners. Some of them may be detected using data coming from the integration
of a protein-protein interaction network and mRNA expression profiles. This
inference problem can be mapped onto the problem of finding appropriate optimal
connected subgraphs of a network defined by these datasets. The optimization
procedure turns out to be computationally intractable in general. Here we
present a new distributed algorithm for this task, inspired from statistical
physics, and apply this scheme to alpha factor and drug perturbations data in
yeast. We identify the role of the COS8 protein, a member of a gene family of
previously unknown function, and validate the results by genetic experiments.
The algorithm we present is specially suited for very large datasets, can run
in parallel, and can be adapted to other problems in systems biology. On
renowned benchmarks it outperforms other algorithms in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4594</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4594</id><created>2011-01-24</created><updated>2011-03-31</updated><authors><author><keyname>Sobocinski</keyname><forenames>Pawel</forenames><affiliation>DSSE, ECS, University of Southampton</affiliation></author><author><keyname>Heindel</keyname><forenames>Tobias</forenames><affiliation>Laboratoire d'Informatique de Paris-Nord, Universit&#xe9; de Paris, France</affiliation></author></authors><title>Being Van Kampen is a universal property</title><categories>math.CT cs.PL</categories><comments>22 pages</comments><proxy>LMCS</proxy><acm-class>cs.PL</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (April 1,
  2011) lmcs:701</journal-ref><doi>10.2168/LMCS-7(1:14)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colimits that satisfy the Van Kampen condition have interesting exactness
properties. We show that the elementary presentation of the Van Kampen
condition is actually a characterisation of a universal property in the
associated bicategory of spans. The main theorem states that Van Kampen cocones
are precisely those diagrams in a category that induce bicolimit diagrams in
its associated bicategory of spans, provided that the category has pullbacks
and enough colimits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4603</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4603</id><created>2011-01-24</created><updated>2012-06-12</updated><authors><author><keyname>Couvreur</keyname><forenames>Alain</forenames></author><author><keyname>Duursma</keyname><forenames>Iwan</forenames></author></authors><title>Evaluation Codes from smooth Quadric Surfaces and Twisted Segre
  Varieties</title><categories>cs.IT math.AG math.IT math.NT</categories><comments>10 pages. Presented at the conference Workshop on Coding theory and
  Cryptography 2011</comments><msc-class>94B27, 14J20, 94B15</msc-class><journal-ref>Des. Codes Cryptogr. 66(1), 291-303. 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the parameters of any evaluation code on a smooth quadric surface.
For hyperbolic quadrics the approach uses elementary results on product codes
and the parameters of codes on elliptic quadrics are obtained by detecting a
BCH structure of these codes and using the BCH bound. The elliptic quadric is a
twist of the surface P^1 x P^1 and we detect a similar BCH structure on twists
of the Segre embedding of a product of any d copies of the projective line.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4609</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4609</id><created>2011-01-24</created><updated>2011-02-01</updated><authors><author><keyname>Pettarin</keyname><forenames>Alberto</forenames></author><author><keyname>Pietracaprina</keyname><forenames>Andrea</forenames></author><author><keyname>Pucci</keyname><forenames>Geppino</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author></authors><title>Tight Bounds on Information Dissemination in Sparse Mobile Networks</title><categories>cs.DM cs.DS</categories><comments>19 pages; we rewrote Lemma 4, fixing a claim which was not fully
  justified in the first version of the draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the growing interest in mobile systems, we study the dynamics of
information dissemination between agents moving independently on a plane.
Formally, we consider $k$ mobile agents performing independent random walks on
an $n$-node grid. At time $0$, each agent is located at a random node of the
grid and one agent has a rumor. The spread of the rumor is governed by a
dynamic communication graph process ${G_t(r) | t \geq 0}$, where two agents are
connected by an edge in $G_t(r)$ iff their distance at time $t$ is within their
transmission radius $r$. Modeling the physical reality that the speed of radio
transmission is much faster than the motion of the agents, we assume that the
rumor can travel throughout a connected component of $G_t$ before the graph is
altered by the motion. We study the broadcast time $T_B$ of the system, which
is the time it takes for all agents to know the rumor. We focus on the sparse
case (below the percolation point $r_c \approx \sqrt{n/k}$) where, with high
probability, no connected component in $G_t$ has more than a logarithmic number
of agents and the broadcast time is dominated by the time it takes for many
independent random walks to meet each other. Quite surprisingly, we show that
for a system below the percolation point the broadcast time does not depend on
the relation between the mobility speed and the transmission radius. In fact,
we prove that $T_B = \tilde{O}(n / \sqrt{k})$ for any $0 \leq r &lt; r_c$, even
when the transmission range is significantly larger than the mobility range in
one step, giving a tight characterization up to logarithmic factors. Our result
complements a recent result of Peres et al. (SODA 2011) who showed that above
the percolation point the broadcast time is polylogarithmic in $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4617</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4617</id><created>2011-01-24</created><authors><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author><author><keyname>Rajan</keyname><forenames>Adithya</forenames></author><author><keyname>Zhang</keyname><forenames>Yuan</forenames></author></authors><title>Applications of Stochastic Ordering to Wireless Communications</title><categories>cs.IT math.IT</categories><comments>25 pages, 10 figures, Submitted to the IEEE transactions on wireless
  communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic orders are binary relations defined on probability distributions
which capture intuitive notions like being larger or being more variable. This
paper introduces stochastic ordering of instantaneous SNRs of fading channels
as a tool to compare the performance of communication systems over different
channels. Stochastic orders unify existing performance metrics such as ergodic
capacity, and metrics based on error rate functions for commonly used
modulation schemes through their relation with convex, and completely monotonic
(c.m.) functions. Toward this goal, performance metrics such as instantaneous
error rates of M-QAM and M-PSK modulations are shown to be c.m. functions of
the instantaneous SNR, while metrics such as the instantaneous capacity are
seen to have a completely monotonic derivative (c.m.d.). It is shown that the
commonly used parametric fading distributions for modeling line of sight (LoS),
exhibit a monotonicity in the LoS parameter with respect to the stochastic
Laplace transform order. Using stochastic orders, average performance of
systems involving multiple random variables are compared over different
channels, even when closed form expressions for such averages are not
tractable. These include diversity combining schemes, relay networks, and
signal detection over fading channels with non-Gaussian additive noise, which
are investigated herein. Simulations are also provided to corroborate our
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4620</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4620</id><created>2011-01-24</created><updated>2011-10-25</updated><authors><author><keyname>Kent</keyname><forenames>Adrian</forenames><affiliation>Centre for Quantum Information and Foundations, DAMTP, University of Cambridge and Perimeter Institute</affiliation></author></authors><title>Unconditionally Secure Bit Commitment with Flying Qudits</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>To appear in New J. Phys. Edits in response to referee comments.
  Protocol unaltered. Security proofs unaltered but expanded for clarity. Added
  discussion of strategies for countering errors and losses. Discussions of
  practicality expanded and qualified, leaving open challenges for experimental
  implementations</comments><journal-ref>New J. Phys. 13 (2011) 113015</journal-ref><doi>10.1088/1367-2630/13/11/113015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the task cryptographers call bit commitment, one party encrypts a
prediction in a way that cannot be decrypted until they supply a key, but has
only one valid key. Bit commitment has many applications, and has been much
studied, but completely and provably secure schemes have remained elusive. Here
we report a new development in physics-based cryptography which gives a
completely new way of implementing bit commitment that is perfectly secure. The
technique involves sending a quantum state (for instance one or more photons)
at light speed in one of two or more directions, either along a secure channel
or by quantum teleportation. Its security proof relies on the no-cloning
theorem of quantum theory and the no superluminal signalling principle of
special relativity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4632</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4632</id><created>2011-01-24</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Laverdi&#xe8;re</keyname><forenames>Marc-Andr&#xe9;</forenames></author><author><keyname>Benssam</keyname><forenames>Ali</forenames></author><author><keyname>Benredjem</keyname><forenames>Djamel</forenames></author></authors><title>A Secure Web-Based File Exchange Server: Software Requirements
  Specification Document</title><categories>cs.CR</categories><comments>13 pages, 3 figures; a December 2005 report</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This document presents brief software specification of a secure file exchange
system prototype involving mutual authentication of the users via their browser
and the application server with PKI-based certificates as credentials, the use
of LDAP for credential management, and authentication between the application
and database servers to maintain a high level of trust between all parties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4640</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4640</id><created>2011-01-24</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Laverdi&#xe8;re</keyname><forenames>Marc-Andr&#xe9;</forenames></author><author><keyname>Benssam</keyname><forenames>Ali</forenames></author><author><keyname>Benredjem</keyname><forenames>Djamel</forenames></author></authors><title>Design and Implementation of a Secure Web-Based File Exchange Server:
  Specification Design Document</title><categories>cs.CR</categories><comments>27 pages; 14 figures; a December 2005 report; complements the SRS
  document</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We report on the software engineering design and implementation of an web-
and LDAP-based secure file exchange system with bi-directional authentication
of all parties involved in the process that is the user's browsers and the
application server mutually authenticate, and the application and database
servers authenticate using certificates, credentials, etcs. with the directory
service provided by LDAP using open-source technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4667</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4667</id><created>2011-01-24</created><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>Jiang</keyname><forenames>Minghui</forenames></author></authors><title>Sweeping an oval to a vanishing point</title><categories>cs.CG</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a convex region in the plane, and a sweep-line as a tool, what is best
way to reduce the region to a single point by a sequence of sweeps? The problem
of sweeping points by orthogonal sweeps was first studied in [2]. Here we
consider the following \emph{slanted} variant of sweeping recently introduced
in [1]: In a single sweep, the sweep-line is placed at a start position
somewhere in the plane, then moved continuously according to a sweep vector
$\vec v$ (not necessarily orthogonal to the sweep-line) to another parallel end
position, and then lifted from the plane. The cost of a sequence of sweeps is
the sum of the lengths of the sweep vectors. The (optimal) sweeping cost of a
region is the infimum of the costs over all finite sweeping sequences for that
region. An optimal sweeping sequence for a region is one with a minimum total
cost, if it exists. Another parameter of interest is the number of sweeps.
  We show that there exist convex regions for which the optimal sweeping cost
cannot be attained by two sweeps. This disproves a conjecture of Bousany,
Karker, O'Rourke, and Sparaco stating that two sweeps (with vectors along the
two adjacent sides of a minimum-perimeter enclosing parallelogram) always
suffice [1]. Moreover, we conjecture that for some convex regions, no finite
sweeping sequence is optimal. On the other hand, we show that both the 2-sweep
algorithm based on minimum-perimeter enclosing rectangle and the 2-sweep
algorithm based on minimum-perimeter enclosing parallelogram achieve a $4/\pi
\approx 1.27$ approximation in this sweeping model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4681</identifier>
 <datestamp>2013-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4681</id><created>2011-01-24</created><updated>2013-06-26</updated><authors><author><keyname>Wang</keyname><forenames>Zizhuo</forenames></author><author><keyname>Deng</keyname><forenames>Shiming</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>Close the Gaps: A Learning-while-Doing Algorithm for a Class of
  Single-Product Revenue Management Problems</title><categories>cs.LG</categories><msc-class>93E35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a retailer selling a single product with limited on-hand
inventory over a finite selling season. Customer demand arrives according to a
Poisson process, the rate of which is influenced by a single action taken by
the retailer (such as price adjustment, sales commission, advertisement
intensity, etc.). The relationship between the action and the demand rate is
not known in advance. However, the retailer is able to learn the optimal action
&quot;on the fly&quot; as she maximizes her total expected revenue based on the observed
demand reactions.
  Using the pricing problem as an example, we propose a dynamic
&quot;learning-while-doing&quot; algorithm that only involves function value estimation
to achieve a near-optimal performance. Our algorithm employs a series of
shrinking price intervals and iteratively tests prices within that interval
using a set of carefully chosen parameters. We prove that the convergence rate
of our algorithm is among the fastest of all possible algorithms in terms of
asymptotic &quot;regret&quot; (the relative loss comparing to the full information
optimal solution). Our result closes the performance gaps between parametric
and non-parametric learning and between a post-price mechanism and a
customer-bidding mechanism. Important managerial insight from this research is
that the values of information on both the parametric form of the demand
function as well as each customer's exact reservation price are less important
than prior literature suggests. Our results also suggest that firms would be
better off to perform dynamic learning and action concurrently rather than
sequentially.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4689</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4689</id><created>2011-01-24</created><updated>2011-01-25</updated><authors><author><keyname>Kawarabayashi</keyname><forenames>Ken-ichi</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>Minimum k-way cut of bounded size is fixed-parameter tractable</title><categories>cs.DM math.CO</categories><msc-class>05C85 (Primary) 68R10 (Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a the minimum k-way cut problem for unweighted graphs with a size
bound s on the number of cut edges allowed. Thus we seek to remove as few edges
as possible so as to split a graph into k components, or report that this
requires cutting more than s edges. We show that this problem is
fixed-parameter tractable (FPT) in s. More precisely, for s=O(1), our algorithm
runs in quadratic time while we have a different linear time algorithm for
planar graphs and bounded genus graphs. Our tractability result stands in
contrast to known W[1] hardness of related problems. Without the size bound,
Downey et al.[2003] proved that the minimum k-way cut problem is W[1] hard in k
even for simple unweighted graphs. Downey et al. asked about the status for
planar graphs. Our result implies tractability in k for the planar graphs since
the minimum k-way cut of a planar graph is of size at most 6k (more generally,
we get tractability in k for any graph class with k-way cuts of size limited by
is a function of k, e.g., bounded degree graphs, or simple graphs with an
excluded minor). A simple reduction shows that vertex cuts are at least as hard
as edge cuts, so the minimum k-way vertex cut is also W[1] hard in terms of k.
Marx [2004] proved that finding a minimum k-way vertex cut of size s is also
W[1] hard in s. Marx asked about the FPT status with edge cuts, which we prove
tractable here. We are not aware of any other cut problem where the vertex
version is W[1] hard but the edge version is FPT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4711</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4711</id><created>2011-01-24</created><authors><author><keyname>Abbott</keyname><forenames>Alastair A.</forenames></author><author><keyname>Calude</keyname><forenames>Cristian S.</forenames></author></authors><title>Von Neumann Normalisation of a Quantum Random Number Generator</title><categories>cs.IT math.IT quant-ph</categories><comments>26 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study von Neumann un-biasing normalisation for ideal and
real quantum random number generators, operating on finite strings or infinite
bit sequences. In the ideal cases one can obtain the desired un-biasing. This
relies critically on the independence of the source, a notion we rigorously
define for our model. In real cases, affected by imperfections in measurement
and hardware, one cannot achieve a true un-biasing, but, if the bias &quot;drifts
sufficiently slowly&quot;, the result can be arbitrarily close to un-biasing. For
infinite sequences, normalisation can both increase or decrease the
(algorithmic) randomness of the generated sequences. A successful application
of von Neumann normalisation-in fact, any un-biasing transformation-does
exactly what it promises, un-biasing, one (among infinitely many) symptoms of
randomness; it will not produce &quot;true&quot; randomness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4718</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4718</id><created>2011-01-24</created><updated>2012-04-17</updated><authors><author><keyname>Arnaudon</keyname><forenames>Marc</forenames></author><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author></authors><title>On Approximating the Riemannian 1-Center</title><categories>cs.CG</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we generalize the simple Euclidean 1-center approximation
algorithm of Badoiu and Clarkson (2003) to Riemannian geometries and study
accordingly the convergence rate. We then show how to instantiate this generic
algorithm to two particular cases: (1) hyperbolic geometry, and (2) Riemannian
manifold of symmetric positive definite matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4724</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4724</id><created>2011-01-25</created><updated>2011-06-05</updated><authors><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>A Message-Passing Receiver for BICM-OFDM over Unknown Clustered-Sparse
  Channels</title><categories>cs.IT math.IT</categories><doi>10.1109/JSTSP.2011.2169232</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a factor-graph-based approach to joint
channel-estimation-and-decoding (JCED) of bit- interleaved coded orthogonal
frequency division multiplexing (BICM-OFDM). In contrast to existing designs,
ours is capable of exploiting not only sparsity in sampled channel taps but
also clustering among the large taps, behaviors which are known to manifest at
larger communication bandwidths. In order to exploit these channel-tap
structures, we adopt a two-state Gaussian mixture prior in conjunction with a
Markov model on the hidden state. For loopy belief propagation, we exploit a
&quot;generalized approximate message passing&quot; (GAMP) algorithm recently developed
in the context of compressed sensing, and show that it can be successfully
coupled with soft-input soft-output decoding, as well as hidden Markov
inference, through the standard sum-product framework. For N subcarriers and
any channel length L &lt; N, the resulting JCED-GAMP scheme has a computational
complexity of only O(N log2 N + N|S|), where |S| is the constellation size.
Numerical experiments using IEEE 802.15.4a channels show that our scheme yields
BER performance within 1 dB of the known-channel bound and 3-4 dB better than
soft equalization based on LMMSE and LASSO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4730</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4730</id><created>2011-01-25</created><updated>2011-04-07</updated><authors><author><keyname>Hassan</keyname><forenames>M. Kamrul</forenames></author><author><keyname>Hassan</keyname><forenames>M. Zahedul</forenames></author><author><keyname>Pavel</keyname><forenames>Neeaj I.</forenames></author></authors><title>Dynamic scaling, data-collapse and self-similarity in
  Barab\'{a}si-Albert networks</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>5 pages, six figures, Minor changes in the title, abstract, figures
  and in the text in response to referee reports</comments><journal-ref>J. Phys. A: Math. Theor. 44, 175101 (2011)</journal-ref><doi>10.1088/1751-8113/44/17/175101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we show that if each node of the Barab\'{a}si-Albert (BA)
network is characterized by the generalized degree $q$, i.e. the product of
their degree $k$ and the square root of their respective birth time, then the
distribution function $F(q,t)$ exhibits dynamic scaling $F(q,t\rightarrow
\infty)\sim t^{-1/2}\phi(q/t^{1/2})$ where $\phi(x)$ is the scaling function.
We verified it by showing that a series of distinct $F(q,t)$ vs $q$ curves for
different network sizes $N$ collapse onto a single universal curve if we plot
$t^{1/2}F(q,t)$ vs $q/t^{1/2}$ instead. Finally, we show that the BA network
falls into two universality classes depending on whether new nodes arrive with
single edge ($m=1$) or with multiple edges ($m&gt;1$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4731</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4731</id><created>2011-01-25</created><authors><author><keyname>Bauer</keyname><forenames>Sebastian S.</forenames><affiliation>LMU Munich</affiliation></author><author><keyname>Hennicker</keyname><forenames>Rolf</forenames><affiliation>LMU Munich</affiliation></author><author><keyname>Janisch</keyname><forenames>Stephan</forenames><affiliation>LMU Munich</affiliation></author></authors><title>Interface Theories for (A)synchronously Communicating Modal
  I/O-Transition Systems</title><categories>cs.SE</categories><comments>In Proceedings FIT 2010, arXiv:1101.4266</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 46, 2011, pp. 1-8</journal-ref><doi>10.4204/EPTCS.46.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interface specifications play an important role in component-based software
development. An interface theory is a formal framework supporting composition,
refinement and compatibility of interface specifications. We present different
interface theories which use modal I/O-transition systems as their underlying
domain for interface specifications: synchronous interface theories, which
employ a synchronous communication schema, as well as a novel interface theory
for asynchronous communication where components communicate via FIFO-buffers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4732</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4732</id><created>2011-01-25</created><authors><author><keyname>Buscemi</keyname><forenames>Maria Grazia</forenames></author><author><keyname>Melgratti</keyname><forenames>Hern&#xe1;n</forenames></author></authors><title>Contracts for Abstract Processes in Service Composition</title><categories>cs.PL</categories><comments>In Proceedings FIT 2010, arXiv:1101.4266</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 46, 2011, pp. 9-27</journal-ref><doi>10.4204/EPTCS.46.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contracts are a well-established approach for describing and analyzing
behavioral aspects of web service compositions. The theory of contracts comes
equipped with a notion of compatibility between clients and servers that
ensures that every possible interaction between compatible clients and servers
will complete successfully. It is generally agreed that real applications often
require the ability of exposing just partial descriptions of their behaviors,
which are usually known as abstract processes. We propose a formal
characterization of abstraction as an extension of the usual symbolic
bisimulation and we recover the notion of abstraction in the context of
contracts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4733</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4733</id><created>2011-01-25</created><authors><author><keyname>Mendler</keyname><forenames>Michael</forenames><affiliation>Bamberg University, Germany</affiliation></author></authors><title>An Algebra of Synchronous Scheduling Interfaces</title><categories>cs.LO cs.PF cs.PL</categories><comments>In Proceedings FIT 2010, arXiv:1101.4266</comments><proxy>EPTCS</proxy><acm-class>F.3.1;F.3.2;F.4.1;F.2.2</acm-class><journal-ref>EPTCS 46, 2011, pp. 28-48</journal-ref><doi>10.4204/EPTCS.46.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an algebra of synchronous scheduling interfaces
which combines the expressiveness of Boolean algebra for logical and functional
behaviour with the min-max-plus arithmetic for quantifying the non-functional
aspects of synchronous interfaces. The interface theory arises from a
realisability interpretation of intuitionistic modal logic (also known as
Curry-Howard-Isomorphism or propositions-as-types principle). The resulting
algebra of interface types aims to provide a general setting for specifying
type-directed and compositional analyses of worst-case scheduling bounds. It
covers synchronous control flow under concurrent, multi-processing or
multi-threading execution and permits precise statements about exactness and
coverage of the analyses supporting a variety of abstractions. The paper
illustrates the expressiveness of the algebra by way of some examples taken
from network flow problems, shortest-path, task scheduling and worst-case
reaction times in synchronous programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4734</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4734</id><created>2011-01-25</created><authors><author><keyname>Legay</keyname><forenames>Axel</forenames><affiliation>INRIA Rennes, France</affiliation></author><author><keyname>W&#x105;sowski</keyname><forenames>Andrzej</forenames><affiliation>IT University of Copenhagen, Denmark</affiliation></author></authors><title>A Few Considerations on Structural and Logical Composition in
  Specification Theories</title><categories>cs.LO</categories><comments>In Proceedings FIT 2010, arXiv:1101.4266</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 46, 2011, pp. 49-54</journal-ref><doi>10.4204/EPTCS.46.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last 20 years a large number of automata-based specification
theories have been proposed for modeling of discrete,real-time and
probabilistic systems. We have observed a lot of shared algebraic structure
between these formalisms. In this short abstract, we collect results of our
work in progress on describing and systematizing the algebraic assumptions in
specification theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4749</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4749</id><created>2011-01-25</created><authors><author><keyname>Gunay</keyname><forenames>Osman</forenames></author><author><keyname>Toreyin</keyname><forenames>Behcet Ugur</forenames></author><author><keyname>Kose</keyname><forenames>Kivanc</forenames></author><author><keyname>Cetin</keyname><forenames>A. Enis</forenames></author></authors><title>Online Adaptive Decision Fusion Framework Based on Entropic Projections
  onto Convex Sets with Application to Wildfire Detection in Video</title><categories>cs.CV cs.LG</categories><comments>10 pages, 7 figures</comments><doi>10.1117/1.3595426</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an Entropy functional based online Adaptive Decision Fusion
(EADF) framework is developed for image analysis and computer vision
applications. In this framework, it is assumed that the compound algorithm
consists of several sub-algorithms each of which yielding its own decision as a
real number centered around zero, representing the confidence level of that
particular sub-algorithm. Decision values are linearly combined with weights
which are updated online according to an active fusion method based on
performing entropic projections onto convex sets describing sub-algorithms. It
is assumed that there is an oracle, who is usually a human operator, providing
feedback to the decision fusion method. A video based wildfire detection system
is developed to evaluate the performance of the algorithm in handling the
problems where data arrives sequentially. In this case, the oracle is the
security guard of the forest lookout tower verifying the decision of the
combined algorithm. Simulation results are presented. The EADF framework is
also tested with a standard dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4750</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4750</id><created>2011-01-25</created><authors><author><keyname>Zhou</keyname><forenames>Ping</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Fractional counting of citations in research evaluation: A cross- and
  interdisciplinary assessment of the Tsinghua University in Beijing</title><categories>cs.DL</categories><comments>30 pages, four tables, and one figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the case of the scientometric evaluation of multi- or interdisciplinary
units one risks to compare apples with oranges: each paper has to be assessed
in comparison to an appropriate reference set. We suggest that the set of
citing papers can be considered as the relevant representation of the field of
impact. In order to normalize for differences in citation behavior among
fields, citations can be fractionally counted proportionately to the length of
the reference lists in the citing papers. This new method enables us to compare
among units with different disciplinary affiliations at the paper level and
also to assess the statistical significance of differences among sets.
Twenty-seven departments of the Tsinghua University in Beijing are thus
compared. Among them, the Department of Chinese Language and Linguistics is
upgraded from the 19th to the second position in the ranking. The overall
impact of 19 of the 27 departments is not significantly different at the 5%
level when thus normalized for different citation potentials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4752</identifier>
 <datestamp>2012-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4752</id><created>2011-01-25</created><updated>2012-04-02</updated><authors><author><keyname>Telgarsky</keyname><forenames>Matus</forenames></author></authors><title>A Primal-Dual Convergence Analysis of Boosting</title><categories>cs.LG math.OC</categories><comments>40 pages, 8 figures; the NIPS 2011 submission &quot;The Fast Convergence
  of Boosting&quot; is a brief presentation of the primary results; compared with
  the JMLR version, this arXiv version has hyperref and some formatting tweaks</comments><journal-ref>Journal of Machine Learning Research, 13:561-606, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosting combines weak learners into a predictor with low empirical risk. Its
dual constructs a high entropy distribution upon which weak learners and
training labels are uncorrelated. This manuscript studies this primal-dual
relationship under a broad family of losses, including the exponential loss of
AdaBoost and the logistic loss, revealing:
  - Weak learnability aids the whole loss family: for any {\epsilon}&gt;0,
O(ln(1/{\epsilon})) iterations suffice to produce a predictor with empirical
risk {\epsilon}-close to the infimum;
  - The circumstances granting the existence of an empirical risk minimizer may
be characterized in terms of the primal and dual problems, yielding a new proof
of the known rate O(ln(1/{\epsilon}));
  - Arbitrary instances may be decomposed into the above two, granting rate
O(1/{\epsilon}), with a matching lower bound provided for the logistic loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4753</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4753</id><created>2011-01-25</created><updated>2011-01-25</updated><authors><author><keyname>Lee</keyname><forenames>Beom Hee</forenames></author><author><keyname>Kim</keyname><forenames>Seong-Lyun</forenames></author></authors><title>Mobility Control for Machine-to-Machine LTE Systems</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an efficient mobility control algorithm for the
downlink multi-cell orthogonal frequency division multiplexing access (OFDMA)
system for co-channel interference reduction. It divides each cell into several
areas. The mobile nodes in each area find their own optimal position according
to their present location. Both the signal to interference plus noise ratio
(SINR) and the capacity for each node are increased by the proposed mobility
control algorithm. Simulation results say that, even the frequency reuse factor
(FRF) is equal to 1, the average capacity is improved after applying the
mobility control algorithm, compared to existing partial frequency reuse (PFR)
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4789</identifier>
 <datestamp>2013-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4789</id><created>2011-01-25</created><updated>2012-04-09</updated><authors><author><keyname>Fraczek</keyname><forenames>Wojciech</forenames></author><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Multi-Level Steganography: Improving Hidden Communication in Networks</title><categories>cs.CR cs.MM</categories><comments>18 pages, 13 figures</comments><journal-ref>Journal of Universal Computer Science (J. UCS), Vol. 18, No. 14,
  pp. 1967-1986</journal-ref><doi>10.3217/jucs-018-14-1967</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents Multi-Level Steganography (MLS), which defines a new
concept for hidden communication in telecommunication networks. In MLS, at
least two steganographic methods are utilised simultaneously, in such a way
that one method (called the upper-level) serves as a carrier for the second one
(called the lower-level). Such a relationship between two (or more) information
hiding solutions has several potential benefits. The most important is that the
lower-level method steganographic bandwidth can be utilised to make the
steganogram unreadable even after the detection of the upper-level method:
e.g., it can carry a cryptographic key that deciphers the steganogram carried
by the upper-level one. It can also be used to provide the steganogram with
integrity. Another important benefit is that the lower-layer method may be used
as a signalling channel in which to exchange information that affects the way
that the upper-level method functions, thus possibly making the steganographic
communication harder to detect. The prototype of MLS for IP networks was also
developed, and the experimental results are included in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4795</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4795</id><created>2011-01-25</created><updated>2011-10-05</updated><authors><author><keyname>Delahaye</keyname><forenames>Jean-Paul</forenames></author><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>Numerical Evaluation of Algorithmic Complexity for Short Strings: A
  Glance into the Innermost Structure of Randomness</title><categories>cs.IT cs.CC math.IT</categories><comments>29 pages, 5 figures. Version as accepted by the journal Applied
  Mathematics and Computation</comments><acm-class>E.4; F.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an alternative method (to compression) that combines several
theoretical and experimental results to numerically approximate the algorithmic
(Kolmogorov-Chaitin) complexity of all $\sum_{n=1}^82^n$ bit strings up to 8
bits long, and for some between 9 and 16 bits long. This is done by an
exhaustive execution of all deterministic 2-symbol Turing machines with up to 4
states for which the halting times are known thanks to the Busy Beaver problem,
that is 11019960576 machines. An output frequency distribution is then
computed, from which the algorithmic probability is calculated and the
algorithmic complexity evaluated by way of the (Levin-Zvonkin-Chaitin) coding
theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4813</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4813</id><created>2011-01-25</created><authors><author><keyname>Mimram</keyname><forenames>Samuel</forenames><affiliation>CEA LIST</affiliation></author></authors><title>The Structure of First-Order Causality (extended version)</title><categories>cs.LO cs.GT math.CT</categories><proxy>ccsd</proxy><journal-ref>Mathematical Structures in Computer Science 21, 01 (2011) 65-110</journal-ref><doi>10.1017/S0960129510000459</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game semantics describe the interactive behavior of proofs by interpreting
formulas as games on which proofs induce strategies. Such a semantics is
introduced here for capturing dependencies induced by quantifications in
first-order propositional logic. One of the main difficulties that has to be
faced during the elaboration of this kind of semantics is to characterize
definable strategies, that is strategies which actually behave like a proof.
This is usually done by restricting the model to strategies satisfying subtle
combinatorial conditions, whose preservation under composition is often
difficult to show. Here, we present an original methodology to achieve this
task, which requires to combine advanced tools from game semantics, rewriting
theory and categorical algebra. We introduce a diagrammatic presentation of the
monoidal category of definable strategies of our model, by the means of
generators and relations: those strategies can be generated from a finite set
of atomic strategies and the equality between strategies admits a finite
axiomatization, this equational structure corresponding to a polarized
variation of the notion of bialgebra. This work thus bridges algebra and
denotational semantics in order to reveal the structure of dependencies induced
by first-order quantifiers, and lays the foundations for a mechanized analysis
of causality in programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4815</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4815</id><created>2011-01-25</created><authors><author><keyname>Ding</keyname><forenames>Minhua</forenames></author><author><keyname>Zhang</keyname><forenames>Q. T.</forenames></author></authors><title>Source Optimization in MISO Relaying with Channel Mean Feedback: A
  Stochastic Ordering Approach</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of IEEE ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the optimum source transmission strategy to maximize
the capacity of a multiple-input single-output (MISO) amplify-and-forward relay
channel, assuming source-relay channel mean feedback at the source. The
challenge here is that relaying introduces a nonconvex structure in the
objective function, thereby excluding the possible use of previous methods
dealing with mean feedback that generally rely on the concavity of the
objective function. A novel method is employed, which divides the feasible set
into two subsets and establishes the optimum from one of them by comparison. As
such, the optimization is transformed into the comparison of two nonnegative
random variables in the Laplace transform order, which is one of the important
stochastic orders. It turns out that the optimum transmission strategy is to
transmit along the known channel mean and its orthogonal eigenchannels. The
condition for rank-one precoding (beamforming) to achieve capacity is also
determined. Our results subsume those for traditional MISO precoding with mean
feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4824</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4824</id><created>2011-01-25</created><authors><author><keyname>Diekert</keyname><forenames>Volker</forenames></author><author><keyname>Kopecki</keyname><forenames>Steffen</forenames></author></authors><title>It Is NL-complete to Decide Whether a Hairpin Completion of Regular
  Languages Is Regular</title><categories>cs.FL cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hairpin completion is an operation on formal languages which is inspired
by the hairpin formation in biochemistry. Hairpin formations occur naturally
within DNA-computing. It has been known that the hairpin completion of a
regular language is linear context-free, but not regular, in general. However,
for some time it is was open whether the regularity of the hairpin completion
of a regular language is is decidable. In 2009 this decidability problem has
been solved positively by providing a polynomial time algorithm. In this paper
we improve the complexity bound by showing that the decision problem is
actually NL-complete. This complexity bound holds for both, the one-sided and
the two-sided hairpin completions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4848</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4848</id><created>2011-01-25</created><authors><author><keyname>Moser</keyname><forenames>Philippe</forenames></author></authors><title>A zero-one SUBEXP-dimension law for BPP</title><categories>cs.CC</categories><comments>to be published in information processing letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that BPP has either SUBEXP-dimension zero (randomness is easy) or
BPP=EXP (randomness is intractable).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4849</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4849</id><created>2011-01-25</created><authors><author><keyname>Carli</keyname><forenames>Francesca</forenames></author><author><keyname>Ferrante</keyname><forenames>Augusto</forenames></author><author><keyname>Pavon</keyname><forenames>Michele</forenames></author><author><keyname>Picci</keyname><forenames>Giorgio</forenames></author></authors><title>A Maximum Entropy solution of the Covariance Extension Problem for
  Reciprocal Processes</title><categories>math.OC cs.IT cs.SY math.IT math.PR</categories><comments>33 pages, to appear in the IEEE Trans. Aut. Contr</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stationary reciprocal processes defined on a finite interval of the integer
line can be seen as a special class of Markov random fields restricted to one
dimension. Non stationary reciprocal processes have been extensively studied in
the past especially by Jamison, Krener, Levy and co-workers. The specialization
of the non-stationary theory to the stationary case, however, does not seem to
have been pursued in sufficient depth in the literature. Stationary reciprocal
processes (and reciprocal stochastic models) are potentially useful for
describing signals which naturally live in a finite region of the time (or
space) line. Estimation or identification of these models starting from
observed data seems still to be an open problem which can lead to many
interesting applications in signal and image processing. In this paper, we
discuss a class of reciprocal processes which is the acausal analog of
auto-regressive (AR) processes, familiar in control and signal processing. We
show that maximum likelihood identification of these processes leads to a
covariance extension problem for block-circulant covariance matrices. This
generalizes the famous covariance band extension problem for stationary
processes on the integer line. As in the usual stationary setting on the
integer line, the covariance extension problem turns out to be a basic
conceptual and practical step in solving the identification problem. We show
that the maximum entropy principle leads to a complete solution of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4918</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4918</id><created>2011-01-25</created><authors><author><keyname>Iqbal</keyname><forenames>Ridwan Al</forenames></author></authors><title>Using Feature Weights to Improve Performance of Neural Networks</title><categories>cs.LG cs.AI cs.CV</categories><comments>2 tables, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different features have different relevance to a particular learning problem.
Some features are less relevant; while some very important. Instead of
selecting the most relevant features using feature selection, an algorithm can
be given this knowledge of feature importance based on expert opinion or prior
learning. Learning can be faster and more accurate if learners take feature
importance into account. Correlation aided Neural Networks (CANN) is presented
which is such an algorithm. CANN treats feature importance as the correlation
coefficient between the target attribute and the features. CANN modifies normal
feed-forward Neural Network to fit both correlation values and training data.
Empirical evaluation shows that CANN is faster and more accurate than applying
the two step approach of feature selection and then using normal learning
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4924</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4924</id><created>2011-01-25</created><authors><author><keyname>Iqbal</keyname><forenames>Ridwan Al</forenames></author></authors><title>A Generalized Method for Integrating Rule-based Knowledge into Inductive
  Methods Through Virtual Sample Creation</title><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid learning methods use theoretical knowledge of a domain and a set of
classified examples to develop a method for classification. Methods that use
domain knowledge have been shown to perform better than inductive learners.
However, there is no general method to include domain knowledge into all
inductive learning algorithms as all hybrid methods are highly specialized for
a particular algorithm. We present an algorithm that will take domain knowledge
in the form of propositional rules, generate artificial examples from the rules
and also remove instances likely to be flawed. This enriched dataset then can
be used by any learning algorithm. Experimental results of different scenarios
are shown that demonstrate this method to be more effective than simple
inductive learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4929</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4929</id><created>2011-01-25</created><updated>2011-04-20</updated><authors><author><keyname>Adamek</keyname><forenames>Jiri</forenames><affiliation>Institut fuer Theoretische Informatik, Technische Universitaet Braunschweig, Ger</affiliation></author><author><keyname>Milius</keyname><forenames>Stefan</forenames><affiliation>Institut fuer Theoretische Informatik, Technische Universitaet Braunschweig, Ger</affiliation></author><author><keyname>Velebil</keyname><forenames>Jiri</forenames><affiliation>Faculty of Electrical Engineering, Czech Technical University of Prague, Prague,</affiliation></author></authors><title>Semantics of Higher-Order Recursion Schemes</title><categories>cs.LO math.CT</categories><proxy>LMCS</proxy><acm-class>math.CT</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (April 1,
  2011) lmcs:1177</journal-ref><doi>10.2168/LMCS-7(1:15)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Higher-order recursion schemes are recursive equations defining new
operations from given ones called &quot;terminals&quot;. Every such recursion scheme is
proved to have a least interpreted semantics in every Scott's model of
\lambda-calculus in which the terminals are interpreted as continuous
operations. For the uninterpreted semantics based on infinite \lambda-terms we
follow the idea of Fiore, Plotkin and Turi and work in the category of sets in
context, which are presheaves on the category of finite sets. Fiore et al
showed how to capture the type of variable binding in \lambda-calculus by an
endofunctor H\lambda and they explained simultaneous substitution of
\lambda-terms by proving that the presheaf of \lambda-terms is an initial
H\lambda-monoid. Here we work with the presheaf of rational infinite
\lambda-terms and prove that this is an initial iterative H\lambda-monoid. We
conclude that every guarded higher-order recursion scheme has a unique
uninterpreted solution in this monoid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4957</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4957</id><created>2011-01-25</created><updated>2011-02-06</updated><authors><author><keyname>Sala&#xfc;n</keyname><forenames>Erwan</forenames></author><author><keyname>Gariel</keyname><forenames>Maxime</forenames></author><author><keyname>Vela</keyname><forenames>Adan</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Aircraft Proximity Maps Based on Data-Driven Flow Modeling</title><categories>cs.SY physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the forecast increase in air traffic demand over the next decades, it is
imperative to develop tools to provide traffic flow managers with the
information required to support decision making. In particular,
decision-support tools for traffic flow management should aid in limiting
controller workload and complexity, while supporting increases in air traffic
throughput. While many decision-support tools exist for short-term traffic
planning, few have addressed the strategic needs for medium- and long-term
planning for time horizons greater than 30 minutes. This paper seeks to address
this gap through the introduction of 3D aircraft proximity maps that evaluate
the future probability of presence of at least one or two aircraft at any given
point of the airspace. Three types of proximity maps are presented: presence
maps that indicate the local density of traffic; conflict maps that determine
locations and probabilities of potential conflicts; and outliers maps that
evaluate the probability of conflict due to aircraft not belonging to dominant
traffic patterns. These maps provide traffic flow managers with information
relating to the complexity and difficulty of managing an airspace. The intended
purpose of the maps is to anticipate how aircraft flows will interact, and how
outliers impact the dominant traffic flow for a given time period. This
formulation is able to predict which &quot;critical&quot; regions may be subject to
conflicts between aircraft, thereby requiring careful monitoring. These
probabilities are computed using a generative aircraft flow model. Time-varying
flow characteristics, such as geometrical configuration, speed, and probability
density function of aircraft spatial distribution within the flow, are
determined from archived Enhanced Traffic Management System data, using a
tailored clustering algorithm. Aircraft not belonging to flows are identified
as outliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4981</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4981</id><created>2011-01-25</created><updated>2012-02-29</updated><authors><author><keyname>Froese</keyname><forenames>Brittany D.</forenames></author></authors><title>A numerical method for the elliptic Monge-Amp\`ere equation with
  transport boundary conditions</title><categories>math.NA cs.NA physics.comp-ph</categories><comments>Will appear in SIAM J. Sci. Comput</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of optimal mass transport arises in numerous applications
including image registration, mesh generation, reflector design, and
astrophysics. One approach to solving this problem is via the Monge-Amp\`ere
equation. While recent years have seen much work in the development of
numerical methods for solving this equation, very little has been done on the
implementation of the transport boundary condition. In this paper, we propose a
method for solving the transport problem by iteratively solving a
Monge-Amp\`ere equation with Neumann boundary conditions. To enable mappings
between variable densities, we extend an earlier discretization of the equation
to allow for right-hand sides that depend on gradients of the solution [Froese
and Oberman, SIAM J. Numer. Anal., 49 (2011) 1692--1714]. This discretization
provably converges to the viscosity solution. The resulting system is solved
efficiently with Newton's method. We provide several challenging computational
examples that demonstrate the effectiveness and efficiency ($O(M)-O(M^{1.3})$
time) of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4989</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4989</id><created>2011-01-25</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Huang</keyname><forenames>Huang</forenames></author></authors><title>Opportunistic Buffered Decode-Wait-and-Forward (OBDWF) Protocol for
  Mobile Wireless Relay Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an opportunistic buffered decode-wait-and-forward
(OBDWF) protocol to exploit both relay buffering and relay mobility to enhance
the system throughput and the end-to-end packet delay under bursty arrivals. We
consider a point-to-point communication link assisted by K mobile relays. We
illustrate that the OBDWF protocol could achieve a better throughput and delay
performance compared with existing baseline systems such as the conventional
dynamic decode-and-forward (DDF) and amplified-and-forward (AF) protocol. In
addition to simulation performance, we also derived closed-form asymptotic
throughput and delay expressions of the OBDWF protocol. Specifically, the
proposed OBDWF protocol achieves an asymptotic throughput O(logK) with O(1)
total transmit power in the relay network. This is a significant gain compared
with the best known performance in conventional protocols (O(logK) throughput
with O(K) total transmit power). With bursty arrivals, we show that both the
stability region and average delay of the proposed OBDWF protocol can achieve
order-wise performance gain O(K) compared with conventional DDF protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.4999</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.4999</id><created>2011-01-26</created><authors><author><keyname>Geil</keyname><forenames>Olav</forenames></author><author><keyname>Thomsen</keyname><forenames>Casper</forenames></author></authors><title>List decoding of a class of affine variety codes</title><categories>cs.IT math.IT</categories><comments>11 pages, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a polynomial $F$ in $m$ variables and a finite point ensemble $S=S_1
\times ... \times S_m$. When given the leading monomial of $F$ with respect to
a lexicographic ordering we derive improved information on the possible number
of zeros of $F$ of multiplicity at least $r$ from $S$. We then use this
information to design a list decoding algorithm for a large class of affine
variety codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5019</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5019</id><created>2011-01-26</created><updated>2011-08-02</updated><authors><author><keyname>Wehmuth</keyname><forenames>Klaus</forenames></author><author><keyname>Ziviani</keyname><forenames>Artur</forenames></author></authors><title>Distributed Algorithm to Locate Critical Nodes to Network Robustness
  based on Spectral Analysis</title><categories>cs.NI</categories><comments>Proceedings of the 7th Latin American Network Operations and
  Management Symposium - LANOMS 2011, Quito, Ecuador, October 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an algorithm to locate the most critical nodes to network
robustness. Such critical nodes may be thought of as those most related to the
notion of network centrality. Our proposal relies only on a localized spectral
analysis of a limited subnetwork centered at each node in the network. We also
present a procedure allowing the navigation from any node towards a critical
node following only local information computed by the proposed algorithm.
Experimental results confirm the effectiveness of our proposal considering
networks of different scales and topological characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5025</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5025</id><created>2011-01-26</created><authors><author><keyname>Alnawayseh</keyname><forenames>Saif E. A.</forenames></author><author><keyname>Loskot</keyname><forenames>Pavel</forenames></author></authors><title>Order Statistics Based List Decoding Techniques for Linear Binary Block
  Codes</title><categories>cs.IT math.IT</categories><comments>17 pages, 2 tables, 6 figures, submitted to IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The order statistics based list decoding techniques for linear binary block
codes of small to medium block length are investigated. The construction of the
list of the test error patterns is considered. The original order statistics
decoding is generalized by assuming segmentation of the most reliable
independent positions of the received bits. The segmentation is shown to
overcome several drawbacks of the original order statistics decoding. The
complexity of the order statistics based decoding is further reduced by
assuming a partial ordering of the received bits in order to avoid the complex
Gauss elimination. The probability of the test error patterns in the decoding
list is derived. The bit error rate performance and the decoding complexity
trade-off of the proposed decoding algorithms is studied by computer
simulations. Numerical examples show that, in some cases, the proposed decoding
schemes are superior to the original order statistics decoding in terms of both
the bit error rate performance as well as the decoding complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5027</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5027</id><created>2011-01-26</created><authors><author><keyname>Bosio</keyname><forenames>Sandro</forenames></author><author><keyname>Yuan</keyname><forenames>Di</forenames></author></authors><title>Modeling and Solving AP Location and Frequency Assignment for Maximizing
  Access Efficiency in Wi-Fi Networks</title><categories>math.OC cs.NI</categories><comments>In proceedings of International Network Optimization Conference 2009
  (INOC 2009), Pisa, Italy, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present optimization approaches for Access Point (AP)
location and frequency assignment, two major planning tasks in deploying Wi-Fi
networks. Since APs are relatively cheap, the major concern is network
performance. We consider a performance metric, referred to as access
efficiency, that captures key aspects of how user devices share access to the
wireless medium. We propose a two-step approach to deal with AP location and
frequency assignment in maximizing access efficiency. A novelty of our modeling
approach is to estimate, in the first step of AP location, the impact of
expected frequency availability on frequency assignment. For each of the two
steps we derive hyperbolic formulations and their linearizations, and we
propose a promising enumerative formulation. Sample results are reported to
show the applicability of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5039</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5039</id><created>2011-01-26</created><authors><author><keyname>Abolghasemi-Dahaghani</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author><author><keyname>Nowroozi</keyname><forenames>Alireza</forenames></author></authors><title>A Novel Template-Based Learning Model</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a model which is capable of learning and abstracting
new concepts based on comparing observations and finding the resemblance
between the observations. In the model, the new observations are compared with
the templates which have been derived from the previous experiences. In the
first stage, the objects are first represented through a geometric description
which is used for finding the object boundaries and a descriptor which is
inspired by the human visual system and then they are fed into the model. Next,
the new observations are identified through comparing them with the
previously-learned templates and are used for producing new templates. The
comparisons are made based on measures like Euclidean or correlation distance.
The new template is created by applying onion-pealing algorithm. The algorithm
consecutively uses convex hulls which are made by the points representing the
objects. If the new observation is remarkably similar to one of the observed
categories, it is no longer utilized in creating a new template. The existing
templates are used to provide a description of the new observation. This
description is provided in the templates space. Each template represents a
dimension of the feature space. The degree of the resemblance each template
bears to each object indicates the value associated with the object in that
dimension of the templates space. In this way, the description of the new
observation becomes more accurate and detailed as the time passes and the
experiences increase. We have used this model for learning and recognizing the
new polygons in the polygon space. Representing the polygons was made possible
through employing a geometric method and a method inspired by human visual
system. Various implementations of the model have been compared. The evaluation
results of the model prove its efficiency in learning and deriving new
templates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5046</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5046</id><created>2011-01-26</created><authors><author><keyname>S&#xe9;nizergues</keyname><forenames>G&#xe9;raud</forenames><affiliation>Bordeaux, France</affiliation></author></authors><title>Jancar's formal system for deciding bisimulation of first-order grammars
  and its non-soundness</title><categories>cs.FL cs.LO</categories><comments>12 pages, 9 figures</comments><acm-class>F.4.2; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct an example of proof within the main formal system from
arXiv:1010.4760v3, which is intended to capture the bisimulation equivalence
for non-deterministic first-order grammars, and show that its conclusion is
semantically false. We then locate and analyze the flawed argument in the
soundness (meta)-proof of the above reference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5048</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5048</id><created>2011-01-26</created><authors><author><keyname>Mirshahvalad</keyname><forenames>Atieh</forenames></author><author><keyname>Rosvall</keyname><forenames>Martin</forenames></author></authors><title>Reinforced communication and social navigation: remember your friends
  and remember yourself</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages, 6 Figures</comments><doi>10.1103/PhysRevE.84.036102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In social systems, people communicate with each other and form groups based
on their interests. The pattern of interactions, the network, and the ideas
that flow on the network naturally evolve together. Researchers use simple
models to capture the feedback between changing network patterns and ideas on
the network, but little is understood about the role of past events in the
feedback process. Here we introduce a simple agent-based model to study the
coupling between peoples' ideas and social networks, and better understand the
role of history in dynamic social networks. We measure how information about
ideas can be recovered from information about network structure and, the other
way around, how information about network structure can be recovered from
information about ideas. We find that it is in general easier to recover ideas
from the network structure than vice versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5058</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5058</id><created>2011-01-26</created><authors><author><keyname>Jiang</keyname><forenames>Luo-Luo</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author><author><keyname>Wang</keyname><forenames>Wen-Xu</forenames></author><author><keyname>Lai</keyname><forenames>Ying-Cheng</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author></authors><title>Impact of link deletions on public cooperation in scale-free networks</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>6 two-column pages, 5 figures; accepted for publication in
  Europhysics Letters [related work available at http://arxiv.org/abs/0902.4661
  and http://www.matjazperc.com/]</comments><journal-ref>EPL 93 (2011) 40001</journal-ref><doi>10.1209/0295-5075/93/40001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Working together in groups may be beneficial if compared to isolated efforts.
Yet this is true only if all group members contribute to the success. If not,
group efforts may act detrimentally on the fitness of their members. Here we
study the evolution of cooperation in public goods games on scale-free networks
that are subject to deletion of links that are connected to the highest-degree
individuals, i.e., on networks that are under attack. We focus on the case
where all groups a player belongs to are considered for the determination of
payoffs; the so-called multi-group public goods games. We find that the effect
of link deletions on the evolution of cooperation is predominantly detrimental,
although there exist regions of the multiplication factor where the existence
of an &quot;optimal&quot; number of removed links for deterioration of cooperation can
also be demonstrated. The findings are explained by means of wealth
distributions and analytical approximations, confirming that socially diverse
states are crucial for the successful evolution of cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5076</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5076</id><created>2011-01-26</created><updated>2012-06-20</updated><authors><author><keyname>Graben</keyname><forenames>Peter beim</forenames></author><author><keyname>Gerth</keyname><forenames>Sabrina</forenames></author></authors><title>Geometric representations for minimalist grammars</title><categories>cs.CL</categories><comments>43 pages, 4 figures</comments><doi>10.1007/s10849-012-9164-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reformulate minimalist grammars as partial functions on term algebras for
strings and trees. Using filler/role bindings and tensor product
representations, we construct homomorphisms for these data structures into
geometric vector spaces. We prove that the structure-building functions as well
as simple processors for minimalist languages can be realized by piecewise
linear operators in representation space. We also propose harmony, i.e. the
distance of an intermediate processing step from the final well-formed state in
representation space, as a measure of processing complexity. Finally, we
illustrate our findings by means of two particular arithmetic and fractal
representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5079</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5079</id><created>2011-01-26</created><updated>2011-01-27</updated><authors><author><keyname>Kose</keyname><forenames>Kivanc</forenames></author><author><keyname>Gunay</keyname><forenames>Osman</forenames></author><author><keyname>Cetin</keyname><forenames>A. Enis</forenames></author></authors><title>Compressive Sensing Using the Entropy Functional</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most compressive sensing problems l1 norm is used during the signal
reconstruction process. In this article the use of entropy functional is
proposed to approximate the l1 norm. A modified version of the entropy
functional is continuous, differentiable and convex. Therefore, it is possible
to construct globally convergent iterative algorithms using Bregman's row
action D-projection method for compressive sensing applications. Simulation
examples are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5088</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5088</id><created>2011-01-26</created><authors><author><keyname>Chen</keyname><forenames>Yi-Ting</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Shakkottai</keyname><forenames>Sanjay</forenames></author></authors><title>On Sharing Viral Video over an Ad Hoc Wireless Network</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of broadcasting a viral video (a large file) over an
ad hoc wireless network (e.g., students in a campus). Many smartphones are GPS
enabled, and equipped with peer-to-peer (ad hoc) transmission mode, allowing
them to wirelessly exchange files over short distances rather than use the
carrier's WAN. The demand for the file however is transmitted through the
social network (e.g., a YouTube link posted on Facebook).
  To address this coupled-network problem (demand on the social network;
bandwidth on the wireless network) where the two networks have different
topologies, we propose a file dissemination algorithm. In our scheme, users
query their social network to find geographically nearby friends that have the
desired file, and utilize the underlying ad hoc network to route the data via
multi-hop transmissions. We show that for many popular models for social
networks, the file dissemination time scales sublinearly with n; the number of
users, compared to the linear scaling required if each user who wants the file
must download it from the carrier's WAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5097</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5097</id><created>2011-01-26</created><authors><author><keyname>M&#xf8;rup</keyname><forenames>Morten</forenames></author><author><keyname>Schmidt</keyname><forenames>Mikkel N.</forenames></author><author><keyname>Hansen</keyname><forenames>Lars Kai</forenames></author></authors><title>Infinite Multiple Membership Relational Modeling for Complex Networks</title><categories>cs.SI cs.LG physics.soc-ph</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning latent structure in complex networks has become an important problem
fueled by many types of networked data originating from practically all fields
of science. In this paper, we propose a new non-parametric Bayesian
multiple-membership latent feature model for networks. Contrary to existing
multiple-membership models that scale quadratically in the number of vertices
the proposed model scales linearly in the number of links admitting
multiple-membership analysis in large scale networks. We demonstrate a
connection between the single membership relational model and multiple
membership models and show on &quot;real&quot; size benchmark network data that
accounting for multiple memberships improves the learning of latent structure
as measured by link prediction while explicitly accounting for multiple
membership result in a more compact representation of the latent structure of
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5108</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5108</id><created>2011-01-26</created><authors><author><keyname>Quinn</keyname><forenames>Christopher J.</forenames></author><author><keyname>Coleman</keyname><forenames>Todd P.</forenames></author><author><keyname>Kiyavash</keyname><forenames>Negar</forenames></author></authors><title>Causal Dependence Tree Approximations of Joint Distributions for
  Multiple Random Processes</title><categories>cs.IT math.IT</categories><comments>9 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate approximating joint distributions of random processes with
causal dependence tree distributions. Such distributions are particularly
useful in providing parsimonious representation when there exists causal
dynamics among processes. By extending the results by Chow and Liu on
dependence tree approximations, we show that the best causal dependence tree
approximation is the one which maximizes the sum of directed informations on
its edges, where best is defined in terms of minimizing the KL-divergence
between the original and the approximate distribution. Moreover, we describe a
low-complexity algorithm to efficiently pick this approximate distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5120</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5120</id><created>2011-01-26</created><updated>2011-12-08</updated><authors><author><keyname>Dodds</keyname><forenames>Peter Sheridan</forenames></author><author><keyname>Harris</keyname><forenames>Kameron Decker</forenames></author><author><keyname>Kloumann</keyname><forenames>Isabel M.</forenames></author><author><keyname>Bliss</keyname><forenames>Catherine A.</forenames></author><author><keyname>Danforth</keyname><forenames>Christopher M.</forenames></author></authors><title>Temporal patterns of happiness and information in a global social
  network: Hedonometrics and Twitter</title><categories>physics.soc-ph cs.SI</categories><comments>27 pages, 17 figures, 3 tables. Supplementary Information: 1 table,
  52 figures</comments><journal-ref>PLoS ONE, Vol 6(2): e26752, 2011</journal-ref><doi>10.1371/journal.pone.0026752</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Individual happiness is a fundamental societal metric. Normally measured
through self-report, happiness has often been indirectly characterized and
overshadowed by more readily quantifiable economic indicators such as gross
domestic product. Here, we examine expressions made on the online, global
microblog and social networking service Twitter, uncovering and explaining
temporal variations in happiness and information levels over timescales ranging
from hours to years. Our data set comprises over 46 billion words contained in
nearly 4.6 billion expressions posted over a 33 month span by over 63 million
unique users. In measuring happiness, we use a real-time, remote-sensing,
non-invasive, text-based approach---a kind of hedonometer. In building our
metric, made available with this paper, we conducted a survey to obtain
happiness evaluations of over 10,000 individual words, representing a tenfold
size improvement over similar existing word sets. Rather than being ad hoc, our
word list is chosen solely by frequency of usage and we show how a highly
robust metric can be constructed and defended.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5127</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5127</id><created>2011-01-13</created><authors><author><keyname>Anitha</keyname><forenames>J.</forenames></author><author><keyname>Pandian</keyname><forenames>S. Immanuel Alex</forenames></author></authors><title>A Color Image Digital Watermarking Scheme Based on SOFM</title><categories>cs.MM cs.CR</categories><comments>International Journal of Computer Science Issues online at
  http://www.ijcsi.org</comments><journal-ref>IJCSI, Volume 7, Issue 5, September 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital watermarking technique has been presented and widely researched to
solve some important issues in the digital world, such as copyright protection,
copy protection and content authentication. Several robust watermarking schemes
based on vector quantization (VQ) have been presented. In this paper, we
present a new digital image watermarking method based on SOFM vector quantizer
for color images. This method utilizes the codebook partition technique in
which the watermark bit is embedded into the selected VQ encoded block. The
main feature of this scheme is that the watermark exists both in VQ compressed
image and in the reconstructed image. The watermark extraction can be performed
without the original image. The watermark is hidden inside the compressed
image, so much transmission time and storage space can be saved when the
compressed data are transmitted over the Internet. Simulation results
demonstrate that the proposed method has robustness against various image
processing operations without sacrificing compression performance and the
computational speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5130</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5130</id><created>2011-01-26</created><authors><author><keyname>Novlan</keyname><forenames>Thomas David</forenames></author><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Ghosh</keyname><forenames>Arunabha</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Analytical Evaluation of Fractional Frequency Reuse for OFDMA Cellular
  Networks</title><categories>cs.IT cs.NI math.IT math.PR</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractional frequency reuse (FFR) is an interference management technique
well-suited to OFDMA-based cellular networks wherein the cells are partitioned
into spatial regions with different frequency reuse factors. To date, FFR
techniques have been typically been evaluated through system-level simulations
using a hexagonal grid for the base station locations. This paper instead
focuses on analytically evaluating the two main types of FFR deployments -
Strict FFR and Soft Frequency Reuse (SFR) - using a Poisson point process to
model the base station locations. The results are compared with the standard
grid model and an actual urban deployment. Under reasonable special cases for
modern cellular networks, our results reduce to simple closed-form expressions,
which provide insight into system design guidelines and the relative merits of
Strict FFR, SFR, universal reuse, and fixed frequency reuse. We observe that
FFR provides an increase in the sum-rate as well as the well-known benefit of
improved coverage for cell-edge users. Finally, a SINR-proportional resource
allocation strategy is proposed based on the analytical expressions, showing
that Strict FFR provides greater overall network throughput at low traffic
loads, while SFR better balances the requirements of interference reduction and
resource efficiency when the traffic load is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5141</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5141</id><created>2011-01-26</created><authors><author><keyname>Rodrigues</keyname><forenames>Francisco A.</forenames></author><author><keyname>de Arruda</keyname><forenames>Guilherme Ferraz</forenames></author><author><keyname>Costa</keyname><forenames>Luciano da Fontoura</forenames></author></authors><title>A Complex Networks Approach for Data Clustering</title><categories>physics.data-an cs.LG cs.SI physics.soc-ph</categories><comments>9 pages, 8 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many methods have been developed for data clustering, such as k-means,
expectation maximization and algorithms based on graph theory. In this latter
case, graphs are generally constructed by taking into account the Euclidian
distance as a similarity measure, and partitioned using spectral methods.
However, these methods are not accurate when the clusters are not well
separated. In addition, it is not possible to automatically determine the
number of clusters. These limitations can be overcome by taking into account
network community identification algorithms. In this work, we propose a
methodology for data clustering based on complex networks theory. We compare
different metrics for quantifying the similarity between objects and take into
account three community finding techniques. This approach is applied to two
real-world databases and to two sets of artificially generated data. By
comparing our method with traditional clustering approaches, we verify that the
proximity measures given by the Chebyshev and Manhattan distances are the most
suitable metrics to quantify the similarity between objects. In addition, the
community identification method based on the greedy optimization provides the
smallest misclassification rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5151</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5151</id><created>2011-01-26</created><authors><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author></authors><title>Simulation of Self-Assembly in the Abstract Tile Assembly Model with ISU
  TAS</title><categories>cs.MS cs.CE</categories><comments>This paper was in the Proceedings of the 6th Annual Conference of the
  Foundations of Nanoscience: Self-Assembled Architectures and Devices (2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since its introduction by Erik Winfree in 1998, the abstract Tile Assembly
Model (aTAM) has inspired a wealth of research. As an abstract model for tile
based self-assembly, it has proven to be remarkably powerful and expressive in
terms of the structures which can self-assemble within it. As research has
progressed in the aTAM, the self-assembling structures being studied have
become progressively more complex. This increasing complexity, along with a
need for standardization of definitions and tools among researchers, motivated
the development of the Iowa State University Tile Assembly Simulator (ISU TAS).
ISU TAS is a graphical simulator and tile set editor for designing and building
2-D and 3-D aTAM tile assembly systems and simulating their self-assembly. This
paper reviews the features and functionality of ISU TAS and describes how it
can be used to further research into the complexities of the aTAM. Software and
source code are available at http://www.cs.iastate.edu/~lnsa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5188</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5188</id><created>2011-01-26</created><authors><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author></authors><title>Strict Authentication Watermarking with JPEG Compression (SAW-JPEG) for
  Medical Images</title><categories>cs.CR</categories><comments>10 pages, 12 figures, journal</comments><journal-ref>European Journal of Scientific Research, Volume 42 Issue 2 May
  2010 pages 232-241</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a strict authentication watermarking for medical images.
In this scheme, we define region of interest (ROI) by taking the smallest
rectangle around an image. The watermark is generated from hashing the area of
interest. The embedding region is considered to be outside the region of
interest as to preserve the area from distortion as a result from watermarking.
The strict authentication watermarking is robust to some degree of JPEG
compression (SAW-JPEG). JPEG compression will be reviewed. To embed a watermark
in the spatial domain, we have to make sure that the embedded watermark will
survive JPEG quantization process. The watermarking scheme, including data
embedding, extracting and verifying procedure were presented. Experimental
results showed that such a scheme could embed and extract the watermark at a
high compression rate. The watermark is robust to a high compression rate up to
90.6%. The JPEG image quality threshold is 60 for the least significant bit
embedding. The image quality threshold is increased to 61 for 2nd and 3rd LSB
manipulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5200</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5200</id><created>2011-01-26</created><authors><author><keyname>van Bakel</keyname><forenames>Steffen</forenames></author><author><keyname>Berardi</keyname><forenames>Stefano</forenames></author><author><keyname>Berger</keyname><forenames>Ulrich</forenames></author></authors><title>Proceedings Third International Workshop on Classical Logic and
  Computation</title><categories>cs.LO</categories><proxy>EPTCS</proxy><acm-class>F.4.1; I.2.2</acm-class><journal-ref>EPTCS 47, 2011</journal-ref><doi>10.4204/EPTCS.47</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fact that classical mathematical proofs of simply existential statements
can be read as programs was established by Goedel and Kreisel half a century
ago. But the possibility of extracting useful computational content from
classical proofs was taken seriously only from the 1990s on when it was
discovered that proof interpretations based on Goedel's and Kreisel's ideas can
provide new nontrivial algorithms and numerical results, and the Curry-Howard
correspondence can be extended to classical logic via programming concepts such
as continuations and control operators.
  The workshop series &quot;Classical Logic and Computation&quot; aims to support a
fruitful exchange of ideas between the various lines of research on
computational aspects of classical logic. This volume contains the abstracts of
the invited lectures and the accepted contributed papers of the third CL&amp;C
workshop which was held jointly with the workshop &quot;Program Extraction and
Constructive Mathematics&quot; at the University of Brno in August 21-22, 2010, as a
satellite of CSL and MFCS. The workshops were held in honour of Helmut
Schwichtenberg who became &quot;professor emeritus&quot; in September 2010.
  The topics of the papers include the foundations, optimizations and
applications of proof interpretations such as Hilbert's epsilon substitution
method, Goedel's functional interpretation, learning based realizability and
negative translations as well as special calculi and theories capturing
computational and complexity-theoretic aspects of classical logic such as the
lambda-mu-calculus, applicative theories, sequent-calculi, resolution and
cut-elimination
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5207</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5207</id><created>2011-01-26</created><authors><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Puri</keyname><forenames>Rohit</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Hybrid Digital-Analog Codes for Source-Channel Broadcast of Gaussian
  Sources over Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>24 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of broadcasting a parallel Gaussian source over an additive white
Gaussian noise broadcast channel under the mean-squared error distortion
criterion is studied. A hybrid digital-analog coding strategy which combines
source coding with side information, channel coding with side information,
layered source coding, and superposition broadcast channel coding is presented.
When specialized to the open problem of broadcasting a white Gaussian source
over an additive white Gaussian noise broadcast channel with bandwidth mismatch
which has been the subject of several previous investigations, this coding
scheme strictly improves on the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5221</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5221</id><created>2011-01-27</created><updated>2012-02-16</updated><authors><author><keyname>Even</keyname><forenames>Guy</forenames></author><author><keyname>Medina</keyname><forenames>Moti</forenames></author><author><keyname>Schaffrath</keyname><forenames>Gregor</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>Competitive and Deterministic Embeddings of Virtual Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network virtualization is an important concept to overcome the ossification
of today's Internet as it facilitates innovation also in the network core and
as it promises a more efficient use of the given resources and infrastructure.
Virtual networks (VNets) provide an abstraction of the physical network:
multiple VNets may cohabit the same physical network, but can be based on
completely different protocol stacks (also beyond IP). One of the main
challenges in network virtualization is the efficient admission control and
embedding of VNets. The demand for virtual networks (e.g., for a video
conference) can be hard to predict, and once the request is accepted, the
specification / QoS guarantees must be ensured throughout the VNet's lifetime.
This requires an admission control algorithm which only selects high-benefit
VNets in times of scarce resources, and an embedding algorithm which realizes
the VNet in such a way that the likelihood that future requests can be embedded
as well is maximized.
  This article describes a generic algorithm for the online VNet embedding
problem which does not rely on any knowledge of the future VNet requests but
whose performance is competitive to an optimal offline algorithm that has
complete knowledge of the request sequence in advance: the so-called
competitive ratio is, loosely speaking, logarithmic in the sum of the
resources. Our algorithm is generic in the sense that it supports multiple
traffic models, multiple routing models, and even allows for nonuniform
benefits and durations of VNet requests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5227</identifier>
 <datestamp>2012-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5227</id><created>2011-01-27</created><updated>2012-04-05</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>NP has log-space verifiers with fixed-size public quantum registers</title><categories>cs.CC quant-ph</categories><comments>9 pages. A revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In classical Arthur-Merlin games, the class of languages whose membership
proofs can be verified by Arthur using logarithmic space (AM(log-space))
coincides with the class P \cite{Co89}. In this note, we show that if Arthur
has a fixed-size quantum register (the size of the register does not depend on
the length of the input) instead of another source of random bits, membership
in any language in NP can be verified with any desired error bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5257</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5257</id><created>2011-01-27</created><updated>2011-02-07</updated><authors><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author></authors><title>Cooperative Regenerating Codes for Distributed Storage Systems</title><categories>cs.IT cs.DC math.IT</categories><comments>5 pages, 7 figures, to appear in Proc. IEEE ICC, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When there are multiple node failures in a distributed storage system,
regenerating the failed storage nodes individually in a one-by-one manner is
suboptimal as far as repair-bandwidth minimization is concerned. If data
exchange among the newcomers is enabled, we can get a better tradeoff between
repair bandwidth and the storage per node. An explicit and optimal construction
of cooperative regenerating code is illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5260</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5260</id><created>2011-01-27</created><updated>2011-01-28</updated><authors><author><keyname>Dallmeier-Tiessen</keyname><forenames>Suenje</forenames></author><author><keyname>Darby</keyname><forenames>Robert</forenames></author><author><keyname>Goerner</keyname><forenames>Bettina</forenames></author><author><keyname>Hyppoelae</keyname><forenames>Jenni</forenames></author><author><keyname>Igo-Kemenes</keyname><forenames>Peter</forenames></author><author><keyname>Kahn</keyname><forenames>Deborah</forenames></author><author><keyname>Lambert</keyname><forenames>Simon</forenames></author><author><keyname>Lengenfelder</keyname><forenames>Anja</forenames></author><author><keyname>Leonard</keyname><forenames>Chris</forenames></author><author><keyname>Mele</keyname><forenames>Salvatore</forenames></author><author><keyname>Nowicka</keyname><forenames>Malgorzata</forenames></author><author><keyname>Polydoratou</keyname><forenames>Panayiota</forenames></author><author><keyname>Ross</keyname><forenames>David</forenames></author><author><keyname>Ruiz-Perez</keyname><forenames>Sergio</forenames></author><author><keyname>Schimmer</keyname><forenames>Ralf</forenames></author><author><keyname>Swaisland</keyname><forenames>Mark</forenames></author><author><keyname>van der Stelt</keyname><forenames>Wim</forenames></author></authors><title>Highlights from the SOAP project survey. What Scientists Think about
  Open Access Publishing</title><categories>cs.DL</categories><comments>Data manual available at http://bit.ly/gI8nct Compressed CSV data
  file available at http://bit.ly/gSmm71 Alternative data formats: CSV
  http://bit.ly/ejuvKO XLS http://bit.ly/e6gE7o XLSX http://bit.ly/gTjyvy</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The SOAP (Study of Open Access Publishing) project has run a large-scale
survey of the attitudes of researchers on, and the experiences with, open
access publishing. Around forty thousands answers were collected across
disciplines and around the world, showing an overwhelming support for the idea
of open access, while highlighting funding and (perceived) quality as the main
barriers to publishing in open access journals. This article serves as an
introduction to the survey and presents this and other highlights from a
preliminary analysis of the survey responses. To allow a maximal re-use of the
information collected by this survey, the data are hereby released under a CC0
waiver, so to allow libraries, publishers, funding agencies and academics to
further analyse risks and opportunities, drivers and barriers, in the
transition to open access publishing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5305</identifier>
 <datestamp>2014-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5305</id><created>2011-01-27</created><updated>2014-06-12</updated><authors><author><keyname>Dowden</keyname><forenames>Chris</forenames></author></authors><title>An axiomatic approach to diversity</title><categories>math.CO cs.DM</categories><comments>12 pages. This is a revised presentation of the material in the
  earlier version of the manuscript</comments><msc-class>05C90 (Primary), 92B05, 91B14 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The topic of diversity is an interesting subject, both as a purely
mathematical concept and also for its applications to important real-life
situations. Unfortunately, although the meaning of diversity seems intuitively
clear, no precise mathematical definition exists. In this paper, we adopt an
axiomatic approach to the problem, and attempt to produce a satisfactory
measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5308</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5308</id><created>2011-01-27</created><authors><author><keyname>Clementi</keyname><forenames>Andrea</forenames></author><author><keyname>Silvestri</keyname><forenames>Riccardo</forenames></author></authors><title>Parsimonious Flooding in Geometric Random-Walks</title><categories>cs.SI cs.DM</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the information spreading yielded by the \emph{(Parsimonious)
$1$-Flooding Protocol} in geometric Mobile Ad-Hoc Networks. We consider $n$
agents on a convex plane region of diameter $D$ performing independent random
walks with move radius $\rho$. At any time step, every active agent $v$ informs
every non-informed agent which is within distance $R$ from $v$ ($R&gt;0$ is the
transmission radius). An agent is only active at the time step immediately
after the one in which has been informed and, after that, she is removed. At
the initial time step, a source agent is informed and we look at the
\emph{completion time} of the protocol, i.e., the first time step (if any) in
which all agents are informed. This random process is equivalent to the
well-known \emph{Susceptible-Infective-Removed ($SIR$}) infection process in
Mathematical Epidemiology. No analytical results are available for this random
process over any explicit mobility model. The presence of removed agents makes
this process much more complex than the (standard) flooding. We prove optimal
bounds on the completion time depending on the parameters $n$, $D$, $R$, and
$\rho$. The obtained bounds hold with high probability. We remark that our
method of analysis provides a clear picture of the dynamic shape of the
information spreading (or infection wave) over the time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5313</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5313</id><created>2011-01-23</created><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>A Chronology of Torah Cryptography</title><categories>cs.OH</categories><comments>10 Pages, 1 Table, 7 Figures</comments><journal-ref>Proc. ANPA 31, 2011, Cambridge, UK</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regarding some papers and notes submitted to, or presented at, the second
congress of the International Torah Codes Society in Jerusalem, Israel, June
2000.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5317</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5317</id><created>2011-01-26</created><authors><author><keyname>Yilmaz</keyname><forenames>Ferkan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>A Novel Unified Expression for the Capacity and Bit Error Probability of
  Wireless Communication Systems over Generalized Fading Channels</title><categories>cs.IT cs.PF math.IT</categories><comments>In this paper (including 5 Tables and 6 Figures), we presented a
  unified performance expression combining the ABEP and AC of wireless
  communication systems over generalized fading channels. In addition, the
  hyper-Fox's H fading model is proposed as a unified fading distribution for a
  majority of the well-known generalized fading models</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of the average binary error probabilities (ABEP) and average
capacity (AC) of wireless communications systems over generalized fading
channels have been considered separately in the past. This paper introduces a
novel moment generating function (MGF)-based \emph{unified expression} for the
ABEP and AC of single and multiple link communication with maximal ratio
combining. In addition, this paper proposes the hyper-Fox's H fading model as a
unified fading distribution of a majority of the well-known generalized fading
models. As such, we offer a generic unified performance expression that can be
easily calculated and that is applicable to a wide variety of fading scenarios.
The mathematical formalism is illustrated with some selected numerical examples
that validate the correctness of our newly derived results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5320</identifier>
 <datestamp>2011-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5320</id><created>2011-01-27</created><updated>2011-04-20</updated><authors><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author><author><keyname>Duval</keyname><forenames>Laurent</forenames></author><author><keyname>Chaux</keyname><forenames>Caroline</forenames></author><author><keyname>Peyr&#xe9;</keyname><forenames>Gabriel</forenames></author></authors><title>A Panorama on Multiscale Geometric Representations, Intertwining
  Spatial, Directional and Frequency Selectivity</title><categories>cs.CV</categories><comments>65 pages, 33 figures, 303 references</comments><journal-ref>Signal Processing, Volume 91, Issue 12, December 2011, Pages
  2699-2730</journal-ref><doi>10.1016/j.sigpro.2011.04.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The richness of natural images makes the quest for optimal representations in
image processing and computer vision challenging. The latter observation has
not prevented the design of image representations, which trade off between
efficiency and complexity, while achieving accurate rendering of smooth regions
as well as reproducing faithful contours and textures. The most recent ones,
proposed in the past decade, share an hybrid heritage highlighting the
multiscale and oriented nature of edges and patterns in images. This paper
presents a panorama of the aforementioned literature on decompositions in
multiscale, multi-orientation bases or dictionaries. They typically exhibit
redundancy to improve sparsity in the transformed domain and sometimes its
invariance with respect to simple geometric deformations (translation,
rotation). Oriented multiscale dictionaries extend traditional wavelet
processing and may offer rotation invariance. Highly redundant dictionaries
require specific algorithms to simplify the search for an efficient (sparse)
representation. We also discuss the extension of multiscale geometric
decompositions to non-Euclidean domains such as the sphere or arbitrary meshed
surfaces. The etymology of panorama suggests an overview, based on a choice of
partially overlapping &quot;pictures&quot;. We hope that this paper will contribute to
the appreciation and apprehension of a stream of current research directions in
image understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5322</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5322</id><created>2011-01-27</created><authors><author><keyname>Fallani</keyname><forenames>F. De Vico</forenames></author><author><keyname>Nicosia</keyname><forenames>V.</forenames></author><author><keyname>Sinatra</keyname><forenames>R.</forenames></author><author><keyname>Astolfi</keyname><forenames>L.</forenames></author><author><keyname>Cincotti</keyname><forenames>F.</forenames></author><author><keyname>Mattia</keyname><forenames>D.</forenames></author><author><keyname>Wilke</keyname><forenames>C.</forenames></author><author><keyname>Doud</keyname><forenames>A.</forenames></author><author><keyname>Latora</keyname><forenames>V.</forenames></author><author><keyname>He</keyname><forenames>B.</forenames></author><author><keyname>Babiloni</keyname><forenames>F.</forenames></author></authors><title>Defecting or not defecting: how to &quot;read&quot; human behavior during
  cooperative games by EEG measurements</title><categories>physics.soc-ph cs.SI q-bio.NC</categories><journal-ref>PLoS ONE 5(12): e14187 (2010)</journal-ref><doi>10.1371/journal.pone.0014187</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the neural mechanisms responsible for human social interactions
is difficult, since the brain activities of two or more individuals have to be
examined simultaneously and correlated with the observed social patterns. We
introduce the concept of hyper-brain network, a connectivity pattern
representing at once the information flow among the cortical regions of a
single brain as well as the relations among the areas of two distinct brains.
Graph analysis of hyper-brain networks constructed from the EEG scanning of 26
couples of individuals playing the Iterated Prisoner's Dilemma reveals the
possibility to predict non-cooperative interactions during the decision-making
phase. The hyper-brain networks of two-defector couples have significantly less
inter-brain links and overall higher modularity - i.e. the tendency to form two
separate subgraphs - than couples playing cooperative or tit-for-tat
strategies. The decision to defect can be &quot;read&quot; in advance by evaluating the
changes of connectivity pattern in the hyper-brain network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5324</identifier>
 <datestamp>2013-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5324</id><created>2011-01-27</created><authors><author><keyname>Hwong</keyname><forenames>Yi-Ling</forenames></author><author><keyname>Kusters</keyname><forenames>Vincent J. J.</forenames></author><author><keyname>Willemse</keyname><forenames>Tim A. C.</forenames></author></authors><title>Analysing the Control Software of the Compact Muon Solenoid Experiment
  at the Large Hadron Collider</title><categories>cs.LO cs.SE</categories><comments>To appear in FSEN'11. Extended version with details of the ASF+SDF
  translation of SML into mCRL2</comments><doi>10.1016/j.scico.2012.11.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The control software of the CERN Compact Muon Solenoid experiment contains
over 30,000 finite state machines. These state machines are organised
hierarchically: commands are sent down the hierarchy and state changes are sent
upwards. The sheer size of the system makes it virtually impossible to fully
understand the details of its behaviour at the macro level. This is fuelled by
unclarities that already exist at the micro level. We have solved the latter
problem by formally describing the finite state machines in the mCRL2 process
algebra. The translation has been implemented using the ASF+SDF
meta-environment, and its correctness was assessed by means of simulations and
visualisations of individual finite state machines and through formal
verification of subsystems of the control software. Based on the formalised
semantics of the finite state machines, we have developed dedicated tooling for
checking properties that can be verified on finite state machines in isolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5334</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5334</id><created>2011-01-27</created><updated>2011-01-31</updated><authors><author><keyname>Gummadi</keyname><forenames>Ravi</forenames></author><author><keyname>Khulbe</keyname><forenames>Anupam</forenames></author><author><keyname>Kalavagattu</keyname><forenames>Aravind</forenames></author><author><keyname>Salvi</keyname><forenames>Sanil</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author></authors><title>SmartInt: Using Mined Attribute Dependencies to Integrate Fragmented Web
  Databases</title><categories>cs.DB cs.IR</categories><journal-ref>A shorter version presented as a poster at WWW 2011 (Hyderabad)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many web databases can be seen as providing partial and overlapping
information about entities in the world. To answer queries effectively, we need
to integrate the information about the individual entities that are fragmented
over multiple sources. At first blush this is just the inverse of traditional
database normalization problem - rather than go from a universal relation to
normalized tables, we want to reconstruct the universal relation given the
tables (sources). The standard way of reconstructing the entities will involve
joining the tables. Unfortunately, because of the autonomous and decentralized
way in which the sources are populated, they often do not have Primary Key -
Foreign Key relations. While tables may share attributes, naive joins over
these shared attributes can result in reconstruction of many spurious entities
thus seriously compromising precision. Our system, \smartint\ is aimed at
addressing the problem of data integration in such scenarios. Given a query,
our system uses the Approximate Functional Dependencies (AFDs) to piece
together a tree of relevant tables to answer it. The result tuples produced by
our system are able to strike a favorable balance between precision and recall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5335</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5335</id><created>2011-01-10</created><authors><author><keyname>Tourki</keyname><forenames>Kamel</forenames></author><author><keyname>Yang</keyname><forenames>Hong-Chuan</forenames></author><author><keyname>Alouni</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Accurate Performance Analysis of Opportunistic Decode-and-Forward
  Relaying</title><categories>cs.PF</categories><comments>15 pages, 4 figures, Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate an opportunistic relaying scheme where the
selected relay assists the source-destination (direct) communication. In our
study, we consider a regenerative opportunistic relaying scheme in which the
direct path can be considered unusable, and takes into account the effect of
the possible erroneously detected and transmitted data at the best relay. We
first derive statistics based on exact probability density function (PDF) of
each hop. Then, the PDFs are used to determine accurate closed form expressions
for end-to-end bit-error rate (BER) of binary phase-shift keying (BPSK)
modulation. Furthermore, we evaluate the asymptotical performance analysis and
the diversity order is deduced. Finally, we validate our analysis by showing
that performance simulation results coincide with our analytical results over
different network architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5336</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5336</id><created>2011-01-27</created><authors><author><keyname>Heden</keyname><forenames>Olof</forenames></author><author><keyname>Sissokho</keyname><forenames>Papa A.</forenames></author></authors><title>On the existence of a (2,3)-spread in V(7,2)</title><categories>math.CO cs.IT math.IT</categories><msc-class>51E14, 51E23, 51E10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $(s,t)$-spread in a finite vector space $V=V(n,q)$ is a collection
$\mathcal F$ of $t$-dimensional subspaces of $V$ with the property that every
$s$-dimensional subspace of $V$ is contained in exactly one member of $\mathcal
F$. It is remarkable that no $(s,t)$-spreads has been found yet, except in the
case $s=1$. In this note, the concept $\alpha$-point to a $(2,3)$-spread
$\mathcal F$ in {$V=V(7,2)$} is introduced. A classical result of Thomas,
applied to the vector space $V$, states that all points of $V$ cannot be
$\alpha$-points to a given $(2,3)$-spread $\mathcal F$ in $V$. {In this note,
we strengthened this result by proving that} every 6-dimensional subspace of
$V$ must contain at least one point that is not an $\alpha$-point to a given
$(2,3)$-spread of $V$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5341</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5341</id><created>2011-01-27</created><updated>2011-02-01</updated><authors><author><keyname>Espa&#xf1;a</keyname><forenames>Sergio</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Arturo</forenames></author><author><keyname>Pastor</keyname><forenames>&#xd3;scar</forenames></author><author><keyname>Ruiz</keyname><forenames>Marcela</forenames></author></authors><title>A practical guide to Message Structures: a modelling technique for
  information systems analysis and design</title><categories>cs.SE</categories><comments>30 pages, 10 figures. It includes the same content both in English
  and in Spanish</comments><report-no>ProS-TR-2011-02</report-no><msc-class>68N01</msc-class><acm-class>D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the increasing maturity of model-driven software development (MDD),
some research challenges remain open in the field of information systems (IS).
For instance, there is a need to improve modelling techniques so that they
cover several development stages in an integrated way, and they facilitate the
transition from analysis to design. This paper presents Message Structures, a
technique for the specification of communicative interactions between the IS
and organisational actors. This technique can be used both in the analysis
stage and in the design stage. During analysis, it allows abstracting from the
technology that will support the IS, and to complement business process
diagramming techniques with the specification of the communicational needs of
the organisation. During design, Message Structures serves two purposes: (i) it
allows to systematically derive a specification of the IS memory (e.g. a UML
class diagram), (ii) and it allows to reason the user interface design using
abstract patterns. This technique is part of Communication Analysis, a
communication-oriented requirements engineering method, but it can be adopted
in order to extend widely-used business process and functional requirements
modelling techniques (e.g. BPMN, Use Cases). Moreover, the paper presents two
tools that support Message Structures, one uses the Xtext technology, and the
other uses the Eclipse Modelling Framework. Industrial experience has shown us
that the technique can be adopted and applied in complex projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5345</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5345</id><created>2011-01-27</created><authors><author><keyname>Ron</keyname><forenames>Dana</forenames></author><author><keyname>Rubinfeld</keyname><forenames>Ronitt</forenames></author><author><keyname>Safra</keyname><forenames>Muli</forenames></author><author><keyname>Weinstein</keyname><forenames>Omri</forenames></author></authors><title>Approximating the Influence of a monotone Boolean function in
  O(\sqrt{n}) query complexity</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\em Total Influence} ({\em Average Sensitivity) of a discrete function
is one of its fundamental measures. We study the problem of approximating the
total influence of a monotone Boolean function \ifnum\plusminus=1 $f:
\{\pm1\}^n \longrightarrow \{\pm1\}$, \else $f: \bitset^n \to \bitset$, \fi
which we denote by $I[f]$. We present a randomized algorithm that approximates
the influence of such functions to within a multiplicative factor of $(1\pm
\eps)$ by performing $O(\frac{\sqrt{n}\log n}{I[f]} \poly(1/\eps)) $ queries. %
\mnote{D: say something about technique?} We also prove a lower bound of %
$\Omega(\frac{\sqrt{n/\log n}}{I[f]})$ $\Omega(\frac{\sqrt{n}}{\log n \cdot
I[f]})$ on the query complexity of any constant-factor approximation algorithm
for this problem (which holds for $I[f] = \Omega(1)$), % and $I[f] =
O(\sqrt{n}/\log n)$), hence showing that our algorithm is almost optimal in
terms of its dependence on $n$. For general functions we give a lower bound of
$\Omega(\frac{n}{I[f]})$, which matches the complexity of a simple sampling
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5355</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5355</id><created>2011-01-27</created><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Drucker</keyname><forenames>Andrew</forenames></author></authors><title>Advice Coins for Classical and Quantum Computation</title><categories>quant-ph cs.CC</categories><comments>23 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the power of classical and quantum algorithms equipped with
nonuniform advice, in the form of a coin whose bias encodes useful information.
This question takes on particular importance in the quantum case, due to a
surprising result that we prove: a quantum finite automaton with just two
states can be sensitive to arbitrarily small changes in a coin's bias. This
contrasts with classical probabilistic finite automata, whose sensitivity to
changes in a coin's bias is bounded by a classic 1970 result of Hellman and
Cover. Despite this finding, we are able to bound the power of advice coins for
space-bounded classical and quantum computation. We define the classes
BPPSPACE/coin and BQPSPACE/coin, of languages decidable by classical and
quantum polynomial-space machines with advice coins. Our main theorem is that
both classes coincide with PSPACE/poly. Proving this result turns out to
require substantial machinery. We use an algorithm due to Neff for finding
roots of polynomials in NC; a result from algebraic geometry that lower-bounds
the separation of a polynomial's roots; and a result on fixed-points of
superoperators due to Aaronson and Watrous, originally proved in the context of
quantum computing with closed timelike curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5364</identifier>
 <datestamp>2013-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5364</id><created>2011-01-27</created><authors><author><keyname>Masood</keyname><forenames>Farhat</forenames></author></authors><title>RISC and CISC</title><categories>cs.AR</categories><journal-ref>Computing Research Repository - CORR, vol. abs/1101.5, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comparison of RISC &amp; CISC in details, encompassing the addressing modes,
evolution, definitions and characteristics. Pre - RISC design is also
elaborated. Both the architectures are explained with the help of example.
Analysis is made based on performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5376</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5376</id><created>2011-01-27</created><authors><author><keyname>Thachuk</keyname><forenames>Chris</forenames></author></authors><title>Succincter Text Indexing with Wildcards</title><categories>cs.DS q-bio.QM</categories><comments>10 pages, 3 additional pages for supporting proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of indexing text with wildcard positions, motivated by
the challenge of aligning sequencing data to large genomes that contain
millions of single nucleotide polymorphisms (SNPs)---positions known to differ
between individuals. SNPs modeled as wildcards can lead to more informed and
biologically relevant alignments. We improve the space complexity of previous
approaches by giving a succinct index requiring $(2 + o(1))n \log \sigma + O(n)
+ O(d \log n) + O(k \log k)$ bits for a text of length $n$ over an alphabet of
size $\sigma$ containing $d$ groups of $k$ wildcards. A key to the space
reduction is a result we give showing how any compressed suffix array can be
supplemented with auxiliary data structures occupying $O(n) + O(d \log
\frac{n}{d})$ bits to also support efficient dictionary matching queries. The
query algorithm for our wildcard index is faster than previous approaches using
reasonable working space. More importantly our new algorithm greatly reduces
the query working space to $O(d m + m \log n)$ bits. We note that compared to
previous results this reduces the working space by two orders of magnitude when
aligning short read data to the Human genome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5379</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5379</id><created>2011-01-27</created><updated>2011-10-01</updated><authors><author><keyname>Viana</keyname><forenames>Matheus P.</forenames></author><author><keyname>Batista</keyname><forenames>Jo&#xe3;o L. B.</forenames></author><author><keyname>Costa</keyname><forenames>Luciano da F.</forenames></author></authors><title>How Many Nodes are Effectively Accessed in Complex Networks?</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>8 pages and 7 figures</comments><msc-class>05C82</msc-class><doi>10.1103/PhysRevE.85.036105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The measurement called accessibility has been proposed as a means to quantify
the efficiency of the communication between nodes in complex networks. This
article reports important results regarding the properties of the
accessibility, including its relationship with the average minimal time to
visit all nodes reachable after $h$ steps along a random walk starting from a
source, as well as the number of nodes that are visited after a finite period
of time. We characterize the relationship between accessibility and the average
number of walks required in order to visit all reachable nodes (the exploration
time), conjecture that the maximum accessibility implies the minimal
exploration time, and confirm the relationship between the accessibility values
and the number of nodes visited after a basic time unit. The latter
relationship is investigated with respect to three types of dynamics, namely:
traditional random walks, self-avoiding random walks, and preferential random
walks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5407</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5407</id><created>2011-01-27</created><authors><author><keyname>Bender</keyname><forenames>Michael A.</forenames></author><author><keyname>Fekete</keyname><forenames>S&#xe1;ndor P.</forenames></author><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Schweer</keyname><forenames>Nils</forenames></author></authors><title>Maintaining Arrays of Contiguous Objects</title><categories>cs.DS</categories><comments>12 pages, 4 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider methods for dynamically storing a set of different
objects (&quot;modules&quot;) in a physical array. Each module requires one free
contiguous subinterval in order to be placed. Items are inserted or removed,
resulting in a fragmented layout that makes it harder to insert further
modules. It is possible to relocate modules, one at a time, to another free
subinterval that is contiguous and does not overlap with the current location
of the module. These constraints clearly distinguish our problem from classical
memory allocation. We present a number of algorithmic results, including a
bound of Theta(n^2) on physical sorting if there is a sufficiently large free
space and sum up NP-hardness results for arbitrary initial layouts. For online
scenarios in which modules arrive one at a time, we present a method that
requires O(1) moves per insertion or deletion and amortized cost O(m_i log M)
per insertion or deletion, where m_i is the module's size, M is the size of the
largest module and costs for moves are linear in the size of a module.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5410</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5410</id><created>2011-01-27</created><updated>2015-04-04</updated><authors><author><keyname>Rodis</keyname><forenames>Panteleimon</forenames></author></authors><title>Connection errors in networks of linear features and the application of
  geometrical reduction in spatial data algorithms</title><categories>cs.DS cs.CG</categories><comments>14 pages, 4 spatial algorithms, 3 illustrations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a study on connection errors in networks of linear features and
methods of error detection. We model networks with special connection
specifications as networks with hierarchically connected features and define
errors considering the spatial relationships and the functionality of the
network elements. A general definition of the problem of the detection of
connection errors which takes into account the functionality of the network
elements is discussed. Then a series of spatial algorithms that solve different
aspects of the problem is presented. We also define and analyze the notion of
geometrical reduction as a method of achieving efficient performance. In the
last section the undecidability of algorithmic error correction is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5411</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5411</id><created>2011-01-27</created><authors><author><keyname>Villalba</keyname><forenames>Luis Javier Garc&#xed;a</forenames></author><author><keyname>Cortez</keyname><forenames>Jos&#xe9; Ren&#xe9; Fuentes</forenames></author><author><keyname>Orozco</keyname><forenames>Ana Lucila Sandoval</forenames></author><author><keyname>Blaum</keyname><forenames>Mario</forenames></author></authors><title>Efficient Algorithms for Searching Optimal Shortened Cyclic
  Single-Burst-Correcting Codes</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous work it was shown that the best measure for the efficiency of a
single burst-correcting code is obtained using the Gallager bound as opposed to
the Reiger bound. In this paper, an efficient algorithm that searches for the
best (shortened) cyclic burst-correcting codes is presented. Using this
algorithm, extensive tables that either tie existing constructions or improve
them are obtained for burst lengths up to b=10.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5428</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5428</id><created>2011-01-27</created><authors><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author><author><keyname>De Wilde</keyname><forenames>Philippe</forenames></author></authors><title>The Computing of Digital Ecosystems</title><categories>cs.DC cs.MA cs.NE</categories><comments>18 pages, 11 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A primary motivation for our research in digital ecosystems is the desire to
exploit the self-organising properties of biological ecosystems. Ecosystems are
thought to be robust, scalable architectures that can automatically solve
complex, dynamic problems. However, the computing technologies that contribute
to these properties have not been made explicit in digital ecosystems research.
Here, we discuss how different computing technologies can contribute to
providing the necessary self-organising features, including Multi-Agent Systems
(MASs), Service-Oriented Architectures (SOAs), and distributed evolutionary
computing (DEC). The potential for exploiting these properties in digital
ecosystems is considered, suggesting how several key features of biological
ecosystems can be exploited in Digital Ecosystems, and discussing how mimicking
these features may assist in developing robust, scalable self-organising
architectures. An example architecture, the Digital Ecosystem, is considered in
detail. The Digital Ecosystem is then measured experimentally through
simulations, considering the self-organised diversity of its evolving agent
populations relative to the user request behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5441</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5441</id><created>2011-01-27</created><authors><author><keyname>Aschieri</keyname><forenames>Federico</forenames></author></authors><title>Interactive Learning Based Realizability and 1-Backtracking Games</title><categories>cs.LO</categories><comments>In Proceedings CL&amp;C 2010, arXiv:1101.5200</comments><proxy>EPTCS</proxy><acm-class>F.4.1</acm-class><journal-ref>EPTCS 47, 2011, pp. 6-20</journal-ref><doi>10.4204/EPTCS.47.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that interactive learning based classical realizability (introduced
by Aschieri and Berardi for first order arithmetic) is sound with respect to
Coquand game semantics. In particular, any realizer of an
implication-and-negation-free arithmetical formula embodies a winning recursive
strategy for the 1-Backtracking version of Tarski games. We also give examples
of realizer and winning strategy extraction for some classical proofs. We also
sketch some ongoing work about how to extend our notion of realizability in
order to obtain completeness with respect to Coquand semantics, when it is
restricted to 1-Backtracking games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5442</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5442</id><created>2011-01-27</created><authors><author><keyname>Ferreira</keyname><forenames>Gilda</forenames></author><author><keyname>Oliva</keyname><forenames>Paulo</forenames></author></authors><title>On Various Negative Translations</title><categories>cs.LO</categories><comments>In Proceedings CL&amp;C 2010, arXiv:1101.5200</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 47, 2011, pp. 21-33</journal-ref><doi>10.4204/EPTCS.47.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several proof translations of classical mathematics into intuitionistic
mathematics have been proposed in the literature over the past century. These
are normally referred to as negative translations or double-negation
translations. Among those, the most commonly cited are translations due to
Kolmogorov, Godel, Gentzen, Kuroda and Krivine (in chronological order). In
this paper we propose a framework for explaining how these different
translations are related to each other. More precisely, we define a notion of a
(modular) simplification starting from Kolmogorov translation, which leads to a
partial order between different negative translations. In this derived
ordering, Kuroda and Krivine are minimal elements. Two new minimal translations
are introduced, with Godel and Gentzen translations sitting in between
Kolmogorov and one of these new translations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5443</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5443</id><created>2011-01-27</created><authors><author><keyname>Houtmann</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>INRIA Saclay Ile de France</affiliation></author></authors><title>Superdeduction in Lambda-Bar-Mu-Mu-Tilde</title><categories>cs.LO</categories><comments>In Proceedings CL&amp;C 2010, arXiv:1101.5200</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 47, 2011, pp. 34-43</journal-ref><doi>10.4204/EPTCS.47.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superdeduction is a method specially designed to ease the use of first-order
theories in predicate logic. The theory is used to enrich the deduction system
with new deduction rules in a systematic, correct and complete way.
  A proof-term language and a cut-elimination reduction already exist for
superdeduction, both based on Christian Urban's work on classical sequent
calculus. However the computational content of Christian Urban's calculus is
not directly related to the (lambda-calculus based) Curry-Howard
correspondence. In contrast the Lambda bar mu mu tilde calculus is a
lambda-calculus for classical sequent calculus.
  This short paper is a first step towards a further exploration of the
computational content of superdeduction proofs, for we extend the Lambda bar mu
mu tilde calculus in order to obtain a proofterm langage together with a
cut-elimination reduction for superdeduction. We also prove strong
normalisation for this extension of the Lambda bar mu mu tilde calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5444</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5444</id><created>2011-01-27</created><authors><author><keyname>Kahle</keyname><forenames>Reinhard</forenames><affiliation>CENTRIA and DM, FCT, Universidade Nova de Lisboa</affiliation></author><author><keyname>Oitavem</keyname><forenames>Isabel</forenames><affiliation>CMAF, Universidade de Lisboa and DM, FCT, Universidade Nova de Lisboa</affiliation></author></authors><title>An applicative theory for FPH</title><categories>cs.LO cs.CC</categories><comments>In Proceedings CL&amp;C 2010, arXiv:1101.5200</comments><proxy>EPTCS</proxy><acm-class>F.4.1; F.1.3</acm-class><journal-ref>EPTCS 47, 2011, pp. 44-56</journal-ref><doi>10.4204/EPTCS.47.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce an applicative theory which characterizes the
polynomial hierarchy of time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5445</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5445</id><created>2011-01-27</created><authors><author><keyname>Pinto</keyname><forenames>Lu&#xed;s</forenames></author><author><keyname>Uustalu</keyname><forenames>Tarmo</forenames></author></authors><title>Relating Sequent Calculi for Bi-intuitionistic Propositional Logic</title><categories>cs.LO</categories><comments>In Proceedings CL&amp;C 2010, arXiv:1101.5200</comments><proxy>EPTCS</proxy><acm-class>F.4.1; I.2.3</acm-class><journal-ref>EPTCS 47, 2011, pp. 57-72</journal-ref><doi>10.4204/EPTCS.47.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bi-intuitionistic logic is the conservative extension of intuitionistic logic
with a connective dual to implication. It is sometimes presented as a symmetric
constructive subsystem of classical logic.
  In this paper, we compare three sequent calculi for bi-intuitionistic
propositional logic: (1) a basic standard-style sequent calculus that restricts
the premises of implication-right and exclusion-left inferences to be
single-conclusion resp. single-assumption and is incomplete without the cut
rule, (2) the calculus with nested sequents by Gore et al., where a complete
class of cuts is encapsulated into special &quot;unnest&quot; rules and (3) a cut-free
labelled sequent calculus derived from the Kripke semantics of the logic. We
show that these calculi can be translated into each other and discuss the
ineliminable cuts of the standard-style sequent calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5446</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5446</id><created>2011-01-27</created><authors><author><keyname>Trifonov</keyname><forenames>Trifon</forenames></author></authors><title>Dialectica Interpretation with Marked Counterexamples</title><categories>cs.LO</categories><comments>In Proceedings CL&amp;C 2010, arXiv:1101.5200</comments><proxy>EPTCS</proxy><acm-class>F.3.2; F.3.3; F.4.1</acm-class><journal-ref>EPTCS 47, 2011, pp. 73-84</journal-ref><doi>10.4204/EPTCS.47.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goedel's functional &quot;Dialectica&quot; interpretation can be used to extract
functional programs from non-constructive proofs in arithmetic by employing two
sorts of higher-order witnessing terms: positive realisers and negative
counterexamples. In the original interpretation decidability of atoms is
required to compute the correct counterexample from a set of candidates. When
combined with recursion, this choice needs to be made for every step in the
extracted program, however, in some special cases the decision on negative
witnesses can be calculated only once. We present a variant of the
interpretation in which the time complexity of extracted programs can be
improved by marking the chosen witness and thus avoiding recomputation. The
achieved effect is similar to using an abortive control operator to interpret
computational content of non-constructive principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5449</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5449</id><created>2011-01-27</created><authors><author><keyname>Peng</keyname><forenames>Kun</forenames></author></authors><title>Failure of A Mix Network</title><categories>cs.CR</categories><msc-class>68</msc-class><acm-class>F.2</acm-class><journal-ref>International Journal of Network Security and Its Applications
  (IJNSA), Vol.3, No.1, January 2011</journal-ref><doi>10.5121/ijnsa.2011.3106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mix network by Wikstrom fails in correctness, provable privacy and
soundness. Its claimed advantages in security and efficiency are compromised.
The analysis in this paper illustrates that although the first two failures may
be fixed by modifying the shuffling protocol, the last one is too serious to
fix at a tolerable cost. Especially, an attack is proposed to show how easily
soundness of the shuffling scheme can be compromised. Moreover, the most
surprising discovery in this paper is that it is formally illustrated that in
practice it is impossible to fix soundness of the shuffling scheme by Wikstrom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5455</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5455</id><created>2011-01-28</created><updated>2012-01-31</updated><authors><author><keyname>Lutz</keyname><forenames>Jack</forenames></author></authors><title>Resource Bounded Measure</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general theory of resource-bounded measurability and measure is developed.
Starting from any feasible probability measure $\nu$ on the Cantor space $\C$
and any suitable complexity class $C \subseteq \C$, the theory identifies the
subsets of $\C$ that are $\nu$-measurable in $C$ and assigns measures to these
sets, thereby endowing $C$ with internal measure-theoretic structure. Classes
to which the theory applies include various exponential time and space
complexity classes, the class of all decidable languages, and the Cantor space
itself, on which the resource-bounded theory is shown to agree with the
classical theory.
  The sets that are $\nu$-measurable in $C$ are shown to form an algebra
relative to which $\nu$-measure is well-behaved. This algebra is also shown to
be complete and closed under sufficiently uniform infinitary unions and
intersections, and $\nu$-measure in $C$ is shown to have the appropriate
additivity and monotone convergence properties with respect to such infinitary
operations.
  A generalization of the classical Kolmogorov zero-one law is proven, showing
that when $\nu$ is any feasible coin-toss probability measure on $\C$, every
set that is $\nu$-measurable in $C$ and (like most complexity classes)
invariant under finite alterations must have $\nu$-measure 0 or $\nu$-measure 1
in $C$.
  The theory is presented here is based on resource-bounded martingale
splitting operators, which are type-2 functionals, each of which maps $\N
\times {\cal D}_\nu$ into ${\cal D}_\nu \times {\cal D}_\nu$, where ${\cal
D}_\nu$ is the set of all $\nu$-martingales. This type-2 aspect of the theory
appears to be essential for general $\nu$-measure in complexity classes $C$,
but the sets of $\nu$-measure 0 or 1 in C are shown to be characterized by the
success conditions for martingales (type-1 functions) that have been used in
resource-bounded measure to date.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5460</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5460</id><created>2011-01-28</created><authors><author><keyname>Ghadiri</keyname><forenames>Nasser</forenames></author><author><keyname>Baraani-Dastjerdi</keyname><forenames>Ahmad</forenames></author><author><keyname>Ghasem-Aghaee</keyname><forenames>Nasser</forenames></author><author><keyname>Nematbakhsh</keyname><forenames>Mohammad A.</forenames></author></authors><title>A Human-Centric Approach to Group-Based Context-Awareness</title><categories>cs.AI cs.HC</categories><journal-ref>International Journal of Network Security and its Applications 3
  (2011), 47-66</journal-ref><doi>10.5121/ijnsa.2011.3104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emerging need for qualitative approaches in context-aware information
processing calls for proper modeling of context information and efficient
handling of its inherent uncertainty resulted from human interpretation and
usage. Many of the current approaches to context-awareness either lack a solid
theoretical basis for modeling or ignore important requirements such as
modularity, high-order uncertainty management and group-based
context-awareness. Therefore, their real-world application and extendability
remains limited. In this paper, we present f-Context as a service-based
context-awareness framework, based on language-action perspective (LAP) theory
for modeling. Then we identify some of the complex, informational parts of
context which contain high-order uncertainties due to differences between
members of the group in defining them. An agent-based perceptual computer
architecture is proposed for implementing f-Context that uses computing with
words (CWW) for handling uncertainty. The feasibility of f-Context is analyzed
using a realistic scenario involving a group of mobile users. We believe that
the proposed approach can open the door to future research on context-awareness
by offering a theoretical foundation based on human communication, and a
service-based layered architecture which exploits CWW for context-aware,
group-based and platform-independent access to information systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5463</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5463</id><created>2011-01-28</created><updated>2011-03-27</updated><authors><author><keyname>Kurant</keyname><forenames>M.</forenames></author><author><keyname>Gjoka</keyname><forenames>M.</forenames></author><author><keyname>Butts</keyname><forenames>C. T.</forenames></author><author><keyname>Markopoulou</keyname><forenames>A.</forenames></author></authors><title>Walking on a Graph with a Magnifying Glass: Stratified Sampling via
  Weighted Random Walks</title><categories>cs.SI cs.NI physics.soc-ph stat.ME</categories><comments>To appear in SIGMETRICS 2011</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Our objective is to sample the node set of a large unknown graph via
crawling, to accurately estimate a given metric of interest. We design a random
walk on an appropriately defined weighted graph that achieves high efficiency
by preferentially crawling those nodes and edges that convey greater
information regarding the target metric. Our approach begins by employing the
theory of stratification to find optimal node weights, for a given estimation
problem, under an independence sampler. While optimal under independence
sampling, these weights may be impractical under graph crawling due to
constraints arising from the structure of the graph. Therefore, the edge
weights for our random walk should be chosen so as to lead to an equilibrium
distribution that strikes a balance between approximating the optimal weights
under an independence sampler and achieving fast convergence. We propose a
heuristic approach (stratified weighted random walk, or S-WRW) that achieves
this goal, while using only limited information about the graph structure and
the node properties. We evaluate our technique in simulation, and
experimentally, by collecting a sample of Facebook college users. We show that
S-WRW requires 13-15 times fewer samples than the simple re-weighted random
walk (RW) to achieve the same estimation accuracy for a range of metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5490</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5490</id><created>2011-01-28</created><authors><author><keyname>Cuypers</keyname><forenames>Tom</forenames></author><author><keyname>Oh</keyname><forenames>Se Baek</forenames></author><author><keyname>Haber</keyname><forenames>Tom</forenames></author><author><keyname>Bekaert</keyname><forenames>Philippe</forenames></author><author><keyname>Raskar</keyname><forenames>Ramesh</forenames></author></authors><title>Ray-Based Reflectance Model for Diffraction</title><categories>cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel method of simulating wave effects in graphics using
ray--based renderers with a new function: the Wave BSDF (Bidirectional
Scattering Distribution Function). Reflections from neighboring surface patches
represented by local BSDFs are mutually independent. However, in many surfaces
with wavelength-scale microstructures, interference and diffraction requires a
joint analysis of reflected wavefronts from neighboring patches. We demonstrate
a simple method to compute the BSDF for the entire microstructure, which can be
used independently for each patch. This allows us to use traditional ray--based
rendering pipelines to synthesize wave effects of light and sound. We exploit
the Wigner Distribution Function (WDF) to create transmissive, reflective, and
emissive BSDFs for various diffraction phenomena in a physically accurate way.
In contrast to previous methods for computing interference, we circumvent the
need to explicitly keep track of the phase of the wave by using BSDFs that
include positive as well as negative coefficients. We describe and compare the
theory in relation to well understood concepts in rendering and demonstrate a
straightforward implementation. In conjunction with standard raytracers, such
as PBRT, we demonstrate wave effects for a range of scenarios such as
multi--bounce diffraction materials, holograms and reflection of high frequency
surfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5494</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5494</id><created>2011-01-28</created><authors><author><keyname>Gridach</keyname><forenames>Mourad</forenames></author><author><keyname>Chenfour</keyname><forenames>Noureddine</forenames></author></authors><title>Developing a New Approach for Arabic Morphological Analysis and
  Generation</title><categories>cs.CL</categories><comments>18 pages, 15 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Arabic morphological analysis is one of the essential stages in Arabic
Natural Language Processing. In this paper we present an approach for Arabic
morphological analysis. This approach is based on Arabic morphological
automaton (AMAUT). The proposed technique uses a morphological database
realized using XMODEL language. Arabic morphology represents a special type of
morphological systems because it is based on the concept of scheme to represent
Arabic words. We use this concept to develop the Arabic morphological automata.
The proposed approach has development standardization aspect. It can be
exploited by NLP applications such as syntactic and semantic analysis,
information retrieval, machine translation and orthographical correction. The
proposed approach is compared with Xerox Arabic Analyzer and Smrz Arabic
Analyzer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5506</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5506</id><created>2011-01-28</created><authors><author><keyname>Brisaboa</keyname><forenames>Nieves R.</forenames></author><author><keyname>C&#xe1;novas</keyname><forenames>Rodrigo</forenames></author><author><keyname>Mart&#xed;nez-Prieto</keyname><forenames>Miguel A.</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author></authors><title>Compressed String Dictionaries</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of storing a set of strings --- a string dictionary --- in
compact form appears naturally in many cases. While classically it has
represented a small part of the whole data to be processed (e.g., for Natural
Language processing or for indexing text collections), more recent applications
in Web engines, Web mining, RDF graphs, Internet routing, Bioinformatics, and
many others, make use of very large string dictionaries, whose size is a
significant fraction of the whole data. Thus novel approaches to compress them
efficiently are necessary. In this paper we experimentally compare time and
space performance of some existing alternatives, as well as new ones we
propose. We show that space reductions of up to 20% of the original size of the
strings is possible while supporting fast dictionary searches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5509</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5509</id><created>2011-01-28</created><authors><author><keyname>Ricciato</keyname><forenames>Fabio</forenames></author><author><keyname>Burkhart</keyname><forenames>Martin</forenames></author></authors><title>Reduce to the Max: A Simple Approach for Massive-Scale
  Privacy-Preserving Collaborative Network Measurements (Extended Version)</title><categories>cs.NI</categories><comments>This is an extended version of the paper presented at the Third
  International Workshop on Traffic Monitoring and Analysis (TMA'11), Vienna,
  27 April 2011</comments><journal-ref>Third International Workshop on Traffic Monitoring and Analysis
  (TMA), 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy-preserving techniques for distributed computation have been proposed
recently as a promising framework in collaborative inter-domain network
monitoring. Several different approaches exist to solve such class of problems,
e.g., Homomorphic Encryption (HE) and Secure Multiparty Computation (SMC) based
on Shamir's Secret Sharing algorithm (SSS). Such techniques are complete from a
computation-theoretic perspective: given a set of private inputs, it is
possible to perform arbitrary computation tasks without revealing any of the
intermediate results. In fact, HE and SSS can operate also on secret inputs
and/or provide secret outputs. However, they are computationally expensive and
do not scale well in the number of players and/or in the rate of computation
tasks. In this paper we advocate the use of &quot;elementary&quot; (as opposite to
&quot;complete&quot;) Secure Multiparty Computation (E-SMC) procedures for traffic
monitoring. E-SMC supports only simple computations with private input and
public output, i.e., it can not handle secret input nor secret (intermediate)
output. Such a simplification brings a dramatic reduction in complexity and
enables massive-scale implementation with acceptable delay and overhead.
Notwithstanding its simplicity, we claim that an E-SMC scheme is sufficient to
perform a great variety of computation tasks of practical relevance to
collaborative network monitoring, including, e.g., anonymous publishing and set
operations. This is achieved by combining a E-SMC scheme with data structures
like Bloom Filters and bitmap strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5518</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5518</id><created>2011-01-28</created><updated>2013-06-13</updated><authors><author><keyname>Meeks</keyname><forenames>Kitty</forenames></author><author><keyname>Scott</keyname><forenames>Alexander</forenames></author></authors><title>The complexity of Free-Flood-It on 2xn boards</title><categories>cs.DS</categories><doi>10.1016/j.tcs.2013.06.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the complexity of problems related to the combinatorial game
Free-Flood-It, in which players aim to make a coloured graph monochromatic with
the minimum possible number of flooding operations. Our main result is that
computing the length of an optimal sequence is fixed parameter tractable (with
the number of colours present as a parameter) when restricted to rectangular
2xn boards. We also show that, when the number of colours is unbounded, the
problem remains NP-hard on such boards. This resolves a question of Clifford,
Jalsenius, Montanaro and Sach (2010).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5546</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5546</id><created>2011-01-28</created><authors><author><keyname>Lau</keyname><forenames>August</forenames></author><author><keyname>Yin</keyname><forenames>Chuan</forenames></author></authors><title>Solvability by semigroup : Application to seismic imaging with complex
  decomposition of wave equations and migration operators with idempotents</title><categories>physics.geo-ph cs.NA math.NA</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical approach of solvability using group theory is well known and
one original motivation is to solve polynomials by radicals. Radicals are
square, cube, square root, cube root etc of the original coefficients for the
polynomial. A polynomial is solvable by radicals if the permutation group is
solvable. This is exact solvability via group theory. With modern computers, we
might need to relax our definition of exact solvability and move towards
practical solvability. We will address seismic imaging as an example of
practical solvability by semigroup theory. The difference between semigroup and
group is that the semigroup operators do not have to be invertible as in group
operators. Using the metaphor of complex decomposition, we will decompose an
operator into simple part and complex part. The simple part of the operator is
solvable by numerical methods. The complex part of the operator is
interpretable but not numerically solvable. It is sometimes called the
evanescent energy in geophysics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5569</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5569</id><created>2011-01-28</created><authors><author><keyname>Puczynski</keyname><forenames>Piotr J.</forenames></author></authors><title>T2Script Programming Language</title><categories>cs.PL</categories><comments>27 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Event-driven programming is used in many fields of modern Computer Science.
In event-driven programming languages user interacts with a program by
triggering the events. We propose a new approach that we denote command-event
driven programming in which the user interacts with a program by means of
events and commands. We describe a new programming language, T2Script, which is
based on command-event driven paradigm. T2Script has been already implemented
and used in one of industrial products. We describe the rationale, basic
concepts and advanced programming techniques of new T2Script language. We
evaluate the new language and show what advantages and limitations it has.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5578</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5578</id><created>2011-01-28</created><updated>2011-03-08</updated><authors><author><keyname>Perito</keyname><forenames>Daniele</forenames></author><author><keyname>Castelluccia</keyname><forenames>Claude</forenames></author><author><keyname>Kaafar</keyname><forenames>Mohamed Ali</forenames></author><author><keyname>Manils</keyname><forenames>Pere</forenames></author></authors><title>How Unique and Traceable are Usernames?</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose you find the same username on different online services, what is the
probability that these usernames refer to the same physical person? This work
addresses what appears to be a fairly simple question, which has many
implications for anonymity and privacy on the Internet. One possible way of
estimating this probability would be to look at the public information
associated to the two accounts and try to match them. However, for most
services, these information are chosen by the users themselves and are often
very heterogeneous, possibly false and difficult to collect. Furthermore,
several websites do not disclose any additional public information about users
apart from their usernames (e.g., discus- sion forums or Blog comments),
nonetheless, they might contain sensitive information about users. This paper
explores the possibility of linking users profiles only by looking at their
usernames. The intuition is that the probability that two usernames refer to
the same physical person strongly depends on the &quot;entropy&quot; of the username
string itself. Our experiments, based on crawls of real web services, show that
a significant portion of the users' profiles can be linked using their
usernames. To the best of our knowledge, this is the first time that usernames
are considered as a source of information when profiling users on the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5586</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5586</id><created>2011-01-28</created><authors><author><keyname>Aggarwal</keyname><forenames>Nishita</forenames></author><author><keyname>Garg</keyname><forenames>Naveen</forenames></author><author><keyname>Gupta</keyname><forenames>Swati</forenames></author></authors><title>A 4/3-approximation for TSP on cubic 3-edge-connected graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a polynomial time 4/3 approximation algorithm for TSP on metrics
arising from the metric completion of cubic 3-edge connected graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5591</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5591</id><created>2011-01-28</created><updated>2011-05-16</updated><authors><author><keyname>Dodds</keyname><forenames>Peter Sheridan</forenames></author><author><keyname>Harris</keyname><forenames>Kameron Decker</forenames></author><author><keyname>Payne</keyname><forenames>Joshua L.</forenames></author></authors><title>Direct, physically-motivated derivation of the contagion condition for
  spreading processes on generalized random networks</title><categories>cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>4 pages, 1 figure, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a broad range single-seed contagion processes acting on generalized
random networks, we derive a unifying analytic expression for the possibility
of global spreading events in a straightforward, physically intuitive fashion.
Our reasoning lays bare a direct mechanical understanding of an archetypal
spreading phenomena that is not evident in circuitous extant mathematical
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5598</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5598</id><created>2011-01-28</created><updated>2011-05-11</updated><authors><author><keyname>Hedtke</keyname><forenames>Ivo</forenames></author></authors><title>A Note on the Group-theoretic Approach to Fast Matrix Multiplication</title><categories>math.GR cs.SC</categories><comments>5 pages</comments><msc-class>20D60, 68Q17, 68R05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2003 COHN and UMANS introduced a group-theoretic approach to fast matrix
multiplication. This involves finding large subsets S, T and U of a group G
satisfying the Triple Product Property (TPP) as a means to bound the exponent
$\omega$ of the matrix multiplication. We show that S, T and U may be be
assumed to contain the identity and be otherwise disjoint. We also give a much
shorter proof of the upper bound |S|+|T|+|U| &lt;= |G|+2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5613</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5613</id><created>2011-01-28</created><authors><author><keyname>Bisong</keyname><forenames>Anthony</forenames><affiliation>Shawon</affiliation></author><author><keyname>Syed</keyname><affiliation>Shawon</affiliation></author><author><keyname>Rahman</keyname><forenames>M.</forenames></author></authors><title>An Overview of the Security Concerns in Enterprise Cloud Computing</title><categories>cs.CR cs.CY cs.NI cs.SE</categories><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.1, January 2011</journal-ref><doi>10.5121/ijnsa.2011.3103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deploying cloud computing in an enterprise infrastructure bring significant
security concerns. Successful implementation of cloud computing in an
enterprise requires proper planning and understanding of emerging risks,
threats, vulnerabilities, and possible countermeasures. We believe enterprise
should analyze the company/organization security risks, threats, and available
countermeasures before adopting this technology. In this paper, we have
discussed security risks and concerns in cloud computing and enlightened steps
that an enterprise can take to reduce security risks and protect their
resources. We have also explained cloud computing strengths/benefits,
weaknesses, and applicable areas in information risk management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5617</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5617</id><created>2011-01-28</created><authors><author><keyname>Candogan</keyname><forenames>Ozan</forenames></author><author><keyname>Bimpikis</keyname><forenames>Kostas</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author></authors><title>Optimal Pricing in Networks with Externalities</title><categories>cs.GT cs.NI</categories><comments>29 pages</comments><report-no>LIDS pub# 2854</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the optimal pricing strategies of a monopolist selling a divisible
good (service) to consumers that are embedded in a social network. A key
feature of our model is that consumers experience a (positive) local network
effect. In particular, each consumer's usage level depends directly on the
usage of her neighbors in the social network structure. Thus, the monopolist's
optimal pricing strategy may involve offering discounts to certain agents, who
have a central position in the underlying network.
  First, we consider a setting where the monopolist can offer individualized
prices and derive an explicit characterization of the optimal price for each
consumer as a function of her network position. In particular, we show that it
is optimal for the monopolist to charge each agent a price that is proportional
to her Bonacich centrality in the social network. In the second part of the
paper, we discuss the optimal strategy of a monopolist that can only choose a
single uniform price for the good and derive an algorithm polynomial in the
number of agents to compute such a price. Thirdly, we assume that the
monopolist can offer the good in two prices, full and discounted, and study the
problem of determining which set of consumers should be given the discount. We
show that the problem is NP-hard, however we provide an explicit
characterization of the set of agents that should be offered the discounted
price. Next, we describe an approximation algorithm for finding the optimal set
of agents. We show that if the profit is nonnegative under any feasible price
allocation, the algorithm guarantees at least 88% of the optimal profit.
Finally, we highlight the value of network information by comparing the profits
of a monopolist that does not take into account the network effects when
choosing her pricing policy to those of a monopolist that uses this information
optimally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5632</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5632</id><created>2011-01-28</created><authors><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Dolan</keyname><forenames>John M.</forenames></author><author><keyname>Khosla</keyname><forenames>Pradeep</forenames></author></authors><title>Active Markov Information-Theoretic Path Planning for Robotic
  Environmental Sensing</title><categories>cs.LG cs.AI cs.MA cs.RO</categories><comments>10th International Conference on Autonomous Agents and Multiagent
  Systems (AAMAS 2011), Extended version with proofs, 11 pages</comments><acm-class>G.3; I.2.8; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research in multi-robot exploration and mapping has focused on
sampling environmental fields, which are typically modeled using the Gaussian
process (GP). Existing information-theoretic exploration strategies for
learning GP-based environmental field maps adopt the non-Markovian problem
structure and consequently scale poorly with the length of history of
observations. Hence, it becomes computationally impractical to use these
strategies for in situ, real-time active sampling. To ease this computational
burden, this paper presents a Markov-based approach to efficient
information-theoretic path planning for active sampling of GP-based fields. We
analyze the time complexity of solving the Markov-based path planning problem,
and demonstrate analytically that it scales better than that of deriving the
non-Markovian strategies with increasing length of planning horizon. For a
class of exploration tasks called the transect sampling task, we provide
theoretical guarantees on the active sampling performance of our Markov-based
policy, from which ideal environmental field conditions and sampling task
settings can be established to limit its performance degradation due to
violation of the Markov assumption. Empirical evaluation on real-world
temperature and plankton density field data shows that our Markov-based policy
can generally achieve active sampling performance comparable to that of the
widely-used non-Markovian greedy policies under less favorable realistic field
conditions and task settings while enjoying significant computational gain over
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5668</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5668</id><created>2011-01-29</created><authors><author><keyname>Grace</keyname><forenames>L. K. Joshila</forenames></author><author><keyname>Maheswari</keyname><forenames>V.</forenames></author><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author></authors><title>Analysis of Web Logs and Web User in Web Mining</title><categories>cs.DB</categories><comments>12 pages,6 figures,CCSIT 2011</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.1, January 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Log files contain information about User Name, IP Address, Time Stamp, Access
Request, number of Bytes Transferred, Result Status, URL that Referred and User
Agent. The log files are maintained by the web servers. By analysing these log
files gives a neat idea about the user. This paper gives a detailed discussion
about these log files, their formats, their creation, access procedures, their
uses, various algorithms used and the additional parameters that can be used in
the log files which in turn gives way to an effective mining. It also provides
the idea of creating an extended log file and learning the user behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5672</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5672</id><created>2011-01-29</created><authors><author><keyname>Geng</keyname><forenames>Quan</forenames></author><author><keyname>Wang</keyname><forenames>Huan</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author></authors><title>On the Local Correctness of L^1 Minimization for Dictionary Learning</title><categories>cs.IT cs.LG math.IT</categories><comments>37 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea that many important classes of signals can be well-represented by
linear combinations of a small set of atoms selected from a given dictionary
has had dramatic impact on the theory and practice of signal processing. For
practical problems in which an appropriate sparsifying dictionary is not known
ahead of time, a very popular and successful heuristic is to search for a
dictionary that minimizes an appropriate sparsity surrogate over a given set of
sample data. While this idea is appealing, the behavior of these algorithms is
largely a mystery; although there is a body of empirical evidence suggesting
they do learn very effective representations, there is little theory to
guarantee when they will behave correctly, or when the learned dictionary can
be expected to generalize. In this paper, we take a step towards such a theory.
We show that under mild hypotheses, the dictionary learning problem is locally
well-posed: the desired solution is indeed a local minimum of the $\ell^1$
norm. Namely, if $\mb A \in \Re^{m \times n}$ is an incoherent (and possibly
overcomplete) dictionary, and the coefficients $\mb X \in \Re^{n \times p}$
follow a random sparse model, then with high probability $(\mb A,\mb X)$ is a
local minimum of the $\ell^1$ norm over the manifold of factorizations $(\mb
A',\mb X')$ satisfying $\mb A' \mb X' = \mb Y$, provided the number of samples
$p = \Omega(n^3 k)$. For overcomplete $\mb A$, this is the first result showing
that the dictionary learning problem is locally solvable. Our analysis draws on
tools developed for the problem of completing a low-rank matrix from a small
subset of its entries, which allow us to overcome a number of technical
obstacles; in particular, the absence of the restricted isometry property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5675</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5675</id><created>2011-01-29</created><updated>2011-02-01</updated><authors><author><keyname>Khan</keyname><forenames>Imdadullah</forenames></author></authors><title>Perfect Matchings in 4-uniform hypergraphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A perfect matching in a 4-uniform hypergraph is a subset of
$\lfloor\frac{n}{4}\rfloor$ disjoint edges. We prove that if $H$ is a
sufficiently large 4-uniform hypergraph on $n=4k$ vertices such that every
vertex belongs to more than ${n-1\choose 3} - {3n/4 \choose 3}$ edges then $H$
contains a perfect matching. This bound is tight and settles a conjecture of
H{\'a}n, Person and Schacht.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5684</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5684</id><created>2011-01-29</created><authors><author><keyname>Li</keyname><forenames>Qin</forenames></author><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Long</keyname><forenames>Dong-Yang</forenames></author><author><keyname>Chan</keyname><forenames>W. H.</forenames></author><author><keyname>Wu</keyname><forenames>Chun-Hui</forenames></author></authors><title>On the impossibility of non-static quantum bit commitment between two
  parties</title><categories>cs.CR quant-ph</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Choi \emph{et al}. proposed an assumption on Mayers-Lo-Chau (MLC)
no-go theorem that the state of the entire quantum system is invariable to both
participants before the unveiling phase. This means that the theorem is only
applicable to static quantum bit commitment (QBC). This paper find that the
assumption is unnecessary and the MLC no-go theorem can be applied to not only
static QBC, but also non-static one. A non-static QBC protocol proposed by Choi
\emph{et al.} is briefly reviewed and analyzed to work as a supporting example.
In addition, a novel way to prove the impossibility of the two kinds of QBC is
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5687</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5687</id><created>2011-01-29</created><authors><author><keyname>Pokrass</keyname><forenames>Jonathan</forenames></author><author><keyname>Bronstein</keyname><forenames>Alexander M.</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author></authors><title>A correspondence-less approach to matching of deformable shapes</title><categories>cs.CV cs.CG</categories><comments>Preprint submitted to Intl. Conference on Scale Space and Variational
  Methods (SSVM'11)</comments><msc-class>35A15, 65D19, 35J05</msc-class><acm-class>I.4.7; I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding a match between partially available deformable shapes is a
challenging problem with numerous applications. The problem is usually
approached by computing local descriptors on a pair of shapes and then
establishing a point-wise correspondence between the two. In this paper, we
introduce an alternative correspondence-less approach to matching fragments to
an entire shape undergoing a non-rigid deformation. We use diffusion geometric
descriptors and optimize over the integration domains on which the integral
descriptors of the two parts match. The problem is regularized using the
Mumford-Shah functional. We show an efficient discretization based on the
Ambrosio-Tortorelli approximation generalized to triangular meshes. Experiments
demonstrating the success of the proposed method are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5711</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5711</id><created>2011-01-29</created><updated>2012-06-07</updated><authors><author><keyname>Orenshtein</keyname><forenames>Tal</forenames></author><author><keyname>Shinkar</keyname><forenames>Igor</forenames></author></authors><title>Greedy Random Walk</title><categories>math.PR cs.DS</categories><doi>10.1017/S0963548313000552</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a discrete time self interacting random process on graphs, which we
call Greedy Random Walk. The walker is located initially at some vertex. As
time evolves, each vertex maintains the set of adjacent edges touching it that
have not been crossed yet by the walker. At each step, the walker being at some
vertex, picks an adjacent edge among the edges that have not traversed thus far
according to some (deterministic or randomized) rule. If all the adjacent edges
have already been traversed, then an adjacent edge is chosen uniformly at
random. After picking an edge the walk jumps along it to the neighboring
vertex. We show that the expected edge cover time of the greedy random walk is
linear in the number of edges for certain natural families of graphs. Examples
of such graphs include the complete graph, even degree expanders of logarithmic
girth, and the hypercube graph. We also show that GRW is transient in $\Z^d$
for all $d \geq 3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5716</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5716</id><created>2011-01-29</created><updated>2012-04-03</updated><authors><author><keyname>Floor</keyname><forenames>Paal Anders</forenames></author><author><keyname>Kim</keyname><forenames>Anna N.</forenames></author><author><keyname>Wernersson</keyname><forenames>Niklas</forenames></author><author><keyname>Ramstad</keyname><forenames>Tor A.</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author><author><keyname>Balasingham</keyname><forenames>Ilangko</forenames></author></authors><title>Zero-Delay Joint Source-Channel Coding for a Bivariate Gaussian on a
  Gaussian MAC</title><categories>cs.IT math.IT</categories><comments>27 page draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, delay-free, low complexity, joint source-channel coding (JSCC)
for transmission of two correlated Gaussian memoryless sources over a Gaussian
Multiple Access Channel (GMAC) is considered. The main contributions of the
paper are two distributed JSCC schemes: one discrete scheme based on nested
scalar quantization, and one hybrid discrete-analog scheme based on a scalar
quantizer and a linear continuous mapping. The proposed schemes show promising
performance which improve with increasing correlation and are robust against
variations in noise level. Both schemes exhibit a constant gap to the
performance upper bound when the channel signal-to-noise ratio gets large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5731</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5731</id><created>2011-01-29</created><authors><author><keyname>Bliss</keyname><forenames>Daniel W.</forenames></author><author><keyname>Govindasamy</keyname><forenames>Siddhartan</forenames></author></authors><title>Minimizing Hidden-Node Network Interference by Optimizing SISO and MIMO
  Spectral Efficiency</title><categories>cs.IT math.IT</categories><comments>12 pages, 6 figures, contributed to the 2010 IEEE Asilomar Conference
  on Signals, Systems and Computers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the optimal spectral efficiency (data rate divided by the
message bandwidth) that minimizes the probability of causing disruptive
interference for ad hoc wireless networks or cognitive radios is investigated.
Two basic problem constraints are considered: a given message size, or fixed
data rate. Implicitly, the trade being optimized is between longer transmit
duration and wider bandwidth versus higher transmit power. Both single-input
single-output (SISO) and multiple-input multiple-output (MIMO) links are
considered. Here, a link optimizes its spectral efficiency to be a &quot;good
neighbor.&quot; The probability of interference is characterized by the probability
that the signal power received by a hidden node in a wireless network exceeds
some threshold. The optimized spectral efficiency is a function of the
transmitter-to-hidden-node channel exponent, exclusively. It is shown that for
typical channel exponents a spectral efficiency of slightly greater than
1~b/s/Hz per antenna is optimal. It is also shown that the optimal spectral
efficiency is valid in the environment with multiple hidden nodes. Also
explicit evaluations of the probability of collisions is presented as a
function of spectral efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5747</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5747</id><created>2011-01-30</created><updated>2011-02-01</updated><authors><author><keyname>Li</keyname><forenames>Xueliang</forenames></author><author><keyname>Sun</keyname><forenames>Yuefang</forenames></author></authors><title>Rainbow connections of graphs -- A survey</title><categories>math.CO cs.DM</categories><comments>34 pages</comments><msc-class>05C15, 05C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of rainbow connection was introduced by Chartrand et al. in 2008.
It is fairly interesting and recently quite a lot papers have been published
about it. In this survey we attempt to bring together most of the results and
papers that dealt with it. We begin with an introduction, and then try to
organize the work into five categories, including (strong) rainbow connection
number, rainbow $k$-connectivity, $k$-rainbow index, rainbow vertex-connection
number, algorithms and computational complexity. This survey also contains some
conjectures, open problems or questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5753</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5753</id><created>2011-01-30</created><authors><author><keyname>Dinitz</keyname><forenames>Michael</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author></authors><title>Fault-Tolerant Spanners: Better and Simpler</title><categories>cs.DS math.CO</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural requirement of many distributed structures is fault-tolerance:
after some failures, whatever remains from the structure should still be
effective for whatever remains from the network. In this paper we examine
spanners of general graphs that are tolerant to vertex failures, and
significantly improve their dependence on the number of faults $r$, for all
stretch bounds.
  For stretch $k \geq 3$ we design a simple transformation that converts every
$k$-spanner construction with at most $f(n)$ edges into an $r$-fault-tolerant
$k$-spanner construction with at most $O(r^3 \log n) \cdot f(2n/r)$ edges.
Applying this to standard greedy spanner constructions gives $r$-fault tolerant
$k$-spanners with $\tilde O(r^{2} n^{1+\frac{2}{k+1}})$ edges. The previous
construction by Chechik, Langberg, Peleg, and Roddity [STOC 2009] depends
similarly on $n$ but exponentially on $r$ (approximately like $k^r$).
  For the case $k=2$ and unit-length edges, an $O(r \log n)$-approximation
algorithm is known from recent work of Dinitz and Krauthgamer [arXiv 2010],
where several spanner results are obtained using a common approach of rounding
a natural flow-based linear programming relaxation. Here we use a different
(stronger) LP relaxation and improve the approximation ratio to $O(\log n)$,
which is, notably, independent of the number of faults $r$. We further
strengthen this bound in terms of the maximum degree by using the \Lovasz Local
Lemma.
  Finally, we show that most of our constructions are inherently local by
designing equivalent distributed algorithms in the LOCAL model of distributed
computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5755</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5755</id><created>2011-01-30</created><updated>2011-04-26</updated><authors><author><keyname>Fang</keyname><forenames>Yong</forenames></author><author><keyname>Huang</keyname><forenames>Bormin</forenames></author><author><keyname>Wu</keyname><forenames>Jiaji</forenames></author></authors><title>2D Sparse Signal Recovery via 2D Orthogonal Matching Pursuit</title><categories>cs.IT cs.MM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovery algorithms play a key role in compressive sampling (CS). Most of
current CS recovery algorithms are originally designed for one-dimensional (1D)
signal, while many practical signals are two-dimensional (2D). By utilizing 2D
separable sampling, 2D signal recovery problem can be converted into 1D signal
recovery problem so that ordinary 1D recovery algorithms, e.g. orthogonal
matching pursuit (OMP), can be applied directly. However, even with 2D
separable sampling, the memory usage and complexity at the decoder is still
high. This paper develops a novel recovery algorithm called 2D-OMP, which is an
extension of 1D-OMP. In the 2D-OMP, each atom in the dictionary is a matrix. At
each iteration, the decoder projects the sample matrix onto 2D atoms to select
the best matched atom, and then renews the weights for all the already selected
atoms via the least squares. We show that 2D-OMP is in fact equivalent to
1D-OMP, but it reduces recovery complexity and memory usage significantly.
What's more important, by utilizing the same methodology used in this paper,
one can even obtain higher dimensional OMP (say 3D-OMP, etc.) with ease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5757</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5757</id><created>2011-01-30</created><authors><author><keyname>Bastenhof</keyname><forenames>Arno</forenames></author></authors><title>Polarized Montagovian Semantics for the Lambek-Grishin calculus</title><categories>cs.CL</categories><comments>To appear in the proceedings of the 15th conference on Formal
  Grammar, Copenhagen, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grishin proposed enriching the Lambek calculus with multiplicative
disjunction (par) and coresiduals. Applications to linguistics were discussed
by Moortgat, who spoke of the Lambek-Grishin calculus (LG). In this paper, we
adapt Girard's polarity-sensitive double negation embedding for classical logic
to extract a compositional Montagovian semantics from a display calculus for
focused proof search in LG. We seize the opportunity to illustrate our approach
alongside an analysis of extraction, providing linguistic motivation for linear
distributivity of tensor over par, thus answering a question of
Kurtonina&amp;Moortgat. We conclude by comparing our proposal to the continuation
semantics of Bernardi&amp;Moortgat, corresponding to call-by- name and
call-by-value evaluation strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5763</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5763</id><created>2011-01-30</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Chandrima</forenames></author><author><keyname>Chakravorty</keyname><forenames>Sounak</forenames></author></authors><title>A New Semantic Web Approach for Constructing, Searching and Modifying
  Ontology Dynamically</title><categories>cs.IR</categories><comments>6 pages, 14 figures</comments><report-no>WiDiCoReL/2011/03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic web is the next generation web, which concerns the meaning of web
documents It has the immense power to pull out the most relevant information
from the web pages, which is also meaningful to any user, using software
agents. In today's world, agent communication is not possible if concerned
ontology is changed a little. We have pointed out this very problem and
developed an Ontology Purification System to help agent communication. In our
system you can send queries and view the search results. If it can't meet the
criteria then it finds out the mismatched elements. Modification is done within
a second and you can see the difference. That's why we emphasis on the word
dynamic. When Administrator is updating the system, at the same time that
updation is visible to the user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5766</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5766</id><created>2011-01-30</created><authors><author><keyname>Bruna</keyname><forenames>Joan</forenames></author><author><keyname>Mallat</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Geometric Models with Co-occurrence Groups</title><categories>cs.CV cs.IT math.IT</categories><comments>6 pages, ESANN 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A geometric model of sparse signal representations is introduced for classes
of signals. It is computed by optimizing co-occurrence groups with a maximum
likelihood estimate calculated with a Bernoulli mixture model. Applications to
face image compression and MNIST digit classification illustrate the
applicability of this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5779</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5779</id><created>2011-01-30</created><authors><author><keyname>Cloud</keyname><forenames>Jason</forenames></author><author><keyname>Zeger</keyname><forenames>Linda</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Co-Designing Multi-Packet Reception, Network Coding, and MAC Using a
  Simple Predictive Model</title><categories>cs.NI</categories><comments>8 Pages, 10 Figures, Submitted to WiOpt 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a cross-layer approach to optimize the joint use of multi-packet
reception and network coding, in order to relieve congestion. We construct a
model for the behavior of the 802.11 MAC and apply it to several key canonical
topology components and their extensions to any number of nodes. The results
obtained from this model match the available experimental results, which are
for routing and opportunistic network coding, with fidelity. Using this model,
we show that fairness allocation by the MAC can seriously impact performance;
hence, we devise a new MAC that not only substantially improves throughput
relative to the current 802.11 MAC, but also provides fairness to flows of
information rather than to nodes. We show that the proper combination of
network coding, multi-packet reception, and our new MAC protocol achieves
super-additive throughput gains of up to 6.3 times that of routing alone with
the use of the standard 802.11 MAC. Finally, we extend the model to analyze the
asymptotic behavior of our new MAC as the number of nodes increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5785</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5785</id><created>2011-01-30</created><authors><author><keyname>Yu</keyname><forenames>Guoshen</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Statistical Compressed Sensing of Gaussian Mixture Models</title><categories>cs.CV cs.LG</categories><doi>10.1109/TSP.2011.2168521</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A novel framework of compressed sensing, namely statistical compressed
sensing (SCS), that aims at efficiently sampling a collection of signals that
follow a statistical distribution, and achieving accurate reconstruction on
average, is introduced. SCS based on Gaussian models is investigated in depth.
For signals that follow a single Gaussian model, with Gaussian or Bernoulli
sensing matrices of O(k) measurements, considerably smaller than the O(k
log(N/k)) required by conventional CS based on sparse models, where N is the
signal dimension, and with an optimal decoder implemented via linear filtering,
significantly faster than the pursuit decoders applied in conventional CS, the
error of SCS is shown tightly upper bounded by a constant times the best k-term
approximation error, with overwhelming probability. The failure probability is
also significantly smaller than that of conventional sparsity-oriented CS.
Stronger yet simpler results further show that for any sensing matrix, the
error of Gaussian SCS is upper bounded by a constant times the best k-term
approximation with probability one, and the bound constant can be efficiently
calculated. For Gaussian mixture models (GMMs), that assume multiple Gaussian
distributions and that each signal follows one of them with an unknown index, a
piecewise linear estimator is introduced to decode SCS. The accuracy of model
selection, at the heart of the piecewise linear decoder, is analyzed in terms
of the properties of the Gaussian distributions and the number of sensing
measurements. A maximum a posteriori expectation-maximization algorithm that
iteratively estimates the Gaussian models parameters, the signals model
selection, and decodes the signals, is presented for GMM-based SCS. In real
image sensing applications, GMM-based SCS is shown to lead to improved results
compared to conventional CS, at a considerably lower computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5791</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5791</id><created>2011-01-30</created><authors><author><keyname>Bela</keyname><forenames>Genge</forenames></author><author><keyname>Piroska</keyname><forenames>Haller</forenames></author></authors><title>Using Planetlab to Implement Multicast at the Application Level</title><categories>cs.DC cs.MM</categories><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.3, No.1, January 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Application-layer multicast implements the multicast functionality at the
application layer. The main goal of application-layer multicast is to construct
and maintain efficient distribution structures between endhosts. In this paper
we focus on the implementation of an application-layer multicast network using
PlanetLab. We observe that the total time required to measure network latency
over TCP is influenced dramatically by the TCP connection time. We argue that
end-host distribution is not only influenced by the quality of network links
but also by the time required to make connections between nodes. We provide
several solutions to decrease the total end-host distribution time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5794</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5794</id><created>2011-01-30</created><authors><author><keyname>Ayesta</keyname><forenames>U.</forenames></author><author><keyname>Erausquin</keyname><forenames>M.</forenames></author><author><keyname>Jonckheere</keyname><forenames>M.</forenames></author><author><keyname>Verloop</keyname><forenames>I. M.</forenames></author></authors><title>Scheduling in a random environment: stability and asymptotic optimality</title><categories>cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the scheduling of a common resource between several concurrent
users when the feasible transmission rate of each user varies randomly over
time. Time is slotted and users arrive and depart upon service completion. This
may model for example the flow-level behavior of end-users in a narrowband HDR
wireless channel (CDMA 1xEV-DO). As performance criteria we consider the
stability of the system and the mean delay experienced by the users. Given the
complexity of the problem we investigate the fluid-scaled system, which allows
to obtain important results and insights for the original system: (1) We
characterize for a large class of scheduling policies the stability conditions
and identify a set of maximum stable policies, giving in each time slot
preference to users being in their best possible channel condition. We find in
particular that many opportunistic scheduling policies like Score-Based,
Proportionally Best or Potential Improvement are stable under the maximum
stability conditions, whereas the opportunistic scheduler Relative-Best or the
cmu-rule are not. (2) We show that choosing the right tie-breaking rule is
crucial for the performance (e.g. average delay) as perceived by a user. We
prove that a policy is asymptotically optimal if it is maximum stable and the
tie-breaking rule gives priority to the user with the highest departure
probability. We will refer to such tie-breaking rule as myopic. (3) We derive
the growth rates of the number of users in the system in overload settings
under various policies, which give additional insights on the performance. (4)
We conclude that simple priority-index policies with the myopic tie-breaking
rule, are stable and asymptotically optimal. All our findings are validated
with extensive numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5805</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5805</id><created>2011-01-30</created><updated>2011-08-11</updated><authors><author><keyname>Riondato</keyname><forenames>Matteo</forenames></author><author><keyname>Akdere</keyname><forenames>Mert</forenames></author><author><keyname>Cetintemel</keyname><forenames>Ugur</forenames></author><author><keyname>Zdonik</keyname><forenames>Stanley B.</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author></authors><title>The VC-Dimension of Queries and Selectivity Estimation Through Sampling</title><categories>cs.DB cs.DS cs.LG</categories><comments>20 pages, 3 figures</comments><acm-class>H.2.4; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a novel method, based on the statistical concept of the
Vapnik-Chervonenkis dimension, to evaluate the selectivity (output cardinality)
of SQL queries - a crucial step in optimizing the execution of large scale
database and data-mining operations. The major theoretical contribution of this
work, which is of independent interest, is an explicit bound to the
VC-dimension of a range space defined by all possible outcomes of a collection
(class) of queries. We prove that the VC-dimension is a function of the maximum
number of Boolean operations in the selection predicate and of the maximum
number of select and join operations in any individual query in the collection,
but it is neither a function of the number of queries in the collection nor of
the size (number of tuples) of the database. We leverage on this result and
develop a method that, given a class of queries, builds a concise random sample
of a database, such that with high probability the execution of any query in
the class on the sample provides an accurate estimate for the selectivity of
the query on the original large database. The error probability holds
simultaneously for the selectivity estimates of all queries in the collection,
thus the same sample can be used to evaluate the selectivity of multiple
queries, and the sample needs to be refreshed only following major changes in
the database. The sample representation computed by our method is typically
sufficiently small to be stored in main memory. We present extensive
experimental results, validating our theoretical analysis and demonstrating the
advantage of our technique when compared to complex selectivity estimation
techniques used in PostgreSQL and the Microsoft SQL Server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5809</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5809</id><created>2011-01-30</created><updated>2011-03-11</updated><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>The Degrees of Freedom Region and Interference Alignment for the MIMO
  Interference Channel with Delayed CSI</title><categories>cs.IT math.IT</categories><comments>New results are added. 57 pages, 6 figures, 2 tables, submitted to
  IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degrees of freedom (DoF) region of the 2-user multiple-antenna or MIMO
(multiple-input, multiple-output) interference channel (IC) is studied under
fast fading and the assumption of {\em delayed} channel state information (CSI)
wherein all terminals know all (or certain) channel matrices perfectly, but
with a delay, and each receiver in addition knows its own incoming channels
instantaneously. The general MIMO IC is considered with an arbitrary number of
antennas at each of the four terminals. Dividing it into several classes
depending on the relation between the numbers of antennas at the four
terminals, the fundamental DoF regions are characterized under the delayed CSI
assumption for {\em all} possible values of number of antennas at the four
terminals. In particular, an outer bound on the DoF region of the general MIMO
IC is derived. This bound is then shown to be tight for all MIMO ICs by
developing interference alignment based achievability schemes for each class. A
comparison of these DoF regions under the delayed CSI assumption is made with
those of the idealistic `perfect CSI' assumption where perfect and
instantaneous CSI is available at all terminals on the one hand and with the
DoF regions of the conservative `no CSI' assumption on the other, where CSI is
available at the receivers but not at all at the transmitters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5828</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5828</id><created>2011-01-30</created><updated>2011-08-01</updated><authors><author><keyname>Acosta</keyname><forenames>Gabriel</forenames></author><author><keyname>Caridi</keyname><forenames>In&#xe9;s</forenames></author><author><keyname>Guala</keyname><forenames>Sebasti&#xe1;n</forenames></author><author><keyname>Marenco</keyname><forenames>Javier</forenames></author></authors><title>The Full Strategy Minority Game</title><categories>physics.soc-ph cs.GT</categories><comments>To appear in Physica A</comments><doi>10.1016/j.physa.2011.07.049</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Full Strategy Minority Game (FSMG) is an instance of the Minority Game
(MG) which includes a single copy of every potential agent. In this work, we
explicitly solve the FSMG thanks to certain symmetries of this game.
Furthermore, by considering the MG as a statistical sample of the FSMG, we
compute approximated values of the key variable {\sigma}2/N in the symmetric
phase for different versions of the MG. As another application we prove that
our results can be easily modified in order to handle certain kind of initial
biased strategies scores, in particular when the bias is introduced at the
agents' level. We also show that the FSMG verifies a strict period two dynamics
(i.e., period two dynamics satisfied with probability 1) giving, to the best of
our knowledge, the first example of an instance of the MG for which this
feature can be analytically proved. Thanks to this property, it is possible to
compute in a simple way the probability that a general instance of the MG
breaks the period two dynamics for the first time in a given simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5830</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5830</id><created>2011-01-30</created><updated>2012-07-07</updated><authors><author><keyname>Khan</keyname><forenames>Imdadullah</forenames></author></authors><title>Perfect matching in 3-uniform hypergraphs with large vertex degree</title><categories>cs.DM math.CO</categories><comments>arXiv admin note: text overlap with arXiv:1101.5675</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A perfect matching in a 3-uniform hypergraph on $n=3k$ vertices is a subset
of $\frac{n}{3}$ disjoint edges. We prove that if $H$ is a 3-uniform hypergraph
on $n=3k$ vertices such that every vertex belongs to at least ${n-1\choose 2} -
{2n/3\choose 2}+1$ edges then $H$ contains a perfect matching. We give a
construction to show that this result is best possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5833</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5833</id><created>2011-01-30</created><authors><author><keyname>Daiger</keyname><forenames>Katy</forenames></author></authors><title>The Documents and Assets Created During the Video Game Production
  Process</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to take that first step in helping archivists
understand the video game industry by examining the documents and assets
created by game companies. This paper is intended as a survey of the records
generated during video game production, and an overview of why and how those
records are created. It is not intended to be a statement on archiving best
practices, but rather a tool for archivists to use when assessing and
processing video game collections. It is an overview of how a video game is
made and the paper trail left behind that an archivist might encounter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5842</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5842</id><created>2011-01-30</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Prabhu</keyname><forenames>Vinayak S.</forenames></author></authors><title>Synthesis of Memory-Efficient Real-Time Controllers for Safety
  Objectives (Full Version)</title><categories>cs.LO cs.GT</categories><comments>Full version, including proofs, of the paper appearing in HSCC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study synthesis of controllers for real-time systems, where the objective
is to stay in a given safe set. The problem is solved by obtaining winning
strategies in concurrent two-player \emph{timed automaton games} with safety
objectives. To prevent a player from winning by blocking time, we restrict each
player to strategies that ensure that the player cannot be responsible for
causing a zeno run. We construct winning strategies for the controller which
require access only to (1) the system clocks (thus, controllers which require
their own internal infinitely precise clocks are not necessary), and (2) a
linear (in the number of clocks) number of memory bits. Precisely, we show that
a memory of size $\big(3\cdot|C|+1 + \lg(|C|+1)\big)$ bits suffices for winning
controller strategies for safety objectives, where $C$ is the set of clocks of
the timed automaton game, significantly improving the previous known
exponential bound. We also settle the open question of whether \emph{region}
strategies for controllers require memory for safety objectives by showing with
an example that region strategies do require memory for safety objectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5858</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5858</id><created>2011-01-31</created><authors><author><keyname>Tajima</keyname><forenames>Masato</forenames></author><author><keyname>Okino</keyname><forenames>Koji</forenames></author><author><keyname>Miyagoshi</keyname><forenames>Takashi</forenames></author></authors><title>Simultaneous Code/Error-Trellis Reduction for Convolutional Codes Using
  Shifted Code/Error-Subsequences</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to the 2011 IEEE International Symposium on
  Information Theory</comments><doi>10.1587/transfun.E94.A.2894</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that the code-trellis and the error-trellis for a
convolutional code can be reduced simultaneously, if reduction is possible.
Assume that the error-trellis can be reduced using shifted error-subsequences.
In this case, if the identical shifts occur in the subsequences of each code
path, then the code-trellis can also be reduced. First, we obtain pairs of
transformations which generate the identical shifts both in the subsequences of
the code-path and in those of the error-path. Next, by applying these
transformations to the generator matrix and the parity-check matrix, we show
that reduction of these matrices is accomplished simultaneously, if it is
possible. Moreover, it is shown that the two associated trellises are also
reduced simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5876</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5876</id><created>2011-01-31</created><updated>2011-10-18</updated><authors><author><keyname>Meeks</keyname><forenames>Kitty</forenames></author><author><keyname>Scott</keyname><forenames>Alexander</forenames></author></authors><title>The complexity of flood-filling games on graphs</title><categories>cs.DS</categories><comments>More typos corrected!</comments><doi>10.1016/j.dam.2011.09.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the complexity of problems related to the combinatorial game
Free-Flood-It, in which players aim to make a coloured graph monochromatic with
the minimum possible number of flooding operations. Although computing the
minimum number of moves required to flood an arbitrary graph is known to be
NP-hard, we demonstrate a polynomial time algorithm to compute the minimum
number of moves required to link each pair of vertices. We apply this result to
compute in polynomial time the minimum number of moves required to flood a
path, and an additive approximation to this quantity for an arbitrary k x n
board, coloured with a bounded number of colours, for any fixed k. On the other
hand, we show that, for k&gt;=3, determining the minimum number of moves required
to flood a k x n board coloured with at least four colours remains NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5888</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5888</id><created>2011-01-31</created><updated>2011-07-28</updated><authors><author><keyname>Hisano</keyname><forenames>Ryohei</forenames></author><author><keyname>Sornette</keyname><forenames>Didier</forenames></author><author><keyname>Mizuno</keyname><forenames>Takayuki</forenames></author></authors><title>Predicted and Verified Deviations from Zipf's law in Ecology of
  Competing Products</title><categories>physics.soc-ph cs.SI</categories><doi>10.1103/PhysRevE.84.026117</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zipf's power-law distribution is a generic empirical statistical regularity
found in many complex systems. However, rather than universality with a single
power-law exponent (equal to 1 for Zipf's law), there are many reported
deviations that remain unexplained. A recently developed theory finds that the
interplay between (i) one of the most universal ingredients, namely stochastic
proportional growth, and (ii) birth and death processes, leads to a generic
power-law distribution with an exponent that depends on the characteristics of
each ingredient. Here, we report the first complete empirical test of the
theory and its application, based on the empirical analysis of the dynamics of
market shares in the product market. We estimate directly the average growth
rate of market shares and its standard deviation, the birth rates and the
&quot;death&quot; (hazard) rate of products. We find that temporal variations and product
differences of the observed power-law exponents can be fully captured by the
theory with no adjustable parameters. Our results can be generalized to many
systems for which the statistical properties revealed by power law exponents
are directly linked to the underlying generating mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5913</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5913</id><created>2011-01-31</created><updated>2011-07-19</updated><authors><author><keyname>Pan</keyname><forenames>Raj Kumar</forenames></author><author><keyname>Saram&#xe4;ki</keyname><forenames>Jari</forenames></author></authors><title>Path lengths, correlations, and centrality in temporal networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI physics.data-an</categories><comments>10 pages, 8 figures, Published version</comments><journal-ref>Phys. Rev. E 84, 016105 (2011)</journal-ref><doi>10.1103/PhysRevE.84.016105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In temporal networks, where nodes interact via sequences of temporary events,
information or resources can only flow through paths that follow the
time-ordering of events. Such temporal paths play a crucial role in dynamic
processes. However, since networks have so far been usually considered static
or quasi-static, the properties of temporal paths are not yet well understood.
Building on a definition and algorithmic implementation of the average temporal
distance between nodes, we study temporal paths in empirical networks of human
communication and air transport. Although temporal distances correlate with
static graph distances, there is a large spread, and nodes that appear close
from the static network view may be connected via slow paths or not at all.
Differences between static and temporal properties are further highlighted in
studies of the temporal closeness centrality. In addition, correlations and
heterogeneities in the underlying event sequences affect temporal path lengths,
increasing temporal distances in communication networks and decreasing them in
the air transport network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5915</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5915</id><created>2011-01-31</created><authors><author><keyname>Brunetti</keyname><forenames>Sara</forenames></author><author><keyname>Lodi</keyname><forenames>Elena</forenames></author><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author></authors><title>Dynamic Monopolies in Colored Tori</title><categories>cs.SI cs.DC cs.DS physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\em information diffusion} has been modeled as the spread of an
information within a group through a process of social influence, where the
diffusion is driven by the so called {\em influential network}. Such a process,
which has been intensively studied under the name of {\em viral marketing}, has
the goal to select an initial good set of individuals that will promote a new
idea (or message) by spreading the &quot;rumor&quot; within the entire social network
through the word-of-mouth. Several studies used the {\em linear threshold
model} where the group is represented by a graph, nodes have two possible
states (active, non-active), and the threshold triggering the adoption
(activation) of a new idea to a node is given by the number of the active
neighbors.
  The problem of detecting in a graph the presence of the minimal number of
nodes that will be able to activate the entire network is called {\em target
set selection} (TSS). In this paper we extend TSS by allowing nodes to have
more than two colors. The multicolored version of the TSS can be described as
follows: let $G$ be a torus where every node is assigned a color from a finite
set of colors. At each local time step, each node can recolor itself, depending
on the local configurations, with the color held by the majority of its
neighbors. We study the initial distributions of colors leading the system to a
monochromatic configuration of color $k$, focusing on the minimum number of
initial $k$-colored nodes. We conclude the paper by providing the time
complexity to achieve the monochromatic configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5938</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5938</id><created>2011-01-31</created><authors><author><keyname>Prehnal</keyname><forenames>Vojtech</forenames></author></authors><title>Dialog interface for dynamic data models</title><categories>cs.SE cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the new information system development methodology will be
proposed. This methodology will enable the whole data model to be built and
adjusted at the run time, without rebuilding the application. This will make
the user much more powerful and independent on the manufacturer of the system.
It will also cut the price and shorten the development time of the information
systems dramatically, because common business logic will not have to be
implemented for each individual table and the major part of the user interface
will be generated automatically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5940</identifier>
 <datestamp>2013-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5940</id><created>2011-01-31</created><authors><author><keyname>Perrot</keyname><forenames>Kevin</forenames></author><author><keyname>R&#xe9;mila</keyname><forenames>Eric</forenames></author></authors><title>Avalanche Structure in the Kadanoff Sand Pile Model</title><categories>cs.DM</categories><comments>12 pages</comments><journal-ref>LATA 2011, LNCS Springer-Verlag, volume 6638, pages 427-439</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sand pile models are dynamical systems emphasizing the phenomenon of Self
Organized Criticality (SOC). From N stacked grains, iterating evolution rules
leads to some critical configuration where a small disturbance has deep
consequences on the system, involving numerous steps of grain fall. Physicists
L. Kadanoff et al. inspire KSPM, a model presenting a sharp SOC behavior,
extending the well known Sand Pile Model. In KSPM with parameter D we start
from a pile of N stacked grains and apply the rule: D-1 grains can fall from
column i onto the D-1 adjacent columns to the right if the difference of height
between columns i and i+1 is greater or equal to D. We propose an iterative
study of KSPM evolution where one single grain addition is repeated on a heap
of sand. The sequence of grain falls following a single grain addition is
called an avalanche. From a certain column precisely studied for D=3, we
provide a plain process describing avalanches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5944</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5944</id><created>2011-01-31</created><updated>2011-02-01</updated><authors><author><keyname>Denysyuk</keyname><forenames>Oksana</forenames></author><author><keyname>Rodrigues</keyname><forenames>Luis</forenames></author></authors><title>Random Walk on Directed Dynamic Graphs</title><categories>cs.DS</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic graphs have emerged as an appropriate model to capture the changing
nature of many modern networks, such as peer-to-peer overlays and mobile ad hoc
networks. Most of the recent research on dynamic networks has only addressed
the undirected dynamic graph model. However, realistic networks such as the
ones identified above are directed. In this paper we present early work in
addressing the properties of directed dynamic graphs. In particular, we explore
the problem of random walk in such graphs. We assume the existence of an
oblivious adversary that makes arbitrary changes in every communication round.
We explore the problem of covering the dynamic graph, that even in the static
case can be exponential, and we establish an upper bound O(d_max n^3 log^2 n)
of the cover time for balanced dynamic graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5957</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5957</id><created>2011-01-31</created><authors><author><keyname>Zheng</keyname><forenames>Bojin</forenames></author><author><keyname>Li</keyname><forenames>Deyi</forenames></author><author><keyname>Chen</keyname><forenames>Guisheng</forenames></author><author><keyname>Wang</keyname><forenames>Jianmin</forenames></author></authors><title>A Kind of Representation of Common Knowledge and its Application in
  Requirements Analysis</title><categories>cs.SE</categories><comments>9 Pages, 0 Figure</comments><acm-class>D.2.1; D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the birth of software engineering, it always are recognized as one pure
engineering subject, therefore, the foundational scientific problems are not
paid much attention. This paper proposes that Requirements Analysis, the kernel
process of software engineering, can be modeled based on the concept of &quot;common
knowledge&quot;. Such a model would make us understand the nature of this process.
This paper utilizes the formal language as the tool to characterize the &quot;common
knowledge&quot;-based Requirements Analysis model, and theoretically proves that :
1) the precondition of success of software projects regardless of cost would be
that the participants in a software project have fully known the requirement
specification, if the participants do not understand the meaning of the other
participants; 2) the precondition of success of software projects regardless of
cost would be that the union set of knowledge of basic facts of the
participants in a software project can fully cover the requirement
specification, if the participants can always understand the meaning of the
other participants. These two theorems may have potential meanings to propose
new software engineering methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5966</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5966</id><created>2011-01-31</created><authors><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author></authors><title>On the Analysis of Weighted Nonbinary Repeat Multiple-Accumulate Codes</title><categories>cs.IT math.IT</categories><comments>The material in this paper was presented in part at the 6th
  International Symposium on Turbo Codes &amp; Iterative Information Processing,
  Brest, France, September 2010, and at the Information Theory and Applications
  (ITA) workshop, La Jolla, CA, February 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider weighted nonbinary repeat multiple-accumulate
(WNRMA) code ensembles obtained from the serial concatenation of a nonbinary
rate-1/n repeat code and the cascade of L&gt;= 1 accumulators, where each encoder
is followed by a nonbinary random weighter. The WNRMA codes are assumed to be
iteratively decoded using the turbo principle with maximum a posteriori
constituent decoders. We derive the exact weight enumerator of nonbinary
accumulators and subsequently give the weight enumerators for WNRMA code
ensembles. We formally prove that the symbol-wise minimum distance of WNRMA
code ensembles asymptotically grows linearly with the block length when L &gt;= 3
and n &gt;= 2, and L=2 and n &gt;= 3, for all powers of primes q &gt;= 3 considered,
where q is the field size. Thus, WNRMA code ensembles are asymptotically good
for these parameters. We also give iterative decoding thresholds, computed by
an extrinsic information transfer chart analysis, on the q-ary symmetric
channel to show the convergence properties. Finally, we consider the binary
image of WNRMA code ensembles and compare the asymptotic minimum distance
growth rates with those of binary repeat multiple-accumulate code ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5972</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5972</id><created>2011-01-31</created><authors><author><keyname>Zheng</keyname><forenames>Bojin</forenames></author><author><keyname>Wang</keyname><forenames>Jianmin</forenames></author><author><keyname>Chen</keyname><forenames>Guisheng</forenames></author><author><keyname>Jiang</keyname><forenames>Jian</forenames></author><author><keyname>Shen</keyname><forenames>Xianjun</forenames></author></authors><title>Hidden Tree Structure is a Key to the Emergence of Scaling in the World
  Wide Web</title><categories>cs.SI physics.soc-ph</categories><comments>4 Pages, 7 Figures</comments><journal-ref>Chin. Phys. Lett. Vol. 28, No. 1 (2011) 018901</journal-ref><doi>10.1088/0256-307X/28/1/018901</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preferential attachment is the most popular explanation for the emergence of
scaling behavior in the World Wide Web, but this explanation has been
challenged by the global information hypothesis, the existence of linear
preference and the emergence of new big internet companies in the real world.
We notice that most websites have an obvious feature that their pages are
organized as a tree (namely hidden tree) and hence propose a new model that
introduces a hidden tree structure into the Erd\H{o}s-R\'e}yi model by adding a
new rule: when one node connects to another, it should also connect to all
nodes in the path between these two nodes in the hidden tree. The experimental
results show that the degree distribution of the generated graphs would obey
power law distributions and have variable high clustering coefficients and
variable small average lengths of shortest paths. The proposed model provides
an alternative explanation to the emergence of scaling in the World Wide Web
without the above-mentioned difficulties, and also explains the &quot;preferential
attachment&quot; phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5984</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5984</id><created>2011-01-31</created><authors><author><keyname>Rahman</keyname><forenames>Md. Saifur</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>Optimality of Binning for Distributed Hypothesis Testing</title><categories>cs.IT math.IT</categories><comments>38 pages, 8 figures, submitted to IEEE Transactions on Information
  Theory, and part of the paper appeared in the proceedings of the 48th Annual
  Allerton Conference on Communications, Control, and Computing, University of
  Illinois, Urbana-Champaign, Sept. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a hypothesis testing problem in which data is compressed
distributively and sent to a detector that seeks to decide between two possible
distributions for the data. The aim is to characterize all achievable encoding
rates and exponents of the type 2 error probability when the type 1 error
probability is at most a fixed value. For related problems in distributed
source coding, schemes based on random binning perform well and often optimal.
For distributed hypothesis testing, however, the use of binning is hindered by
the fact that the overall error probability may be dominated by errors in
binning process. We show that despite this complication, binning is optimal for
a class of problems in which the goal is to &quot;test against conditional
independence.&quot; We then use this optimality result to give an outer bound for a
more general class of instances of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5985</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5985</id><created>2011-01-31</created><authors><author><keyname>Neto</keyname><forenames>H. V. Beltrao</forenames></author><author><keyname>Henkel</keyname><forenames>W.</forenames></author><author><keyname>Rocha</keyname><forenames>V. C. da</forenames><suffix>Jr</suffix></author></authors><title>Multi-Edge type Unequal Error Protection LDPC codes</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE International Symposium on Information Theory
  2011. 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Irregular low-density parity check (LDPC) codes are particularly well-suited
for transmission schemes that require unequal error protection (UEP) of the
transmitted data due to the different connection degrees of its variable nodes.
However, this UEP capability is strongly dependent on the connection profile
among the protection classes. This paper applies a multi-edge type analysis of
LDPC codes for optimizing such connection profile according to the performance
requirements of each protection class. This allows the construction of UEP-LDPC
codes where the difference between the performance of the protection classes
can be adjusted and with an UEP capability that does not vanish as the number
of decoding iterations grows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.5997</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.5997</id><created>2011-01-31</created><authors><author><keyname>Zheng</keyname><forenames>Bojin</forenames></author><author><keyname>Li</keyname><forenames>Yuanxiang</forenames></author></authors><title>New Model for Multi-Objective Evolutionary Algorithms</title><categories>cs.NE</categories><comments>8 pages,ICCS 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-Objective Evolutionary Algorithms (MOEAs) have been proved efficient to
deal with Multi-objective Optimization Problems (MOPs). Until now tens of MOEAs
have been proposed. The unified mode would provide a more systematic approach
to build new MOEAs. Here a new model is proposed which includes two sub-models
based on two classes of different schemas of MOEAs. According to the new model,
some representatives algorithms are decomposed and some interesting issues are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6001</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6001</id><created>2011-01-31</created><authors><author><keyname>Roli</keyname><forenames>Andrea</forenames></author><author><keyname>Manfroni</keyname><forenames>Mattia</forenames></author><author><keyname>Pinciroli</keyname><forenames>Carlo</forenames></author><author><keyname>Birattari</keyname><forenames>Mauro</forenames></author></authors><title>Boolean network robotics: a proof of concept</title><categories>cs.AI cs.NE cs.RO</categories><comments>11 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamical systems theory and complexity science provide powerful tools for
analysing artificial agents and robots. Furthermore, they have been recently
proposed also as a source of design principles and guidelines. Boolean networks
are a prominent example of complex dynamical systems and they have been shown
to effectively capture important phenomena in gene regulation. From an
engineering perspective, these models are very compelling, because they can
exhibit rich and complex behaviours, in spite of the compactness of their
description. In this paper, we propose the use of Boolean networks for
controlling robots' behaviour. The network is designed by means of an automatic
procedure based on stochastic local search techniques. We show that this
approach makes it possible to design a network which enables the robot to
accomplish a task that requires the capability of navigating the space using a
light stimulus, as well as the formation and use of an internal memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6006</identifier>
 <datestamp>2011-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6006</id><created>2011-01-31</created><updated>2011-02-24</updated><authors><author><keyname>de Verdi&#xe8;re</keyname><forenames>&#xc9;ric Colin</forenames></author><author><keyname>Ginot</keyname><forenames>Gr&#xe9;gory</forenames></author><author><keyname>Goaoc</keyname><forenames>Xavier</forenames></author></authors><title>Helly numbers of acyclic families</title><categories>math.CO cs.CG cs.DM math.AT math.MG</categories><comments>Minor changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Helly number of a family of sets with empty intersection is the size of
its largest inclusion-wise minimal sub-family with empty intersection. Let F be
a finite family of open subsets of an arbitrary locally arc-wise connected
topological space Gamma. Assume that for every sub-family G of F the
intersection of the elements of G has at most r connected components, each of
which is a Q-homology cell. We show that the Helly number of F is at most
r(d_Gamma+1), where d_Gamma is the smallest integer j such that every open set
of Gamma has trivial Q-homology in dimension j and higher. (In particular
d_{R^d} = d). This bound is best possible. We prove, in fact, a stronger
theorem where small sub-families may have more than r connected components,
each possibly with nontrivial homology in low dimension. As an application, we
obtain several explicit bounds on Helly numbers in geometric transversal theory
for which only ad hoc geometric proofs were previously known; in certain cases,
the bound we obtain is better than what was previously known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6009</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6009</id><created>2011-01-31</created><authors><author><keyname>Roli</keyname><forenames>Andrea</forenames></author><author><keyname>Milano</keyname><forenames>Michela</forenames></author></authors><title>Solving the Satisfiability Problem Through Boolean Networks</title><categories>cs.AI cs.NE nlin.CG</categories><comments>12 pages, 6 figures, 2 tables</comments><journal-ref>In Evelina Lamma and Paola Mello (eds.), AI*IA99: Advances in
  Artificial Intelligence, LNAI series, vol. 1792, pp. 72-83, Springer, 2000</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new approach to solve the satisfiability problem
(SAT), based on boolean networks (BN). We define a mapping between a SAT
instance and a BN, and we solve SAT problem by simulating the BN dynamics. We
prove that BN fixed points correspond to the SAT solutions. The mapping
presented allows to develop a new class of algorithms to solve SAT. Moreover,
this new approach suggests new ways to combine symbolic and connectionist
computation and provides a general framework for local search algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6016</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6016</id><created>2011-01-31</created><authors><author><keyname>Iellamo</keyname><forenames>Stefano</forenames></author><author><keyname>Chen</keyname><forenames>Lin</forenames></author><author><keyname>Coupechoux</keyname><forenames>Marceau</forenames></author></authors><title>Let Cognitive Radios Imitate: Imitation-based Spectrum Access for
  Cognitive Radio Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we tackle the problem of opportunistic spectrum access in
large-scale cognitive radio networks, where the unlicensed Secondary Users (SU)
access the frequency channels partially occupied by the licensed Primary Users
(PU). Each channel is characterized by an availability probability unknown to
the SUs. We apply evolutionary game theory to model the spectrum access problem
and develop distributed spectrum access policies based on imitation, a behavior
rule widely applied in human societies consisting of imitating successful
behavior. We first develop two imitation-based spectrum access policies based
on the basic Proportional Imitation (PI) rule and the more advanced Double
Imitation (DI) rule given that a SU can imitate any other SUs. We then adapt
the proposed policies to a more practical scenario where a SU can only imitate
the other SUs operating on the same channel. A systematic theoretical analysis
is presented for both scenarios on the induced imitation dynamics and the
convergence properties of the proposed policies to an imitation-stable
equilibrium, which is also the $\epsilon$-optimum of the system. Simple,
natural and incentive-compatible, the proposed imitation-based spectrum access
policies can be implemented distributedly based on solely local interactions
and thus is especially suited in decentralized adaptive learning environments
as cognitive radio networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6018</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6018</id><created>2011-01-31</created><authors><author><keyname>Roli</keyname><forenames>Andrea</forenames></author><author><keyname>Arcaroli</keyname><forenames>Cristian</forenames></author><author><keyname>Lazzarini</keyname><forenames>Marco</forenames></author><author><keyname>Benedettini</keyname><forenames>Stefano</forenames></author></authors><title>Boolean Networks Design by Genetic Algorithms</title><categories>cs.NE nlin.AO</categories><comments>13 pages, 7 figures, 2 tables</comments><journal-ref>In Villani, M. and Cagnoni, S. (eds.), Proceedings of CEEI 2009 -
  Workshop on complexity, evolution and emergent intelligence, Reggio Emilia,
  Italy, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and discuss the results of an experimental analysis in the design
of Boolean networks by means of genetic algorithms. A population of networks is
evolved with the aim of finding a network such that the attractor it reaches is
of required length $l$. In general, any target can be defined, provided that it
is possible to model the task as an optimisation problem over the space of
networks. We experiment with different initial conditions for the networks,
namely in ordered, chaotic and critical regions, and also with different target
length values. Results show that all kinds of initial networks can attain the
desired goal, but with different success ratios: initial populations composed
of critical or chaotic networks are more likely to reach the target. Moreover,
the evolution starting from critical networks achieves the best overall
performance. This study is the first step toward the use of search algorithms
as tools for automatically design Boolean networks with required properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6022</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6022</id><created>2011-01-31</created><authors><author><keyname>Roberts</keyname><forenames>E. S.</forenames></author><author><keyname>Coolen</keyname><forenames>A. C. C.</forenames></author><author><keyname>Schlitt</keyname><forenames>T.</forenames></author></authors><title>Tailored graph ensembles as proxies or null models for real networks II:
  results on directed graphs</title><categories>q-bio.QM cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>21 pages, 1 figure, submitted to J. Phys. A</comments><doi>10.1088/1751-8113/44/27/275002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generate new mathematical tools with which to quantify the macroscopic
topological structure of large directed networks. This is achieved via a
statistical mechanical analysis of constrained maximum entropy ensembles of
directed random graphs with prescribed joint distributions for in- and
outdegrees and prescribed degree-degree correlation functions. We calculate
exact and explicit formulae for the leading orders in the system size of the
Shannon entropies and complexities of these ensembles, and for
information-theoretic distances. The results are applied to data on gene
regulation networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6029</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6029</id><created>2011-01-31</created><updated>2011-02-21</updated><authors><author><keyname>Lopes</keyname><forenames>Ricardo</forenames></author><author><keyname>Costa</keyname><forenames>V&#xed;tor Santos</forenames></author><author><keyname>Silva</keyname><forenames>Fernando</forenames></author></authors><title>A Design and Implementation of the Extended Andorra Model</title><categories>cs.PL</categories><comments>43 pages, To appear in Theory and Practice of Logic Programming
  (TPLP)</comments><acm-class>D.1.6; I.2.5</acm-class><doi>10.1017/S1471068411000068</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logic programming provides a high-level view of programming, giving
implementers a vast latitude into what techniques to explore to achieve the
best performance for logic programs. Towards obtaining maximum performance, one
of the holy grails of logic programming has been to design computational models
that could be executed efficiently and that would allow both for a reduction of
the search space and for exploiting all the available parallelism in the
application. These goals have motivated the design of the Extended Andorra
Model, a model where goals that do not constrain non-deterministic goals can
execute first.
  In this work we present and evaluate the Basic design for Extended Andorra
Model (BEAM), a system that builds upon David H. D. Warren's original EAM with
Implicit Control. We provide a complete description and implementation of the
BEAM System as a set of rewrite and control rules. We present the major data
structures and execution algorithms that are required for efficient execution,
and evaluate system performance.
  A detailed performance study of our system is included. Our results show that
the system achieves acceptable base performance, and that a number of
applications benefit from the advanced search inherent to the EAM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6030</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6030</id><created>2011-01-31</created><authors><author><keyname>Bhattacharya</keyname><forenames>Sourabh</forenames></author><author><keyname>Khanafer</keyname><forenames>Ali</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author></authors><title>Power Allocation in Team Jamming Games in Wireless Ad Hoc Networks</title><categories>cs.GT cs.CR cs.IT cs.SY math.IT math.OC</categories><comments>11 pages, 5 figues, submitted to Gamecomm 2011</comments><msc-class>91Axx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the problem of power allocation in teams. Each team
consists of two agents who try to split their available power between the tasks
of communication and jamming the nodes of the other team. The agents have
constraints on their total energy and instantaneous power usage. The cost
function is the difference between the rates of erroneously transmitted bits of
each team. We model the problem as a zero-sum differential game between the two
teams and use {\it{Isaacs'}} approach to obtain the necessary conditions for
the optimal trajectories. This leads to a continuous-kernel power allocation
game among the players. Based on the communications model, we present
sufficient conditions on the physical parameters of the agents for the
existence of a pure strategy Nash equilibrium (PSNE). Finally, we present
simulation results for the case when the agents are holonomic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6033</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6033</id><created>2011-01-31</created><authors><author><keyname>Rodier</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>IML</affiliation></author></authors><title>Some More Functions That Are Not APN Infinitely Often. The Case of
  Kasami exponents</title><categories>cs.IT math.IT math.NT</categories><comments>10</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a necessary condition for some polynomials of Kasami degree to be
APN over F_{q^n} for large n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6038</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6038</id><created>2011-01-31</created><authors><author><keyname>H</keyname><forenames>Jose Antonio Martin</forenames></author></authors><title>A polynomial 3-colorability algorithm with automatic generation of NO
  3-colorability (i.e. Co-NP) short proofs</title><categories>cs.DM cs.CC cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an algorithm for determining 3-colorability, i.e. the decision
problem (YES/NO), in planar graphs is presented. The algorithm, although not
exact (it could produce false positives) has two very important features: (i)
it has polynomial complexity and (ii) for every &quot;NO&quot; answer, a &quot;short&quot; proof is
generated, which is of much interest since 3-colorability is a NP-complete
problem and thus its complementary problem is in Co-NP. Hence the algorithm is
exact when it determines that a given planar graph is not 3-colorable since
this is verifiable via an automatic generation of short formal proofs (also
human-readable).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1101.6052</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1101.6052</id><created>2011-01-31</created><updated>2012-09-07</updated><authors><author><keyname>Schwab</keyname><forenames>Russell W.</forenames></author></authors><title>Stochastic Homogenization for Some Nonlinear Integro-Differential
  Equations</title><categories>math.AP cs.SY math.OC math.PR</categories><comments>24 pages; fixed some typos; rearranged the presentation in first 2
  sections</comments><msc-class>35J99, 45J05, 47G20, 49L25, 49N70, 60J75, 93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we extend to the random, stationary ergodic setting previous
results of periodic homogenization for a particular family of nonlinear
nonlocal &quot;elliptic&quot; equations with oscillatory coefficients. Such equations
include, but are not limited to Bellman equations and the Isaacs equations for
the control and differential games of some pure jump processes. The existence
of an effective equation and convergence the solutions of the family of the
original equations is obtained. Even in the linear case of the equations
contained herein the results appear to be new.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0008</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0008</id><created>2011-01-31</created><authors><author><keyname>Kossovsky</keyname><forenames>Alex Ely</forenames></author></authors><title>Scale invariance versus translation variance in Nash bargaining problem</title><categories>math.ST cs.GT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nash's solution in his celebrated article on the bargaining problem calling
for maximization of product of marginal utilities is revisited; a different
line of argument supporting such a solution is suggested by straightforward or
more direct reasoning, and a conjecture is raised which purports uniqueness of
algorithm, namely his solution. Other alternative inferior algorithms are also
suggested. It is argued in this article that the scale invariance principle for
utility functions should and could be applied here, namely that utility
rescaling u'=a*u is allowed, while translations, adding a constant to utility
functions u'=u+b could not be applied here, since it is not invariant and leads
to contradictory behavior. Finally, special situations of ownership and
utilities, where trading is predicted not to take place at all because none is
profitable are examined, and then shown to be consistent with the scale
invariance principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0023</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0023</id><created>2011-01-31</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Lubacz</keyname><forenames>Jozef</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>On Steganography in Lost Audio Packets</title><categories>cs.CR cs.MM</categories><comments>23 pages, 27 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a new hidden data insertion procedure based on estimated
probability of the remaining time of the call for steganographic method called
LACK (Lost Audio PaCKets steganography). LACK provides hidden communication for
real-time services like Voice over IP. The analytical results presented in this
paper concern the influence of LACK's hidden data insertion procedures on the
method's impact on quality of voice transmission and its resistance to
steganalysis. The proposed hidden data insertion procedure is also compared to
previous steganogram insertion approach based on estimated remaining average
call duration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0026</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0026</id><created>2011-01-31</created><authors><author><keyname>Raman</keyname><forenames>Parasaran</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Spatially-Aware Comparison and Consensus for Clusterings</title><categories>cs.LG cs.CG cs.DB</categories><comments>12 Pages, 9 figures, Proceedings of 2011 Siam International
  Conference on Data Mining</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new distance metric between clusterings that
incorporates information about the spatial distribution of points and clusters.
Our approach builds on the idea of a Hilbert space-based representation of
clusters as a combination of the representations of their constituent points.
We use this representation and the underlying metric to design a
spatially-aware consensus clustering procedure. This consensus procedure is
implemented via a novel reduction to Euclidean clustering, and is both simple
and efficient. All of our results apply to both soft and hard clusterings. We
accompany these algorithms with a detailed experimental evaluation that
demonstrates the efficiency and quality of our techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0033</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0033</id><created>2011-01-31</created><authors><author><keyname>Huang</keyname><forenames>Huang</forenames></author><author><keyname>Yu</keyname><forenames>Changbin</forenames></author><author><keyname>Wu</keyname><forenames>Qinghe</forenames></author></authors><title>Control of Multi-Agent Formations with Only Shape Constraints</title><categories>cs.SY</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a novel problem of how to choose an appropriate geometry
for a group of agents with only shape constraints but with a flexible scale.
Instead of assigning the formation system with a specific geometry, here the
only requirement on the desired geometry is a shape without any location,
rotation and, most importantly, scale constraints. Optimal rigid transformation
between two different geometries is discussed with especial focus on the
scaling operation, and the cooperative performance of the system is evaluated
by what we call the geometries degrees of similarity (DOS) with respect to the
desired shape during the entire convergence process. The design of the scale
when measuring the DOS is discussed from constant value and time-varying
function perspectives respectively. Fixed structured nonlinear control laws
that are functions on the scale are developed to guarantee the exponential
convergence of the system to the assigned shape. Our research is originated
from a three-agent formation system and is further extended to multiple (n &gt; 3)
agents by defining a triangular complement graph. Simulations demonstrate that
formation system with the time-varying scale function outperforms the one with
an arbitrary constant scale, and the relationship between underlying topology
and the system performance is further discussed based on the simulation
observations. Moveover, the control scheme is applied to bearing-only
sensor-target localization to show its application potentials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0040</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0040</id><created>2011-01-31</created><authors><author><keyname>Kash</keyname><forenames>Ian A.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Thaler</keyname><forenames>Justin</forenames></author><author><keyname>Ullman</keyname><forenames>Jonathan</forenames></author></authors><title>On the Zero-Error Capacity Threshold for Deletion Channels</title><categories>cs.IT math.IT</categories><comments>9 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the zero-error capacity of deletion channels. Specifically, we
consider the setting where we choose a codebook ${\cal C}$ consisting of
strings of $n$ bits, and our model of the channel corresponds to an adversary
who may delete up to $pn$ of these bits for a constant $p$. Our goal is to
decode correctly without error regardless of the actions of the adversary. We
consider what values of $p$ allow non-zero capacity in this setting. We suggest
multiple approaches, one of which makes use of the natural connection between
this problem and the problem of finding the expected length of the longest
common subsequence of two random sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0041</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0041</id><created>2011-01-31</created><updated>2011-03-22</updated><authors><author><keyname>Battaglia</keyname><forenames>Giovanni</forenames></author><author><keyname>Grossi</keyname><forenames>Roberto</forenames></author><author><keyname>Scutell&#xe0;</keyname><forenames>Noemi</forenames></author></authors><title>Consecutive Ones Property and PQ-Trees for Multisets: Hardness of
  Counting Their Orderings</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A binary matrix satisfies the consecutive ones property (COP) if its columns
can be permuted such that the ones in each row of the resulting matrix are
consecutive. Equivalently, a family of sets F = {Q_1,..,Q_m}, where Q_i is
subset of R for some universe R, satisfies the COP if the symbols in R can be
permuted such that the elements of each set Q_i occur consecutively, as a
contiguous segment of the permutation of R's symbols. We consider the COP
version on multisets and prove that counting its solutions is difficult
(#P-complete). We prove completeness results also for counting the frontiers of
PQ-trees, which are typically used for testing the COP on sets, thus showing
that a polynomial algorithm is unlikely to exist when dealing with multisets.
We use a combinatorial approach based on parsimonious reductions from the
Hamiltonian path problem, showing that the decisional version of our problems
is therefore NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0043</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0043</id><created>2011-01-31</created><authors><author><keyname>Tian</keyname><forenames>Ye</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>The Gaussian Interference Relay Channel: Improved Achievable Rates and
  Sum Rate Upperbounds Using a Potent Relay</title><categories>cs.IT math.IT</categories><comments>35 pages, 9 figures, to appear in IEEE Transactions on Information
  Theory, Special Issue on Interference Networks, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Gaussian interference channel with an intermediate relay as a
main building block for cooperative interference networks. On the achievability
side, we consider compress-and-forward based strategies. Specifically, a
generalized compress-and-forward strategy, where the destinations jointly
decode the compression indices and the source messages, is shown to improve
upon the compress-and-forward strategy which sequentially decodes the
compression indices and source messages, and the recently proposed generalized
hash-and-forward strategy. We also construct a nested lattice code based
compute-and-forward relaying scheme, which outperforms other relaying schemes
when the direct link is weak. In this case, it is shown that, with a relay, the
interference link can be useful for decoding the source messages. Noting the
need for upperbounding the capacity for this channel, we propose a new
technique with which the sum rate can be bounded. In particular, the sum
capacity is upperbounded by considering the channel when the relay node has
abundant power and is named potent for that reason. For the Gaussian
interference relay channel with potent relay, we study the strong and the weak
interference regimes and establish the sum capacity, which, in turn, serve as
upperbounds for the sum capacity of the GIFRC with finite relay power.
Numerical results demonstrate that upperbounds are tighter than the cut-set
bound, and coincide with known achievable sum rates for many scenarios of
interest. Additionally, the degrees of freedom of the GIFRC are shown to be 2
when the relay has large power, achievable using compress-and-forward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0048</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0048</id><created>2011-01-31</created><updated>2011-04-18</updated><authors><author><keyname>Mottelet</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Germain</keyname><forenames>Luc de Saint</forenames></author><author><keyname>Mondin</keyname><forenames>Olivier</forenames></author></authors><title>Smart depth of field optimization applied to a robotised view camera</title><categories>math.OC cs.CV cs.RO</categories><comments>17 pages, 19 figures</comments><doi>10.1007/s10851-011-0306-y</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The great flexibility of a view camera allows to take high quality
photographs that would not be possible any other way. But making a given object
into focus is a long and tedious task, although the underlying laws are well
known. This paper presents the result of a project which has lead to the design
of a computer controlled view camera and to its companion software. Thanks to
the high precision machining of its components, and to the known optical
parameters of lenses and sensor, we have been able to consider a reliable
mathematical model of the view camera, allowing the acquisition of 3D
coordinates to build a geometrical model of the object. Then many problems can
be solved, e.g. minimizing the f-number while maintaining the object within the
depth of field, which takes the form of a constrained optimization problem. All
optimization algorithms have been validated on a virtual view camera before
implementation on the prototype
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0058</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0058</id><created>2011-01-31</created><updated>2011-02-02</updated><authors><author><keyname>Akribopoulos</keyname><forenames>Orestis</forenames></author><author><keyname>Georgitzikis</keyname><forenames>Vasileios</forenames></author><author><keyname>Koninis</keyname><forenames>Christos</forenames></author><author><keyname>Papavasileiou</keyname><forenames>Ioannis</forenames></author><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author></authors><title>Deployment and Evaluation of a 802.15.4 Heterogeneous Network</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study the performance of a heterogeneous wireless sensor
network which consists of 4 different hardware platforms (TelosB, SunSPOT,
Arduino, iSense). All hardware platforms use 802.15.4 compliant radios. Due to
partial implementation of the standard, they do not communicate out of the box.
A first contribution of our work is a careful description of the necessary
steps to make such a heterogeneous network interoperate. Our software code is
available online. We deploy a heterogeneous network testbed and conduct a
thorough evaluation of the performance. We examine various network performance
metrics (e.g., transmission rate, receiving rate, packet loss, etc.), and
assess the capabilities of each device and their intercommunication. We used
different setups (e.g., distance between transmitters and receivers, etc.) to
better understand the network limitations for each hardware platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0059</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0059</id><created>2011-01-31</created><updated>2012-10-01</updated><authors><author><keyname>Yan</keyname><forenames>Donghui</forenames></author><author><keyname>Wang</keyname><forenames>Pei</forenames></author><author><keyname>Linden</keyname><forenames>Michael</forenames></author><author><keyname>Knudsen</keyname><forenames>Beatrice</forenames></author><author><keyname>Randolph</keyname><forenames>Timothy</forenames></author></authors><title>Statistical methods for tissue array images - algorithmic scoring and
  co-training</title><categories>stat.ME cs.CE cs.CV cs.LG q-bio.QM</categories><comments>Published in at http://dx.doi.org/10.1214/12-AOAS543 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS543</report-no><journal-ref>Annals of Applied Statistics 2012, Vol. 6, No. 3, 1280-1305</journal-ref><doi>10.1214/12-AOAS543</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in tissue microarray technology have allowed
immunohistochemistry to become a powerful medium-to-high throughput analysis
tool, particularly for the validation of diagnostic and prognostic biomarkers.
However, as study size grows, the manual evaluation of these assays becomes a
prohibitive limitation; it vastly reduces throughput and greatly increases
variability and expense. We propose an algorithm - Tissue Array Co-Occurrence
Matrix Analysis (TACOMA) - for quantifying cellular phenotypes based on
textural regularity summarized by local inter-pixel relationships. The
algorithm can be easily trained for any staining pattern, is absent of
sensitive tuning parameters and has the ability to report salient pixels in an
image that contribute to its score. Pathologists' input via informative
training patches is an important aspect of the algorithm that allows the
training for any specific marker or cell type. With co-training, the error rate
of TACOMA can be reduced substantially for a very small training sample (e.g.,
with size 30). We give theoretical insights into the success of co-training via
thinning of the feature set in a high-dimensional setting when there is
&quot;sufficient&quot; redundancy among the features. TACOMA is flexible, transparent and
provides a scoring process that can be evaluated with clarity and confidence.
In a study based on an estrogen receptor (ER) marker, we show that TACOMA is
comparable to, or outperforms, pathologists' performance in terms of accuracy
and repeatability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0072</identifier>
 <datestamp>2012-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0072</id><created>2011-01-31</created><authors><author><keyname>Alexeev</keyname><forenames>Boris</forenames></author><author><keyname>Forbes</keyname><forenames>Michael</forenames></author><author><keyname>Tsimerman</keyname><forenames>Jacob</forenames></author></authors><title>Tensor Rank: Some Lower and Upper Bounds</title><categories>cs.CC</categories><comments>27 pages</comments><msc-class>68Q17 (Primary), 68W30 (Secondary)</msc-class><acm-class>F.2.1</acm-class><journal-ref>IEEE Conference on Computational Complexity 26 (2011), 283-291</journal-ref><doi>10.1109/CCC.2011.28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The results of Strassen and Raz show that good enough tensor rank lower
bounds have implications for algebraic circuit/formula lower bounds.
  We explore tensor rank lower and upper bounds, focusing on explicit tensors.
For odd d, we construct field-independent explicit 0/1 tensors T:[n]^d-&gt;F with
rank at least 2n^(floor(d/2))+n-Theta(d log n). This matches (over F_2) or
improves (all other fields) known lower bounds for d=3 and improves (over any
field) for odd d&gt;3.
  We also explore a generalization of permutation matrices, which we denote
permutation tensors. We show, by counting, that there exists an order-3
permutation tensor with super-linear rank. We also explore a natural class of
permutation tensors, which we call group tensors. For any group G, we define
the group tensor T_G^d:G^d-&gt;F, by T_G^d(g_1,...,g_d)=1 iff g_1 x ... x g_d=1_G.
We give two upper bounds for the rank of these tensors. The first uses
representation theory and works over large fields F, showing (among other
things) that rank_F(T_G^d)&lt;= |G|^(d/2). We also show that if this upper bound
is tight, then super-linear tensor rank lower bounds would follow. The second
upper bound uses interpolation and only works for abelian G, showing that over
any field F that rank_F(T_G^d)&lt;= O(|G|^(1+log d)log^(d-1)|G|). In either case,
this shows that many permutation tensors have far from maximal rank, which is
very different from the matrix case and thus eliminates many natural candidates
for high tensor rank.
  We also explore monotone tensor rank. We give explicit 0/1 tensors T:[n]^d-&gt;F
that have tensor rank at most dn but have monotone tensor rank exactly n^(d-1).
This is a nearly optimal separation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0079</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0079</id><created>2011-02-01</created><authors><author><keyname>Zhu</keyname><forenames>Ping</forenames></author><author><keyname>Wen</keyname><forenames>Qiaoyan</forenames></author></authors><title>Information-theoretic measures associated with rough set approximations</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although some information-theoretic measures of uncertainty or granularity
have been proposed in rough set theory, these measures are only dependent on
the underlying partition and the cardinality of the universe, independent of
the lower and upper approximations. It seems somewhat unreasonable since the
basic idea of rough set theory aims at describing vague concepts by the lower
and upper approximations. In this paper, we thus define new
information-theoretic entropy and co-entropy functions associated to the
partition and the approximations to measure the uncertainty and granularity of
an approximation space. After introducing the novel notions of entropy and
co-entropy, we then examine their properties. In particular, we discuss the
relationship of co-entropies between different universes. The theoretical
development is accompanied by illustrative numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0099</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0099</id><created>2011-02-01</created><authors><author><keyname>Echtermeyer</keyname><forenames>Christoph</forenames></author><author><keyname>Costa</keyname><forenames>Luciano da Fontoura</forenames></author><author><keyname>Rodrigues</keyname><forenames>Francisco A.</forenames></author><author><keyname>Kaiser</keyname><forenames>Marcus</forenames></author></authors><title>Automatic Network Fingerprinting through Single-Node Motifs</title><categories>physics.soc-ph cs.SI q-bio.QM</categories><comments>16 pages (4 figures) plus supporting information 8 pages (5 figures)</comments><journal-ref>Echtermeyer C, da Fontoura Costa L, Rodrigues FA, Kaiser M (2011)
  Automatic Network Fingerprinting through Single-Node Motifs. PLoS ONE 6(1):
  e15765</journal-ref><doi>10.1371/journal.pone.0015765</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Complex networks have been characterised by their specific connectivity
patterns (network motifs), but their building blocks can also be identified and
described by node-motifs---a combination of local network features. One
technique to identify single node-motifs has been presented by Costa et al. (L.
D. F. Costa, F. A. Rodrigues, C. C. Hilgetag, and M. Kaiser, Europhys. Lett.,
87, 1, 2009). Here, we first suggest improvements to the method including how
its parameters can be determined automatically. Such automatic routines make
high-throughput studies of many networks feasible. Second, the new routines are
validated in different network-series. Third, we provide an example of how the
method can be used to analyse network time-series. In conclusion, we provide a
robust method for systematically discovering and classifying characteristic
nodes of a network. In contrast to classical motif analysis, our approach can
identify individual components (here: nodes) that are specific to a network.
Such special nodes, as hubs before, might be found to play critical roles in
real-world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0115</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0115</id><created>2011-02-01</created><authors><author><keyname>Grabova</keyname><forenames>Oksana</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author><author><keyname>Chauchat</keyname><forenames>Jean-Hugues</forenames><affiliation>ERIC</affiliation></author><author><keyname>Zolotaryova</keyname><forenames>Iryna</forenames></author></authors><title>Business Intelligence for Small and Middle-Sized Entreprises</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>SIGMOD Record 39, 2 (2010) 39-50</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data warehouses are the core of decision support sys- tems, which nowadays
are used by all kind of enter- prises in the entire world. Although many
studies have been conducted on the need of decision support systems (DSSs) for
small businesses, most of them adopt ex- isting solutions and approaches, which
are appropriate for large-scaled enterprises, but are inadequate for small and
middle-sized enterprises. Small enterprises require cheap, lightweight
architec- tures and tools (hardware and software) providing on- line data
analysis. In order to ensure these features, we review web-based business
intelligence approaches. For real-time analysis, the traditional OLAP
architecture is cumbersome and storage-costly; therefore, we also re- view
in-memory processing. Consequently, this paper discusses the existing approa-
ches and tools working in main memory and/or with web interfaces (including
freeware tools), relevant for small and middle-sized enterprises in decision
making.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0144</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0144</id><created>2011-02-01</created><authors><author><keyname>Prasad</keyname><forenames>Peeyush</forenames></author><author><keyname>Subrahmanya</keyname><forenames>C. R.</forenames></author></authors><title>A High Speed Networked Signal Processing Platform for Multi-element
  Radio Telescopes</title><categories>astro-ph.IM cs.DC</categories><comments>19 pages, 4 eps figures, To be published in Experimental Astronomy
  (Springer)</comments><doi>10.1007/s10686-011-9216-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new architecture is presented for a Networked Signal Processing System
(NSPS) suitable for handling the real-time signal processing of multi-element
radio telescopes. In this system, a multi-element radio telescope is viewed as
an application of a multi-sensor, data fusion problem which can be decomposed
into a general set of computing and network components for which a practical
and scalable architecture is enabled by current technology. The need for such a
system arose in the context of an ongoing program for reconfiguring the Ooty
Radio Telescope (ORT) as a programmable 264-element array, which will enable
several new observing capabilities for large scale surveys on this mature
telescope. For this application, it is necessary to manage, route and combine
large volumes of data whose real-time collation requires large I/O bandwidths
to be sustained. Since these are general requirements of many multi-sensor
fusion applications, we first describe the basic architecture of the NSPS in
terms of a Fusion Tree before elaborating on its application for the ORT. The
paper addresses issues relating to high speed distributed data acquisition,
Field Programmable Gate Array (FPGA) based peer-to-peer networks supporting
significant on-the fly processing while routing, and providing a last mile
interface to a typical commodity network like Gigabit Ethernet. The system is
fundamentally a pair of two co-operative networks, among which one is part of a
commodity high performance computer cluster and the other is based on
Commercial-Off The-Shelf (COTS) technology with support from software/firmware
components in the public domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0151</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0151</id><created>2011-02-01</created><updated>2012-07-13</updated><authors><author><keyname>Habert</keyname><forenames>Luc</forenames></author><author><keyname>Pocchiola</keyname><forenames>Michel</forenames></author></authors><title>Computing pseudotriangulations via branched coverings</title><categories>cs.CG math.CO</categories><comments>66 pages, 39 figures</comments><msc-class>52C30, 52A10, 52C40, 68-04, 68U05, 68R05</msc-class><journal-ref>Discrete Comput. Geom. 48(3):518-579, 2012</journal-ref><doi>10.1007/s00454-012-9447-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an efficient algorithm to compute a pseudotriangulation of a
finite planar family of pairwise disjoint convex bodies presented by its
chirotope. The design of the algorithm relies on a deepening of the theory of
visibility complexes and on the extension of that theory to the setting of
branched coverings. The problem of computing a pseudotriangulation that
contains a given set of bitangent line segments is also examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0155</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0155</id><created>2011-02-01</created><authors><author><keyname>Dekkers</keyname><forenames>Wil</forenames></author></authors><title>Weak mu-equality is decidable</title><categories>cs.LO cs.PL</categories><comments>11 pages</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the set of mu-types, an extension of the set of
simple types freely generated from a set of atomic types and the type
constructor -&gt;, by a new operator mu, to explicitly denote solutions of
recursive equations like A = A -&gt; beta. We show that this so-called weak
mu-equality for mu-types is decidable by defining a derivation system for weak
mu-equality based on standard reduction for mu-types such that the number of
nodes in a derivation tree for A = B is bounded as a function of A, B. We give
two proofs. One for decidability of = for alpha-equivalence classes of mu-types
and one for = for mu-types theselves. Both proofs are straightforward and
elementary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0160</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0160</id><created>2011-02-01</created><authors><author><keyname>Liu</keyname><forenames>Tingting</forenames></author><author><keyname>Jiang</keyname><forenames>Chengling</forenames></author></authors><title>Optimal Band Allocation for Cognitive Cellular Networks</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  FCC new regulation for cognitive use of the TV white space spectrum provides
a new means for improving traditional cellular network performance. But it also
introduces a number of technical challenges. This letter studies one of the
challenges, that is, given the significant differences in the propagation
property and the transmit power limitations between the cellular band and the
TV white space, how to jointly utilize both bands such that the benefit from
the TV white space for improving cellular network performance is maximized.
Both analytical and simulation results are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0183</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0183</id><created>2011-02-01</created><authors><author><keyname>Cire&#x15f;an</keyname><forenames>Dan C.</forenames></author><author><keyname>Meier</keyname><forenames>Ueli</forenames></author><author><keyname>Masci</keyname><forenames>Jonathan</forenames></author><author><keyname>Gambardella</keyname><forenames>Luca M.</forenames></author><author><keyname>Schmidhuber</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>High-Performance Neural Networks for Visual Object Classification</title><categories>cs.AI cs.NE</categories><comments>12 pages, 2 figures, 5 tables</comments><report-no>IDSIA 1-11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a fast, fully parameterizable GPU implementation of Convolutional
Neural Network variants. Our feature extractors are neither carefully designed
nor pre-wired, but rather learned in a supervised way. Our deep hierarchical
architectures achieve the best published results on benchmarks for object
classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with
error rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple
back-propagation perform better than more shallow ones. Learning is
surprisingly rapid. NORB is completely trained within five epochs. Test error
rates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0200</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0200</id><created>2011-02-01</created><updated>2011-05-26</updated><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author><author><keyname>Luo</keyname><forenames>Feng</forenames></author></authors><title>Harmonic Functions for Data Reconstruction on 3D Manifolds</title><categories>math.NA cs.GR</categories><comments>12 pages, 8 figures, add algorithm analysis</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In computer graphics, smooth data reconstruction on 2D or 3D manifolds
usually refers to subdivision problems. Such a method is only valid based on
dense sample points. The manifold usually needs to be triangulated into meshes
(or patches) and each node on the mesh will have an initial value. While the
mesh is refined the algorithm will provide a smooth function on the redefined
manifolds. However, when data points are not dense and the original mesh is not
allowed to be changed, how is the &quot;continuous and/or smooth&quot; reconstruction
possible? This paper will present a new method using harmonic functions to
solve the problem. Our method contains the following steps: (1) Partition the
boundary surfaces of the 3D manifold based on sample points so that each sample
point is on the edge of the partition. (2) Use gradually varied interpolation
on the edges so that each point on edge will be assigned a value. In addition,
all values on the edge are gradually varied. (3) Use discrete harmonic function
to fit the unknown points, i.e. the points inside each partition patch.
  The fitted function will be a harmonic or a local harmonic function in each
partitioned area. The function on edge will be &quot;near&quot; continuous (or &quot;near&quot;
gradually varied). If we need a smoothed surface on the manifold, we can apply
subdivision algorithms. This paper has also a philosophical advantage over
triangulation meshes. People usually use triangulation for data reconstruction.
This paper employs harmonic functions, a generalization of triangulation
because linearity is a form of harmonic. Therefore, local harmonic
initialization is more sophisticated then triangulation. This paper is a
conceptual and methodological paper. This paper does not focus on detailed
mathematical analysis nor fine algorithm design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0203</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0203</id><created>2011-02-01</created><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author></authors><title>A Primer on Strategic Games</title><categories>cs.GT</categories><comments>33 pages, appeared as Chapter 1 in Lectures in Game Theory for
  Computer Scientists, K.R. Apt and E. Graedel (editors), Cambridge University
  Press (2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a short introduction to the subject of strategic games. We focus on
the concepts of best response, Nash equilibrium, strict and weak dominance, and
mixed strategies, and study the relation between these concepts in the context
of the iterated elimination of strategies. Also, we discuss some variants of
the original definition of a strategic game. Finally, we introduce the basics
of mechanism design and use pre-Bayesian games to explain it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0204</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0204</id><created>2011-02-01</created><updated>2013-09-17</updated><authors><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames></author><author><keyname>Straub</keyname><forenames>Gilles</forenames></author><author><keyname>Scouarnec</keyname><forenames>Nicolas Le</forenames></author></authors><title>Repairing Multiple Failures with Coordinated and Adaptive Regenerating
  Codes</title><categories>cs.IT cs.DC math.IT</categories><comments>Update to previous version adding (i) study of lazy repairs, (ii)
  adaptive codes at the MBR point, and (iii) discussion of related work.
  Extended from a regular paper at NetCod 2011 available at
  http://dx.doi.org/10.1109/ISNETCOD.2011.5978920 . First version: &quot;Beyond
  Regenerating Codes&quot;, September 2010 on http://hal.inria.fr/inria-00516647/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Erasure correcting codes are widely used to ensure data persistence in
distributed storage systems. This paper addresses the simultaneous repair of
multiple failures in such codes. We go beyond existing work (i.e., regenerating
codes by Dimakis et al.) by describing (i) coordinated regenerating codes (also
known as cooperative regenerating codes) which support the simultaneous repair
of multiple devices, and (ii) adaptive regenerating codes which allow adapting
the parameters at each repair. Similarly to regenerating codes by Dimakis et
al., these codes achieve the optimal tradeoff between storage and the repair
bandwidth. Based on these extended regenerating codes, we study the impact of
lazy repairs applied to regenerating codes and conclude that lazy repairs
cannot reduce the costs in term of network bandwidth but allow reducing the
disk-related costs (disk bandwidth and disk I/O).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0230</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0230</id><created>2011-02-01</created><authors><author><keyname>Ghosh</keyname><forenames>Arup Kumar</forenames><affiliation>School of EECS, University of Central Florida</affiliation></author></authors><title>Speeding up SAT solver by exploring CNF symmetries : Revisited</title><categories>math.CO cs.AI</categories><comments>12 pages, Forty-First Southeastern International Conference on
  Combinatorics, Graph Theory, and Computing (USA, 2010)</comments><msc-class>68R10</msc-class><journal-ref>Congressus Numerantium 206 (2010), pp. 73-84</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boolean Satisfiability solvers have gone through dramatic improvements in
their performances and scalability over the last few years by considering
symmetries. It has been shown that by using graph symmetries and generating
symmetry breaking predicates (SBPs) it is possible to break symmetries in
Conjunctive Normal Form (CNF). The SBPs cut down the search space to the
nonsymmetric regions of the space without affecting the satisfiability of the
CNF formula. The symmetry breaking predicates are created by representing the
formula as a graph, finding the graph symmetries and using some symmetry
extraction mechanism (Crawford et al.). Here in this paper we take one
non-trivial CNF and explore its symmetries. Finally, we generate the SBPs and
adding it to CNF we show how it helps to prune the search tree, so that SAT
solver would take short time. Here we present the pruning procedure of the
search tree from scratch, starting from the CNF and its graph representation.
As we explore the whole mechanism by a non-trivial example, it would be easily
comprehendible. Also we have given a new idea of generating symmetry breaking
predicates for breaking symmetry in CNF, not derived from Crawford's
conditions. At last we propose a backtrack SAT solver with inbuilt SBP
generator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0240</identifier>
 <datestamp>2013-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0240</id><created>2011-02-01</created><updated>2013-10-28</updated><authors><author><keyname>Rothenberg</keyname><forenames>Robert</forenames></author></authors><title>Translating Labels to Hypersequents for Intermediate Logics with
  Geometric Kripke Semantics</title><categories>math.LO cs.LO</categories><comments>19 pages, 5 figures, 1 table, longer versions of proofs from
  conference paper and journal submission</comments><msc-class>03F03</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a procedure for translating geometric Kripke frame axioms into
structural hypersequent rules for the corresponding intermediate logics in
Int^*/Geo that admit weakening, contraction and in some cases, cut. We give a
procedure for translating labelled sequents in the corresponding logic to
hypersequents that share the same linear models (which correspond to
G\&quot;odel-Dummett logic). We prove that labelled proofs Int^*/Geo can be
translated into hypersequent proofs that may use the linearity rule, which
corresponds to the well-known communication rule for G\&quot;odel-Dummett logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0250</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0250</id><created>2011-02-01</created><authors><author><keyname>Gorantla</keyname><forenames>Siva</forenames></author><author><keyname>Coleman</keyname><forenames>Todd</forenames></author></authors><title>Information-Theoretic Viewpoints on Optimal Causal Coding-Decoding
  Problems</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider an interacting two-agent sequential decision-making
problem consisting of a Markov source process, a causal encoder with feedback,
and a causal decoder. Motivated by a desire to foster links between control and
information theory, we augment the standard formulation by considering general
alphabets and a cost function operating on current and previous symbols. Using
dynamic programming, we provide a structural result whereby an optimal scheme
exists that operates on appropriate sufficient statistics. We emphasize an
example where the decoder alphabet lies in a space of beliefs on the source
alphabet, and the additive cost function is a log likelihood ratio pertaining
to sequential information gain. We also consider the inverse optimal control
problem, where a fixed encoder/decoder pair satisfying statistical conditions
is shown to be optimal for some cost function, using probabilistic matching. We
provide examples of the applicability of this framework to communication with
feedback, hidden Markov models and the nonlinear filter, decentralized control,
brain-machine interfaces, and queuing theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0257</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0257</id><created>2011-02-01</created><authors><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author><author><keyname>Amblard</keyname><forenames>Frederic</forenames></author></authors><title>Emergence through Selection: The Evolution of a Scientific Challenge</title><categories>cs.SI cs.AI math.DS physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most interesting scientific challenges nowadays deals with the
analysis and the understanding of complex networks' dynamics and how their
processes lead to emergence according to the interactions among their
components. In this paper we approach the definition of new methodologies for
the visualization and the exploration of the dynamics at play in real dynamic
social networks. We present a recently introduced formalism called TVG (for
time-varying graphs), which was initially developed to model and analyze
highly-dynamic and infrastructure-less communication networks such as mobile
ad-hoc networks, wireless sensor networks, or vehicular networks. We discuss
its applicability to complex networks in general, and social networks in
particular, by showing how it enables the specification and analysis of complex
dynamic phenomena in terms of temporal interactions, and allows to easily
switch the perspective between local and global dynamics. As an example, we
chose the case of scientific communities by analyzing portion of the ArXiv
repository (ten years of publications in physics) focusing on the social
determinants (e.g. goals and potential interactions among individuals) behind
the emergence and the resilience of scientific communities. We consider that
scientific communities are at the same time communities of practice (through
co-authorship) and that they exist also as representations in the scientists'
mind, since references to other scientists' works is not merely an objective
link to a relevant work, but it reveals social objects that one manipulates,
select and refers to. In the paper we show the emergence/selection of a
community as a goal-driven preferential attachment toward a set of authors
among which there are some key scientists (Nobel prizes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0264</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0264</id><created>2011-02-01</created><updated>2011-11-29</updated><authors><author><keyname>Abramsky</keyname><forenames>Samson</forenames></author><author><keyname>Brandenburger</keyname><forenames>Adam</forenames></author></authors><title>The Sheaf-Theoretic Structure Of Non-Locality and Contextuality</title><categories>quant-ph cs.LO math.CT</categories><comments>33 pages. Extensively revised, new results included. Published in New
  Journal of Physics</comments><journal-ref>New Journal of Physics 13 (2011) 113036</journal-ref><doi>10.1088/1367-2630/13/11/113036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the mathematical language of sheaf theory to give a unified treatment
of non-locality and contextuality, in a setting which generalizes the familiar
probability tables used in non-locality theory to arbitrary measurement covers;
this includes Kochen-Specker configurations and more. We show that
contextuality, and non-locality as a special case, correspond exactly to
obstructions to the existence of global sections. We describe a linear
algebraic approach to computing these obstructions, which allows a systematic
treatment of arguments for non-locality and contextuality. We distinguish a
proper hierarchy of strengths of no-go theorems, and show that three leading
examples --- due to Bell, Hardy, and Greenberger, Horne and Zeilinger,
respectively --- occupy successively higher levels of this hierarchy. A general
correspondence is shown between the existence of local hidden-variable
realizations using negative probabilities, and no-signalling; this is based on
a result showing that the linear subspaces generated by the non-contextual and
no-signalling models, over an arbitrary measurement cover, coincide. Maximal
non-locality is generalized to maximal contextuality, and characterized in
purely qualitative terms, as the non-existence of global sections in the
support. A general setting is developed for Kochen-Specker type results, as
generic, model-independent proofs of maximal contextuality, and a new
combinatorial condition is given, which generalizes the `parity proofs'
commonly found in the literature. We also show how our abstract setting can be
represented in quantum mechanics. This leads to a strengthening of the usual
no-signalling theorem, which shows that quantum mechanics obeys no-signalling
for arbitrary families of commuting observables, not just those represented on
different factors of a tensor product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0267</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0267</id><created>2011-02-01</created><updated>2013-02-15</updated><authors><author><keyname>Karmakar</keyname><forenames>Sanjay</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>The Capacity Region of the MIMO Interference Channel and its Reciprocity
  to Within a Constant Gap</title><categories>cs.IT math.IT</categories><comments>22 pages, 5 figures, accepted in Trans. on Inform. Th</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity region of the 2-user multi-input multi-output (MIMO) Gaussian
interference channel (IC) is characterized to within a constant gap that is
independent of the channel matrices for the general case of the MIMO IC with an
arbitrary number of antennas at each node. An achievable rate region and an
outer bound to the capacity region of a class of interference channels were
obtained in previous work by Telatar and Tse as unions over all possible input
distributions. In contrast to that previous work on the MIMO IC, a simple and
an explicit achievable coding scheme are obtained here and shown to have the
constant-gap-to-capacity property and in which the sub-rates of the common and
private messages of each user are explicitly specified for each achievable rate
pair. The constant-gap-to-capacity results are thus proved in this work by
first establishing explicit upper and lower bounds to the capacity region. A
reciprocity result is also proved which is that the capacity of the reciprocal
MIMO IC is within a constant gap of the capacity region of the forward MIMO IC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0309</identifier>
 <datestamp>2011-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0309</id><created>2011-02-01</created><updated>2011-07-14</updated><authors><author><keyname>Dress</keyname><forenames>A. W. M.</forenames></author><author><keyname>Huber</keyname><forenames>K. T.</forenames></author><author><keyname>Steel</keyname><forenames>M.</forenames></author></authors><title>`Lassoing' a phylogenetic tree I: Basic properties, shellings, and
  covers</title><categories>q-bio.PE cs.CE cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classical result, fundamental to evolutionary biology, states that an
edge-weighted tree $T$ with leaf set $X$, positive edge weights, and no
vertices of degree 2 can be uniquely reconstructed from the set of leaf-to-leaf
distances between any two elements of $X$. In biology, $X$ corresponds to a set
of taxa (e.g. extant species), the tree $T$ describes their phylogenetic
relationships, the edges correspond to earlier species evolving for a time
until splitting in two or more species by some speciation/bifurcation event,
and their length corresponds to the genetic change accumulating over that time
in such a species. In this paper, we investigate which subsets of
$\binom{X}{2}$ suffice to determine (`lasso') a tree from the leaf-to-leaf
distances induced by that tree. The question is particularly topical since
reliable estimates of genetic distance - even (if not in particular) by modern
mass-sequencing methods - are, in general, available only for certain
combinations of taxa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0316</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0316</id><created>2011-02-01</created><authors><author><keyname>Forney,</keyname><forenames>G. David</forenames><suffix>Jr.</suffix></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Partition Functions of Normal Factor Graphs</title><categories>cs.IT math.IT</categories><comments>8 pages, 17 figures. To be presented at 2011 Information Theory and
  Applications Workshop, La Jolla, CA, February 7, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most common types of functions in mathematics, physics, and
engineering is a sum of products, sometimes called a partition function. After
&quot;normalization,&quot; a sum of products has a natural graphical representation,
called a normal factor graph (NFG), in which vertices represent factors, edges
represent internal variables, and half-edges represent the external variables
of the partition function. In physics, so-called trace diagrams share similar
features. We believe that the conceptual framework of representing sums of
products as partition functions of NFGs is an important and intuitive paradigm
that, surprisingly, does not seem to have been introduced explicitly in the
previous factor graph literature. Of particular interest are NFG modifications
that leave the partition function invariant. A simple subclass of such NFG
modifications offers a unifying view of the Fourier transform, tree-based
reparameterization, loop calculus, and the Legendre transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0333</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0333</id><created>2011-02-01</created><authors><author><keyname>McIver</keyname><forenames>Annabelle</forenames></author><author><keyname>Meinicke</keyname><forenames>Larissa</forenames></author><author><keyname>Morgan</keyname><forenames>Carroll</forenames></author></authors><title>Hidden-Markov Program Algebra with iteration</title><categories>cs.CR</categories><doi>10.1017/S0960129513000625</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use Hidden Markov Models to motivate a quantitative compositional
semantics for noninterference-based security with iteration, including a
refinement- or &quot;implements&quot; relation that compares two programs with respect to
their information leakage; and we propose a program algebra for source-level
reasoning about such programs, in particular as a means of establishing that an
&quot;implementation&quot; program leaks no more than its &quot;specification&quot; program.
&lt;p&gt;This joins two themes: we extend our earlier work, having iteration but only
qualitative, by making it quantitative; and we extend our earlier quantitative
work by including iteration. &lt;p&gt;We advocate stepwise refinement and
source-level program algebra, both as conceptual reasoning tools and as targets
for automated assistance. A selection of algebraic laws is given to support
this view in the case of quantitative noninterference; and it is demonstrated
on a simple iterated password-guessing attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0365</identifier>
 <datestamp>2012-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0365</id><created>2011-02-02</created><updated>2012-04-12</updated><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author></authors><title>Limit Theorems in Hidden Markov Models</title><categories>cs.IT math.IT</categories><comments>35 pages</comments><msc-class>60F05, 60F15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, under mild assumptions, we derive a law of large numbers, a
central limit theorem with an error estimate, an almost sure invariance
principle and a variant of Chernoff bound in finite-state hidden Markov models.
These limit theorems are of interest in certain ares in statistics and
information theory. Particularly, we apply the limit theorems to derive the
rate of convergence of the maximum likelihood estimator in finite-state hidden
Markov models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0371</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0371</id><created>2011-02-02</created><authors><author><keyname>Ndeko</keyname><forenames>Jean Marie Moanda</forenames></author><author><keyname>Mongo</keyname><forenames>Junior Jugis Bakola</forenames></author></authors><title>Synthese des Controleurs Optimaux pour les Systemes a Evenements
  Discrets</title><categories>cs.FL cs.SY</categories><comments>l'article pr\'esent\'e \`a 6 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the problem of synthesizing optimal controllers
for discrete event systems and we propose a procedure for solving this problem,
where the method and specifications are represented by finite state automata
and with increasing complexity. We will subscribe to the synthetic methodology
by the control theory initiated by supervision by Ramadge and Wonham. For an
illustration on a simple example, then a model with a complexity high. In this
spirit, languages, methods and tools development used to specify and
development must reach a level of quality to meet the requirements expressed.
Face this situation, we are helping in this work the systematic use of formal
methods in systems development cycles in the equipping and adapting the UML
(Unified Modeling Language) which is the most exploited in industrial projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0372</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0372</id><created>2011-02-02</created><authors><author><keyname>Mahboubi</keyname><forenames>Hadj</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>XWeB: the XML Warehouse Benchmark</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>2nd TPC Technology Conference on Performance Evaluation \&amp;
  Benchmarking (VLDB/TPCTC 10), Singapore : Singapore (2010)</journal-ref><doi>10.1007/978-3-642-18206-8_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the emergence of XML as a standard for representing business data, new
decision support applications are being developed. These XML data warehouses
aim at supporting On-Line Analytical Processing (OLAP) operations that
manipulate irregular XML data. To ensure feasibility of these new tools,
important performance issues must be addressed. Performance is customarily
assessed with the help of benchmarks. However, decision support benchmarks do
not currently support XML features. In this paper, we introduce the XML
Warehouse Benchmark (XWeB), which aims at filling this gap. XWeB derives from
the relational decision support benchmark TPC-H. It is mainly composed of a
test data warehouse that is based on a unified reference model for XML
warehouses and that features XML-specific structures, and its associate XQuery
decision support workload. XWeB's usage is illustrated by experiments on
several XML database management systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0378</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0378</id><created>2011-02-02</created><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author></authors><title>Classical and quantum computation with small space bounds (PhD thesis)</title><categories>cs.CC quant-ph</categories><comments>Bogazici University (Istanbul) PhD thesis, 183 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this thesis, we introduce a new quantum Turing machine (QTM) model that
supports general quantum operators, together with its pushdown, counter, and
finite automaton variants, and examine the computational power of classical and
quantum machines using small space bounds in many different cases. The main
contributions are summarized below.
  Firstly, we consider QTMs in the unbounded error setting: (i) in some cases
of sublogarithmic space bounds, the class of languages recognized by QTMs is
shown to be strictly larger than that of classical ones; (ii) in constant space
bounds, the same result can still be obtained for restricted QTMs; (iii) the
complete characterization of the class of languages recognized by realtime
constant space nondeterministic QTMs is given.
  Secondly, we consider constant space-bounded QTMs in the bounded error
setting: (i) we introduce a new type of quantum and probabilistic finite
automata (QFAs and PFAs, respectively,) with a special two-way input head which
is not allowed to be stationary or move to the left but has the capability to
reset itself to its starting position; (ii) the computational power of this
type of quantum machine is shown to be superior to that of the probabilistic
machine; (iii) based on these models, two-way PFAs and two-way classical-head
QFAs are shown to be more succinct than two-way nondeterministic finite
automata and their one-way variants; (iv) we also introduce PFAs and QFAs with
postselection with their bounded error language classes, and give many
characterizations of them.
  Thirdly, the computational power of realtime QFAs augmented with a write-only
memory is investigated by showing many simulation results for different kinds
of counter automata.
  Finally, some lower bounds of realtime classical Turing machines in order to
recognize a nonregular language are shown to be tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0395</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0395</id><created>2011-02-02</created><authors><author><keyname>Fischer</keyname><forenames>Johannes</forenames></author></authors><title>Combined Data Structure for Previous- and Next-Smaller-Values</title><categories>cs.DS</categories><comments>to appear in Theoretical Computer Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $A$ be a static array storing $n$ elements from a totally ordered set. We
present a data structure of optimal size at most $n\log_2(3+2\sqrt{2})+o(n)$
bits that allows us to answer the following queries on $A$ in constant time,
without accessing $A$: (1) previous smaller value queries, where given an index
$i$, we wish to find the first index to the left of $i$ where $A$ is strictly
smaller than at $i$, and (2) next smaller value queries, which search to the
right of $i$. As an additional bonus, our data structure also allows to answer
a third kind of query: given indices $i&lt;j$, find the position of the minimum in
$A[i..j]$. Our data structure has direct consequences for the space-efficient
storage of suffix trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0401</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0401</id><created>2011-02-02</created><updated>2011-02-07</updated><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Vertices Belonging to All Critical Independent Sets of a Graph</title><categories>cs.DM math.CO</categories><comments>9 pages; 4 figures</comments><msc-class>05C69, 05C70 (Primary) 05A20(Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G=(V,E) be a graph. A set S is independent if no two vertices from S are
adjacent. The independence number alpha(G) is the cardinality of a maximum
independent set, and mu(G) is the size of a maximum matching. The number
id_{c}(G)=max{|I|-|N(I)|:I is an independent set} is called the critical
independence difference of G, and A is critical if |A|-|N(A)|=id_{c}(G). We
define core(G) as the intersection of all maximum independent sets, and
ker(G)as the intersection of all critical independent sets. In this paper we
prove that if a graph G is non-quasi-regularizable (i.e., there exists some
independent set A, such that |A|&gt;|N(A)|), then: ker(G) is a subset of core(G),
and |ker(G)|&gt; id_{c}(G) &gt;= alpha(G)-mu(G) &gt; 0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0406</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0406</id><created>2011-02-02</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author></authors><title>Threshold Saturation on Channels with Memory via Spatial Coupling</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2011</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We consider spatially coupled code ensembles. A particular instance are
convolutional LDPC ensembles. It was recently shown that, for transmission over
the memoryless binary erasure channel, this coupling increases the belief
propagation threshold of the ensemble to the maximum a-posteriori threshold of
the underlying component ensemble. This paved the way for a new class of
capacity achieving low-density parity check codes. It was also shown
empirically that the same threshold saturation occurs when we consider
transmission over general binary input memoryless channels.
  In this work, we report on empirical evidence which suggests that the same
phenomenon also occurs when transmission takes place over a class of channels
with memory. This is confirmed both by simulations as well as by computing EXIT
curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0424</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0424</id><created>2011-02-02</created><authors><author><keyname>Asvadi</keyname><forenames>Reza</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author><author><keyname>Ahmadian-Attari</keyname><forenames>Mahmoud</forenames></author></authors><title>Design of Finite-Length Irregular Protograph Codes with Low Error Floors
  over the Binary-Input AWGN Channel Using Cyclic Liftings</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Communications</comments><msc-class>Information Theory</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a technique to design finite-length irregular low-density
parity-check (LDPC) codes over the binary-input additive white Gaussian noise
(AWGN) channel with good performance in both the waterfall and the error floor
region. The design process starts from a protograph which embodies a desirable
degree distribution. This protograph is then lifted cyclically to a certain
block length of interest. The lift is designed carefully to satisfy a certain
approximate cycle extrinsic message degree (ACE) spectrum. The target ACE
spectrum is one with extremal properties, implying a good error floor
performance for the designed code. The proposed construction results in
quasi-cyclic codes which are attractive in practice due to simple encoder and
decoder implementation. Simulation results are provided to demonstrate the
effectiveness of the proposed construction in comparison with similar existing
constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0445</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0445</id><created>2011-02-02</created><authors><author><keyname>Boesten</keyname><forenames>Dion</forenames></author><author><keyname>Skoric</keyname><forenames>Boris</forenames></author></authors><title>Asymptotic fingerprinting capacity for non-binary alphabets</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compute the channel capacity of non-binary fingerprinting under the
Marking Assumption, in the limit of large coalition size c. The solution for
the binary case was found by Huang and Moulin. They showed that asymptotically,
the capacity is $1/(c^2 2\ln 2)$, the interleaving attack is optimal and the
arcsine distribution is the optimal bias distribution. In this paper we prove
that the asymptotic capacity for general alphabet size q is $(q-1)/(c^2 2\ln
q)$. Our proof technique does not reveal the optimal attack or bias
distribution. The fact that the capacity is an increasing function of q shows
that there is a real gain in going to non-binary alphabets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0451</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0451</id><created>2011-02-02</created><authors><author><keyname>Simone</keyname><forenames>Antonino</forenames></author><author><keyname>Skoric</keyname><forenames>Boris</forenames></author></authors><title>Asymptotically false-positive-maximizing attack on non-binary Tardos
  codes</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use a method recently introduced by Simone and Skoric to study accusation
probabilities for non-binary Tardos fingerprinting codes. We generalize the
pre-computation steps in this approach to include a broad class of collusion
attack strategies. We analytically derive properties of a special attack that
asymptotically maximizes false accusation probabilities. We present numerical
results on sufficient code lengths for this attack, and explain the abrupt
transitions that occur in these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0454</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0454</id><created>2011-02-02</created><authors><author><keyname>Ramisa</keyname><forenames>Arnau</forenames></author><author><keyname>Aldavert</keyname><forenames>David</forenames></author><author><keyname>Vasudevan</keyname><forenames>Shrihari</forenames></author><author><keyname>Toledo</keyname><forenames>Ricardo</forenames></author><author><keyname>de Mantaras</keyname><forenames>Ramon Lopez</forenames></author></authors><title>Evaluation of Three Vision Based Object Perception Methods for a Mobile
  Robot</title><categories>cs.RO</categories><comments>37 pages, 11 figures</comments><report-no>IIIA research report 2011-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses object perception applied to mobile robotics. Being able
to perceive semantically meaningful objects in unstructured environments is a
key capability in order to make robots suitable to perform high-level tasks in
home environments. However, finding a solution for this task is daunting: it
requires the ability to handle the variability in image formation in a moving
camera with tight time constraints. The paper brings to attention some of the
issues with applying three state of the art object recognition and detection
methods in a mobile robotics scenario, and proposes methods to deal with
windowing/segmentation. Thus, this work aims at evaluating the state-of-the-art
in object perception in an attempt to develop a lightweight solution for mobile
robotics use/research in typical indoor settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0467</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0467</id><created>2011-02-02</created><authors><author><keyname>Fraigniaud</keyname><forenames>Pierre</forenames></author><author><keyname>Pelc</keyname><forenames>Andrzej</forenames></author></authors><title>Delays Induce an Exponential Memory Gap for Rendezvous in Trees</title><categories>cs.DC cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of rendezvous in a graph is meeting of two mobile agents at some node
of an unknown anonymous connected graph. In this paper, we focus on rendezvous
in trees, and, analogously to the efforts that have been made for solving the
exploration problem with compact automata, we study the size of memory of
mobile agents that permits to solve the rendezvous problem deterministically.
We assume that the agents are identical, and move in synchronous rounds.
  We first show that if the delay between the starting times of the agents is
arbitrary, then the lower bound on memory required for rendezvous is Omega(log
n) bits, even for the line of length n. This lower bound meets a previously
known upper bound of O(log n) bits for rendezvous in arbitrary graphs of size
at most n. Our main result is a proof that the amount of memory needed for
rendezvous with simultaneous start depends essentially on the number L of
leaves of the tree, and is exponentially less impacted by the number n of
nodes. Indeed, we present two identical agents with O(log L + loglog n) bits of
memory that solve the rendezvous problem in all trees with at most n nodes and
at most L leaves. Hence, for the class of trees with polylogarithmically many
leaves, there is an exponential gap in minimum memory size needed for
rendezvous between the scenario with arbitrary delay and the scenario with
delay zero. Moreover, we show that our upper bound is optimal by proving that
Omega(log L + loglog n)$ bits of memory are required for rendezvous, even in
the class of trees with degrees bounded by 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0471</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0471</id><created>2011-02-01</created><updated>2011-02-03</updated><authors><author><keyname>Ishkov</keyname><forenames>Sergey</forenames></author><author><keyname>Ishkova</keyname><forenames>Elena</forenames></author></authors><title>Matrix method for the multi salesmen problem (TSP) with several vehicles</title><categories>cs.DS</categories><comments>10 pages with 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper discussed procedure of separation of the original problem with
several vehicles to a number of simpler problems with one vehicle which based
on the matrix approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0485</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0485</id><created>2011-02-02</created><updated>2011-04-15</updated><authors><author><keyname>Murphy</keyname><forenames>Patrick</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Design, Implementation and Characterization of a Cooperative
  Communications System</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear in IEEE TVT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative communications is a class of techniques which seek to improve
reliability and throughput in wireless systems by pooling the resources of
distributed nodes. While cooperation can occur at different network layers and
time scales, physical layer cooperation at symbol time scales offers the
largest benefit in combating losses due to fading. However, symbol level
cooperation poses significant implementation challenges, especially in
synchronizing the behaviors and carrier frequencies of distributed nodes. We
present the implementation and characterization of a complete, real-time
cooperative physical layer transceiver built on the Rice Wireless Open-Access
Research Platform (WARP). In our implementation autonomous nodes employ
physical layer cooperation without a central synchronization source, and are
capable of selecting between non-cooperative and cooperative communication per
packet. Cooperative transmissions use a distributed Alamouti space-time block
code and employ either amplify-and-forward or decode-and-forward relaying. We
also present experimental results of our transceiver's real-time performance
under a variety of topologies and propagation conditions. Our results clearly
demonstrate significant performance gains (more than 40x improvement in PER in
some topologies) provided by physical layer cooperation, even when subject to
the constraints of a real-time implementation. We also present methodologies to
isolate and understand the sources of performance bottlenecks in our design. As
with all our work on WARP, our transceiver design and experimental framework
are available via the open-source WARP repository for use by other wireless
researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0486</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0486</id><created>2011-02-02</created><authors><author><keyname>Bisalapur</keyname><forenames>Sahana S.</forenames></author></authors><title>Design of an Efficient Neural Key Distribution Centre</title><categories>cs.CR</categories><comments>11 pages,9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of any cryptographic system is the exchange of information among the
intended users without any leakage of information to others who may have
unauthorized access to it. A common secret key could be created over a public
channel accessible to any opponent. Neural networks can be used to generate
common secret key. In case of neural cryptography, both the communicating
networks receive an identical input vector, generate an output bit and are
trained based on the output bit. The two networks and their weight vectors
exhibit a novel phenomenon, where the networks synchronize to a state with
identical time-dependent weights. The generated secret key over a public
channel is used for encrypting and decrypting the information being sent on the
channel. This secret key is distributed to the other vendor efficiently by
using an agent based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0516</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0516</id><created>2011-02-02</created><authors><author><keyname>Patel</keyname><forenames>Sanjay</forenames></author><author><keyname>Bhavsar</keyname><forenames>Madhuri</forenames></author></authors><title>QOS based user driven scheduler for grid environment</title><categories>cs.DC</categories><comments>9 pages, ACIJ</comments><journal-ref>Advanced Computing: An International Journal ( ACIJ ), Vol.2,
  No.1, January 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  As grids are in essence heterogeneous, dynamic, shared and distributed
environments, managing these kinds of platforms efficiently is extremely
complex. A promising scalable approach to deal with these intricacies is the
design of self-managing of autonomic applications. Autonomic applications adapt
their execution accordingly by considering knowledge about their own behaviour
and environmental conditions.QoS based User Driven scheduling for grid that
provides the self-optimizing ability in autonomic applications. Computational
grids to provide a user to solve large scale problem by spreading a single
large computation across multiple machines of physical location. QoS based User
Driven scheduler for grid also provides reliability of the grid systems and
increase the performance of the grid to reducing the execution time of job by
applying scheduling policies defined by the user. The main aim of this paper is
to distribute the computational load among the available grid nodes and to
developed a QoS based scheduling algorithm for grid and making grid more
reliable.Grid computing system is different from conventional distributed
computing systems by its focus on large scale resource sharing, where
processors and communication have significant inuence on Grid computing
reliability. Reliability capabilities initiated by end users from within
applications they submit to the grid for execution. Reliability of
infrastructure and management services that perform essential functions
necessary for grid systems to operate, such as resource allocation and
scheduling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0522</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0522</id><created>2011-02-02</created><authors><author><keyname>Kuppinger</keyname><forenames>Patrick</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Uncertainty Relations and Sparse Signal Recovery for Pairs of General
  Signal Sets</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an uncertainty relation for the representation of signals in two
different general (possibly redundant or incomplete) signal sets. This
uncertainty relation is relevant for the analysis of signals containing two
distinct features each of which can be described sparsely in a suitable general
signal set. Furthermore, the new uncertainty relation is shown to lead to
improved sparsity thresholds for recovery of signals that are sparse in general
dictionaries. Specifically, our results improve on the well-known
$(1+1/d)/2$-threshold for dictionaries with coherence $d$ by up to a factor of
two. Furthermore, we provide probabilistic recovery guarantees for pairs of
general dictionaries that also allow us to understand which parts of a general
dictionary one needs to randomize over to &quot;weed out&quot; the sparsity patterns that
prohibit breaking the square-root bottleneck.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0540</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0540</id><created>2011-02-02</created><authors><author><keyname>Hambrey</keyname><forenames>Oliver</forenames></author><author><keyname>Parnell</keyname><forenames>Thomas</forenames></author><author><keyname>Zaboronski</keyname><forenames>Oleg</forenames></author></authors><title>Information theory of massively parallel probe storage channels</title><categories>cs.IT cs.IR math.IT</categories><comments>16 pages, 10 figures</comments><msc-class>68P20, 68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the concept of probe storage, we study the problem of
information retrieval using a large array of N nano-mechanical probes, N ~
4000. At the nanometer scale it is impossible to avoid errors in the
positioning of the array, thus all signals retrieved by the probes of the array
at a given sampling moment are affected by the same amount of random position
jitter. Therefore a massively parallel probe storage device is an example of a
noisy communication channel with long range correlations between channel
outputs due to the global positioning errors. We find that these correlations
have a profound effect on the channel's properties. For example, it turns out
that the channel's information capacity does approach 1 bit per probe in the
limit of high signal-to-noise ratio, but the rate of the approach is only
polynomial in the channel noise strength. Moreover, any error correction code
with block size N &gt;&gt; 1 such that codewords correspond to the instantaneous
outputs of the all probes in the array exhibits an error floor independently of
the code rate. We illustrate this phenomenon explicitly using Reed-Solomon
codes the performance of which is easy to simulate numerically. We also discuss
capacity-achieving error correction codes for the global jitter channel and
their complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0580</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0580</id><created>2011-02-02</created><updated>2011-02-09</updated><authors><author><keyname>Weitz</keyname><forenames>Benjamin</forenames></author></authors><title>An Improvement on Ranks of Explicit Tensors</title><categories>cs.DM cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give constructions of n^k x n^k x n tensors of rank at least 2n^k -
O(n^(k-1)). As a corollary we obtain an [n]^r shaped tensor with rank at least
2n^(r/2) - O(n^(r/2)-1) when r is odd. The tensors are constructed from a
simple recursive pattern, and the lower bounds are proven using a partitioning
theorem developed by Brockett and Dobkin. These two bounds are improvements
over the previous best-known explicit tensors that had ranks n^k and n^(r/2)
respectively
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0583</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0583</id><created>2011-02-02</created><authors><author><keyname>Kumar</keyname><forenames>Bimal Aklesh</forenames></author></authors><title>Thin Client Web-Based Campus Information Systems for Fiji National
  University</title><categories>cs.SE</categories><comments>14 pages</comments><journal-ref>International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol.2, No.1, January 2011</journal-ref><doi>10.5121/ijsea.2011.2102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fiji National University is encountering many difficulties with its current
administrative systems. These difficulties include accessibility, scalability,
performance, flexibility and integration. We propose a new campus information
system, FNU-CIS to addresses these difficulties. FNU-CIS has the potential to
provide wide range of the services for students and staffs at the university.
In order to assist in the design and implementation of proposed FNU-CIS, we
present an overview, software architecture and prototype implementation of our
proposed system. We discuss the key properties of our system, compare it with
other similar systems available and outline our future plans for research in
FNU-CIS implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0588</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0588</id><created>2011-02-02</created><updated>2011-03-02</updated><authors><author><keyname>L&#xe4;ssig</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Sudholt</keyname><forenames>Dirk</forenames></author></authors><title>Adaptive Population Models for Offspring Populations and Parallel
  Evolutionary Algorithms</title><categories>cs.DS</categories><comments>26 pages, 1 table</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two adaptive schemes for dynamically choosing the number of
parallel instances in parallel evolutionary algorithms. This includes the
choice of the offspring population size in a (1+$\lambda$) EA as a special
case. Our schemes are parameterless and they work in a black-box setting where
no knowledge on the problem is available. Both schemes double the number of
instances in case a generation ends without finding an improvement. In a
successful generation, the first scheme resets the system to one instance,
while the second scheme halves the number of instances. Both schemes provide
near-optimal speed-ups in terms of the parallel time. We give upper bounds for
the asymptotic sequential time (i.e., the total number of function evaluations)
that are not larger than upper bounds for a corresponding non-parallel
algorithm derived by the fitness-level method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0603</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0603</id><created>2011-02-03</created><authors><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Schwager</keyname><forenames>Mac</forenames></author><author><keyname>Rus</keyname><forenames>Daniela</forenames></author></authors><title>Persistent Robotic Tasks: Monitoring and Sweeping in Changing
  Environments</title><categories>cs.RO math.OC</categories><comments>This is an expanded version of a paper at ICRA 2011. This expanded
  version has been submitted to the IEEE Transactions on Robotics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present controllers that enable mobile robots to persistently monitor or
sweep a changing environment. The changing environment is modeled as a field
which grows in locations that are not within range of a robot, and decreases in
locations that are within range of a robot. We assume that the robots travel on
given closed paths. The speed of each robot along its path is controlled to
prevent the field from growing unbounded at any location. We consider the space
of speed controllers that can be parametrized by a finite set of basis
functions. For a single robot, we develop a linear program that is guaranteed
to compute a speed controller in this space to keep the field bounded, if such
a controller exists. Another linear program is then derived whose solution is
the speed controller that minimizes the maximum field value over the
environment. We extend our linear program formulation to develop a multi-robot
controller that keeps the field bounded. The multi-robot controller has the
unique feature that it does not require communication among the robots.
Simulation studies demonstrate the robustness of the controllers to modeling
errors, and to stochasticity in the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0604</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0604</id><created>2011-02-03</created><updated>2012-05-11</updated><authors><author><keyname>Gallos</keyname><forenames>Lazaros K.</forenames></author><author><keyname>Makse</keyname><forenames>Hernan A.</forenames></author><author><keyname>Sigman</keyname><forenames>Mariano</forenames></author></authors><title>A small-world of weak ties provides optimal global integration of
  self-similar modules in functional brain networks</title><categories>physics.bio-ph cond-mat.stat-mech cs.SI physics.soc-ph q-bio.NC</categories><comments>37 pages, 11 figures</comments><journal-ref>Proceedings of the National Academy of Sciences USA, 109, 2825
  (2012)</journal-ref><doi>10.1073/pnas.1106612109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The human brain is organized in functional modules. Such an organization
presents a basic conundrum: modules ought to be sufficiently independent to
guarantee functional specialization and sufficiently connected to bind multiple
processors for efficient information transfer. It is commonly accepted that
small-world architecture of short lengths and large local clustering may solve
this problem. However, there is intrinsic tension between shortcuts generating
small-worlds and the persistence of modularity; a global property unrelated to
local clustering. Here, we present a possible solution to this puzzle. We first
show that a modified percolation theory can define a set of hierarchically
organized modules made of strong links in functional brain networks. These
modules are &quot;large-world&quot; self-similar structures and, therefore, are far from
being small-world. However, incorporating weaker ties to the network converts
it into a small-world preserving an underlying backbone of well-defined
modules. Remarkably, weak ties are precisely organized as predicted by theory
maximizing information transfer with minimal wiring cost. This trade-off
architecture is reminiscent of the &quot;strength of weak ties&quot; crucial concept of
social networks. Such a design suggests a natural solution to the paradox of
efficient information flow in the highly modular structure of the brain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0629</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0629</id><created>2011-02-03</created><authors><author><keyname>Santoro</keyname><forenames>Nicola</forenames></author><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author><author><keyname>Flocchini</keyname><forenames>Paola</forenames></author><author><keyname>Casteigts</keyname><forenames>Arnaud</forenames></author><author><keyname>Amblard</keyname><forenames>Frederic</forenames></author></authors><title>Time-Varying Graphs and Social Network Analysis: Temporal Indicators and
  Metrics</title><categories>cs.SI cs.AI cs.DC physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most instruments - formalisms, concepts, and metrics - for social networks
analysis fail to capture their dynamics. Typical systems exhibit different
scales of dynamics, ranging from the fine-grain dynamics of interactions (which
recently led researchers to consider temporal versions of distance,
connectivity, and related indicators), to the evolution of network properties
over longer periods of time. This paper proposes a general approach to study
that evolution for both atemporal and temporal indicators, based respectively
on sequences of static graphs and sequences of time-varying graphs that cover
successive time-windows. All the concepts and indicators, some of which are
new, are expressed using a time-varying graph formalism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0634</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0634</id><created>2011-02-03</created><authors><author><keyname>Zuki&#x107;</keyname><forenames>D&#x17e;enan</forenames></author><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Bauer</keyname><forenames>Miriam H. A.</forenames></author><author><keyname>Kuhnt</keyname><forenames>Daniela</forenames></author><author><keyname>Carl</keyname><forenames>Barbara</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Kolb</keyname><forenames>Andreas</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author></authors><title>Glioblastoma Multiforme Segmentation in MRI Data with a Balloon
  Inflation Approach</title><categories>cs.GR</categories><comments>4 pages, 4 figures, Proc. of the 6th Russian-Bavarian Conference on
  Bio-Medical Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gliomas are the most common primary brain tumors, evolving from the cerebral
supportive cells. For clinical follow-up, the evaluation of the preoperative
tumor volume is essential. Volumetric assessment of tumor volume with manual
segmentation of its outlines is a time-consuming process that can be overcome
with the help of computer-assisted segmentation methods. In this paper, a
semi-automatic approach for World Health Organization (WHO) grade IV glioma
segmentation is introduced that uses balloon inflation forces, and relies on
the detection of high-intensity tumor boundaries that are coupled by using
contrast agent gadolinium. The presented method is evaluated on 27 magnetic
resonance imaging (MRI) data sets and the ground truth data of the tumor
boundaries - for evaluation of the results - are manually extracted by
neurosurgeons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0642</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0642</id><created>2011-02-03</created><authors><author><keyname>Vabishchevich</keyname><forenames>Petr N.</forenames></author></authors><title>Domain decomposition schemes for the Stokes equation</title><categories>cs.NA</categories><msc-class>65M06 65M12 65M55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical algorithms for solving problems of mathematical physics on modern
parallel computers employ various domain decomposition techniques. Domain
decomposition schemes are developed here to solve numerically initial/boundary
value problems for the Stokes system of equations in the primitive variables
pressure-velocity. Unconditionally stable schemes of domain decomposition are
based on the partition of unit for a computational domain and the corresponding
Hilbert spaces of grid functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0651</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0651</id><created>2011-02-02</created><authors><author><keyname>Masucci</keyname><forenames>A. P.</forenames></author><author><keyname>Kalampokis</keyname><forenames>A.</forenames></author><author><keyname>Egu&#xed;luz</keyname><forenames>V. M.</forenames></author><author><keyname>Hern&#xe1;ndez-Garc&#xed;a</keyname><forenames>E.</forenames></author></authors><title>Wikipedia information flow analysis reveals the scale-free architecture
  of the Semantic Space</title><categories>physics.soc-ph cs.IR cs.SI physics.data-an</categories><comments>12 pages, in press at PloS ONE</comments><journal-ref>PLoS ONE 6(2): e17333 (2011)</journal-ref><doi>10.1371/journal.pone.0017333</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we extract the topology of the semantic space in its
encyclopedic acception, measuring the semantic flow between the different
entries of the largest modern encyclopedia, Wikipedia, and thus creating a
directed complex network of semantic flows. Notably at the percolation
threshold the semantic space is characterised by scale-free behaviour at
different levels of complexity and this relates the semantic space to a wide
range of biological, social and linguistics phenomena. In particular we find
that the cluster size distribution, representing the size of different semantic
areas, is scale-free. Moreover the topology of the resulting semantic space is
scale-free in the connectivity distribution and displays small-world
properties. However its statistical properties do not allow a classical
interpretation via a generative model based on a simple multiplicative process.
After giving a detailed description and interpretation of the topological
properties of the semantic space, we introduce a stochastic model of
content-based network, based on a copy and mutation algorithm and on the Heaps'
law, that is able to capture the main statistical properties of the analysed
semantic space, including the Zipf's law for the word frequency distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0666</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0666</id><created>2011-02-03</created><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Probabilistic and quantum finite automata with postselection</title><categories>cs.CC quant-ph</categories><comments>24 pages. A preliminary version of this paper appeared in the
  Proceedings of Randomized and Quantum Computation (satellite workshop of MFCS
  and CSL 2010), pages 14--24, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that endowing a real-time probabilistic or quantum computer with the
ability of postselection increases its computational power. For this purpose,
we provide a new model of finite automata with postselection, and compare it
with the model of L\={a}ce et al. We examine the related language classes, and
also establish separations between the classical and quantum versions, and
between the zero-error vs. bounded-error modes of recognition in this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0674</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0674</id><created>2011-02-03</created><authors><author><keyname>Wei</keyname><forenames>Dong</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Cimini</keyname><forenames>Giulio</forenames></author><author><keyname>Wu</keyname><forenames>Pei</forenames></author><author><keyname>Liu</keyname><forenames>Weiping</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Effective Mechanism for Social Recommendation of News</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Physica A, Volume 390, Issue 11, p. 2117-2126 (2011)</journal-ref><doi>10.1016/j.physa.2011.02.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommendation systems represent an important tool for news distribution on
the Internet. In this work we modify a recently proposed social recommendation
model in order to deal with no explicit ratings of users on news. The model
consists of a network of users which continually adapts in order to achieve an
efficient news traffic. To optimize network's topology we propose different
stochastic algorithms that are scalable with respect to the network's size.
Agent-based simulations reveal the features and the performance of these
algorithms. To overcome the resultant drawbacks of each method we introduce two
improved algorithms and show that they can optimize network's topology almost
as fast and effectively as other not-scalable methods that make use of much
more information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0676</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0676</id><created>2011-02-03</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Mukherjee</keyname><forenames>Sajal</forenames></author><author><keyname>Ghosh</keyname><forenames>Soumya</forenames></author><author><keyname>Kar</keyname><forenames>Saheli</forenames></author><author><keyname>Kim</keyname><forenames>Young-Chon</forenames></author></authors><title>Architecture of A Scalable Dynamic Parallel WebCrawler with High Speed
  Downloadable Capability for a Web Search Engine</title><categories>cs.IR</categories><comments>6 pages, 6 figures</comments><journal-ref>MSPT 2006 - 6th International Workshop on MSPT Proceedings,
  Republic of Korea</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today World Wide Web (WWW) has become a huge ocean of information and it is
growing in size everyday. Downloading even a fraction of this mammoth data is
like sailing through a huge ocean and it is a challenging task indeed. In order
to download a large portion of data from WWW, it has become absolutely
essential to make the crawling process parallel. In this paper we offer the
architecture of a dynamic parallel Web crawler, christened as &quot;WEB-SAILOR,&quot;
which presents a scalable approach based on Client-Server model to speed up the
download process on behalf of a Web Search Engine in a distributed Domain-set
specific environment. WEB-SAILOR removes the possibility of overlapping of
downloaded documents by multiple crawlers without even incurring the cost of
communication overhead among several parallel &quot;client&quot; crawling processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0682</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0682</id><created>2011-02-03</created><authors><author><keyname>Saleem</keyname><forenames>Shahnaz</forenames></author><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>A Study of IEEE 802.15.4 Security Framework for Wireless Body Area
  Network</title><categories>cs.NI</categories><comments>14 pages, 7 figures, 2 tables</comments><journal-ref>Sensors Journal, Vol.11, No.2, pp.1383-1395, 2011</journal-ref><doi>10.3390/s110201383</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Wireless Body Area Network (WBAN) is a collection of low-power and
lightweight wireless sensor nodes that are used to monitor the human body
functions and the surrounding environment. It supports a number of innovative
and interesting applications, including ubiquitous healthcare and Consumer
Electronics (CE) applications. Since WBAN nodes are used to collect sensitive
(life-critical) information and may operate in hostile environments, they
require strict security mechanisms to prevent malicious interaction with the
system. In this paper, we first highlight major security requirements and
Denial of Service (DoS) attacks in WBAN at Physical, Medium Access Control
(MAC), Network, and Transport layers. Then we discuss the IEEE 802.15.4
security framework and identify the security vulnerabilities and major attacks
in the context of WBAN. Different types of attacks on the Contention Access
Period (CAP) and Contention Free Period (CFP) parts of the superframe are
analyzed and discussed. It is observed that a smart attacker can successfully
corrupt an increasing number of GTS slots in the CFP period and can
considerably affect the Quality of Service (QoS) in WBAN (since most of the
data is carried in CFP period). As we increase the number of smart attackers
the corrupted GTS slots are eventually increased, which prevents the legitimate
nodes to utilize the bandwidth efficiently. This means that the direct
adaptation of IEEE 802.15.4 security framework for WBAN is not totally secure
for certain WBAN applications. New solutions are required to integrate high
level security in WBAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0683</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0683</id><created>2011-02-03</created><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>LIX</affiliation></author><author><keyname>Join</keyname><forenames>C&#xe9;dric</forenames><affiliation>INRIA Saclay - Ile de France, CRAN</affiliation></author><author><keyname>Hatt</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author></authors><title>Volatility made observable at last</title><categories>q-fin.CP cs.CE q-fin.ST</categories><proxy>ccsd</proxy><journal-ref>3\`emes Journ\'ees Identification et Mod\'elisation
  Exp\'erimentale, Douai : France (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Cartier-Perrin theorem, which was published in 1995 and is expressed in
the language of nonstandard analysis, permits, for the first time perhaps, a
clear-cut mathematical definition of the volatility of a financial asset. It
yields as a byproduct a new understanding of the means of returns, of the beta
coefficient, and of the Sharpe and Treynor ratios. New estimation techniques
from automatic control and signal processing, which were already successfully
applied in quantitative finance, lead to several computer experiments with some
quite convincing forecasts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0684</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0684</id><created>2011-02-03</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Mishra</keyname><forenames>Priyanka</forenames></author><author><keyname>Saha</keyname><forenames>Dwaipayan</forenames></author><author><keyname>Kim</keyname><forenames>Young-Chon</forenames></author></authors><title>A Dynamic Web Page Prediction Model Based on Access Patterns to Offer
  Better User Latency</title><categories>cs.NI</categories><comments>6 pages, 3 figures, 1 table, 1 chart, MSPT 2006 - 6th International
  Workshop on MSPT Proceedings, Republic of Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growth of the World Wide Web has emphasized the need for improvement in
user latency. One of the techniques that are used for improving user latency is
Caching and another is Web Prefetching. Approaches that bank solely on caching
offer limited performance improvement because it is difficult for caching to
handle the large number of increasingly diverse files. Studies have been
conducted on prefetching models based on decision trees, Markov chains, and
path analysis. However, the increased uses of dynamic pages, frequent changes
in site structure and user access patterns have limited the efficacy of these
static techniques. In this paper, we have proposed a methodology to cluster
related pages into different categories based on the access patterns.
Additionally we use page ranking to build up our prediction model at the
initial stages when users haven't already started sending requests. This way we
have tried to overcome the problems of maintaining huge databases which is
needed in case of log based techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0686</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0686</id><created>2011-02-03</created><updated>2011-03-31</updated><authors><author><keyname>Taveneaux</keyname><forenames>Antoine</forenames></author></authors><title>Towards an axiomatic system for Kolmogorov complexity</title><categories>cs.IT cs.CC cs.LO math.IT math.LO</categories><journal-ref>Computability in Europe 2011 Springer LNCS volume</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [She82], it is shown that four basic functional properties are enough to
characterize plain Kolmogorov complexity, hence obtaining an axiomatic
characterization of this notion. In this paper, we try to extend this work,
both by looking at alternative axiomatic systems for plain complexity and by
considering potential axiomatic systems for other types of complexity. First we
show that the axiomatic system given by Shen cannot be weakened (at least in
any natural way). We then give an analogue of Shen's axiomatic system for
conditional complexity. In a the second part of the paper, we look at
prefix-free complexity and try to construct an axiomatic system for it. We show
however that the natural analogues of Shen's axiomatic systems fails to
characterize prefix-free complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0690</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0690</id><created>2011-02-03</created><authors><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author></authors><title>A New Sum-Rate Outer Bound for Interference Channels with Three
  Source-Destination Pairs</title><categories>cs.IT math.IT</categories><comments>8 pages, 4 figures, to be presented at the 2011 Information Theory
  and Applications Workshop Sunday 2/06 - Friday 2/11, UCSD, San Diego, CA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives a novel sum-rate outer bound for the general memoryless
interference channel with three users. The derivation is a generalization of
the techniques developed by Kramer and by Etkin et al for the Gaussian two-user
channel. For the three-user Gaussian channel the proposed sum-rate outer bound
outperforms known bounds for certain channel parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0694</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0694</id><created>2011-02-03</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Biswas</keyname><forenames>Pradipta</forenames></author><author><keyname>Kim</keyname><forenames>Young-Chon</forenames></author></authors><title>A Syntactic Classification based Web Page Ranking Algorithm</title><categories>cs.IR</categories><comments>10 pages, 4 figures, 2 tables MSPT 2006 - 6th International Workshop
  on MSPT Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existing search engines sometimes give unsatisfactory search result for
lack of any categorization of search result. If there is some means to know the
preference of user about the search result and rank pages according to that
preference, the result will be more useful and accurate to the user. In the
present paper a web page ranking algorithm is being proposed based on syntactic
classification of web pages. Syntactic Classification does not bother about the
meaning of the content of a web page. The proposed approach mainly consists of
three steps: select some properties of web pages based on user's demand,
measure them, and give different weightage to each property during ranking for
different types of pages. The existence of syntactic classification is
supported by running fuzzy c-means algorithm and neural network classification
on a set of web pages. The change in ranking for difference in type of pages
but for same query string is also being demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0695</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0695</id><created>2011-02-03</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Banik</keyname><forenames>Aritra</forenames></author><author><keyname>Mukherjee</keyname><forenames>Sreemoyee</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Jhilik</forenames></author><author><keyname>Kim</keyname><forenames>Young-Chon</forenames></author></authors><title>A Domain Specific Ontology Based Semantic Web Search Engine</title><categories>cs.IR</categories><comments>9 pages, 11 figures, MSPT 2007 - 7th International Workshop on MSPT
  Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since its emergence in the 1990s the World Wide Web (WWW) has rapidly evolved
into a huge mine of global information and it is growing in size everyday. The
presence of huge amount of resources on the Web thus poses a serious problem of
accurate search. This is mainly because today's Web is a human-readable Web
where information cannot be easily processed by machine. Highly sophisticated,
efficient keyword based search engines that have evolved today have not been
able to bridge this gap. So comes up the concept of the Semantic Web which is
envisioned by Tim Berners-Lee as the Web of machine interpretable information
to make a machine processable form for expressing information. Based on the
semantic Web technologies we present in this paper the design methodology and
development of a semantic Web search engine which provides exact search results
for a domain specific search. This search engine is developed for an
agricultural Website which hosts agricultural information about the state of
West Bengal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0699</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0699</id><created>2011-02-03</created><updated>2012-02-24</updated><authors><author><keyname>Erramilli</keyname><forenames>Vijay</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoyuan</forenames></author><author><keyname>Rodriguez</keyname><forenames>Pablo</forenames></author></authors><title>Explore what-if scenarios with SONG: Social Network Write Generator</title><categories>cs.SI cs.NI physics.soc-ph</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online Social Networks (OSNs) have witnessed a tremendous growth the last few
years, becoming a platform for online users to communicate, exchange content
and even find employment. The emergence of OSNs has attracted researchers and
analysts and much data-driven research has been conducted. However, collecting
data-sets is non-trivial and sometimes it is difficult for data-sets to be
shared between researchers. The main contribution of this paper is a framework
called SONG (Social Network Write Generator) to generate synthetic traces of
write activity on OSNs. We build our framework based on a characterization
study of a large Twitter data-set and identifying the important factors that
need to be accounted for. We show how one can generate traces with SONG and
validate it by comparing against real data. We discuss how one can extend and
use SONG to explore different `what-if' scenarios. We build a Twitter clone
using 16 machines and Cassandra. We then show by example the usefulness of SONG
by stress-testing our implementation. We hope that SONG is used by researchers
and analysts for their own work that involves write activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0705</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0705</id><created>2011-02-03</created><updated>2011-07-21</updated><authors><author><keyname>Liu</keyname><forenames>Jiang</forenames></author><author><keyname>Zhan</keyname><forenames>Naijun</forenames></author><author><keyname>Zhao</keyname><forenames>Hengjun</forenames></author></authors><title>Computing Semi-algebraic Invariants for Polynomial Dynamical Systems</title><categories>cs.SC cs.PL</categories><comments>28 pages</comments><acm-class>I.1.2; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider an extended concept of invariant for polynomial
dynamical system (PDS) with domain and initial condition, and establish a sound
and complete criterion for checking semi-algebraic invariants (SAI) for such
PDSs. The main idea is encoding relevant dynamical properties as conditions on
the high order Lie derivatives of polynomials occurring in the SAI. A direct
consequence of this criterion is a relatively complete method of SAI generation
based on template assumption and semi-algebraic constraint solving. Relative
completeness means if there is an SAI in the form of a predefined template,
then our method can indeed find one using this template.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0706</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0706</id><created>2011-02-03</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Mishra</keyname><forenames>Sangeeta</forenames></author></authors><title>Strategic Issues For A Successful E-Commerce</title><categories>cs.CY</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  E-commerce is an emerging technology. Impact of this new technology is
getting clearer with time and results are tangible to the user community. In
this paper we have tried to focus some of its issues like paradigms,
infrastructure integration, and security, which is considered to be the most
important issue in E-Commerce. At first we have elaborated the paradigms of
E-Commerce (Business-to-Business and Business-to-Consumer). Then comes the
necessity of infrastructure integration with the legacy system. Security
concerns comes next. Rest of the part contains conclusion and references.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0710</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0710</id><created>2011-02-03</created><updated>2012-02-02</updated><authors><author><keyname>Lomnitz</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Universal Communication over Arbitrarily Varying Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of universally communicating over an unknown and
arbitrarily varying channel, using feedback. The focus of this paper is on
determining the input behavior, and specifically, a prior distribution which is
used to randomly generate the codebook. We pose the problem of setting the
prior as a sequential universal prediction problem, that attempts to approach a
given target rate, which depends on the unknown channel sequence. The main
result is that, for a channel comprised of an unknown, arbitrary sequence of
memoryless channels, there is a system using feedback and common randomness
that asymptotically attains, with high probability, the capacity of the
time-averaged channel, universally for every sequence of channels. While no
prior knowledge of the channel sequence is assumed, the rate achieved meets or
exceeds the traditional arbitrarily varying channel (AVC) capacity for every
memoryless AVC defined over the same alphabets, and therefore the system
universally attains the random code AVC capacity, without knowledge of the AVC
parameters. The system we present combines rateless coding with a universal
prediction scheme for the prior. We present rough upper bounds on the rates
that can be achieved in this setting and lower bounds for the redundancies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0714</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0714</id><created>2011-02-03</created><authors><author><keyname>Insa-Cabrera</keyname><forenames>Javier</forenames></author><author><keyname>Hernandez-Orallo</keyname><forenames>Jose</forenames></author></authors><title>An architecture for the evaluation of intelligent systems</title><categories>cs.AI</categories><comments>112 pages. In Spanish. Final Project Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main research areas in Artificial Intelligence is the coding of
agents (programs) which are able to learn by themselves in any situation. This
means that agents must be useful for purposes other than those they were
created for, as, for example, playing chess. In this way we try to get closer
to the pristine goal of Artificial Intelligence. One of the problems to decide
whether an agent is really intelligent or not is the measurement of its
intelligence, since there is currently no way to measure it in a reliable way.
The purpose of this project is to create an interpreter that allows for the
execution of several environments, including those which are generated
randomly, so that an agent (a person or a program) can interact with them. Once
the interaction between the agent and the environment is over, the interpreter
will measure the intelligence of the agent according to the actions, states and
rewards the agent has undergone inside the environment during the test. As a
result we will be able to measure agents' intelligence in any possible
environment, and to make comparisons between several agents, in order to
determine which of them is the most intelligent. In order to perform the tests,
the interpreter must be able to randomly generate environments that are really
useful to measure agents' intelligence, since not any randomly generated
environment will serve that purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0720</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0720</id><created>2011-02-03</created><updated>2014-07-28</updated><authors><author><keyname>D'Angelo</keyname><forenames>Gabriele</forenames></author><author><keyname>Ferretti</keyname><forenames>Stefano</forenames></author><author><keyname>Marzolla</keyname><forenames>Moreno</forenames></author></authors><title>Adaptive Event Dissemination for Peer-to-Peer Multiplayer Online Games</title><categories>cs.NI cs.DC</categories><comments>ICST/CREATE-NET DISIO 2011: 2nd Workshop on DIstributed SImulation
  and Online gaming. March 21, 2011, Barcelona, Spain</comments><acm-class>D.2.8; H.4; K.8.0</acm-class><doi>10.4108/icst.simutools.2011.245539</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that gossip algorithms may be effectively used to
disseminate game events in Peer-to-Peer (P2P) Multiplayer Online Games (MOGs).
Game events are disseminated through an overlay network. The proposed scheme
exploits the typical behavior of players to tune the data dissemination. In
fact, it is well known that users playing a MOG typically generate game events
at a rate that can be approximated using some (game dependent) probability
distribution. Hence, as soon as a given node experiences a reception rate, for
messages coming from a given peer, which is lower than expected, it can send a
stimulus to the neighbor that usually forwards these messages, asking it to
increase its dissemination probability. Three variants of this approach will be
studied. According to the first one, upon reception of a stimulus from a
neighbor, a peer increases its dissemination probability towards that node
irrespectively from the sender. In the second protocol a peer increases only
the dissemination probability for a given sender towards all its neighbors.
Finally, the third protocol takes into consideration both the sender and the
neighbor in order to decide how to increase the dissemination probability. We
performed extensive simulations to assess the efficacy of the proposed scheme,
and based on the simulation results we compare the different dissemination
protocols. The results confirm that adaptive gossip schemes are indeed
effective and deserve further investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0735</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0735</id><created>2011-02-03</created><authors><author><keyname>Omidvar</keyname><forenames>Mohammad Amin</forenames></author><author><keyname>Mirabi</keyname><forenames>Vahid Reza</forenames></author><author><keyname>Shokry</keyname><forenames>Najes</forenames></author></authors><title>Analyzing the Impact of Visitors on Page Views with Google Analytics</title><categories>cs.IR</categories><comments>32 pages,16 table, 10 figure</comments><msc-class>62M10, 62J05</msc-class><journal-ref>International Journal of Web &amp; Semantic Technology (IJWesT) Vol.2,
  No.1, January 2011</journal-ref><doi>10.5121/ijwest.2011.2102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a flexible methodology to analyze the effectiveness of
different variables on various dependent variables which all are times series
and especially shows how to use a time series regression on one of the most
important and primary index (page views per visit) on Google analytic and in
conjunction it shows how to use the most suitable data to gain a more accurate
result. Search engine visitors have a variety of impact on page views which
cannot be described by single regression. On one hand referral visitors are
well-fitted on linear regression with low impact. On the other hand, direct
visitors made a huge impact on page views. The higher connection speed does not
simply imply higher impact on page views and the content of web page and the
territory of visitors can help connection speed to describe user behavior.
Returning visitors have some similarities with direct visitors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0749</identifier>
 <datestamp>2012-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0749</id><created>2011-02-03</created><updated>2012-03-28</updated><authors><author><keyname>Buiras</keyname><forenames>Pablo</forenames></author><author><keyname>D&#xed;az-Caro</keyname><forenames>Alejandro</forenames></author><author><keyname>Jaskelioff</keyname><forenames>Mauro</forenames></author></authors><title>Confluence via strong normalisation in an algebraic \lambda-calculus
  with rewriting</title><categories>cs.LO</categories><comments>In Proceedings LSFA 2011, arXiv:1203.5423</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 81, 2012, pp. 16-29</journal-ref><doi>10.4204/EPTCS.81.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear-algebraic lambda-calculus and the algebraic lambda-calculus are
untyped lambda-calculi extended with arbitrary linear combinations of terms.
The former presents the axioms of linear algebra in the form of a rewrite
system, while the latter uses equalities. When given by rewrites, algebraic
lambda-calculi are not confluent unless further restrictions are added. We
provide a type system for the linear-algebraic lambda-calculus enforcing strong
normalisation, which gives back confluence. The type system allows an abstract
interpretation in System F.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0755</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0755</id><created>2011-02-03</created><authors><author><keyname>Li</keyname><forenames>Min</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Message and State Cooperation in a Relay Channel When the Relay Has
  Strictly Causal State Information</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, to appear in Information Theory and Applications
  Workshop, February 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A state-dependent relay channel is studied in which strictly causal channel
state information is available at the relay and no state information is
available at the source and destination. Source and relay are connected via two
unidirectional out-of-band orthogonal links of finite capacity, and a
state-dependent memoryless channel connects source and relay, on one side, and
the destination, on the other. Via the orthogonal links, the source can convey
information about the message to be delivered to the destination to the relay
while the relay can forward state information to the source. This exchange
enables cooperation between source and relay on both transmission of message
and state information to the destination. First, an achievable scheme, inspired
by noisy network coding, is proposed that exploits both message and state
cooperation. Next, based on the given achievable rate and appropriate upper
bounds, capacity results are identified for some special cases. Finally, a
Gaussian model is studied, along with corresponding numerical results that
illuminate the relative merits of state and message cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0763</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0763</id><created>2011-02-03</created><updated>2011-02-04</updated><authors><author><keyname>Habibi</keyname><forenames>Mohammad Hassan</forenames></author><author><keyname>Gardeshi</keyname><forenames>Mahmud</forenames></author><author><keyname>Alaghband</keyname><forenames>Mahdi R.</forenames></author></authors><title>Practical Attacks on a RFID Authentication Protocol Conforming to EPC
  C-1 G-2 Standard</title><categories>cs.CR</categories><comments>13 page, International Journal of Ubicomp</comments><msc-class>68-02</msc-class><journal-ref>International Journal of Ubicomp, Volume 2, Number 1,pp. 1-13,
  2011</journal-ref><doi>10.5121/iju.2011.2101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Yeh et al. recently have proposed a mutual authentication protocol based on
EPC Class-1 Gen.-2 standard [1]. They have claimed that their protocol is
secure against adversarial attacks and also provides forward secrecy. In this
paper we will show that the proposed protocol does not have proper security
features. A powerful and practical attack is presented on this protocol whereby
the whole security of the protocol is broken. Furthermore, Yeh et al. protocol
does not assure the untraceabilitiy and backward untraceabilitiy aspects.
Namely, all past and next transactions of a compromised tag will be traceable
by an adversary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0768</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0768</id><created>2011-02-03</created><updated>2014-07-13</updated><authors><author><keyname>Li</keyname><forenames>Min</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Message and State Cooperation in a Relay Channel When Only the Relay
  Knows the State</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A state-dependent relay channel is studied in which strictly causal channel
state information is available at the relay and no state information is
available at the source and destination. The source and the relay are connected
via two unidirectional out-of-band orthogonal links of finite capacity, and a
state-dependent memoryless channel connects the source and the relay, on one
side, and the destination, on the other. Via the orthogonal links, the source
can convey information about the message to be delivered to the destination to
the relay while the relay can forward state information to the source. This
exchange enables cooperation between the source and the relay on transmission
of message and state information to the destination. First, two achievable
schemes are proposed that exploit both message and state cooperation. It is
shown that a transmission scheme inspired by noisy network coding performs
better than a strategy based on block Markov coding and backward decoding.
Next, based on the given achievable schemes and appropriate upper bounds,
capacity results are identified for some special cases. Finally, a Gaussian
model is studied, along with corresponding numerical results that illuminate
the relative merits of state and message cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0805</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0805</id><created>2011-02-03</created><authors><author><keyname>King</keyname><forenames>Andrew D.</forenames></author><author><keyname>Reed</keyname><forenames>Bruce</forenames></author></authors><title>Asymptotics of the chromatic number for quasi-line graphs</title><categories>cs.DM cs.DS math.CO</categories><comments>20 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As proved by Kahn, the chromatic number and fractional chromatic number of a
line graph agree asymptotically. That is, for any line graph $G$ we have
$\chi(G) \leq (1+o(1))\chi_f(G)$. We extend this result to quasi-line graphs,
an important subclass of claw-free graphs. Furthermore we prove that we can
construct a colouring that achieves this bound in polynomial time, giving us an
asymptotic approximation algorithm for the chromatic number of quasi-line
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0817</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0817</id><created>2011-02-03</created><authors><author><keyname>Tka&#x10d;ik</keyname><forenames>Ga&#x161;per</forenames></author><author><keyname>Garrigan</keyname><forenames>Patrick</forenames></author><author><keyname>Ratliff</keyname><forenames>Charles</forenames></author><author><keyname>Mil&#x10d;inski</keyname><forenames>Grega</forenames></author><author><keyname>Klein</keyname><forenames>Jennifer M</forenames></author><author><keyname>Seyfarth</keyname><forenames>Lucia H</forenames></author><author><keyname>Sterling</keyname><forenames>Peter</forenames></author><author><keyname>Brainard</keyname><forenames>David</forenames></author><author><keyname>Balasubramanian</keyname><forenames>Vijay</forenames></author></authors><title>Natural images from the birthplace of the human eye</title><categories>q-bio.NC cs.CV</categories><comments>Submitted to PLoS ONE</comments><journal-ref>PLoS ONE 6: e20409 (2011)</journal-ref><doi>10.1371/journal.pone.0020409</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we introduce a database of calibrated natural images publicly available
through an easy-to-use web interface. Using a Nikon D70 digital SLR camera, we
acquired about 5000 six-megapixel images of Okavango Delta of Botswana, a
tropical savanna habitat similar to where the human eye is thought to have
evolved. Some sequences of images were captured unsystematically while
following a baboon troop, while others were designed to vary a single parameter
such as aperture, object distance, time of day or position on the horizon.
Images are available in the raw RGB format and in grayscale. Images are also
available in units relevant to the physiology of human cone photoreceptors,
where pixel values represent the expected number of photoisomerizations per
second for cones sensitive to long (L), medium (M) and short (S) wavelengths.
This database is distributed under a Creative Commons Attribution-Noncommercial
Unported license to facilitate research in computer vision, psychophysics of
perception, and visual neuroscience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0823</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0823</id><created>2011-02-03</created><updated>2011-02-14</updated><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author><author><keyname>Vilcu</keyname><forenames>Costin</forenames></author></authors><title>Conical Existence of Closed Curves on Convex Polyhedra</title><categories>cs.DM cs.CG</categories><comments>24 pages, 15 figures, 6 references. Version 2 includes a solution to
  one of the open problems posed in Version 1, concerning quasigeodesic loops</comments><msc-class>52B10</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let C be a simple, closed, directed curve on the surface of a convex
polyhedron P. We identify several classes of curves C that &quot;live on a cone,&quot; in
the sense that C and a neighborhood to one side may be isometrically embedded
on the surface of a cone Lambda, with the apex a of Lambda enclosed inside (the
image of) C; we also prove that each point of C is &quot;visible to&quot; a. In
particular, we obtain that these curves have non-self-intersecting developments
in the plane. Moreover, the curves we identify that live on cones to both sides
support a new type of &quot;source unfolding&quot; of the entire surface of P to one
non-overlapping piece, as reported in a companion paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0831</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0831</id><created>2011-02-03</created><authors><author><keyname>Madhu</keyname><forenames>G.</forenames></author><author><keyname>Govardhan</keyname><forenames>Dr. A.</forenames></author><author><keyname>Rajinikanth</keyname><forenames>Dr. T. V.</forenames></author></authors><title>Intelligent Semantic Web Search Engines: A Brief Survey</title><categories>cs.AI</categories><journal-ref>International journal of Web &amp; Semantic Technology (IJWesT) Vol.2,
  No.1, January 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The World Wide Web (WWW) allows the people to share the information (data)
from the large database repositories globally. The amount of information grows
billions of databases. We need to search the information will specialize tools
known generically search engine. There are many of search engines available
today, retrieving meaningful information is difficult. However to overcome this
problem in search engines to retrieve meaningful information intelligently,
semantic web technologies are playing a major role. In this paper we present
survey on the search engine generations and the role of search engines in
intelligent web and semantic search technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0836</identifier>
 <datestamp>2011-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0836</id><created>2011-02-03</created><updated>2011-02-07</updated><authors><author><keyname>Qi</keyname><forenames>Yuan</forenames></author><author><keyname>Yan</keyname><forenames>Feng</forenames></author></authors><title>EigenNet: A Bayesian hybrid of generative and conditional models for
  sparse learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a challenging task to select correlated variables in a high dimensional
space. To address this challenge, the elastic net has been developed and
successfully applied to many applications. Despite its great success, the
elastic net does not explicitly use correlation information embedded in data to
select correlated variables. To overcome this limitation, we present a novel
Bayesian hybrid model, the EigenNet, that uses the eigenstructures of data to
guide variable selection. Specifically, it integrates a sparse conditional
classification model with a generative model capturing variable correlations in
a principled Bayesian framework. We reparameterize the hybrid model in the
eigenspace to avoid overfiting and to increase the computational efficiency of
its MCMC sampler. Furthermore, we provide an alternative view to the EigenNet
from a regularization perspective: the EigenNet has an adaptive
eigenspace-based composite regularizer, which naturally generalizes the
$l_{1/2}$ regularizer used by the elastic net. Experiments on synthetic and
real data show that the EigenNet significantly outperforms the lasso, the
elastic net, and the Bayesian lasso in terms of prediction accuracy, especially
when the number of training samples is smaller than the number of variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0850</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0850</id><created>2011-02-04</created><updated>2011-02-22</updated><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author></authors><title>Scattered context-free linear orderings</title><categories>cs.FL</categories><msc-class>68Q45</msc-class><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that it is decidable in exponential time whether the lexicographic
ordering of a context-free language is scattered, or a well-ordering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0858</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0858</id><created>2011-02-04</created><authors><author><keyname>Habibi</keyname><forenames>Mohammad Hassan</forenames></author><author><keyname>Gardeshi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Alaghband</keyname><forenames>Mahdi R.</forenames></author></authors><title>Cryptanalysis of two mutual authentication protocols for low-cost RFID</title><categories>cs.CR</categories><comments>17 pages, 2 figures, 1 table, International Journal of Distributed
  and Parallel systems</comments><msc-class>68-02</msc-class><journal-ref>International Journal of Distributed and Parallel systems, Volume
  2, Number 1, pp. 103-114. 2011</journal-ref><doi>10.5121/ijdps.2011.2109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio Frequency Identification (RFID) is appearing as a favorite technology
for automated identification, which can be widely applied to many applications
such as e-passport, supply chain management and ticketing. However, researchers
have found many security and privacy problems along RFID technology. In recent
years, many researchers are interested in RFID authentication protocols and
their security flaws. In this paper, we analyze two of the newest RFID
authentication protocols which proposed by Fu et al. and Li et al. from several
security viewpoints. We present different attacks such as desynchronization
attack and privacy analysis over these protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0860</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0860</id><created>2011-02-04</created><updated>2011-02-08</updated><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames></author><author><keyname>Fargetton</keyname><forenames>Renan</forenames></author><author><keyname>Nesme</keyname><forenames>Vincent</forenames></author><author><keyname>Thierry</keyname><forenames>Eric</forenames></author></authors><title>Applying causality principles to the axiomatization of probabilistic
  cellular automata</title><categories>cs.DM cs.FL math-ph math.MP quant-ph</categories><comments>13 pages, 6 figures, LaTeX, v2: refs added</comments><msc-class>37B15, 68Q80, 37A50, 37L55, 81P45</msc-class><acm-class>B.6.1; F.1.1; F.1.2; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular automata (CA) consist of an array of identical cells, each of which
may take one of a finite number of possible states. The entire array evolves in
discrete time steps by iterating a global evolution G. Further, this global
evolution G is required to be shift-invariant (it acts the same everywhere) and
causal (information cannot be transmitted faster than some fixed number of
cells per time step). At least in the classical, reversible and quantum cases,
these two top-down axiomatic conditions are sufficient to entail more
bottom-up, operational descriptions of G. We investigate whether the same is
true in the probabilistic case. Keywords: Characterization, noise, Markov
process, stochastic Einstein locality, screening-off, common cause principle,
non-signalling, Multi-party non-local box.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0874</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0874</id><created>2011-02-04</created><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author><author><keyname>Kyncl</keyname><forenames>Jan</forenames></author><author><keyname>M&#xe9;sz&#xe1;ros</keyname><forenames>Viola</forenames></author><author><keyname>Stolar</keyname><forenames>Rudolf</forenames></author><author><keyname>Valtr</keyname><forenames>Pavel</forenames></author></authors><title>Universal Sets for Straight-Line Embeddings of Bicolored Graphs</title><categories>cs.DM</categories><comments>extended version of the paper &quot;Hamiltonian alternating paths on
  bicolored double-chains&quot; presented at Graph Drawing 2008</comments><msc-class>52C10, 05C62</msc-class><journal-ref>Thirty Essays on Geometric Graph Theory, Algorithms and
  Combinatorics, pp. 101-119 (Springer, 2013)</journal-ref><doi>10.1007/978-1-4614-0110-0_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set S of n points is 2-color universal for a graph G on n vertices if for
every proper 2-coloring of G and for every 2-coloring of S with the same sizes
of color classes as G has, G is straight-line embeddable on S. We show that the
so-called double chain is 2-color universal for paths if each of the two chains
contains at least one fifth of all the points, but not if one of the chains is
more than approximately 28 times longer than the other. A 2-coloring of G is
equitable if the sizes of the color classes differ by at most 1. A bipartite
graph is equitable if it admits an equitable proper coloring. We study the case
when S is the double-chain with chain sizes differing by at most 1 and G is an
equitable bipartite graph. We prove that this S is not 2-color universal if G
is not a forest of caterpillars and that it is 2-color universal for equitable
caterpillars with at most one half non-leaf vertices. We also show that if this
S is equitably 2-colored, then equitably properly 2-colored forests of stars
can be embedded on it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0876</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0876</id><created>2011-02-04</created><authors><author><keyname>Realpe-Gomez</keyname><forenames>John</forenames></author><author><keyname>Szczesny</keyname><forenames>Bartosz</forenames></author><author><keyname>Dall'Asta</keyname><forenames>Luca</forenames></author><author><keyname>Galla</keyname><forenames>Tobias</forenames></author></authors><title>Fixation and escape times in stochastic game learning</title><categories>physics.soc-ph cs.GT q-bio.PE</categories><comments>19 pages, 9 figures</comments><doi>10.1088/1742-5468/2012/10/P10022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary dynamics in finite populations is known to fixate eventually in
the absence of mutation. We here show that a similar phenomenon can be found in
stochastic game dynamical batch learning, and investigate fixation in learning
processes in a simple 2x2 game, for two-player games with cyclic interaction,
and in the context of the best-shot network game. The analogues of finite
populations in evolution are here finite batches of observations between
strategy updates. We study when and how such fixation can occur, and present
results on the average time-to-fixation from numerical simulations. Simple
cases are also amenable to analytical approaches and we provide estimates of
the behaviour of so-called escape times as a function of the batch size. The
differences and similarities with escape and fixation in evolutionary dynamics
are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0884</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0884</id><created>2011-02-04</created><authors><author><keyname>Ahmad</keyname><forenames>A.</forenames></author></authors><title>A Simulation Experiment on a Built-In Self Test Equipped with
  Pseudorandom Test Pattern Generator and Multi-Input Shift Register (MISR)</title><categories>cs.AR</categories><comments>12 pages,2 figures, Journal</comments><journal-ref>International journal of VLSI Design &amp; Communication Systems,
  vol.1, no.4, pp. 1-12, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the impact of the changes of the characteristic
polynomials and initial loadings, on behaviour of aliasing errors of parallel
signature analyzer (Multi-Input Shift Register), used in an LFSR based digital
circuit testing technique. The investigation is carried-out through an
extensive simulation study of the effectiveness of the LFSR based digital
circuit testing technique. The results of the study show that when the
identical characteristic polynomials of order n are used in both pseudo-random
test-pattern generator, as well as in Multi-Input Shift Register (MISR)
signature analyzer (parallel type) then the probability of aliasing errors
remains unchanged due to the changes in the initial loadings of the
pseudo-random test-pattern generator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0885</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0885</id><created>2011-02-04</created><updated>2011-02-09</updated><authors><author><keyname>Lunemann</keyname><forenames>Carolin</forenames></author></authors><title>Cryptographic Protocols under Quantum Attacks</title><categories>quant-ph cs.CR</categories><comments>PhD Thesis, Aarhus University, Denmark, 146 pages; v2: updated bib
  entry</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The realm of this thesis is cryptographic protocol theory in the quantum
world. We study the security of quantum and classical protocols against
adversaries that are assumed to exploit quantum effects to their advantage.
Security in the quantum world means that quantum computation does not
jeopardize the assumption, underlying the protocol construction. But moreover,
we encounter additional setbacks in the security proofs, which are mostly due
to the fact that some well-known classical proof techniques are forbidden by
certain properties of a quantum environment. Interestingly, we can exploit some
of the very same properties to the benefit of quantum cryptography. Thus, this
work lies right at the heart of the conflict between highly potential effects
but likewise rather demanding conditions in the quantum world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0887</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0887</id><created>2011-02-04</created><updated>2011-06-23</updated><authors><author><keyname>Lunemann</keyname><forenames>Carolin</forenames></author><author><keyname>Nielsen</keyname><forenames>Jesper Buus</forenames></author></authors><title>Fully Simulatable Quantum-Secure Coin-Flipping and Applications</title><categories>quant-ph cs.CR</categories><comments>27 pages; v3: updated according to final proceedings version</comments><journal-ref>full version of Progress in Cryptology - AFRICACRYPT 2011, LNCS
  6737, pages 21-40</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a coin-flip protocol which yields a string of strong, random coins
and is fully simulatable against poly-sized quantum adversaries on both sides.
It can be implemented with quantum-computational security without any set-up
assumptions, since our construction only assumes mixed commitment schemes which
we show how to construct in the given setting. We then show that the
interactive generation of random coins at the beginning or during outer
protocols allows for quantum-secure realizations of classical schemes, again
without any set-up assumptions. As example applications we discuss quantum
zero-knowledge proofs of knowledge and quantum-secure two-party function
evaluation. Both applications assume only fully simulatable coin-flipping and
mixed commitments. Since our framework allows to construct fully simulatable
coin-flipping from mixed commitments, this in particular shows that mixed
commitments are complete for quantum-secure two-party function evaluation. This
seems to be the first completeness result for quantum-secure two-party function
evaluation from a generic assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0899</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0899</id><created>2011-02-04</created><authors><author><keyname>DelRose</keyname><forenames>Michael</forenames></author><author><keyname>Wagner</keyname><forenames>Christian</forenames></author><author><keyname>Frederick</keyname><forenames>Philip</forenames></author></authors><title>Evidence Feed Forward Hidden Markov Model: A New Type of Hidden Markov
  Model</title><categories>cs.AI cs.CV cs.LG math.NA math.PR</categories><comments>19 pages, International Journal of Artificial Intelligence and
  Applications</comments><msc-class>60J20, 61E40, 65C50</msc-class><acm-class>I.2.10</acm-class><journal-ref>International Journal of Artificial Intelligence and Applications
  (IJAIA), Vol. 2, No. 1, Jan 2011</journal-ref><doi>10.5121/ijaia.2011.2101</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The ability to predict the intentions of people based solely on their visual
actions is a skill only performed by humans and animals. The intelligence of
current computer algorithms has not reached this level of complexity, but there
are several research efforts that are working towards it. With the number of
classification algorithms available, it is hard to determine which algorithm
works best for a particular situation. In classification of visual human intent
data, Hidden Markov Models (HMM), and their variants, are leading candidates.
  The inability of HMMs to provide a probability in the observation to
observation linkages is a big downfall in this classification technique. If a
person is visually identifying an action of another person, they monitor
patterns in the observations. By estimating the next observation, people have
the ability to summarize the actions, and thus determine, with pretty good
accuracy, the intention of the person performing the action. These visual cues
and linkages are important in creating intelligent algorithms for determining
human actions based on visual observations.
  The Evidence Feed Forward Hidden Markov Model is a newly developed algorithm
which provides observation to observation linkages. The following research
addresses the theory behind Evidence Feed Forward HMMs, provides mathematical
proofs of their learning of these parameters to optimize the likelihood of
observations with a Evidence Feed Forwards HMM, which is important in all
computational intelligence algorithm, and gives comparative examples with
standard HMMs in classification of both visual action data and measurement
data; thus providing a strong base for Evidence Feed Forward HMMs in
classification of many types of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0902</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0902</id><created>2011-02-04</created><updated>2012-03-01</updated><authors><author><keyname>Biswas</keyname><forenames>Soumyajyoti</forenames></author><author><keyname>Chatterjee</keyname><forenames>Arnab</forenames></author><author><keyname>Sen</keyname><forenames>Parongama</forenames></author></authors><title>Disorder induced phase transition in kinetic models of opinion dynamics</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>10 pages, 5 eps figs</comments><journal-ref>Physica A: Statistical Mechanics and its Applications 391 (2012)
  pp. 3257-3265</journal-ref><doi>10.1016/j.physa.2012.01.046</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model of continuous opinion dynamics, where mutual interactions
can be both positive and negative. Different types of distributions for the
interactions, all characterized by a single parameter $p$ denoting the fraction
of negative interactions, are considered. Results from exact calculation of a
discrete version and numerical simulations of the continuous version of the
model indicate the existence of a universal continuous phase transition at
p=p_c below which a consensus is reached. Although the order-disorder
transition is analogous to a ferromagnetic-paramagnetic phase transition with
comparable critical exponents, the model is characterized by some distinctive
features relevant to a social system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0908</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0908</id><created>2011-02-04</created><authors><author><keyname>Langer</keyname><forenames>Alexander</forenames></author><author><keyname>Rossmanith</keyname><forenames>Peter</forenames></author><author><keyname>Sikdar</keyname><forenames>Somnath</forenames></author></authors><title>Linear-Time Algorithms for Graphs of Bounded Rankwidth: A Fresh Look
  Using Game Theory</title><categories>cs.DS cs.CC</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an alternative proof of a theorem by Courcelle, Makowski and
Rotics which states that problems expressible in MSO are solvable in linear
time for graphs of bounded rankwidth. Our proof uses a game-theoretic approach
and has the advantage of being self-contained, intuitive, and fairly easy to
follow. In particular, our presentation does not assume any background in logic
or automata theory. We believe that it is good to have alternative proofs of
this important result. Moreover our approach can be generalized to prove other
results of a similar flavor, for example, that of Courcelle's Theorem for
treewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0913</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0913</id><created>2011-02-04</created><updated>2012-04-05</updated><authors><author><keyname>F&#xe9;dou</keyname><forenames>Jean-Marc</forenames></author><author><keyname>Fici</keyname><forenames>Gabriele</forenames></author></authors><title>Automata and Differentiable Words</title><categories>cs.DM cs.FL</categories><comments>Accepted for publication</comments><msc-class>68R15</msc-class><journal-ref>Theoretical Computer Science 443:46-62 (2012)</journal-ref><doi>10.1016/j.tcs.2012.03.033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit the construction of a deterministic automaton that, given k &gt; 0,
recognizes the (regular) language of k-differentiable words. Our approach
follows a scheme of Crochemore et al. based on minimal forbidden words. We
extend this construction to the case of C\infinity-words, i.e., words
differentiable arbitrary many times. We thus obtain an infinite automaton for
representing the set of C\infinity-words. We derive a classification of
C\infinity-words induced by the structure of the automaton. Then, we introduce
a new framework for dealing with \infinity-words, based on a three letter
alphabet. This allows us to define a compacted version of the automaton, that
we use to prove that every C\infinity-word admits a repetition in C\infinity
whose length is polynomially bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0918</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0918</id><created>2011-02-04</created><updated>2011-02-07</updated><authors><author><keyname>Mohite</keyname><forenames>Mayur</forenames></author><author><keyname>Narahari</keyname><forenames>Y.</forenames></author></authors><title>Incentive Compatible Influence Maximization in Social Networks and
  Application to Viral Marketing</title><categories>cs.GT cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information diffusion and influence maximization are important and
extensively studied problems in social networks. Various models and algorithms
have been proposed in the literature in the context of the influence
maximization problem. A crucial assumption in all these studies is that the
influence probabilities are known to the social planner. This assumption is
unrealistic since the influence probabilities are usually private information
of the individual agents and strategic agents may not reveal them truthfully.
Moreover, the influence probabilities could vary significantly with the type of
the information flowing in the network and the time at which the information is
propagating in the network. In this paper, we use a mechanism design approach
to elicit influence probabilities truthfully from the agents. We first work
with a simple model, the influencer model, where we assume that each user knows
the level of influence she has on her neighbors but this is private
information. In the second model, the influencer-influencee model, which is
more realistic, we determine influence probabilities by combining the
probability values reported by the influencers and influencees. In the context
of the first model, we present how VCG (Vickrey-Clarke-Groves) mechanisms could
be used for truthfully eliciting the influence probabilities. Our main
contribution is to design a scoring rule based mechanism in the context of the
influencer-influencee model. In particular, we show the incentive compatibility
of the mechanisms when the scoring rules are proper and propose a reverse
weighted scoring rule based mechanism as an appropriate mechanism to use. We
also discuss briefly the implementation of such a mechanism in viral marketing
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0919</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0919</id><created>2011-02-04</created><authors><author><keyname>De Sterck</keyname><forenames>Hans</forenames></author></authors><title>A Self-learning Algebraic Multigrid Method for Extremal Singular
  Triplets and Eigenpairs</title><categories>math.NA cs.NA</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A self-learning algebraic multigrid method for dominant and minimal singular
triplets and eigenpairs is described. The method consists of two multilevel
phases. In the first, multiplicative phase (setup phase), tentative singular
triplets are calculated along with a multigrid hierarchy of interpolation
operators that approximately fit the tentative singular vectors in a collective
and self-learning manner, using multiplicative update formulas. In the second,
additive phase (solve phase), the tentative singular triplets are improved up
to the desired accuracy by using an additive correction scheme with fixed
interpolation operators, combined with a Ritz update. A suitable generalization
of the singular value decomposition is formulated that applies to the coarse
levels of the multilevel cycles. The proposed algorithm combines and extends
two existing multigrid approaches for symmetric positive definite eigenvalue
problems to the case of dominant and minimal singular triplets. Numerical tests
on model problems from different areas show that the algorithm converges to
high accuracy in a modest number of iterations, and is flexible enough to deal
with a variety of problems due to its self-learning properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0930</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0930</id><created>2011-02-04</created><authors><author><keyname>Ware</keyname><forenames>Jeb</forenames></author><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>An Evaluation of Link Neighborhood Lexical Signatures to Rediscover
  Missing Web Pages</title><categories>cs.IR cs.DL cs.SI</categories><comments>24 pages, 13 figures, 8 tables, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For discovering the new URI of a missing web page, lexical signatures, which
consist of a small number of words chosen to represent the &quot;aboutness&quot; of a
page, have been previously proposed. However, prior methods relied on computing
the lexical signature before the page was lost, or using cached or archived
versions of the page to calculate a lexical signature. We demonstrate a system
of constructing a lexical signature for a page from its link neighborhood, that
is the &quot;backlinks&quot;, or pages that link to the missing page. After testing
various methods, we show that one can construct a lexical signature for a
missing web page using only ten backlink pages. Further, we show that only the
first level of backlinks are useful in this effort. The text that the backlinks
use to point to the missing page is used as input for the creation of a
four-word lexical signature. That lexical signature is shown to successfully
find the target URI in over half of the test cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0947</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0947</id><created>2011-02-04</created><authors><author><keyname>Berstel</keyname><forenames>Jean</forenames></author><author><keyname>Boasson</keyname><forenames>Luc</forenames></author><author><keyname>Fagnot</keyname><forenames>Isabelle</forenames></author></authors><title>Splicing systems and the Chomsky hierarchy</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we prove decidability properties and new results on the
position of the family of languages generated by (circular) splicing systems
within the Chomsky hierarchy. The two main results of the paper are the
following. First, we show that it is decidable, given a circular splicing
language and a regular language, whether they are equal. Second, we prove the
language generated by an alphabetic splicing system is context-free. Alphabetic
splicing systems are a generalization of simple and semi-simple splicin systems
already considered in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0951</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0951</id><created>2011-02-04</created><authors><author><keyname>Kerneis</keyname><forenames>Gabriel</forenames><affiliation>PPS</affiliation></author><author><keyname>Chroboczek</keyname><forenames>Juliusz</forenames><affiliation>PPS</affiliation></author></authors><title>CPC: programming with a massive number of lightweight threads</title><categories>cs.PL</categories><comments>To appear in PLACES'11</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Threads are a convenient and modular abstraction for writing concurrent
programs, but often fairly expensive. The standard alternative to threads,
event-loop programming, allows much lighter units of concurrency, but leads to
code that is difficult to write and even harder to understand. Continuation
Passing C (CPC) is a translator that converts a program written in threaded
style into a program written with events and native system threads, at the
programmer's choice. Together with two undergraduate students, we taught
ourselves how to program in CPC by writing Hekate, a massively concurrent
network server designed to efficiently handle tens of thousands of
simultaneously connected peers. In this paper, we describe a number of
programming idioms that we learnt while writing Hekate; while some of these
idioms are specific to CPC, many should be applicable to other programming
systems with sufficiently cheap threads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0952</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0952</id><created>2011-02-04</created><authors><author><keyname>Hachicha</keyname><forenames>Marouane</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>Pattern tree-based XOLAP rollup operator for XML complex hierarchies</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>International Conference on Machine and Web Intelligence (ICMWI
  10), Algiers : Algeria (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rise of XML as a standard for representing business data, XML data
warehousing appears as a suitable solution for decision-support applications.
In this context, it is necessary to allow OLAP analyses on XML data cubes.
Thus, XQuery extensions are needed. To define a formal framework and allow
much-needed performance optimizations on analytical queries expressed in
XQuery, defining an algebra is desirable. However, XML-OLAP (XOLAP) algebras
from the literature still largely rely on the relational model. Hence, we
propose in this paper a rollup operator based on a pattern tree in order to
handle multidimensional XML data expressed within complex hierarchies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0958</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0958</id><created>2011-02-04</created><authors><author><keyname>C&#xc1;novas</keyname><forenames>M. J.</forenames></author><author><keyname>L&#xd3;pez</keyname><forenames>M. A.</forenames></author><author><keyname>Mordukhovich</keyname><forenames>B. S.</forenames></author><author><keyname>Parra</keyname><forenames>J.</forenames></author></authors><title>Quantitative Stability and Optimality Conditions in Convex Semi-Infinite
  and Infinite Programming</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns parameterized convex infinite (or semi-infinite)
inequality systems whose decision variables run over general
infinite-dimensional Banach (resp. finite-dimensional) spaces and that are
indexed by an arbitrary fixed set T . Parameter perturbations on the right-hand
side of the inequalities are measurable and bounded, and thus the natural
parameter space is $l_{\infty}(T)$. Based on advanced variational analysis, we
derive a precise formula for computing the exact Lipschitzian bound of the
feasible solution map, which involves only the system data, and then show that
this exact bound agrees with the coderivative norm of the aforementioned
mapping. On one hand, in this way we extend to the convex setting the results
of [4] developed in the linear framework under the boundedness assumption on
the system coefficients. On the other hand, in the case when the decision space
is reflexive, we succeed to remove this boundedness assumption in the general
convex case, establishing therefore results new even for linear infinite and
semi-infinite systems. The last part of the paper provides verifiable necessary
optimality conditions for infinite and semi-infinite programs with convex
inequality constraints and general nonsmooth and nonconvex objectives. In this
way we extend the corresponding results of [5] obtained for programs with
linear infinite inequality constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0964</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0964</id><created>2011-02-04</created><authors><author><keyname>Song</keyname><forenames>Yiwei</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>Structured interference-mitigation in two-hop networks</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, to be presented at ITA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two-hop S-R-D Gaussian networks with a source (S), a relay (R)
and a destination (D), some of which experience additive interference. This
additive interference, which renders the channels state-dependent, is either a)
experienced at the destination D and known non-causally at the source S, or b)
experienced at the relay R and known at the destination D. In both cases, one
would hope to exploit this knowledge of the channel state at some of the nodes
to obtain &quot;clean&quot; or interference-free channels, just as Costa's dirty-paper
coding does for one-hop channels with state non-causally known to the
transmitter. We demonstrate a scheme which achieves to within 0.5 bit of a
&quot;clean&quot; channel. This novel scheme is based on nested-lattice code and a
Decode-and-Forward (DF) relay. Intuitively, this strategy uses the structure
provided by nested lattice codes to cancel the &quot;integer&quot; (or lattice quantized)
part of the interference and treats the &quot;residual&quot; (or quantization noise) as
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0969</identifier>
 <datestamp>2012-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0969</id><created>2011-02-04</created><updated>2012-04-10</updated><authors><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author><author><keyname>Desai</keyname><forenames>Devendra</forenames></author></authors><title>On the Complexity of Newman's Community Finding Approach for Biological
  and Social Networks</title><categories>physics.soc-ph cs.CC cs.DM cs.SI</categories><comments>Journal of Computer and System Sciences, 2012</comments><msc-class>68Q25, 68R01, 05C85</msc-class><acm-class>F.2.2; G.2.2</acm-class><doi>10.1016/j.jcss.2012.04.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph of interactions, a module (also called a community or cluster)
is a subset of nodes whose fitness is a function of the statistical
significance of the pairwise interactions of nodes in the module. The topic of
this paper is a model-based community finding approach, commonly referred to as
modularity clustering, that was originally proposed by Newman and has
subsequently been extremely popular in practice. Various heuristic methods are
currently employed for finding the optimal solution. However, the exact
computational complexity of this approach is still largely unknown.
  To this end, we initiate a systematic study of the computational complexity
of modularity clustering. Due to the specific quadratic nature of the
modularity function, it is necessary to study its value on sparse graphs and
dense graphs separately. Our main results include a (1+\eps)-inapproximability
for dense graphs and a logarithmic approximation for sparse graphs. We make use
of several combinatorial properties of modularity to get these results. These
are the first non-trivial approximability results beyond the previously known
NP-hardness results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0987</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0987</id><created>2011-02-04</created><updated>2012-03-01</updated><authors><author><keyname>No&#xeb;l</keyname><forenames>Pierre-Andr&#xe9;</forenames></author><author><keyname>Allard</keyname><forenames>Antoine</forenames></author><author><keyname>H&#xe9;bert-Dufresne</keyname><forenames>Laurent</forenames></author><author><keyname>Marceau</keyname><forenames>Vincent</forenames></author><author><keyname>Dub&#xe9;</keyname><forenames>Louis J.</forenames></author></authors><title>Propagation on networks: an exact alternative perspective</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>8 pages, 4 figures</comments><journal-ref>Phys. Rev. E 85, 031118 (2012)</journal-ref><doi>10.1103/PhysRevE.85.031118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By generating the specifics of a network structure only when needed
(on-the-fly), we derive a simple stochastic process that exactly models the
time evolution of susceptible-infectious dynamics on finite-size networks. The
small number of dynamical variables of this birth-death Markov process greatly
simplifies analytical calculations. We show how a dual analytical description,
treating large scale epidemics with a Gaussian approximations and small
outbreaks with a branching process, provides an accurate approximation of the
distribution even for rather small networks. The approach also offers important
computational advantages and generalizes to a vast class of systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.0989</identifier>
 <datestamp>2011-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.0989</id><created>2011-02-04</created><updated>2011-06-06</updated><authors><author><keyname>Sun</keyname><forenames>Yi</forenames></author><author><keyname>Sundararajan</keyname><forenames>Mukund</forenames></author></authors><title>Axiomatic Attribution for Multilinear Functions</title><categories>cs.GT</categories><comments>21 pages, 2 figures, updated version for EC '11</comments><acm-class>J.4; K.6.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the attribution problem, that is, the problem of attributing a
change in the value of a characteristic function to its independent variables.
We make three contributions. First, we propose a formalization of the problem
based on a standard cost sharing model. Second, we show that there is a unique
attribution method that satisfies Dummy, Additivity, Conditional Nonnegativity,
Affine Scale Invariance, and Anonymity for all characteristic functions that
are the sum of a multilinear function and an additive function. We term this
the Aumann-Shapley-Shubik method. Conversely, we show that such a uniqueness
result does not hold for characteristic functions outside this class. Third, we
study multilinear characteristic functions in detail; we describe a
computationally efficient implementation of the Aumann-Shapley-Shubik method
and discuss practical applications to pay-per-click advertising and portfolio
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1003</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1003</id><created>2011-02-04</created><authors><author><keyname>Amossen</keyname><forenames>Rasmus Resen</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>A New Data Layout For Set Intersection on GPUs</title><categories>cs.DS cs.DC</categories><comments>A version of this paper appears in Proceedings of IPDPS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Set intersection is the core in a variety of problems, e.g. frequent itemset
mining and sparse boolean matrix multiplication. It is well-known that large
speed gains can, for some computational problems, be obtained by using a
graphics processing unit (GPU) as a massively parallel computing device.
However, GPUs require highly regular control flow and memory access patterns,
and for this reason previous GPU methods for intersecting sets have used a
simple bitmap representation. This representation requires excessive space on
sparse data sets. In this paper we present a novel data layout, &quot;BatMap&quot;, that
is particularly well suited for parallel processing, and is compact even for
sparse data.
  Frequent itemset mining is one of the most important applications of set
intersection. As a case-study on the potential of BatMaps we focus on frequent
pair mining, which is a core special case of frequent itemset mining. The main
finding is that our method is able to achieve speedups over both Apriori and
FP-growth when the number of distinct items is large, and the density of the
problem instance is above 1%. Previous implementations of frequent itemset
mining on GPU have not been able to show speedups over the best single-threaded
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1006</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1006</id><created>2011-02-04</created><authors><author><keyname>Ashley</keyname><forenames>Mary</forenames></author><author><keyname>Berger-Wolf</keyname><forenames>Tanya</forenames></author><author><keyname>Berman</keyname><forenames>Piotr</forenames></author><author><keyname>Chaovalitwongse</keyname><forenames>Wanpracha</forenames></author><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author><author><keyname>Kao</keyname><forenames>Ming-Yang</forenames></author></authors><title>On Approximating Four Covering and Packing Problems</title><categories>cs.CC cs.DM cs.DS q-bio.PE</categories><comments>25 pages</comments><msc-class>68Q17, 68Q25, 68W25, 68W40, 92D25</msc-class><acm-class>F.2.2; J.3</acm-class><journal-ref>Journal of Computer and System Sciences, 75, 287-302, 2009</journal-ref><doi>10.1016/j.jcss.2009.01.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider approximability issues of the following four
problems: triangle packing, full sibling reconstruction, maximum profit
coverage and 2-coverage. All of them are generalized or specialized versions of
set-cover and have applications in biology ranging from full-sibling
reconstructions in wild populations to biomolecular clusterings; however, as
this paper shows, their approximability properties differ considerably. Our
inapproximability constant for the triangle packing problem improves upon the
previous results; this is done by directly transforming the inapproximability
gap of Haastad for the problem of maximizing the number of satisfied equations
for a set of equations over GF(2) and is interesting in its own right. Our
approximability results on the full siblings reconstruction problems answers
questions originally posed by Berger-Wolf et al. and our results on the maximum
profit coverage problem provides almost matching upper and lower bounds on the
approximation ratio, answering a question posed by Hassin and Or.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1025</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1025</id><created>2011-02-04</created><updated>2011-09-08</updated><authors><author><keyname>Venkatesan</keyname><forenames>R. C.</forenames></author><author><keyname>Plastino</keyname><forenames>A.</forenames></author></authors><title>Deformed Statistics Kullback-Leibler Divergence Minimization within a
  Scaled Bregman Framework</title><categories>cond-mat.stat-mech cs.IT math-ph math.IT math.MP</categories><comments>16 pages. Iterative corrections and expansions</comments><doi>10.1016/j.physleta.2011.09.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized Kullback-Leibler divergence (K-Ld) in Tsallis statistics
[constrained by the additive duality of generalized statistics (dual
generalized K-Ld)] is here reconciled with the theory of Bregman divergences
for expectations defined by normal averages, within a measure-theoretic
framework. Specifically, it is demonstrated that the dual generalized K-Ld is a
scaled Bregman divergence. The Pythagorean theorem is derived from the minimum
discrimination information-principle using the dual generalized K-Ld as the
measure of uncertainty, with constraints defined by normal averages. The
minimization of the dual generalized K-Ld, with normal averages constraints, is
shown to exhibit distinctly unique features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1027</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1027</id><created>2011-02-04</created><authors><author><keyname>Abi-Haidar</keyname><forenames>Alaa</forenames></author><author><keyname>Rocha</keyname><forenames>Luis M.</forenames></author></authors><title>Collective Classification of Textual Documents by Guided
  Self-Organization in T-Cell Cross-Regulation Dynamics</title><categories>cs.IR cs.AI cs.LG nlin.AO q-bio.OT</categories><journal-ref>Evolutionary Intelligence. 2011. Volume 4, Number 2, 69-80</journal-ref><doi>10.1007/s12065-011-0052-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and study an agent-based model of T-Cell cross-regulation in the
adaptive immune system, which we apply to binary classification. Our method
expands an existing analytical model of T-cell cross-regulation (Carneiro et
al. in Immunol Rev 216(1):48-68, 2007) that was used to study the
self-organizing dynamics of a single population of T-Cells in interaction with
an idealized antigen presenting cell capable of presenting a single antigen.
With agent-based modeling we are able to study the self-organizing dynamics of
multiple populations of distinct T-cells which interact via antigen presenting
cells that present hundreds of distinct antigens. Moreover, we show that such
self-organizing dynamics can be guided to produce an effective binary
classification of antigens, which is competitive with existing machine learning
methods when applied to biomedical text classification. More specifically, here
we test our model on a dataset of publicly available full-text biomedical
articles provided by the BioCreative challenge (Krallinger in The biocreative
ii. 5 challenge overview, p 19, 2009). We study the robustness of our model's
parameter configurations, and show that it leads to encouraging results
comparable to state-of-the-art classifiers. Our results help us understand both
T-cell cross-regulation as a general principle of guided self-organization, as
well as its applicability to document classification. Therefore, we show that
our bio-inspired algorithm is a promising novel method for biomedical article
classification and for binary document classification in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1038</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1038</id><created>2011-02-04</created><authors><author><keyname>Manshadi</keyname><forenames>Vahideh H.</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author></authors><title>Prisoner's Dilemma on Graphs with Large Girth</title><categories>cs.SI math.PR physics.soc-ph</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the evolution of cooperation in populations where individuals play
prisoner's dilemma on a network. Every node of the network corresponds on an
individual choosing whether to cooperate or defect in a repeated game. The
players revise their actions by imitating those neighbors who have higher
payoffs. We show that when the interactions take place on graphs with large
girth, cooperation is more likely to emerge. On the flip side, in graphs with
many cycles of length 3 and 4, defection spreads more rapidly. One of the key
ideas of our analysis is that our dynamics can be seen as a perturbation of the
voter model. We write the transition kernel of the corresponding Markov chain
in terms of the pairwise correlations in the voter model. We analyze the
pairwise correlation and show that in graphs with relatively large girth,
cooperators cluster and help each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1053</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1053</id><created>2011-02-05</created><authors><author><keyname>Blackburn</keyname><forenames>Simon R.</forenames></author><author><keyname>Ostafe</keyname><forenames>Alina</forenames></author><author><keyname>Shparlinski</keyname><forenames>Igor E.</forenames></author></authors><title>On the Distribution of the Subset Sum Pseudorandom Number Generator on
  Elliptic Curves</title><categories>math.NT cs.CR</categories><msc-class>Primary 11K45, 11T71, Secondary 11G05, 11T23, 65C05, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a prime $p$, an elliptic curve $\E/\F_p$ over the finite field $\F_p$
of $p$ elements and a binary \lrs\ $\(u(n)\)_{n =1}^\infty$ of order~$r$, we
study the distribution of the sequence of points $$ \sum_{j=0}^{r-1} u(n+j)P_j,
\qquad n =1,..., N, $$ on average over all possible choices of $\F_p$-rational
points $P_1,..., P_r$ on~$\E$. For a sufficiently large $N$ we improve and
generalise a previous result in this direction due to E.~El~Mahassni.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1054</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1054</id><created>2011-02-05</created><updated>2011-11-21</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>A new face of the branching recurrence of computability logic</title><categories>cs.LO math.LO</categories><msc-class>03B47, 03B70, 68Q10</msc-class><acm-class>F.1.1; F.1.2; F.1.3</acm-class><journal-ref>Applied Mathematics Letters 25 (2012), pp. 1585-1589</journal-ref><doi>10.1016/j.aml.2011.11.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter introduces a new, substantially simplified version of the
branching recurrence operation of computability logic (see
http://www.cis.upenn.edu/~giorgi/cl.html), and proves its equivalence to the
old, &quot;canonical&quot; version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1059</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1059</id><created>2011-02-05</created><updated>2011-08-17</updated><authors><author><keyname>Pei</keyname><forenames>Yu</forenames></author><author><keyname>Wei</keyname><forenames>Yi</forenames></author><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Nordio</keyname><forenames>Martin</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>Code-based Automated Program Fixing</title><categories>cs.SE</categories><journal-ref>Proceedings of the 26th IEEE/ACM International Conference on
  Automated Software Engineering (ASE'11). Pgg. 392--395, ACM, November 2011</journal-ref><doi>10.1109/ASE.2011.6100080</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many programmers, when they encounter an error, would like to have the
benefit of automatic fix suggestions---as long as they are, most of the time,
adequate. Initial research in this direction has generally limited itself to
specific areas, such as data structure classes with carefully designed
interfaces, and relied on simple approaches. To provide high-quality fix
suggestions in a broad area of applicability, the present work relies on the
presence of contracts in the code, and on the availability of dynamic analysis
to gather evidence on the values taken by expressions derived from the program
text. The ideas have been built into the AutoFix-E2 automatic fix generator.
Applications of AutoFix-E2 to general-purpose software, such as a library to
manipulate documents, show that the approach provides an improvement over
previous techniques, in particular purely model-based approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1061</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1061</id><created>2011-02-05</created><updated>2011-03-03</updated><authors><author><keyname>Ilik</keyname><forenames>Danko</forenames></author></authors><title>Continuation-passing Style Models Complete for Intuitionistic Logic</title><categories>math.LO cs.LO cs.PL</categories><msc-class>03B20, 03B35, 03B40, 68N18, 03F55, 03F50, 03B55</msc-class><journal-ref>Annals of Pure and Applied Logic 164(6), 2013</journal-ref><doi>10.1016/j.apal.2012.05.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of models is presented, in the form of continuation monads
polymorphic for first-order individuals, that is sound and complete for minimal
intuitionistic predicate logic. The proofs of soundness and completeness are
constructive and the computational content of their composition is, in
particular, a $\beta$-normalisation-by-evaluation program for simply typed
lambda calculus with sum types. Although the inspiration comes from Danvy's
type-directed partial evaluator for the same lambda calculus, the there
essential use of delimited control operators (i.e. computational effects) is
avoided. The role of polymorphism is crucial -- dropping it allows one to
obtain a notion of model complete for classical predicate logic. The connection
between ours and Kripke models is made through a strengthening of the
Double-negation Shift schema.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1064</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1064</id><created>2011-02-05</created><authors><author><keyname>Sakr</keyname><forenames>Sherif</forenames></author><author><keyname>Alomari</keyname><forenames>Mohammad</forenames></author></authors><title>A Decade of Database Research Publications</title><categories>cs.DL cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the database research publications of four major core database
technology conferences (SIGMOD, VLDB, ICDE, EDBT), two main theoretical
database conferences (PODS, ICDT) and three database journals (TODS, VLDB
Journal, TKDE) over a period of 10 years (2001 - 2010). Our analysis considers
only regular papers as we do not include short papers, demo papers, posters,
tutorials or panels into our statistics. We rank the research scholars
according to their number of publication in each conference/journal separately
and in combined. We also report about the growth in the number of research
publications and the size of the research community in the last decade.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1087</identifier>
 <datestamp>2015-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1087</id><created>2011-02-05</created><updated>2015-05-13</updated><authors><author><keyname>Gilbert</keyname><forenames>Jesse D.</forenames></author></authors><title>Graph Theory</title><categories>cs.DM math.CO</categories><comments>There was significant text overlap with arXiv:1102.1087 and
  arXiv:1107.3279</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This was a replacement paper. Some of the conclusions from statistical graph
theory were reiterated in the sixth section, but not fully resolved therein.
(We later found statistical errors in some of the conclusions; we are still
working on this.) Most of the redundancies in the later sections were deleted,
but there were some errors related to graceful labeling that we had added. An
important number-theoretical technique in the opening section related to one of
the main techniques in the last (sixth) section, but we found a critical error:
We assumed that $$N \Prod_{r_k \in C} (1-1/r_k)=\pi(N),$$ but later found this
to be incorrect. That is, $\pi(N) \not = N^{2/3},$ as we had concluded was
asymptotically true.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1096</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1096</id><created>2011-02-05</created><updated>2011-03-28</updated><authors><author><keyname>Budinich</keyname><forenames>Michele</forenames></author><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author></authors><title>Repeated Matching Pennies with Limited Randomness</title><categories>cs.GT cs.CC</categories><comments>To appear in Proceedings of the 12th ACM Conference on Electronic
  Commerce. ACM, New York, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a repeated Matching Pennies game in which players have limited
access to randomness. Playing the (unique) Nash equilibrium in this n-stage
game requires n random bits. Can there be Nash equilibria that use less than n
random coins?
  Our main results are as follows: We give a full characterization of
approximate equilibria, showing that, for any e in [0, 1], the game has a
e-Nash equilibrium if and only if both players have (1 - e)n random coins. When
players are bound to run in polynomial time, Nash equilibria can exist if and
only if one-way functions exist. It is possible to trade-off randomness for
running time. In particular, under reasonable assumptions, if we give one
player only O(log n) random coins but allow him to run in arbitrary polynomial
time and we restrict his opponent to run in time n^k, for some fixed k, then we
can sustain an Nash equilibrium. When the game is played for an infinite amount
of rounds with time discounted utilities, under reasonable assumptions, we can
reduce the amount of randomness required to achieve a e-Nash equilibrium to n,
where n is the number of random coins necessary to achieve an approximate Nash
equilibrium in the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1101</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1101</id><created>2011-02-05</created><authors><author><keyname>Michel</keyname><forenames>Vincent</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>LNAO, Parietal, LCogn</affiliation></author><author><keyname>Eger</keyname><forenames>Evelyn</forenames><affiliation>LCogn</affiliation></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author></authors><title>Total variation regularization for fMRI-based prediction of behaviour</title><categories>cs.CV q-bio.NC</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Medical Imaging (2011)</journal-ref><doi>10.1109/TMI.2011.2113378</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While medical imaging typically provides massive amounts of data, the
extraction of relevant information for predictive diagnosis remains a difficult
challenge. Functional MRI (fMRI) data, that provide an indirect measure of
task-related or spontaneous neuronal activity, are classically analyzed in a
mass-univariate procedure yielding statistical parametric maps. This analysis
framework disregards some important principles of brain organization:
population coding, distributed and overlapping representations. Multivariate
pattern analysis, i.e., the prediction of behavioural variables from brain
activation patterns better captures this structure. To cope with the high
dimensionality of the data, the learning method has to be regularized. However,
the spatial structure of the image is not taken into account in standard
regularization methods, so that the extracted features are often hard to
interpret. More informative and interpretable results can be obtained with the
l_1 norm of the image gradient, a.k.a. its Total Variation (TV), as
regularization. We apply for the first time this method to fMRI data, and show
that TV regularization is well suited to the purpose of brain mapping while
being a powerful tool for brain decoding. Moreover, this article presents the
first use of TV regularization for classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1103</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1103</id><created>2011-02-05</created><authors><author><keyname>Ioannou</keyname><forenames>Ioanna</forenames></author><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author></authors><title>Compound Outage Probability and Capacity of a Class of Fading MIMO
  Channels with Channel Distribution Uncertainty</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE IT Transactions, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outage probability and capacity of a class of block-fading MIMO channels are
considered with partial channel distribution information. Specifically, the
channel or its distribution are not known but the latter is known to belong to
a class of distributions where each member is within a certain distance
(uncertainty) from a nominal distribution. Relative entropy is used as a
measure of distance between distributions. Compound outage probability defined
as min (over the transmit signal distribution) -max (over the channel
distribution class) outage probability is introduced and investigated. This
generalizes the standard outage probability to the case of partial channel
distribution information. Compound outage probability characterization (via
one-dimensional convex optimization), its properties and approximations are
given. It is shown to have two-regime behavior: when the nominal outage
probability decreases (e.g. by increasing the SNR), the compound outage first
decreases linearly down to a certain threshold (related to relative entropy
distance) and then only logarithmically (i.e. very slowly), so that no
significant further decrease is possible. The compound outage depends on the
relative entropy distance and the nominal outage only, all other details
(nominal fading and noise distributions) being irrelevant. The transmit signal
distribution optimized for the nominal channel distribution is shown to be also
optimal for the whole class of distributions. The effect of swapping the
distributions in relative entropy is investigated and an error floor effect is
established. The compound outage probability under Lp distance constraint is
also investigated. The obtained results hold for a generic channel model
(arbitrary nominal fading and noise distributions).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1107</identifier>
 <datestamp>2012-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1107</id><created>2011-02-05</created><updated>2011-03-24</updated><authors><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Savla</keyname><forenames>Ketan</forenames></author><author><keyname>Acemoglu</keyname><forenames>Daron</forenames></author><author><keyname>Dahleh</keyname><forenames>Munther A.</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>Robust Distributed Routing in Dynamical Flow Networks - Part I: Locally
  Responsive Policies and Weak Resilience</title><categories>cs.SY math.CA math.DS math.OC nlin.AO</categories><comments>32 pages, 5 figures, journal submission</comments><doi>10.1016/j.compeleceng.2012.04.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robustness of distributed routing policies is studied for dynamical flow
networks, with respect to adversarial disturbances that reduce the link flow
capacities. A dynamical flow network is modeled as a system of ordinary
differential equations derived from mass conservation laws on a directed
acyclic graph with a single origin-destination pair and a constant inflow at
the origin. Routing policies regulate the way the inflow at a non-destination
node gets split among its outgoing links as a function of the current particle
density, while the outflow of a link is modeled to depend on the current
particle density on that link through a flow function. The dynamical flow
network is called partially transferring if the total inflow at the destination
node is asymptotically bounded away from zero, and its weak resilience is
measured as the minimum sum of the link-wise magnitude of all disturbances that
make it not partially transferring. The weak resilience of a dynamical flow
network with arbitrary routing policy is shown to be upper-bounded by the
network's min-cut capacity, independently of the initial flow conditions.
Moreover, a class of distributed routing policies that rely exclusively on
local information on the particle densities, and are locally responsive to
that, is shown to yield such maximal weak resilience. These results imply that
locality constraints on the information available to the routing policies do
not cause loss of weak resilience. Some fundamental properties of dynamical
flow networks driven by locally responsive distributed policies are analyzed in
detail, including global convergence to a unique limit flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1111</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1111</id><created>2011-02-05</created><authors><author><keyname>Mullins</keyname><forenames>Matt</forenames></author><author><keyname>Fizzano</keyname><forenames>Perry</forenames></author></authors><title>Treelicious: a System for Semantically Navigating Tagged Web Pages</title><categories>cs.IR</categories><comments>6 pages, 3 figures</comments><acm-class>H.3.3; H.4.m</acm-class><journal-ref>WI-IAT '10: Proceedings of the 2010 IEEE/WIC/ACM International
  Conference on Web Intelligence and Intelligent Agent Technology</journal-ref><doi>10.1109/WI-IAT.2010.289</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative tagging has emerged as a popular and effective method for
organizing and describing pages on the Web. We present Treelicious, a system
that allows hierarchical navigation of tagged web pages. Our system enriches
the navigational capabilities of standard tagging systems, which typically
exploit only popularity and co-occurrence data. We describe a prototype that
leverages the Wikipedia category structure to allow a user to semantically
navigate pages from the Delicious social bookmarking service. In our system a
user can perform an ordinary keyword search and browse relevant pages but is
also given the ability to broaden the search to more general topics and narrow
it to more specific topics. We show that Treelicious indeed provides an
intuitive framework that allows for improved and effective discovery of
knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1102.1115</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1102.1115</id><created>2011-02-05</created><authors><author><keyname>Khanafer</keyname><forenames>Ali</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Sourabh</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author></authors><title>Adaptive Resource Allocation in Jamming Teams Using Game Theory</title><categories>cs.GT cs.IT cs.SY math.IT math.OC</categories><comments>6 pages, 2 figures, submitted to RAWNET/WNC3 2011</comments><msc-class>91Axx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the problem of power allocation and adaptive
modulation in teams of decision makers. We consider the special case of two
teams with each team consisting of two mobile agents. Agents belonging to the
same team communicate over wireless ad hoc networks, and they try to split
their available power between the tasks of communication and jamming the nodes
of the other team. The agents have constraints on their total energy and
instantaneous power usage. The cost function adopted is the difference between
the rates of erroneously transmitted bits of each team. We model the adaptive
modulation problem as a zero-sum matrix game which in turn gives rise to a a
continuous kernel game to handle power control. Based on the communications
model, we present sufficient conditions on the physical parameters of the
agents for the existence of a pure strategy saddle-point equilibrium (PSSPE).
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="18000" completeListSize="102538">1122234|19001</resumptionToken>
</ListRecords>
</OAI-PMH>
