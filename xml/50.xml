<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T02:00:35Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|49001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2218</identifier>
 <datestamp>2013-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2218</id><created>2013-08-09</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Shrivastava</keyname><forenames>Anshumali</forenames></author></authors><title>Coding for Random Projections</title><categories>cs.LG cs.DS cs.IT math.IT stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The method of random projections has become very popular for large-scale
applications in statistical learning, information retrieval, bio-informatics
and other applications. Using a well-designed coding scheme for the projected
data, which determines the number of bits needed for each projected value and
how to allocate these bits, can significantly improve the effectiveness of the
algorithm, in storage cost as well as computational speed. In this paper, we
study a number of simple coding schemes, focusing on the task of similarity
estimation and on an application to training linear classifiers. We demonstrate
that uniform quantization outperforms the standard existing influential method
(Datar et. al. 2004). Indeed, we argue that in many cases coding with just a
small number of bits suffices. Furthermore, we also develop a non-uniform 2-bit
coding scheme that generally performs well in practice, as confirmed by our
experiments on training linear support vector machines (SVM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2234</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2234</id><created>2013-08-09</created><authors><author><keyname>Ahrweiler</keyname><forenames>Petra</forenames></author><author><keyname>Keane</keyname><forenames>Mark T.</forenames></author></authors><title>Innovation networks</title><categories>cs.AI cs.SI physics.soc-ph</categories><journal-ref>Mind &amp; Society, 12, 73-90, 2013</journal-ref><doi>10.1007/s11299-013-0123-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper advances a framework for modeling the component interactions
between cognitive and social aspects of scientific creativity and technological
innovation. Specifically, it aims to characterize Innovation Networks; those
networks that involve the interplay of people, ideas and organizations to
create new, technologically feasible, commercially-realizable products,
processes and organizational structures. The tri-partite framework captures
networks of ideas (Concept Level), people (Individual Level) and social
structures (Social-Organizational Level) and the interactions between these
levels. At the concept level, new ideas are the nodes that are created and
linked, kept open for further investigation or closed if solved by actors at
the individual or organizational levels. At the individual level, the nodes are
actors linked by shared worldviews (based on shared professional, educational,
experiential backgrounds) who are the builders of the concept level. At the
social-organizational level, the nodes are organizations linked by common
efforts on a given project (e.g., a company-university collaboration) that by
virtue of their intellectual property or rules of governance constrain the
actions of individuals (at the Individual Level) or ideas (at the Concept
Level). After describing this framework and its implications we paint a number
of scenarios to flesh out how it can be applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2236</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2236</id><created>2013-08-09</created><authors><author><keyname>Foster</keyname><forenames>Meadhbh</forenames></author><author><keyname>Keane</keyname><forenames>Mark T.</forenames></author></authors><title>Surprise: Youve got some explaining to do</title><categories>cs.AI cs.HC</categories><comments>Proceedings of the Thirty-Fifth Annual Conference of the Cognitive
  Science Society. Berlin, Germany (pp. 2321-2326), 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Why are some events more surprising than others? We propose that events that
are more difficult to explain are those that are more surprising. The two
experiments reported here test the impact of different event outcomes
(Outcome-Type) and task demands (Task) on ratings of surprise for simple story
scenarios. For the Outcome-Type variable, participants saw outcomes that were
either known or less-known surprising outcomes for each scenario. For the Task
variable, participants either answered comprehension questions or provided an
explanation of the outcome. Outcome-Type reliably affected surprise judgments;
known outcomes were rated as less surprising than less-known outcomes. Task
also reliably affected surprise judgments; when people provided an explanation
it lowered surprise judgments relative to simply answering comprehension
questions. Both experiments thus provide evidence on this less-explored
explanation aspect of surprise, specifically showing that ease of explanation
is a key factor in determining the level of surprise experienced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2240</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2240</id><created>2013-08-09</created><authors><author><keyname>OToole</keyname><forenames>Stephanie</forenames></author><author><keyname>Keane</keyname><forenames>Mark T.</forenames></author></authors><title>Cognitive residues of similarity</title><categories>cs.AI cs.HC</categories><comments>Long version of original abstract; In Proceedings of the Thirty-Fifth
  Annual Conference of the Cognitive Science Society. Berlin, Germany (pp.
  4070), 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What are the cognitive after-effects of making a similarity judgement? What,
cognitively, is left behind and what effect might these residues have on
subsequent processing? In this paper, we probe for such after-effects using a
visual search task, performed after a task in which pictures of real-world
objects were compared. So, target objects were first presented in a comparison
task (e.g., rate the similarity of this object to another) thus, presumably,
modifying some of their features before asking people to visually search for
the same object in complex scenes (with distractors and camouflaged
backgrounds). As visual search is known to be influenced by the features of
target objects, then any after-effects of the comparison task should be
revealed in subsequent visual searches. Results showed that when people
previously rated an object as being high on a scale (e.g., colour similarity or
general similarity) then visual search is inhibited (slower RTs and more
saccades in eye-tracking) relative to an object being rated as low in the same
scale. There was also some evidence that different comparison tasks (e.g.,
compare on colour or compare on general similarity) have differential effects
on visual search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2248</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2248</id><created>2013-08-09</created><authors><author><keyname>Shahrampour</keyname><forenames>Shahin</forenames></author><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author></authors><title>Topology Identification of Directed Dynamical Networks via Power
  Spectral Analysis</title><categories>cs.SY math.DS math.OC</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of identifying the topology of an unknown weighted,
directed network of LTI systems stimulated by wide-sense stationary noises of
unknown power spectral densities. We propose several reconstruction algorithms
based on the cross-power spectral densities of the network's response to the
input noises. Our first algorithm reconstructs the Boolean structure (i.e.,
existence and directions of links) of a directed network from a series of
dynamical responses. Moreover, we propose a second algorithm to recover the
exact structure of the network (including edge weights), as well as the power
spectral density of the input noises, when an eigenvalue-eigenvector pair of
the connectivity matrix is known (for example, Laplacian connectivity
matrices). Finally, for the particular cases of nonreciprocal networks (i.e.,
networks with no directed edges pointing in opposite directions) and undirected
networks, we propose specialized algorithms that result in a lower
computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2260</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2260</id><created>2013-08-09</created><authors><author><keyname>Raety</keyname><forenames>Petteri</forenames></author><author><keyname>Behm</keyname><forenames>Benjamin</forenames></author><author><keyname>Dikert</keyname><forenames>Kim-Karol</forenames></author><author><keyname>Paasivaara</keyname><forenames>Maria</forenames></author><author><keyname>Lassenius</keyname><forenames>Casper</forenames></author><author><keyname>Damian</keyname><forenames>Daniela</forenames></author></authors><title>Communication Practices in a Distributed Scrum Project</title><categories>cs.SE cs.SI</categories><comments>Presented at COINs13 Conference, Chile, 2013 (arxiv:1308.1028)</comments><report-no>coins13/2013/13</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While global software development (GSD) projects face cultural and time
differences, the biggest challenge is communication. We studied a distributed
student project with an industrial customer. The project lasted 3 months,
involved 25 participants, and was distributed between the University of
Victoria, Canada and Aalto University, Finland. We analyzed email
communication, version control system (VCS) data, and surveys on satisfaction.
Our aim was to find out whether reflecting on communication affected it, if
standups influenced when developers committed to the VCS repository, and if
leaders emerged in the three distributed Scrum teams. Initially students sent
on average 21 emails per day. With the reduction to 16 emails, satisfaction
with communication increased. By comparing Scrum standup times and VCS activity
we found that the live communication of standups activated people to work on
the project. Out of the three teams, one had an emergent communication
facilitator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2264</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2264</id><created>2013-08-09</created><authors><author><keyname>Islam</keyname><forenames>Shama N.</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author></authors><title>Error Performance Analysis of DF and AF Multi-way Relay Networks with
  BPSK Modulation</title><categories>cs.IT math.IT</categories><comments>accepted in IET Communications</comments><msc-class>94A05</msc-class><journal-ref>IET Communications, vol. 7, no. 15, pp. 1605-1616, Oct., 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the error performance of decode and forward (DF)
and amplify and forward (AF) multi-way relay networks (MWRN). We consider a
MWRN with pair-wise data exchange protocol using binary phase shift keying
(BPSK) modulation in both additive white Gaussian noise (AWGN) and Rayleigh
fading channels. We quantify the possible error events in an $L$-user DF or AF
MWRN and derive accurate asymptotic bounds on the probability for the general
case that a user incorrectly decodes the messages of exactly $k$
($k\in[1,L-1]$) users. We show that at high signal-to-noise ratio (SNR), the
higher order error events ($k\geq 3$) are less probable in AF MWRN, but all
error events are equally probable in a DF MWRN. We derive the average BER of a
user in a DF or AF MWRN in both AWGN and Rayleigh fading channels under high
SNR conditions. Simulation results validate the correctness of the derived
expressions. Our results show that at medium to high SNR, DF MWRN provides
better error performance than AF MWRN in AWGN channels even with a large number
of users (for example, L=100). Whereas, AF MWRN outperforms DF MWRN in Rayleigh
fading channels even for much smaller number of users (for example, $L &gt; 10$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2272</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2272</id><created>2013-08-09</created><authors><author><keyname>Jang</keyname><forenames>Dae-Sung</forenames></author><author><keyname>Choi</keyname><forenames>Han-Lim</forenames></author><author><keyname>Roh</keyname><forenames>Ji-Eun</forenames></author></authors><title>Search Optimization for Minimum Load under Detection Performance
  Constraints in Multifunction Radars</title><categories>cs.SY math.OC</categories><comments>11 pages, 13 figures, submitted to IEEE Transactions on Aerospace and
  Electronic Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a solution procedure of search parameter optimization for
minimum load ensuring desired one-off and cumulative probabilities of detection
in a multifunction phased array radar. The key approach is to convert this
nonlinear optimization on four search parameters into a scalar optimization on
signal-to-noise ratio by a semi-analytic process based on subproblem
decomposition. The efficacy of the proposed solution approach is verified with
theoretical analysis and numerical case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2286</identifier>
 <datestamp>2014-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2286</id><created>2013-08-10</created><updated>2014-05-13</updated><authors><author><keyname>Koiran</keyname><forenames>Pascal</forenames><affiliation>LIP</affiliation></author><author><keyname>Portier</keyname><forenames>Natacha</forenames><affiliation>LIP</affiliation></author><author><keyname>Tavenas</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP</affiliation></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames><affiliation>LIP</affiliation></author></authors><title>A tau-conjecture for Newton polygons</title><categories>cs.CC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One can associate to any bivariate polynomial P(X,Y) its Newton polygon. This
is the convex hull of the points (i,j) such that the monomial X^i Y^j appears
in P with a nonzero coefficient. We conjecture that when P is expressed as a
sum of products of sparse polynomials, the number of edges of its Newton
polygon is polynomially bounded in the size of such an expression. We show that
this &quot;tau-conjecture for Newton polygons,&quot; even in a weak form, implies that
the permanent polynomial is not computable by polynomial size arithmetic
circuits. We make the same observation for a weak version of an earlier &quot;real
tau-conjecture.&quot; Finally, we make some progress toward the tau-conjecture for
Newton polygons using recent results from combinatorial geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2291</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2291</id><created>2013-08-10</created><authors><author><keyname>Nagahara</keyname><forenames>Masaaki</forenames></author><author><keyname>Quevedo</keyname><forenames>Daniel E.</forenames></author><author><keyname>Matsuda</keyname><forenames>Takahiro</forenames></author><author><keyname>Hayashi</keyname><forenames>Kazunori</forenames></author></authors><title>Compressive Sampling for Networked Feedback Control</title><categories>cs.SY cs.IT math.IT math.OC</categories><journal-ref>IEEE International Conference on Acoustics, Speech, and Signal
  Processing (ICASSP), pp. 2733-2736, Mar. 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the use of compressive sampling for networked feedback control
systems. The method proposed serves to compress the control vectors which are
transmitted through rate-limited channels without much deterioration of control
performance. The control vectors are obtained by an L1-L2 optimization, which
can be solved very efficiently by FISTA (Fast Iterative Shrinkage-Thresholding
Algorithm). Simulation results show that the proposed sparsity-promoting
control scheme gives a better control performance than a conventional
energy-limiting L2-optimal control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2292</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2292</id><created>2013-08-10</created><authors><author><keyname>Benninghoff</keyname><forenames>Heike</forenames></author><author><keyname>Garcke</keyname><forenames>Harald</forenames></author></authors><title>Fast image segmentation and restoration using parametric curve evolution
  with junctions and topology changes</title><categories>cs.CV math.AP math.NA</categories><comments>26 pages, 16 figures</comments><msc-class>94A08, 68U10, 65K10, 35K55, 49Q10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Curve evolution schemes for image segmentation based on a region based
contour model allowing for junctions, vector-valued images and topology changes
are introduced. Together with an a posteriori denoising in the segmented
homogeneous regions this leads to a fast and efficient method for image
segmentation and restoration. An uneven spread of mesh points is avoided by
using the tangential degrees of freedom. Several numerical simulations on
artificial test problems and on real images illustrate the performance of the
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2293</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2293</id><created>2013-08-10</created><updated>2013-12-26</updated><authors><author><keyname>Malek-Mohammadi</keyname><forenames>Mohammadreza</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Massoud</forenames></author><author><keyname>Amini</keyname><forenames>Arash</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>Recovery of Low-Rank Matrices under Affine Constraints via a Smoothed
  Rank Function</title><categories>cs.IT math.IT</categories><comments>Accepted in IEEE TSP on December 4th, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of matrix rank minimization under affine
constraints is addressed. The state-of-the-art algorithms can recover matrices
with a rank much less than what is sufficient for the uniqueness of the
solution of this optimization problem. We propose an algorithm based on a
smooth approximation of the rank function, which practically improves recovery
limits on the rank of the solution. This approximation leads to a non-convex
program; thus, to avoid getting trapped in local solutions, we use the
following scheme. Initially, a rough approximation of the rank function subject
to the affine constraints is optimized. As the algorithm proceeds, finer
approximations of the rank are optimized and the solver is initialized with the
solution of the previous approximation until reaching the desired accuracy.
  On the theoretical side, benefiting from the spherical section property, we
will show that the sequence of the solutions of the approximating function
converges to the minimum rank solution. On the experimental side, it will be
shown that the proposed algorithm, termed SRF standing for Smoothed Rank
Function, can recover matrices which are unique solutions of the rank
minimization problem and yet not recoverable by nuclear norm minimization.
Furthermore, it will be demonstrated that, in completing partially observed
matrices, the accuracy of SRF is considerably and consistently better than some
famous algorithms when the number of revealed entries is close to the minimum
number of parameters that uniquely represent a low-rank matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2299</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2299</id><created>2013-08-10</created><authors><author><keyname>Nagaraj</keyname><forenames>Nithin</forenames></author></authors><title>Lossless Data Compression with Error Detection using Cantor Set</title><categories>cs.IT math.IT nlin.CD</categories><comments>10 pages, 3 figures, 4 tables, submitted for review to European
  Physical Journal - Special Topics: Special Issue on &quot;Chaos, Cryptography and
  Communications&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2009, a lossless compression algorithm based on 1D chaotic maps known as
Generalized Lur\&quot;{o}th Series (or GLS) has been proposed. This algorithm
(GLS-coding) encodes the input message as a symbolic sequence on an appropriate
1D chaotic map (GLS) and the compressed file is obtained as the initial value
by iterating backwards on the map. For ergodic sources, it was shown that
GLS-coding achieves the best possible lossless compression (in the noiseless
setting) bounded by Shannon entropy. However, in the presence of noise, even
small errors in the compressed file leads to catastrophic decoding errors owing
to sensitive dependence on initial values. In this paper, we first show that
Repetition codes $\mathcal{R}_n$ (every symbol is repeated $n$ times, where $n$
is a positive odd integer), the oldest and the most basic error correction and
detection codes in literature, actually lie on a Cantor set with a fractal
dimension of $\frac{1}{n}$, which is also the rate of the code. Inspired by
this, we incorporate error detection capability to GLS-coding by ensuring that
the compressed file (initial value on the map) lies on a Cantor set of measure
zero. Even a 1-bit error in the initial value will throw it outside the Cantor
set which can be detected while decoding. The error detection performance (and
also the rate of the code) can be controlled by the fractal dimension of the
Cantor set and could be suitably adjusted depending on the noise level of the
communication channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2302</identifier>
 <datestamp>2015-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2302</id><created>2013-08-10</created><updated>2013-12-20</updated><authors><author><keyname>Deleforge</keyname><forenames>Antoine</forenames></author><author><keyname>Forbes</keyname><forenames>Florence</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author></authors><title>High-Dimensional Regression with Gaussian Mixtures and Partially-Latent
  Response Variables</title><categories>cs.LG stat.ML</categories><journal-ref>Statistics and Computing, 25(5), 893-911, 2015</journal-ref><doi>10.1007/s11222-014-9461-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we address the problem of approximating high-dimensional data
with a low-dimensional representation. We make the following contributions. We
propose an inverse regression method which exchanges the roles of input and
response, such that the low-dimensional variable becomes the regressor, and
which is tractable. We introduce a mixture of locally-linear probabilistic
mapping model that starts with estimating the parameters of inverse regression,
and follows with inferring closed-form solutions for the forward parameters of
the high-dimensional regression problem of interest. Moreover, we introduce a
partially-latent paradigm, such that the vector-valued response variable is
composed of both observed and latent entries, thus being able to deal with data
contaminated by experimental artifacts that cannot be explained with noise
models. The proposed probabilistic formulation could be viewed as a
latent-variable augmentation of regression. We devise expectation-maximization
(EM) procedures based on a data augmentation strategy which facilitates the
maximum-likelihood search over the model parameters. We propose two
augmentation schemes and we describe in detail the associated EM inference
procedures that may well be viewed as generalizations of a number of EM
regression, dimension reduction, and factor analysis algorithms. The proposed
framework is validated with both synthetic and real data. We provide
experimental evidence that our method outperforms several existing regression
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2307</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2307</id><created>2013-08-10</created><authors><author><keyname>Boulkabeit</keyname><forenames>I.</forenames></author><author><keyname>Mthembu</keyname><forenames>L.</forenames></author><author><keyname>Marwala</keyname><forenames>T.</forenames></author><author><keyname>Neto</keyname><forenames>F. De Lima</forenames></author></authors><title>Finite Element Model Updating Using Fish School Search Optimization
  Method</title><categories>cs.CE cs.NE</categories><comments>To appear in the 1st BRICS Countries &amp; 11th CBIC Brazilian Congress
  on Computational Intelligence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent nature inspired optimization algorithm, Fish School Search (FSS) is
applied to the finite element model (FEM) updating problem. This method is
tested on a GARTEUR SM-AG19 aeroplane structure. The results of this algorithm
are compared with two other metaheuristic algorithms; Genetic Algorithm (GA)
and Particle Swarm Optimization (PSO). It is observed that on average, the FSS
and PSO algorithms give more accurate results than the GA. A minor modification
to the FSS is proposed. This modification improves the performance of FSS on
the FEM updating problem which has a constrained search space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2309</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2309</id><created>2013-08-10</created><authors><author><keyname>Paul</keyname><forenames>Satyakama</forenames></author><author><keyname>Janecek</keyname><forenames>Andreas</forenames></author><author><keyname>Neto</keyname><forenames>Fernando Buarque de Lima</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Applying the Negative Selection Algorithm for Merger and Acquisition
  Target Identification</title><categories>cs.AI</categories><comments>To appear in the proceedings of the 1st BRICS Countries &amp; 11th CBIC
  Brazilian Congress on Computational Intelligence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new methodology based on the Negative Selection
Algorithm that belongs to the field of Computational Intelligence,
specifically, Artificial Immune Systems to identify takeover targets. Although
considerable research based on customary statistical techniques and some
contemporary Computational Intelligence techniques have been devoted to
identify takeover targets, most of the existing studies are based upon multiple
previous mergers and acquisitions. Contrary to previous research, the novelty
of this proposal lies in its ability to suggest takeover targets for novice
firms that are at the beginning of their merger and acquisition spree. We first
discuss the theoretical perspective and then provide a case study with details
for practical implementation, both capitalizing from unique generalization
capabilities of artificial immune systems algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2310</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2310</id><created>2013-08-10</created><authors><author><keyname>Duggirala</keyname><forenames>Rakesh</forenames></author><author><keyname>Narayana</keyname><forenames>P.</forenames></author></authors><title>Mining Positive and Negative Association Rules Using CoherentApproach</title><categories>cs.DB</categories><comments>IJCTT-2013</comments><msc-class>97Pxx</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the data mining field, association rules are discovered having domain
knowledge specified as a minimum support threshold. The accuracy in setting up
this threshold directly influences the number and the quality of association
rules discovered. Typically, before association rules are mined, a user needs
to determine a support threshold in order to obtain only the frequent item
sets. Having users to determine a support threshold attracts a number of
issues. We propose an association rule mining framework that does not require a
per-set support threshold. Often, the number of association rules, even though
large in number, misses some interesting rules and the rules quality
necessitates further analysis. As a result, decision making using these rules
could lead to risky actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2338</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2338</id><created>2013-08-10</created><authors><author><keyname>Si</keyname><forenames>Hongbo</forenames></author><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Lossy Compression of Exponential and Laplacian Sources using Expansion
  Coding</title><categories>cs.IT math.IT</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general method of source coding over expansion is proposed in this paper,
which enables one to reduce the problem of compressing an analog
(continuous-valued source) to a set of much simpler problems, compressing
discrete sources. Specifically, the focus is on lossy compression of
exponential and Laplacian sources, which is subsequently expanded using a
finite alphabet prior to being quantized. Due to decomposability property of
such sources, the resulting random variables post expansion are independent and
discrete. Thus, each of the expanded levels corresponds to an independent
discrete source coding problem, and the original problem is reduced to coding
over these parallel sources with a total distortion constraint. Any feasible
solution to the optimization problem is an achievable rate distortion pair of
the original continuous-valued source compression problem. Although finding the
solution to this optimization problem at every distortion is hard, we show that
our expansion coding scheme presents a good solution in the low distrotion
regime. Further, by adopting low-complexity codes designed for discrete source
coding, the total coding complexity can be tractable in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2349</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2349</id><created>2013-08-10</created><updated>2013-09-20</updated><authors><author><keyname>Bonnet</keyname><forenames>Remi</forenames><affiliation>LSV, ENS Cachan and CNRS</affiliation></author><author><keyname>Chadha</keyname><forenames>Rohit</forenames><affiliation>University of Missouri</affiliation></author><author><keyname>Viswanathan</keyname><forenames>Mahesh</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Madhusudan</keyname><forenames>P.</forenames><affiliation>University of Illinois</affiliation></author></authors><title>Reachability under Contextual Locking</title><categories>cs.LO</categories><comments>A preliminary version appears in TACAS 2012</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  17, 2013) lmcs:762</journal-ref><doi>10.2168/LMCS-9(3:21)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pairwise reachability problem for a multi-threaded program asks, given
control locations in two threads, whether they can be simultaneously reached in
an execution of the program. The problem is important for static analysis and
is used to detect statements that are concurrently enabled. This problem is in
general undecidable even when data is abstracted and when the threads (with
recursion) synchronize only using a finite set of locks. Popular programming
paradigms that limit the lock usage patterns have been identified under which
the pairwise reachability problem becomes decidable. In this paper, we consider
a new natural programming paradigm, called contextual locking, which ties the
lock usage to calling patterns in each thread: we assume that locks are
released in the same context that they were acquired and that every lock
acquired by a thread in a procedure call is released before the procedure
returns. Our main result is that the pairwise reachability problem is
polynomial-time decidable for this new programming paradigm as well. The
problem becomes undecidable if the locks are reentrant; reentrant locking is a
\emph{recursive locking} mechanism which allows a thread in a multi-threaded
program to acquire the reentrant lock multiple times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2350</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2350</id><created>2013-08-10</created><authors><author><keyname>Dutta</keyname><forenames>Jayanta K.</forenames></author><author><keyname>Banerjee</keyname><forenames>Bonny</forenames></author></authors><title>Learning Features and their Transformations by Spatial and Temporal
  Spherical Clustering</title><categories>cs.NE cs.CV q-bio.NC</categories><acm-class>I.2; I.4; I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning features invariant to arbitrary transformations in the data is a
requirement for any recognition system, biological or artificial. It is now
widely accepted that simple cells in the primary visual cortex respond to
features while the complex cells respond to features invariant to different
transformations. We present a novel two-layered feedforward neural model that
learns features in the first layer by spatial spherical clustering and
invariance to transformations in the second layer by temporal spherical
clustering. Learning occurs in an online and unsupervised manner following the
Hebbian rule. When exposed to natural videos acquired by a camera mounted on a
cat's head, the first and second layer neurons in our model develop simple and
complex cell-like receptive field properties. The model can predict by learning
lateral connections among the first layer neurons. A topographic map to their
spatial features emerges by exponentially decaying the flow of activation with
distance from one neuron to another in the first layer that fire in close
temporal proximity, thereby minimizing the pooling length in an online manner
simultaneously with feature learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2354</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2354</id><created>2013-08-10</created><authors><author><keyname>Ravikumar</keyname><forenames>Srijith</forenames></author><author><keyname>Talamadupula</keyname><forenames>Kartik</forenames></author><author><keyname>Balakrishnan</keyname><forenames>Raju</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author></authors><title>RAProp: Ranking Tweets by Exploiting the Tweet/User/Web Ecosystem and
  Inter-Tweet Agreement</title><categories>cs.IR</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing popularity of Twitter renders improved trustworthiness and
relevance assessment of tweets much more important for search. However, given
the limitations on the size of tweets, it is hard to extract measures for
ranking from the tweets' content alone. We present a novel ranking method,
called RAProp, which combines two orthogonal measures of relevance and
trustworthiness of a tweet. The first, called Feature Score, measures the
trustworthiness of the source of the tweet. This is done by extracting features
from a 3-layer twitter ecosystem, consisting of users, tweets and the pages
referred to in the tweets. The second measure, called agreement analysis,
estimates the trustworthiness of the content of the tweet, by analyzing how and
whether the content is independently corroborated by other tweets. We view the
candidate result set of tweets as the vertices of a graph, with the edges
measuring the estimated agreement between each pair of tweets. The feature
score is propagated over this agreement graph to compute the top-k tweets that
have both trustworthy sources and independent corroboration. The evaluation of
our method on 16 million tweets from the TREC 2011 Microblog Dataset shows that
for top-30 precision we achieve 53% higher than current best performing method
on the Dataset and over 300% over current Twitter Search. We also present a
detailed internal empirical evaluation of RAProp in comparison to several
alternative approaches proposed by us.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2357</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2357</id><created>2013-08-10</created><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>On the Detection of Passive Eavesdroppers in the MIMO Wiretap Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classic MIMO wiretap channel comprises a passive eavesdropper that
attempts to intercept communications between an authorized transmitter-receiver
pair, each node being equipped with multiple antennas. In a dynamic network, it
is imperative that the presence of an eavesdropper be determined before the
transmitter can deploy robust secrecyencoding schemes as a countermeasure. This
is a difficult task in general, since by definition the eavesdropper is passive
and never transmits. In this work we adopt a method that allows the legitimate
nodes to detect the passive eavesdropper from the local oscillator power that
is inadvertently leaked from its RF front end. We examine the performance of
non-coherent energy detection and optimal coherent detection, followed by
composite GLRT detection methods that account for unknown parameters. Numerical
experiments demonstrate that the proposed detectors allow the legitimate nodes
to increase the secrecy rate of the MIMO wiretap channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2359</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2359</id><created>2013-08-10</created><authors><author><keyname>Maiya</keyname><forenames>Arun S.</forenames></author><author><keyname>Thompson</keyname><forenames>John P.</forenames></author><author><keyname>Loaiza-Lemos</keyname><forenames>Francisco</forenames></author><author><keyname>Rolfe</keyname><forenames>Robert M.</forenames></author></authors><title>Exploratory Analysis of Highly Heterogeneous Document Collections</title><categories>cs.CL cs.HC cs.IR</categories><comments>9 pages; KDD 2013: 19th ACM SIGKDD Conference on Knowledge Discovery
  and Data Mining</comments><acm-class>I.2.7; H.3.3; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an effective multifaceted system for exploratory analysis of
highly heterogeneous document collections. Our system is based on intelligently
tagging individual documents in a purely automated fashion and exploiting these
tags in a powerful faceted browsing framework. Tagging strategies employed
include both unsupervised and supervised approaches based on machine learning
and natural language processing. As one of our key tagging strategies, we
introduce the KERA algorithm (Keyword Extraction for Reports and Articles).
KERA extracts topic-representative terms from individual documents in a purely
unsupervised fashion and is revealed to be significantly more effective than
state-of-the-art methods. Finally, we evaluate our system in its ability to
help users locate documents pertaining to military critical technologies buried
deep in a large heterogeneous sea of information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2362</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2362</id><created>2013-08-10</created><authors><author><keyname>Jang</keyname><forenames>Yunsik Jake</forenames></author><author><keyname>Lim</keyname><forenames>Bo young</forenames></author></authors><title>Harmonization among national cyber security and cybercrime response
  organizations: New challenges of cybercrime</title><categories>cs.CY</categories><comments>4th Asian Criminology Conference (2012)</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper will discuss the need for national-level organizational strategies
to effectively combat cyber security threats and cybercrime. In many countries,
new agencies have been established and/or new roles have been allotted to
existing agencies to cope with the needs for cyber security or fighting against
cybercrime. The two pillars of organizational structure and functions (i.e.,
security vs. law enforcement) have given new challenges to us, especially in
the context of traditional criminal justice system. To illustrate the
challenges, a case study examining the responses to major security incidents
followed by nationwide debates and remarkable organizational changes in Korea
will be given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2371</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2371</id><created>2013-08-11</created><authors><author><keyname>Sun</keyname><forenames>Yao</forenames></author></authors><title>Signature-Based Gr\&quot;obner Basis Algorithms --- Extended MMM Algorithm
  for computing Gr\&quot;obner bases</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signature-based algorithms is a popular kind of algorithms for computing
Gr\&quot;obner bases, and many related papers have been published recently. In this
paper, no new signature-based algorithms and no new proofs are presented.
Instead, a view of signature-based algorithms is given, that is,
signature-based algorithms can be regarded as an extended version of the famous
MMM algorithm. By this view, this paper aims to give an easier way to
understand signature-based Gr\&quot;obner basis algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2372</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2372</id><created>2013-08-11</created><authors><author><keyname>Shariatpanahi</keyname><forenames>Seyed Pooya</forenames></author><author><keyname>Shah-Mansouri</keyname><forenames>Hamed</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak Hossein</forenames></author></authors><title>Throughput of One-Hop Wireless Networks with Noisy Feedback Channel</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the effect of feedback channel error on the
throughput of one-hop wireless networks under the random connection model. The
transmission strategy is based on activating source-destination pairs with
strongest direct links. While these activated pairs are identified based on
Channel State Information (CSI) at the receive side, the transmit side will be
provided with a noisy version of this information via the feedback channel.
Such error will degrade network throughput, as we investigate in this paper.
Our results show that if the feedback error probability is below a given
threshold, network can tolerate such error without any significant throughput
loss. The threshold value depends on the number of nodes in the network and the
channel fading distribution. Such analysis is crucial in design of error
correction codes for feedback channel in such networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2375</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2375</id><created>2013-08-11</created><authors><author><keyname>Bonanno</keyname><forenames>Francesco</forenames></author><author><keyname>Capizzi</keyname><forenames>Giacomo</forenames></author><author><keyname>Napoli</keyname><forenames>Christian</forenames></author><author><keyname>Graditi</keyname><forenames>Giorgio</forenames></author><author><keyname>Tina</keyname><forenames>Giuseppe Marco</forenames></author></authors><title>A radial basis function neural network based approach for the electrical
  characteristics estimation of a photovoltaic module</title><categories>cs.NE</categories><journal-ref>F. Bonanno, G. Capizzi, G. Graditi, C. Napoli, G.M. Tina, Applied
  Energy, Vol. 97, pp. 956-961 (2012)</journal-ref><doi>10.1016/j.apenergy.2011.12.085</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design process of photovoltaic (PV) modules can be greatly enhanced by
using advanced and accurate models in order to predict accurately their
electrical output behavior. The main aim of this paper is to investigate the
application of an advanced neural network based model of a module to improve
the accuracy of the predicted output I--V and P--V curves and to keep in
account the change of all the parameters at different operating conditions.
Radial basis function neural networks (RBFNN) are here utilized to predict the
output characteristic of a commercial PV module, by reading only the data of
solar irradiation and temperature. A lot of available experimental data were
used for the training of the RBFNN, and a backpropagation algorithm was
employed. Simulation and experimental validation is reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2390</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2390</id><created>2013-08-11</created><authors><author><keyname>Sarma</keyname><forenames>Santanu</forenames></author></authors><title>Adaptive Technique for Computationally Efficient Time Delay and
  Magnitude Estimation of Sinusoidal Signals</title><categories>cs.SY</categories><comments>7 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An online, adaptive method of time delay and magnitude estimation for
sinusoidal signals is presented. The method is based on an adaptive gradient
descent algorithm that directly determines the time delay and magnitudes of two
noisy sinusoidal signals. The new estimator uses a novel quadrature carrier
generator to produce the carriers for an adaptive quadrature phase detector,
which in turn uses an arc tan function to compute the time delay. The proposed
method is quite robust and can adapt to significant variation in input signal
characteristics like magnitude and frequency imposing no requirement on the
magnitudes of the two signals. It even works effectively when the signals have
time-varying magnitudes. The convergence analysis of the proposed technique
shows that estimate converges exponentially fast to their nominal values. In
addition, if the technique is implemented in the continuous time domain, the
delay estimation accuracy will not be constrained by the sampling frequency as
observed in some of the classical techniques. Extensive simulations show that
the proposed method provides very accurate estimates of the time delay
comparable to that of the popular methods like Sinc-based estimator, Lagrange
estimator, and the Quadrature estimator, as well the magnitude estimate of the
input signals at lower signal to noise ratio at appreciably reduced
computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2393</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2393</id><created>2013-08-11</created><authors><author><keyname>Jaganathan</keyname><forenames>Suresh</forenames></author><author><keyname>Arulanadam</keyname><forenames>Srinivasan</forenames></author><author><keyname>Avula</keyname><forenames>Damodaram</forenames></author></authors><title>An Efficient Transport Protocol for delivery of Multimedia An Efficient
  Transport Protocol for delivery of Multimedia Content in Wireless Grids</title><categories>cs.MM cs.NI</categories><comments>20 pages, 15 figures, Peer Reviewed Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A grid computing system is designed for solving complicated scientific and
commercial problems effectively,whereas mobile computing is a traditional
distributed system having computing capability with mobility and adopting
wireless communications. Media and Entertainment fields can take advantage from
both paradigms by applying its usage in gaming applications and multimedia data
management. Multimedia data has to be stored and retrieved in an efficient and
effective manner to put it in use. In this paper, we proposed an application
layer protocol for delivery of multimedia data in wireless girds i.e.
multimedia grid protocol (MMGP). To make streaming efficient a new video
compression algorithm called dWave is designed and embedded in the proposed
protocol. This protocol will provide faster, reliable access and render an
imperceptible QoS in delivering multimedia in wireless grid environment and
tackles the challenging issues such as i) intermittent connectivity, ii) device
heterogeneity, iii) weak security and iv) device mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2400</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2400</id><created>2013-08-11</created><authors><author><keyname>Singh</keyname><forenames>Niraj Kumar</forenames></author><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author><author><keyname>Mallick</keyname><forenames>Dheeresh Kumar</forenames></author></authors><title>An Adaptable Fast Matrix Multiplication Algorithm, Going Beyond the Myth
  of Decimal War</title><categories>cs.DS</categories><comments>No of tables is 1. No of diagrams is 01</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an adaptable fast matrix multiplication (AFMM)
algorithm, for two nxn dense matrices which computes the product matrix with
average complexity Tavg(n) = d1d2n3 with the acknowledgement that the average
count is obtained for addition as the basic operation rather than
multiplication which is probably the unquestionable choice for basic operation
in existing matrix multiplication algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2401</identifier>
 <datestamp>2014-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2401</id><created>2013-08-11</created><updated>2014-10-16</updated><authors><author><keyname>Li</keyname><forenames>Tiancheng</forenames></author><author><keyname>Sun</keyname><forenames>Shudong</forenames></author><author><keyname>Corchado</keyname><forenames>Juan M.</forenames></author><author><keyname>Sattar</keyname><forenames>Tariq P.</forenames></author><author><keyname>Si</keyname><forenames>Shubin</forenames></author></authors><title>Numerical Fitting-based Likelihood Calculation to Speed up the Particle
  Filter</title><categories>cs.IT cs.NA math.IT</categories><comments>42 pages, 17 figures, 4 tables and 1 appendix. This paper is a
  draft/preprint of one paper submitted to the IEEE Transactions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The likelihood calculation of a vast number of particles is the computational
bottleneck for the particle filter in applications where the observation
information is rich. For fast computing the likelihood of particles, a
numerical fitting approach is proposed to construct the Likelihood Probability
Density Function (Li-PDF) by using a comparably small number of so-called
fulcrums. The likelihood of particles is thereby analytically inferred,
explicitly or implicitly, based on the Li-PDF instead of directly computed by
utilizing the observation, which can significantly reduce the computation and
enables real time filtering. The proposed approach guarantees the estimation
quality when an appropriate fitting function and properly distributed fulcrums
are used. The details for construction of the fitting function and fulcrums are
addressed respectively in detail. In particular, to deal with multivariate
fitting, the nonparametric kernel density estimator is presented which is
flexible and convenient for implicit Li-PDF implementation. Simulation
comparison with a variety of existing approaches on a benchmark 1-dimensional
model and multi-dimensional robot localization and visual tracking demonstrate
the validity of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2405</identifier>
 <datestamp>2014-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2405</id><created>2013-08-11</created><updated>2014-01-10</updated><authors><author><keyname>Aggarwal</keyname><forenames>Divesh</forenames></author><author><keyname>Regev</keyname><forenames>Oded</forenames></author></authors><title>A Note on Discrete Gaussian Combinations of Lattice Vectors</title><categories>cs.CR math.CO math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the distribution of $\sum_{i=1}^m v_i \bx_i$ where
$\bx_1,...,\bx_m$ are fixed vectors from some lattice $\cL \subset \R^n$ (say
$\Z^n$) and $v_1,...,v_m$ are chosen independently from a discrete Gaussian
distribution over $\Z$. We show that under a natural constraint on
$\bx_1,...,\bx_m$, if the $v_i$ are chosen from a wide enough Gaussian, the sum
is statistically close to a discrete Gaussian over $\cL$. We also analyze the
case of $\bx_1,...,\bx_m$ that are themselves chosen from a discrete Gaussian
distribution (and fixed).
  Our results simplify and qualitatively improve upon a recent result by
Agrawal, Gentry, Halevi, and Sahai \cite{AGHS13}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2409</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2409</id><created>2013-08-11</created><updated>2013-08-22</updated><authors><author><keyname>Mouawad</keyname><forenames>Amer E.</forenames></author><author><keyname>Nishimura</keyname><forenames>Naomi</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Simjour</keyname><forenames>Narges</forenames></author><author><keyname>Suzuki</keyname><forenames>Akira</forenames></author></authors><title>On the Parameterized Complexity of Reconfiguration Problems</title><categories>cs.CC cs.DS</categories><comments>IPEC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first results on the parameterized complexity of
reconfiguration problems, where a reconfiguration version of an optimization
problem $Q$ takes as input two feasible solutions $S$ and $T$ and determines if
there is a sequence of {\em reconfiguration steps} that can be applied to
transform $S$ into $T$ such that each step results in a feasible solution to
$Q$. For most of the results in this paper, $S$ and $T$ are subsets of vertices
of a given graph and a reconfiguration step adds or deletes a vertex. Our study
is motivated by recent results establishing that for most NP-hard problems, the
classical complexity of reconfiguration is PSPACE-complete. We address the
question for several important graph properties under two natural
parameterizations: $k$, the size of the solutions, and $\ell$, the length of
the sequence of steps. Our first general result is an algorithmic paradigm, the
{\em reconfiguration kernel}, used to obtain fixed-parameter algorithms for the
reconfiguration versions of {\sc Vertex Cover} and, more generally, {\sc
Bounded Hitting Set} and {\sc Feedback Vertex Set}, all parameterized by $k$.
In contrast, we show that reconfiguring {\sc Unbounded Hitting Set} is
$W[2]$-hard when parameterized by $k+\ell$. We also demonstrate the
$W[1]$-hardness of the reconfiguration versions of a large class of
maximization problems parameterized by $k+\ell$, and of their corresponding
deletion problems parameterized by $\ell$; in doing so, we show that there
exist problems in FPT when parameterized by $k$, but whose reconfiguration
versions are $W[1]$-hard when parameterized by $k+\ell$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2410</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2410</id><created>2013-08-11</created><authors><author><keyname>Fursin</keyname><forenames>Grigori</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author></authors><title>Collective Mind: cleaning up the research and experimentation mess in
  computer engineering using crowdsourcing, big data and machine learning</title><categories>cs.SE cs.HC stat.ML</categories><comments>I started drafting this document at the beginning of the development
  of the 3rd version of plugin-based cTuning infrastructure and repository (aka
  Collective Mind) to systematize and crowdsource program and architecture
  auto-tuning; (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software and hardware co-design and optimization of HPC systems has become
intolerably complex, ad-hoc, time consuming and error prone due to enormous
number of available design and optimization choices, complex interactions
between all software and hardware components, and multiple strict requirements
placed on performance, power consumption, size, reliability and cost. We
present our novel long-term holistic and practical solution to this problem
based on customizable, plugin-based, schema-free, heterogeneous, open-source
Collective Mind repository and infrastructure with unified web interfaces and
on-line advise system. This collaborative framework distributes analysis and
multi-objective off-line and on-line auto-tuning of computer systems among many
participants while utilizing any available smart phone, tablet, laptop, cluster
or data center, and continuously observing, classifying and modeling their
realistic behavior. Any unexpected behavior is analyzed using shared data
mining and predictive modeling plugins or exposed to the community at
cTuning.org for collaborative explanation, top-down complexity reduction,
incremental problem decomposition and detection of correlating program,
architecture or run-time properties (features). Gradually increasing
optimization knowledge helps to continuously improve optimization heuristics of
any compiler, predict optimizations for new programs or suggest efficient
run-time (online) tuning and adaptation strategies depending on end-user
requirements. We decided to share all our past research artifacts including
hundreds of codelets, numerical applications, data sets, models, universal
experimental analysis and auto-tuning pipelines, self-tuning machine learning
based meta compiler, and unified statistical analysis and machine learning
plugins in a public repository to initiate systematic, reproducible and
collaborative research, development and experimentation with a new publication
model where experiments and techniques are validated, ranked and improved by
the community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2426</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2426</id><created>2013-08-11</created><authors><author><keyname>Li</keyname><forenames>Tiancheng</forenames></author></authors><title>Bias of the SIR filter in estimation of the state transition noise</title><categories>cs.SY cs.NA</categories><comments>9 pages, 2 figures. Interesting experiment evidence of the bias of
  SIR filter in estimation of the state transition noise</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This Note investigates the bias of the sampling importance resampling (SIR)
filter in estimation of the state transition noise in the state space model.
The SIR filter may suffer from sample impoverishment that is caused by the
resampling and therefore will benefit from a sampling proposal that has a
heavier tail, e.g. the state transition noise simulated for particle
preparation is bigger than the true noise involved with the state dynamics.
This is because a comparably big transition noise used for particle propagation
can spread overlapped particles to counteract impoverishment, giving better
approximation of the posterior. As such, the SIR filter tends to yield a biased
(bigger-than-the-truth) estimate of the transition noise if it is unknown and
needs to be estimated, at least, in the forward-only filtering estimation. The
bias is elaborated via the direct roughening approach by means of both
qualitative logical deduction and quantitative numerical simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2428</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2428</id><created>2013-08-11</created><updated>2013-09-16</updated><authors><author><keyname>Picard</keyname><forenames>Olivier</forenames></author><author><keyname>Lord</keyname><forenames>M&#xe9;lanie</forenames></author><author><keyname>Blondin-Mass&#xe9;</keyname><forenames>Alexandre</forenames></author><author><keyname>Marcotte</keyname><forenames>Odile</forenames></author><author><keyname>Lopes</keyname><forenames>Marcos</forenames></author><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>Hidden Structure and Function in the Lexicon</title><categories>cs.CL</categories><comments>11 pages, 5 figures, 2 tables</comments><journal-ref>NLPCS 2013: 10th International Workshop on Natural Language
  Processing and Cognitive Science, Marseille, France 15-16 October 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How many words are needed to define all the words in a dictionary?
Graph-theoretic analysis reveals that about 10% of a dictionary is a unique
Kernel of words that define one another and all the rest, but this is not the
smallest such subset. The Kernel consists of one huge strongly connected
component (SCC), about half its size, the Core, surrounded by many small SCCs,
the Satellites. Core words can define one another but not the rest of the
dictionary. The Kernel also contains many overlapping Minimal Grounding Sets
(MGSs), each about the same size as the Core, each part-Core, part-Satellite.
MGS words can define all the rest of the dictionary. They are learned earlier,
more concrete and more frequent than the rest of the dictionary. Satellite
words, not correlated with age or frequency, are less concrete (more abstract)
words that are also needed for full lexical power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2433</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2433</id><created>2013-08-11</created><authors><author><keyname>Xie</keyname><forenames>Zhiwu</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author><author><keyname>Liu</keyname><forenames>Jinyang</forenames></author><author><keyname>van Reenen</keyname><forenames>Johann</forenames></author><author><keyname>Jordan</keyname><forenames>Ramiro</forenames></author></authors><title>Archiving the Relaxed Consistency Web</title><categories>cs.DL cs.DB cs.SI</categories><comments>10 pages, 6 figures, CIKM 2013</comments><acm-class>H.3.5; H.3.7; H.2.4</acm-class><doi>10.1145/2505515.2505551</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The historical, cultural, and intellectual importance of archiving the web
has been widely recognized. Today, all countries with high Internet penetration
rate have established high-profile archiving initiatives to crawl and archive
the fast-disappearing web content for long-term use. As web technologies
evolve, established web archiving techniques face challenges. This paper
focuses on the potential impact of the relaxed consistency web design on
crawler driven web archiving. Relaxed consistent websites may disseminate,
albeit ephemerally, inaccurate and even contradictory information. If captured
and preserved in the web archives as historical records, such information will
degrade the overall archival quality. To assess the extent of such quality
degradation, we build a simplified feed-following application and simulate its
operation with synthetic workloads. The results indicate that a non-trivial
portion of a relaxed consistency web archive may contain observable
inconsistency, and the inconsistency window may extend significantly longer
than that observed at the data store. We discuss the nature of such quality
degradation and propose a few possible remedies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2435</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2435</id><created>2013-08-11</created><authors><author><keyname>Farr&#xe0;s</keyname><forenames>Oriol</forenames></author><author><keyname>Domingo-Ferrer</keyname><forenames>Josep</forenames></author><author><keyname>Blanco-Justicia</keyname><forenames>Alberto</forenames></author></authors><title>Privacy-Preserving Trust Management Mechanisms from Private Matching
  Schemes</title><categories>cs.CR</categories><comments>The material in this paper will be presented in part at the 8th DPM
  International Workshop on Data Privacy Management (DPM 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptographic primitives are essential for constructing privacy-preserving
communication mechanisms. There are situations in which two parties that do not
know each other need to exchange sensitive information on the Internet. Trust
management mechanisms make use of digital credentials and certificates in order
to establish trust among these strangers. We address the problem of choosing
which credentials are exchanged. During this process, each party should learn
no information about the preferences of the other party other than strictly
required for trust establishment. We present a method to reach an agreement on
the credentials to be exchanged that preserves the privacy of the parties. Our
method is based on secure two-party computation protocols for set intersection.
Namely, it is constructed from private matching schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2443</identifier>
 <datestamp>2014-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2443</id><created>2013-08-11</created><updated>2014-01-08</updated><authors><author><keyname>Li</keyname><forenames>Tiancheng</forenames></author><author><keyname>Sun</keyname><forenames>Shudong</forenames></author><author><keyname>Sattar</keyname><forenames>Tariq P.</forenames></author><author><keyname>Corchado</keyname><forenames>Juan M.</forenames></author></authors><title>Fighting Sample Degeneracy and Impoverishment in Particle Filters: A
  Review of Intelligent Approaches</title><categories>cs.AI stat.CO</categories><comments>Expert Systems with Applications, 2014</comments><doi>10.1016/j.eswa.2013.12.031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last two decades there has been a growing interest in Particle
Filtering (PF). However, PF suffers from two long-standing problems that are
referred to as sample degeneracy and impoverishment. We are investigating
methods that are particularly efficient at Particle Distribution Optimization
(PDO) to fight sample degeneracy and impoverishment, with an emphasis on
intelligence choices. These methods benefit from such methods as Markov Chain
Monte Carlo methods, Mean-shift algorithms, artificial intelligence algorithms
(e.g., Particle Swarm Optimization, Genetic Algorithm and Ant Colony
Optimization), machine learning approaches (e.g., clustering, splitting and
merging) and their hybrids, forming a coherent standpoint to enhance the
particle filter. The working mechanism, interrelationship, pros and cons of
these approaches are provided. In addition, Approaches that are effective for
dealing with high-dimensionality are reviewed. While improving the filter
performance in terms of accuracy, robustness and convergence, it is noted that
advanced techniques employed in PF often causes additional computational
requirement that will in turn sacrifice improvement obtained in real life
filtering. This fact, hidden in pure simulations, deserves the attention of the
users and designers of new filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2450</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2450</id><created>2013-08-11</created><updated>2013-08-18</updated><authors><author><keyname>Sun</keyname><forenames>Xiaoming</forenames></author><author><keyname>Villagra</keyname><forenames>Marcos</forenames></author></authors><title>Exponential Quantum-Classical Gaps in Multiparty Nondeterministic
  Communication Complexity</title><categories>cs.CC quant-ph</categories><comments>This paper has been withdrawn by the author due to a crucial mistake
  in the main proof</comments><acm-class>F.1.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are three different types of nondeterminism in quantum communication:
i) $\nqp$-communication, ii) $\qma$-communication, and iii)
$\qcma$-communication. In this \redout{paper} we show that multiparty
$\nqp$-communication can be exponentially stronger than $\qcma$-communication.
This also implies an exponential separation with respect to classical
multiparty nondeterministic communication complexity. We argue that there
exists a total function that is hard for $\qcma$-communication and easy for
$\nqp$-communication. The proof of it involves an application of the pattern
tensor method and a new lower bound for polynomial threshold degree. Another
important consequence of this result is that nondeterministic rank can be
exponentially lower than the discrepancy bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2451</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2451</id><created>2013-08-11</created><authors><author><keyname>Garc&#xed;a</keyname><forenames>Cristobal</forenames></author><author><keyname>Chauveau</keyname><forenames>Paul</forenames></author><author><keyname>Ledezma</keyname><forenames>Javier</forenames></author><author><keyname>Pinto</keyname><forenames>Maria</forenames></author></authors><title>What can Social Media teach us about protests? Analyzing the Chilean
  2011-12 Student Movement's Network evolution through Twitter data</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>Presented at COINs13 Conference, Chile, 2013 (arxiv:1308.1028)</comments><report-no>coins13/2013/11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using social media data -specially twitter -of the Chilean 2011-12 student
movement, we study their social network evolution over time to analyze how
leaders and participants self-organize and spread information. Based on a few
key events of the student movement's timeline, we visualize the student network
trajectory and analyze their structural and semantic properties. Therefore, in
this paper we: i) describe the basic network topology of the 2011-12 Chilean
massive student movement; ii) explore how the 180 key central nodes of the
movement are connected, self-organize and spread information. We contend that
this social media enabled massive movement is yet another manifestation of the
network era, which leverages agents' socio-technical networks, and thus
accelerates how agents coordinate, mobilize resources and enact collective
intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2454</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2454</id><created>2013-08-11</created><authors><author><keyname>Bao</keyname><forenames>Wei</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author></authors><title>Understanding the Benefits of Open Access in Femtocell Networks:
  Stochastic Geometric Analysis in the Uplink</title><categories>cs.NI cs.IT math.IT</categories><comments>11 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We introduce a comprehensive analytical framework to compare between open
access and closed access in two-tier femtocell networks, with regard to uplink
interference and outage. Interference at both the macrocell and femtocell
levels is considered. A stochastic geometric approach is employed as the basis
for our analysis. We further derive sufficient conditions for open access and
closed access to outperform each other in terms of the outage probability,
leading to closed-form expressions to upper and lower bound the difference in
the targeted received power between the two access modes. Simulations are
conducted to validate the accuracy of the analytical model and the correctness
of the bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2462</identifier>
 <datestamp>2014-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2462</id><created>2013-08-12</created><updated>2014-02-13</updated><authors><author><keyname>Zhou</keyname><forenames>Xun</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Ho</keyname><forenames>Chin Keong</forenames></author></authors><title>Wireless Information and Power Transfer in Multiuser OFDM Systems</title><categories>cs.IT math.IT</categories><comments>submitted for possible journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the optimal design for simultaneous wireless
information and power transfer (SWIPT) in downlink multiuser orthogonal
frequency division multiplexing (OFDM) systems. For information transmission,
we consider two types of multiple access schemes, namely, time division
multiple access (TDMA) and orthogonal frequency division multiple access
(OFDMA). At the receiver side, due to the practical limitation that circuits
for harvesting energy from radio signals are not yet able to decode the carried
information directly, each user applies either time switching (TS) or power
splitting (PS) to coordinate the energy harvesting (EH) and information
decoding (ID) processes. For the TDMA-based information transmission, we employ
TS at the receivers; for the OFDMA-based information transmission, we employ PS
at the receivers. Under the above two scenarios, we address the problem of
maximizing the weighted sum-rate over all users by varying the time/frequency
power allocation and either TS or PS ratio, subject to a minimum harvested
energy constraint on each user as well as a peak and/or total transmission
power constraint. For the TS scheme, by an appropriate variable transformation
the problem is reformulated as a convex problem, for which the optimal power
allocation and TS ratio are obtained by the Lagrange duality method. For the PS
scheme, we propose an iterative algorithm to optimize the power allocation,
subcarrier (SC) allocation and the PS ratio for each user. The performances of
the two schemes are compared numerically as well as analytically for the
special case of single-user setup. It is revealed that the peak power
constraint imposed on each OFDM SC as well as the number of users in the system
play a key role in the rate-energy performance comparison by the two proposed
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2464</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2464</id><created>2013-08-12</created><authors><author><keyname>Huang</keyname><forenames>Hui</forenames></author><author><keyname>Ascher</keyname><forenames>Uri</forenames></author></authors><title>Faster gradient descent and the efficient recovery of images</title><categories>cs.CV cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much recent attention has been devoted to gradient descent algorithms where
the steepest descent step size is replaced by a similar one from a previous
iteration or gets updated only once every second step, thus forming a {\em
faster gradient descent method}. For unconstrained convex quadratic
optimization these methods can converge much faster than steepest descent. But
the context of interest here is application to certain ill-posed inverse
problems, where the steepest descent method is known to have a smoothing,
regularizing effect, and where a strict optimization solution is not necessary.
  Specifically, in this paper we examine the effect of replacing steepest
descent by a faster gradient descent algorithm in the practical context of
image deblurring and denoising tasks. We also propose several highly efficient
schemes for carrying out these tasks independently of the step size selection,
as well as a scheme for the case where both blur and significant noise are
present.
  In the above context there are situations where many steepest descent steps
are required, thus building slowness into the solution procedure. Our general
conclusion regarding gradient descent methods is that in such cases the faster
gradient descent methods offer substantial advantages. In other situations
where no such slowness buildup arises the steepest descent method can still be
very effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2468</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2468</id><created>2013-08-12</created><authors><author><keyname>Soomro</keyname><forenames>Safeeullah</forenames></author><author><keyname>Hussain</keyname><forenames>Zahid</forenames></author><author><keyname>Keerio</keyname><forenames>Ayaz</forenames></author></authors><title>Path Conditions Help to Locate and Localize Faults from Programs</title><categories>cs.SE</categories><comments>9 pages and 3 figures; Safeeullah Soomro, Zahid Hussain and Ayaz
  Keriyo How Path conditions can help to diagnose faults from programs,
  Published Sindh University of Research Journal, SURJ University of Sindh,
  Jamshoro 2011 ISI Index and HEC Recognized</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Precisely and automatically detection of faults in programs, is a software
engineering dream. Every effort in this regard takes us one step closer to
realizing it. Many efforts have been taken from the people of these areas on
testing, verification and debugging. We are proposing such effort for the
research community of this domain is using path conditions to generate a
minimal set of PLOFC (possible lines of faulty code). It's a run time method
that will effectively bring the minimal possible set of faulty lines of code
through the help of path conditions and some heuristics involved. In this paper
we are generating possible fault locations from programs using path conditions
which can put positive impact on the static analysis of programs. Further we
discuss the basic ideas regarding path conditions, the theory, and first
analysis results. This work is based on a previous work that uses the variable
dependences for fault detection. We showed some examples to the applicable of
this idea and can be useful for software verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2473</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2473</id><created>2013-08-12</created><authors><author><keyname>Berns</keyname><forenames>Andrew</forenames></author><author><keyname>Hegeman</keyname><forenames>James</forenames></author><author><keyname>Pemmaraju</keyname><forenames>Sriram V.</forenames></author></authors><title>Super-Fast Distributed Algorithms for Metric Facility Location</title><categories>cs.DC cs.DS</categories><comments>15 pages, 2 figures. This is the full version of a paper that
  appeared in ICALP 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a distributed O(1)-approximation algorithm, with
expected-$O(\log \log n)$ running time, in the $\mathcal{CONGEST}$ model for
the metric facility location problem on a size-$n$ clique network. Though
metric facility location has been considered by a number of researchers in
low-diameter settings, this is the first sub-logarithmic-round algorithm for
the problem that yields an O(1)-approximation in the setting of non-uniform
facility opening costs. In order to obtain this result, our paper makes three
main technical contributions. First, we show a new lower bound for metric
facility location, extending the lower bound of B\u{a}doiu et al. (ICALP 2005)
that applies only to the special case of uniform facility opening costs. Next,
we demonstrate a reduction of the distributed metric facility location problem
to the problem of computing an O(1)-ruling set of an appropriate spanning
subgraph. Finally, we present a sub-logarithmic-round (in expectation)
algorithm for computing a 2-ruling set in a spanning subgraph of a clique. Our
algorithm accomplishes this by using a combination of randomized and
deterministic sparsification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2475</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2475</id><created>2013-08-12</created><updated>2014-07-30</updated><authors><author><keyname>Roosta-Khorasani</keyname><forenames>Farbod</forenames></author><author><keyname>Ascher</keyname><forenames>Uri</forenames></author></authors><title>Improved bounds on sample size for implicit matrix trace estimators</title><categories>cs.NA math.NA</categories><msc-class>65C20, 65C05, 68W20</msc-class><doi>10.1007/s10208-014-9220-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is concerned with Monte-Carlo methods for the estimation of the
trace of an implicitly given matrix $A$ whose information is only available
through matrix-vector products. Such a method approximates the trace by an
average of $N$ expressions of the form $\ww^t (A\ww)$, with random vectors
$\ww$ drawn from an appropriate distribution. We prove, discuss and experiment
with bounds on the number of realizations $N$ required in order to guarantee a
probabilistic bound on the relative error of the trace estimation upon
employing Rademacher (Hutchinson), Gaussian and uniform unit vector (with and
without replacement) probability distributions.
  In total, one necessary bound and six sufficient bounds are proved, improving
upon and extending similar estimates obtained in the seminal work of Avron and
Toledo (2011) in several dimensions. We first improve their bound on $N$ for
the Hutchinson method, dropping a term that relates to $rank(A)$ and making the
bound comparable with that for the Gaussian estimator.
  We further prove new sufficient bounds for the Hutchinson, Gaussian and the
unit vector estimators, as well as a necessary bound for the Gaussian
estimator, which depend more specifically on properties of the matrix $A$. As
such they may suggest for what type of matrices one distribution or another
provides a particularly effective or relatively ineffective stochastic
estimation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2480</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2480</id><created>2013-08-12</created><authors><author><keyname>Rokos</keyname><forenames>Georgios</forenames></author><author><keyname>Gorman</keyname><forenames>Gerard J.</forenames></author><author><keyname>Southern</keyname><forenames>James</forenames></author><author><keyname>Kelly</keyname><forenames>Paul H. J.</forenames></author></authors><title>A thread-parallel algorithm for anisotropic mesh adaptation</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anisotropic mesh adaptation is a powerful way to directly minimise the
computational cost of mesh based simulation. It is particularly important for
multi-scale problems where the required number of floating-point operations can
be reduced by orders of magnitude relative to more traditional static mesh
approaches.
  Increasingly, finite element and finite volume codes are being optimised for
modern multi-core architectures. Typically, decomposition methods implemented
through the Message Passing Interface (MPI) are applied for inter-node
parallelisation, while a threaded programming model, such as OpenMP, is used
for intra-node parallelisation. Inter-node parallelism for mesh adaptivity has
been successfully implemented by a number of groups. However, thread-level
parallelism is significantly more challenging because the underlying data
structures are extensively modified during mesh adaptation and a greater degree
of parallelism must be realised.
  In this paper we describe a new thread-parallel algorithm for anisotropic
mesh adaptation algorithms. For each of the mesh optimisation phases
(refinement, coarsening, swapping and smoothing) we describe how independent
sets of tasks are defined. We show how a deferred updates strategy can be used
to update the mesh data structures in parallel and without data contention. We
show that despite the complex nature of mesh adaptation and inherent load
imbalances in the mesh adaptivity, a parallel efficiency of 60% is achieved on
an 8 core Intel Xeon Sandybridge, and a 40% parallel efficiency is achieved
using 16 cores in a 2 socket Intel Xeon Sandybridge ccNUMA system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2493</identifier>
 <datestamp>2013-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2493</id><created>2013-08-12</created><authors><author><keyname>Soeken</keyname><forenames>Mathias</forenames></author><author><keyname>Miller</keyname><forenames>D. Michael</forenames></author><author><keyname>Drechsler</keyname><forenames>Rolf</forenames></author></authors><title>On quantum circuits employing roots of the Pauli matrices</title><categories>quant-ph cs.ET</categories><comments>7 pages, 1 figure</comments><journal-ref>Phys. Rev. A 88, 042322 (2013)</journal-ref><doi>10.1103/PhysRevA.88.042322</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Pauli matrices are a set of three 2x2 complex Hermitian, unitary
matrices. In this article, we investigate the relationships between certain
roots of the Pauli matrices and how gates implementing those roots are used in
quantum circuits. Techniques for simplifying such circuits are given. In
particular, we show how those techniques can be used to find a circuit of
Clifford+T gates starting from a circuit composed of gates from the well
studied NCV library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2495</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2495</id><created>2013-08-12</created><authors><author><keyname>G&#xe4;rtner</keyname><forenames>Bernd</forenames></author><author><keyname>Helbling</keyname><forenames>Christian</forenames></author><author><keyname>Ota</keyname><forenames>Yoshiki</forenames></author><author><keyname>Takahashi</keyname><forenames>Takeru</forenames></author></authors><title>Large Shadows from Sparse Inequalities</title><categories>math.MG cs.DM math.CO math.OC</categories><comments>10 pages</comments><msc-class>05A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $d$-dimensional Goldfarb cube is a polytope with the property that all
its $2^d$ vertices appear on some \emph{shadow} of it (projection onto a
2-dimensional plane). The Goldfarb cube is the solution set of a system of 2d
linear inequalities with at most 3 variables per inequality. We show in this
paper that the $d$-dimensional Klee-Minty cube --- constructed from
inequalities with at most 2 variables per inequality --- also has a shadow with
$2^d$ vertices. In contrast, with one variable per inequality, the size of the
shadow is bounded by 2d.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2497</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2497</id><created>2013-08-12</created><authors><author><keyname>Rahn</keyname><forenames>Mona</forenames></author><author><keyname>Sch&#xe4;fer</keyname><forenames>Guido</forenames></author></authors><title>Bounding the Inefficiency of Altruism Through Social Contribution Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of games, called social contribution games (SCGs),
where each player's individual cost is equal to the cost he induces on society
because of his presence. Our results reveal that SCGs constitute useful
abstractions of altruistic games when it comes to the analysis of the robust
price of anarchy. We first show that SCGs are altruism-independently smooth,
i.e., the robust price of anarchy of these games remains the same under
arbitrary altruistic extensions. We then devise a general reduction technique
that enables us to reduce the problem of establishing smoothness for an
altruistic extension of a base game to a corresponding SCG. Our reduction
applies whenever the base game relates to a canonical SCG by satisfying a
simple social contribution boundedness property. As it turns out, several
well-known games satisfy this property and are thus amenable to our reduction
technique. Examples include min-sum scheduling games, congestion games, second
price auctions and valid utility games. Using our technique, we derive mostly
tight bounds on the robust price of anarchy of their altruistic extensions. For
the majority of the mentioned game classes, the results extend to the more
differentiated friendship setting. As we show, our reduction technique covers
this model if the base game satisfies three additional natural properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2505</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2505</id><created>2013-08-12</created><authors><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Papageorgiou</keyname><forenames>Markos</forenames></author></authors><title>Stability Results for Simple Traffic Models Under PI-Regulator Control</title><categories>math.OC cs.SY</categories><comments>19 pages, 5 figures, submitted to IMA Journal of Mathematical Control
  and Information for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides necessary conditions and sufficient conditions for the
(global) Input-to-State Stability property of simple uncertain
vehicular-traffic network models under the effect of a PI-regulator. Local
stability properties for vehicular-traffic networks under the effect of
PI-regulator control are studied as well: the region of attraction of a locally
exponentially stable equilibrium point is estimated by means of Lyapunov
functions. All obtained results are illustrated by means of simple examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2507</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2507</id><created>2013-08-12</created><updated>2013-09-20</updated><authors><author><keyname>Gotsman</keyname><forenames>Alexey</forenames><affiliation>IMDEA Software Institute</affiliation></author><author><keyname>Yang</keyname><forenames>Hongseok</forenames><affiliation>University of Oxford</affiliation></author></authors><title>Linearizability with Ownership Transfer</title><categories>cs.LO cs.PL</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  9, 2013) lmcs:931</journal-ref><doi>10.2168/LMCS-9(3:12)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linearizability is a commonly accepted notion of correctness for libraries of
concurrent algorithms. Unfortunately, it assumes a complete isolation between a
library and its client, with interactions limited to passing values of a given
data type. This is inappropriate for common programming languages, where
libraries and their clients can communicate via the heap, transferring the
ownership of data structures, and can even run in a shared address space
without any memory protection. In this paper, we present the first definition
of linearizability that lifts this limitation and establish an Abstraction
Theorem: while proving a property of a client of a concurrent library, we can
soundly replace the library by its abstract implementation related to the
original one by our generalisation of linearizability. This allows abstracting
from the details of the library implementation while reasoning about the
client. We also prove that linearizability with ownership transfer can be
derived from the classical one if the library does not access some of data
structures transferred to it by the client.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2509</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2509</id><created>2013-08-12</created><authors><author><keyname>Aramyan</keyname><forenames>Rafik</forenames></author><author><keyname>Mkrtchyan</keyname><forenames>Gagik</forenames></author><author><keyname>Karapetyan</keyname><forenames>Arman</forenames></author></authors><title>Coding and Compression of Three Dimensional Meshes by Planes</title><categories>cs.CG cs.IT math.IT</categories><comments>10 pages, 7 figures</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper suggests a new approach for geometric representation of 3D
spatial models and provides a new compression algorithm for 3D meshes, which is
based on mathematical theory of convex geometry. In our approach we represent a
3D convex polyhedron by means of planes, containing only its faces. This allows
not to consider topological aspects of the problem (connectivity information
among vertices and edges) since by means of the planes we construct the
polyhedron uniquely. Due to the fact that the topological data is ignored this
representation provides high degree of compression. Also planes based
representation provides a compression of geometrical data because most of the
faces of the polyhedron are not triangles but polygons with more than three
vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2516</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2516</id><created>2013-08-12</created><authors><author><keyname>Matsubara</keyname><forenames>Yoshitsugu</forenames></author><author><keyname>Hieida</keyname><forenames>Yasuhiro</forenames></author><author><keyname>Tadaki</keyname><forenames>Shin-ichi</forenames></author></authors><title>Fluctuation in e-mail sizes weakens power-law correlations in e-mail
  flow</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>8 pages, 6 figures, EPJB accepted</comments><journal-ref>Eur. Phys. J. B (2013) 86: 371</journal-ref><doi>10.1140/epjb/e2013-40209-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power-law correlations have been observed in packet flow over the Internet.
The possible origin of these correlations includes demand for Internet
services. We observe the demand for e-mail services in an organization, and
analyze correlations in the flow and the sequence of send requests using a
Detrended Fluctuation Analysis (DFA). The correlation in the flow is found to
be weaker than that in the send requests. Four types of artificial flow are
constructed to investigate the effects of fluctuations in e-mail sizes. As a
result, we find that the correlation in the flow originates from that in the
sequence of send requests. The strength of the power-law correlation decreases
as a function of the ratio of the standard deviation of e-mail sizes to their
average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2541</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2541</id><created>2013-08-12</created><authors><author><keyname>Kamalian</keyname><forenames>R. R.</forenames></author></authors><title>Interval colorings of complete bipartite graphs and trees</title><categories>cs.DM math.CO</categories><comments>R.R. Kamalian &quot;Interval colorings of complete bipartite graphs and
  trees&quot;, Preprint of the Computing Centre of the Academy of Sciences of
  Armenia, Yerevan, 1989</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A translation from Russian of the work of R.R. Kamalian &quot;Interval colorings
of complete bipartite graphs and trees&quot;, Preprint of the Computing Centre of
the Academy of Sciences of Armenia, Yerevan, 1989. (Was published by the
decision of the Academic Council of the Computing Centre of the Academy of
Sciences of Armenian SSR and Yerevan State University from 7.09.1989).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2565</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2565</id><created>2013-08-12</created><authors><author><keyname>Brown</keyname><forenames>Chlo&#xeb;</forenames></author><author><keyname>Noulas</keyname><forenames>Anastasios</forenames></author><author><keyname>Mascolo</keyname><forenames>Cecilia</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent</forenames></author></authors><title>A place-focused model for social networks in cities</title><categories>cs.SI physics.soc-ph</categories><comments>13 pages, 7 figures. IEEE/ASE SocialCom 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focused organization theory of social ties proposes that the structure of
human social networks can be arranged around extra-network foci, which can
include shared physical spaces such as homes, workplaces, restaurants, and so
on. Until now, this has been difficult to investigate on a large scale, but the
huge volume of data available from online location-based social services now
makes it possible to examine the friendships and mobility of many thousands of
people, and to investigate the relationship between meetings at places and the
structure of the social network. In this paper, we analyze a large dataset from
Foursquare, the most popular online location-based social network. We examine
the properties of city-based social networks, finding that they have common
structural properties, and that the category of place where two people meet has
very strong influence on the likelihood of their being friends. Inspired by
these observations in combination with the focused organization theory, we then
present a model to generate city-level social networks, and show that it
produces networks with the structural properties seen in empirical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2572</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2572</id><created>2013-08-12</created><authors><author><keyname>Bahl</keyname><forenames>A. K.</forenames></author><author><keyname>Baltzer</keyname><forenames>O.</forenames></author><author><keyname>Rau-Chaplin</keyname><forenames>A.</forenames></author><author><keyname>Varghese</keyname><forenames>B.</forenames></author><author><keyname>Whiteway</keyname><forenames>A.</forenames></author></authors><title>Achieving Speedup in Aggregate Risk Analysis using Multiple GPUs</title><categories>cs.DC cs.CE cs.DS q-fin.RM</categories><comments>Workshop Proceedings of International Conference on Parallel
  Processing, Lyon, France, 2013, 8 pages. arXiv admin note: text overlap with
  arXiv:1308.2066</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic simulation techniques employed for the analysis of portfolios of
insurance/reinsurance risk, often referred to as `Aggregate Risk Analysis', can
benefit from exploiting state-of-the-art high-performance computing platforms.
In this paper, parallel methods to speed-up aggregate risk analysis for
supporting real-time pricing are explored. An algorithm for analysing aggregate
risk is proposed and implemented for multi-core CPUs and for many-core GPUs.
Experimental studies indicate that GPUs offer a feasible alternative solution
over traditional high-performance computing systems. A simulation of 1,000,000
trials with 1,000 catastrophic events per trial on a typical exposure set and
contract structure is performed in less than 5 seconds on a multiple GPU
platform. The key result is that the multiple GPU implementation can be used in
real-time pricing scenarios as it is approximately 77x times faster than the
sequential counterpart implemented on a CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2574</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2574</id><created>2013-08-12</created><updated>2013-11-30</updated><authors><author><keyname>Abbas</keyname><forenames>Taimoor</forenames><affiliation>Department of Electrical and Information Technology, Lund University, Lund, Sweden</affiliation></author><author><keyname>Tufvesson</keyname><forenames>Fredrik</forenames><affiliation>Department of Electrical and Information Technology, Lund University, Lund, Sweden</affiliation></author></authors><title>Line-of-Sight Obstruction Analysis for Vehicle-to-Vehicle Network
  Simulations in a Two-Lane Highway Scenario</title><categories>cs.NI</categories><comments>8 pages, 11 figures, Accepted for publication in the International
  Journal of Antennas and Propagation, Special Issue on Radio Wave Propagation
  and Wireless Channel Modeling 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In vehicular ad-hoc networks (VANETs) the impact of vehicles as obstacles has
largely been neglected in the past. Recent studies have reported that the
vehicles that obstruct the line-of-sight (LOS) path may introduce 10-20 dB
additional loss, and as a result reduce the communication range. Most of the
traffic mobility models (TMMs) today do not treat other vehicles as obstacles
and thus can not model the impact of LOS obstruction in VANET simulations. In
this paper the LOS obstruction caused by other vehicles is studied in a highway
scenario. First a car-following model is used to characterize the motion of the
vehicles driving in the same direction on a two-lane highway. Vehicles are
allowed to change lanes when necessary. The position of each vehicle is updated
by using the car-following rules together with the lane-changing rules for the
forward motion. Based on the simulated traffic a simple TMM is proposed for
VANET simulations, which is capable to identify the vehicles that are in the
shadow region of other vehicles. The presented traffic mobility model together
with the shadow fading path loss model can take in to account the impact of LOS
obstruction on the total received power in the multiple-lane highway scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2576</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2576</id><created>2013-08-12</created><authors><author><keyname>Roemheld</keyname><forenames>Lars</forenames></author></authors><title>Evolutionary Extortion and Mischief: Zero Determinant strategies in
  iterated 2x2 games</title><categories>cs.GT q-bio.PE</categories><comments>Bachelor thesis at Heidelberg University</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the mechanisms, implications, and potential applications
of the recently discovered class of Zero Determinant (ZD) strategies in
iterated 2x2 games. These strategies were reported to successfully extort pure
economic maximizers, and to mischievously determine the set of feasible
long-term payoffs in iterated Prisoners' Dilemma by enforcing linear
constraints on both players' expected average scores.
  These results are generalized for all symmetric 2x2 games and a general
Battle of the Sexes, exemplified by four common games. Additionally, a
comparison to conventional strategies is made and typical ZD gameplay
simulations are analyzed along with convergence speeds. Several response
strategies are discussed, including a glance on how time preferences change
previous results. Furthermore, a possibility of retaliation is presented: when
maximin scores exceed the minimum symmetric payoff, it is possible to extort
the extortioner.
  Finally, a summary of findings from evolutionary game theory shows that
mischief is limited by its own malice. Nevertheless, this does not challenge
the result that mindless economic maximization is subject to extortion: the
study of ZD strategies reveals exciting new perspectives and opportunities in
game theory, both evolutionary and classic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2581</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2581</id><created>2013-08-12</created><updated>2013-08-14</updated><authors><author><keyname>Vercueil</keyname><forenames>Craig</forenames></author></authors><title>A Simple Circle Discretization Algorithm With Applications</title><categories>cs.DS cs.CG</categories><comments>9 pages,2 figures,Java code, fixed typos,improved typesetting,results
  unchanged,revision2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In CNC manufacturing,there often arises the need to create G-Code programs
which require the calculation of discrete x-y coordinate pairs(2D).An example
of this situation is when the programmer needs to create a program to machine a
helix(or thread).The required toolpath will be a set of points on a helix
curve.The problem now entails calculating the number of points along this
curve.Too few points and the toolpath will not be smooth.Too many points and
the program becomes too big.This article will serve to provide a simple way to
divide a circle into discrete points,with a notion of &quot;dimensional tolerance&quot;
built into the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2591</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2591</id><created>2013-08-12</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames></author><author><keyname>Litvak</keyname><forenames>Nelly</forenames></author><author><keyname>Medyanikov</keyname><forenames>Vasily</forenames></author><author><keyname>Sokol</keyname><forenames>Marina</forenames></author></authors><title>Alpha current flow betweenness centrality</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of centrality measures called betweenness centralities reflects
degree of participation of edges or nodes in communication between different
parts of the network. The original shortest-path betweenness centrality is
based on counting shortest paths which go through a node or an edge. One of
shortcomings of the shortest-path betweenness centrality is that it ignores the
paths that might be one or two steps longer than the shortest paths, while the
edges on such paths can be important for communication processes in the
network. To rectify this shortcoming a current flow betweenness centrality has
been proposed. Similarly to the shortest path betwe has prohibitive complexity
for large size networks. In the present work we propose two regularizations of
the current flow betweenness centrality, \alpha-current flow betweenness and
truncated \alpha-current flow betweenness, which can be computed fast and
correlate well with the original current flow betweenness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2592</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2592</id><created>2013-08-12</created><authors><author><keyname>Nagahara</keyname><forenames>Masaaki</forenames></author><author><keyname>Quevedo</keyname><forenames>Daniel E.</forenames></author><author><keyname>Ostergaard</keyname><forenames>Jan</forenames></author><author><keyname>Matsuda</keyname><forenames>Takahiro</forenames></author><author><keyname>Hayashi</keyname><forenames>Kazunori</forenames></author></authors><title>Sparse Command Generator for Remote Control</title><categories>cs.SY cs.IT math.IT math.OC</categories><journal-ref>The 9th IEEE International Conference on Control &amp; Automation
  (ICCA), pp. 1055-1059, Dec. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we consider remote-controlled systems, where the command
generator and the controlled object are connected with a bandwidth-limited
communication link. In the remote-controlled systems, efficient representation
of control commands is one of the crucial issues because of the bandwidth
limitations of the link. We propose a new representation method for control
commands based on compressed sensing. In the proposed method, compressed
sensing reduces the number of bits in each control signal by representing it as
a sparse vector. The compressed sensing problem is solved by an L1-L2
optimization, which can be effectively implemented with an iterative shrinkage
algorithm. A design example also shows the effectiveness of the proposed
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2597</identifier>
 <datestamp>2014-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2597</id><created>2013-08-12</created><updated>2014-04-08</updated><authors><author><keyname>Graziotin</keyname><forenames>Daniel</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author><author><keyname>Wang</keyname><forenames>Xiaofeng</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author><author><keyname>Abrahamsson</keyname><forenames>Pekka</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author></authors><title>A framework for systematic analysis of Open Access journals and its
  application in software engineering and information systems</title><categories>cs.DL cs.CY cs.SE</categories><comments>This is a self-archived post-print (accepted version) of the article,
  published in Scientometrics at http://dx.doi.org/10.1007/s11192-014-1278-7.
  37 pages, 3 figures, 5 tables</comments><acm-class>D.2.0; H.1.0; K.4.1</acm-class><doi>10.1007/s11192-014-1278-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is a contribution towards an understanding of Open Access (OA)
publishing. It proposes an analysis framework of 18 core attributes, divided
into the areas of Bibliographic information, Activity metrics, Economics,
Accessibility, and Predatory issues of OA journals. The framework has been
employed in a systematic analysis of 30 OA journals in software engineering
(SE) and information systems (IS), which were selected among 386 OA journals in
Computer Science from the Directory of OA Journals. An analysis is performed on
the sample of the journals, to provide an overview of the current situation of
OA journals in the fields of SE and IS. The journals are then compared
between-group, according to the presence of a publication fee. A within-group
analysis is performed on the journals requesting publication charges to
authors, in order to understand what is the value added according to different
price ranges. This article offers several contributions. It presents an
overview of OA definitions and models. It provides an analysis framework born
from the observation of data and the literature. It raises the need to study OA
in the fields of SE and IS while offering a first analysis. Finally, it
provides recommendations to readers of OA journals. This paper highlights
several concerns still threatening OA publishing in the fields of SE and IS.
Among them, it is shown that high publication fees are not sufficiently
justified by the publishers, which often lack transparency and may prevent
authors from adopting OA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2599</identifier>
 <datestamp>2014-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2599</id><created>2013-08-12</created><updated>2014-03-31</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Wahlstrom</keyname><forenames>Magnus</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>Parameterized Rural Postman Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Directed Rural Postman Problem (DRPP) can be formulated as follows: given
a strongly connected directed multigraph $D=(V,A)$ with nonnegative integral
weights on the arcs, a subset $R$ of $A$ and a nonnegative integer $\ell$,
decide whether $D$ has a closed directed walk containing every arc of $R$ and
of total weight at most $\ell$. Let $k$ be the number of weakly connected
components in the the subgraph of $D$ induced by $R$. Sorge et al. (2012) ask
whether the DRPP is fixed-parameter tractable (FPT) when parameterized by $k$,
i.e., whether there is an algorithm of running time $O^*(f(k))$ where $f$ is a
function of $k$ only and the $O^*$ notation suppresses polynomial factors.
Sorge et al. (2012) note that this question is of significant practical
relevance and has been open for more than thirty years. Using an algebraic
approach, we prove that DRPP has a randomized algorithm of running time
$O^*(2^k)$ when $\ell$ is bounded by a polynomial in the number of vertices in
$D$. We also show that the same result holds for the undirected version of
DRPP, where $D$ is a connected undirected multigraph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2600</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2600</id><created>2013-08-12</created><authors><author><keyname>Hanini</keyname><forenames>Mohamed</forenames></author><author><keyname>Bouchti</keyname><forenames>Abdelali El</forenames></author><author><keyname>Haqiq</keyname><forenames>Abdelkrim</forenames></author><author><keyname>Berqia</keyname><forenames>Amine</forenames></author></authors><title>An Enhanced Time Space Priority Scheme to Manage QoS for Multimedia
  Flows transmitted to an end user in HSDPA Network</title><categories>cs.NI cs.MM cs.SY</categories><comments>5 pages</comments><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 9, No. 2, February 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  When different type of packets with different needs of Quality of Service
(QoS) requirements share the same network resources, it became important to use
queue management and scheduling schemes in order to maintain perceived quality
at the end users at an acceptable level. Many schemes have been studied in the
literature, these schemes use time priority (to maintain QoS for Real Time (RT)
packets) and/or space priority (to maintain QoS for Non Real Time (NRT)
packets). In this paper, we study and show the drawback of a combined time and
space priority (TSP) scheme used to manage QoS for RT and NRT packets intended
for an end user in High Speed Downlink Packet Access (HSDPA) cell, and we
propose an enhanced scheme (Enhanced Basic-TSP scheme) to improve QoS
relatively to the RT packets, and to exploit efficiently the network resources.
A mathematical model for the EB-TSP scheme is done, and numerical results show
the positive impact of this scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2617</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2617</id><created>2013-08-12</created><updated>2013-08-18</updated><authors><author><keyname>Chalermsook</keyname><forenames>Parinya</forenames></author><author><keyname>Laekhanukit</keyname><forenames>Bundit</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author></authors><title>Independent Set, Induced Matching, and Pricing: Connections and Tight
  (Subexponential Time) Approximation Hardnesses</title><categories>cs.CC cs.DS</categories><comments>The full version of FOCS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a series of almost settled inapproximability results for three
fundamental problems. The first in our series is the subexponential-time
inapproximability of the maximum independent set problem, a question studied in
the area of parameterized complexity. The second is the hardness of
approximating the maximum induced matching problem on bounded-degree bipartite
graphs. The last in our series is the tight hardness of approximating the
k-hypergraph pricing problem, a fundamental problem arising from the area of
algorithmic game theory. In particular, assuming the Exponential Time
Hypothesis, our two main results are:
  - For any r larger than some constant, any r-approximation algorithm for the
maximum independent set problem must run in at least
2^{n^{1-\epsilon}/r^{1+\epsilon}} time. This nearly matches the upper bound of
2^{n/r} (Cygan et al., 2008). It also improves some hardness results in the
domain of parameterized complexity (e.g., Escoffier et al., 2012 and Chitnis et
al., 2013)
  - For any k larger than some constant, there is no polynomial time min
(k^{1-\epsilon}, n^{1/2-\epsilon})-approximation algorithm for the k-hypergraph
pricing problem, where n is the number of vertices in an input graph. This
almost matches the upper bound of min (O(k), \tilde O(\sqrt{n})) (by Balcan and
Blum, 2007 and an algorithm in this paper).
  We note an interesting fact that, in contrast to n^{1/2-\epsilon} hardness
for polynomial-time algorithms, the k-hypergraph pricing problem admits
n^{\delta} approximation for any \delta &gt;0 in quasi-polynomial time. This puts
this problem in a rare approximability class in which approximability
thresholds can be improved significantly by allowing algorithms to run in
quasi-polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2630</identifier>
 <datestamp>2014-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2630</id><created>2013-08-12</created><updated>2013-08-14</updated><authors><author><keyname>Lelievre</keyname><forenames>Yohann</forenames></author><author><keyname>Rutkowski</keyname><forenames>Tomasz M.</forenames></author></authors><title>Novel Virtual Moving Sound-based Spatial Auditory Brain-Computer
  Interface Paradigm</title><categories>q-bio.NC cs.HC</categories><comments>4 pages (in conference proceedings original version); 6 figures,
  accepted at 6th International IEEE EMBS Conference on Neural Engineering,
  November 6-8, 2013, Sheraton San Diego Hotel &amp; Marina, San Diego, CA; paper
  ID 465; to be available at IEEE Xplore; IEEE Copyright 2013</comments><msc-class>92C55, 92C50, 92C30</msc-class><acm-class>D.2.2; H.5.2</acm-class><journal-ref>Neural Engineering (NER), 2013 6th International IEEE/EMBS
  Conference on. IEEE Engineering in Medicine and Biology Society; 2013. p.
  9-12</journal-ref><doi>10.1109/NER.2013.6695858</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports on a study in which a novel virtual moving sound-based
spatial auditory brain-computer interface (BCI) paradigm is developed. Classic
auditory BCIs rely on spatially static stimuli, which are often boring and
difficult to perceive when subjects have non-uniform spatial hearing perception
characteristics. The concept of moving sound proposed and tested in the paper
allows for the creation of a P300 oddball paradigm of necessary target and
non-target auditory stimuli, which are more interesting and easier to
distinguish. We present a report of our study of seven healthy subjects, which
proves the concept of moving sound stimuli usability for a novel BCI. We
compare online BCI classification results in static and moving sound paradigms
yielding similar accuracy results. The subject preference reports suggest that
the proposed moving sound protocol is more comfortable and easier to
discriminate with the online BCI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2654</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2654</id><created>2013-08-12</created><authors><author><keyname>Celaya-Padilla</keyname><forenames>Jos&#xe9; M.</forenames><affiliation>Instituto Tecnol&#xf3;gico y de Estudios Superiores de Monterrey, Eugenio Garza Sada, Monterrey, Nuevo Le&#xf3;n, M&#xe9;xico</affiliation></author><author><keyname>Rodriguez-Rojas</keyname><forenames>Juan</forenames><affiliation>Instituto Tecnol&#xf3;gico y de Estudios Superiores de Monterrey, Eugenio Garza Sada, Monterrey, Nuevo Le&#xf3;n, M&#xe9;xico</affiliation></author><author><keyname>Trevino</keyname><forenames>Victor</forenames><affiliation>Instituto Tecnol&#xf3;gico y de Estudios Superiores de Monterrey, Eugenio Garza Sada, Monterrey, Nuevo Le&#xf3;n, M&#xe9;xico</affiliation></author><author><keyname>Tamez-Pena</keyname><forenames>Jos&#xe9; G. Gerardo</forenames><affiliation>Dept. of Investigaci&#xf3;n e Inovaci&#xf3;n, Escuela de Medicina, ITESM, Monterrey, NL, M&#xe9;xico</affiliation></author></authors><title>Local image registration a comparison for bilateral registration
  mammography</title><categories>cs.CV</categories><comments>9 pages, Submitted to The 9th International Seminar on Medical
  Information Processing and Analysis (formerly International Seminar on
  Medical Image Processing and Analysis) (pending approval)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early tumor detection is key in reducing the number of breast cancer death
and screening mammography is one of the most widely available and reliable
method for early detection. However, it is difficult for the radiologist to
process with the same attention each case, due the large amount of images to be
read. Computer aided detection (CADe) systems improve tumor detection rate; but
the current efficiency of these systems is not yet adequate and the correct
interpretation of CADe outputs requires expert human intervention. Computer
aided diagnosis systems (CADx) are being designed to improve cancer diagnosis
accuracy, but they have not been efficiently applied in breast cancer. CADx
efficiency can be enhanced by considering the natural mirror symmetry between
the right and left breast. The objective of this work is to evaluate
co-registration algorithms for the accurate alignment of the left to right
breast for CADx enhancement. A set of mammograms were artificially altered to
create a ground truth set to evaluate the registration efficiency of DEMONs,
and SPLINE deformable registration algorithms. The registration accuracy was
evaluated using mean square errors, mutual information and correlation. The
results on the 132 images proved that the SPLINE deformable registration
over-perform the DEMONS on mammography images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2655</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2655</id><created>2013-08-12</created><updated>2013-08-18</updated><authors><author><keyname>Loshchilov</keyname><forenames>Ilya</forenames><affiliation>LIS</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>LRI</affiliation></author></authors><title>KL-based Control of the Learning Schedule for Surrogate Black-Box
  Optimization</title><categories>cs.LG cs.AI stat.ML</categories><proxy>ccsd</proxy><journal-ref>Conf\'erence sur l'Apprentissage Automatique (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the control of an ML component within the Covariance
Matrix Adaptation Evolution Strategy (CMA-ES) devoted to black-box
optimization. The known CMA-ES weakness is its sample complexity, the number of
evaluations of the objective function needed to approximate the global optimum.
This weakness is commonly addressed through surrogate optimization, learning an
estimate of the objective function a.k.a. surrogate model, and replacing most
evaluations of the true objective function with the (inexpensive) evaluation of
the surrogate model. This paper presents a principled control of the learning
schedule (when to relearn the surrogate model), based on the Kullback-Leibler
divergence of the current search distribution and the training distribution of
the former surrogate model. The experimental validation of the proposed
approach shows significant performance gains on a comprehensive set of
ill-conditioned benchmark problems, compared to the best state of the art
including the quasi-Newton high-precision BFGS method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2666</identifier>
 <datestamp>2014-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2666</id><created>2013-08-12</created><updated>2014-07-23</updated><authors><author><keyname>Engbers</keyname><forenames>John</forenames></author><author><keyname>Galvin</keyname><forenames>David</forenames></author><author><keyname>Hilyard</keyname><forenames>Justin</forenames></author></authors><title>Combinatorially interpreting generalized Stirling numbers</title><categories>math.CO cs.DM</categories><comments>To appear in Eur. J. Combin., doi:10.1016/j.ejc.2014.07.002</comments><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $w$ be a word in alphabet $\{x,D\}$ with $m$ $x$'s and $n$ $D$'s.
Interpreting &quot;$x$&quot; as multiplication by $x$, and &quot;$D$&quot; as differentiation with
respect to $x$, the identity $wf(x) = x^{m-n}\sum_k S_w(k) x^k D^k f(x)$, valid
for any smooth function $f(x)$, defines a sequence $(S_w(k))_k$, the terms of
which we refer to as the {\em Stirling numbers (of the second kind)} of $w$.
The nomenclature comes from the fact that when $w=(xD)^n$, we have $S_w(k)={n
\brace k}$, the ordinary Stirling number of the second kind.
  Explicit expressions for, and identities satisfied by, the $S_w(k)$ have been
obtained by numerous authors, and combinatorial interpretations have been
presented. Here we provide a new combinatorial interpretation that retains the
spirit of the familiar interpretation of ${n \brace k}$ as a count of
partitions. Specifically, we associate to each $w$ a quasi-threshold graph
$G_w$, and we show that $S_w(k)$ enumerates partitions of the vertex set of
$G_w$ into classes that do not span an edge of $G_w$. We also discuss some
relatives of, and consequences of, our interpretation, including $q$-analogs
and bijections between families of labelled forests and sets of restricted
partitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2690</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2690</id><created>2013-08-12</created><updated>2013-09-20</updated><authors><author><keyname>Schuster</keyname><forenames>Peter M</forenames><affiliation>University of Leeds</affiliation></author></authors><title>Induction in Algebra: a First Case Study</title><categories>cs.LO math.AC math.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  17, 2013) lmcs:959</journal-ref><doi>10.2168/LMCS-9(3:20)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many a concrete theorem of abstract algebra admits a short and elegant proof
by contradiction but with Zorn's Lemma (ZL). A few of these theorems have
recently turned out to follow in a direct and elementary way from the Principle
of Open Induction distinguished by Raoult. The ideal objects characteristic of
any invocation of ZL are eliminated, and it is made possible to pass from
classical to intuitionistic logic. If the theorem has finite input data, then a
finite partial order carries the required instance of induction, which thus is
constructively provable. A typical example is the well-known theorem &quot;every
nonconstant coefficient of an invertible polynomial is nilpotent&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2694</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2694</id><created>2013-08-12</created><authors><author><keyname>Hegeman</keyname><forenames>James</forenames></author><author><keyname>Pemmaraju</keyname><forenames>Sriram V.</forenames></author></authors><title>A Super-Fast Distributed Algorithm for Bipartite Metric Facility
  Location</title><categories>cs.DC</categories><comments>22 pages. This is the full version of a paper that appeared in DISC
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \textit{facility location} problem consists of a set of
\textit{facilities} $\mathcal{F}$, a set of \textit{clients} $\mathcal{C}$, an
\textit{opening cost} $f_i$ associated with each facility $x_i$, and a
\textit{connection cost} $D(x_i,y_j)$ between each facility $x_i$ and client
$y_j$. The goal is to find a subset of facilities to \textit{open}, and to
connect each client to an open facility, so as to minimize the total facility
opening costs plus connection costs. This paper presents the first
expected-sub-logarithmic-round distributed O(1)-approximation algorithm in the
$\mathcal{CONGEST}$ model for the \textit{metric} facility location problem on
the complete bipartite network with parts $\mathcal{F}$ and $\mathcal{C}$. Our
algorithm has an expected running time of $O((\log \log n)^3)$ rounds, where $n
= |\mathcal{F}| + |\mathcal{C}|$. This result can be viewed as a continuation
of our recent work (ICALP 2012) in which we presented the first
sub-logarithmic-round distributed O(1)-approximation algorithm for metric
facility location on a \textit{clique} network. The bipartite setting presents
several new challenges not present in the problem on a clique network. We
present two new techniques to overcome these challenges. (i) In order to deal
with the problem of not being able to choose appropriate probabilities (due to
lack of adequate knowledge), we design an algorithm that performs a random walk
over a probability space and analyze the progress our algorithm makes as the
random walk proceeds. (ii) In order to deal with a problem of quickly
disseminating a collection of messages, possibly containing many duplicates,
over the bipartite network, we design a probabilistic hashing scheme that
delivers all of the messages in expected-$O(\log \log n)$ rounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2696</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2696</id><created>2013-08-12</created><authors><author><keyname>Paxton</keyname><forenames>A.</forenames></author><author><keyname>Dale</keyname><forenames>R.</forenames></author></authors><title>B(eo)W(u)LF: Facilitating recurrence analysis on multi-level language</title><categories>cs.CL</categories><comments>3 pages plus 6 appendices (including code and sample data)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discourse analysis may seek to characterize not only the overall composition
of a given text but also the dynamic patterns within the data. This technical
report introduces a data format intended to facilitate multi-level
investigations, which we call the by-word long-form or B(eo)W(u)LF. Inspired by
the long-form data format required for mixed-effects modeling, B(eo)W(u)LF
structures linguistic data into an expanded matrix encoding any number of
researchers-specified markers, making it ideal for recurrence-based analyses.
While we do not necessarily claim to be the first to use methods along these
lines, we have created a series of tools utilizing Python and MATLAB to enable
such discourse analyses and demonstrate them using 319 lines of the Old English
epic poem, Beowulf, translated into modern English.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2705</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2705</id><created>2013-08-12</created><authors><author><keyname>Hogg</keyname><forenames>Tad</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Smith</keyname><forenames>Laura M.</forenames></author></authors><title>Stochastic Models Predict User Behavior in Social Media</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>ASE/IEEE Social Computing Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User response to contributed content in online social media depends on many
factors. These include how the site lays out new content, how frequently the
user visits the site, how many friends the user follows, how active these
friends are, as well as how interesting or useful the content is to the user.
We present a stochastic modeling framework that relates a user's behavior to
details of the site's user interface and user activity and describe a procedure
for estimating model parameters from available data. We apply the model to
study discussions of controversial topics on Twitter, specifically, to predict
how followers of an advocate for a topic respond to the advocate's posts. We
show that a model of user behavior that explicitly accounts for a user
transitioning through a series of states before responding to an advocate's
post better predicts response than models that fail to take these states into
account. We demonstrate other benefits of stochastic models, such as their
ability to identify users who are highly interested in advocate's posts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2725</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2725</id><created>2013-08-12</created><authors><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author></authors><title>Adaptive and Iterative Multi-Branch MMSE Decision Feedback Detection
  Algorithms for MIMO Systems</title><categories>cs.IT math.IT</categories><comments>10 figures, 3 tables; IEEE Transactions on Wireless Communications,
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, decision feedback (DF) detection algorithms based on multiple
processing branches for multi-input multi-output (MIMO) spatial multiplexing
systems are proposed. The proposed detector employs multiple cancellation
branches with receive filters that are obtained from a common matrix inverse
and achieves a performance close to the maximum likelihood detector (MLD).
Constrained minimum mean-squared error (MMSE) receive filters designed with
constraints on the shape and magnitude of the feedback filters for the
multi-branch MMSE DF (MB-MMSE-DF) receivers are presented. An adaptive
implementation of the proposed MB-MMSE-DF detector is developed along with a
recursive least squares-type algorithm for estimating the parameters of the
receive filters when the channel is time-varying. A soft-output version of the
MB-MMSE-DF detector is also proposed as a component of an iterative detection
and decoding receiver structure. A computational complexity analysis shows that
the MB-MMSE-DF detector does not require a significant additional complexity
over the conventional MMSE-DF detector, whereas a diversity analysis discusses
the diversity order achieved by the MB-MMSE-DF detector. Simulation results
show that the MB-MMSE-DF detector achieves a performance superior to existing
suboptimal detectors and close to the MLD, while requiring significantly lower
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2737</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2737</id><created>2013-08-12</created><authors><author><keyname>Nagahara</keyname><forenames>Masaaki</forenames></author><author><keyname>Yamamoto</keyname><forenames>Yutaka</forenames></author></authors><title>H-infinity Optimal Approximation for Causal Spline Interpolation</title><categories>cs.IT cs.SY math.IT math.OC</categories><journal-ref>Signal Processing, Vol. 91, No. 2, pp. 176-184, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give a causal solution to the problem of spline
interpolation using H-infinity optimal approximation. Generally speaking,
spline interpolation requires filtering the whole sampled data, the past and
the future, to reconstruct the inter-sample values. This leads to non-causality
of the filter, and this becomes a critical issue for real-time applications.
Our objective here is to derive a causal system which approximates spline
interpolation by H-infinity optimization for the filter. The advantage of
H-infinity optimization is that it can address uncertainty in the input signals
to be interpolated in design, and hence the optimized system has robustness
property against signal uncertainty. We give a closed-form solution to the
H-infinity optimization in the case of the cubic splines. For higher-order
splines, the optimal filter can be effectively solved by a numerical
computation. We also show that the optimal FIR (Finite Impulse Response) filter
can be designed by an LMI (Linear Matrix Inequality), which can also be
effectively solved numerically. A design example is presented to illustrate the
result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2743</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2743</id><created>2013-08-12</created><authors><author><keyname>Nagahara</keyname><forenames>Masaaki</forenames></author><author><keyname>Ogura</keyname><forenames>Masaki</forenames></author><author><keyname>Yamamoto</keyname><forenames>Yutaka</forenames></author></authors><title>H-infinity Design of Periodically Nonuniform Interpolation and
  Decimation for Non-Band-Limited Signals</title><categories>cs.IT cs.SY math.IT math.OC</categories><journal-ref>SICE Journal of Control, Measurement, and System Integration, Vol.
  4, No. 5, pp. 341-348, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider signal interpolation of discrete-time signals
which are decimated nonuniformly. A conventional interpolation method is based
on the sampling theorem, and the resulting system consists of an ideal filter
with complex-valued coefficients. While the conventional method assumes band
limitation of signals, we propose a new method by sampled-data H-infinity
optimization. By this method, we can remove the band-limiting assumption and
the optimal filter can be with real-valued coefficients. Moreover, we show that
without band-limited assumption, there can be the optimal decimation patterns
among ones with the same ratio. By examples, we show the effectiveness of our
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2745</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2745</id><created>2013-08-12</created><updated>2013-08-16</updated><authors><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author><author><keyname>Sharad</keyname><forenames>Mrigank</forenames></author><author><keyname>Fan</keyname><forenames>Deliang</forenames></author><author><keyname>Yogendra</keyname><forenames>Karthik</forenames></author></authors><title>Exploring Boolean and Non-Boolean Computing Applications of Spin Torque
  Devices</title><categories>cond-mat.dis-nn cs.ET</categories><comments>arXiv admin note: text overlap with arXiv:1304.5291, arXiv:1206.3227</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discuss the potential of emerging spintorque devices for
computing applications. Recent proposals for spinbased computing schemes may be
differentiated as all-spin vs. hybrid, programmable vs. fixed, and, Boolean vs.
non-Boolean. All spin logic-styles may offer high area-density due to small
form-factor of nano-magnetic devices. However, circuit and system-level design
techniques need to be explored that leverage the specific spin-device
characteristics to achieve energy-efficiency, performance and reliability
comparable to those of CMOS. The non-volatility of nanomagnets can be exploited
in the design of energy and area-efficient programmable logic. In such
logic-styles, spin-devices may play the dual-role of computing as well as
memory-elements that provide field-programmability. Spin-based threshold logic
design is presented as an example (dynamic resisitve threshold logic and
magnetic threshold logic). Emerging spintronic phenomena may lead to ultralow-
voltage, current-mode, spin-torque switches that can offer attractive computing
capabilities, beyond digital switches. Such devices may be suitable for
non-Boolean data-processing applications which involve analog processing.
Integration of such spin-torque devices with charge-based devices like CMOS and
resistive memory can lead to highly energy-efficient information processing
hardware for applications like pattern-matching, neuromorphic-computing,
image-processing and data-conversion. Towards the end, we discuss the
possibility of applying emerging spin-torque switches in the design of
energy-efficient global interconnects, for future chip multiprocessors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2747</identifier>
 <datestamp>2014-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2747</id><created>2013-08-13</created><updated>2014-04-02</updated><authors><author><keyname>Duly</keyname><forenames>Andrew J.</forenames></author><author><keyname>Kim</keyname><forenames>Taejoon</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Krogmeier</keyname><forenames>James V.</forenames></author></authors><title>Closed-Loop Beam Alignment for Massive MIMO Channel Estimation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training sequences are designed to probe wireless channels in order to obtain
channel state information for block-fading channels. Optimal training sounds
the channel using orthogonal beamforming vectors to find an estimate that
optimizes some cost function, such as mean square error. As the number of
transmit antennas increases, however, the training overhead becomes
significant. This creates a need for alternative channel estimation schemes for
increasingly large transmit arrays. In this work, we relax the orthogonal
restriction on sounding vectors. The use of a feedback channel after each
forward channel use during training enables closed-loop sounding vector design.
A misalignment cost function is introduced, which provides a metric to
sequentially design sounding vectors. In turn, the structure of the sounding
vectors aligns the transmit beamformer with the true channel direction, thereby
increasing beamforming gain. This beam alignment scheme for massive MIMO is
shown to improve beamforming gain over conventional orthogonal training for a
MISO channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2757</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2757</id><created>2013-08-13</created><updated>2013-09-28</updated><authors><author><keyname>Durocher</keyname><forenames>Stephane</forenames></author><author><keyname>Filtser</keyname><forenames>Omrit</forenames></author><author><keyname>Fraser</keyname><forenames>Robert</forenames></author><author><keyname>Mehrabi</keyname><forenames>Ali</forenames></author><author><keyname>Mehrabi</keyname><forenames>Saeed</forenames></author></authors><title>A (7/2)-Approximation Algorithm for Guarding Orthogonal Art Galleries
  with Sliding Cameras</title><categories>cs.CG</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a sliding camera that travels back and forth along an orthogonal
line segment $s$ inside an orthogonal polygon $P$ with $n$ vertices. The camera
can see a point $p$ inside $P$ if and only if there exists a line segment
containing $p$ that crosses $s$ at a right angle and is completely contained in
$P$. In the minimum sliding cameras (MSC) problem, the objective is to guard
$P$ with the minimum number of sliding cameras. In this paper, we give an
$O(n^{5/2})$-time $(7/2)$-approximation algorithm to the MSC problem on any
simple orthogonal polygon with $n$ vertices, answering a question posed by Katz
and Morgenstern (2011). To the best of our knowledge, this is the first
constant-factor approximation algorithm for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2762</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2762</id><created>2013-08-13</created><authors><author><keyname>Sensarma</keyname><forenames>Debajit</forenames></author><author><keyname>Majumder</keyname><forenames>Koushik</forenames></author></authors><title>An efficient ant based qos aware intelligent temporally ordered routing
  algorithm for manets</title><categories>cs.NI cs.NE</categories><comments>15 pages, 7 figures, International Journal of Computer Networks &amp;
  Communications (IJCNC) Vol.5, No.4, July 2013</comments><doi>10.5121/ijcnc.2013.5415</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Mobile Ad hoc network (MANET) is a self configurable network connected by
wireless links. This type of network is only suitable for temporary
communication links as it is infrastructure-less and there is no centralised
control. Providing QoS aware routing is a challenging task in this type of
network due to dynamic topology and limited resources. The main purpose of QoS
aware routing is to find a feasible path from source to destination which will
satisfy two or more end to end QoS constrains. Therefore, the task of designing
an efficient routing algorithm which will satisfy all the quality of service
requirements and be robust and adaptive is considered as a highly challenging
problem. In this work we have designed a new efficient and energy aware
multipath routing algorithm based on ACO framework, inspired by the behaviours
of biological ants. Basically by considering QoS constraints and artificial
ants we have designed an intelligent version of classical Temporally Ordered
Routing Algorithm (TORA) which will increase network lifetime and decrease
packet loss and average end to end delay that makes this algorithm suitable for
real time and multimedia applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2772</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2772</id><created>2013-08-13</created><authors><author><keyname>Meybodi</keyname><forenames>M. R. Mollakhalili</forenames></author><author><keyname>Meybodi</keyname><forenames>M. R.</forenames></author></authors><title>Extended Distributed Learning Automata:A New Method for Solving
  Stochastic Graph Optimization Problems</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new structure of cooperative learning automata so-called
extended learning automata (eDLA) is introduced. Based on the proposed
structure, a new iterative randomized heuristic algorithm for finding optimal
sub-graph in a stochastic edge-weighted graph through sampling is proposed. It
has been shown that the proposed algorithm based on new networked-structure can
be to solve the optimization problems on stochastic graph through less number
of sampling in compare to standard sampling. Stochastic graphs are graphs in
which the edges have an unknown distribution probability weights. Proposed
algorithm uses an eDLA to find a policy that leads to an induced sub-graph that
satisfies some restrictions such as minimum or maximum weight (length). At each
stage of the proposed algorithm, eDLA determines which edges to be sampled.
This eDLA-based proposed sampling method may result in decreasing unnecessary
samples and hence decreasing the time that algorithm requires for finding the
optimal sub-graph. It has been shown that proposed method converge to optimal
solution, furthermore the probability of this convergence can be made
arbitrarily close to 1 by using a sufficiently small learning rate. A new
variance-aware threshold value was proposed that can be improving significantly
convergence rate of the proposed eDLA-based algorithm. It has been shown that
the proposed algorithm is competitive in terms of the quality of the solution
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2773</identifier>
 <datestamp>2015-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2773</id><created>2013-08-13</created><updated>2015-06-03</updated><authors><author><keyname>Mukhopadhyay</keyname><forenames>Sabyasachi</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K</forenames></author></authors><title>Wind Speed Data Analysis for Various Seasons during a Decade by Wavelet
  and S transform</title><categories>cs.CE</categories><journal-ref>International Journal in Foundations of Computer Science &amp;
  Technology (IJFCST), Vol. 3, No.4, July 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The appropriate weather prediction is a challenging task and it can be
feasible with proper wind speed fluctuation analysis. In this current paper
daubechies-4 wavelet is used to analyze the winter wind speed fluctuations due
to lesser agitated wind data samples of winter. In summer abrupt changes in
wind speed occurs which creates difficulty for wavelets to keep proper track of
wind speed fluctuations. So, in that case the concept of the S-transform is
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2779</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2779</id><created>2013-08-13</created><authors><author><keyname>Elrawy</keyname><forenames>Mohamed Faisal</forenames></author><author><keyname>Abdelhamid</keyname><forenames>T. K.</forenames></author><author><keyname>Mohamed</keyname><forenames>A. M.</forenames></author></authors><title>IDS in Telecommunication Network Using PCA</title><categories>cs.NI</categories><comments>12 pages, 1 figures, 4 tables, International Journal of Computer
  Networks &amp; Communications (IJCNC) Vol.5, No.4, July 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data Security has become a very serious part of any organizational
information system. Internet threats have become more intelligent so it can
deceive the basic security solutions such as firewalls and antivirus scanners.
To enhance the overall security of the network an additional security layer
such as intrusion detection system (IDS) has to be added. The anomaly detection
IDS is a type of IDS that can differentiate between normal and abnormal in the
data monitored. This paper proposes two types of IDS, one of them can be used
as a network intrusion detection system (NIDS) with overall success (0.9161)
and high detection rate (0.9288) and the other type can also be used as a host
intrusion detection system (HIDS) with overall success (0.8493) and very high
detection rate (0.9628) using NSL-KDD data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2787</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2787</id><created>2013-08-13</created><authors><author><keyname>Patel</keyname><forenames>Ishan</forenames></author><author><keyname>Rau-Chaplin</keyname><forenames>Andrew</forenames></author><author><keyname>Varghese</keyname><forenames>Blesson</forenames></author></authors><title>Accelerating R-based Analytics on the Cloud</title><categories>cs.DC cs.CE cs.SE</categories><comments>Concurrency and Computation, 2013</comments><doi>10.1002/cpe.3026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses how the benefits of cloud-based infrastructure can be
harnessed for analytical workloads. Often the software handling analytical
workloads is not developed by a professional programmer, but on an ad hoc basis
by Analysts in high-level programming environments such as R or Matlab. The
goal of this research is to allow Analysts to take an analytical job that
executes on their personal workstations, and with minimum effort execute it on
cloud infrastructure and manage both the resources and the data required by the
job. If this can be facilitated gracefully, then the Analyst benefits from
on-demand resources, low maintenance cost and scalability of computing
resources, all of which are offered by the cloud. In this paper, a Platform for
Parallel R-based Analytics on the Cloud (P2RAC) that is placed between an
Analyst and a cloud infrastructure is proposed and implemented. P2RAC offers a
set of command-line tools for managing the resources, such as instances and
clusters, the data and the execution of the software on the Amazon Elastic
Computing Cloud infrastructure. Experimental studies are pursued using two
parallel problems and the results obtained confirm the feasibility of employing
P2RAC for solving large-scale analytical problems on the cloud.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2794</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2794</id><created>2013-08-13</created><authors><author><keyname>Kahn</keyname><forenames>Jeff</forenames></author><author><keyname>Kalai</keyname><forenames>Gil</forenames></author></authors><title>Functions without influential coalitions</title><categories>math.CO cs.DM</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give counterexamples to a conjecture of Benny Chor and another of the
second author, both from the late 80s, by exhibiting functions for which the
influences of large coalitions are unexpectedly small relative to the
expectations of the functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2797</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2797</id><created>2013-08-13</created><authors><author><keyname>Ahmad</keyname><forenames>Iftikhar</forenames></author><author><keyname>Jabeen</keyname><forenames>Humaira</forenames></author><author><keyname>Riaz</keyname><forenames>Faisal</forenames></author></authors><title>Improved Quality of Service Protocol for Real Time Traffic in MANET</title><categories>cs.NI</categories><comments>13 pages</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.5, No.4, July 2013</journal-ref><doi>10.5121/ijcnc.2013.5407</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The technologies like Wi-Fi, Blue tooth, WiMax etc. have made Mobile Ad hoc
Networks common in our Real life. Multi-media applications need to be supported
on MANET. A certain level of QoS (Quality of Service) support is essential for
Real time data. Our proposed protocol provides the required QoS without having
negative impact on Best Effort data traffic. An efficient rout discovery
mechanism for AODV routing protocol as well as transmission technique for real
time data are proposed. This technique gives more transmission opportunities to
real time data traffic results in decreasing transmission delay and increasing
throughput. A modified version of the popular AODV routing protocol to provide
QoS guarantee for real time traffic in MANETs is proposed. The simulation shows
better performance results for proposed protocol over the basic AODV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2798</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2798</id><created>2013-08-13</created><authors><author><keyname>Tang</keyname><forenames>Chunming</forenames></author><author><keyname>Qi</keyname><forenames>Yanfeng</forenames></author></authors><title>Effective Construction of a Class of Bent Quadratic Boolean Functions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the characterization of the bentness of quadratic
Boolean functions of the form $f(x)=\sum_{i=1}^{\frac{m}{2}-1}
Tr^n_1(c_ix^{1+2^{ei}})+ Tr_1^{n/2}(c_{m/2}x^{1+2^{n/2}}) ,$ where $n=me$, $m$
is even and $c_i\in GF(2^e)$. For a general $m$, it is difficult to determine
the bentness of these functions. We present the bentness of quadratic Boolean
function for two cases: $m=2^vp^r$ and $m=2^vpq$, where $p$ and $q$ are two
distinct primes. Further, we give the enumeration of quadratic bent functions
for the case $m=2^vpq$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2808</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2808</id><created>2013-08-13</created><authors><author><keyname>Bannert</keyname><forenames>Severin</forenames></author><author><keyname>Gr&#xf6;chenig</keyname><forenames>Karlheinz</forenames></author><author><keyname>St&#xf6;ckler</keyname><forenames>Joachim</forenames></author></authors><title>Discretized Gabor Frames of Totally Positive Functions</title><categories>cs.IT math.IT math.NA</categories><comments>18 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a large class of universal windows for Gabor frames
(Weyl-Heisenberg frames) is constructed. These windows have the fundamental
property that every overcritical rectangular lattice generates a Gabor frame.
Likewise, every undercritical rectangular lattice generates a Riesz sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2831</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2831</id><created>2013-08-13</created><authors><author><keyname>Baldangombo</keyname><forenames>Usukhbayar</forenames></author><author><keyname>Jambaljav</keyname><forenames>Nyamjav</forenames></author><author><keyname>Horng</keyname><forenames>Shi-Jinn</forenames></author></authors><title>A Static Malware Detection System Using Data Mining Methods</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A serious threat today is malicious executables. It is designed to damage
computer system and some of them spread over network without the knowledge of
the owner using the system. Two approaches have been derived for it i.e.
Signature Based Detection and Heuristic Based Detection. These approaches
performed well against known malicious programs but cannot catch the new
malicious programs. Different researchers have proposed methods using data
mining and machine learning for detecting new malicious programs. The method
based on data mining and machine learning has shown good results compared to
other approaches. This work presents a static malware detection system using
data mining techniques such as Information Gain, Principal component analysis,
and three classifiers: SVM, J48, and Na\&quot;ive Bayes. For overcoming the lack of
usual anti-virus products, we use methods of static analysis to extract
valuable features of Windows PE file. We extract raw features of Windows
executables which are PE header information, DLLs, and API functions inside
each DLL of Windows PE file. Thereafter, Information Gain, calling frequencies
of the raw features are calculated to select valuable subset features, and then
Principal Component Analysis is used for dimensionality reduction of the
selected features. By adopting the concepts of machine learning and
data-mining, we construct a static malware detection system which has a
detection rate of 99.6%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2833</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2833</id><created>2013-08-13</created><updated>2015-11-16</updated><authors><author><keyname>Zlatanov</keyname><forenames>Nikola</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Hadzi-Velkov</keyname><forenames>Zoran</forenames></author></authors><title>Asymptotically Optimal Power Allocation for Energy Harvesting
  Communication Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a general energy harvesting (EH) communication network, i.e., a network
where the nodes generate their transmit power through EH, we derive the
asymptotically optimal online power allocation solution which optimizes a
general utility function when the number of transmit time slots, $N$, and the
battery capacities of the EH nodes, $B_{\rm max}$, satisfy $N\to\infty$ and
$B_{\rm max}\to\infty$. The considered family of utility functions is general
enough to include the most important performance measures in communication
theory such as the average data rate, outage probability, average bit error
probability, and average signal-to-noise ratio. The proposed power allocation
solution is very simple. Namely, the asymptotically optimal power allocation
for the EH network is identical to the optimal power allocation for an
equivalent non-EH network whose nodes have infinite energy available but their
average transmit power is constrained to be equal to the average harvested
power and/or the maximum average transmit power of the corresponding nodes in
the EH network. Moreover, the maximum average performance of a general EH
network converges to the maximum average performance of the corresponding
equivalent non-EH network, when $N\to\infty$ and $B_{\rm max}\to\infty$.
Although the proposed solution is asymptotic in nature, it is applicable to EH
systems transmitting in a large but finite number of time slots and having a
battery capacity much larger than the average harvested power and/or the
maximum average transmit power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2838</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2838</id><created>2013-08-13</created><authors><author><keyname>Shen</keyname><forenames>Chao</forenames></author><author><keyname>Li</keyname><forenames>Wei-Chiang</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-Hui</forenames></author></authors><title>Wireless Information and Energy Transfer in Multi-Antenna Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>13 pages, 10 pt, two columns, 11 figures, submitted to IEEE Trans.
  Signal Processing</comments><doi>10.1109/TSP.2014.2355781</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper considers the transmitter design for wireless information and
energy transfer (WIET) in a multiple-input single-output (MISO) interference
channel (IFC). The design problem is to maximize the system throughput (i.e.,
the weighted sum rate) subject to individual energy harvesting constraints and
power constraints. Different from the conventional IFCs without energy
harvesting, the cross-link signals in the considered scenario play two opposite
roles in information detection (ID) and energy harvesting (EH). It is observed
that the ideal scheme, where the receivers can simultaneously perform ID and EH
from the received signal, may not always achieve the best tradeoff between
information transfer and energy harvesting, but simple practical schemes based
on time splitting may perform better. We therefore propose two practical time
splitting schemes, namely time division mode switching (TDMS) and time division
multiple access (TDMA), in addition to a power splitting (PS) scheme which
separates the received signal into two parts for ID and EH, respectively. In
the two-user scenario, we show that beamforming is optimal to all the schemes.
Moreover, the design problems associated with the TDMS and TDMA schemes admit
semi-analytical solutions. In the general K-user scenario, a successive convex
approximation method is proposed to handle the WIET problems associated with
the ideal scheme and the PS scheme, which are known to be NP-hard in general.
The K-user TDMS and TDMA schemes are shown efficiently solvable as convex
problems. Simulation results show that stronger cross-link channel powers
actually improve the information sum rate under energy harvesting constraints.
Moreover, none of the schemes under consideration can dominate another in terms
of the sum rate performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2839</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2839</id><created>2013-08-13</created><authors><author><keyname>Bonato</keyname><forenames>Anthony</forenames></author><author><keyname>Clarke</keyname><forenames>N. E.</forenames></author><author><keyname>Finbow</keyname><forenames>S.</forenames></author><author><keyname>Fitzpatrick</keyname><forenames>S.</forenames></author><author><keyname>Messinger</keyname><forenames>M. E.</forenames></author></authors><title>A note on bounds for the cop number using tree decompositions</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short note, we supply a new upper bound on the cop number in terms of
tree decompositions. Our results in some cases extend a previously derived
bound on the cop number using treewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2843</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2843</id><created>2013-08-13</created><authors><author><keyname>Bonato</keyname><forenames>Anthony</forenames></author><author><keyname>Finbow</keyname><forenames>Stephen</forenames></author><author><keyname>Gordinowicz</keyname><forenames>Przemyslaw</forenames></author><author><keyname>Haidar</keyname><forenames>Ali</forenames></author><author><keyname>Kinnersley</keyname><forenames>William B.</forenames></author><author><keyname>Mitsche</keyname><forenames>Dieter</forenames></author><author><keyname>Pralat</keyname><forenames>Pawel</forenames></author><author><keyname>Stacho</keyname><forenames>Ladislav</forenames></author></authors><title>The robber strikes back</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the new game of Cops and Attacking Robbers, which is identical to
the usual Cops and Robbers game except that if the robber moves to a vertex
containing a single cop, then that cop is removed from the game. We study the
minimum number of cops needed to capture a robber on a graph $G$, written
$cc(G)$. We give bounds on $cc(G)$ in terms of the cop number of $G$ in the
classes of bipartite graphs and diameter two, $K_{1,m}$-free graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2853</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2853</id><created>2013-08-13</created><authors><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Janzamin</keyname><forenames>Majid</forenames></author><author><keyname>Kakade</keyname><forenames>Sham</forenames></author></authors><title>When are Overcomplete Topic Models Identifiable? Uniqueness of Tensor
  Tucker Decompositions with Structured Sparsity</title><categories>cs.LG cs.IR math.NA math.ST stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Overcomplete latent representations have been very popular for unsupervised
feature learning in recent years. In this paper, we specify which overcomplete
models can be identified given observable moments of a certain order. We
consider probabilistic admixture or topic models in the overcomplete regime,
where the number of latent topics can greatly exceed the size of the observed
word vocabulary. While general overcomplete topic models are not identifiable,
we establish generic identifiability under a constraint, referred to as topic
persistence. Our sufficient conditions for identifiability involve a novel set
of &quot;higher order&quot; expansion conditions on the topic-word matrix or the
population structure of the model. This set of higher-order expansion
conditions allow for overcomplete models, and require the existence of a
perfect matching from latent topics to higher order observed words. We
establish that random structured topic models are identifiable w.h.p. in the
overcomplete regime. Our identifiability results allows for general
(non-degenerate) distributions for modeling the topic proportions, and thus, we
can handle arbitrarily correlated topics in our framework. Our identifiability
results imply uniqueness of a class of tensor decompositions with structured
sparsity which is contained in the class of Tucker decompositions, but is more
general than the Candecomp/Parafac (CP) decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2857</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2857</id><created>2013-08-13</created><authors><author><keyname>Mantovani</keyname><forenames>M. C.</forenames></author><author><keyname>Ribeiro</keyname><forenames>H. V.</forenames></author><author><keyname>Lenzi</keyname><forenames>E. K.</forenames></author><author><keyname>Picoli</keyname><forenames>S.</forenames><suffix>Jr.</suffix></author><author><keyname>Mendes</keyname><forenames>R. S.</forenames></author></authors><title>Engagement in the electoral processes: scaling laws and the role of the
  political positions</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>Accepted for publication in PRE</comments><journal-ref>Phys. Rev. E 88, 024802 (2013)</journal-ref><doi>10.1103/PhysRevE.88.024802</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on a statistical analysis of the engagement in the electoral
processes of all Brazilian cities by considering the number of party
memberships and the number of candidates for mayor and councillor. By
investigating the relationships between the number of party members and the
population of voters, we have found that the functional form of these
relationships are well described by sub-linear power laws (allometric scaling)
surrounded by a multiplicative log-normal noise. We have observed that this
pattern is quite similar to those previously-reported for the relationships
between the number candidates (mayor and councillor) and population of voters
[EPL 96, 48001 (2011)], suggesting that similar universal laws may be ruling
the engagement in the electoral processes. We also note that the power law
exponents display a clear hierarchy, where the more influential is the
political position the smaller is the value of the exponent. We have also
investigated the probability distributions of the number of candidates (mayor
and councilor), party memberships and voters. The results indicate that the
most influential positions are characterized by distributions with very
short-tails, while less influential positions display an intermediate power law
decay before showing an exponential-like cutoff. We discuss that, in addition
to the political power of the position, limitations in the number of available
seats can also be connected with this changing of behavior. We further believe
that our empirical findings point out to an underrepresentation effect, where
the larger city is, the larger are the obstacles for more individuals to become
directly engaged in the electoral process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2858</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2858</id><created>2013-08-13</created><updated>2013-08-14</updated><authors><author><keyname>Gajarsk&#xfd;</keyname><forenames>Jakub</forenames></author><author><keyname>Lampis</keyname><forenames>Michael</forenames></author><author><keyname>Ordyniak</keyname><forenames>Sebastian</forenames></author></authors><title>Parameterized Algorithms for Modular-Width</title><categories>cs.DS cs.CC cs.DM</categories><comments>to appear in IPEC 2013. arXiv admin note: text overlap with
  arXiv:1304.5479 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that a number of natural graph problems which are FPT
parameterized by treewidth become W-hard when parameterized by clique-width. It
is therefore desirable to find a different structural graph parameter which is
as general as possible, covers dense graphs but does not incur such a heavy
algorithmic penalty.
  The main contribution of this paper is to consider a parameter called
modular-width, defined using the well-known notion of modular decompositions.
Using a combination of ILPs and dynamic programming we manage to design FPT
algorithms for Coloring and Partitioning into paths (and hence Hamiltonian path
and Hamiltonian cycle), which are W-hard for both clique-width and its recently
introduced restriction, shrub-depth. We thus argue that modular-width occupies
a sweet spot as a graph parameter, generalizing several simpler notions on
dense graphs but still evading the &quot;price of generality&quot; paid by clique-width.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2867</identifier>
 <datestamp>2014-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2867</id><created>2013-08-13</created><updated>2014-04-14</updated><authors><author><keyname>Tran-Dinh</keyname><forenames>Quoc</forenames></author><author><keyname>Kyrillidis</keyname><forenames>Anastasios</forenames></author><author><keyname>Cevher</keyname><forenames>Volkan</forenames></author></authors><title>Composite Self-Concordant Minimization</title><categories>stat.ML cs.LG math.OC</categories><comments>46 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a variable metric framework for minimizing the sum of a
self-concordant function and a possibly non-smooth convex function, endowed
with an easily computable proximal operator. We theoretically establish the
convergence of our framework without relying on the usual Lipschitz gradient
assumption on the smooth part. An important highlight of our work is a new set
of analytic step-size selection and correction procedures based on the
structure of the problem. We describe concrete algorithmic instances of our
framework for several interesting applications and demonstrate them numerically
on both synthetic and real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2872</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2872</id><created>2013-08-13</created><authors><author><keyname>Varghese</keyname><forenames>Blesson</forenames></author><author><keyname>McKee</keyname><forenames>Gerard</forenames></author><author><keyname>Alexandrov</keyname><forenames>Vassil</forenames></author></authors><title>Can Agent Intelligence be used to Achieve Fault Tolerant Parallel
  Computing Systems?</title><categories>cs.DC cs.MA</categories><journal-ref>Parallel Processing Letters, Volume 21, Issue 04, December 2011</journal-ref><doi>10.1142/S012962641100028X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work reported in this paper is motivated towards validating an
alternative approach for fault tolerance over traditional methods like
checkpointing that constrain efficacious fault tolerance. Can agent
intelligence be used to achieve fault tolerant parallel computing systems? If
so, &quot;What agent capabilities are required for fault tolerance?&quot;, &quot;What parallel
computational tasks can benefit from such agent capabilities?&quot; and &quot;How can
agent capabilities be implemented for fault tolerance?&quot; need to be addressed.
Cognitive capabilities essential for achieving fault tolerance through agents
are considered. Parallel reduction algorithms are identified as a class of
algorithms that can benefit from cognitive agent capabilities. The Message
Passing Interface is utilized for implementing an intelligent agent based
approach. Preliminary results obtained from the experiments validate the
feasibility of an agent based approach for achieving fault tolerance in
parallel computing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2876</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2876</id><created>2013-08-13</created><authors><author><keyname>Hans</keyname><forenames>Robert T.</forenames></author></authors><title>Work Breakdown Structure: A Tool for Software Project Scope Verification</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software project scope verification is a very important process in project
scope management and it needs to be performed properly and thoroughly so as to
avoid project rework and scope creep. Moreover, software scope verification is
crucial in the process of delivering exactly what the customer requested and
minimizing project scope changes. Well defined software scope eases the process
of scope verification and contributes to project success. Furthermore, a
deliverable-oriented WBS provides a road map to a well defined software scope
of work. It is on the basis of this that this paper extends the use of
deliverable-oriented WBS to that of scope verification process. This paper
argues that a deliverable-oriented WBS is a tool for software scope
verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2881</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2881</id><created>2013-08-13</created><authors><author><keyname>Machens</keyname><forenames>Holger</forenames></author><author><keyname>Turau</keyname><forenames>Volker</forenames></author></authors><title>Opacity of Memory Management in Software Transactional Memory</title><categories>cs.DC cs.OS</categories><comments>Keywords: transactional memory, opacity, privatization, memory
  reclamation</comments><msc-class>65Y05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opacity of Transactional Memory is proposed to be established by incremental
validation. Quiescence in terms of epoch-based memory reclamation is applied to
deal with doomed transactions causing memory access violations. This method
unfortunately involves increased memory consumption and does not cover
reclamations outside of transactions. This paper introduces a different method
which combines incremental validation with elements of sandboxing to solve
these issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2891</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2891</id><created>2013-08-05</created><updated>2013-08-28</updated><authors><author><keyname>Carella</keyname><forenames>N. A.</forenames></author></authors><title>Deterministic Integer Factorization Algorithms</title><categories>cs.DS</categories><comments>Six Pages, Improved Version. arXiv admin note: substantial text
  overlap with arXiv:1003.3261</comments><msc-class>11A51</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note presents a deterministic integer factorization algorithm of running
time complexity O(N^(1/6+e)), e &gt; 0. This improves the current performances of
deterministic integer factorization algorithms rated at O(N^(1/4+e)) arithmetic
operations. Equivalently, given the least (log N)/6 bits of a factor of N = pq,
the algorithm factors the integer in polynomial time O(log(N)^c), c &gt; 0
constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2892</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2892</id><created>2013-08-13</created><authors><author><keyname>Stockhusen</keyname><forenames>Christoph</forenames></author><author><keyname>Tantau</keyname><forenames>Till</forenames></author></authors><title>Completeness Results for Parameterized Space Classes</title><categories>cs.CC</categories><comments>IPEC 2013</comments><msc-class>68Q15, 68Q17</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The parameterized complexity of a problem is considered &quot;settled&quot; once it has
been shown to lie in FPT or to be complete for a class in the W-hierarchy or a
similar parameterized hierarchy. Several natural parameterized problems have,
however, resisted such a classification. At least in some cases, the reason is
that upper and lower bounds for their parameterized space complexity have
recently been obtained that rule out completeness results for parameterized
time classes. In this paper, we make progress in this direction by proving that
the associative generability problem and the longest common subsequence problem
are complete for parameterized space classes. These classes are defined in
terms of different forms of bounded nondeterminism and in terms of simultaneous
time--space bounds. As a technical tool we introduce a &quot;union operation&quot; that
translates between problems complete for classical complexity classes and for
W-classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2893</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2893</id><created>2013-08-13</created><updated>2014-11-24</updated><authors><author><keyname>Daniely</keyname><forenames>Amit</forenames></author><author><keyname>Sabato</keyname><forenames>Sivan</forenames></author><author><keyname>Ben-David</keyname><forenames>Shai</forenames></author><author><keyname>Shalev-Shwartz</keyname><forenames>Shai</forenames></author></authors><title>Multiclass learnability and the ERM principle</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the sample complexity of multiclass prediction in several learning
settings. For the PAC setting our analysis reveals a surprising phenomenon: In
sharp contrast to binary classification, we show that there exist multiclass
hypothesis classes for which some Empirical Risk Minimizers (ERM learners) have
lower sample complexity than others. Furthermore, there are classes that are
learnable by some ERM learners, while other ERM learners will fail to learn
them. We propose a principle for designing good ERM learners, and use this
principle to prove tight bounds on the sample complexity of learning {\em
symmetric} multiclass hypothesis classes---classes that are invariant under
permutations of label names. We further provide a characterization of mistake
and regret bounds for multiclass learning in the online setting and the bandit
setting, using new generalizations of Littlestone's dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2894</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2894</id><created>2013-08-13</created><authors><author><keyname>Niu</keyname><forenames>Kai</forenames></author><author><keyname>Chen</keyname><forenames>Kai</forenames></author><author><keyname>Lin</keyname><forenames>Jiaru</forenames></author></authors><title>Low-Complexity Sphere Decoding of Polar Codes based on Optimum Path
  Metric</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sphere decoding (SD) of polar codes is an efficient method to achieve the
error performance of maximum likelihood (ML) decoding. But the complexity of
the conventional sphere decoder is still high, where the candidates in a target
sphere are enumerated and the radius is decreased gradually until no available
candidate is in the sphere. In order to reduce the complexity of SD, a stack SD
(SSD) algorithm with an efficient enumeration is proposed in this paper. Based
on a novel path metric, SSD can effectively narrow the search range when
enumerating the candidates within a sphere. The proposed metric follows an
exact ML rule and takes the full usage of the whole received sequence.
Furthermore, another very simple metric is provided as an approximation of the
ML metric in the high signal-to-noise ratio regime. For short polar codes,
simulation results over the additive white Gaussian noise channels show that
the complexity of SSD based on the proposed metrics is up to 100 times lower
than that of the conventional SD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2903</identifier>
 <datestamp>2014-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2903</id><created>2013-08-13</created><updated>2014-06-05</updated><authors><author><keyname>Miettinen</keyname><forenames>Markus</forenames></author><author><keyname>Heuser</keyname><forenames>Stephan</forenames></author><author><keyname>Kronz</keyname><forenames>Wiebke</forenames></author><author><keyname>Sadeghi</keyname><forenames>Ahmad-Reza</forenames></author><author><keyname>Asokan</keyname><forenames>N.</forenames></author></authors><title>ConXsense - Automated Context Classification for Context-Aware Access
  Control</title><categories>cs.CR</categories><comments>Recipient of the Best Paper Award</comments><acm-class>D.4.6</acm-class><journal-ref>Proceedings of the 9th ACM Symposium on Information, Computer and
  Communications Security (ASIACCS 2014), pp. 293-304, June 4-6, Kyoto, Japan,
  ACM, 2014</journal-ref><doi>10.1145/2590296.2590337</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present ConXsense, the first framework for context-aware access control on
mobile devices based on context classification. Previous context-aware access
control systems often require users to laboriously specify detailed policies or
they rely on pre-defined policies not adequately reflecting the true
preferences of users. We present the design and implementation of a
context-aware framework that uses a probabilistic approach to overcome these
deficiencies. The framework utilizes context sensing and machine learning to
automatically classify contexts according to their security and privacy-related
properties. We apply the framework to two important smartphone-related use
cases: protection against device misuse using a dynamic device lock and
protection against sensory malware. We ground our analysis on a sociological
survey examining the perceptions and concerns of users related to contextual
smartphone security and analyze the effectiveness of our approach with
real-world context data. We also demonstrate the integration of our framework
with the FlaskDroid architecture for fine-grained access control enforcement on
the Android platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2907</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2907</id><created>2013-08-13</created><updated>2013-10-03</updated><authors><author><keyname>Li</keyname><forenames>Ying</forenames></author><author><keyname>Bartos</keyname><forenames>Radim</forenames></author></authors><title>A Survey of Protocols for Intermittently Connected Delay-Tolerant
  Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Intermittently Connected Delay-Tolerant Wireless Sensor Networks (ICDT-WSNs),
a branch of Wireless Sensor Networks (WSNs), have features of WSNs and the
intermittent connectivity of Delay-Tolerant Networks (DTNs). The applications
of ICDT-WSNs are increasing in recent years, however, the communication
protocols suitable for this category of networks often fall short. Most of the
existing communication protocols are designed for either WSNs or DTNs and tend
to be inadequate for direct use in ICDT-WSNs. This survey summarizes
characteristics of ICDT-WSNs and their communication protocol requirements, and
examines the communication protocols designed for WSNs and DTNs in recent years
from the perspective of ICDT-WSNs. Opportunities for future research in
ICDT-WSNs are also outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2912</identifier>
 <datestamp>2014-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2912</id><created>2013-08-13</created><authors><author><keyname>Talal</keyname><forenames>Bendaoud Karim</forenames></author><author><keyname>Rachid</keyname><forenames>Merzougui</forenames></author></authors><title>Service Discovery -- A Survey and Comparison</title><categories>cs.NI</categories><comments>17 pages, 7 figures, 1 Comparative table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing number of services in the internet, companies intranets,
and home networks: service discovery becomes an integral part of modern
networked system. This paper provides a comprehensive survey of major solutions
for service discovery. We cover techniques and features used in existing
systems. Although a few survey articles have been published on this object, our
contribution focuses on comparing and analyzing surveyed solutions according
eight prime criteria, which we have defined before. This comparison will be
helpful to determine limits of existing discovery protocols and identify future
research opportunities in service discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2920</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2920</id><created>2013-08-13</created><authors><author><keyname>Dixit</keyname><forenames>Rahul K</forenames></author><author><keyname>Johari</keyname><forenames>Rahul</forenames></author></authors><title>As-puma ; anycast semantics in parking using metaheuristic approach</title><categories>cs.NI</categories><journal-ref>Rahul K Dixit, Research Scholar, USICT, GGSIP University,
  Delhi-110078., AMIETE from I.E.T.E,Lodhi Road, Delhi Gate Scholar in 2011 and
  2012. Rahul Johari, is working as a Assistant Professor in USICT, GGSIPU</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of vehicle used in the world are increasing day by day resulting
in the obvious problem of parking of these vehicles in residential and
vocational areas. We perceive the problem of vehicles parking in vocational
establishments / malls. Today majority of parking systems are manual parking
systems where in, on the spot, parking of the vehicle is done and a parking
slip is generated and handed over to customer. This is cumbersome technique
wherein various parking attendants in the parking areas manually keeps on
informing the Parking inspector on how many free parking slots available so
that only that many number of parking slips/tickets are generated as the number
of free parking slots. We address the problem of parking in Delay Tolerant
Network (DTN) by proposing metaheuristic driven approach of Ant Colony
optimization (ACO) technique with anycast semantics models . Here we propose
the parking architecture to solve the problem of parking especially in
commercial areas with their design diagrams . In this architecture we apply the
delivery model to deliver the packet correctly to the intended receiver. Using
this we can book various parkings through remote areas so that the customer can
get the information about availability of various parkings inside an area and
the parking fare for each category of the automobile. Using this architecture
the customer can get the prior knowledge about various vacant parking slots
inside a parking area and he can book the corresponding parking from his
location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2921</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2921</id><created>2013-08-13</created><authors><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Soriente</keyname><forenames>Claudio</forenames></author></authors><title>Extended Capabilities for a Privacy-Enhanced Participatory Sensing
  Infrastructure (PEPSI)</title><categories>cs.CR</categories><comments>A preliminary version of this article, titled &quot;PEPSI:
  Privacy-Enhanced Participatory Sensing Infrastructure&quot;, appears in the
  Proceedings of the 4th ACM Conference on Wireless Security (WiSec 2011). This
  is the extended (journal) version, currently in revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Participatory sensing is emerging as an innovative computing paradigm that
targets the ubiquity of always-connected mobile phones and their sensing
capabilities. In this context, a multitude of pioneering applications
increasingly carry out pervasive collection and dissemination of information
and environmental data, such as, traffic conditions, pollution, temperature,
etc. Participants collect and report measurements from their mobile devices and
entrust them to the cloud to be made available to applications and users.
Naturally, due to the personal information associated to the reports (e.g.,
location, movements, etc.), a number of privacy concerns need to be taken into
account prior to a large-scale deployment of these applications. Motivated by
the need for privacy protection in Participatory Sensing, this work presents
PEPSI: a Privacy-Enhanced Participatory Sensing Infrastructure. We explore
realistic architectural assumptions and a minimal set of formal requirements
aiming at protecting privacy of both data producers and consumers. We propose
two instantiations that attain privacy guarantees with provable security at
very low additional computational cost and almost no extra communication
overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2923</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2923</id><created>2013-08-13</created><authors><author><keyname>Wang</keyname><forenames>Shangxing</forenames></author><author><keyname>Gasparri</keyname><forenames>Andrea</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author></authors><title>Robotic Message Ferrying for Wireless Networks using Coarse-Grained
  Backpressure Control</title><categories>cs.NI cs.RO cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate the problem of robots ferrying messages between
statically-placed source and sink pairs that they can communicate with
wirelessly. We first analyze the capacity region for this problem under both
ideal (arbitrarily high velocity, long scheduling periods) and realistic
conditions. We indicate how robots could be scheduled optimally to satisfy any
arrival rate in the capacity region, given prior knowledge about arrival rates.
We find that if the number of robots allocated grows proportionally with the
number of source-sink pairs, then the capacity of the network scales as
$\Theta(1)$, similar to what was shown previously by Grossglauser and Tse for
uncontrolled mobility; however, in contrast to that prior result, we also find
that with controlled mobility this constant capacity scaling can be obtained
while ensuring finite delay. We then consider the setting where the arrival
rates are unknown and present a coarse-grained backpressure message ferrying
algorithm (CBMF) for it. In CBMF, the robots are matched to sources and sinks
once every epoch to maximize a queue-differential-based weight. The matching
controls both motion and transmission for each robot: if a robot is matched to
a source, it moves towards that source and collects data from it; and if it is
matched to a sink, it moves towards that sink and transmits data to it. We show
through analysis and simulations the conditions under which CBMF can stabilize
the network. We show that the maximum achievable stable throughput with this
policy tends to the ideal capacity as the schedule duration and robot velocity
increase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2930</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2930</id><created>2013-08-13</created><updated>2013-12-06</updated><authors><author><keyname>Hui</keyname><forenames>Qing</forenames></author><author><keyname>Zhang</keyname><forenames>Haopeng</forenames></author></authors><title>Semistability-Based Convergence Analysis for Paracontracting Multiagent
  Coordination Optimization</title><categories>cs.SY cs.NE math.OC</categories><comments>41 pages, 1 figure. arXiv admin note: substantial text overlap with
  arXiv:1306.0225</comments><report-no>Technical Report CSEL-08-13</report-no><msc-class>90C59, 93D99</msc-class><acm-class>G.1.0; G.1.6; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This sequential technical report extends some of the previous results we
posted at arXiv:1306.0225.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2938</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2938</id><created>2013-08-13</created><authors><author><keyname>Jaaskelainen</keyname><forenames>K.</forenames></author><author><keyname>Pau</keyname><forenames>L-F</forenames></author></authors><title>ERP projects Internal Stakeholder network and how it influences the
  projects outcome</title><categories>cs.SI cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  So far little effort has been put into researching the importance of internal
ERP project stakeholders mutual interactions,realizing the projects
complexity,influence on the whole organization, and high risk for a useful
final outcome. This research analyzes the stakeholders interactions and
positions in the project network, their criticality, potential bottlenecks and
conflicts. The main methods used are Social Network Analysis, and the
elicitation of drivers for the individual players. Information was collected
from several stakeholders from three large ERP projects all in global companies
headquartered in Finland, together with representatives from two different ERP
vendors, and with two experienced ERP consultants. The analysis gives
quantitative as well as qualitative characterization of stakeholder criticality
(mostly the Project Manager(s), the Business Owner(s) and the Process
Owner(s)), degree of centrality, closeness, mediating or bottleneck roles,
relational ties and conflicts (individual, besides those between business and
project organizations), and clique formations. A generic internal stakeholder
network model is established as well as the criticality of the project phases.
The results are summarized in the form of a list of recommendations for future
ERP projects to address the internal stakeholder impacts .Project management
should utilize the latest technology to provide tools to increase the
interaction between the stakeholders and to monitor the strength of these
relations. Social network analysis tools could be used in the projects to
visualize the stakeholder relations in order to better understand the possible
risks related to the relations (or lack of them).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2940</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2940</id><created>2013-08-13</created><authors><author><keyname>Pau</keyname><forenames>L. F.</forenames></author></authors><title>Mobile operators as banks or vice-versa? and: regulators interest in the
  best efficiency for payments</title><categories>cs.CY</categories><comments>COST 605 Workshop, Paris, 2008 http://www.cost605.org/docs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the strategic challenges of deposit banks, and payment
clearinghouses, posed by the growing role of mobile operators as collectors and
payment agents for flows of cash for themselves and third parties. Through
analysis and data analysis from selected operators, it is shown that mobile
operators achieve as money flow handlers levels of efficiency,
profitability,and risk control comparable with deposit banks. Furthermore, the
payment infrastructures deployed by both are found to be quite similar, and are
analyzed in relation to financial profitability, strategic challenges and
opportunities. This paves the way to either mobile operators taking a bigger
role,or for banks to tie up such operators to them even more tightly,or for
alliances/mergers to take place,all these options being subject to regulatory
evolution which is analyzed as well . The consequences are mapped out in
operational and regulatory terms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2944</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2944</id><created>2013-08-13</created><authors><author><keyname>Pau</keyname><forenames>L. F.</forenames></author></authors><title>Smart business networks and business genetics with a high tech
  communications supplier selection industry case</title><categories>cs.CY cs.SI</categories><comments>Research report ERIM, Rotterdam school of management, Feb. 2006,
  http://hdl.handle.net/1765/7319</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the emergence of event driven business process management, smart
business networks, social networks, etc. as important research areas in
management, for all the attractiveness of these concepts, two major challenges
remain around their design and the partner selection rules while learning from
interaction events.While smart business networks should provide advantages due
to the quick connect of business partners for selected functions in a process
common to several parties, literature does not provide constructive methods
whereby the selection of temporary partners and functions can be done. Most
discussions only rely solely on human judgment. This paper introduces both
computational geometry, and genetic programming, as systematic methods whereby
to identify, characterize, and then display on a continuing basis from event
monitoring such possible partnerships; such techniques also allow to plan for
their effect on the organizations and thus to carry out selection. The two
methods are being put in the context of emergence theory. Tessellations address
the identification and categorization issues; business maps address the display
and monitoring challenge with the use of Voronoii diagrams. Cellular automata
mimicking living bodies, with genetic algorithms of which parameters are
estimated by learning, address the selection and effect issues. To illustrate
the approach, some experimental results from the sourcing function in a high
tech industry, are discussed; they address the case of how to determine the
selection process for a systems integrator to set up joint ventures with
smaller technology suppliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2947</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2947</id><created>2013-08-13</created><authors><author><keyname>Pau</keyname><forenames>L. F.</forenames></author></authors><title>How and why communications industry suppliers get squeezed out: now, and
  the next phase</title><categories>cs.CY</categories><comments>Research report Erasmus Research Institute of management, Erasmus
  University, Rotterdam, http://hdl.handle.net/1765/317</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The communications systems, terminals, software and deployment service,
industries, have undergone the past ten years a significant technological
internal evolution and external revolution at customer end (such as Internet,
Mobile networks and terminals, Broadband,..). Very little management research
has studied their financial survivability irrespective of changes in demand
volumes in the present technological /organizational cycle. This paper analyzes
the implications of genuine open mandated communications standards, of higher
product volumes, of very high R&amp;D, of the larger use of sourced /purchased
technologies, and of contract manufacturing. The methodology used is
equilibrium analyses. Two specific areas will be mentioned as examples. The
paper also shows how eventually those industries in a later cycle will bounce
back.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2950</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2950</id><created>2013-08-13</created><updated>2013-11-22</updated><authors><author><keyname>Li</keyname><forenames>Xinfeng</forenames></author><author><keyname>Wu</keyname><forenames>Chenshu</forenames></author><author><keyname>Wang</keyname><forenames>Xiaoyuan</forenames></author><author><keyname>Gu</keyname><forenames>Ming</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author><author><keyname>Xuan</keyname><forenames>Dong</forenames></author></authors><title>BlueSky: Realizing Buried Potential of Bluetooth to Sustain a
  Large-scale Multi-hop Network</title><categories>cs.NI</categories><comments>We need to improve this paper further</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, Bluetooth has been deemed unsuitable for sustaining a
large-scale multi-hop network. There are two main reasons: severe frequency
channel collisions under a large-scale network and high complexity of designing
an efficient formation protocol. In this work, we reconsider this viewpoint
from a practical usability perspective and aim to realize the buried potential
of Bluetooth. Firstly, we find that the collision probability under a
low-overhead network is fairly small, which is acceptable for practical
applications. Secondly, we propose BlueSky, a complete system solution to
provide necessary networking functionalities for Bluetooth. In BlueSky, we
develop a connection maintenance mechanism for mitigating the influence of
collisions and a network formation protocol for reliable packet transmissions.
We implement BlueSky on Windows Mobile using 100 commercial smartphones.
Comprehensive usability evaluations demonstrate the negligible overheads of
BlueSky and its good network performance. In particular, 90%-95% of the whole
100 nodes can participate in the communication smoothly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2952</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2952</id><created>2013-08-13</created><authors><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author><author><keyname>Chen</keyname><forenames>Richard Y.</forenames></author></authors><title>Subadditivity of Matrix phi-Entropy and Concentration of Random Matrices</title><categories>cs.IT math.IT math.PR</categories><comments>23 pages</comments><msc-class>60B20, 60E15, 60F10</msc-class><journal-ref>Electron. J. Probab., Vol. 19, Article 27, pp. 1-30, Mar. 2014</journal-ref><doi>10.1214/EJP.v19-2964</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix concentration inequalities provide a direct way to bound the typical
spectral norm of a random matrix. The methods for establishing these results
often parallel classical arguments, such as the Laplace transform method. This
work develops a matrix extension of the entropy method, and it applies these
ideas to obtain some matrix concentration inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2954</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2954</id><created>2013-08-13</created><authors><author><keyname>Abrahao</keyname><forenames>Bruno</forenames></author><author><keyname>Chierichetti</keyname><forenames>Flavio</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Panconesi</keyname><forenames>Alessandro</forenames></author></authors><title>Trace Complexity of Network Inference</title><categories>cs.DS cs.SI</categories><comments>25 pages, preliminary version appeared in Proceedings of the 19th ACM
  SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD
  2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The network inference problem consists of reconstructing the edge set of a
network given traces representing the chronology of infection times as
epidemics spread through the network. This problem is a paradigmatic
representative of prediction tasks in machine learning that require deducing a
latent structure from observed patterns of activity in a network, which often
require an unrealistically large number of resources (e.g., amount of available
data, or computational time). A fundamental question is to understand which
properties we can predict with a reasonable degree of accuracy with the
available resources, and which we cannot. We define the trace complexity as the
number of distinct traces required to achieve high fidelity in reconstructing
the topology of the unobserved network or, more generally, some of its
properties. We give algorithms that are competitive with, while being simpler
and more efficient than, existing network inference approaches. Moreover, we
prove that our algorithms are nearly optimal, by proving an
information-theoretic lower bound on the number of traces that an optimal
inference algorithm requires for performing this task in the general case.
Given these strong lower bounds, we turn our attention to special cases, such
as trees and bounded-degree graphs, and to property recovery tasks, such as
reconstructing the degree distribution without inferring the network. We show
that these problems require a much smaller (and more realistic) number of
traces, making them potentially solvable in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2970</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2970</id><created>2013-08-13</created><authors><author><keyname>Ahlbach</keyname><forenames>Connor</forenames></author><author><keyname>Usatine</keyname><forenames>Jeremy</forenames></author><author><keyname>Pippenger</keyname><forenames>Nicholas</forenames></author></authors><title>Gap Theorems for the Delay of Circuits Simulating Finite Automata</title><categories>cs.CC</categories><comments>i+14 pp</comments><msc-class>68Q25, 68Q45, 94C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the delay (also known as depth) of circuits that simulate finite
automata, showing that only certain growth rates (as a function of the number
$n$ of steps simulated) are possible. A classic result due to Ofman
(rediscovered and popularized by Ladner and Fischer) says that delay $O(\log
n)$ is always sufficient. We show that if the automaton is &quot;generalized
definite&quot;, then delay O(1) is sufficient, but otherwise delay $\Omega(\log n)$
is necessary; there are no intermediate growth rates. We also consider
&quot;physical&quot; (rather than &quot;logical&quot;) delay, whereby we consider the lengths of
wires when inputs and outputs are laid out along a line. In this case, delay
O(n) is clearly always sufficient. We show that if the automaton is &quot;definite&quot;,
then delay O(1) is sufficient, but otherwise delay $\Omega(n)$ is necessary;
again there are no intermediate growth rates. Inspired by an observation of
Burks, Goldstein and von Neumann concerning the average delay due to carry
propagation in ripple-carry adders, we derive conditions for the average
physical delay to be reduced from O(n) to $O(\log n)$, or to O(1), when the
inputs are independent and uniformly distributed random variables; again there
are no intermediate growth rates. Finally we consider an extension of this last
result to a situation in which the inputs are not independent and uniformly
distributed, but rather are produced by a non-stationary Markov process, and in
which the computation is not performed by a single automaton, but rather by a
sequence of automata acting in alternating directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.2979</identifier>
 <datestamp>2015-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.2979</id><created>2013-08-13</created><updated>2015-10-12</updated><authors><author><keyname>Junqueira</keyname><forenames>Flavio P.</forenames></author><author><keyname>Serafini</keyname><forenames>Marco</forenames></author></authors><title>On Barriers and the Gap between Active and Passive Replication (Full
  Version)</title><categories>cs.DC</categories><comments>A shorter version of this work (without appendices) appears in the
  proceedings of the 27th International Symposium on Distributed Computing
  (DISC) 2013 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active replication is commonly built on top of the atomic broadcast
primitive. Passive replication, which has been recently used in the popular
ZooKeeper coordination system, can be naturally built on top of the
primary-order atomic broadcast primitive. Passive replication differs from
active replication in that it requires processes to cross a barrier before they
become primaries and start broadcasting messages. In this paper, we propose a
barrier function tau that explains and encapsulates the differences between
existing primary-order atomic broadcast algorithms, namely semi-passive
replication and Zookeeper atomic broadcast (Zab), as well as the differences
between Paxos and Zab. We also show that implementing primary-order atomic
broadcast on top of a generic consensus primitive and tau inherently results in
higher time complexity than atomic broadcast, as witnessed by existing
algorithms. We overcome this problem by presenting an alternative,
primary-order atomic broadcast implementation that builds on top of a generic
consensus primitive and uses consensus itself to form a barrier. This algorithm
is modular and matches the time complexity of existing tau-based algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3009</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3009</id><created>2013-08-13</created><authors><author><keyname>Cabral</keyname><forenames>Raquel S.</forenames></author><author><keyname>Aquino</keyname><forenames>Andre L. L.</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author><author><keyname>Rosso</keyname><forenames>Osvaldo A.</forenames></author><author><keyname>Ram&#xed;rez</keyname><forenames>Jaime A.</forenames></author></authors><title>Structural Changes in Data Communication in Wireless Sensor Networks</title><categories>physics.data-an cs.IT cs.NI math.IT</categories><comments>12 pages, 4 figures, Central European Journal of Physics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks are an important technology for making distributed
autonomous measures in hostile or inaccessible environments. Among the
challenges they pose, the way data travel among them is a relevant issue since
their structure is quite dynamic. The operational topology of such devices can
often be described by complex networks. In this work, we assess the variation
of measures commonly employed in the complex networks literature applied to
wireless sensor networks. Four data communication strategies were considered:
geometric, random, small-world, and scale-free models, along with the shortest
path length measure. The sensitivity of this measure was analyzed with respect
to the following perturbations: insertion and removal of nodes in the geometric
strategy; and insertion, removal and rewiring of links in the other models. The
assessment was performed using the normalized Kullback-Leibler divergence and
Hellinger distance quantifiers, both deriving from the Information Theory
framework. The results reveal that the shortest path length is sensitive to
perturbations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3015</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3015</id><created>2013-08-13</created><authors><author><keyname>Ahmed</keyname><forenames>Nisar</forenames></author><author><keyname>Yang</keyname><forenames>Tsung-Lin</forenames></author><author><keyname>Campbell</keyname><forenames>Mark</forenames></author></authors><title>On Generalized Bayesian Data Fusion with Complex Models in Large Scale
  Networks</title><categories>cs.RO cs.SY stat.CO stat.ME</categories><comments>Revised version of paper submitted to 2013 Workshop on Wireless
  Intelligent Sensor Networks (WISeNET 2013) at Duke University, June 5, 2013</comments><acm-class>G.3; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in communications, mobile computing, and artificial
intelligence have greatly expanded the application space of intelligent
distributed sensor networks. This in turn motivates the development of
generalized Bayesian decentralized data fusion (DDF) algorithms for robust and
efficient information sharing among autonomous agents using probabilistic
belief models. However, DDF is significantly challenging to implement for
general real-world applications requiring the use of dynamic/ad hoc network
topologies and complex belief models, such as Gaussian mixtures or hybrid
Bayesian networks. To tackle these issues, we first discuss some new key
mathematical insights about exact DDF and conservative approximations to DDF.
These insights are then used to develop novel generalized DDF algorithms for
complex beliefs based on mixture pdfs and conditional factors. Numerical
examples motivated by multi-robot target search demonstrate that our methods
lead to significantly better fusion results, and thus have great potential to
enhance distributed intelligent reasoning in sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3025</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3025</id><created>2013-08-14</created><authors><author><keyname>Uchida</keyname><forenames>Satoshi</forenames></author><author><keyname>Sasaki</keyname><forenames>Tatsuya</forenames></author></authors><title>Effect of assessment error and private information on stern-judging in
  indirect reciprocity</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>18 pages and 2 figures</comments><journal-ref>Chaos, Solitons &amp; Fractals, 56,175-180 (2013)</journal-ref><doi>10.1016/j.chaos.2013.08.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stern-judging is one of the best-known assessment rules in indirect
reciprocity. Indirect reciprocity is a fundamental mechanism for the evolution
of cooperation. It relies on mutual monitoring and assessments, i.e.,
individuals judge, following their own assessment rules, whether other
individuals are &quot;good&quot; or &quot;bad&quot; according to information on their past
behaviors. Among many assessment rules, stern-judging is known to provide
stable cooperation in a population, as observed when all members in the
population know all about others' behaviors (public information case) and when
the members never commit an assessment error. In this paper, the effect of
assessment error and private information on stern-judging is investigated. By
analyzing the image matrix, which describes who is good in the eyes of whom in
the population, we analytically show that private information and assessment
error cause the collapse of stern-judging: all individuals assess other
individuals as &quot;good&quot; at random with a probability of 1/2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3052</identifier>
 <datestamp>2013-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3052</id><created>2013-08-14</created><updated>2013-11-25</updated><authors><author><keyname>Xue</keyname><forenames>Wufeng</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Mou</keyname><forenames>Xuanqin</forenames></author><author><keyname>Bovik</keyname><forenames>Alan C.</forenames></author></authors><title>Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual
  Image Quality Index</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  It is an important task to faithfully evaluate the perceptual quality of
output images in many applications such as image compression, image restoration
and multimedia streaming. A good image quality assessment (IQA) model should
not only deliver high quality prediction accuracy but also be computationally
efficient. The efficiency of IQA metrics is becoming particularly important due
to the increasing proliferation of high-volume visual data in high-speed
networks. We present a new effective and efficient IQA model, called gradient
magnitude similarity deviation (GMSD). The image gradients are sensitive to
image distortions, while different local structures in a distorted image suffer
different degrees of degradations. This motivates us to explore the use of
global variation of gradient based local quality map for overall image quality
prediction. We find that the pixel-wise gradient magnitude similarity (GMS)
between the reference and distorted images combined with a novel pooling
strategy the standard deviation of the GMS map can predict accurately
perceptual image quality. The resulting GMSD algorithm is much faster than most
state-of-the-art IQA methods, and delivers highly competitive prediction
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3058</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3058</id><created>2013-08-14</created><updated>2013-09-26</updated><authors><author><keyname>Ranieri</keyname><forenames>Juri</forenames></author><author><keyname>Chebira</keyname><forenames>Amina</forenames></author><author><keyname>Lu</keyname><forenames>Yue M.</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Phase Retrieval for Sparse Signals: Uniqueness Conditions</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE TIT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a variety of fields, in particular those involving imaging and optics, we
often measure signals whose phase is missing or has been irremediably
distorted. Phase retrieval attempts the recovery of the phase information of a
signal from the magnitude of its Fourier transform to enable the reconstruction
of the original signal. A fundamental question then is: &quot;Under which conditions
can we uniquely recover the signal of interest from its measured magnitudes?&quot;
In this paper, we assume the measured signal to be sparse. This is a natural
assumption in many applications, such as X-ray crystallography, speckle imaging
and blind channel estimation. In this work, we derive a sufficient condition
for the uniqueness of the solution of the phase retrieval (PR) problem for both
discrete and continuous domains, and for one and multi-dimensional domains.
More precisely, we show that there is a strong connection between PR and the
turnpike problem, a classic combinatorial problem. We also prove that the
existence of collisions in the autocorrelation function of the signal may
preclude the uniqueness of the solution of PR. Then, assuming the absence of
collisions, we prove that the solution is almost surely unique on 1-dimensional
domains. Finally, we extend this result to multi-dimensional signals by solving
a set of 1-dimensional problems. We show that the solution of the
multi-dimensional problem is unique when the autocorrelation function has no
collisions, significantly improving upon a previously known result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3059</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3059</id><created>2013-08-14</created><authors><author><keyname>Zeng</keyname><forenames>Wei</forenames></author><author><keyname>Zeng</keyname><forenames>An</forenames></author><author><keyname>Shang</keyname><forenames>Ming-Sheng</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Membership in social networks and the application in information
  filtering</title><categories>cs.IR cs.SI physics.soc-ph</categories><comments>7 pages, 4 figures</comments><doi>10.1140/epjb/e2013-40258-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the past a few years, users' membership in the online system (i.e. the
social groups that online users joined) are wildly investigated. Most of these
works focus on the detection, formulation and growth of online communities. In
this paper, we study users' membership in a coupled system which contains
user-group and user-object bipartite networks. By linking users' membership
information and their object selection, we find that the users who have
collected only a few objects are more likely to be &quot;influenced&quot; by the
membership when choosing objects. Moreover, we observe that some users may join
many online communities though they collected few objects. Based on these
findings, we design a social diffusion recommendation algorithm which can
effectively solve the user cold-start problem. Finally, we propose a
personalized combination of our method and the hybrid method in [PNAS 107, 4511
(2010)], which leads to a further improvement in the overall recommendation
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3060</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3060</id><created>2013-08-14</created><authors><author><keyname>Zeng</keyname><forenames>Wei</forenames></author><author><keyname>Zeng</keyname><forenames>An</forenames></author><author><keyname>Shang</keyname><forenames>Ming-Sheng</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Information filtering in sparse online systems: recommendation via
  semi-local diffusion</title><categories>cs.IR</categories><comments>8 figures</comments><doi>10.1371/journal.pone.0079354</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid growth of the Internet and overwhelming amount of information
and choices that people are confronted with, recommender systems have been
developed to effectively support users' decision-making process in the online
systems. However, many recommendation algorithms suffer from the data sparsity
problem, i.e. the user-object bipartite networks are so sparse that algorithms
cannot accurately recommend objects for users. This data sparsity problem makes
many well-known recommendation algorithms perform poorly. To solve the problem,
we propose a recommendation algorithm based on the semi-local diffusion process
on a user-object bipartite network. The numerical simulation on two sparse
datasets, Amazon and Bookcross, show that our method significantly outperforms
the state-of-the-art methods especially for those small-degree users. Two
personalized semi-local diffusion methods are proposed which further improve
the recommendation accuracy. Finally, our work indicates that sparse online
systems are essentially different from the dense online systems, all the
algorithms and conclusions based on dense data should be rechecked again in
sparse data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3080</identifier>
 <datestamp>2014-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3080</id><created>2013-08-14</created><updated>2014-05-31</updated><authors><author><keyname>He</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Tianshi</forenames></author><author><keyname>Yao</keyname><forenames>Xin</forenames></author></authors><title>Average Drift Analysis and its Application</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drift analysis is a useful tool for estimating the running time of
evolutionary algorithms. A new representation of drift analysis, called average
drift analysis, is described in this paper. It takes a weaker requirement than
point-wise drift analysis does. Point-wise drift theorems are corollaries of
our average drift theorems. Therefore average drift analysis is more powerful
than point-wise drift analysis. To demonstrate the application of average drift
analysis, we choose a (1+N) evolutionary algorithms for linear-like functions
as a case study. Linear-like functions are proposed as a natural extension of
linear functions. For the (1+N) evolutionary algorithms to maximise linear-like
functions, the lower and upper bounds on their running time have been derived
using the average drift analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3101</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3101</id><created>2013-08-14</created><authors><author><keyname>Zach</keyname><forenames>Christopher</forenames></author><author><keyname>Haene</keyname><forenames>Christian</forenames></author></authors><title>Compact Relaxations for MAP Inference in Pairwise MRFs with Piecewise
  Linear Priors</title><categories>cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Label assignment problems with large state spaces are important tasks
especially in computer vision. Often the pairwise interaction (or smoothness
prior) between labels assigned at adjacent nodes (or pixels) can be described
as a function of the label difference. Exact inference in such labeling tasks
is still difficult, and therefore approximate inference methods based on a
linear programming (LP) relaxation are commonly used in practice. In this work
we study how compact linear programs can be constructed for general piecwise
linear smoothness priors. The number of unknowns is O(LK) per pairwise clique
in terms of the state space size $L$ and the number of linear segments K. This
compares to an O(L^2) size complexity of the standard LP relaxation if the
piecewise linear structure is ignored. Our compact construction and the
standard LP relaxation are equivalent and lead to the same (approximate) label
assignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3106</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3106</id><created>2013-08-14</created><authors><author><keyname>Kumar</keyname><forenames>Sachin</forenames></author><author><keyname>Kumar</keyname><forenames>Ashish</forenames></author><author><keyname>Mitra</keyname><forenames>Pinaki</forenames></author><author><keyname>Sundaram</keyname><forenames>Girish</forenames></author></authors><title>System and Methods for Converting Speech to SQL</title><categories>cs.CL cs.DB</categories><comments>Appeared In proceedings of International Conference ERCICA 2013 pp:
  291-298, Published by Elsevier Ltd, ISBN:9789351071020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns with the conversion of a Spoken English Language Query
into SQL for retrieving data from RDBMS. A User submits a query as speech
signal through the user interface and gets the result of the query in the text
format. We have developed the acoustic and language models using which a speech
utterance can be converted into English text query and thus natural language
processing techniques can be applied on this English text query to generate an
equivalent SQL query. For conversion of speech into English text HTK and Julius
tools have been used and for conversion of English text query into SQL query we
have implemented a System which uses rule based translation to translate
English Language Query into SQL Query. The translation uses lexical analyzer,
parser and syntax directed translation techniques like in compilers. JFLex and
BYACC tools have been used to build lexical analyzer and parser respectively.
System is domain independent i.e. system can run on different database as it
generates lex files from the underlying database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3112</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3112</id><created>2013-08-14</created><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author></authors><title>Nonlinearity measures of random Boolean functions</title><categories>math.CO cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The r-th order nonlinearity of a Boolean function is the minimum number of
elements that have to be changed in its truth table to arrive at a Boolean
function of degree at most r. It is shown that the (suitably normalised) r-th
order nonlinearity of a random Boolean function converges strongly for all r\ge
1. This extends results by Rodier for r=1 and by Dib for r=2. The methods in
the present paper are mostly of elementary combinatorial nature and also lead
to simpler proofs in the cases that r=1 or 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3119</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3119</id><created>2013-08-14</created><updated>2014-12-07</updated><authors><author><keyname>Peng</keyname><forenames>Qiuyu</forenames></author><author><keyname>Walid</keyname><forenames>Anwar</forenames></author><author><keyname>Hwang</keyname><forenames>Jaehyun</forenames></author><author><keyname>Low</keyname><forenames>Steven H.</forenames></author></authors><title>Multipath TCP: Analysis, Design and Implementation</title><categories>cs.NI</categories><comments>15 pages</comments><doi>10.1109/TNET.2014.2379698</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-path TCP (MP-TCP) has the potential to greatly improve application
performance by using multiple paths transparently. We propose a fluid model for
a large class of MP-TCP algorithms and identify design criteria that guarantee
the existence, uniqueness, and stability of system equilibrium. We clarify how
algorithm parameters impact TCP-friendliness, responsiveness, and window
oscillation and demonstrate an inevitable tradeoff among these properties. We
discuss the implications of these properties on the behavior of existing
algorithms and motivate a new design that generalizes existing algorithms and
strikes a good balance among TCP-friendliness, responsiveness, and window
oscillation. We have implemented our algorithm in the Linux kernel. We use our
prototype to compare the new algorithm with existing MP-TCP algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3123</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3123</id><created>2013-08-14</created><authors><author><keyname>Weinberg</keyname><forenames>Volker</forenames></author><author><keyname>Allalen</keyname><forenames>Momme</forenames></author></authors><title>First experiences with the Intel MIC architecture at LRZ</title><categories>cs.PF cs.AR</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapidly growing demand for computing power new accelerator based
architectures have entered the world of high performance computing since around
5 years. In particular GPGPUs have recently become very popular, however
programming GPGPUs using programming languages like CUDA or OpenCL is
cumbersome and error-prone. Trying to overcome these difficulties, Intel
developed their own Many Integrated Core (MIC) architecture which can be
programmed using standard parallel programming techniques like OpenMP and MPI.
In the beginning of 2013, the first production-level cards named Intel Xeon Phi
came on the market. LRZ has been considered by Intel as a leading research
centre for evaluating coprocessors based on the MIC architecture since 2010
under strict NDA. Since the Intel Xeon Phi is now generally available, we can
share our experience on programming Intel's new MIC architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3127</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3127</id><created>2013-08-12</created><authors><author><keyname>Bouchti</keyname><forenames>Abdelali El</forenames></author><author><keyname>Kafhali</keyname><forenames>Said El</forenames></author><author><keyname>Haqiq</keyname><forenames>Abdelkrim</forenames></author></authors><title>Performance Analysis of Connection Admission Control Scheme in IEEE
  802.16 OFDMA Networks</title><categories>cs.PF cs.IT cs.NI cs.SY math.IT</categories><comments>7 pages, (IJCSIS) International Journal of Computer Science and
  Information Security, Volume 9 No. 3, March 2011. arXiv admin note:
  substantial text overlap with arXiv:1304.2033, arXiv:1203.4339</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  IEEE 802.16 OFDMA (Orthogonal Frequency Division Multiple Access) technology
has emerged as a promising technology for broadband access in a Wireless
Metropolitan Area Network (WMAN) environment. In this paper, we address the
problem of queueing theoretic performance modeling and analysis of OFDMA under
broad-band wireless networks. We consider a single-cell IEEE 802.16 environment
in which the base station allocates subchannels to the subscriber stations in
its coverage area. The subchannels allocated to a subscriber station are shared
by multiple connections at that subscriber station. To ensure the Quality of
Service (QoS) performances, a Connection Admission Control (CAC) scheme is
considered at a subscriber station. A queueing analytical framework for these
admission control schemes is presented considering OFDMA-based transmission at
the physical layer. Then, based on the queueing model, both the
connection-level and the packet-level performances are studied and compared
with their analogues in the case without CAC. The connection arrival is modeled
by a Poisson process and the packet arrival for a connection by a two-state
Markov Modulated Poisson Process (MMPP). We determine analytically and
numerically different performance parameters, such as connection blocking
probability, average number of ongoing connections, average queue length,
packet dropping probability, queue throughput and average packet delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3136</identifier>
 <datestamp>2015-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3136</id><created>2013-08-13</created><updated>2015-01-15</updated><authors><author><keyname>Preen</keyname><forenames>Richard J.</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>Toward the Coevolution of Novel Vertical-Axis Wind Turbines</title><categories>cs.NE cs.AI cs.CE</categories><comments>appears in IEEE Transactions on Evolutionary Computation (2014).
  arXiv admin note: substantial text overlap with arXiv:1212.5271,
  arXiv:1204.4107</comments><journal-ref>IEEE Transactions on Evolutionary Computation (2015),
  19(2):284-294</journal-ref><doi>10.1109/TEVC.2014.2316199</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The production of renewable and sustainable energy is one of the most
important challenges currently facing mankind. Wind has made an increasing
contribution to the world's energy supply mix, but still remains a long way
from reaching its full potential. In this paper, we investigate the use of
artificial evolution to design vertical-axis wind turbine prototypes that are
physically instantiated and evaluated under fan generated wind conditions.
Initially a conventional evolutionary algorithm is used to explore the design
space of a single wind turbine and later a cooperative coevolutionary algorithm
is used to explore the design space of an array of wind turbines. Artificial
neural networks are used throughout as surrogate models to assist learning and
found to reduce the number of fabrications required to reach a higher
aerodynamic efficiency. Unlike in other approaches, such as computational fluid
dynamics simulations, no mathematical formulations are used and no model
assumptions are made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3155</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3155</id><created>2013-08-14</created><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author><author><keyname>Iyer</keyname><forenames>Srikanth</forenames></author></authors><title>Percolation on the Information-Theoretically Secure Signal to
  Interference Ratio Graph</title><categories>cs.IT math.IT math.PR</categories><comments>To appear in Journal of Applied Probability</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a continuum percolation model consisting of two types of nodes,
namely legitimate and eavesdropper nodes, distributed according to independent
Poisson point processes (PPPs) in $\bbR ^2$ of intensities $\lambda$ and
$\lambda_E$ respectively. A directed edge from one legitimate node $A$ to
another legitimate node $B$ exists provided the strength of the {\it signal}
transmitted from node $A$ that is received at node $B$ is higher than that
received at any eavesdropper node. The strength of the received signal at a
node from a legitimate node depends not only on the distance between these
nodes, but also on the location of the other legitimate nodes and an
interference suppression parameter $\gamma$. The graph is said to percolate
when there exists an infinite connected component. We show that for any finite
intensity $\lambda_E$ of eavesdropper nodes, there exists a critical intensity
$\lambda_c &lt; \infty$ such that for all $\lambda &gt; \lambda_c$ the graph
percolates for sufficiently small values of the interference parameter.
Furthermore, for the sub-critical regime, we show that there exists a
$\lambda_0$ such that for all $\lambda &lt; \lambda_0 \leq \lambda_c$ a suitable
graph defined over eavesdropper node connections percolates that precludes
percolation in the graphs formed by the legitimate nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3156</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3156</id><created>2013-08-14</created><authors><author><keyname>Gupta</keyname><forenames>Kartik</forenames></author><author><keyname>Nandivada</keyname><forenames>V. Krishna</forenames></author></authors><title>Lexical State Analyzer</title><categories>cs.FL cs.PL</categories><comments>16 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lexical states provide a powerful mechanism to scan regular expressions in a
context sensitive manner. At the same time, lexical states also make it hard to
reason about the correctness of the grammar. We first categorize the related
correctness issues into two classes: errors and warnings, and then present a
context sensitive and a context insensitive analysis to identify errors and
warnings in context-free-grammars (CFGs). We also present a comparative study
of these analyses. A standalone tool (LSA) has also been implemented by us that
can identify errors and warnings in JavaCC grammars. The LSA tool outputs a
graph that depicts the grammar and the error transitions. It can also generates
counter example strings that can be used to establish the errors. We have used
LSA to analyze a host of open-source JavaCC grammar files to good effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3161</identifier>
 <datestamp>2014-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3161</id><created>2013-08-14</created><updated>2014-01-14</updated><authors><author><keyname>Harks</keyname><forenames>Tobias</forenames></author><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Schewior</keyname><forenames>Kevin</forenames></author><author><keyname>Skopalik</keyname><forenames>Alexander</forenames></author></authors><title>Routing Games with Progressive Filling</title><categories>cs.NI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Max-min fairness (MMF) is a widely known approach to a fair allocation of
bandwidth to each of the users in a network. This allocation can be computed by
uniformly raising the bandwidths of all users without violating capacity
constraints. We consider an extension of these allocations by raising the
bandwidth with arbitrary and not necessarily uniform time-depending velocities
(allocation rates). These allocations are used in a game-theoretic context for
routing choices, which we formalize in progressive filling games (PFGs).
  We present a variety of results for equilibria in PFGs. We show that these
games possess pure Nash and strong equilibria. While computation in general is
NP-hard, there are polynomial-time algorithms for prominent classes of
Max-Min-Fair Games (MMFG), including the case when all users have the same
source-destination pair. We characterize prices of anarchy and stability for
pure Nash and strong equilibria in PFGs and MMFGs when players have different
or the same source-destination pairs. In addition, we show that when a designer
can adjust allocation rates, it is possible to design games with optimal strong
equilibria. Some initial results on polynomial-time algorithms in this
direction are also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3174</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3174</id><created>2013-08-14</created><authors><author><keyname>Lubin</keyname><forenames>Benjamin</forenames></author><author><keyname>Shore</keyname><forenames>Jesse</forenames></author><author><keyname>Ishakian</keyname><forenames>Vatche</forenames></author></authors><title>Communication Network Design: Balancing Modularity and Mixing via
  Optimal Graph Spectra</title><categories>cs.SI cs.GT cs.MA</categories><msc-class>68R10, 05C35, 90C35, 94C15</msc-class><acm-class>G.2.2; G.2.3; H.1.2; H.5.3; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By leveraging information technologies, organizations now have the ability to
design their communication networks and crowdsourcing platforms to pursue
various performance goals, but existing research on network design does not
account for the specific features of social networks, such as the notion of
teams. We fill this gap by demonstrating how desirable aspects of
organizational structure can be mapped parsimoniously onto the spectrum of the
graph Laplacian allowing the specification of structural objectives and build
on recent advances in non-convex programming to optimize them. This design
framework is general, but we focus here on the problem of creating graphs that
balance high modularity and low mixing time, and show how &quot;liaisons&quot; rather
than brokers maximize this objective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3177</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3177</id><created>2013-08-14</created><authors><author><keyname>Cohen</keyname><forenames>Andrew R.</forenames><affiliation>Dept Electrical and Comput. Engin., Drexel Univ.</affiliation></author><author><keyname>Vitanyi</keyname><forenames>P. M. B.</forenames><affiliation>CWI and Comput. Sci., Univ. Amsterdam</affiliation></author></authors><title>Normalized Google Distance of Multisets with Applications</title><categories>cs.IR cs.LG</categories><comments>25 pages, LaTeX, 3 figures/tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normalized Google distance (NGD) is a relative semantic distance based on the
World Wide Web (or any other large electronic database, for instance Wikipedia)
and a search engine that returns aggregate page counts. The earlier NGD between
pairs of search terms (including phrases) is not sufficient for all
applications. We propose an NGD of finite multisets of search terms that is
better for many applications. This gives a relative semantics shared by a
multiset of search terms. We give applications and compare the results with
those obtained using the pairwise NGD. The derivation of NGD method is based on
Kolmogorov complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3181</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3181</id><created>2013-08-14</created><authors><author><keyname>Chalopin</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author><author><keyname>Chepoi</keyname><forenames>Victor</forenames></author><author><keyname>Naves</keyname><forenames>Guyslain</forenames></author></authors><title>Isometric embedding of Busemann surfaces into $L_1$</title><categories>cs.CG cs.DM math.MG</categories><acm-class>I.3.5; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we prove that any non-positively curved 2-dimensional surface
(alias, Busemann surface) is isometrically embeddable into $L_1$. As a
corollary, we obtain that all planar graphs which are 1-skeletons of planar
non-positively curved complexes with regular Euclidean polygons as cells are
$L_1$-embeddable with distortion at most $2+\pi/2&lt;4$. Our results significantly
improve and simplify the results of the recent paper {\it A. Sidiropoulos,
Non-positive curvature, and the planar embedding conjecture, FOCS 2013.}}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3182</identifier>
 <datestamp>2014-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3182</id><created>2013-08-14</created><updated>2014-03-14</updated><authors><author><keyname>Battiston</keyname><forenames>Federico</forenames></author><author><keyname>Nicosia</keyname><forenames>Vincenzo</forenames></author><author><keyname>Latora</keyname><forenames>Vito</forenames></author></authors><title>Structural measures for multiplex networks</title><categories>physics.soc-ph cs.SI</categories><comments>16 pages, 11 figures, 3 tables -- Was &quot;Metrics for the analysis of
  multiplex networks&quot; -- Final version published in Phys. Rev. E</comments><journal-ref>Phys. Rev. E 89, 032804 (2014)</journal-ref><doi>10.1103/PhysRevE.89.032804</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world complex systems consist of a set of elementary units
connected by relationships of different kinds. All such systems are better
described in terms of multiplex networks, where the links at each layer
represent a different type of interaction between the same set of nodes, rather
than in terms of (single-layer) networks. In this paper we present a general
framework to describe and study multiplex networks, whose links are either
unweighted or weighted. In particular we propose a series of measures to
characterize the multiplexicity of the systems in terms of: i) basic node and
link properties such as the node degree, and the edge overlap and
reinforcement, ii) local properties such as the clustering coefficient and the
transitivity, iii) global properties related to the navigability of the
multiplex across the different layers. The measures we introduce are validated
on a genuine multiplex data set of Indonesian terrorists, where information
among 78 individuals are recorded with respect to mutual trust, common
operations, exchanged communications and business relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3185</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3185</id><created>2013-06-04</created><updated>2014-12-28</updated><authors><author><keyname>Mastronarde</keyname><forenames>Nicholas</forenames></author><author><keyname>Patel</keyname><forenames>Viral</forenames></author><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Liu</keyname><forenames>Lingjia</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>To Relay or Not to Relay: Learning Device-to-Device Relaying Strategies
  in Cellular Networks</title><categories>cs.GT cs.MA cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a cellular network where mobile transceiver devices that are
owned by self-interested users are incentivized to cooperate with each other
using tokens, which they exchange electronically to &quot;buy&quot; and &quot;sell&quot; downlink
relay services, thereby increasing the network's capacity compared to a network
that only supports base station-to-device (B2D) communications. We investigate
how an individual device in the network can learn its optimal cooperation
policy online, which it uses to decide whether or not to provide downlink relay
services for other devices in exchange for tokens. We propose a supervised
learning algorithm that devices can deploy to learn their optimal cooperation
strategies online given their experienced network environment. We then
systematically evaluate the learning algorithm in various deployment scenarios.
Our simulation results suggest that devices have the greatest incentive to
cooperate when the network contains (i) many devices with high energy budgets
for relaying, (ii) many highly mobile users (e.g., users in motor vehicles),
and (iii) neither too few nor too many tokens. Additionally, within the token
system, self-interested devices can effectively learn to cooperate online, and
achieve over 20% higher throughput on average than with B2D communications
alone, all while selfishly maximizing their own utilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3200</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3200</id><created>2013-08-14</created><updated>2015-03-26</updated><authors><author><keyname>Cadambe</keyname><forenames>Viveck</forenames></author><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author></authors><title>An Upper Bound On the Size of Locally Recoverable Codes</title><categories>cs.IT math.IT</categories><comments>A shorter version has appeared in IEEE NetCod, 2013</comments><msc-class>94B65, 94B25, 94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a {\em locally recoverable} or {\em repairable} code, any symbol of a
codeword can be recovered by reading only a small (constant) number of other
symbols. The notion of local recoverability is important in the area of
distributed storage where a most frequent error-event is a single storage node
failure (erasure). A common objective is to repair the node by downloading data
from as few other storage node as possible. In this paper, we bound the minimum
distance of a code in terms of its length, size and locality. Unlike previous
bounds, our bound follows from a significantly simple analysis and depends on
the size of the alphabet being used. It turns out that the binary Simplex codes
satisfy our bound with equality; hence the Simplex codes are the first example
of a optimal binary locally repairable code family. We also provide
achievability results based on random coding and concatenated codes that are
numerically verified to be close to our bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3203</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3203</id><created>2013-08-14</created><authors><author><keyname>Distefano</keyname><forenames>Dino</forenames></author><author><keyname>Dubreil</keyname><forenames>Jeremy</forenames></author></authors><title>Detecting Data Races on OpenCL Kernels with Symbolic Execution</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an automatic analysis technique for checking data races on OpenCL
kernels. Our method defines symbolic execution techniques based on separation
logic with suitable abstractions to automatically detect non-benign racy
behaviours on kernel
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3217</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3217</id><created>2013-08-14</created><authors><author><keyname>Noshad</keyname><forenames>Mohammad</forenames></author><author><keyname>Brandt-Pearce</keyname><forenames>Maite</forenames></author></authors><title>Can Visible Light Communications Provide Gb/s Service?</title><categories>cs.IT math.IT</categories><comments>IEEE Communications Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communications (VLC) that use the infrastructure of the indoor
illumination system have been envisioned as a compact, safe, and green
alternative to WiFi for the downlink of an indoor wireless mobile communication
system. Although the optical spectrum is typically well-suited to high
throughput applications, combining communications with indoor lighting in a
commercially viable system imposes severe limitations both in bandwidth and
received power. Clever techniques are needed to achieve Gb/s transmission, and
to do it in a cost effective manner so as to successfully compete with other
high-capacity alternatives for indoor access, such as millimeter-wave
radio-frequency (RF). This article presents modulation schemes that have the
potential to overcome the many challenges faced by VLC in providing multi Gb/s
indoor wireless connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3225</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3225</id><created>2013-08-14</created><authors><author><keyname>Halima</keyname><forenames>M. Ben</forenames></author><author><keyname>Hamroun</keyname><forenames>M.</forenames></author><author><keyname>Moussa</keyname><forenames>S. Ben</forenames></author><author><keyname>Alimi</keyname><forenames>A. M.</forenames></author></authors><title>An interactive engine for multilingual video browsing using semantic
  content</title><categories>cs.MM cs.CV cs.IR</categories><comments>4 pages, IGS 2013 Conference; IGS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The amount of audio-visual information has increased dramatically with the
advent of High Speed Internet. Furthermore, technological advances in recent
years in the field of information technology, have simplified the use of video
data in various fields by the general public. This made it possible to store
large collections of video documents into computer systems. To enable efficient
use of these collections, it is necessary to develop tools to facilitate access
to these documents and handling them. In this paper we propose a method for
indexing and retrieval of video sequences in a video database of large
dimension, based on a weighting technique to calculate the degree of membership
of a concept in a video also a structuring of the data of the audio-visual
(context / concept / video) and a relevance feedback mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3229</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3229</id><created>2013-08-14</created><updated>2013-08-16</updated><authors><author><keyname>Nardelli</keyname><forenames>Pedro H. J.</forenames></author><author><keyname>Pomalaza-Raez</keyname><forenames>Carlos</forenames></author><author><keyname>Cardieri</keyname><forenames>Paulo</forenames></author><author><keyname>Latva-aho</keyname><forenames>Matti</forenames></author></authors><title>The Quest for Sustainable Smart Grids</title><categories>cs.SY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter is our comment about the opinion paper: Transdisciplinary
electric power grid science (PNAS, 2013 -
http://www.pnas.org/content/110/30/12159.full). [arXiv:1307.7305].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3239</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3239</id><created>2013-08-14</created><authors><author><keyname>Rossi</keyname><forenames>Pierluigi Salvo</forenames></author><author><keyname>Ciuonzo</keyname><forenames>Domenico</forenames></author><author><keyname>Romano</keyname><forenames>Gianmarco</forenames></author></authors><title>Orthogonality and Cooperation in Collaborative Spectrum Sensing through
  MIMO Decision Fusion</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Wireless Communications - accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with spectrum sensing for cognitive radio scenarios where
the decision fusion center (DFC) exploits array processing. More specifically,
we explore the impact of user cooperation and orthogonal transmissions among
secondary users (SUs) on the reporting channel. To this aim four protocols are
considered: (i) non-orthogonal and non-cooperative; (ii) orthogonal and
non-cooperative; (iii) non-orthogonal and cooperative; (iv) orthogonal and
cooperative. The DFC employs maximum ratio combining (MRC) rule and performance
are evaluated in terms of complementary receiver operating characteristic
(CROC). Analytical results, coupled with Monte Carlo simulations, are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3243</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3243</id><created>2013-08-14</created><authors><author><keyname>Halima</keyname><forenames>M. Ben</forenames></author><author><keyname>Karray</keyname><forenames>H.</forenames></author><author><keyname>Alimi</keyname><forenames>A. M.</forenames></author></authors><title>Arabic Text Recognition in Video Sequences</title><categories>cs.MM cs.CL cs.CV</categories><comments>10 pages - International Journal of Computational Linguistics
  Research. arXiv admin note: substantial text overlap with arXiv:1211.2150</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a robust approach for text extraction and
recognition from Arabic news video sequence. The text included in video
sequences is an important needful for indexing and searching system. However,
this text is difficult to detect and recognize because of the variability of
its size, their low resolution characters and the complexity of the
backgrounds. To solve these problems, we propose a system performing in two
main tasks: extraction and recognition of text. Our system is tested on a
varied database composed of different Arabic news programs and the obtained
results are encouraging and show the merits of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3247</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3247</id><created>2013-08-14</created><updated>2013-10-04</updated><authors><author><keyname>Khot</keyname><forenames>Subhash</forenames></author><author><keyname>Saket</keyname><forenames>Rishi</forenames></author></authors><title>Hardness of Finding Independent Sets in 2-Colorable and Almost
  2-Colorable Hypergraphs</title><categories>cs.CC</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the hardness of finding independent sets in hypergraphs
which are either 2-colorable or are almost 2-colorable, i.e. can be 2-colored
after removing a small fraction of vertices and the incident hyperedges. To be
precise, say that a hypergraph is (1-eps)-almost 2-colorable if removing an eps
fraction of its vertices and all hyperedges incident on them makes the
remaining hypergraph 2-colorable. In particular we prove the following results.
  For an arbitrarily small constant gamma &gt; 0, there is a constant xi &gt; 0, such
that, given a 4-uniform hypergraph on n vertices which is (1 - eps)-almost
2-colorable for eps = 2^{-(log n)^xi}, it is quasi-NP-hard to find an
independent set of n/(2^{(log n)^{1-gamma}}) vertices.
  For any constants eps, delta &gt; 0, given as input a 3-uniform hypergraph on
$n$ vertices which is (1-eps)-almost 2-colorable, it is NP-hard to find an
independent set of delta n vertices. Assuming the d-to-1 Games Conjecture the
following holds.
  For any constant delta &gt; 0, given a 2-colorable 3-uniform hypergraph on n
vertices, it is NP-hard to find an independent set of delta n vertices.
  The hardness result on independent set in almost 2-colorable 3-uniform
hypergraphs was earlier known only assuming the Unique Games Conjecture. In
this work we prove the result unconditionally. For independent sets in
2-colorable 3-uniform hypergaphs we prove the first strong hardness result,
albeit assuming the d-to-1 Games Conjecture. Our result on almost 2-colorable
4-uniform hypergraphs gives the first nearly polynomial hardness factor for
independent set in hypergraphs which are (almost) colorable with constantly
many colors. It partially bridges the gap between the previous best lower bound
of poly(log n) and the algorithmic upper bounds of n^{Omega(1)}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3258</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3258</id><created>2013-08-14</created><authors><author><keyname>Kun</keyname><forenames>Jeremy</forenames></author><author><keyname>Powers</keyname><forenames>Brian</forenames></author><author><keyname>Reyzin</keyname><forenames>Lev</forenames></author></authors><title>Anti-Coordination Games and Stable Graph Colorings</title><categories>cs.GT cs.DM</categories><comments>Appearing in SAGT 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by understanding non-strict and strict pure strategy equilibria in
network anti-coordination games, we define notions of stable and, respectively,
strictly stable colorings in graphs. We characterize the cases when such
colorings exist and when the decision problem is NP-hard. These correspond to
finding pure strategy equilibria in the anti-coordination games, whose price of
anarchy we also analyze. We further consider the directed case, a
generalization that captures both coordination and anti-coordination. We prove
the decision problem for non-strict equilibria in directed graphs is NP-hard.
Our notions also have multiple connections to other combinatorial questions,
and our results resolve some open problems in these areas, most notably the
complexity of the strictly unfriendly partition problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3272</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3272</id><created>2013-08-14</created><authors><author><keyname>Lee</keyname><forenames>Namyoon</forenames></author><author><keyname>Heath</keyname><forenames>Robert</forenames></author></authors><title>Space-Time Interference Alignment and Degrees of Freedom Regions for the
  MISO Broadcast Channel with Periodic CSI Feedback</title><categories>cs.IT math.IT</categories><comments>15 pages, 6 figures. To be appeared in IEEE Transactions on
  Information Theory</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper characterizes the degrees of freedom (DoF) regions for the
multi-user vector broadcast channel with periodic channel state information
(CSI) feedback. As a part of the characterization, a new transmission method
called space-time interference alignment is proposed, which exploits both the
current and past CSI jointly. Using the proposed alignment technique, an inner
bound of the sum-DoF region is characterized as a function of a normalized CSI
feedback frequency, which measures CSI feedback speed compared to the speed of
user's channel variations. One consequence of the result is that the achievable
sum-DoF gain is improved significantly when a user sends back both current and
outdated CSI compared to the case where the user sends back current CSI only.
Then, a trade-off between CSI feedback delay and the sum-DoF gain is
characterized for the multi-user vector broadcast channel in terms of a
normalized CSI feedback delay that measures CSI obsoleteness compared to
channel coherence time. A crucial insight is that it is possible to achieve the
optimal DoF gain if the feedback delay is less than a derived fraction of the
channel coherence time. This precisely characterizes the intuition that a small
delay should be negligible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3280</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3280</id><created>2013-08-14</created><authors><author><keyname>Nelson</keyname><forenames>Jelani</forenames></author><author><keyname>Nguyen</keyname><forenames>Huy L.</forenames></author></authors><title>Lower bounds for oblivious subspace embeddings</title><categories>cs.DM cs.CG math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An oblivious subspace embedding (OSE) for some eps, delta in (0,1/3) and d &lt;=
m &lt;= n is a distribution D over R^{m x n} such that for any linear subspace W
of R^n of dimension d,
  Pr_{Pi ~ D}(for all x in W, (1-eps) |x|_2 &lt;= |Pi x|_2 &lt;= (1+eps)|x|_2) &gt;= 1 -
delta.
  We prove that any OSE with delta &lt; 1/3 must have m = Omega((d +
log(1/delta))/eps^2), which is optimal. Furthermore, if every Pi in the support
of D is sparse, having at most s non-zero entries per column, then we show
tradeoff lower bounds between m and s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3282</identifier>
 <datestamp>2015-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3282</id><created>2013-08-14</created><updated>2015-07-27</updated><authors><author><keyname>Sokolov</keyname><forenames>Yury</forenames></author><author><keyname>Kozma</keyname><forenames>Robert</forenames></author><author><keyname>Werbos</keyname><forenames>Ludmilla D.</forenames></author><author><keyname>Werbos</keyname><forenames>Paul J.</forenames></author></authors><title>Complete stability analysis of a heuristic ADP control design</title><categories>cs.NE cs.SY</categories><comments>20 pages</comments><journal-ref>Automatica 59 (2015) 9-18</journal-ref><doi>10.1016/j.automatica.2015.06.001</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper provides new stability results for Action-Dependent Heuristic
Dynamic Programming (ADHDP), using a control algorithm that iteratively
improves an internal model of the external world in the autonomous system based
on its continuous interaction with the environment. We extend previous results
by ADHDP control to the case of general multi-layer neural networks with deep
learning across all layers. In particular, we show that the introduced control
approach is uniformly ultimately bounded (UUB) under specific conditions on the
learning rates, without explicit constraints on the temporal discount factor.
We demonstrate the benefit of our results to the control of linear and
nonlinear systems, including the cart-pole balancing problem. Our results show
significantly improved learning and control performance as compared to the
state-of-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3294</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3294</id><created>2013-08-14</created><authors><author><keyname>Kersting</keyname><forenames>Nicholas</forenames></author></authors><title>A Secure and Comparable Text Encryption Algorithm</title><categories>cs.CR cs.CL cs.CY cs.SI</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discloses a simple algorithm for encrypting text messages, based
on the NP-completeness of the subset sum problem, such that the similarity
between encryptions is roughly proportional to the semantic similarity between
their generating messages. This allows parties to compare encrypted messages
for semantic overlap without trusting an intermediary and might be applied, for
example, as a means of finding scientific collaborators over the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3297</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3297</id><created>2013-08-14</created><authors><author><keyname>Gjoka</keyname><forenames>Minas</forenames></author><author><keyname>Smith</keyname><forenames>Emily</forenames></author><author><keyname>Butts</keyname><forenames>Carter T.</forenames></author></authors><title>Estimating Clique Composition and Size Distributions from Sampled
  Network Data</title><categories>cs.SI physics.data-an physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cliques are defined as complete graphs or subgraphs; they are the strongest
form of cohesive subgroup, and are of interest in both social science and
engineering contexts. In this paper we show how to efficiently estimate the
distribution of clique sizes from a probability sample of nodes obtained from a
graph (e.g., by independence or link-trace sampling). We introduce two types of
unbiased estimators, one of which exploits labeling of sampled nodes neighbors
and one of which does not require this information. We compare the estimators
on a variety of real-world graphs and provide suggestions for their use. We
generalize our estimators to cases in which cliques are distinguished not only
by size but also by node attributes, allowing us to estimate clique composition
by size. Finally, we apply our methodology to a sample of Facebook users to
estimate the clique size distribution by gender over the social graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3300</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3300</id><created>2013-08-15</created><authors><author><keyname>Nagahara</keyname><forenames>Masaaki</forenames></author><author><keyname>Hamaguchi</keyname><forenames>Ken-ichi</forenames></author><author><keyname>Yamamoto</keyname><forenames>Yutaka</forenames></author></authors><title>Active Noise Control with Sampled-Data Filtered-x Adaptive Algorithm</title><categories>cs.IT cs.SY math.IT math.OC</categories><journal-ref>Mathematical System Theory - Festschrift in Honor of Uwe Helmke on
  the Occasion of his Sixtieth Birthday, pp. 275-290, CreateSpace, 2013. ISBN
  978-1470044008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis and design of filtered-x adaptive algorithms are conventionally done
by assuming that the transfer function in the secondary path is a discrete-time
system. However, in real systems such as active noise control, the secondary
path is a continuous-time system. Therefore, such a system should be analyzed
and designed as a hybrid system including discrete- and continuous- time
systems and AD/DA devices. In this article, we propose a hybrid design taking
account of continuous-time behavior of the secondary path via lifting
(continuous-time polyphase decomposition) technique in sampled-data control
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3301</identifier>
 <datestamp>2014-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3301</id><created>2013-08-15</created><updated>2014-06-17</updated><authors><author><keyname>Lin</keyname><forenames>Tianrong</forenames></author></authors><title>Note on equivalence of cutpoint languages recognized by measure many
  quantum finite automata</title><categories>cs.FL cs.LO</categories><comments>8 pages, improved linguistics. Suggestion for improvement are welcome</comments><acm-class>F.1.1; F.4.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This note revisits the equivalence of languages recognized by measure many
one way quantum finite automata with non/strict cutpoint. The main
contributions are as follows:
  \begin{enumerate}[(1)]
  \item {We provide an additional proof of the undecidability of non/strict
emptiness of measure many one way quantum finite automata;}
  \item {By the undecidability of non/strict emptiness of measure many one way
quantum finite automata, we show that the equivalence of languages recognized
by measure many one way quantum finite automata with non/strict cutpoint is
undecidable, implying the undecidability of containment problem of measure many
one way quantum finite automata} \end{enumerate}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3302</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3302</id><created>2013-08-15</created><authors><author><keyname>Nagahara</keyname><forenames>Masaaki</forenames></author></authors><title>YY Filter - A Paradigm of Digital Signal Processing</title><categories>cs.IT cs.SY math.IT math.OC</categories><journal-ref>Perspectives in Mathematical System Theory, Control, and Signal
  Processing, pp. 331-340, Springer, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  YY filter, named after the founder Prof. Yutaka Yamamoto, is a digital filter
designed by sampled-data control theory, which can optimize the analog
performance of the signal processing system with AD/DA converters. This article
discusses problems in conventional signal processing and introduces advantages
of the YY filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3303</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3303</id><created>2013-08-15</created><updated>2013-12-26</updated><authors><author><keyname>Zhuang</keyname><forenames>Qiutao</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author></authors><title>Upper Bounds On the ML Decoding Error Probability of General Codes over
  AWGN Channels</title><categories>cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1202.0592</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, parameterized Gallager's first bounding technique (GFBT) is
presented by introducing nested Gallager regions, to derive upper bounds on the
ML decoding error probability of general codes over AWGN channels. The three
well-known bounds, namely, the sphere bound (SB) of Herzberg and Poltyrev, the
tangential bound (TB) of Berlekamp, and the tangential-sphere bound (TSB) of
Poltyrev, are generalized to general codes without the properties of
geometrical uniformity and equal energy. When applied to the binary linear
codes, the three generalized bounds are reduced to the conventional ones. The
new derivation also reveals that the SB of Herzberg and Poltyrev is equivalent
to the SB of Kasami et al., which was rarely cited in the literatures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3309</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3309</id><created>2013-08-15</created><authors><author><keyname>Huntley</keyname><forenames>Daniel</forenames></author><author><keyname>Bulitko</keyname><forenames>Vadim</forenames></author></authors><title>Search-Space Characterization for Real-time Heuristic Search</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent real-time heuristic search algorithms have demonstrated outstanding
performance in video-game pathfinding. However, their applications have been
thus far limited to that domain. We proceed with the aim of facilitating wider
applications of real-time search by fostering a greater understanding of the
performance of recent algorithms. We first introduce eight
algorithm-independent complexity measures for search spaces and correlate their
values with algorithm performance. The complexity measures are statistically
shown to be significant predictors of algorithm performance across a set of
commercial video-game maps. We then extend this analysis to a wider variety of
search spaces in the first application of database-driven real-time search to
domains outside of video-game pathfinding. In doing so, we gain insight into
algorithm performance and possible enhancement as well as into search space
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3310</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3310</id><created>2013-08-15</created><authors><author><keyname>Ashraphijuo</keyname><forenames>Mehdi</forenames></author><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>On the Capacity and Degrees of Freedom Regions of MIMO Interference
  Channels with Limited Receiver Cooperation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Inf. Th., Aug 2013. arXiv admin note: text
  overlap with arXiv:1212.4902; and with arXiv:0911.2053 by other authors</comments><journal-ref>IEEE Transactions on Information Theory, vol.60, no.7,
  pp.4170,4196, July 2014</journal-ref><doi>10.1109/TIT.2014.2321753</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives the approximate capacity region of a two-user MIMO
interference channel with limited receiver cooperation, where the gap between
the inner and outer bounds is in terms of the total number of receive antennas
at the two receivers and is independent of the actual channel values. The
approximate capacity region is then used to find the degrees of freedom region.
For the special case of symmetric interference channels, we also find the
amount of receiver cooperation in terms of the backhaul capacity beyond which
the degrees of freedom do not improve. Further, the generalized degrees of
freedom are found for MIMO interference channels with equal number of antennas
at all nodes. It is shown that the generalized degrees of freedom improve
gradually from a &quot;W&quot; curve to a &quot;V&quot; curve with increase in cooperation in terms
of the backhaul capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3312</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3312</id><created>2013-08-15</created><authors><author><keyname>Sadeghi</keyname><forenames>Sanaz</forenames></author><author><keyname>Sadeghi</keyname><forenames>Behrouz</forenames></author></authors><title>Designing secure clustering protocol with the approach of reducing
  energy consumption in wireless sensor networks</title><categories>cs.NI</categories><journal-ref>The International Journal of Computer Networks &amp; Communications
  (IJCNC), July 2013, Volume 5. Number 4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, many researchers have focused on wireless sensor networks
and their applications. To obtain scalability potential in these networks most
of the nodes are categorized as distinct groups named cluster and the node
which is selected as cluster head or Aggregation Node offers the operation of
data collection from other cluster nodes and aggregation and sending it to the
rest of the network. Clustering and data aggregation increase network
scalability and cause that limited resources of the network are used well.
However, these mechanisms also make several breaches in the network, for
example in clustered networks cluster head nodes are considered Desirable and
attractive targets for attackers since reaching their information whether by
physical attack and node capturing or by other attacks, the attacker can obtain
the whole information of corresponding cluster. In this study secure clustering
of the nodes are considered with the approach of reducing energy consumption of
nodes and a protocol is presented that in addition to satisfying Advanced
security needs of wireless sensor networks reduces the amount of energy
consumption by the nodes. Due to network clustering there is scalability
potential in such a network and According to frequent change of cluster head
nodes load distribution is performed in the cluster and eventually increase the
network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3314</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3314</id><created>2013-08-15</created><authors><author><keyname>Brunet</keyname><forenames>Camille</forenames><affiliation>LAREMA</affiliation></author><author><keyname>Loustau</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LAREMA</affiliation></author></authors><title>The algorithm of noisy k-means</title><categories>stat.ML cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we introduce a new algorithm to deal with finite dimensional
clustering with errors in variables. The design of this algorithm is based on
recent theoretical advances (see Loustau (2013a,b)) in statistical learning
with errors in variables. As the previous mentioned papers, the algorithm mixes
different tools from the inverse problem literature and the machine learning
community. Coarsely, it is based on a two-step procedure: (1) a deconvolution
step to deal with noisy inputs and (2) Newton's iterations as the popular
k-means.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3320</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3320</id><created>2013-08-15</created><authors><author><keyname>Khatri</keyname><forenames>Sujata</forenames></author><author><keyname>Chhillar</keyname><forenames>R. S.</forenames></author><author><keyname>Singh</keyname><forenames>V. B.</forenames></author></authors><title>Improving the Testability of Object-oriented Software during Testing and
  Debugging Processes</title><categories>cs.SE</categories><comments>12; 2011</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Testability is the probability whether tests will detect a fault, given that
a fault in the program exists. How efficiently the faults will be uncovered
depends upon the testability of the software. Various researchers have proposed
qualitative and quantitative techniques to improve and measure the testability
of software. In literature, a plethora of reliability growth models have been
used to assess and measure the quantitative quality assessment of software
during testing and operational phase. The knowledge about failure distribution
and their complexity can improve the testability of software. Testing effort
allocation can be made easy by knowing the failure distribution and complexity
of faults, and this will ease the process of revealing faults from the
software. As a result, the testability of the software will be improved. The
parameters of the model along with the proportion of faults of different
complexity to be removed from the software have been presented in the paper .We
have used failure data of two object oriented software developed under open
source environment namely MySQL for python and Squirrel SQL Client for
estimation purpose
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3322</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3322</id><created>2013-08-15</created><authors><author><keyname>Davtyan</keyname><forenames>N. N.</forenames></author><author><keyname>Kamalian</keyname><forenames>R. R.</forenames></author></authors><title>Some remarks on relations between the $\mu$-parameters of regular graphs</title><categories>cs.DM</categories><comments>arXiv admin note: text overlap with arXiv:1307.1389, arXiv:1307.2348</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an undirected, simple, finite, connected graph $G$, we denote by $V(G)$
and $E(G)$ the sets of its vertices and edges, respectively. A function
$\varphi:E(G)\rightarrow \{1,...,t\}$ is called a proper edge $t$-coloring of a
graph $G$, if adjacent edges are colored differently and each of $t$ colors is
used. The least value of $t$ for which there exists a proper edge $t$-coloring
of a graph $G$ is denoted by $\chi'(G)$. For any graph $G$, and for any integer
$t$ satisfying the inequality $\chi'(G)\leq t\leq |E(G)|$, we denote by
$\alpha(G,t)$ the set of all proper edge $t$-colorings of $G$. Let us also
define a set $\alpha(G)$ of all proper edge colorings of a graph $G$: $$
\alpha(G)\equiv\bigcup_{t=\chi'(G)}^{|E(G)|}\alpha(G,t). $$
  An arbitrary nonempty finite subset of consecutive integers is called an
interval. If $\varphi\in\alpha(G)$ and $x\in V(G)$, then the set of colors of
edges of $G$ which are incident with $x$ is denoted by $S_G(x,\varphi)$ and is
called a spectrum of the vertex $x$ of the graph $G$ at the proper edge
coloring $\varphi$. If $G$ is a graph and $\varphi\in\alpha(G)$, then define
$f_G(\varphi)\equiv|\{x\in V(G)/S_G(x,\varphi) \textrm{is an interval}\}|$.
  For a graph $G$ and any integer $t$, satisfying the inequality $\chi'(G)\leq
t\leq |E(G)|$, we define: $$
\mu_1(G,t)\equiv\min_{\varphi\in\alpha(G,t)}f_G(\varphi),\qquad
\mu_2(G,t)\equiv\max_{\varphi\in\alpha(G,t)}f_G(\varphi). $$
  For any graph $G$, we set: $$ \mu_{11}(G)\equiv\min_{\chi'(G)\leq
t\leq|E(G)|}\mu_1(G,t),\qquad \mu_{12}(G)\equiv\max_{\chi'(G)\leq
t\leq|E(G)|}\mu_1(G,t), $$ $$ \mu_{21}(G)\equiv\min_{\chi'(G)\leq
t\leq|E(G)|}\mu_2(G,t),\qquad \mu_{22}(G)\equiv\max_{\chi'(G)\leq
t\leq|E(G)|}\mu_2(G,t). $$
  For regular graphs, some relations between the $\mu$-parameters are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3323</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3323</id><created>2013-08-15</created><authors><author><keyname>Yadav</keyname><forenames>Nikita</forenames></author><author><keyname>Singh</keyname><forenames>V B</forenames></author></authors><title>E-Governance: Past, Present and Future in India</title><categories>cs.CY</categories><comments>13; 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to widespread demand of E-governance and exponentially increasing size of
data, new technologies like Open source solutions and cloud computing need to
be incorporated. In this paper, the latest trends of technology that the
government of most of the country has adopted have been discussed. While
working on this project we have concluded that E-Governance has made the
working of government more efficient and more transparent to its citizens We
have also presented an exhaustive list of E-Governance projects which is
currently being used in India and in international scenario. We have provided a
mechanism for improving E-Governance by including technologies such as Open
Source and Cloud Computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3324</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3324</id><created>2013-08-15</created><authors><author><keyname>Ghaffarizadeh</keyname><forenames>Ahmadreza</forenames></author><author><keyname>Allan</keyname><forenames>Vicki H.</forenames></author></authors><title>History Based Coalition Formation in Hedonic Context Using Trust</title><categories>cs.MA cs.AI</categories><comments>8 pages</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA), Vol. 4, No. 4, July 2013</journal-ref><doi>10.5121/ijaia.2013.4401</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we address the problem of coalition formation in hedonic
context. Our modelling tries to be as realistic as possible. In previous
models, once an agent joins a coalition it would not be able to leave the
coalition and join the new one; in this research we made it possible to leave a
coalition but put some restrictions to control the behavior of agents. Leaving
or staying of an agent in a coalition will affect on the trust of the other
agents included in this coalition. Agents will use the trust values in
computing the expected utility of coalitions. Three different risk behaviors
are introduced for agents that want to initiate a coalition. Using these risk
behaviors, some simulations are made and results are analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3326</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3326</id><created>2013-08-15</created><authors><author><keyname>Zhou</keyname><forenames>Gelin</forenames></author></authors><title>Sorted Range Reporting Revisited</title><categories>cs.DS</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the two-dimensional sorted range reporting problem. Our data
structure requires O(n lglg n) words of space and O(lglg n + k lglg n) query
time, where k is the number of points in the query range. This data structure
improves a recent result of Nekrich and Navarro [8] by a factor of O(lglg n) in
query time, and matches the state of the art for unsorted range reporting [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3329</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3329</id><created>2013-08-15</created><authors><author><keyname>Bil&#xf2;</keyname><forenames>Vittorio</forenames></author></authors><title>On Linear Congestion Games with Altruistic Social Context</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the issues of existence and inefficiency of pure Nash equilibria in
linear congestion games with altruistic social context, in the spirit of the
model recently proposed by de Keijzer {\em et al.} \cite{DSAB13}. In such a
framework, given a real matrix $\Gamma=(\gamma_{ij})$ specifying a particular
social context, each player $i$ aims at optimizing a linear combination of the
payoffs of all the players in the game, where, for each player $j$, the
multiplicative coefficient is given by the value $\gamma_{ij}$. We give a broad
characterization of the social contexts for which pure Nash equilibria are
always guaranteed to exist and provide tight or almost tight bounds on their
prices of anarchy and stability. In some of the considered cases, our
achievements either improve or extend results previously known in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3336</identifier>
 <datestamp>2015-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3336</id><created>2013-08-15</created><updated>2015-06-17</updated><authors><author><keyname>&#x141;&#x105;cki</keyname><forenames>Jakub</forenames></author><author><keyname>O&#x107;wieja</keyname><forenames>Jakub</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Sankowski</keyname><forenames>Piotr</forenames></author><author><keyname>Zych</keyname><forenames>Anna</forenames></author></authors><title>The Power of Dynamic Distance Oracles: Efficient Dynamic Algorithms for
  the Steiner Tree</title><categories>cs.DS</categories><comments>Full version of the paper accepted to STOC'15</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the Steiner tree problem over a dynamic set of
terminals. We consider the model where we are given an $n$-vertex graph
$G=(V,E,w)$ with positive real edge weights, and our goal is to maintain a tree
which is a good approximation of the minimum Steiner tree spanning a terminal
set $S \subseteq V$, which changes over time. The changes applied to the
terminal set are either terminal additions (incremental scenario), terminal
removals (decremental scenario), or both (fully dynamic scenario). Our task
here is twofold. We want to support updates in sublinear $o(n)$ time, and keep
the approximation factor of the algorithm as small as possible. We show that we
can maintain a $(6+\varepsilon)$-approximate Steiner tree of a general graph in
$\tilde{O}(\sqrt{n} \log D)$ time per terminal addition or removal. Here, $D$
denotes the stretch of the metric induced by $G$. For planar graphs we achieve
the same running time and the approximation ratio of $(2+\varepsilon)$.
Moreover, we show faster algorithms for incremental and decremental scenarios.
Finally, we show that if we allow higher approximation ratio, even more
efficient algorithms are possible. In particular we show a polylogarithmic time
$(4+\varepsilon)$-approximate algorithm for planar graphs.
  One of the main building blocks of our algorithms are dynamic distance
oracles for vertex-labeled graphs, which are of independent interest. We also
improve and use the online algorithms for the Steiner tree problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3339</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3339</id><created>2013-08-15</created><updated>2016-01-19</updated><authors><author><keyname>Ibeid</keyname><forenames>Huda</forenames></author><author><keyname>Yokota</keyname><forenames>Rio</forenames></author><author><keyname>Pestana</keyname><forenames>Jennifer</forenames></author><author><keyname>Keyes</keyname><forenames>David</forenames></author></authors><title>Fast Multipole Preconditioners for Sparse Matrices Arising from Elliptic
  Equations</title><categories>cs.NA math.NA</categories><comments>17 pages, 9 figures</comments><msc-class>65F08, 65F50, 65N30, 65N55, 65N80, 65R20, 65Y05, 65Y20</msc-class><acm-class>D.1.3; G.1.2; G.1.3; G.1.8; G.1.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among optimal hierarchical algorithms for the computational solution of
elliptic problems, the Fast Multipole Method (FMM) stands out for its
adaptability to emerging architectures, having high arithmetic intensity,
tunable accuracy, and relaxable global synchronization requirements. We
demonstrate that, beyond its traditional use as a solver in problems for which
explicit free-space kernel representations are available, the FMM has
applicability as a preconditioner in finite domain elliptic boundary value
problems, by equipping it with boundary integral capability for satisfying
conditions at finite boundaries and by wrapping it in a Krylov method for
extensibility to more general operators. Here, we do not discuss the well
developed applications of FMM to implement matrix-vector multiplications within
Krylov solvers of boundary element methods. Instead, we propose using FMM for
the volume-to-volume contribution of inhomogeneous Poisson-like problems, where
the boundary integral is a small part of the overall computation. Our method
may be used to precondition sparse matrices arising from finite
difference/element discretizations, and can handle a broader range of
scientific applications. Compared with multigrid methods, it is capable of
comparable algebraic convergence rates down to the truncation error of the
discretized PDE, and it offers potentially superior multicore and distributed
memory scalability properties on commodity architecture supercomputers.
Compared with other methods exploiting the low rank character of off-diagonal
blocks of the dense resolvent operator, FMM-preconditioned Krylov iteration may
reduce the amount of communication because it is matrix-free and exploits the
tree structure of FMM. We describe our tests in reproducible detail with freely
available codes and outline directions for further extensibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3340</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3340</id><created>2013-08-15</created><authors><author><keyname>Toth</keyname><forenames>Balint</forenames></author><author><keyname>Vicsek</keyname><forenames>Tamas</forenames></author><author><keyname>Palla</keyname><forenames>Gergely</forenames></author></authors><title>Overlapping modularity at the critical point of k-clique percolation</title><categories>physics.soc-ph cs.SI</categories><comments>20 pages, 6 figures</comments><journal-ref>Journal of Statistical Physics, May 2013, Volume 151, Issue 3-4,
  pp 689-706</journal-ref><doi>10.1007/s10955-012-0640-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most remarkable social phenomena is the formation of communities
in social networks corresponding to families, friendship circles, work teams,
etc. Since people usually belong to several different communities at the same
time, the induced overlaps result in an extremely complicated web of the
communities themselves. Thus, uncovering the intricate community structure of
social networks is a non-trivial task with great potential for practical
applications, gaining a notable interest in the recent years. The Clique
Percolation Method (CPM) is one of the earliest overlapping community finding
methods, which was already used in the analysis of several different social
networks. In this approach the communities correspond to k-clique percolation
clusters, and the general heuristic for setting the parameters of the method is
to tune the system just below the critical point of k-clique percolation.
However, this rule is based on simple physical principles and its validity was
never subject to quantitative analysis. Here we examine the quality of the
partitioning in the vicinity of the critical point using recently introduced
overlapping modularity measures. According to our results on real social- and
other networks, the overlapping modularities show a maximum close to the
critical point, justifying the original criteria for the optimal parameter
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3354</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3354</id><created>2013-08-15</created><authors><author><keyname>Bonato</keyname><forenames>Anthony</forenames></author><author><keyname>Kinnersley</keyname><forenames>William B.</forenames></author><author><keyname>Gordinowicz</keyname><forenames>P.</forenames></author><author><keyname>Pralat</keyname><forenames>P.</forenames></author></authors><title>The capture time of the hypercube</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the game of Cops and Robbers, the capture time of a graph is the minimum
number of moves needed by the cops to capture the robber, assuming optimal
play. We prove that the capture time of the $n$-dimensional hypercube is
$\Theta (n\ln n).$ Our methods include a novel randomized strategy for the
players, which involves the analysis of the coupon-collector problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3357</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3357</id><created>2013-08-15</created><authors><author><keyname>Charlaganov</keyname><forenames>Marat</forenames></author><author><keyname>Cudr&#xe9;-Mauroux</keyname><forenames>Philippe</forenames></author><author><keyname>Dinu</keyname><forenames>Cristian</forenames></author><author><keyname>Gu&#xe9;ret</keyname><forenames>Christophe</forenames></author><author><keyname>Grund</keyname><forenames>Martin</forenames></author><author><keyname>Macicas</keyname><forenames>Teodor</forenames></author></authors><title>The Entity Registry System: Implementing 5-Star Linked Data Without the
  Web</title><categories>cs.DB cs.CY</categories><comments>16 pages, authors are listed in alphabetical order</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linked Data applications often assume that connectivity to data repositories
and entity resolution services are always available. This may not be a valid
assumption in many cases. Indeed, there are about 4.5 billion people in the
world who have no or limited Web access. Many data-driven applications may have
a critical impact on the life of those people, but are inaccessible to those
populations due to the architecture of today's data registries. In this paper,
we propose and evaluate a new open-source system that can be used as a
general-purpose entity registry suitable for deployment in poorly-connected or
ad-hoc environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3370</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3370</id><created>2013-08-15</created><authors><author><keyname>Mchedlidze</keyname><forenames>Tamara</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author></authors><title>Drawing Planar Graphs with a Prescribed Inner Face</title><categories>cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a plane graph $G$ (i.e., a planar graph with a fixed planar embedding)
and a simple cycle $C$ in $G$ whose vertices are mapped to a convex polygon, we
consider the question whether this drawing can be extended to a planar
straight-line drawing of $G$. We characterize when this is possible in terms of
simple necessary conditions, which we prove to be sufficient. This also leads
to a linear-time testing algorithm. If a drawing extension exists, it can be
computed in the same running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3372</identifier>
 <datestamp>2014-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3372</id><created>2013-08-15</created><updated>2014-04-03</updated><authors><author><keyname>Jianfeng</keyname><forenames>Xu</forenames></author><author><keyname>Jun</keyname><forenames>Tang</forenames></author><author><keyname>Xuefeng</keyname><forenames>Ma</forenames></author><author><keyname>Bin</keyname><forenames>Xu</forenames></author><author><keyname>Yanli</keyname><forenames>Shen</forenames></author><author><keyname>Yongjie</keyname><forenames>Qiao</forenames></author></authors><title>Objective Information Theory: A Sextuple Model and 9 Kinds of Metrics</title><categories>cs.IT math.IT</categories><comments>20 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the contemporary era, the importance of information is undisputed, but
there has never been a common understanding of information, nor a unanimous
conclusion to the researches on information metrics. Based on the previous
studies, this paper analyzes the important achievements in the researches of
the properties and metrics of information as well as their main
insufficiencies, and explores the essence and connotation, the mathematical
expressions and other basic problems related to information. On the basis of
the understanding of the objectivity of information, it proposes the
definitions and a Sextuple model of information; discusses the basic properties
of information, and brings forward the definitions and mathematical expressions
of nine kinds of metrics of information, i.e., extensity, detailedness,
sustainability, containability, delay, richness, distribution, validity and
matchability. Through these, this paper establishes a basic theory frame of
Objective Information Theory to support the analysis and research on
information and information system systematically and comprehensively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3374</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3374</id><created>2013-08-15</created><authors><author><keyname>Zachariah</keyname><forenames>Dave</forenames></author><author><keyname>Jansson</keyname><forenames>Magnus</forenames></author><author><keyname>Bengtsson</keyname><forenames>Mats</forenames></author></authors><title>Utilization of Noise-Only Samples in Array Processing With Prior
  Knowledge</title><categories>math.ST cs.IT math.IT stat.TH</categories><journal-ref>IEEE Signal Processing Letters, Sept. 2013, Vol. 20, No. 9, pages
  865-868</journal-ref><doi>10.1109/LSP.2013.2271515</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For array processing, we consider the problem of estimating signals of
interest, and their directions of arrival (DOA), in unknown colored noise
fields. We develop an estimator that efficiently utilizes a set of noise-only
samples and, further, can incorporate prior knowledge of the DOAs with varying
degrees of certainty. The estimator is compared with state of the art
estimators that utilize noise-only samples, and the Cram\'{e}r-Rao bound,
exhibiting improved performance for smaller sample sets and in poor signal
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3381</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3381</id><created>2013-08-15</created><updated>2013-10-05</updated><authors><author><keyname>Lotsi</keyname><forenames>Anani</forenames></author><author><keyname>Wit</keyname><forenames>Ernst</forenames></author></authors><title>High dimensional Sparse Gaussian Graphical Mixture Model</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of networks reconstruction from
heterogeneous data using a Gaussian Graphical Mixture Model (GGMM). It is well
known that parameter estimation in this context is challenging due to large
numbers of variables coupled with the degeneracy of the likelihood. We propose
as a solution a penalized maximum likelihood technique by imposing an $l_{1}$
penalty on the precision matrix. Our approach shrinks the parameters thereby
resulting in better identifiability and variable selection. We use the
Expectation Maximization (EM) algorithm which involves the graphical LASSO to
estimate the mixing coefficients and the precision matrices. We show that under
certain regularity conditions the Penalized Maximum Likelihood (PML) estimates
are consistent. We demonstrate the performance of the PML estimator through
simulations and we show the utility of our method for high dimensional data
analysis in a genomic application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3383</identifier>
 <datestamp>2014-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3383</id><created>2013-08-15</created><updated>2014-07-22</updated><authors><author><keyname>van Laarhoven</keyname><forenames>Twan</forenames></author><author><keyname>Marchiori</keyname><forenames>Elena</forenames></author></authors><title>Axioms for graph clustering quality functions</title><categories>cs.CV cs.LG stat.ML</categories><comments>23 pages. Full text and sources available on:
  http://www.cs.ru.nl/~T.vanLaarhoven/graph-clustering-axioms-2014/</comments><journal-ref>Journal of Machine Learning Research, 15(Jan):193-215, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate properties that intuitively ought to be satisfied by graph
clustering quality functions, that is, functions that assign a score to a
clustering of a graph. Graph clustering, also known as network community
detection, is often performed by optimizing such a function. Two axioms
tailored for graph clustering quality functions are introduced, and the four
axioms introduced in previous work on distance based clustering are
reformulated and generalized for the graph setting. We show that modularity, a
standard quality function for graph clustering, does not satisfy all of these
six properties. This motivates the derivation of a new family of quality
functions, adaptive scale modularity, which does satisfy the proposed axioms.
Adaptive scale modularity has two parameters, which give greater flexibility in
the kinds of clusterings that can be found. Standard graph clustering quality
functions, such as normalized cut and unnormalized cut, are obtained as special
cases of adaptive scale modularity.
  In general, the results of our investigation indicate that the considered
axiomatic framework covers existing `good' quality functions for graph
clustering, and can be used to derive an interesting new family of quality
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3384</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3384</id><created>2013-08-15</created><authors><author><keyname>Femminella</keyname><forenames>Mauro</forenames></author><author><keyname>Reali</keyname><forenames>Gianluca</forenames></author></authors><title>Consistency Analysis of Sensor Data Distribution</title><categories>cs.NI</categories><comments>IEEE IWCMC 2013, Cagliari, Italy, June 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyze the probability of consistency of sensor data
distribution systems (SDDS), and determine suitable evaluation models. This
problem is typically difficult, since a reliable model taking into account all
parameters and processes which affect the system consistency is unavoidably
very complex. The simplest candidate approach consists of modeling the state
sojourn time, or holding time, as memoryless, and resorting to the well known
solutions of Markovian processes. Nevertheless, it may happen that this
approach does not fit with some working conditions. In particular, the correct
modeling of the SDDS dynamics requires the introduction of a number of
parameters, such as the packet transfer time or the packet loss probability,
the value of which may determine the suitability of unsuitability of the
Markovian model. Candidate alternative solutions include the Erlang phase-type
approximation of nearly constant state holding time and a more refined model to
account for overlapping events in semi-Markov processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3388</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3388</id><created>2013-08-15</created><authors><author><keyname>Bonato</keyname><forenames>Anthony</forenames></author><author><keyname>Hadi</keyname><forenames>Noor</forenames></author><author><keyname>Horn</keyname><forenames>Paul</forenames></author><author><keyname>Pralat</keyname><forenames>Pawel</forenames></author><author><keyname>Wang</keyname><forenames>Changping</forenames></author></authors><title>Models of on-line social networks</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deterministic model for on-line social networks (OSNs) based on
transitivity and local knowledge in social interactions. In the Iterated Local
Transitivity (ILT) model, at each time-step and for every existing node $x$, a
new node appears which joins to the closed neighbour set of $x.$ The ILT model
provably satisfies a number of both local and global properties that were
observed in OSNs and other real-world complex networks, such as a densification
power law, decreasing average distance, and higher clustering than in random
graphs with the same average degree. Experimental studies of social networks
demonstrate poor expansion properties as a consequence of the existence of
communities with low number of inter-community edges. Bounds on the spectral
gap for both the adjacency and normalized Laplacian matrices are proved for
graphs arising from the ILT model, indicating such bad expansion properties.
The cop and domination number are shown to remain the same as the graph from
the initial time-step $G_0$, and the automorphism group of $G_0$ is a subgroup
of the automorphism group of graphs generated at all later time-steps. A
randomized version of the ILT model is presented, which exhibits a tuneable
densification power law exponent, and maintains several properties of the
deterministic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3400</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3400</id><created>2013-08-14</created><authors><author><keyname>Sayama</keyname><forenames>Hiroki</forenames></author></authors><title>Guiding Designs of Self-Organizing Swarms: Interactive and Automated
  Approaches</title><categories>cs.NE nlin.AO</categories><comments>23 pages, 16 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-organization of heterogeneous particle swarms is rich in its dynamics
but hard to design in a traditional top-down manner, especially when many types
of kinetically distinct particles are involved. In this chapter, we discuss how
we have been addressing this problem by (1) utilizing and enhancing interactive
evolutionary design methods and (2) realizing spontaneous evolution of self
organizing swarms within an artificial ecosystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3405</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3405</id><created>2013-08-15</created><authors><author><keyname>Poloczek</keyname><forenames>Matthias</forenames></author><author><keyname>Williamson</keyname><forenames>David P.</forenames></author><author><keyname>van Zuylen</keyname><forenames>Anke</forenames></author></authors><title>On Some Recent MAX SAT Approximation Algorithms</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently a number of randomized 3/4-approximation algorithms for MAX SAT have
been proposed that all work in the same way: given a fixed ordering of the
variables, the algorithm makes a random assignment to each variable in
sequence, in which the probability of assigning each variable true or false
depends on the current set of satisfied (or unsatisfied) clauses. To our
knowledge, the first such algorithm was proposed by Poloczek and Schnitger; Van
Zuylen subsequently gave an algorithm that set the probabilities differently
and had a simpler analysis. She also set up a framework for deriving such
algorithms. Buchbinder, Feldman, Naor, and Schwartz, as a special case of their
work on maximizing submodular functions, also give a randomized
3/4-approximation algorithm for MAX SAT with the same structure as these
previous algorithms. In this note we give a gloss on the Buchbinder et al.
algorithm that makes it even simpler, and show that in fact it is equivalent to
the previous algorithm of Van Zuylen. We also show how it extends to a
deterministic LP rounding algorithm; such an algorithm was also given by Van
Zuylen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3420</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3420</id><created>2013-08-12</created><updated>2013-10-06</updated><authors><author><keyname>Aboufadel</keyname><forenames>Edward</forenames></author><author><keyname>Krawczyk</keyname><forenames>Sylvanna V.</forenames></author><author><keyname>Sherman-Bennett</keyname><forenames>Melissa</forenames></author></authors><title>3D Printing for Math Professors and Their Students</title><categories>math.HO cs.OH</categories><comments>18 pages, 6 figures. Version 1.1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this primer, we will describe a number of projects that can be completed
with a 3D printer, particularly by mathematics professors and their students.
For many of the projects, we will utilize Mathematica to design objects that
mathematicians may be interested in printing. Included in the projects that are
described is a method to acquire data from an XBox Kinect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3432</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3432</id><created>2013-08-15</created><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>L&#xe9;onard</keyname><forenames>Nicholas</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author></authors><title>Estimating or Propagating Gradients Through Stochastic Neurons for
  Conditional Computation</title><categories>cs.LG</categories><comments>arXiv admin note: substantial text overlap with arXiv:1305.2982</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic neurons and hard non-linearities can be useful for a number of
reasons in deep learning models, but in many cases they pose a challenging
problem: how to estimate the gradient of a loss function with respect to the
input of such stochastic or non-smooth neurons? I.e., can we &quot;back-propagate&quot;
through these stochastic neurons? We examine this question, existing
approaches, and compare four families of solutions, applicable in different
settings. One of them is the minimum variance unbiased gradient estimator for
stochatic binary neurons (a special case of the REINFORCE algorithm). A second
approach, introduced here, decomposes the operation of a binary stochastic
neuron into a stochastic binary part and a smooth differentiable part, which
approximates the expected effect of the pure stochatic binary neuron to first
order. A third approach involves the injection of additive or multiplicative
noise in a computational graph that is otherwise differentiable. A fourth
approach heuristically copies the gradient with respect to the stochastic
output directly as an estimator of the gradient with respect to the sigmoid
argument (we call this the straight-through estimator). To explore a context
where these estimators are useful, we consider a small-scale version of {\em
conditional computation}, where sparse stochastic units form a distributed
representation of gaters that can turn off in combinatorially many ways large
chunks of the computation performed in the rest of the neural network. In this
case, it is important that the gating units produce an actual 0 most of the
time. The resulting sparsity can be potentially be exploited to greatly reduce
the computational cost of large deep networks for which conditional computation
would be useful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3438</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3438</id><created>2013-08-15</created><updated>2013-09-18</updated><authors><author><keyname>He</keyname><forenames>Dongxiao</forenames></author><author><keyname>Jin</keyname><forenames>Di</forenames></author><author><keyname>Zhang</keyname><forenames>Weixiong</forenames></author></authors><title>Identification of hybrid node and link communities in complex networks</title><categories>cs.SI physics.soc-ph</categories><comments>22 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:1105.0257 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification of communities in complex networks has become an effective
means to analysis of complex systems. It has broad applications in diverse
areas such as social science, engineering, biology and medicine. Finding
communities of nodes and finding communities of links are two popular schemes
for network structure analysis. These schemes, however, have inherent drawbacks
and are often inadequate to properly capture complex organizational structures
in real networks. We introduce a new scheme and effective approach for
identifying complex network structures using a mixture of node and link
communities, called hybrid node-link communities. A central piece of our
approach is a probabilistic model that accommodates node, link and hybrid
node-link communities. Our extensive experiments on various real-world
networks, including a large protein-protein interaction network and a large
semantic association network of commonly used words, illustrated that the
scheme for hybrid communities is superior in revealing network characteristics.
Moreover, the new approach outperformed the existing methods for finding node
or link communities separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3466</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3466</id><created>2013-08-15</created><updated>2016-01-28</updated><authors><author><keyname>Berenbrink</keyname><forenames>Petra</forenames></author><author><keyname>Erg&#xfc;n</keyname><forenames>Funda</forenames></author><author><keyname>Mallmann-Trenn</keyname><forenames>Frederik</forenames></author><author><keyname>Azer</keyname><forenames>Erfan Sadeqi</forenames></author></authors><title>Palindrome Recognition In The Streaming Model</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Palindrome Problem one tries to find all palindromes (palindromic
substrings) in a given string. A palindrome is defined as a string which reads
forwards the same as backwards, e.g., the string &quot;racecar&quot;. A related problem
is the Longest Palindromic Substring Problem in which finding an arbitrary one
of the longest palindromes in the given string suffices. We regard the
streaming version of both problems. In the streaming model the input arrives
over time and at every point in time we are only allowed to use sublinear
space. The main algorithms in this paper are the following: The first one is a
one-pass randomized algorithm that solves the Palindrome Problem. It has an
additive error and uses $O(\sqrt n$) space. The second algorithm is a two-pass
algorithm which determines the exact locations of all longest palindromes. It
uses the first algorithm as the first pass. The third algorithm is again a
one-pass randomized algorithm, which solves the Longest Palindromic Substring
Problem. It has a multiplicative error using only $O(\log(n))$ space. We also
give two variants of the first algorithm which solve other related practical
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3472</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3472</id><created>2013-08-15</created><authors><author><keyname>Popescu</keyname><forenames>Andrei</forenames></author></authors><title>Security Type Systems as Recursive Predicates</title><categories>cs.CR cs.PL</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how security type systems from the literature of language-based
noninterference can be represented more directly as predicates defined by
structural recursion on the programs. In this context, we show how our uniform
syntactic criteria from previous work cover several previous type-system
soundness results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3481</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3481</id><created>2013-08-15</created><authors><author><keyname>Mitra</keyname><forenames>Pinaki</forenames></author><author><keyname>Sundaram</keyname><forenames>Girish</forenames></author><author><keyname>Mallick</keyname><forenames>Swarup Kumar</forenames></author></authors><title>Application Behavior Enforcement Based On Network Characteristics</title><categories>cs.NI</categories><comments>Selected for proceedings of NETs2012 International Conference on
  Internet Studies held in Bangkok, Thailand from August 17-19, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every device defines the behavior of various applications running on it with
the help of user profiles or settings. What if a user wants different different
applications to run in different different networks. Then he cannot do this
because in todays existing operating systems the application profile, user
specific tool settings and any such system usage settings do not consider the
current network characteristics of the user or system and are therefore static
in nature.Therefore there is a need for an intelligent system which will
dynamically change or apply changes to the settings of various applications
running on the system considering the current network characteristics based on
user specifications. This paper presents an idea such that a user can set
different different applications in different different networks.This paper
presents how the user will get pop up messages when he visits to safe web
sites. And according to the users current network status he will get a pop up
message when he will go for download or stream audio or video files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3482</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3482</id><created>2013-08-15</created><authors><author><keyname>Mitra</keyname><forenames>Pinaki</forenames></author><author><keyname>Das</keyname><forenames>Rinku</forenames></author><author><keyname>Sundaram</keyname><forenames>Girish</forenames></author></authors><title>Privatizing user credential information of Web services in a shared user
  environment</title><categories>cs.CR</categories><comments>Selected for proceedings of NETs2012 International Conference on
  Internet Studies held in Bangkok, Thailand from August 17-19, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User credentials security is one of the most important tasks in Web World.
Most Web sites on the Internet that support user accounts store the users
credentials in a database. Now a days, most of the web browsers offer auto
login feature for the favorite web sites such as yahoo, google, gmail etc.
using these credential information. This facilitates the misuse of user
credentials. Privatizing user credential information of web services in a
shared user environment provides a feature enhancement where the root user will
be able to privatize his stored credentials by enforcing some masking
techniques such that even a user logs on to the system with root user
credentials, he will not be able to access privatized data. In case of web
browsers auto login feature, a root user can disable the feature manually by
deleting entries from web browsers' saved password list. But this involves
spending a considerable amount of time and the biggest problem is that he has
to insert those credentials once again when he next visits these websites. This
application resumes auto login feature whenever root user disable the masked
mode. The application includes two parts: Masked Application Mode and Disabling
the Masked Application Mode. When the system goes for masked application mode,
the other user will not be able to use the credentials of the root user.If the
other user tries to access any of the web pages which have been masked, the
other user will have to authenticate with his own credentials. Disabling the
masked mode requires authentication from the root user. As long as this
credential is not shared, masked mode can be disabled only by the root user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3485</identifier>
 <datestamp>2013-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3485</id><created>2013-08-15</created><authors><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Information sharing promotes prosocial behaviour</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>14 pages, 7 figures; accepted for publication in New Journal of
  Physics</comments><journal-ref>New J. Phys. 15 (2013) 053010</journal-ref><doi>10.1088/1367-2630/15/5/053010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More often than not, bad decisions are bad regardless of where and when they
are made. Information sharing might thus be utilized to mitigate them. Here we
show that sharing the information about strategy choice between players
residing on two different networks reinforces the evolution of cooperation. In
evolutionary games the strategy reflects the action of each individual that
warrants the highest utility in a competitive setting. We therefore assume that
identical strategies on the two networks reinforce themselves by lessening
their propensity to change. Besides network reciprocity working in favour of
cooperation on each individual network, we observe the spontaneous emerge of
correlated behaviour between the two networks, which further deters defection.
If information is shared not just between individuals but also between groups,
the positive effect is even stronger, and this despite the fact that
information sharing is implemented without any assumptions with regards to
content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3489</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3489</id><created>2013-08-15</created><authors><author><keyname>Asghar</keyname><forenames>Muhammad Rizwan</forenames></author><author><keyname>Ion</keyname><forenames>Mihaela</forenames></author><author><keyname>Russello</keyname><forenames>Giovanni</forenames></author><author><keyname>Crispo</keyname><forenames>Bruno</forenames></author></authors><title>ESPOON$_{{ERBAC}}$: Enforcing Security Policies In Outsourced
  Environments</title><categories>cs.CR</categories><comments>The final version of this paper has been accepted for publication in
  Elsevier Computers &amp; Security 2013. arXiv admin note: text overlap with
  arXiv:1306.4828</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data outsourcing is a growing business model offering services to individuals
and enterprises for processing and storing a huge amount of data. It is not
only economical but also promises higher availability, scalability, and more
effective quality of service than in-house solutions. Despite all its benefits,
data outsourcing raises serious security concerns for preserving data
confidentiality. There are solutions for preserving confidentiality of data
while supporting search on the data stored in outsourced environments. However,
such solutions do not support access policies to regulate access to a
particular subset of the stored data.
  For complex user management, large enterprises employ Role-Based Access
Controls (RBAC) models for making access decisions based on the role in which a
user is active in. However, RBAC models cannot be deployed in outsourced
environments as they rely on trusted infrastructure in order to regulate access
to the data. The deployment of RBAC models may reveal private information about
sensitive data they aim to protect. In this paper, we aim at filling this gap
by proposing \textbf{$\mathit{ESPOON_{ERBAC}}$} for enforcing RBAC policies in
outsourced environments. $\mathit{ESPOON_{ERBAC}}$ enforces RBAC policies in an
encrypted manner where a curious service provider may learn a very limited
information about RBAC policies. We have implemented $\mathit{ESPOON_{ERBAC}}$
and provided its performance evaluation showing a limited overhead, thus
confirming viability of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3493</identifier>
 <datestamp>2014-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3493</id><created>2013-08-15</created><authors><author><keyname>Nutma</keyname><forenames>Teake</forenames></author></authors><title>xTras: a field-theory inspired xAct package for Mathematica</title><categories>cs.SC cs.MS gr-qc hep-th</categories><comments>29 pages. The package can be downloaded from
  http://www.xact.es/xtras/</comments><report-no>AEI-2013-236</report-no><journal-ref>Comput. Phys. Commun. 185 (2014) 1719-1738</journal-ref><doi>10.1016/j.cpc.2014.02.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the tensor computer algebra package xTras, which provides
functions and methods frequently needed when doing (classical) field theory.
Amongst others, it can compute contractions, make Ans\&quot;atze, and solve
tensorial equations. It is built upon the tensor computer algebra system xAct,
a collection of packages for Mathematica.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3506</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3506</id><created>2013-08-15</created><authors><author><keyname>Waugh</keyname><forenames>Kevin</forenames></author><author><keyname>Ziebart</keyname><forenames>Brian D.</forenames></author><author><keyname>Bagnell</keyname><forenames>J. Andrew</forenames></author></authors><title>Computational Rationalization: The Inverse Equilibrium Problem</title><categories>cs.GT cs.LG stat.ML</categories><comments>In submission to JMLR, conference version: arXiv:1103.5254</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling the purposeful behavior of imperfect agents from a small number of
observations is a challenging task. When restricted to the single-agent
decision-theoretic setting, inverse optimal control techniques assume that
observed behavior is an approximately optimal solution to an unknown decision
problem. These techniques learn a utility function that explains the example
behavior and can then be used to accurately predict or imitate future behavior
in similar observed or unobserved situations.
  In this work, we consider similar tasks in competitive and cooperative
multi-agent domains. Here, unlike single-agent settings, a player cannot
myopically maximize its reward; it must speculate on how the other agents may
act to influence the game's outcome. Employing the game-theoretic notion of
regret and the principle of maximum entropy, we introduce a technique for
predicting and generalizing behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3508</identifier>
 <datestamp>2014-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3508</id><created>2013-08-15</created><updated>2014-10-01</updated><authors><author><keyname>Sobolevsky</keyname><forenames>Stanislav</forenames></author><author><keyname>Campari</keyname><forenames>Riccardo</forenames></author><author><keyname>Belyi</keyname><forenames>Alexander</forenames></author><author><keyname>Ratti</keyname><forenames>Carlo</forenames></author></authors><title>A General Optimization Technique for High Quality Community Detection in
  Complex Networks</title><categories>cs.SI physics.soc-ph</categories><comments>MAIN text: 14 pages, 4 figures, 1 table Supplementary information: 19
  pages, 8 figures, 5 tables</comments><msc-class>05C82, 91D30, 92C42, 05C85</msc-class><acm-class>G.2.2; I.5.3</acm-class><journal-ref>Phys. Rev. E 90, 012811 (2014)</journal-ref><doi>10.1103/PhysRevE.90.012811</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed the development of a large body of algorithms for
community detection in complex networks. Most of them are based upon the
optimization of objective functions, among which modularity is the most common,
though a number of alternatives have been suggested in the scientific
literature. We present here an effective general search strategy for the
optimization of various objective functions for community detection purposes.
When applied to modularity, on both real-world and synthetic networks, our
search strategy substantially outperforms the best existing algorithms in terms
of final scores of the objective function; for description length, its
performance is on par with the original Infomap algorithm. The execution time
of our algorithm is on par with non-greedy alternatives present in literature,
and networks of up to 10,000 nodes can be analyzed in time spans ranging from
minutes to a few hours on average workstations, making our approach readily
applicable to tasks which require the quality of partitioning to be as high as
possible, and are not limited by strict time constraints. Finally, based on the
most effective of the available optimization techniques, we compare the
performance of modularity and code length as objective functions, in terms of
the quality of the partitions one can achieve by optimizing them. To this end,
we evaluated the ability of each objective function to reconstruct the
underlying structure of a large set of synthetic and real-world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3509</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3509</id><created>2013-08-15</created><authors><author><keyname>Cotter</keyname><forenames>Andrew</forenames></author></authors><title>Stochastic Optimization for Machine Learning</title><categories>cs.LG</categories><comments>PhD Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been found that stochastic algorithms often find good solutions much
more rapidly than inherently-batch approaches. Indeed, a very useful rule of
thumb is that often, when solving a machine learning problem, an iterative
technique which relies on performing a very large number of
relatively-inexpensive updates will often outperform one which performs a
smaller number of much &quot;smarter&quot; but computationally-expensive updates.
  In this thesis, we will consider the application of stochastic algorithms to
two of the most important machine learning problems. Part i is concerned with
the supervised problem of binary classification using kernelized linear
classifiers, for which the data have labels belonging to exactly two classes
(e.g. &quot;has cancer&quot; or &quot;doesn't have cancer&quot;), and the learning problem is to
find a linear classifier which is best at predicting the label. In Part ii, we
will consider the unsupervised problem of Principal Component Analysis, for
which the learning task is to find the directions which contain most of the
variance of the data distribution.
  Our goal is to present stochastic algorithms for both problems which are,
above all, practical--they work well on real-world data, in some cases better
than all known competing algorithms. A secondary, but still very important,
goal is to derive theoretical bounds on the performance of these algorithms
which are at least competitive with, and often better than, those known for
other approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3513</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3513</id><created>2013-08-15</created><authors><author><keyname>Doshi-Velez</keyname><forenames>Finale</forenames></author><author><keyname>Konidaris</keyname><forenames>George</forenames></author></authors><title>Hidden Parameter Markov Decision Processes: A Semiparametric Regression
  Approach for Discovering Latent Task Parametrizations</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Control applications often feature tasks with similar, but not identical,
dynamics. We introduce the Hidden Parameter Markov Decision Process (HiP-MDP),
a framework that parametrizes a family of related dynamical systems with a
low-dimensional set of latent factors, and introduce a semiparametric
regression approach for learning its structure from data. In the control
setting, we show that a learned HiP-MDP rapidly identifies the dynamics of a
new task instance, allowing an agent to flexibly adapt to task variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3520</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3520</id><created>2013-08-15</created><authors><author><keyname>Chitnis</keyname><forenames>Rajesh</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Kortsarz</keyname><forenames>Guy</forenames></author></authors><title>Fixed-Parameter and Approximation Algorithms: A New Look</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Fixed-Parameter Tractable (\FPT) $\rho$-approximation algorithm for a
minimization (resp. maximization) parameterized problem $P$ is an FPT algorithm
that, given an instance $(x, k)\in P$ computes a solution of cost at most $k
\cdot \rho(k)$ (resp. $k/\rho(k)$) if a solution of cost at most (resp. at
least) $k$ exists; otherwise the output can be arbitrary. For well-known
intractable problems such as the W[1]-hard {Clique} and W[2]-hard {Set Cover}
problems, the natural question is whether we can get any \FPT-approximation. It
is widely believed that both {Clique} and {Set-Cover} admit no FPT
$\rho$-approximation algorithm, for any increasing function $\rho$. Assuming
standard conjectures such as the Exponential Time Hypothesis (ETH)
\cite{eth-paturi} and the Projection Games Conjecture (PGC) \cite{r3}, we make
the first progress towards proving this conjecture by showing that
  1. Under the ETH and PGC, there exist constants $F_1, F_2 &gt;0$ such that the
{Set Cover} problem does not admit an FPT approximation algorithm with ratio
$k^{F_1}$ in $2^{k^{F_2}}\cdot \text{poly}(N,M)$ time, where $N$ is the size of
the universe and $M$ is the number of sets.
  2. Unless $\NP\subseteq \SUBEXP$, for every $1&gt; \delta &gt; 0$ there exists a
constant $F(\delta)&gt;0$ such that {Clique} has no FPT cost approximation with
ratio $k^{1-\delta}$ in $2^{k^{F}}\cdot \text{poly}(n)$ time, where $n$ is the
number of vertices in the graph.
  In the second part of the paper we consider various W[1]-hard problems such
as {\dst}, {\dsf}, Directed Steiner Network and {\mec}. For all these problem
we give polynomial time $f(\text{OPT})$-approximation algorithms for some small
function $f$ (the largest approximation ratio we give is $\text{OPT}^2$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3521</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3521</id><created>2013-08-15</created><updated>2013-09-20</updated><authors><author><keyname>Alvarado</keyname><forenames>Alberth</forenames></author><author><keyname>Scutari</keyname><forenames>Gesualdo</forenames></author><author><keyname>Pang</keyname><forenames>Jong-Shi</forenames></author></authors><title>A New Distributed DC-Programming Method and its Applications</title><categories>cs.IT math.IT math.OC</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel decomposition framework for the distributed optimization
of Difference Convex (DC)-type nonseparable sum-utility functions subject to
coupling convex constraints. A major contribution of the paper is to develop
for the first time a class of (inexact) best-response-like algorithms with
provable convergence, where a suitably convexified version of the original DC
program is iteratively solved. The main feature of the proposed successive
convex approximation method is its decomposability structure across the users,
which leads naturally to distributed algorithms in the primal and/or dual
domain. The proposed framework is applicable to a variety of multiuser DC
problems in different areas, ranging from signal processing, to communications
and networking. As a case study, in the second part of the paper we focus on
two examples, namely: i) a novel resource allocation problem in the emerging
area of cooperative physical layer security; ii) and the renowned sum-rate
maximization of MIMO Cognitive Radio networks. Our contribution in this context
is to devise a class of easy-to-implement distributed algorithms with provable
convergence to stationary solution of such problems. Numerical results show
that the proposed distributed schemes reach performance close to (and sometimes
better than) that of centralized methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3524</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3524</id><created>2013-08-15</created><authors><author><keyname>Capizzi</keyname><forenames>Giacomo</forenames></author><author><keyname>Napoli</keyname><forenames>Christian</forenames></author><author><keyname>Bonanno</keyname><forenames>Francesco</forenames></author></authors><title>Innovative Second-Generation Wavelets Construction With Recurrent Neural
  Networks for Solar Radiation Forecasting</title><categories>cs.NE</categories><journal-ref>IEEE Trans. Neural Networks and Learning Systems, vol. 23, N. 11,
  pp. 1805-1815, 2012</journal-ref><doi>10.1109/TNNLS.2012.2216546</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solar radiation prediction is an important challenge for the electrical
engineer because it is used to estimate the power developed by commercial
photovoltaic modules. This paper deals with the problem of solar radiation
prediction based on observed meteorological data. A 2-day forecast is obtained
by using novel wavelet recurrent neural networks (WRNNs). In fact, these WRNNS
are used to exploit the correlation between solar radiation and
timescale-related variations of wind speed, humidity, and temperature. The
input to the selected WRNN is provided by timescale-related bands of wavelet
coefficients obtained from meteorological time series. The experimental setup
available at the University of Catania, Italy, provided this information. The
novelty of this approach is that the proposed WRNN performs the prediction in
the wavelet domain and, in addition, also performs the inverse wavelet
transform, giving the predicted signal as output. The obtained simulation
results show a very low root-mean-square error compared to the results of the
solar radiation prediction approaches obtained by hybrid neural networks
reported in the recent literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3536</identifier>
 <datestamp>2016-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3536</id><created>2013-08-15</created><updated>2014-01-24</updated><authors><author><keyname>Adams</keyname><forenames>Henry</forenames></author><author><keyname>Carlsson</keyname><forenames>Gunnar</forenames></author></authors><title>Evasion Paths in Mobile Sensor Networks</title><categories>math.AT cs.RO</categories><journal-ref>International Journal of Robotics Research 34 (2015), 90-104</journal-ref><doi>10.1177/0278364914548051</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that ball-shaped sensors wander in a bounded domain. A sensor doesn't
know its location but does know when it overlaps a nearby sensor. We say that
an evasion path exists in this sensor network if a moving intruder can avoid
detection. In &quot;Coordinate-free coverage in sensor networks with controlled
boundaries via homology&quot;, Vin deSilva and Robert Ghrist give a necessary
condition, depending only on the time-varying connectivity data of the sensors,
for an evasion path to exist. Using zigzag persistent homology, we provide an
equivalent condition that moreover can be computed in a streaming fashion.
However, no method with time-varying connectivity data as input can give
necessary and sufficient conditions for the existence of an evasion path.
Indeed, we show that the existence of an evasion path depends not only on the
fibrewise homotopy type of the region covered by sensors but also on its
embedding in spacetime. For planar sensors that also measure weak rotation and
distance information, we provide necessary and sufficient conditions for the
existence of an evasion path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3541</identifier>
 <datestamp>2014-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3541</id><created>2013-08-15</created><updated>2014-03-15</updated><authors><author><keyname>Zhou</keyname><forenames>Jiaji</forenames></author><author><keyname>Ross</keyname><forenames>Stephane</forenames></author><author><keyname>Yue</keyname><forenames>Yisong</forenames></author><author><keyname>Dey</keyname><forenames>Debadeepta</forenames></author><author><keyname>Bagnell</keyname><forenames>J. Andrew</forenames></author></authors><title>Knapsack Constrained Contextual Submodular List Prediction with
  Application to Multi-document Summarization</title><categories>cs.LG</categories><comments>8 pages, ICML 2013 Workshop on Inferning: Interactions between
  Inference and Learning</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We study the problem of predicting a set or list of options under knapsack
constraint. The quality of such lists are evaluated by a submodular reward
function that measures both quality and diversity. Similar to DAgger (Ross et
al., 2010), by a reduction to online learning, we show how to adapt two
sequence prediction models to imitate greedy maximization under knapsack
constraint problems: CONSEQOPT (Dey et al., 2012) and SCP (Ross et al., 2013).
Experiments on extractive multi-document summarization show that our approach
outperforms existing state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3548</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3548</id><created>2013-08-16</created><updated>2013-09-09</updated><authors><author><keyname>Gan</keyname><forenames>Ming</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Dai</keyname><forenames>Xuchu</forenames></author></authors><title>Distributed Ranging and Localization for Wireless Networks via
  Compressed Sensing</title><categories>cs.NI cs.IT math.IT</categories><comments>8 pages, 5 figures, submitted to Infocom 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location-based services in a wireless network require nodes to know their
locations accurately. Conventional solutions rely on contention-based medium
access, where only one node can successfully transmit at any time in any
neighborhood. In this paper, a novel, complete, distributed ranging and
localization solution is proposed, which let all nodes in the network broadcast
their location estimates and measure distances to all neighbors simultaneously.
An on-off signaling is designed to overcome the physical half-duplex
constraint. In each iteration, all nodes transmit simultaneously, each
broadcasting codewords describing the current location estimate. From the
superposed signals from all neighbors, each node decodes their neighbors'
locations and also estimates their distances using the signal strengths. The
node then broadcasts its improved location estimates in the subsequent
iteration. Simulations demonstrate accurate localization throughout a large
network over a few thousand symbol intervals, suggesting much higher efficiency
than conventional schemes based on ALOHA or CSMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3553</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3553</id><created>2013-08-16</created><authors><author><keyname>Gan</keyname><forenames>Ming</forenames></author><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Dai</keyname><forenames>Xuchu</forenames></author></authors><title>Application of Analog Network Coding to MIMO Two-Way Relay Channel in
  Cellular Systems</title><categories>cs.IT math.IT</categories><comments>4 pages,2 figures</comments><journal-ref>IEEE Signal Processing Letters, vol.20, no.7, pp.641-644, July
  2013</journal-ref><doi>10.1109/LSP.2013.2262044</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient analog network coding transmission protocol is proposed in this
letter for a MIMO two way cellular network. Block signal alignment is first
proposed to null the inter-user interference for multi-antenna users, which
makes the dimensions of aligned space larger compared with the existing signal
alignment. Two algorithms are developed to jointly design the precoding
matrices at the relay and BS for outage optimization. Especially, the last
algorithm is designed to maximize the effective channel gain to the effective
noise gain ratio. The performance of this transmission protocol is also
verified by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3554</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3554</id><created>2013-08-16</created><authors><author><keyname>Udagawa</keyname><forenames>Yoshihisa</forenames></author></authors><title>Source Code Retrieval Using Sequence Based Similarity</title><categories>cs.SE cs.IR</categories><comments>16 pages, 6 figures, 3 tables</comments><acm-class>H.2.8; D.2.7; H.3.3</acm-class><journal-ref>International Journal of Data Mining &amp; Knowledge Management
  Process (IJDKP) Vol.3, No.4, July 2013, pp.57-74</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Duplicated code has a negative impact on the quality of software systems and
should be detected at least. In this paper, we discuss an approach that
improves source code retrieval using the structural information about the
programs. We developed a lexical parser to extract control statements and
method identifiers from Java programs. We propose a similarity measure that is
defined by the ratio of the number of sequentially full matching statements to
the number of sequentially partial matching ones. The similarity measure is
considered to be an extension of a set based similarity index, e.g.,
Sorensen-Dice index. Our key contribution of this research is the development
of a similarity retrieval algorithm that derives meaningful search conditions
from a given sequence, and then performs retrieval using all of the derived
conditions. Experiments show that our retrieval model outperforms the other
retrieval models up to 90.9% in the number of retrieved methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3558</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3558</id><created>2013-08-16</created><authors><author><keyname>Zhong</keyname><forenames>Leon Wenliang</forenames></author><author><keyname>Kwok</keyname><forenames>James T.</forenames></author></authors><title>Fast Stochastic Alternating Direction Method of Multipliers</title><categories>cs.LG cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new stochastic alternating direction method of
multipliers (ADMM) algorithm, which incrementally approximates the full
gradient in the linearized ADMM formulation. Besides having a low per-iteration
complexity as existing stochastic ADMM algorithms, the proposed algorithm
improves the convergence rate on convex problems from $O(\frac 1 {\sqrt{T}})$
to $O(\frac 1 T)$, where $T$ is the number of iterations. This matches the
convergence rate of the batch ADMM algorithm, but without the need to visit all
the samples in each iteration. Experiments on the graph-guided fused lasso
demonstrate that the new algorithm is significantly faster than
state-of-the-art stochastic and batch ADMM algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3559</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3559</id><created>2013-08-16</created><authors><author><keyname>Benton</keyname><forenames>Kevin</forenames></author><author><keyname>Bross</keyname><forenames>Ty</forenames></author></authors><title>Timing Analysis of SSL/TLS Man in the Middle Attacks</title><categories>cs.CR</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Man in the middle attacks are a significant threat to modern e-commerce and
online communications, even when such transactions are protected by TLS. We
intend to show that it is possible to detect man-in-the-middle attacks on SSL
and TLS by detecting timing differences between a standard SSL session and an
attack we created.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3565</identifier>
 <datestamp>2014-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3565</id><created>2013-08-16</created><updated>2014-02-27</updated><authors><author><keyname>Field</keyname><forenames>Scott E.</forenames></author><author><keyname>Galley</keyname><forenames>Chad R.</forenames></author><author><keyname>Hesthaven</keyname><forenames>Jan S.</forenames></author><author><keyname>Kaye</keyname><forenames>Jason</forenames></author><author><keyname>Tiglio</keyname><forenames>Manuel</forenames></author></authors><title>Fast prediction and evaluation of gravitational waveforms using
  surrogate models</title><categories>gr-qc cs.CE</categories><comments>20 pages, 17 figures, uses revtex 4.1. Version 2 includes new
  numerical experiments for longer waveform durations, larger regions of
  parameter space and multi-mode models</comments><journal-ref>Phys. Rev. X 4, 031006 (2014)</journal-ref><doi>10.1103/PhysRevX.4.031006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  [Abridged] We propose a solution to the problem of quickly and accurately
predicting gravitational waveforms within any given physical model. The method
is relevant for both real-time applications and in more traditional scenarios
where the generation of waveforms using standard methods can be prohibitively
expensive. Our approach is based on three offline steps resulting in an
accurate reduced-order model that can be used as a surrogate for the
true/fiducial waveform family. First, a set of m parameter values is determined
using a greedy algorithm from which a reduced basis representation is
constructed. Second, these m parameters induce the selection of m time values
for interpolating a waveform time series using an empirical interpolant. Third,
a fit in the parameter dimension is performed for the waveform's value at each
of these m times. The cost of predicting L waveform time samples for a generic
parameter choice is of order m L + m c_f online operations where c_f denotes
the fitting function operation count and, typically, m &lt;&lt; L. We generate
accurate surrogate models for Effective One Body (EOB) waveforms of
non-spinning binary black hole coalescences with durations as long as 10^5 M,
mass ratios from 1 to 10, and for multiple harmonic modes. We find that these
surrogates are three orders of magnitude faster to evaluate as compared to the
cost of generating EOB waveforms in standard ways. Surrogate model building for
other waveform models follow the same steps and have the same low online
scaling cost. For expensive numerical simulations of binary black hole
coalescences we thus anticipate large speedups in generating new waveforms with
a surrogate. As waveform generation is one of the dominant costs in parameter
estimation algorithms and parameter space exploration, surrogate models offer a
new and practical way to dramatically accelerate such studies without impacting
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3575</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3575</id><created>2013-08-16</created><authors><author><keyname>Jin</keyname><forenames>Lingfei</forenames></author><author><keyname>Xing</keyname><forenames>Chaoping</forenames></author></authors><title>Euclidean and Hermitian Self-orthogonal Algebraic Geometry Codes and
  Their Application to Quantum Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, we show that if the dimension of an arbitrary algebraic
geometry code over a finite field of even characters is slightly less than half
of its length, then it is equivalent to an Euclidean self-orthogonal code.
However, in the literatures, a strong contrition about existence of certain
differential is required to obtain such a result. We also show a similar result
on Hermitian self-orthogonal algebraic geometry codes. As a consequence, we can
apply our result to quantum codes and obtain quantum codes with good asymptotic
bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3577</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3577</id><created>2013-08-16</created><authors><author><keyname>Jin</keyname><forenames>Lingfei</forenames></author><author><keyname>Xing</keyname><forenames>Chaoping</forenames></author></authors><title>A Construction of Quantum Codes via A Class of Classical Polynomial
  Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There have been various constructions of classical codes from polynomial
valuations in literature \cite{ARC04, LNX01,LX04,XF04,XL00}. In this paper, we
present a construction of classical codes based on polynomial construction
again. One of the features of this construction is that not only the classical
codes arisen from the construction have good parameters, but also quantum codes
with reasonably good parameters can be produced from these classical codes. In
particular, some new quantum codes are constructed (see Examples \ref{5.5} and
\ref{5.6}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3578</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3578</id><created>2013-08-16</created><authors><author><keyname>Jin</keyname><forenames>Lingfei</forenames></author><author><keyname>Xing</keyname><forenames>Chaoping</forenames></author></authors><title>Quantum Gilbert-Varshamov Bound Through Symplectic Self-Orthogonal Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that quantum codes can be constructed through classical
symplectic self-orthogonal codes. In this paper, we give a kind of
Gilbert-Varshamov bound for symplectic self-orthogonal codes first and then
obtain the Gilbert-Varshamov bound for quantum codes. The idea of obtaining the
Gilbert-Varshamov bound for symplectic self-orthogonal codes follows from
counting arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3579</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3579</id><created>2013-08-16</created><authors><author><keyname>John</keyname><forenames>Mohit</forenames></author><author><keyname>JosephPalai</keyname><forenames>Arun</forenames></author></authors><title>ZigBee Based Wireless Data Acquisition Using LabVIEW for Implementing
  Smart Driving Skill Evaluation System</title><categories>cs.CY cs.HC</categories><comments>19 pages</comments><doi>10.5121/ijics.2013.3301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Smart Driving Skill Evaluation (SDSE) System presented in this paper
expedite the testing of candidates aspiring for a driving license in a more
efficient and transparent manner, as compared to the present manual testing
procedure existing in most parts of Asia and Pacific region. The manual test
procedure is also subjected to multiple limitations like time consuming, costly
and heavily controlled by the experience of examiner in conducting the test.
This technological solution is developed by customizing 8051 controller based
embedded system and LabVIEW based virtual instrument. The controller module
senses the motion of the test vehicle on the test track referred to as zero rpm
measurement and the LabVIEW based virtual instrument provides a Graphical User
Interface for remote end monitoring of the sensors embedded on the test track.
The proposed technological solution for the automation of existing manual test
process enables the elimination of human intervention and improves the driving
test accuracy while going paperless with Driving Skill Evaluation System. As a
contribution to the society this technological solution can reduce the number
of road accidents because most accidents results from lack of planning,
anticipation and control which are highly dependent on driving skill.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3600</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3600</id><created>2013-08-16</created><authors><author><keyname>Malmros</keyname><forenames>Jens</forenames></author><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author><author><keyname>Britton</keyname><forenames>Tom</forenames></author></authors><title>Random Walks on Directed Networks: Inference and Respondent-driven
  Sampling</title><categories>stat.ME cs.SI physics.soc-ph</categories><comments>31 pages, 5 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Respondent driven sampling (RDS) is a method often used to estimate
population properties (e.g. sexual risk behavior) in hard-to-reach populations.
It combines an effective modified snowball sampling methodology with an
estimation procedure that yields unbiased population estimates under the
assumption that the sampling process behaves like a random walk on the social
network of the population. Current RDS estimation methodology assumes that the
social network is undirected, i.e. that all edges are reciprocal. However,
empirical social networks in general also have non-reciprocated edges. To
account for this fact, we develop a new estimation method for RDS in the
presence of directed edges on the basis of random walks on directed networks.
We distinguish directed and undirected edges and consider the possibility that
the random walk returns to its current position in two steps through an
undirected edge. We derive estimators of the selection probabilities of
individuals as a function of the number of outgoing edges of sampled
individuals. We evaluate the performance of the proposed estimators on
artificial and empirical networks to show that they generally perform better
than existing methods. This is in particular the case when the fraction of
directed edges in the network is large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3603</identifier>
 <datestamp>2014-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3603</id><created>2013-08-16</created><updated>2014-02-24</updated><authors><author><keyname>Salnikov</keyname><forenames>Vsevolod</forenames></author><author><keyname>Schien</keyname><forenames>Daniel</forenames></author><author><keyname>Youn</keyname><forenames>Hyejin</forenames></author><author><keyname>Lambiotte</keyname><forenames>Renaud</forenames></author><author><keyname>Gastner</keyname><forenames>Michael T.</forenames></author></authors><title>The geography and carbon footprint of mobile phone use in Cote d'Ivoire</title><categories>cs.CY physics.soc-ph</categories><comments>23 pages, 8 figures, 1 table</comments><journal-ref>EPJ Data Science 2014, 3:3</journal-ref><doi>10.1140/epjds21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The newly released Orange D4D mobile phone data base provides new insights
into the use of mobile technology in a developing country. Here we perform a
series of spatial data analyses that reveal important geographic aspects of
mobile phone use in Cote d'Ivoire. We first map the locations of base stations
with respect to the population distribution and the number and duration of
calls at each base station. On this basis, we estimate the energy consumed by
the mobile phone network. Finally, we perform an analysis of inter-city
mobility, and identify high-traffic roads in the country.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3613</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3613</id><created>2013-08-15</created><authors><author><keyname>Ding</keyname><forenames>Liang</forenames></author><author><keyname>Samad</keyname><forenames>Abdul</forenames></author><author><keyname>Xue</keyname><forenames>Xingran</forenames></author><author><keyname>Huang</keyname><forenames>Xiuzhen</forenames></author><author><keyname>Cai</keyname><forenames>Liming</forenames></author></authors><title>Polynomial kernels collapse the W-hierarchy</title><categories>cs.CC cs.DS</categories><comments>13 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that, for many parameterized problems in the class FPT, the
existence of polynomial kernels implies the collapse of the W-hierarchy (i.e.,
W[P] = FPT). The collapsing results are also extended to assumed exponential
kernels for problems in the class FPT. In particular, we establish a close
relationship between polynomial (and exponential) kernelizability and the
existence of sub-exponential time algorithms for a spectrum of circuit
satisfiability problems in FPT. To the best of our knowledge, this is the first
work that connects hardness for polynomial kernelizability of FPT problems to
parameterized intractability. Our work also offers some new insights into the
class FPT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3615</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3615</id><created>2013-08-16</created><authors><author><keyname>Rau-Chaplin</keyname><forenames>Andrew</forenames></author><author><keyname>Varghese</keyname><forenames>Blesson</forenames></author><author><keyname>Wilson</keyname><forenames>Duane</forenames></author><author><keyname>Yao</keyname><forenames>Zhimin</forenames></author><author><keyname>Zeh</keyname><forenames>Norbert</forenames></author></authors><title>QuPARA: Query-Driven Large-Scale Portfolio Aggregate Risk Analysis on
  MapReduce</title><categories>cs.DC cs.CE</categories><comments>9 pages, IEEE International Conference on Big Data (BigData), Santa
  Clara, USA, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic simulation techniques are used for portfolio risk analysis. Risk
portfolios may consist of thousands of reinsurance contracts covering millions
of insured locations. To quantify risk each portfolio must be evaluated in up
to a million simulation trials, each capturing a different possible sequence of
catastrophic events over the course of a contractual year. In this paper, we
explore the design of a flexible framework for portfolio risk analysis that
facilitates answering a rich variety of catastrophic risk queries. Rather than
aggregating simulation data in order to produce a small set of high-level risk
metrics efficiently (as is often done in production risk management systems),
the focus here is on allowing the user to pose queries on unaggregated or
partially aggregated data. The goal is to provide a flexible framework that can
be used by analysts to answer a wide variety of unanticipated but natural ad
hoc queries. Such detailed queries can help actuaries or underwriters to better
understand the multiple dimensions (e.g., spatial correlation, seasonality,
peril features, construction features, and financial terms) that can impact
portfolio risk. We implemented a prototype system, called QuPARA (Query-Driven
Large-Scale Portfolio Aggregate Risk Analysis), using Hadoop, which is Apache's
implementation of the MapReduce paradigm. This allows the user to take
advantage of large parallel compute servers in order to answer ad hoc risk
analysis queries efficiently even on very large data sets typically encountered
in practice. We describe the design and implementation of QuPARA and present
experimental results that demonstrate its feasibility. A full portfolio risk
analysis run consisting of a 1,000,000 trial simulation, with 1,000 events per
trial, and 3,200 risk transfer contracts can be completed on a 16-node Hadoop
cluster in just over 20 minutes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3616</identifier>
 <datestamp>2014-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3616</id><created>2013-08-14</created><updated>2013-12-16</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Complexity in animal communication: Estimating the size of N-Gram
  structures</title><categories>q-bio.PE cs.IT math.IT q-bio.QM</categories><comments>17 pages, 4 figures, 4 tables; accepted and to appear in Entropy</comments><journal-ref>Entropy 2014, 16(1), 526-542</journal-ref><doi>10.3390/e16010526</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, new techniques that allow conditional entropy to estimate the
combinatorics of symbols are applied to animal communication studies to
estimate the communication's repertoire size. By using the conditional entropy
estimates at multiple orders, the paper estimates the total repertoire sizes
for animal communication across bottlenose dolphins, humpback whales, and
several species of birds for N-grams length one to three. In addition to
discussing the impact of this method on studies of animal communication
complexity, the reliability of these estimates is compared to other methods
through simulation. While entropy does undercount the total repertoire size due
to rare N-grams, it gives a more accurate picture of the most frequently used
repertoire than just repertoire size alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3648</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3648</id><created>2013-08-16</created><authors><author><keyname>Hunold</keyname><forenames>Sascha</forenames></author><author><keyname>Tr&#xe4;ff</keyname><forenames>Jesper Larsson</forenames></author></authors><title>On the State and Importance of Reproducible Experimental Research in
  Parallel Computing</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer science is also an experimental science. This is particularly the
case for parallel computing, which is in a total state of flux, and where
experiments are necessary to substantiate, complement, and challenge
theoretical modeling and analysis. Here, experimental work is as important as
are advances in theory, that are indeed often driven by the experimental
findings. In parallel computing, scientific contributions presented in research
articles are therefore often based on experimental data, with a substantial
part devoted to presenting and discussing the experimental findings. As in all
of experimental science, experiments must be presented in a way that makes
reproduction by other researchers possible, in principle. Despite appearance to
the contrary, we contend that reproducibility plays a small role, and is
typically not achieved. As can be found, articles often do not have a
sufficiently detailed description of their experiments, and do not make
available the software used to obtain the claimed results. As a consequence,
parallel computational results are most often impossible to reproduce, often
questionable, and therefore of little or no scientific value. We believe that
the description of how to reproduce findings should play an important part in
every serious, experiment-based parallel computing research article. We aim to
initiate a discussion of the reproducibility issue in parallel computing, and
elaborate on the importance of reproducible research for (1) better and sounder
technical/scientific papers, (2) a sounder and more efficient review process
and (3) more effective collective work. This paper expresses our current view
on the subject and should be read as a position statement for discussion and
future work. We do not consider the related (but no less important) issue of
the quality of the experimental design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3654</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3654</id><created>2013-08-16</created><updated>2014-10-27</updated><authors><author><keyname>Kotek</keyname><forenames>Tomer</forenames><affiliation>Institute for Informations systems, Vienna University of Technology</affiliation></author><author><keyname>Makowsky</keyname><forenames>Johann A.</forenames><affiliation>Faculty of Computer Science, Technion--Israel Institute of Technology</affiliation></author></authors><title>Connection Matrices and the Definability of Graph Parameters</title><categories>cs.LO math.CO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 10, Issue 4 (October
  31, 2014) lmcs:731</journal-ref><doi>10.2168/LMCS-10(4:1)2014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we extend and prove in detail the Finite Rank Theorem for
connection matrices of graph parameters definable in Monadic Second Order Logic
with counting (CMSOL) from B. Godlin, T. Kotek and J.A. Makowsky (2008) and
J.A. Makowsky (2009). We demonstrate its vast applicability in simplifying
known and new non-definability results of graph properties and finding new
non-definability results for graph parameters. We also prove a Feferman-Vaught
Theorem for the logic CFOL, First Order Logic with the modular counting
quantifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3657</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3657</id><created>2013-08-16</created><authors><author><keyname>Zhang</keyname><forenames>Amy X.</forenames></author><author><keyname>Noulas</keyname><forenames>Anastasios</forenames></author><author><keyname>Scellato</keyname><forenames>Salvatore</forenames></author><author><keyname>Mascolo</keyname><forenames>Cecilia</forenames></author></authors><title>Hoodsquare: Modeling and Recommending Neighborhoods in Location-based
  Social Networks</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>ASE/IEEE SocialCom 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information garnered from activity on location-based social networks can be
harnessed to characterize urban spaces and organize them into neighborhoods. In
this work, we adopt a data-driven approach to the identification and modeling
of urban neighborhoods using location-based social networks. We represent
geographic points in the city using spatio-temporal information about
Foursquare user check-ins and semantic information about places, with the goal
of developing features to input into a novel neighborhood detection algorithm.
The algorithm first employs a similarity metric that assesses the homogeneity
of a geographic area, and then with a simple mechanism of geographic
navigation, it detects the boundaries of a city's neighborhoods. The models and
algorithms devised are subsequently integrated into a publicly available,
map-based tool named Hoodsquare that allows users to explore activities and
neighborhoods in cities around the world.
  Finally, we evaluate Hoodsquare in the context of a recommendation
application where user profiles are matched to urban neighborhoods. By
comparing with a number of baselines, we demonstrate how Hoodsquare can be used
to accurately predict the home neighborhood of Twitter users. We also show that
we are able to suggest neighborhoods geographically constrained in size, a
desirable property in mobile recommendation scenarios for which geographical
precision is key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3662</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3662</id><created>2013-08-16</created><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Sahneh</keyname><forenames>Faryad Darabi</forenames></author><author><keyname>Scoglio</keyname><forenames>Caterina</forenames></author></authors><title>A Convex Framework for Optimal Investment on Disease Awareness in Social
  Networks</title><categories>cs.SI cs.SY math.OC physics.soc-ph</categories><comments>IEEE GlobalSIP Symposium on Network Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of controlling the propagation of an epidemic
outbreak in an arbitrary network of contacts by investing on disease awareness
throughout the network. We model the effect of agent awareness on the dynamics
of an epidemic using the SAIS epidemic model, an extension of the SIS epidemic
model that includes a state of &quot;awareness&quot;. This model allows to derive a
condition to control the spread of an epidemic outbreak in terms of the
eigenvalues of a matrix that depends on the network structure and the
parameters of the model. We study the problem of finding the cost-optimal
investment on disease awareness throughout the network when the cost function
presents some realistic properties. We propose a convex framework to find
cost-optimal allocation of resources. We validate our results with numerical
simulations in a real online social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3665</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3665</id><created>2013-08-16</created><authors><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author></authors><title>On Sparsification for Computing Treewidth</title><categories>cs.CC cs.DM cs.DS math.CO</categories><comments>21 pages. Full version of the extended abstract presented at IPEC
  2013</comments><msc-class>68Q17, 68Q25, 05C85</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We investigate whether an n-vertex instance (G,k) of Treewidth, asking
whether the graph G has treewidth at most k, can efficiently be made sparse
without changing its answer. By giving a special form of OR-cross-composition,
we prove that this is unlikely: if there is an e &gt; 0 and a polynomial-time
algorithm that reduces n-vertex Treewidth instances to equivalent instances, of
an arbitrary problem, with O(n^{2-e}) bits, then NP is in coNP/poly and the
polynomial hierarchy collapses to its third level.
  Our sparsification lower bound has implications for structural
parameterizations of Treewidth: parameterizations by measures that do not
exceed the vertex count, cannot have kernels with O(k^{2-e}) bits for any e &gt;
0, unless NP is in coNP/poly. Motivated by the question of determining the
optimal kernel size for Treewidth parameterized by vertex cover, we improve the
O(k^3)-vertex kernel from Bodlaender et al. (STACS 2011) to a kernel with
O(k^2) vertices. Our improved kernel is based on a novel form of
treewidth-invariant set. We use the q-expansion lemma of Fomin et al. (STACS
2011) to find such sets efficiently in graphs whose vertex count is
superquadratic in their vertex cover number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3679</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3679</id><created>2013-08-16</created><authors><author><keyname>Mitra</keyname><forenames>Pinaki</forenames></author><author><keyname>Sundaram</keyname><forenames>Girish</forenames></author><author><keyname>PS</keyname><forenames>Sreedish</forenames></author></authors><title>Just In Time Indexing</title><categories>cs.DB</categories><comments>Selected for proceedings of NETs2012 International Conference on
  Internet Studies held in Bangkok, Thailand from August 17-19, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major challenges being faced by Database managers today is to
manage the performance of complex SQL queries which are dynamic in nature.
Since it is not possible to tune each and every query because of its dynamic
nature, there is a definite possibility that these queries may cause serious
database performance issues if left alone. Conventional indexes are useful only
for those queries which are frequently executed or those columns which are
frequently joined in SQL queries. This proposal is regarding a method, a query
optimizer for optimizing database queries in a database management system. Just
In Time(JIT) indexes are On Demand, temporary indexes created on the fly based
on current needs so that they would be able to satisfy any kind of queries. JIT
indexes are created only when the configured threshold values for resource
consumption are exceeded for a query. JIT indexes will be stored in a temporary
basis and will get replaced by new JIT indexes in course of time. The proposal
is substantiated with the help of experimental programs and with various test
cases. The idea of parallel programming is also brought into picture as it can
be effectively used in a multiprocessor system. Multiple threads are employed
while one set of threads proceed in the conventional way and the other set of
threads proceed with the proposed way. A live switch over is made when a
suitable stage is reached and from then onwards the proposed method will only
come into picture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3689</identifier>
 <datestamp>2014-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3689</id><created>2013-08-16</created><updated>2014-12-15</updated><authors><author><keyname>Cully</keyname><forenames>Antoine</forenames></author><author><keyname>Mouret</keyname><forenames>Jean-Baptiste</forenames></author></authors><title>Evolving a Behavioral Repertoire for a Walking Robot</title><categories>cs.RO</categories><comments>33 pages; Evolutionary Computation Journal 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous algorithms have been proposed to allow legged robots to learn to
walk. However, the vast majority of these algorithms is devised to learn to
walk in a straight line, which is not sufficient to accomplish any real-world
mission. Here we introduce the Transferability-based Behavioral Repertoire
Evolution algorithm (TBR-Evolution), a novel evolutionary algorithm that
simultaneously discovers several hundreds of simple walking controllers, one
for each possible direction. By taking advantage of solutions that are usually
discarded by evolutionary processes, TBR-Evolution is substantially faster than
independently evolving each controller. Our technique relies on two methods:
(1) novelty search with local competition, which searches for both
high-performing and diverse solutions, and (2) the transferability approach,
which com-bines simulations and real tests to evolve controllers for a physical
robot. We evaluate this new technique on a hexapod robot. Results show that
with only a few dozen short experiments performed on the robot, the algorithm
learns a repertoire of con-trollers that allows the robot to reach every point
in its reachable space. Overall, TBR-Evolution opens a new kind of learning
algorithm that simultaneously optimizes all the achievable behaviors of a
robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3693</identifier>
 <datestamp>2013-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3693</id><created>2013-08-13</created><authors><author><keyname>Pau</keyname><forenames>L. -F.</forenames></author></authors><title>Business and social evaluation of denial of service attacks of
  communications networks in view of scaling economic counter-measures</title><categories>cs.CY cs.CR</categories><journal-ref>The virtual battlefield : perspectives on cyber warfare ,
  Cryptology and information security Series, Vol 3, IOS Press, Amsterdam,
  2009, pp. 282-293</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives an analytical method to determine the economic and indirect
implications of denial of service and distributed denial of service attacks. It
is based on time preference dynamics applied to the monetary mass for the
restoration of capabilities, on long term investments to rebuild capabilities,
and of the usability level of the capabilities after an attack. A simple
illustrative example is provided for a denial of service on a corporate data
centre. The needed data collection methodologies are categorized by classes of
targets. The use of the method is explained in the context of legal or policy
driven dissuasive, retaliation or compensation/ restoration actions. A concrete
set of deployment cases in mobile communications services is discussed. The
conclusion includes policy recommendations as well as information exchange
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3700</identifier>
 <datestamp>2014-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3700</id><created>2013-08-16</created><authors><author><keyname>Patro</keyname><forenames>Rob</forenames><affiliation>Lane Center for Computational Biology, School of Computer Science, Carnegie Mellon University</affiliation></author><author><keyname>Mount</keyname><forenames>Stephen M.</forenames><affiliation>Department of Cell Biology and Molecular Genetics and Center for Bioinformatics and Computational Biology, University of Maryland</affiliation></author><author><keyname>Kingsford</keyname><forenames>Carl</forenames><affiliation>Lane Center for Computational Biology, School of Computer Science, Carnegie Mellon University</affiliation></author></authors><title>Sailfish: Alignment-free Isoform Quantification from RNA-seq Reads using
  Lightweight Algorithms</title><categories>q-bio.GN cs.CE</categories><comments>28 pages, 2 main figures, 2 algorithm displays, 5 supplementary
  figures and 2 supplementary notes. Accompanying software available at
  http://www.cs.cmu.edu/~ckingsf/software/sailfish</comments><doi>10.1038/nbt.2862</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RNA-seq has rapidly become the de facto technique to measure gene expression.
However, the time required for analysis has not kept up with the pace of data
generation. Here we introduce Sailfish, a novel computational method for
quantifying the abundance of previously annotated RNA isoforms from RNA-seq
data. Sailfish entirely avoids mapping reads, which is a time-consuming step in
all current methods. Sailfish provides quantification estimates much faster
than existing approaches (typically 20-times faster) without loss of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3740</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3740</id><created>2013-08-16</created><authors><author><keyname>Shaikh</keyname><forenames>Mateen</forenames></author><author><keyname>McNicholas</keyname><forenames>Paul D.</forenames></author><author><keyname>Antonie</keyname><forenames>M. Luiza</forenames></author><author><keyname>Murphy</keyname><forenames>T. Brendan</forenames></author></authors><title>Standardizing Interestingness Measures for Association Rules</title><categories>stat.AP cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interestingness measures provide information that can be used to prune or
select association rules. A given value of an interestingness measure is often
interpreted relative to the overall range of the values that the
interestingness measure can take. However, properties of individual association
rules restrict the values an interestingness measure can achieve. An
interesting measure can be standardized to take this into account, but this has
only been done for one interestingness measure to date, i.e., the lift.
Standardization provides greater insight than the raw value and may even alter
researchers' perception of the data. We derive standardized analogues of three
interestingness measures and use real and simulated data to compare them to
their raw versions, each other, and the standardized lift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3745</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3745</id><created>2013-08-16</created><authors><author><keyname>Reddington</keyname><forenames>Joseph</forenames></author><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Cowie</keyname><forenames>Douglas</forenames></author></authors><title>Computational Properties of Fiction Writing and Collaborative Work</title><categories>cs.HC</categories><comments>13 pages, 6 figures</comments><msc-class>91C20, 62H30, 76M27</msc-class><acm-class>J.5; H.1.2; H.3.3; I.5.3; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From the earliest days of computing, there have been tools to help shape
narrative. Spell-checking, word counts, and readability analysis, give today's
novelists tools that Dickens, Austen, and Shakespeare could only have dreamt
of. However, such tools have focused on the word, or phrase levels. In the last
decade, research focus has shifted to support for collaborative editing of
documents. This work considers more sophisticated attempts to visualise the
semantics, pace and rhythm within a narrative through data mining. We describe
real life applications in two related domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3750</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3750</id><created>2013-08-16</created><authors><author><keyname>Forghani</keyname><forenames>Yahya</forenames></author><author><keyname>Yazdi</keyname><forenames>Hadi Sadoghi</forenames></author></authors><title>Comment on &quot;robustness and regularization of support vector machines&quot; by
  H. Xu, et al., (Journal of Machine Learning Research, vol. 10, pp. 1485-1510,
  2009, arXiv:0803.3490)</title><categories>cs.LG</categories><comments>2 pages. This paper has been accepted with minor revision in journal
  of machine learning research (JMLR)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper comments on the published work dealing with robustness and
regularization of support vector machines (Journal of Machine Learning
Research, vol. 10, pp. 1485-1510, 2009) [arXiv:0803.3490] by H. Xu, etc. They
proposed a theorem to show that it is possible to relate robustness in the
feature space and robustness in the sample space directly. In this paper, we
propose a counter example that rejects their theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3763</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3763</id><created>2013-08-17</created><authors><author><keyname>Hameed</keyname><forenames>Ali</forenames></author><author><keyname>Slinko</keyname><forenames>Arkadii</forenames></author></authors><title>A Characterization of Ideal Weighted Secret Sharing Schemes</title><categories>cs.CR math.CO</categories><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beimel, Tassa and Weinreb (2008) and Farras and Padro (2010) partially
characterized access structures of ideal weighted threshold secret sharing
schemes in terms of the operation of composition. They classified
indecomposable ideal weighted threshold access structures, and proved that any
other ideal weighted threshold access structure is a composition of
indecomposable ones. It remained unclear which compositions of indecomposable
weighted threshold access structures are weighted. In this paper we fill the
gap. Using game-theoretic techniques we determine which compositions of
indecomposable ideal access structures are weighted, and obtain an if and only
if characterization of ideal weighted threshold secret sharing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3772</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3772</id><created>2013-08-17</created><authors><author><keyname>Isikman</keyname><forenames>Arif O.</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author><author><keyname>Nasir</keyname><forenames>Ali A.</forenames></author><author><keyname>Amat</keyname><forenames>Alexander G.</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney. A.</forenames></author></authors><title>Joint Phase Noise Estimation and Data Detection in Coded MIMO Systems</title><categories>cs.IT math.IT</categories><comments>19 pages 4 figures and 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of joint oscillator phase noise (PHN) estimation
and data detection for multi-input multi-output (MIMO) systems using
bit-interleaved coded modulation (BICM) is analyzed. A new MIMO receiver that
iterates between the estimator and the detector, based on the
expectation-maximization (EM) framework, is proposed. It is shown that at high
signal-to-noise ratios, a maximum a posteriori estimator (MAP) can be used to
carry out the maximization step of the EM algorithm. Moreover, to reduce the
computational complexity of the proposed EM algorithm, a soft decision-directed
extended Kalman filter-smoother (EKFS) is applied instead of the MAP estimator
to track the PHN parameters. Numerical results show that by combining the
proposed EKFS based approach with an iterative detector that employs low
density parity check (LDPC) codes, PHN can be accurately tracked. Simulations
also demonstrate that compared to existing algorithms, the proposed iterative
receiver can significantly enhance the performance of MIMO systems in the
presence of PHN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3778</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3778</id><created>2013-08-17</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Pass</keyname><forenames>Rafael</forenames></author></authors><title>Game Theory with Translucent Players</title><categories>cs.GT</categories><comments>Extended version of a paper that appear in the Conference on
  Theoretical Aspects of Rationality and Knowledge, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A traditional assumption in game theory is that players are opaque to one
another---if a player changes strategies, then this change in strategies does
not affect the choice of other players' strategies. In many situations this is
an unrealistic assumption. We develop a framework for reasoning about games
where the players may be translucent to one another; in particular, a player
may believe that if she were to change strategies, then the other player would
also change strategies. Translucent players may achieve significantly more
efficient outcomes than opaque ones.
  Our main result is a characterization of strategies consistent with
appropriate analogues of common belief of rationality. Common Counterfactual
Belief of Rationality (CCBR) holds if (1) everyone is rational, (2) everyone
counterfactually believes that everyone else is rational (i.e., all players i
believe that everyone else would still be rational even if $i$ were to switch
strategies), (3) everyone counterfactually believes that everyone else is
rational, and counterfactually believes that everyone else is rational, and so
on. CCBR characterizes the set of strategies surviving iterated removal of
minimax dominated strategies, where a strategy s for player i is minimax
dominated by s' if the worst-case payoff for i using s' is better than the best
possible payoff using s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3780</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3780</id><created>2013-08-17</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Pass</keyname><forenames>Rafael</forenames></author><author><keyname>Seeman</keyname><forenames>Lior</forenames></author></authors><title>Decision Theory with Resource-Bounded Agents</title><categories>cs.GT cs.AI</categories><comments>To appear, Topics in Cognitive Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There have been two major lines of research aimed at capturing
resource-bounded players in game theory. The first, initiated by Rubinstein,
charges an agent for doing costly computation; the second, initiated by Neyman,
does not charge for computation, but limits the computation that agents can do,
typically by modeling agents as finite automata. We review recent work on
applying both approaches in the context of decision theory. For the first
approach, we take the objects of choice in a decision problem to be Turing
machines, and charge players for the ``complexity'' of the Turing machine
chosen (e.g., its running time). This approach can be used to explain
well-known phenomena like first-impression-matters biases (i.e., people tend to
put more weight on evidence they hear early on) and belief polarization (two
people with different prior beliefs, hearing the same evidence, can end up with
diametrically opposed conclusions) as the outcomes of quite rational decisions.
For the second approach, we model people as finite automata, and provide a
simple algorithm that, on a problem that captures a number of settings of
interest, provably performs optimally as the number of states in the automaton
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3784</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3784</id><created>2013-08-17</created><authors><author><keyname>Emami</keyname><forenames>Hojjat</forenames></author><author><keyname>Lotfi</keyname><forenames>Shahriar</forenames></author></authors><title>Graph Colouring Problem Based on Discrete Imperialist Competitive
  Algorithm</title><categories>cs.AI cs.NE</categories><comments>12 pages</comments><journal-ref>International Journal in Foundations of Computer Science &amp;
  Technology (IJFCST), Vol. 3, No.4, July 2013, pp. 1-12</journal-ref><doi>10.5121/ijfcst.2013.3401</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In graph theory, Graph Colouring Problem (GCP) is an assignment of colours to
vertices of any given graph such that the colours on adjacent vertices are
different. The GCP is known to be an optimization and NP-hard problem.
Imperialist Competitive Algorithm (ICA) is a meta-heuristic optimization and
stochastic search strategy which is inspired from socio-political phenomenon of
imperialistic competition. The ICA contains two main operators: the
assimilation and the imperialistic competition. The ICA has excellent
capabilities such as high convergence rate and better global optimum
achievement. In this research, a discrete version of ICA is proposed to deal
with the solution of GCP. We call this algorithm as the DICA. The performance
of the proposed method is compared with Genetic Algorithm (GA) on seven
well-known graph colouring benchmarks. Experimental results demonstrate the
superiority of the DICA for the benchmarks. This means DICA can produce optimal
and valid solutions for different GCP instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3785</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3785</id><created>2013-08-17</created><authors><author><keyname>Hossain</keyname><forenames>Md. Ali</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Mijanur</forenames></author><author><keyname>Prodhan</keyname><forenames>Uzzal Kumar</forenames></author><author><keyname>Khan</keyname><forenames>Md. Farukuzzaman</forenames></author></authors><title>Implementation Of Back-Propagation Neural Network For Isolated Bangla
  Speech Recognition</title><categories>cs.CL cs.NE</categories><comments>9 pages, 3 figures, 1 table</comments><journal-ref>International Journal of Information Sciences and Techniques
  (IJIST) Vol.3, No.4, July 2013</journal-ref><doi>10.5121/ijist.2013.3401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the development of Back-propagation Neural
Network for Bangla Speech Recognition. In this paper, ten bangla digits were
recorded from ten speakers and have been recognized. The features of these
speech digits were extracted by the method of Mel Frequency Cepstral
Coefficient (MFCC) analysis. The mfcc features of five speakers were used to
train the network with Back propagation algorithm. The mfcc features of ten
bangla digit speeches, from 0 to 9, of another five speakers were used to test
the system. All the methods and algorithms used in this research were
implemented using the features of Turbo C and C++ languages. From our
investigation it is seen that the developed system can successfully encode and
analyze the mfcc features of the speech signal to recognition. The developed
system achieved recognition rate about 96.332% for known speakers (i.e.,
speaker dependent) and 92% for unknown speakers (i.e., speaker independent).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3799</identifier>
 <datestamp>2014-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3799</id><created>2013-08-17</created><updated>2014-08-28</updated><authors><author><keyname>Fang</keyname><forenames>Hao</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Jiang</keyname><forenames>Hai</forenames></author></authors><title>Permutation Enhanced Parallel Reconstruction with A Linear Compressive
  Sampling Device</title><categories>cs.IT math.IT</categories><comments>11 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, a permutation enhanced parallel reconstruction architecture
for compressive sampling is proposed. In this architecture, a measurement
matrix is constructed from a block-diagonal sensing matrix and the sparsifying
basis of the target signal. In this way, the projection of the signal onto the
sparsifying basis can be divided into several segments and all segments can be
reconstructed in parallel. Thus, the computational complexity and the time for
reconstruction can be reduced significantly. This feature is especially
appealing for big data processing. Furthermore, to reduce the number of
measurements needed to achieve the desired reconstruction error performance,
permutation is introduced for the projection of the signal. It is shown that
the permutation can be performed implicitly by using a pre-designed measurement
matrix. Thus, the permutation enhanced parallel reconstruction can be achieved
with a linear compressive sampling device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3810</identifier>
 <datestamp>2014-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3810</id><created>2013-08-17</created><updated>2014-11-12</updated><authors><author><keyname>Geneson</keyname><forenames>J. T.</forenames></author><author><keyname>Prasad</keyname><forenames>Rohil</forenames></author><author><keyname>Tidor</keyname><forenames>Jonathan</forenames></author></authors><title>Bounding sequence extremal functions with formations</title><categories>cs.DM math.CO</categories><comments>25 pages</comments><msc-class>05D99</msc-class><journal-ref>Electr. J. Comb. 21(3): P3.24 (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $(r, s)$-formation is a concatenation of $s$ permutations of $r$ letters.
If $u$ is a sequence with $r$ distinct letters, then let $\mathit{Ex}(u, n)$ be
the maximum length of any $r$-sparse sequence with $n$ distinct letters which
has no subsequence isomorphic to $u$. For every sequence $u$ define
$\mathit{fw}(u)$, the formation width of $u$, to be the minimum $s$ for which
there exists $r$ such that there is a subsequence isomorphic to $u$ in every
$(r, s)$-formation. We use $\mathit{fw}(u)$ to prove upper bounds on
$\mathit{Ex}(u, n)$ for sequences $u$ such that $u$ contains an alternation
with the same formation width as $u$.
  We generalize Nivasch's bounds on $\mathit{Ex}((ab)^{t}, n)$ by showing that
$\mathit{fw}((12 \ldots l)^{t})=2t-1$ and $\mathit{Ex}((12\ldots l)^{t}, n)
=n2^{\frac{1}{(t-2)!}\alpha(n)^{t-2}\pm O(\alpha(n)^{t-3})}$ for every $l \geq
2$ and $t\geq 3$, such that $\alpha(n)$ denotes the inverse Ackermann function.
Upper bounds on $\mathit{Ex}((12 \ldots l)^{t} , n)$ have been used in other
papers to bound the maximum number of edges in $k$-quasiplanar graphs on $n$
vertices with no pair of edges intersecting in more than $O(1)$ points.
  If $u$ is any sequence of the form $a v a v' a$ such that $a$ is a letter,
$v$ is a nonempty sequence excluding $a$ with no repeated letters and $v'$ is
obtained from $v$ by only moving the first letter of $v$ to another place in
$v$, then we show that $\mathit{fw}(u)=4$ and $\mathit{Ex}(u, n)
=\Theta(n\alpha(n))$. Furthermore we prove that
$\mathit{fw}(abc(acb)^{t})=2t+1$ and $\mathit{Ex}(abc(acb)^{t}, n) =
n2^{\frac{1}{(t-1)!}\alpha(n)^{t-1}\pm O(\alpha(n)^{t-2})}$ for every $t\geq
2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3818</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3818</id><created>2013-08-17</created><authors><author><keyname>Li</keyname><forenames>Yanpeng</forenames></author></authors><title>Reference Distance Estimator</title><categories>cs.LG stat.ML</categories><comments>10 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A theoretical study is presented for a simple linear classifier called
reference distance estimator (RDE), which assigns the weight of each feature j
as P(r|j)-P(r), where r is a reference feature relevant to the target class y.
The analysis shows that if r performs better than random guess in predicting y
and is conditionally independent with each feature j, the RDE will have the
same classification performance as that from P(y|j)-P(y), a classifier trained
with the gold standard y. Since the estimation of P(r|j)-P(r) does not require
labeled data, under the assumption above, RDE trained with a large number of
unlabeled examples would be close to that trained with infinite labeled
examples. For the case the assumption does not hold, we theoretically analyze
the factors that influence the closeness of the RDE to the perfect one under
the assumption, and present an algorithm to select reference features and
combine multiple RDEs from different reference features using both labeled and
unlabeled data. The experimental results on 10 text classification tasks show
that the semi-supervised learning method improves supervised methods using
5,000 labeled examples and 13 million unlabeled ones, and in many tasks, its
performance is even close to a classifier trained with 13 million labeled
examples. In addition, the bounds in the theorems provide good estimation of
the classification performance and can be useful for new algorithm design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3822</identifier>
 <datestamp>2015-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3822</id><created>2013-08-17</created><updated>2015-01-15</updated><authors><author><keyname>Kearns</keyname><forenames>Steven M.</forenames></author></authors><title>Sublinear Matching With Finite Automata Using Reverse Suffix Scanning</title><categories>cs.DS</categories><comments>This version of the paper is a streamlined presentation that includes
  the definition of Offsetting Finite Automata, which replaces the name
  Accelerated Finite Automata in previous version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give algorithms to accelerate the computation of deterministic finite
automata (DFA) by calculating the state of a DFA n positions ahead utilizing a
reverse scan of the next n characters. Often this requires scanning fewer than
n characters resulting in a fraction of the input being skipped and a
commensurate increase in processing speed. The skipped fraction is &gt; 80% in
several of our examples. We introduce offsetting finite automata (OFA) to
encode the accelerated computation. OFA generalize DFA by adding an integer
offset to the current input index at each state transition. We give algorithms
for constructing an OFA that accepts the same language as a DFA while possibly
skipping input, and for matching with an OFA. Compared to previous algorithms
that attempt to skip some of the input, the new matching algorithm can skip
more often and can skip farther. In the worst case the new matching algorithm
scans the same number of characters as a simple forward scan, whereas previous
approaches often scan more, so the new algorithm can be used as a reliable
replacement for the simple forward scan. Additionally, the new algorithm adapts
to available memory and time constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3827</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3827</id><created>2013-08-17</created><authors><author><keyname>Badr</keyname><forenames>Ahmed</forenames></author><author><keyname>Patil</keyname><forenames>Pratik</forenames></author><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Tan</keyname><forenames>Wai-Tian</forenames></author><author><keyname>Apostolopoulos</keyname><forenames>John</forenames></author></authors><title>Layered Constructions for Low-Delay Streaming Codes</title><categories>cs.IT math.IT</categories><comments>32 pages, Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new class of error correction codes for low-delay streaming
communication. We consider an online setup where a source packet arrives at the
encoder every $M$ channel uses, and needs to be decoded with a maximum delay of
$T$ packets. We consider a sliding-window erasure channel --- $\cC(N,B,W)$ ---
which introduces either up to $N$ erasures in arbitrary positions, or $B$
erasures in a single burst, in any window of length $W$. When $M=1$, the case
where source-arrival and channel-transmission rates are equal, we propose a
class of codes --- MiDAS codes --- that achieve a near optimal rate. Our
construction is based on a {\em layered} approach. We first construct an
optimal code for the $\cC(N=1,B,W)$ channel, and then concatenate an additional
layer of parity-check symbols to deal with $N&gt;1$. When $M &gt; 1$, the case where
source-arrival and channel-transmission rates are unequal, we characterize the
capacity when $N=1$ and $W \ge M(T+1),$ and for $N&gt;1$, we propose a
construction based on a layered approach. Numerical simulations over
Gilbert-Elliott and Fritchman channel models indicate significant gains in the
residual loss probability over baseline schemes. We also discuss the connection
between the error correction properties of the MiDAS codes and their underlying
column distance and column span.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3829</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3829</id><created>2013-08-18</created><updated>2014-07-30</updated><authors><author><keyname>Razgon</keyname><forenames>Igor</forenames></author></authors><title>On OBDDs for CNFs of bounded treewidth</title><categories>cs.LO cs.DS</categories><comments>Corollary 3 is added, separating OBDD and SDD in the classical
  (non-parameterized) sense</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we show that a CNF cannot be compiled into an Ordered Binary
Decision Diagram (OBDD) of fixed-parameter size parameterized by the primal
graph treewidth of the CNF. Thus we provide a parameterized separation between
OBDDs and Sentential Decision Diagrams (SDDs) for which such fixed-parameter
compilation is possible. In fact, we demonstrate that the proposed lower bound
also yields a classical (non-parameterized) separation of OBDDs and SDDs. We
also show that the best existing parameterized upper bound for OBDDs in fact
holds for incidence graph treewidth parameterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3830</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3830</id><created>2013-08-18</created><authors><author><keyname>Alexander</keyname><forenames>Rukshan</forenames></author><author><keyname>Rukshan</keyname><forenames>Prashanthi</forenames></author><author><keyname>Mahesan</keyname><forenames>Sinnathamby</forenames></author></authors><title>Natural Language Web Interface for Database (NLWIDB)</title><categories>cs.CL cs.DB cs.HC</categories><comments>8 pages,5 figures, 12 tables, Proceedings of the Third International
  Symposium, SEUSL: 6-7 July 2013, Oluvil, Sri Lanka</comments><journal-ref>Proceedings of the Third International Symposium, SEUSL: 6-7 July
  2013, Oluvil, Sri Lanka</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a long term desire of the computer users to minimize the communication
gap between the computer and a human. On the other hand, almost all ICT
applications store information in to databases and retrieve from them.
Retrieving information from the database requires knowledge of technical
languages such as Structured Query Language. However majority of the computer
users who interact with the databases do not have a technical background and
are intimidated by the idea of using languages such as SQL. For above reasons,
a Natural Language Web Interface for Database (NLWIDB) has been developed. The
NLWIDB allows the user to query the database in a language more like English,
through a convenient interface over the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3831</identifier>
 <datestamp>2013-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3831</id><created>2013-08-18</created><updated>2013-11-19</updated><authors><author><keyname>Kiwi</keyname><forenames>Marcos</forenames></author><author><keyname>de Espan&#xe9;s</keyname><forenames>Pablo Moisset</forenames></author><author><keyname>Rapaport</keyname><forenames>Ivan</forenames></author><author><keyname>Rica</keyname><forenames>Sergio</forenames></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames></author></authors><title>Strict majority bootstrap percolation in the r-wheel</title><categories>cs.SI math.PR</categories><comments>10 pages</comments><msc-class>60K35, 60C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the strict majority bootstrap percolation process on
graphs. Vertices may be active or passive. Initially, active vertices are
chosen independently with probability p. Each passive vertex becomes active if
at least half of its neighbors are active (and thereafter never changes its
state). If at the end of the process all vertices become active then we say
that the initial set of active vertices percolates on the graph. We address the
problem of finding graphs for which percolation is likely to occur for small
values of p. Specifically, we study a graph that we call r-wheel: a ring of n
vertices augmented with a universal vertex where each vertex in the ring is
connected to its r closest neighbors to the left and to its r closest neighbors
to the right. We prove that the critical probability is 1/4. In other words, if
p&gt;1/4 then for large values of r percolation occurs with probability
arbitrarily close to 1 as n goes to infinity. On the other hand, if p&lt;1/4 then
the probability of percolation is bounded away from 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3836</identifier>
 <datestamp>2014-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3836</id><created>2013-08-18</created><updated>2014-01-25</updated><authors><author><keyname>Ivanova</keyname><forenames>Inga</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Redundancy Generation in University-Industry-Government Relations: The
  Triple Helix Modeled, Measured, and Simulated</title><categories>cs.CY</categories><comments>Scientometrics, accepted for publication, January 24, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Triple Helix (TH) of bi- and trilateral relations among universities,
industries, and governments can be considered as an ecosystem in which
uncertainty can be reduced auto-catalytically. The correlations among the
distributions of relations span a vector space in which two vectors (P and Q)
represent &quot;sending&quot; and &quot;receiving,&quot; respectively. These vectors can also be
understood in terms of the generation versus reduction of uncertainty in the
communication field that results from interactions among the three (bi-lateral)
communication channels. We specify a set of Lotka-Volterra equations between
the vectors that can be solved. Redundancy generation can then be simulated and
the results can be decomposed in terms of the TH components. Among other
things, we show that the strength and frequency of the relations are
independent parameters. Different components in terms of frequencies in
triple-helix systems can also be distinguished and interpreted using Fourier
analysis of the empirical time-series. The case of co-authorship relations in
Japan is analyzed as an empirical example; but &quot;triple contingencies&quot; in an
ecosystem of relations can also be considered more generally as a model for
redundancy generation by providing meaning to the (Shannon-type) information in
inter-human communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3839</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3839</id><created>2013-08-18</created><updated>2013-12-30</updated><authors><author><keyname>Chowdhury</keyname><forenames>Tamal</forenames></author><author><keyname>Rakshit</keyname><forenames>Rabindra</forenames></author><author><keyname>Banerjee</keyname><forenames>Arko</forenames></author></authors><title>Consensus Sequence Segmentation</title><categories>cs.CL</categories><comments>This paper has been withdrawn by the authors. The paper has been
  withdrawn due to error data input in table no. 1</comments><msc-class>68T10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a method to detect words or phrases in a given
sequence of alphabets without knowing the lexicon. Our linear time unsupervised
algorithm relies entirely on statistical relationships among alphabets in the
input sequence to detect location of word boundaries. We compare our algorithm
to previous approaches from unsupervised sequence segmentation literature and
provide superior segmentation over number of benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3842</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3842</id><created>2013-08-18</created><authors><author><keyname>Bai</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Shami</keyname><forenames>Abdallah</forenames></author></authors><title>Modeling Self-Similar Traffic for Network Simulation</title><categories>cs.NI</categories><comments>Self-Similar Traffic</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to closely simulate the real network scenario thereby verify the
effectiveness of protocol designs, it is necessary to model the traffic flows
carried over realistic networks. Extensive studies [1] showed that the actual
traffic in access and local area networks (e.g., those generated by ftp and
video streams) exhibits the property of self-similarity and long-range
dependency (LRD) [2]. In this appendix we briefly introduce the property of
self-similarity and suggest a practical approach for modeling self-similar
traces with specified traffic intensity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3846</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3846</id><created>2013-08-18</created><authors><author><keyname>Kim</keyname><forenames>Kyeong Soo</forenames></author></authors><title>Asynchronous Source Clock Frequency Recovery through Aperiodic Packet
  Streams</title><categories>cs.NI</categories><journal-ref>IEEE Communications Letters, vol. 17, no. 7, pp. 1455-1458, Jul.
  2013</journal-ref><doi>10.1109/LCOMM.2013.052413.130827</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the most general case of source clock frequency recovery (SCFR)
in packet networks, i.e., asynchronous SCFR through aperiodic packet streams,
where there is neither a common reference clock nor any relation between packet
generation intervals and a source clock frequency. We formulate the problem of
asynchronous SCFR with timestamps as a linear case of regression through the
origin (RTO) and propose two schemes, one based on recursive least squares
(RLS) method and the other based on simple heuristics of cumulative ratio of
interarrival and interdeparture times, which provide better estimates of the
source clock frequency with faster convergence than conventional phase-locked
loop (PLL)-based schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3847</identifier>
 <datestamp>2015-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3847</id><created>2013-08-18</created><updated>2015-07-31</updated><authors><author><keyname>Bagnara</keyname><forenames>Roberto</forenames></author><author><keyname>Carlier</keyname><forenames>Matthieu</forenames></author><author><keyname>Gori</keyname><forenames>Roberta</forenames></author><author><keyname>Gotlieb</keyname><forenames>Arnaud</forenames></author></authors><title>Exploiting Binary Floating-Point Representations for Constraint
  Propagation: The Complete Unabridged Version</title><categories>cs.AI cs.SE</categories><comments>51 pages, 3 figures, 1 table, 1 listing</comments><acm-class>D.2.4; D.2.5; I.2.2; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Floating-point computations are quickly finding their way in the design of
safety- and mission-critical systems, despite the fact that designing
floating-point algorithms is significantly more difficult than designing
integer algorithms. For this reason, verification and validation of
floating-point computations is a hot research topic. An important verification
technique, especially in some industrial sectors, is testing. However,
generating test data for floating-point intensive programs proved to be a
challenging problem. Existing approaches usually resort to random or
search-based test data generation, but without symbolic reasoning it is almost
impossible to generate test inputs that execute complex paths controlled by
floating-point computations. Moreover, as constraint solvers over the reals or
the rationals do not natively support the handling of rounding errors, the need
arises for efficient constraint solvers over floating-point domains. In this
paper, we present and fully justify improved algorithms for the propagation of
arithmetic IEEE 754 binary floating-point constraints. The key point of these
algorithms is a generalization of an idea by B. Marre and C. Michel that
exploits a property of the representation of floating-point numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3849</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3849</id><created>2013-08-18</created><updated>2014-06-03</updated><authors><author><keyname>Kim</keyname><forenames>Kyeong Soo</forenames></author></authors><title>The Effect of ISP Traffic Shaping on User-Perceived Performances in
  Broadband Shared Access Networks</title><categories>cs.NI stat.AP</categories><comments>39 pages, 12 figures, accepted for publication in the Computer
  Networks, Jun. 1, 2014</comments><journal-ref>Computer Networks, vol. 70, pp. 192-209, Sep. 2014</journal-ref><doi>10.1016/j.comnet.2014.06.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies on the practice of shaping subscribers' traffic by ISPs give a
new insight into the actual performance of broadband access networks at a
packet level. Unlike metro and backbone networks, however, access networks
directly interface with end-users, so it is important to base the study and
design of access networks on the behaviors of and the actual performance
perceived by end-users. In this paper we study the effect of ISP traffic
shaping using traffic models based on user behaviors and
application/session-layer metrics providing quantifiable measures of
user-perceived performance for HTTP, FTP, and streaming video traffic. To
compare the user-perceived performance of shaped traffic flows with those of
unshaped ones in an integrated way, we use a multivariate non-inferiority
testing procedure. We first investigate the effect of the token generation rate
and the token bucket size of a token bucket filter on user-perceived
performance at a subscriber level with a single subscriber. Then we investigate
their effect at an access level where shaped traffic flows from multiple
subscribers interact with one another in a common shared access network. The
simulation results show that for a given token generation rate, a larger token
bucket provides better user-perceived performance at both subscriber and access
levels. It is also shown that the loose burst control resulting from the large
token bucket --- up to 100 MB for access line rate of 100 Mbit/s --- does not
negatively affect user-perceived performance with multiple subscribers even in
the presence of non-conformant subscribers; with a much larger token bucket,
however, the negative effect of non-conformant subscribers on the
user-perceived performance of conformant subscribers becomes clearly visible
because the impact of token bucket size and that of token generation rate are
virtually indistinguishable in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3855</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3855</id><created>2013-08-18</created><authors><author><keyname>Bachorek</keyname><forenames>Adam</forenames></author><author><keyname>Palanisamy</keyname><forenames>Bagavathiannan</forenames></author><author><keyname>Schmitt</keyname><forenames>Jens B.</forenames></author></authors><title>Measurement and Prediction of Centrical/Peripheral Network Properties
  based on Regression Analysis - A Parametric Foundation for Performance
  Self-Management in WSNs</title><categories>cs.PF cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting performance-related behavior of the underlying network structure
becomes more and more indispensable in terms of the aspired application outcome
quality. However, the reliable forecast of QoS metrics like packet transfer
delay in wireless network systems is still a challenging task. Even though
existing approaches are technically capable of determining such network
properties under certain assumptions, they mostly abstract away from primal
aspects that inherently have an essential impact on temporal network
performance dynamics. Also, they usually require auxiliary resources to be
implemented and deployed along with the actual network components. In the
course of developing a lightweight measurement-based alternative for the
self-inspection and prediction of volatile performance characteristics in
environments of any kind, we selectively investigate the duration of message
delivery and packet loss rate against various parameters peculiar to common
radio network technologies like Wireless Sensor Networks (WSNs). Our hands-on
experiments reveal the relations between the oftentimes underestimated medium
access delay and a variety of main influencing factors including packet size,
backoff period, and number of neighbor nodes contending for the communication
medium. A closed formulation of selected weighted drivers facilitates the
average-case prediction of inter-node packet transfer delays for arbitrary
configurations of given network parameters even on resource-scarce WSN devices.
We validate our prediction method against basic multi-hop networking scenarios.
Yield field test results proof the basic feasibility and high precision of our
approach to network property estimation in virtue of self-governed local
measurements and regression-based calculations paving the way for a prospective
self-management of network properties based upon autonomous distributed
coordination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3860</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3860</id><created>2013-08-18</created><updated>2014-04-21</updated><authors><author><keyname>Derksen</keyname><forenames>Harm</forenames></author></authors><title>On the Nuclear Norm and the Singular Value Decomposition of Tensors</title><categories>math.OC cs.NA math.NA math.SP</categories><msc-class>15A69, 15A18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the rank of a tensor is a problem that has many applications.
Unfortunately it is often very difficult to determine the rank of a given
tensor. Inspired by the heuristics of convex relaxation, we consider the
nuclear norm instead of the rank of a tensor. We determine the nuclear norm of
various tensors of interest. Along the way, we also do a systematic study
various measures of orthogonality in tensor product spaces and we give a new
generalization of the Singular Value Decomposition to higher order tensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3872</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3872</id><created>2013-08-18</created><authors><author><keyname>Sun</keyname><forenames>Jian</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Deng</keyname><forenames>Junhui</forenames></author><author><keyname>Gao</keyname><forenames>Jie</forenames></author><author><keyname>Gu</keyname><forenames>Xianfeng</forenames></author><author><keyname>Luo</keyname><forenames>Feng</forenames></author></authors><title>A Variational Principle for Improving 2D Triangle Meshes based on
  Hyperbolic Volume</title><categories>cs.CG</categories><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of improving 2D triangle meshes
tessellating planar regions. We propose a new variational principle for
improving 2D triangle meshes where the energy functional is a convex function
over the angle structures whose maximizer is unique and consists only of
equilateral triangles. This energy functional is related to hyperbolic volume
of ideal 3-simplex. Even with extra constraints on the angles for embedding the
mesh into the plane and preserving the boundary, the energy functional remains
well-behaved. We devise an efficient algorithm for maximizing the energy
functional over these extra constraints. We apply our algorithm to various
datasets and compare its performance with that of CVT. The experimental results
show that our algorithm produces the meshes with both the angles and the aspect
ratios of triangles lying in tighter intervals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3874</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3874</id><created>2013-08-18</created><authors><author><keyname>Hegde</keyname><forenames>Manu S</forenames></author><author><keyname>Singh</keyname><forenames>Sanjay</forenames></author></authors><title>Alert-BDI: BDI Model with Adaptive Alertness through Situational
  Awareness</title><categories>cs.MA</categories><comments>14 pages, 3 figures. Submitted to ICACCI 2013, Mysore, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problems faced by a group of agents that
possess situational awareness, but lack a security mechanism, by the
introduction of a adaptive risk management system. The Belief-Desire-Intention
(BDI) architecture lacks a framework that would facilitate an adaptive risk
management system that uses the situational awareness of the agents. We extend
the BDI architecture with the concept of adaptive alertness. Agents can modify
their level of alertness by monitoring the risks faced by them and by their
peers. Alert-BDI enables the agents to detect and assess the risks faced by
them in an efficient manner, thereby increasing operational efficiency and
resistance against attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3876</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3876</id><created>2013-08-18</created><authors><author><keyname>HK</keyname><forenames>Jnanamurthy</forenames></author><author><keyname>Singh</keyname><forenames>Sanjay</forenames></author></authors><title>Detection and Filtering of Collaborative Malicious Users in Reputation
  System using Quality Repository Approach</title><categories>cs.SI cs.IR physics.soc-ph</categories><comments>14 pages, 5 figures, 5 tables, submitted to ICACCI 2013, Mysore,
  india</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online reputation system is gaining popularity as it helps a user to be sure
about the quality of a product/service he wants to buy. Nonetheless online
reputation system is not immune from attack. Dealing with malicious ratings in
reputation systems has been recognized as an important but difficult task. This
problem is challenging when the number of true user's ratings is relatively
small and unfair ratings plays majority in rated values. In this paper, we have
proposed a new method to find malicious users in online reputation systems
using Quality Repository Approach (QRA). We mainly concentrated on anomaly
detection in both rating values and the malicious users. QRA is very efficient
to detect malicious user ratings and aggregate true ratings. The proposed
reputation system has been evaluated through simulations and it is concluded
that the QRA based system significantly reduces the impact of unfair ratings
and improve trust on reputation score with lower false positive as compared to
other method used for the purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3881</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3881</id><created>2013-08-18</created><updated>2014-12-23</updated><authors><author><keyname>Kreuzer</keyname><forenames>Alexander P.</forenames><affiliation>National University of Singapore</affiliation></author></authors><title>Bounded variation and the strength of Helly's selection theorem</title><categories>math.LO cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 10, Issue 4 (December
  24, 2014) lmcs:980</journal-ref><doi>10.2168/LMCS-10(4:16)2014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the strength of Helly's selection theorem HST, which is the most
important compactness theorem on the space of functions of bounded variation.
For this we utilize a new representation of this space intermediate between
$L_1$ and the Sobolev space W1,1, compatible with the, so called, weak*
topology. We obtain that HST is instance-wise equivalent to the
Bolzano-Weierstra\ss\ principle over RCA0. With this HST is equivalent to ACA0
over RCA0. A similar classification is obtained in the Weihrauch lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3885</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3885</id><created>2013-08-18</created><authors><author><keyname>Bhorkar</keyname><forenames>Abhijeet</forenames></author><author><keyname>Bhanage</keyname><forenames>Gautam</forenames></author></authors><title>Reliable multicast in large enterprise networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we have presented a complete end-end architecture to employ the
rate-less codes. We have developed a new architecture Rate-less Codes Multicast
(RCNC). This architecture is shown to provide high throughput gains,
reliability and near optimal throughput performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3892</identifier>
 <datestamp>2014-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3892</id><created>2013-08-18</created><updated>2014-03-31</updated><authors><author><keyname>Kondor</keyname><forenames>D&#xe1;niel</forenames></author><author><keyname>P&#xf3;sfai</keyname><forenames>M&#xe1;rton</forenames></author><author><keyname>Csabai</keyname><forenames>Istv&#xe1;n</forenames></author><author><keyname>Vattay</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Do the rich get richer? An empirical analysis of the BitCoin transaction
  network</title><categories>physics.soc-ph cs.SI q-fin.GN</categories><comments>Project website: http://www.vo.elte.hu/bitcoin/; updated after
  publication</comments><journal-ref>PLoS ONE 9(2): e86197, 2014</journal-ref><doi>10.1371/journal.pone.0086197</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The possibility to analyze everyday monetary transactions is limited by the
scarcity of available data, as this kind of information is usually considered
highly sensitive. Present econophysics models are usually employed on presumed
random networks of interacting agents, and only macroscopic properties (e.g.
the resulting wealth distribution) are compared to real-world data. In this
paper, we analyze BitCoin, which is a novel digital currency system, where the
complete list of transactions is publicly available. Using this dataset, we
reconstruct the network of transactions, and extract the time and amount of
each payment. We analyze the structure of the transaction network by measuring
network characteristics over time, such as the degree distribution, degree
correlations and clustering. We find that linear preferential attachment drives
the growth of the network. We also study the dynamics taking place on the
transaction network, i.e. the flow of money. We measure temporal patterns and
the wealth accumulation. Investigating the microscopic statistics of money
movement, we find that sublinear preferential attachment governs the evolution
of the wealth distribution. We report a scaling relation between the degree and
wealth associated to individual nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3898</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3898</id><created>2013-08-18</created><authors><author><keyname>Yang</keyname><forenames>Xin-She</forenames></author><author><keyname>He</keyname><forenames>Xingshi</forenames></author></authors><title>Firefly Algorithm: Recent Advances and Applications</title><categories>math.OC cs.AI</categories><comments>15 pages</comments><msc-class>78M50</msc-class><journal-ref>Xin-She Yang and Xingshi He, (2013). `Firefly Algorithm: Recent
  Advances and Applications', Int. J. Swarm Intelligence, Vol. 1, No. 1, pp.
  36--50</journal-ref><doi>10.1504/IJSI.2013.055801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nature-inspired metaheuristic algorithms, especially those based on swarm
intelligence, have attracted much attention in the last ten years. Firefly
algorithm appeared in about five years ago, its literature has expanded
dramatically with diverse applications. In this paper, we will briefly review
the fundamentals of firefly algorithm together with a selection of recent
publications. Then, we discuss the optimality associated with balancing
exploration and exploitation, which is essential for all metaheuristic
algorithms. By comparing with intermittent search strategy, we conclude that
metaheuristics such as firefly algorithm are better than the optimal
intermittent search strategy. We also analyse algorithms and their implications
for higher-dimensional optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3900</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3900</id><created>2013-08-18</created><authors><author><keyname>Yang</keyname><forenames>Xin-She</forenames></author></authors><title>Bat Algorithm: Literature Review and Applications</title><categories>cs.AI math.OC</categories><comments>10 pages</comments><msc-class>90C26</msc-class><journal-ref>Xin-She Yang, Bat algorithm: literature review and applications,
  Int. J. Bio-Inspired Computation, Vol. 5, No.3, pp. 141--149 (2013)</journal-ref><doi>10.1504/IJBIC.2013.055093</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bat algorithm (BA) is a bio-inspired algorithm developed by Yang in 2010 and
BA has been found to be very efficient. As a result, the literature has
expanded significantly in the last 3 years. This paper provides a timely review
of the bat algorithm and its new variants. A wide range of diverse applications
and case studies are also reviewed and summarized briefly here. Further
research topics are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3916</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3916</id><created>2013-08-18</created><authors><author><keyname>Sanfelice</keyname><forenames>Ricardo G.</forenames></author><author><keyname>Prieur</keyname><forenames>Christophe</forenames></author></authors><title>Robust Supervisory Control for Uniting Two Output-Feedback Hybrid
  Controllers with Different Objectives</title><categories>cs.SY</categories><comments>Version published in Automatica, 21 pages, 5 figures</comments><journal-ref>Automatica, 2013, 49, 1958-1969</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of robustly, asymptotically stabilizing a point (or a set) with
two output-feedback hybrid controllers is considered. These control laws may
have different objectives, e.g., the closed-loop systems resulting with each
controller may have different attractors. We provide a control algorithm that
combines the two hybrid controllers to accomplish the stabilization task. The
algorithm consists of a hybrid supervisor that, based on the values of plant's
outputs and (norm) state estimates, selects the hybrid controller that should
be applied to the plant. The accomplishment of the stabilization task relies on
an output-to-state stability property induced by the controllers, which enables
the construction of an estimator for the norm of the plant's state. The
algorithm is motivated by and applied to robust, semi-global stabilization
problems uniting two controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3917</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3917</id><created>2013-08-18</created><authors><author><keyname>Sun</keyname><forenames>Feng</forenames></author><author><keyname>Choi</keyname><forenames>Yi-King</forenames></author><author><keyname>Yu</keyname><forenames>Yizhou</forenames></author><author><keyname>Wang</keyname><forenames>Wenping</forenames></author></authors><title>Medial Meshes for Volume Approximation</title><categories>cs.GR</categories><comments>12 pages, 14 figures</comments><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Volume approximation is an important problem found in many applications of
computer graphics, vision, and image processing. The problem is about computing
an accurate and compact approximate representation of 3D volumes using some
simple primitives. In this study, we propose a new volume representation,
called medial meshes, and present an efficient method for its computation.
Specifically, we use the union of a novel type of simple volume primitives,
which are spheres and the convex hulls of two or three spheres, to approximate
a given 3D shape. We compute such a volume approximation based on a new method
for medial axis simplification guided by Hausdorff errors. We further
demonstrate the superior efficiency and accuracy of our method over existing
methods for medial axis simplification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3923</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3923</id><created>2013-08-19</created><updated>2013-09-10</updated><authors><author><keyname>Drescher</keyname><forenames>Christian</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Efficient Approximation of Well-Founded Justification and Well-Founded
  Domination (Corrected and Extended Version)</title><categories>cs.LO</categories><comments>12th International Conference on Logic Programming and Nonmonotonic
  Reasoning; Corrected and Extended Version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many native ASP solvers exploit unfounded sets to compute consequences of a
logic program via some form of well-founded negation, but disregard its
contrapositive, well-founded justification (WFJ), due to computational cost.
However, we demonstrate that this can hinder propagation of many relevant
conditions such as reachability. In order to perform WFJ with low computational
cost, we devise a method that approximates its consequences by computing
dominators in a flowgraph, a problem for which linear-time algorithms exist.
Furthermore, our method allows for additional unfounded set inference, called
well-founded domination (WFD). We show that the effect of WFJ and WFD can be
simulated for a important classes of logic programs that include reachability.
This paper is a corrected and extended version of a paper published at the 12th
International Conference on Logic Programming and Nonmonotonic Reasoning (LPNMR
2013). It has been adapted to exclude Theorem 10 and its consequences, but
provides all missing proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3924</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3924</id><created>2013-08-19</created><authors><author><keyname>Tyapchenko</keyname><forenames>Yury A.</forenames></author></authors><title>Analysis and Synthesis of a Subsystem of the Manual Control Loop for
  Manned Spacecraft</title><categories>cs.HC</categories><comments>13 pages, 10 figures. Translation from Russian by Dmitri E. Nikonov</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A salient feature of the manned spacecraft is the predominance of discrete
information in the manual control loop of the onboard systems. Specifically,
command-signaling control panels (CSCP) as a subsystem of the manual control
loop are widely used in the Russian manned spacecraft. In this paper CSCP are
classified into four types: a) control panels based on multi-channel control;
b) control panels based on command-information compression; c) control panels
based on command and signaling information compression; d) integrated control
consoles (ICC) based on computer and information technology. It is shown that
ICC underlies modern information display systems (IDS). ICC first appeared in
the Russian manned space program in the IDS of the Soyuz-TMA spacecraft and the
Russian modules of the International Space Station. Results of engineering and
psychological studies of different types of panels are produced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3937</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3937</id><created>2013-08-19</created><authors><author><keyname>Codish</keyname><forenames>Michael</forenames></author><author><keyname>Fekete</keyname><forenames>Yoav</forenames></author><author><keyname>Metodi</keyname><forenames>Amit</forenames></author></authors><title>Compiling Finite Domain Constraints to SAT with BEE: the Director's Cut</title><categories>cs.PL</categories><comments>Part of WLPE 2013 proceedings (arXiv:1308.2055)</comments><report-no>WLPE/2013/1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BEE is a compiler which facilitates solving finite domain constraints by
encoding them to CNF and applying an underlying SAT solver. In BEE constraints
are modeled as Boolean functions which propagate information about equalities
between Boolean literals. This information is then applied to simplify the CNF
encoding of the constraints. We term this process equi-propagation. A key
factor is that considering only a small fragment of a constraint model at one
time enables to apply stronger, and even complete reasoning to detect
equivalent literals in that fragment. Once detected, equivalences propagate to
simplify the entire constraint model and facilitate further reasoning on other
fragments. BEE is described in several recent papers. In this paper, after a
quick review of BEE, we elaborate on two undocumented details of the
implementation: the hybrid encoding of cardinality constraints and complete
equi-propagation. We thendescribe on-going work aimed to extend BEE to consider
binary representation of numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3938</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3938</id><created>2013-08-19</created><authors><author><keyname>Hadjichristodoulou</keyname><forenames>Spyros</forenames></author><author><keyname>Porter</keyname><forenames>Donald E.</forenames></author><author><keyname>Warren</keyname><forenames>David S.</forenames></author></authors><title>Efficiently Retrieving Function Dependencies in the Linux Kernel Using
  XSB</title><categories>cs.PL</categories><comments>Part of WLPE 2013 proceedings (arXiv:1308.2055)</comments><report-no>WLPE/2013/3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate XSB-Prolog as a static analysis engine for data
represented by medium-sized graphs. We use XSB-Prolog to automatically identify
function dependencies in the Linux Kernel---queries that are difficult to
implement efficiently in a commodity database and that developers often have to
identify manually. This project illustrates that Prolog systems are ideal for
building tools for use in other disciplines that require sophisticated
inferences, because Prolog is both declarative and can efficiently implement
complex problem specifications through tabling and indexing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3939</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3939</id><created>2013-08-19</created><authors><author><keyname>Ivanovi&#x107;</keyname><forenames>Dragan</forenames></author></authors><title>Implementing Constraint Handling Rules as a Domain-Specific Language
  Embedded in Java</title><categories>cs.PL</categories><comments>Part of WLPE 2013 proceedings (arXiv:1308.2055)</comments><report-no>WLPE/2013/4</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Programming languages and techniques based on logic and constraints, such as
the Constraint Handling Rules (CHR), can support many common programming tasks
that can be expressed in the form of a search for feasible or optimal
solutions. Developing new constraint solvers using CHR is especially
interesting in configuration management for large scale, distributed and
dynamic cloud applications, where dynamic configuration and component selection
is an integral part of the programming environment. Writing CHR-style
constraint solvers in a domain-specific language which is a subset of Java --
instead of using a separate language layer -- solves many integration,
development cycle disruption, testing and debugging problems that discourage or
make difficult the adoption of the CHR-based approach in the mainstream
programming environments. Besides, the prototype implementation exposes a
well-defined API that supports transactional store behavior, safe termination,
and debugging via event notifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3940</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3940</id><created>2013-08-19</created><authors><author><keyname>Serrano</keyname><forenames>Alejandro</forenames></author><author><keyname>L&#xf3;pez-Garc&#xed;a</keyname><forenames>Pedro</forenames></author><author><keyname>Hermenegildo</keyname><forenames>Manuel</forenames></author></authors><title>Towards an Abstract Domain for Resource Analysis of Logic Programs Using
  Sized Types</title><categories>cs.PL</categories><comments>Part of WLPE 2013 proceedings (arXiv:1308.2055)</comments><report-no>WLPE/2013/5</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel general resource analysis for logic programs based on
sized types.Sized types are representations that incorporate structural (shape)
information and allow expressing both lower and upper bounds on the size of a
set of terms and their subterms at any position and depth. They also allow
relating the sizes of terms and subterms occurring at different argument
positions in logic predicates. Using these sized types, the resource analysis
can infer both lower and upper bounds on the resources used by all the
procedures in a program as functions on input term (and subterm) sizes,
overcoming limitations of existing analyses and enhancing their precision. Our
new resource analysis has been developed within the abstract interpretation
framework, as an extension of the sized types abstract domain, and has been
integrated into the Ciao preprocessor, CiaoPP. The abstract domain operations
are integrated with the setting up and solving of recurrence equations for
both, inferring size and resource usage functions. We show that the analysis is
an improvement over the previous resource analysis present in CiaoPP and
compares well in power to state of the art systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3941</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3941</id><created>2013-08-19</created><authors><author><keyname>Wielemaker</keyname><forenames>Jan</forenames></author><author><keyname>Hendricks</keyname><forenames>Michael</forenames></author></authors><title>Why It's Nice to be Quoted: Quasiquoting for Prolog</title><categories>cs.PL</categories><comments>Part of WLPE 2013 proceedings (arXiv:1308.2055)</comments><report-no>WLPE/2013/7</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prolog's support for dynamic programming, meta programming and text
processing using context free grammars make the language highly suitable for
defining domain specific languages (DSL) as well as analysing, refactoring or
generating expression states in other (programming) languages. Well known DSLs
are the DCG (Definite Clause Grammar) notation and constraint languages such as
CHR. These extensions use Prolog operator declarations and the {...} notation
to realise a good syntax. When external languages, such as HTML, SQL or
JavaScript enter the picture, operators no longer satisfy for embedding
snippets of these languages into a Prolog source file. In addition, Prolog has
poor support for quoting long text fragments.
  Haskell introduced quasi quotationsto resolve this problem. In this paper we
`ported' the Haskell mechanism for quasi quoting to Prolog. We show that this
can be done cleanly and that quasi quoting can solve the above mentioned
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3946</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3946</id><created>2013-08-19</created><authors><author><keyname>Chan</keyname><forenames>Siu-On</forenames></author><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Valiant</keyname><forenames>Gregory</forenames></author><author><keyname>Valiant</keyname><forenames>Paul</forenames></author></authors><title>Optimal Algorithms for Testing Closeness of Discrete Distributions</title><categories>cs.DS cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the question of closeness testing for two discrete distributions.
More precisely, given samples from two distributions $p$ and $q$ over an
$n$-element set, we wish to distinguish whether $p=q$ versus $p$ is at least
$\eps$-far from $q$, in either $\ell_1$ or $\ell_2$ distance. Batu et al. gave
the first sub-linear time algorithms for these problems, which matched the
lower bounds of Valiant up to a logarithmic factor in $n$, and a polynomial
factor of $\eps.$
  In this work, we present simple (and new) testers for both the $\ell_1$ and
$\ell_2$ settings, with sample complexity that is information-theoretically
optimal, to constant factors, both in the dependence on $n$, and the dependence
on $\eps$; for the $\ell_1$ testing problem we establish that the sample
complexity is $\Theta(\max\{n^{2/3}/\eps^{4/3}, n^{1/2}/\eps^2 \}).$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3956</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3956</id><created>2013-08-19</created><updated>2014-07-31</updated><authors><author><keyname>Yu</keyname><forenames>Jingjin</forenames></author><author><keyname>Chung</keyname><forenames>Soon-Jo</forenames></author><author><keyname>Voulgaris</keyname><forenames>Petros G.</forenames></author></authors><title>Target Assignment in Robotic Networks: Distance Optimality Guarantees
  and Hierarchical Strategies</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of multi-robot target assignment to minimize the total
distance traveled by the robots until they all reach an equal number of static
targets. In the first half of the paper, we present a necessary and sufficient
condition under which true distance optimality can be achieved for robots with
limited communication and target-sensing ranges. Moreover, we provide an
explicit, non-asymptotic formula for computing the number of robots needed to
achieve distance optimality in terms of the robots' communication and
target-sensing ranges with arbitrary guaranteed probabilities. The same bounds
are also shown to be asymptotically tight.
  In the second half of the paper, we present suboptimal strategies for use
when the number of robots cannot be chosen freely. Assuming first that all
targets are known to all robots, we employ a hierarchical communication model
in which robots communicate only with other robots in the same partitioned
region. This hierarchical communication model leads to constant approximations
of true distance-optimal solutions under mild assumptions. We then revisit the
limited communication and sensing models. By combining simple rendezvous-based
strategies with a hierarchical communication model, we obtain decentralized
hierarchical strategies that achieve constant approximation ratios with respect
to true distance optimality. Results of simulation show that the approximation
ratio is as low as 1.4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3957</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3957</id><created>2013-08-19</created><authors><author><keyname>Takeuchi</keyname><forenames>Keigo</forenames></author><author><keyname>Horio</keyname><forenames>Shuhei</forenames></author></authors><title>Iterative Multiuser Detection and Decoding with Spatially Coupled
  Interleaving</title><categories>cs.IT math.IT</categories><comments>Long version of a paper submitted to IEEE Wireless Commun. Lett</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatially coupled (SC) interleaving is proposed to improve the performance of
iterative multiuser detection and decoding (MUDD) for quasi-static fading
multiple-input multiple-output systems. The linear minimum mean-squared error
(LMMSE) demodulator is used to reduce the complexity and to avoid error
propagation. Furthermore, sliding window MUDD is proposed to circumvent an
increase of the decoding latency due to SC interleaving. Theoretical and
numerical analyses show that SC interleaving can improve the performance of the
iterative LMMSE MUDD for regular low-density parity-check codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3985</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3985</id><created>2013-08-19</created><authors><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author></authors><title>Remarks on criteria for achieving the optimal diversity-multiplexing
  gain trade-off</title><categories>cs.IT math.IT</categories><comments>This is a rough draft and includes some misprints etc. Please contact
  me if you disagree with the result</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short note we will prove that non-vanishing determinant (NVD)
criterion is not enough for an asymmetric space-time block code (STBC) to
achieve the optimal diversity-multiplexing gain trade-off (DMT). This result is
in contrast to the recent result made by Srinath and Rajan. In order to clarify
the issue further the approximately universality criterion by Tavildar and
Viswanath is translated into language of lattice theory and some conjectures
are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3987</identifier>
 <datestamp>2014-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3987</id><created>2013-08-19</created><updated>2014-07-18</updated><authors><author><keyname>Chalopin</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author><author><keyname>Chepoi</keyname><forenames>Victor</forenames></author><author><keyname>Papasoglu</keyname><forenames>Panos</forenames></author><author><keyname>Pecatte</keyname><forenames>Timoth&#xe9;e</forenames></author></authors><title>Cop and robber game and hyperbolicity</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we prove that all cop-win graphs G in the game in which the
robber and the cop move at different speeds s and s' with s'&lt;s, are
\delta-hyperbolic with \delta=O(s^2). We also show that the dependency between
\delta and s is linear if s-s'=\Omega(s) and G obeys a slightly stronger
condition. This solves an open question from the paper (J. Chalopin et al., Cop
and robber games when the robber can hide and ride, SIAM J. Discr. Math. 25
(2011) 333-359). Since any \delta-hyperbolic graph is cop-win for s=2r and
s'=r+2\delta for any r&gt;0, this establishes a new - game-theoretical -
characterization of Gromov hyperbolicity. We also show that for weakly modular
graphs the dependency between \delta and s is linear for any s'&lt;s. Using these
results, we describe a simple constant-factor approximation of the
hyperbolicity \delta of a graph on n vertices in O(n^2) time when the graph is
given by its distance-matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3995</identifier>
 <datestamp>2014-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3995</id><created>2013-08-19</created><updated>2014-06-04</updated><authors><author><keyname>Woopen</keyname><forenames>Michael</forenames><affiliation>AICES, RWTH Aachen</affiliation></author><author><keyname>Balan</keyname><forenames>Aravind</forenames><affiliation>AICES, RWTH Aachen</affiliation></author><author><keyname>May</keyname><forenames>Georg</forenames><affiliation>AICES, RWTH Aachen</affiliation></author><author><keyname>Sch&#xfc;tz</keyname><forenames>Jochen</forenames><affiliation>IGPM, RWTH Aachen</affiliation></author></authors><title>A Comparison of Hybridized and Standard DG Methods for Target-Based
  hp-Adaptive Simulation of Compressible Flow</title><categories>cs.CE cs.NA math.NA</categories><journal-ref>Comp.Fluids 98 (2014) 3-16</journal-ref><doi>10.1016/j.compfluid.2014.03.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a comparison between hybridized and non-hybridized discontinuous
Galerkin methods in the context of target-based hp-adaptation for compressible
flow problems. The aim is to provide a critical assessment of the computational
efficiency of hybridized DG methods. Hybridization of finite element
discretizations has the main advantage, that the resulting set of algebraic
equations has globally coupled degrees of freedom only on the skeleton of the
computational mesh. Consequently, solving for these degrees of freedom involves
the solution of a potentially much smaller system. This not only reduces
storage requirements, but also allows for a faster solution with iterative
solvers. Using a discrete-adjoint approach, sensitivities with respect to
output functionals are computed to drive the adaptation. From the error
distribution given by the adjoint-based error estimator, h- or p-refinement is
chosen based on the smoothness of the solution which can be quantified by
properly-chosen smoothness indicators. Numerical results are shown for
subsonic, transonic, and supersonic flow around the NACA0012 airfoil.
hp-adaptation proves to be superior to pure h-adaptation if discontinuous or
singular flow features are involved. In all cases, a higher polynomial degree
turns out to be beneficial. We show that for polynomial degree of approximation
p=2 and higher, and for a broad range of test cases, HDG performs better than
DG in terms of runtime and memory requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.3996</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.3996</id><created>2013-08-19</created><updated>2013-09-20</updated><authors><author><keyname>Czerwi&#x144;ski</keyname><forenames>Wojciech</forenames><affiliation>Universit&#xe4;t Bayreuth</affiliation></author><author><keyname>Hofman</keyname><forenames>Piotr</forenames><affiliation>University of Warsaw</affiliation></author><author><keyname>Lasota</keyname><forenames>S&#x141;awomir</forenames><affiliation>University of Warsaw</affiliation></author></authors><title>Reachability Problem for Weak Multi-Pushdown Automata</title><categories>cs.LO cs.FL</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  11, 2013) lmcs:857</journal-ref><doi>10.2168/LMCS-9(3:13)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about reachability analysis in a restricted subclass of
multi-pushdown automata. We assume that the control states of an automaton are
partially ordered, and all transitions of an automaton go downwards with
respect to the order. We prove decidability of the reachability problem, and
computability of the backward reachability set. As the main contribution, we
identify relevant subclasses where the reachability problem becomes
NP-complete. This matches the complexity of the same problem for
communication-free vector addition systems, a special case of stateless
multi-pushdown automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4002</identifier>
 <datestamp>2013-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4002</id><created>2013-08-19</created><authors><author><keyname>Bagnoli</keyname><forenames>Franco</forenames></author><author><keyname>Rechtman</keyname><forenames>Raul</forenames></author></authors><title>Topological bifurcations in a model society of reasonable contrarians</title><categories>nlin.CG cs.SI nlin.CD physics.soc-ph</categories><journal-ref>Phys. Rev. E 88, 062914 (2013)</journal-ref><doi>10.1103/PhysRevE.88.062914</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People are often divided into conformists and contrarians, the former tending
to align to the majority opinion in their neighborhood and the latter tending
to disagree with that majority. In practice, however, the contrarian tendency
is rarely followed when there is an overwhelming majority with a given opinion,
which denotes a social norm. Such reasonable contrarian behavior is often
considered a mark of independent thought, and can be a useful strategy in
financial markets.
  We present the opinion dynamics of a society of reasonable contrarian agents.
The model is a cellular automaton of Ising type, with antiferromagnetic pair
interactions modeling contrarianism and plaquette terms modeling social norms.
We introduce the entropy of the collective variable as a way of comparing
deterministic (mean-field) and probabilistic (simulations) bifurcation
diagrams.
  In the mean field approximation the model exhibits bifurcations and a chaotic
phase, interpreted as coherent oscillations of the whole society. However, in a
one-dimensional spatial arrangement one observes incoherent oscillations and a
constant average.
  In simulations on Watts-Strogatz networks with a small-world effect the mean
field behavior is recovered, with a bifurcation diagram that resembles the
mean-field one, but using the rewiring probability as the control parameter.
Similar bifurcation diagrams are found for scale free networks, and we are able
to compute an effective connectivity for such networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4004</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4004</id><created>2013-08-19</created><authors><author><keyname>Borgwardt</keyname><forenames>Steffen</forenames></author><author><keyname>Brieden</keyname><forenames>Andreas</forenames></author><author><keyname>Gritzmann</keyname><forenames>Peter</forenames></author></authors><title>A balanced k-means algorithm for weighted point sets</title><categories>math.OC cs.LG stat.ML</categories><msc-class>91C20, 90C90, 68Q32, 90C46, 90C27, 52B12, 90C57</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical k-means algorithm for paritioning n points in R^d into k
subsets is one of the most popular and widely spread clustering methods in
scientific and business applications. The present paper gives a generalization
that is capable of handling weighted point sets and prescribed lower and upper
bounds on the cluster sizes. The new algorithm replaces the assignment step of
k-means by the computation of a weight-balanced least-squares assignment. This
is modelled as a linear program over a weight-balanced partition polytope whose
optimal vertices correspond to clusterings that allow strongly feasible power
diagrams. We use this correspondence to derive a worst-case upper bound n^O(dk)
for the number of operations. This is similar to the known upper bound for
k-means, polynomial for fixed k and d, and in view of the known complexity
results for k-means, essentially the best one can expect. Further, we show the
kernelizability of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4008</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4008</id><created>2013-08-19</created><authors><author><keyname>Jamil</keyname><forenames>Momin</forenames></author><author><keyname>Yang</keyname><forenames>Xin-She</forenames></author></authors><title>A Literature Survey of Benchmark Functions For Global Optimization
  Problems</title><categories>cs.AI math.OC</categories><comments>47 pages</comments><msc-class>90C26</msc-class><journal-ref>Momin Jamil and Xin-She Yang, A literature survey of benchmark
  functions for global optimization problems, Int. Journal of Mathematical
  Modelling and Numerical Optimisation}, Vol. 4, No. 2, pp. 150--194 (2013)</journal-ref><doi>10.1504/IJMMNO.2013.055204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Test functions are important to validate and compare the performance of
optimization algorithms. There have been many test or benchmark functions
reported in the literature; however, there is no standard list or set of
benchmark functions. Ideally, test functions should have diverse properties so
that can be truly useful to test new algorithms in an unbiased way. For this
purpose, we have reviewed and compiled a rich set of 175 benchmark functions
for unconstrained optimization problems with diverse properties in terms of
modality, separability, and valley landscape. This is by far the most complete
set of functions so far in the literature, and tt can be expected this complete
set of functions can be used for validation of new optimization in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4011</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4011</id><created>2013-08-19</created><authors><author><keyname>Napoli</keyname><forenames>Christian</forenames></author><author><keyname>Pappalardo</keyname><forenames>Giuseppe</forenames></author><author><keyname>Tramontana</keyname><forenames>Emiliano</forenames></author></authors><title>Using Modularity Metrics to assist Move Method Refactoring of Large
  System</title><categories>cs.SE cs.DC</categories><journal-ref>7th International Conference on Complex, Intelligent, and Software
  Intensive Systems (CISIS), pp. 529-534, 2013</journal-ref><doi>10.1109/CISIS.2013.96</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For large software systems, refactoring activities can be a challenging task,
since for keeping component complexity under control the overall architecture
as well as many details of each component have to be considered. Product
metrics are therefore often used to quantify several parameters related to the
modularity of a software system. This paper devises an approach for
automatically suggesting refactoring opportunities on large software systems.
We show that by assessing metrics for all components, move methods refactoring
an be suggested in such a way to improve modularity of several components at
once, without hindering any other. However, computing metrics for large
software systems, comprising thousands of classes or more, can be a time
consuming task when performed on a single CPU. For this, we propose a solution
that computes metrics by resorting to GPU, hence greatly shortening computation
time. Thanks to our approach precise knowledge on several properties of the
system can be continuously gathered while the system evolves, hence assisting
developers to quickly assess several solutions for reducing modularity issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4013</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4013</id><created>2013-08-19</created><updated>2013-09-13</updated><authors><author><keyname>Singla</keyname><forenames>Adish</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Incentives for Privacy Tradeoff in Community Sensing</title><categories>cs.GT cs.AI</categories><comments>Extended version of paper to appear in HCOMP'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community sensing, fusing information from populations of privately-held
sensors, presents a great opportunity to create efficient and cost-effective
sensing applications. Yet, reasonable privacy concerns often limit the access
to such data streams. How should systems valuate and negotiate access to
private information, for example in return for monetary incentives? How should
they optimally choose the participants from a large population of strategic
users with privacy concerns, and compensate them for information shared? In
this paper, we address these questions and present a novel mechanism,
SeqTGreedy, for budgeted recruitment of participants in community sensing. We
first show that privacy tradeoffs in community sensing can be cast as an
adaptive submodular optimization problem. We then design a budget feasible,
incentive compatible (truthful) mechanism for adaptive submodular maximization,
which achieves near-optimal utility for a large class of sensing applications.
This mechanism is general, and of independent interest. We demonstrate the
effectiveness of our approach in a case study of air quality monitoring, using
data collected from the Mechanical Turk platform. Compared to the state of the
art, our approach achieves up to 30% reduction in cost in order to achieve a
desired level of utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4014</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4014</id><created>2013-08-19</created><updated>2014-02-10</updated><authors><author><keyname>Sun</keyname><forenames>Ye</forenames></author><author><keyname>Liu</keyname><forenames>Chuang</forenames></author><author><keyname>Zhang</keyname><forenames>Chu-Xu</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author></authors><title>Epidemic Spreading on Weighted Complex Networks</title><categories>physics.soc-ph cs.SI</categories><doi>10.1016/j.physleta.2014.01.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the emergence of online services provides various multi-relation
information to support the comprehensive understanding of the epidemic
spreading process. In this Letter, we consider the edge weights to represent
such multi-role relations. In addition, we perform detailed analysis of two
representative metrics, outbreak threshold and epidemic prevalence, on SIS and
SIR models. Both theoretical and simulation results find good agreements with
each other. Furthermore, experiments show that, on fully mixed networks, the
weight distribution on edges would not affect the epidemic results once the
average weight of whole network is fixed. This work may shed some light on the
in-depth understanding of epidemic spreading on multi-relation and weighted
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4017</identifier>
 <datestamp>2014-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4017</id><created>2013-08-19</created><updated>2014-04-14</updated><authors><author><keyname>Abibullaev</keyname><forenames>Berdakh</forenames></author><author><keyname>An</keyname><forenames>Jinung</forenames></author><author><keyname>Lee</keyname><forenames>Seung-Hyun</forenames></author><author><keyname>Moon</keyname><forenames>Jeon-Il</forenames></author></authors><title>A Study on Stroke Rehabilitation through Task-Oriented Control of a
  Haptic Device via Near-Infrared Spectroscopy-Based BCI</title><categories>stat.ML cs.HC q-bio.NC</categories><comments>13 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a study in task-oriented approach to stroke
rehabilitation by controlling a haptic device via near-infrared
spectroscopy-based brain-computer interface (BCI). The task is to command the
haptic device to move in opposing directions of leftward and rightward
movement. Our study consists of data acquisition, signal preprocessing, and
classification. In data acquisition, we conduct experiments based on two
different mental tasks: one on pure motor imagery, and another on combined
motor imagery and action observation. The experiments were conducted in both
offline and online modes. In the signal preprocessing, we use localization
method to eliminate channels that are irrelevant to the mental task, as well as
perform feature extraction for subsequent classification. We propose multiple
support vector machine classifiers with a majority-voting scheme for improved
classification results. And lastly, we present test results to demonstrate the
efficacy of our proposed approach to possible stroke rehabilitation practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4027</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4027</id><created>2013-08-19</created><updated>2014-08-13</updated><authors><author><keyname>Chirkova</keyname><forenames>Rada</forenames></author></authors><title>Combined-Semantics Equivalence Is Decidable for a Practical Class of
  Conjunctive Queries</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the problem of determining whether two conjunctive
(&quot;CQ&quot;) queries posed on relational data are combined-semantics equivalent [9].
We continue the tradition of [2,5,9] of studying this problem using the tool of
containment between queries. We introduce a syntactic necessary and sufficient
condition for equivalence of queries belonging to a large natural language of
&quot;explicit-wave&quot; combined-semantics CQ queries; this language encompasses (but
is not limited to) all set, bag, and bag-set queries, and appears to cover all
combined-semantics CQ queries that are expressible in SQL. Our result solves in
the positive the decidability problem of determining combined-semantics
equivalence for pairs of explicit-wave CQ queries. That is, for an arbitrary
pair of combined-semantics CQ queries, it is decidable (i) to determine whether
each of the queries is explicit wave, and (ii) to determine, in case both
queries are explicit wave, whether or not they are combined-semantics
equivalent, by using our syntactic criterion. (The problem of determining
equivalence for general combined-semantics CQ queries remains open. Even so,
our syntactic sufficient containment condition could still be used to determine
that two general CQ queries are combined-semantics equivalent.) Our equivalence
test, as well as our general sufficient condition for containment of
combined-semantics CQ queries, reduce correctly to the special cases reported
in [2,5] for set, bag, and bag-set semantics. Our containment and equivalence
conditions also properly generalize the results of [9], provided that the
latter are restricted to the language of (combined-semantics) CQ queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4045</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4045</id><created>2013-08-19</created><authors><author><keyname>Bardin</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Kosmatov</keyname><forenames>Nikolai</forenames></author><author><keyname>Cheynier</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Efficient Leverage of Symbolic ATG Tools to Advanced Coverage Criteria</title><categories>cs.SE</categories><acm-class>D.2.5; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic test data generation (ATG) is a major topic in software
engineering. In this paper, we seek to bridge the gap between the coverage
criteria supported by symbolic ATG tools and the most advanced coverage
criteria found in the literature. We define a new testing criterion, label
coverage, and prove it to be both expressive and amenable to efficient
automation. We propose several innovative techniques resulting in an effective
black-box support for label coverage, while a direct approach induces an
exponential blow-up of the search space. Initial experiments show that ATG for
label coverage can be achieved at a reasonable cost and that our optimisations
yield very significant savings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4048</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4048</id><created>2013-08-19</created><authors><author><keyname>Laxmaiah</keyname><forenames>M.</forenames><affiliation>Tirumala Engineering College, Keesara</affiliation></author><author><keyname>Govardhan</keyname><forenames>A.</forenames><affiliation>School of Information Technology, Jawaharlal Nehru Technological University, Hyderabad, AP, India</affiliation></author></authors><title>Gcube Indexing</title><categories>cs.DB</categories><comments>This paper is published in IJDKP</comments><report-no>ISSN 2230-9608</report-no><journal-ref>International Journal of Data Mining &amp; Knowledge Management
  Process, Vol.3,Number 4,July 2013</journal-ref><doi>10.5121/ijdkp.2013.3406</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Spatial Online Analytical Processing System involves the non-categorical
attribute information also whereas standard Online Analytical Processing System
deals with only categorical attributes. Providing spatial information to the
data warehouse (DW); two major challenges faced are;1.Defining and Aggregation
of Spatial/Continues values and 2.Representation, indexing, updating and
efficient query processing. In this paper, we present GCUBE(Geographical Cube)
storage and indexing procedure to aggregate the spatial information/Continuous
values. We employed the proposed approach storing and indexing using synthetic
and real data sets and evaluated its build, update and Query time. It is
observed that the proposed procedure offers significant performance advantage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4049</identifier>
 <datestamp>2014-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4049</id><created>2013-08-19</created><updated>2014-11-18</updated><authors><author><keyname>Ostrovski</keyname><forenames>Georg</forenames></author><author><keyname>van Strien</keyname><forenames>Sebastian</forenames></author></authors><title>Payoff Performance of Fictitious Play</title><categories>cs.GT math.DS</categories><comments>16 pages, 4 figures</comments><msc-class>91A26, 91A20, 91A05, 34A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate how well continuous-time fictitious play in two-player games
performs in terms of average payoff, particularly compared to Nash equilibrium
payoff. We show that in many games, fictitious play outperforms Nash
equilibrium on average or even at all times, and moreover that any game is
linearly equivalent to one in which this is the case. Conversely, we provide
conditions under which Nash equilibrium payoff dominates fictitious play
payoff. A key step in our analysis is to show that fictitious play dynamics
asymptotically converges the set of coarse correlated equilibria (a fact which
is implicit in the literature).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4064</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4064</id><created>2013-08-19</created><updated>2013-08-20</updated><authors><author><keyname>Kwanashie</keyname><forenames>Augustine</forenames></author><author><keyname>Manlove</keyname><forenames>David F.</forenames></author></authors><title>An Integer Programming Approach to the Hospital/Residents Problem with
  Ties</title><categories>cs.DS cs.CC math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical Hospitals/Residents problem (HR) models the assignment of
junior doctors to hospitals based on their preferences over one another. In an
instance of this problem, a stable matching M is sought which ensures that no
blocking pair can exist in which a resident r and hospital h can improve
relative to M by becoming assigned to each other. Such a situation is
undesirable as it could naturally lead to r and h forming a private arrangement
outside of the matching. The original HR model assumes that preference lists
are strictly ordered. However in practice, this may be an unreasonable
assumption: an agent may find two or more agents equally acceptable, giving
rise to ties in its preference list. We thus obtain the Hospitals/Residents
problem with Ties (HRT). In such an instance, stable matchings may have
different sizes and MAX HRT, the problem of finding a maximum cardinality
stable matching, is NP-hard. In this paper we describe an Integer Programming
(IP) model for MAX HRT. We also provide some details on the implementation of
the model. Finally we present results obtained from an empirical evaluation of
the IP model based on real-world and randomly generated problem instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4067</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4067</id><created>2013-08-19</created><authors><author><keyname>Brunson</keyname><forenames>Jason Cory</forenames></author></authors><title>The S-metric, the Beichl-Cloteaux approximation, and preferential
  attachment</title><categories>math.CO cs.SI physics.soc-ph</categories><comments>14 pages, 3 figures, 1 table. This work grew out of the 2010 REU in
  Modeling and Simulation in Systems Biology and was partially supported by NSF
  Award:477855</comments><msc-class>05C80, 68R10, 91D30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The S-metric has grown popular in network studies, as a measure of
``scale-freeness'' restricted to the collection G(D) of connected graphs with a
common degree sequence D=(d_1,\ldots,d_n). The calculation of S depends on the
maximum possible degree assortativity r among graphs in G(D). The original
method involves a heuristic construction of a maximally assortative graph g*.
The approximation by Beichl and Cloteaux involves constructing a possibly
disconnected graph g' with r(g') &gt;= r(g*) and requires O(n^2) tests for the
graphicality of a degree sequence. The present paper uses the Tripathi-Vijay
test to streamline this approximation, and thereby to investigate two
collections of graphs: Barabasi-Albert trees and coauthorship graphs of
mathematical sciences researchers. Long-term trends in the coauthorship graphs
are discussed, and contextualized by insights derived from the BA trees. It is
known that greater degree-based preferential attachment produces greater
variance in degree sequences, and these trees exhibited assortativities
restricted to a narrow band. In contrast, variance in degree rose over time in
the coauthorship graphs in spite of weakening degree-based preferential
attachment. These observations and their implications are discussed and avenues
of future work are suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4077</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4077</id><created>2013-08-19</created><updated>2013-08-19</updated><authors><author><keyname>Bento</keyname><forenames>Jose</forenames></author><author><keyname>Ibrahimi</keyname><forenames>Morteza</forenames></author></authors><title>Support Recovery for the Drift Coefficient of High-Dimensional
  Diffusions</title><categories>cs.IT cs.LG math.IT math.PR math.ST stat.TH</categories><comments>24 pages, 12 figures</comments><msc-class>60J60, 60H10, 94A15, 62B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the problem of learning the drift coefficient of a $p$-dimensional
stochastic differential equation from a sample path of length $T$. We assume
that the drift is parametrized by a high-dimensional vector, and study the
support recovery problem when both $p$ and $T$ can tend to infinity. In
particular, we prove a general lower bound on the sample-complexity $T$ by
using a characterization of mutual information as a time integral of
conditional variance, due to Kadota, Zakai, and Ziv. For linear stochastic
differential equations, the drift coefficient is parametrized by a $p\times p$
matrix which describes which degrees of freedom interact under the dynamics. In
this case, we analyze a $\ell_1$-regularized least squares estimator and prove
an upper bound on $T$ that nearly matches the lower bound on specific classes
of sparse matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4088</identifier>
 <datestamp>2015-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4088</id><created>2013-08-19</created><updated>2015-03-11</updated><authors><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author><author><keyname>Mehlhorn</keyname><forenames>Kurt</forenames></author></authors><title>Computing Real Roots of Real Polynomials</title><categories>cs.SC cs.NA math.NA</categories><comments>to appear in the Journal of Symbolic Computation</comments><acm-class>G.1.5; F.2.1; G.1.0; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the roots of a univariate polynomial is a fundamental and
long-studied problem of computational algebra with applications in mathematics,
engineering, computer science, and the natural sciences. For isolating as well
as for approximating all complex roots, the best algorithm known is based on an
almost optimal method for approximate polynomial factorization, introduced by
Pan in 2002. Pan's factorization algorithm goes back to the splitting circle
method from Schoenhage in 1982. The main drawbacks of Pan's method are that it
is quite involved and that all roots have to be computed at the same time. For
the important special case, where only the real roots have to be computed, much
simpler methods are used in practice; however, they considerably lag behind
Pan's method with respect to complexity.
  In this paper, we resolve this discrepancy by introducing a hybrid of the
Descartes method and Newton iteration, denoted ANEWDSC, which is simpler than
Pan's method, but achieves a run-time comparable to it. Our algorithm computes
isolating intervals for the real roots of any real square-free polynomial,
given by an oracle that provides arbitrary good approximations of the
polynomial's coefficients. ANEWDSC can also be used to only isolate the roots
in a given interval and to refine the isolating intervals to an arbitrary small
size; it achieves near optimal complexity for the latter task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4101</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4101</id><created>2013-08-19</created><authors><author><keyname>Kannan</keyname><forenames>Rajgopal</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul</forenames></author></authors><title>The Price of Anarchy is Unbounded for Congestion Games with
  Superpolynomial Latency Costs</title><categories>cs.GT</categories><comments>17 pages, submitted to SODA 14</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider non-cooperative unsplittable congestion games where players share
resources, and each player's strategy is pure and consists of a subset of the
resources on which it applies a fixed weight. Such games represent unsplittable
routing flow games and also job allocation games. The congestion of a resource
is the sum of the weights of the players that use it and the player's cost
function is the sum of the utilities of the resources on its strategy. The
social cost is the total weighted sum of the player's costs. The quality of
Nash equilibria is determined by the price of anarchy ($PoA$) which expresses
how much worse is the social outcome in the worst equilibrium versus the
optimal coordinated solution. In the literature the predominant work has only
been on games with polynomial utility costs, where it has been proven that the
price of anarchy is bounded by the degree of the polynomial. However, no
results exist on general bounds for non-polynomial utility functions.
  Here, we consider general versions of these games in which the utility of
each resource is an arbitrary non-decreasing function of the congestion. In
particular, we consider a large family of superpolynomial utility functions
which are asymptotically larger than any polynomial. We demonstrate that for
every such function there exist games for which the price of anarchy is
unbounded and increasing with the number of players (even if they have
infinitesimal weights) while network resources remain fixed. We give tight
lower and upper bounds which show this dependence on the number of players.
Furthermore we provide an exact characterization of the $PoA$ of all congestion
games whose utility costs are bounded above by a polynomial function.
Heretofore such results existed only for games with polynomial cost functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4113</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4113</id><created>2013-08-19</created><authors><author><keyname>Alur</keyname><forenames>Rajeev</forenames></author><author><keyname>Moarref</keyname><forenames>Salar</forenames></author><author><keyname>Topcu</keyname><forenames>Ufuk</forenames></author></authors><title>Counter-Strategy Guided Refinement of GR(1) Temporal Logic
  Specifications</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reactive synthesis problem is to find a finite-state controller that
satisfies a given temporal-logic specification regardless of how its
environment behaves. Developing a formal specification is a challenging and
tedious task and initial specifications are often unrealizable. In many cases,
the source of unrealizability is the lack of adequate assumptions on the
environment of the system. In this paper, we consider the problem of
automatically correcting an unrealizable specification given in the generalized
reactivity (1) fragment of linear temporal logic by adding assumptions on the
environment. When a temporal-logic specification is unrealizable, the synthesis
algorithm computes a counter-strategy as a witness. Our algorithm then analyzes
this counter-strategy and synthesizes a set of candidate environment
assumptions that can be used to remove the counter-strategy from the
environment's possible behaviors. We demonstrate the applicability of our
approach with several case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4123</identifier>
 <datestamp>2013-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4123</id><created>2013-08-18</created><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>A Likelihood Ratio Approach for Probabilistic Inequalities</title><categories>math.PR cs.LG math.ST stat.TH</categories><comments>38 pages, no figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach for deriving probabilistic inequalities based on
bounding likelihood ratios. We demonstrate that this approach is more general
and powerful than the classical method frequently used for deriving
concentration inequalities such as Chernoff bounds. We discover that the
proposed approach is inherently related to statistical concepts such as
monotone likelihood ratio, maximum likelihood, and the method of moments for
parameter estimation. A connection between the proposed approach and the large
deviation theory is also established. We show that, without using moment
generating functions, tightest possible concentration inequalities may be
readily derived by the proposed approach. We have derived new concentration
inequalities using the proposed approach, which cannot be obtained by the
classical approach based on moment generating functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4125</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4125</id><created>2013-08-19</created><authors><author><keyname>Andersen</keyname><forenames>Carl</forenames></author><author><keyname>Benyo</keyname><forenames>Brett</forenames></author><author><keyname>Calejo</keyname><forenames>Miguel</forenames></author><author><keyname>Dean</keyname><forenames>Mike</forenames></author><author><keyname>Fodor</keyname><forenames>Paul</forenames></author><author><keyname>Grosof</keyname><forenames>Benjamin N.</forenames></author><author><keyname>Kifer</keyname><forenames>Michael</forenames></author><author><keyname>Liang</keyname><forenames>Senlin</forenames></author><author><keyname>Swift</keyname><forenames>Terrance</forenames></author></authors><title>Understanding Rulelog Computations in Silk</title><categories>cs.SE cs.PL</categories><comments>Part of WLPE 2013 proceedings (arXiv:1308.2055)</comments><report-no>WLPE/2013/6</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rulelog is a knowledge representation and reasoning language based on logic
programming under the well-founded semantics. It is an extension of the
language of Flora-2 and so supports inheritance and other object-oriented
features, as well as the higher-order syntax of Hilog. However, Rulelog rules
may also contain quantifiers and may be contra-positional. In addition, these
rules are evaluated in the presence of defeasibility mechanisms that include
rule cancellation, rule priorities, and other aspects. Rulelog programs are
sometimes developed by loosely coordinated teams of knowledge engineers (KEs)
who are not necessarily programmers. This requires not only declarative
debugging support, but also support for profiling to help KEs understand the
overall structure of a computation, including its termination properties. The
design of debugging and profiling tools is made more challenging because
Rulelog programs undergo a series of transformations into normal programs, so
that there is a cognitive distance between how rules are specified and how they
are executed.
  In this paper, we describe the debugging and profiling environment for
Rulelog implemented in the integrated development environment of the Silk
system. Our approach includes an interface to justification graphs, which treat
why-not and defeasibility as well as provenance of the rules supporting
answers. It also includes tools for trace-based analysis of computations to
permit understanding of erroneous non-termination and of general performance
issues. For semantically correct cases of the non-terminating behavior, Silk
offers a different approach, which addresses the problem in a formally sound
manner by leveraging a form of bounded rationality called restraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4166</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4166</id><created>2013-08-19</created><authors><author><keyname>Cardonha</keyname><forenames>Carlos</forenames></author><author><keyname>Assun&#xe7;&#xe3;o</keyname><forenames>Marcos D.</forenames></author><author><keyname>Netto</keyname><forenames>Marco A. S.</forenames></author><author><keyname>Cunha</keyname><forenames>Renato L. F.</forenames></author><author><keyname>Queiroz</keyname><forenames>Carlos</forenames></author></authors><title>Patience-aware Scheduling for Cloud Services: Freeing Users from the
  Chains of Boredom</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scheduling of service requests in Cloud computing has traditionally focused
on the reduction of pre-service wait, generally termed as waiting time. Under
certain conditions such as peak load, however, it is not always possible to
give reasonable response times to all users. This work explores the fact that
different users may have their own levels of tolerance or patience with
response delays. We introduce scheduling strategies that produce better
assignment plans by prioritising requests from users who expect to receive the
results earlier and by postponing servicing jobs from those who are more
tolerant to response delays. Our analytical results show that the behaviour of
users' patience plays a key role in the evaluation of scheduling techniques,
and our computational evaluation demonstrates that, under peak load, the new
algorithms typically provide better user experience than the traditional FIFO
strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4169</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4169</id><created>2013-08-08</created><authors><author><keyname>Sharad</keyname><forenames>Mrigank</forenames></author><author><keyname>Fan</keyname><forenames>Deliang</forenames></author><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author></authors><title>Ultra-low Energy, High Performance and Programmable Magnetic Threshold
  Logic</title><categories>cs.ET cond-mat.dis-nn cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose magnetic threshold-logic (MTL) design based on non-volatile
spin-torque switches. A threshold logic gate (TLG) performs summation of
multiple inputs multiplied by a fixed set of weights and compares the sum with
a threshold. MTL employs resistive states of magnetic tunnel junctions as
programmable input weights, while, a low-voltage domain-wall shift based
spin-torque switch is used for thresholding operation. The resulting MTL gate
acts as a low-power, configurable logic unit and can be used to build fully
pipelined, high-performance programmable computing blocks. Multiple stages in
such a MTL design can be connected using energy-efficient ultralow swing
programmable interconnect networks based on resistive switches. Owing to
memory-based compact logic and interconnect design and low-voltage, high-speed
spintorque based threshold operation, MTL can achieve more than two orders of
magnitude improvement in energy-delay product as compared to look-up table
based CMOS FPGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4171</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4171</id><created>2013-08-19</created><authors><author><keyname>Comini</keyname><forenames>Marco</forenames></author><author><keyname>Titolo</keyname><forenames>Laura</forenames></author><author><keyname>Villanueva</keyname><forenames>Alicia</forenames></author></authors><title>Towards an Effective Decision Procedure for LTL formulas with
  Constraints</title><categories>cs.LO</categories><comments>Part of WLPE 2013 proceedings (arXiv:1308.2055)</comments><report-no>WLPE/2013/2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an ongoing work that is part of a more wide-ranging
project whose final scope is to define a method to validate LTL formulas w.r.t.
a program written in the timed concurrent constraint language tccp, which is a
logic concurrent constraint language based on the concurrent constraint
paradigm of Saraswat. Some inherent notions to tccp processes are
non-determinism, dealing with partial information in states and the monotonic
evolution of the information. In order to check an LTL property for a process,
our approach is based on the abstract diagnosis technique. The concluding step
of this technique needs to check the validity of an LTL formula (with
constraints) in an effective way.
  In this paper, we present a decision method for the validity of temporal
logic formulas (with constraints) built by our abstract diagnosis technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4186</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4186</id><created>2013-08-19</created><authors><author><keyname>Lu</keyname><forenames>Bin</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author><author><keyname>Zhong</keyname><forenames>Jianyuan K.</forenames></author></authors><title>A 2-chain can interlock with an open 10-chain</title><categories>cs.CG</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is an open problem, posed in \cite{SoCG}, to determine the minimal $k$
such that an open flexible $k$-chain can interlock with a flexible 2-chain. It
was first established in \cite{GLOSZ} that there is an open 16-chain in a
trapezoid frame that achieves interlocking. This was subsequently improved in
\cite{GLOZ} to establish interlocking between a 2-chain and an open 11-chain.
Here we improve that result once more, establishing interlocking between a
2-chain and a 10-chain. We present arguments that indicate that 10 is likely
the minimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4189</identifier>
 <datestamp>2014-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4189</id><created>2013-08-19</created><updated>2014-05-28</updated><authors><author><keyname>Siddharth</keyname><forenames>N.</forenames></author><author><keyname>Barbu</keyname><forenames>Andrei</forenames></author><author><keyname>Siskind</keyname><forenames>Jeffrey Mark</forenames></author></authors><title>Seeing What You're Told: Sentence-Guided Activity Recognition In Video</title><categories>cs.CV cs.AI cs.CL</categories><comments>To appear in CVPR 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a system that demonstrates how the compositional structure of
events, in concert with the compositional structure of language, can interplay
with the underlying focusing mechanisms in video action recognition, thereby
providing a medium, not only for top-down and bottom-up integration, but also
for multi-modal integration between vision and language. We show how the roles
played by participants (nouns), their characteristics (adjectives), the actions
performed (verbs), the manner of such actions (adverbs), and changing spatial
relations between participants (prepositions) in the form of whole sentential
descriptions mediated by a grammar, guides the activity-recognition process.
Further, the utility and expressiveness of our framework is demonstrated by
performing three separate tasks in the domain of multi-activity videos:
sentence-guided focus of attention, generation of sentential descriptions of
video, and query-based video search, simply by leveraging the framework in
different manners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4197</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4197</id><created>2013-08-19</created><authors><author><keyname>Bonamy</keyname><forenames>Marthe</forenames></author><author><keyname>L&#xe9;v&#xea;que</keyname><forenames>Benjamin</forenames></author><author><keyname>Pinlou</keyname><forenames>Alexandre</forenames></author></authors><title>List coloring the square of sparse graphs with large degree</title><categories>cs.DM math.CO</categories><comments>12 pages, 4 figures, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of coloring the squares of graphs of bounded maximum
average degree, that is, the problem of coloring the vertices while ensuring
that two vertices that are adjacent or have a common neighbour receive
different colors.
  Borodin et al. proved in 2004 and 2008 that the squares of planar graphs of
girth at least seven and sufficiently large maximum degree $\Delta$ are list
$(\Delta+1)$-colorable, while the squares of some planar graphs of girth six
and arbitrarily large maximum degree are not. By Euler's Formula, planar graphs
of girth at least $6$ are of maximum average degree less than $3$, and planar
graphs of girth at least $7$ are of maximum average degree less than $14/5&lt;3$.
  We strengthen their result and prove that there exists a function $f$ such
that the square of any graph with maximum average degree $m&lt;3$ and maximum
degree $\Delta\geq f(m)$ is list $(\Delta+1)$-colorable. This bound of $3$ is
optimal in the sense that the above-mentioned planar graphs with girth $6$ have
maximum average degree less than $3$ and arbitrarily large maximum degree,
while their square cannot be $(\Delta+1)$-colored. The same holds for list
injective $\Delta$-coloring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4200</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4200</id><created>2013-08-19</created><authors><author><keyname>Rodner</keyname><forenames>Erik</forenames></author><author><keyname>Hoffman</keyname><forenames>Judy</forenames></author><author><keyname>Donahue</keyname><forenames>Jeff</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author><author><keyname>Saenko</keyname><forenames>Kate</forenames></author></authors><title>Towards Adapting ImageNet to Reality: Scalable Domain Adaptation with
  Implicit Low-rank Transformations</title><categories>cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images seen during test time are often not from the same distribution as
images used for learning. This problem, known as domain shift, occurs when
training classifiers from object-centric internet image databases and trying to
apply them directly to scene understanding tasks. The consequence is often
severe performance degradation and is one of the major barriers for the
application of classifiers in real-world systems. In this paper, we show how to
learn transform-based domain adaptation classifiers in a scalable manner. The
key idea is to exploit an implicit rank constraint, originated from a
max-margin domain adaptation formulation, to make optimization tractable.
Experiments show that the transformation between domains can be very
efficiently learned from data and easily applied to new categories. This begins
to bridge the gap between large-scale internet image collections and object
images captured in everyday life environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4201</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4201</id><created>2013-08-19</created><updated>2013-09-18</updated><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Sakzad</keyname><forenames>Amin</forenames></author><author><keyname>Viterbo</keyname><forenames>Emanuele</forenames></author></authors><title>Full-Diversity Space-Time Block Codes for Integer-Forcing Linear
  Receivers</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn due to an error in Proposition 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multiple-input multiple-output (MIMO) fading channels, the design
criterion for full-diversity space-time block codes (STBCs) is primarily
determined by the decoding method at the receiver. Although constructions of
STBCs have predominantly matched the maximum-likelihood (ML) decoder, design
criteria and constructions of full-diversity STBCs have also been reported for
low-complexity linear receivers. A new receiver architecture called
Integer-Forcing (IF) linear receiver has been proposed by Zhan \emph{et al.}
which showed promising results for the high-rate V-BLAST encoding scheme. In
this work we address the design of full-diversity STBCs for IF linear
receivers. We derive an upper bound on the probability of decoding error, and
show that STBCs that satisfy the non-vanishing singular value (NVS) property
provide full-diversity for the IF receiver. Further, we prove that all known
STBCs with the non-vanishing determinant property are applicable for IF
receivers, as they guarantee the NVS property. As a special case of our
analysis on STBCs, we present an upper bound on the error probability for the
V-BLAST architecture presented by Zhan \emph{et al.}, and demonstrate that the
IF linear receivers provide full receive diversity. Our results supplement the
existing outage probability based results for the IF receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4206</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4206</id><created>2013-08-19</created><updated>2013-09-05</updated><authors><author><keyname>Zhang</keyname><forenames>Lingsong</forenames></author><author><keyname>Marron</keyname><forenames>J. S.</forenames></author><author><keyname>Lu</keyname><forenames>Shu</forenames></author></authors><title>Nested Nonnegative Cone Analysis</title><categories>stat.ME cs.LG</categories><comments>18 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the analysis of nonnegative data objects, a novel Nested
Nonnegative Cone Analysis (NNCA) approach is proposed to overcome some
drawbacks of existing methods. The application of traditional PCA/SVD method to
nonnegative data often cause the approximation matrix leave the nonnegative
cone, which leads to non-interpretable and sometimes nonsensical results. The
nonnegative matrix factorization (NMF) approach overcomes this issue, however
the NMF approximation matrices suffer several drawbacks: 1) the factorization
may not be unique, 2) the resulting approximation matrix at a specific rank may
not be unique, and 3) the subspaces spanned by the approximation matrices at
different ranks may not be nested. These drawbacks will cause troubles in
determining the number of components and in multi-scale (in ranks)
interpretability. The NNCA approach proposed in this paper naturally generates
a nested structure, and is shown to be unique at each rank. Simulations are
used in this paper to illustrate the drawbacks of the traditional methods, and
the usefulness of the NNCA method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4208</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4208</id><created>2013-08-19</created><authors><author><keyname>Carvalho</keyname><forenames>Jose Fernando S.</forenames></author><author><keyname>Neto</keyname><forenames>Paulo Anselmo da Mota Silveira</forenames></author><author><keyname>Garcia</keyname><forenames>Vincius Cardoso</forenames></author><author><keyname>Assad</keyname><forenames>Rodrigo Elia</forenames></author><author><keyname>Durao</keyname><forenames>Frederico</forenames></author></authors><title>A Systematic Mapping Study on Cloud Computing</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud Computing emerges from the global economic crisis as an option to use
computing resources from a more rational point of view. In other words, a
cheaper way to have IT resources. However, issues as security and privacy, SLA
(Service Layer Agreement), resource sharing, and billing has left open
questions about the real gains of that model. This study aims to investigate
state-of-the-art in Cloud Computing, identify gaps, challenges, synthesize
available evidences both its use and development, and provides relevant
information, clarifying open questions and common discussed issues about that
model through literature. The good practices of systematic map- ping study
methodology were adopted in order to reach those objectives. Al- though Cloud
Computing is based on a business model with over 50 years of existence,
evidences found in this study indicate that Cloud Computing still presents
limitations that prevent the full use of the proposal on-demand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4214</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4214</id><created>2013-08-19</created><authors><author><keyname>Goodfellow</keyname><forenames>Ian J.</forenames></author><author><keyname>Warde-Farley</keyname><forenames>David</forenames></author><author><keyname>Lamblin</keyname><forenames>Pascal</forenames></author><author><keyname>Dumoulin</keyname><forenames>Vincent</forenames></author><author><keyname>Mirza</keyname><forenames>Mehdi</forenames></author><author><keyname>Pascanu</keyname><forenames>Razvan</forenames></author><author><keyname>Bergstra</keyname><forenames>James</forenames></author><author><keyname>Bastien</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Pylearn2: a machine learning research library</title><categories>stat.ML cs.LG cs.MS</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pylearn2 is a machine learning research library. This does not just mean that
it is a collection of machine learning algorithms that share a common API; it
means that it has been designed for flexibility and extensibility in order to
facilitate research projects that involve new or unusual use cases. In this
paper we give a brief history of the library, an overview of its basic
philosophy, a summary of the library's architecture, and a description of how
the Pylearn2 community functions socially.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4216</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4216</id><created>2013-08-19</created><updated>2013-11-19</updated><authors><author><keyname>Valdez</keyname><forenames>L. D.</forenames></author><author><keyname>Macri</keyname><forenames>P. A.</forenames></author><author><keyname>Stanley</keyname><forenames>H. E.</forenames></author><author><keyname>Braunstein</keyname><forenames>L. A.</forenames></author></authors><title>Triple Point in Correlated Interdependent Networks</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Phys. Rev. E 88, 050803 (R) (2013)</journal-ref><doi>10.1103/PhysRevE.88.050803</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world networks depend on other networks, often in non-trivial ways,
to maintain their functionality. These interdependent &quot;networks of networks&quot;
are often extremely fragile. When a fraction $1-p$ of nodes in one network
randomly fails, the damage propagates to nodes in networks that are
interdependent and a dynamic failure cascade occurs that affects the entire
system. We present dynamic equations for two interdependent networks that allow
us to reproduce the failure cascade for an arbitrary pattern of
interdependency. We study the &quot;rich club&quot; effect found in many real
interdependent network systems in which the high-degree nodes are extremely
interdependent, correlating a fraction $\alpha$ of the higher degree nodes on
each network. We find a rich phase diagram in the plane $p-\alpha$, with a
triple point reminiscent of the triple point of liquids that separates a
non-functional phase from two functional phases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4218</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4218</id><created>2013-08-19</created><updated>2013-09-02</updated><authors><author><keyname>Zhang</keyname><forenames>Liang Feng</forenames></author><author><keyname>Safavi-Naini</keyname><forenames>Rehanehi</forenames></author></authors><title>Private Outsourcing of Polynomial Evaluation and Matrix Multiplication
  using Multilinear Maps</title><categories>cs.CR</categories><comments>23 pages, A preliminary version appears in the 12th International
  Conference on Cryptology and Network Security (CANS 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  {\em Verifiable computation} (VC) allows a computationally weak client to
outsource the evaluation of a function on many inputs to a powerful but
untrusted server. The client invests a large amount of off-line computation and
gives an encoding of its function to the server. The server returns both an
evaluation of the function on the client's input and a proof such that the
client can verify the evaluation using substantially less effort than doing the
evaluation on its own. We consider how to privately outsource computations
using {\em privacy preserving} VC schemes whose executions reveal no
information on the client's input or function to the server. We construct VC
schemes with {\em input privacy} for univariate polynomial evaluation and
matrix multiplication and then extend them such that the {\em function privacy}
is also achieved. Our tool is the recently developed {mutilinear maps}. The
proposed VC schemes can be used in outsourcing {private information retrieval
(PIR)}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4227</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4227</id><created>2013-08-20</created><authors><author><keyname>Li</keyname><forenames>Quan-Lin</forenames></author><author><keyname>Cao</keyname><forenames>Jing</forenames></author></authors><title>A Computational Framework for the Mixing Times in the QBD Processes with
  Infinitely-Many Levels</title><categories>math.PR cs.PF cs.SY math.OC</categories><msc-class>60J10, 60J22, 60J45, 90B15, 90B18, 90B22</msc-class><acm-class>G.3; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop some matrix Poisson's equations satisfied by the
mean and variance of the mixing time in an irreducible positive-recurrent
discrete-time Markov chain with infinitely-many levels, and provide a
computational framework for the solution to the matrix Poisson's equations by
means of the UL-type of $RG$-factorization as well as the generalized inverses.
In an important special case: the level-dependent QBD processes, we provide a
detailed computation for the mean and variance of the mixing time. Based on
this, we give new highlight on computation of the mixing time in the
block-structured Markov chains with infinitely-many levels through the
matrix-analytic method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4259</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4259</id><created>2013-08-20</created><authors><author><keyname>Bruun</keyname><forenames>Jesper</forenames></author><author><keyname>Bearden</keyname><forenames>Ian G.</forenames></author></authors><title>Time Development of Early Social Networks: Link analysis and group
  dynamics</title><categories>physics.soc-ph cs.SI physics.ed-ph</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Empirical data on early network history are rare. Students beginning their
studies at a university with no or few prior connections to each other offer a
unique opportunity to investigate the formation and early development of social
networks. During a nine week introductory physics course, first year physics
students were asked to identify those with whom they communicated about problem
solving in physics during the preceding week. We use these students' self
reports to produce time dependent student interaction networks. These networks
have also been investigated to elucidate possible effects of gender and
students' final course grade. Changes in the weekly number of links are
investigated to show that while roughly half of all links change from week to
week, students also reestablish a growing number of links as they progress
through their first weeks of study. To investigate how students group, Infomap
is used to establish groups. Further, student group flow is examined using
alluvial diagrams, showing that many students jump between group each week.,
Finally, a segregation measure is developed which shows that students structure
themselves according to gender and laboratory exercise groups and not according
to end-of-course grade. The results show the behavior of an early
social-educational network, and may have implications for theoretical network
models as well as for physics education.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4260</identifier>
 <datestamp>2015-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4260</id><created>2013-08-20</created><updated>2015-02-21</updated><authors><author><keyname>Berth&#xe9;</keyname><forenames>Valerie</forenames></author><author><keyname>De Felice</keyname><forenames>Clelia</forenames></author><author><keyname>Dolce</keyname><forenames>Francesco</forenames></author><author><keyname>Leroy</keyname><forenames>Julien</forenames></author><author><keyname>Perrin</keyname><forenames>Dominique</forenames></author><author><keyname>Reutenauer</keyname><forenames>Christophe</forenames></author><author><keyname>Rindone</keyname><forenames>Giuseppina</forenames></author></authors><title>Acyclic, connected and tree sets</title><categories>math.CO cs.FL</categories><comments>arXiv admin note: substantial text overlap with arXiv:1305.0127,
  arXiv:1011.5369, Monatsh. Math. (2015)</comments><doi>10.1007/s00605-014-0721-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set $F$ of words, one associates to each word $w$ in $F$ an
undirected graph, called its extension graph, and which describes the possible
extensions of $w$ on the left and on the right. We investigate the family of
sets of words defined by the property of the extension graph of each word in
the set to be acyclic or connected or a tree. We prove that in a uniformly
recurrent tree set, the sets of first return words are bases of the free group
on the alphabet. Concerning acyclic sets, we prove as a main result that a set
$F$ is acyclic if and only if any bifix code included in $F$ is a basis of the
subgroup that it generates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4263</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4263</id><created>2013-08-20</created><authors><author><keyname>Ciaramella</keyname><forenames>Angelo</forenames></author><author><keyname>Giunta</keyname><forenames>Giulio</forenames></author></authors><title>Compressive Sampling for the Packet Loss Recovery in Audio Multimedia
  Streaming</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to introduce a new schema, based on a Compressive
Sampling technique, for the recovery of lost data in multimedia streaming. The
audio streaming data are encapsuled in different packets by using an
interleaving technique. The Compressive Sampling technique is used to recover
audio information in case of lost packets. Experimental results are presented
on speech and musical audio signals to illustrate the performances and the
capabilities of the proposed methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4268</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4268</id><created>2013-08-20</created><authors><author><keyname>Nagahara</keyname><forenames>Masaaki</forenames></author></authors><title>Multirate Digital Signal Processing via Sampled-Data H-infinity
  Optimization</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>PHD Thesis, Kyoto University, 2003</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this thesis, we present a new method for designing multirate signal
processing and digital communication systems via sampled-data H-infinity
control theory. The difference between our method and conventional ones is in
the signal spaces. Conventional designs are executed in the discrete-time
domain, while our design takes account of both the discrete-time and the
continuous-time signals. Namely, our method can take account of the
characteristic of the original analog signal and the influence of the A/D and
D/A conversion. While the conventional method often indicates that an ideal
digital low-pass filter is preferred, we show that the optimal solution need
not be an ideal low-pass when the original analog signal is not completely
band-limited. This fact can not be recognized only in the discrete-time domain.
Moreover, we consider quantization effects. We discuss the stability and the
performance of quantized sampled-data control systems. We justify H-infinity
control to reduce distortion caused by the quantizer. Then we apply it to
differential pulse code modulation. While the conventional Delta modulator is
not optimal and besides not stable, our modulator is stable and optimal with
respect to the H-infinity-norm. We also give an LMI (Linear Matrix Inequality)
solution to the optimal H-infinity approximation of IIR (Infinite Impulse
Response) filters via FIR (Finite Impulse Response) filters. A comparison with
the Nehari shuffle is made with a numerical example, and it is observed that
the LMI solution generally performs better. Another numerical study also
indicates that there is a trade-off between the pass-band and stop-band
approximation characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4273</identifier>
 <datestamp>2014-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4273</id><created>2013-08-20</created><updated>2014-06-18</updated><authors><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Adaptive matching pursuit for off-grid compressed sensing</title><categories>stat.AP cs.IT math.IT</categories><comments>24 pages. 10 figures</comments><journal-ref>EURASIP Journal on Advances in Signal Processing 2012, 2012:76</journal-ref><doi>10.1186/1687-6180-2012-76</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) can effectively recover a signal when it is sparse
in some discrete atoms. However, in some applications, signals are sparse in a
continuous parameter space, e.g., frequency space, rather than discrete atoms.
Usually, we divide the continuous parameter into finite discrete grid points
and build a dictionary from these grid points. However, the actual targets may
not exactly lie on the grid points no matter how densely the parameter is
grided, which introduces mismatch between the predefined dictionary and the
actual one. In this article, a novel method, namely adaptive matching pursuit
with constrained total least squares (AMP-CTLS), is proposed to find actual
atoms even if they are not included in the initial dictionary. In AMP-CTLS, the
grid and the dictionary are adaptively updated to better agree with
measurements. The convergence of the algorithm is discussed, and numerical
experiments demonstrate the advantages of AMP-CTLS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4274</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4274</id><created>2013-08-20</created><authors><author><keyname>Dai</keyname><forenames>Xiongping</forenames></author><author><keyname>Huang</keyname><forenames>Tingwen</forenames></author><author><keyname>Huang</keyname><forenames>Yu</forenames></author><author><keyname>Xiao</keyname><forenames>Mingqing</forenames></author></authors><title>Chaotic Characteristic of Discrete-time Linear Inclusion Dynamical
  Systems</title><categories>cs.SY math.DS math.OC</categories><comments>extends arXiv:1307.3818 [cs.SY]; 23 pages</comments><msc-class>93C30, 37A30, 15B52</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the fiber-chaos of switched linear dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4275</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4275</id><created>2013-08-20</created><updated>2014-08-05</updated><authors><author><keyname>Di Napoli</keyname><forenames>Edoardo</forenames><affiliation>J&#xfc;lich Supercomputing Centre, Forshungszentrum J&#xfc;lich</affiliation></author><author><keyname>Polizzi</keyname><forenames>Eric</forenames><affiliation>Dept. of Electrical and Computer Engineering, University of Massachusetts</affiliation></author><author><keyname>Saad</keyname><forenames>Yousef</forenames><affiliation>Computer Science &amp; Engineering, University of Minnesota</affiliation></author></authors><title>Efficient estimation of eigenvalue counts in an interval</title><categories>cs.NA</categories><comments>24 pages and 8 figures. Submitted to Numerical Linear Algebra with
  Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating the number of eigenvalues located in a given interval of a large
sparse Hermitian matrix is an important problem in certain applications and it
is a prerequisite of eigensolvers based on a divide-and-conquer paradigm. Often
an exact count is not necessary and methods based on stochastic estimates can
be utilized to yield rough approximations. This paper examines a number of
techniques tailored to this specific task. It reviews standard approaches and
explores new ones based on polynomial and rational approximation filtering
combined with a stochastic procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4280</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4280</id><created>2013-08-20</created><authors><author><keyname>Zhang</keyname><forenames>Jinghui</forenames></author><author><keyname>Ye</keyname><forenames>Tong</forenames></author><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author><author><keyname>Yan</keyname><forenames>Fangfang</forenames></author><author><keyname>Hu</keyname><forenames>Weisheng</forenames></author></authors><title>Birkhoff-von-Neumann Switches with Deflection-Compensated Mechanism</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the high throughput and low complexity achieved by input scheduling
based on Birkhoff-von-Neumann (BvN) decomposition; the performance of the BvN
switch becomes less predictable when the input traffic is bursty. In this
paper, we propose a deflection-compensated BvN (D-BvN) switch architecture to
enhance the quasi-static scheduling based on BvN decomposition. The D-BvN
switches provide capacity guarantee for virtual circuits (VCs) and deflect
bursty traffic when overflow occurs. The deflection scheme is devised to offset
the excessive buffer requirement of each VC when input traffic is bursty. The
design of our conditional deflection mechanism is based on the fact that it is
unlikely that the traffic input to VCs is all bursty at the same time; most
likely some starving VCs have spare capacities when some other VCs are in the
overflow state. The proposed algorithm makes full use of the spare capacities
of those starving VCs to deflect the overflow traffic to other inputs and
provide bandwidth for the deflected traffic to re-access the desired VC. Our
analysis and simulation show that this deflection-compensated mechanism can
support BvN switches to achieve close to 100% throughput of offered load even
with bursty input traffic, and reduces the average end-to-end delay and delay
jitter. Also, our result indicates that the packet out-of-sequence probability
due to deflection of overflow traffic is negligible, thus only a small
re-sequencing buffer is needed at each output port.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4291</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4291</id><created>2013-08-20</created><authors><author><keyname>Angelini</keyname><forenames>Patrizio</forenames></author><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author><author><keyname>Patrignani</keyname><forenames>Maurizio</forenames></author><author><keyname>Roselli</keyname><forenames>Vincenzo</forenames></author></authors><title>Morphing Planar Graphs Drawings Efficiently</title><categories>cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A morph between two straight-line planar drawings of the same graph is a
continuous transformation from the first to the second drawing such that
planarity is preserved at all times. Each step of the morph moves each vertex
at constant speed along a straight line. Although the existence of a morph
between any two drawings was established several decades ago, only recently it
has been proved that a polynomial number of steps suffices to morph any two
planar straight-line drawings. Namely, at SODA 2013, Alamdari et al.[1] proved
that any two planar straight-line drawings of a planar graph can be morphed in
O(n^4) steps, while O(n^2) steps suffice if we restrict to maximal planar
graphs.
  In this paper, we improve upon such results, by showing an algorithm to morph
any two planar straight-line drawings of a planar graph in O(n^2) steps;
further, we show that a morph with O(n) steps exists between any two planar
straight-line drawings of a series-parallel graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4294</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4294</id><created>2013-08-19</created><authors><author><keyname>Fioriti</keyname><forenames>Enzo</forenames></author><author><keyname>Chiesa</keyname><forenames>Stefano</forenames></author><author><keyname>Fratichini</keyname><forenames>Fabio</forenames></author></authors><title>Expanding the Knowledge Horizon in Underwater Robot Swarms</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the time delays affecting the diffusion of information
in an underwater heterogeneous robot swarm, considering a time-sensitive
environment. In many situations each member of the swarm must update its
knowledge about the environment as soon as possible, thus every effort to
expand the knowledge horizon is useful. Otherwise critical information may not
reach nodes far from the source causing dangerous misbehaviour of the swarm. We
consider two extreme situations. In the first scenario we have an unique
probabilistic delay distribution. In the second scenario, each agent is subject
to a different truncated gaussian distribution, meaning local conditions are
significantly different from link to link. We study how several swarm
topologies react to the two scenarios and how to allocate the more efficient
transmission resources in order to expand the horizon. Results show that
significant time savings under a gossip-like protocol are possible properly
allocating the resources. Moreover, methods to determine the fastest swarm
topologies and the most important nodes are suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4316</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4316</id><created>2013-08-20</created><updated>2016-01-06</updated><authors><author><keyname>Ghavami</keyname><forenames>Abouzar</forenames></author><author><keyname>Kar</keyname><forenames>Koushik</forenames></author><author><keyname>Gupta</keyname><forenames>Aparna</forenames></author></authors><title>Decentralized Charging of Plug-In Electric Vehicles with Distribution
  Feeder Overload Control</title><categories>cs.SY</categories><comments>25 pages, 6 Figures, Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the number of charging Plug-in Electric Vehicles (PEVs) increase, due to
the limited power capacity of the distribution feeders and the sensitivity of
the mid-way distribution transformers to the excessive load, it is crucial to
control the amount of power through each specific distribution feeder to avoid
system overloads that may lead to breakdowns. In this paper we develop, analyze
and evaluate charging algorithms for PEVs with feeder overload constraints in
the distribution grid. The algorithms we propose jointly minimize the variance
of the aggregate load and prevent overloading of the distribution feeders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4321</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4321</id><created>2013-08-20</created><authors><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>On Obstacle Numbers</title><categories>math.CO cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The obstacle number is a new graph parameter introduced by Alpert, Koch, and
Laison (2010). Mukkamala etal (2012) show that there exist graphs with n
vertices having obstacle number in Omega(n/\log n). In this note, we up this
lower bound to Omega(n/(\log\log n)^2. Our proof makes use of an upper bound of
Mukkamala etal on the number of graphs having obstacle number at most h in such
a way that any subsequent improvements to their upper bound will improve our
lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4338</identifier>
 <datestamp>2013-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4338</id><created>2013-08-20</created><authors><author><keyname>Torres</keyname><forenames>Leonardo</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>SAR Image Despeckling Algorithms using Stochastic Distances and Nonlocal
  Means</title><categories>cs.IT cs.CV cs.GR math.IT stat.AP stat.ML</categories><comments>Accepted for publication in Workshop of Theses and Dissertations
  (WTD) in Conference on Graphics, Patterns, and Images (SIBGRAPI 2013). This
  paper received the first best work award in the Dissertation category at the
  WTD-SIBGRAPI</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents two approaches for filter design based on stochastic
distances for intensity speckle reduction. A window is defined around each
pixel, overlapping samples are compared and only those which pass a
goodness-of-fit test are used to compute the filtered value. The tests stem
from stochastic divergences within the Information Theory framework. The
technique is applied to intensity Synthetic Aperture Radar (SAR) data with
homogeneous regions using the Gamma model. The first approach uses a
Nagao-Matsuyama-type procedure for setting the overlapping samples, and the
second uses the nonlocal method. The proposals are compared with the Improved
Sigma filter and with anisotropic diffusion for speckled data (SRAD) using a
protocol based on Monte Carlo simulation. Among the criteria used to quantify
the quality of filters, we employ the equivalent number of looks, and line and
edge preservation. Moreover, we also assessed the filters by the Universal
Image Quality Index and by the Pearson correlation between edges. Applications
to real images are also discussed. The proposed methods show good results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4368</identifier>
 <datestamp>2014-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4368</id><created>2013-08-20</created><updated>2014-05-21</updated><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames><affiliation>University of Waterloo</affiliation></author><author><keyname>Davies</keyname><forenames>Gareth</forenames><affiliation>University of Waterloo</affiliation></author></authors><title>Maximally Atomic Languages</title><categories>cs.FL</categories><comments>In Proceedings AFL 2014, arXiv:1405.5272</comments><proxy>EPTCS</proxy><acm-class>F.4.3</acm-class><journal-ref>EPTCS 151, 2014, pp. 151-161</journal-ref><doi>10.4204/EPTCS.151.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The atoms of a regular language are non-empty intersections of complemented
and uncomplemented quotients of the language. Tight upper bounds on the number
of atoms of a language and on the quotient complexities of atoms are known. We
introduce a new class of regular languages, called the maximally atomic
languages, consisting of all languages meeting these bounds. We prove the
following result: If L is a regular language of quotient complexity n and G is
the subgroup of permutations in the transition semigroup T of the minimal DFA
of L, then L is maximally atomic if and only if G is transitive on k-subsets of
1,...,n for 0 &lt;= k &lt;= n and T contains a transformation of rank n-1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4371</identifier>
 <datestamp>2014-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4371</id><created>2013-08-20</created><updated>2014-11-12</updated><authors><author><keyname>Roelse</keyname><forenames>Peter</forenames></author></authors><title>A new key establishment protocol and its application in pay-TV systems</title><categories>cs.CR</categories><comments>16 pages, 5 figures, version 2 is a shortened version of the paper</comments><msc-class>68M12, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A pay-TV consumer uses a decoder to access encrypted digital content. To this
end, a decoder contains a chip capable of decrypting the content if provisioned
with the appropriate content decryption keys. A key establishment protocol is
used to secure the delivery of the content decryption keys to the chip. This
paper presents a new key establishment protocol. The paper shows how the new
protocol can be applied in a pay-TV system, and provides a comparison of the
properties of the new protocol and existing protocols. In particular, it is
shown that the new protocol offers a similar level of security as existing
protocols against attacks in which content decryption keys are compromised and
re-distributed. The main advantage of the new protocol is that it achieves the
unique and desirable property of being able to restore security for future
protocol executions without the need to replace any decoder in the event that
all system components other than the content decryption chips have been
compromised. By comparison, existing protocols necessitate the replacement of
the entire decoder population in this scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4391</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4391</id><created>2013-08-20</created><authors><author><keyname>Rahimi</keyname><forenames>M. Reza</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Nalini</forenames></author><author><keyname>Mehrotra</keyname><forenames>Sharad</forenames></author><author><keyname>Vasilakos</keyname><forenames>Athanasios V.</forenames></author></authors><title>On Optimal and Fair Service Allocation in Mobile Cloud Computing</title><categories>cs.DC cs.NI</categories><comments>21 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the optimal and fair service allocation for a variety of
mobile applications (single or group and collaborative mobile applications) in
mobile cloud computing. We exploit the observation that using tiered clouds,
i.e. clouds at multiple levels (local and public) can increase the performance
and scalability of mobile applications. We proposed a novel framework to model
mobile applications as a location-time workflows (LTW) of tasks; here users
mobility patterns are translated to mobile service usage patterns. We show that
an optimal mapping of LTWs to tiered cloud resources considering multiple QoS
goals such application delay, device power consumption and user cost/price is
an NP-hard problem for both single and group-based applications. We propose an
efficient heuristic algorithm called MuSIC that is able to perform well (73% of
optimal, 30% better than simple strategies), and scale well to a large number
of users while ensuring high mobile application QoS. We evaluate MuSIC and the
2-tier mobile cloud approach via implementation (on real world clouds) and
extensive simulations using rich mobile applications like intensive signal
processing, video streaming and multimedia file sharing applications. Our
experimental and simulation results indicate that MuSIC supports scalable
operation (100+ concurrent users executing complex workflows) while improving
QoS. We observe about 25% lower delays and power (under fixed price
constraints) and about 35% decrease in price (considering fixed delay) in
comparison to only using the public cloud. Our studies also show that MuSIC
performs quite well under different mobility patterns, e.g. random waypoint and
Manhattan models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4398</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4398</id><created>2013-08-20</created><authors><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author><author><keyname>Donnay</keyname><forenames>Karsten</forenames></author><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author></authors><title>Understanding recurrent crime as system-immanent collective behavior</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>9 two-column pages, 5 figures; accepted for publication in PLoS ONE</comments><journal-ref>PLoS ONE 8 (2013) e76063</journal-ref><doi>10.1371/journal.pone.0076063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Containing the spreading of crime is a major challenge for society. Yet,
since thousands of years, no effective strategy has been found to overcome
crime. To the contrary, empirical evidence shows that crime is recurrent, a
fact that is not captured well by rational choice theories of crime. According
to these, strong enough punishment should prevent crime from happening. To gain
a better understanding of the relationship between crime and punishment, we
consider that the latter requires prior discovery of illicit behavior and study
a spatial version of the inspection game. Simulations reveal the spontaneous
emergence of cyclic dominance between ''criminals'', ''inspectors'', and
''ordinary people'' as a consequence of spatial interactions. Such cycles
dominate the evolutionary process, in particular when the temptation to commit
crime or the cost of inspection are low or moderate. Yet, there are also
critical parameter values beyond which cycles cease to exist and the population
is dominated either by a stable mixture of criminals and inspectors or one of
these two strategies alone. Both continuous and discontinuous phase transitions
to different final states are possible, indicating that successful strategies
to contain crime can be very much counter-intuitive and complex. Our results
demonstrate that spatial interactions are crucial for the evolutionary outcome
of the inspection game, and they also reveal why criminal behavior is likely to
be recurrent rather than evolving towards an equilibrium with monotonous
parameter dependencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4431</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4431</id><created>2013-08-20</created><authors><author><keyname>Grzesik</keyname><forenames>Andrzej</forenames></author><author><keyname>Khachatrian</keyname><forenames>Hrant</forenames></author></authors><title>Interval edge-colorings of K_{1,m,n}</title><categories>math.CO cs.DM</categories><comments>6 pages, 2 figures. arXiv admin note: text overlap with
  arXiv:1303.1039 by other authors</comments><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we prove that K_{1,m,n} is interval edge-colorable if and only
if gcd(m+1,n+1)=1. It settles in the affirmative a conjecture of Petrosyan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4434</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4434</id><created>2013-08-20</created><updated>2013-08-25</updated><authors><author><keyname>Mei</keyname><forenames>Gang</forenames></author><author><keyname>Tipper</keyname><forenames>John C.</forenames></author></authors><title>Simple and Robust Boolean Operations for Triangulated Surfaces</title><categories>cs.CG</categories><comments>Novel method for determining Union, Subtraction and Intersection</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boolean operations of geometric models is an essential issue in computational
geometry. In this paper, we develop a simple and robust approach to perform
Boolean operations on closed and open triangulated surfaces. Our method mainly
has two stages: (1) We firstly find out candidate intersected-triangles pairs
based on Octree and then compute the inter-section lines for all pairs of
triangles with parallel algorithm; (2) We form closed or open
intersection-loops, sub-surfaces and sub-blocks quite robustly only according
to the cleared and updated topology of meshes while without coordinate
computations for geometric enti-ties. A novel technique instead of
inside/outside classification is also proposed to distinguish the resulting
union, subtraction and intersection. Several examples have been given to
illus-trate the effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4440</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4440</id><created>2013-08-20</created><authors><author><keyname>Firouz</keyname><forenames>AL-Wassai</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author></authors><title>Influences Combination of Multi-Sensor Images on Classification Accuracy</title><categories>cs.CV</categories><comments>Available Online at http://www.ijarcs.info/ Volume 4, No. 9,
  July-August 2013</comments><journal-ref>International Journal of Advanced Research in Computer
  Science,Volume 4, No. 9, July-August 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on two main issues; first one is the impact of combination
of multi-sensor images on the supervised learning classification accuracy using
segment Fusion (SF). The second issue attempts to undertake the study of
supervised machine learning classification technique of remote sensing images
by using four classifiers like Parallelepiped (Pp), Mahalanobis Distance (MD),
Maximum-Likelihood (ML) and Euclidean Distance(ED) classifiers, and their
accuracies have been evaluated on their respected classification to choose the
best technique for classification of remote sensing images. QuickBird
multispectral data (MS) and panchromatic data (PAN) have been used in this
study to demonstrate the enhancement and accuracy assessment of fused image
over the original images using ALwassaiProcess software. According to
experimental result of this study, is that the test results indicate the
supervised classification results of fusion image, which generated better than
the MS did. As well as the result with Euclidean classifier is robust and
provides better results than the other classifiers do, despite of the popular
belief that the maximum-likelihood classifier is the most accurate classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4452</identifier>
 <datestamp>2015-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4452</id><created>2013-08-20</created><updated>2015-08-24</updated><authors><author><keyname>Kwon</keyname><forenames>Keehang</forenames></author></authors><title>A New Statement for Selection and Exception Handling in Imperative
  Languages</title><categories>cs.PL</categories><comments>8 pages. We replace choose with schoose which is more accurate
  alternative of if-then-else and try-catch</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diverse selection statements -- if-then-else, switch and try-catch -- are
commonly used in modern programming languages. To make things simple, we
propose a unifying statement for selection. This statement is of the form
schoose(G_1,...,G_n) where each $G_i$ is a statement. It has a a simple
semantics: sequentially choose the first successful statement $G_i$ and then
proceeds with executing $G_i$. Examples will be provided for this statement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4458</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4458</id><created>2013-08-20</created><authors><author><keyname>Pournaghi</keyname><forenames>Reza</forenames></author><author><keyname>Wu</keyname><forenames>Xiaolin</forenames></author></authors><title>Coded Acquisition of High Frame Rate Video</title><categories>cs.MM</categories><doi>10.1109/TIP.2014.2368359</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High frame video (HFV) is an important investigational tool in sciences,
engineering and military. In ultra-high speed imaging, the obtainable temporal,
spatial and spectral resolutions are limited by the sustainable throughput of
in-camera mass memory, the lower bound of exposure time, and illumination
conditions. In order to break these bottlenecks, we propose a new coded video
acquisition framework that employs K &gt; 2 conventional cameras, each of which
makes random measurements of the 3D video signal in both temporal and spatial
domains. For each of the K cameras, this multi-camera strategy greatly relaxes
the stringent requirements in memory speed, shutter speed, and illumination
strength. The recovery of HFV from these random measurements is posed and
solved as a large scale l1 minimization problem by exploiting joint temporal
and spatial sparsities of the 3D signal. Three coded video acquisition
techniques of varied trade offs between performance and hardware complexity are
developed: frame-wise coded acquisition, pixel-wise coded acquisition, and
column-row-wise coded acquisition. The performances of these techniques are
analyzed in relation to the sparsity of the underlying video signal.
Simulations of these new HFV capture techniques are carried out and
experimental results are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4465</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4465</id><created>2013-08-20</created><authors><author><keyname>Kozat</keyname><forenames>Ulas C.</forenames></author><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author><author><keyname>Kokten</keyname><forenames>Koray</forenames></author></authors><title>On Diagnosis of Forwarding Plane via Static Forwarding Rules in Software
  Defined Networks</title><categories>cs.NI</categories><comments>Submitted to Infocom'14, 9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software Defined Networks (SDN) decouple the forwarding and control planes
from each other. The control plane is assumed to have a global knowledge of the
underlying physical and/or logical network topology so that it can monitor,
abstract and control the forwarding plane. In our paper, we present solutions
that install an optimal or near-optimal (i.e., within 14% of the optimal)
number of static forwarding rules on switches/routers so that any controller
can verify the topology connectivity and detect/locate link failures at data
plane speeds without relying on state updates from other controllers. Our upper
bounds on performance indicate that sub-second link failure localization is
possible even at data-center scale networks. For networks with hundreds or few
thousand links, tens of milliseconds of latency is achievable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4469</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4469</id><created>2013-08-20</created><authors><author><keyname>Dillabaugh</keyname><forenames>Craig</forenames></author></authors><title>External Memory Algorithms For Path Traversal in Graphs</title><categories>cs.DS</categories><comments>181 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis presents a number of results related to path traversal in trees
and graphs. In particular, we focus on data structures which allow such
traversals to be performed efficiently in the external memory setting. In
addition, for trees and planar graphs the data structures we present are
succinct. Our tree structures permit efficient bottom-up path traversal in
rooted trees of arbitrary degree and efficient top-down path traversal in
binary trees. In the graph setting, we permit efficient traversal of an
arbitrary path in bounded degree planar graphs. Our data structures for both
trees and graphs match or slightly improve current best results for external
memory path traversal in these settings while at the same time improving space
bounds due to the succinct nature of our data structures. Employing our path
traversal structure for bounded degree planar graphs, we describe a number of
useful applications of this technique for triangular meshes in R^2. As an
extension of the R^2 representation for triangular meshes we also present an
efficient external memory representation for well-shaped tetrahedral meshes in
R^3. The external memory representation we present is based on a partitioning
scheme that matches the current best-known results for well-shaped tetrahedral
meshes. We describe applications of path traversal in tetrahedral meshes which
are made efficient in the external memory setting using our structure. Finally,
we present a result on using jump-and-walk point location in well-shaped meshes
in both R^2 and R^3. We demonstrate that, given an approximate nearest
neighbour from among the vertices of a mesh, locating the simplex containing
the query point involves a constant length walk (path traversal) in the mesh.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4477</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4477</id><created>2013-08-20</created><updated>2014-09-13</updated><authors><author><keyname>Ye</keyname><forenames>Tong</forenames></author><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author><author><keyname>Hu</keyname><forenames>Weisheng</forenames></author></authors><title>AWG-based Non-blocking Clos Networks</title><categories>cs.NI</categories><comments>Add some contents to the manuscript in page 2, 12 and 13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The three-stage Clos networks remain the most popular solution to many
practical switching systems to date. The aim of this paper is to show that the
modular structure of Clos networks is invariant with respect to the
technological changes. Due to the wavelength routing property of
arrayed-waveguide gratings (AWGs), non-blocking and contention-free
wavelength-division-multiplexing (WDM) switches require that two calls carried
by the same wavelength must be connected by separated links; otherwise, they
must be carried by different wavelengths. Thus, in addition to the non-blocking
condition, the challenge of the design of AWG-based multistage switching
networks is to scale down the wavelength granularity and to reduce the
conversion range of tunable wavelength converters (TWCs). We devise a logic
scheme to partition the WDM switch network into wavelength autonomous cells,
and show that the wavelength scalability problem can be solved by recursively
reusing similar, but smaller, set of wavelengths in different cells.
Furthermore, we prove that the rearrangeably non-blocking (RNB) condition and
route assignments in these AWG-based three-stage networks are consistent with
that of classical Clos networks. Thus, the optimal AWG-based non-blocking Clos
networks also can achieve 100% utilization when all input and output wavelength
channels are busy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4479</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4479</id><created>2013-08-20</created><authors><author><keyname>Luo</keyname><forenames>Juan</forenames></author><author><keyname>Lepage</keyname><forenames>Yves</forenames></author></authors><title>An Investigation of the Sampling-Based Alignment Method and Its
  Contributions</title><categories>cs.CL</categories><comments>11 pages</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA), Vol. 4, No. 4, July 2013</journal-ref><doi>10.5121/ijaia.2013.4402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By investigating the distribution of phrase pairs in phrase translation
tables, the work in this paper describes an approach to increase the number of
n-gram alignments in phrase translation tables output by a sampling-based
alignment method. This approach consists in enforcing the alignment of n-grams
in distinct translation subtables so as to increase the number of n-grams.
Standard normal distribution is used to allot alignment time among translation
subtables, which results in adjustment of the distribution of n- grams. This
leads to better evaluation results on statistical machine translation tasks
than the original sampling-based alignment approach. Furthermore, the
translation quality obtained by merging phrase translation tables computed from
the sampling-based alignment method and from MGIZA++ is examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4485</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4485</id><created>2013-08-21</created><authors><author><keyname>Sharma</keyname><forenames>Neeta</forenames></author><author><keyname>Kumar</keyname><forenames>Manoj</forenames></author></authors><title>The Wonderful Toy of 20th Century can be a Disaster in 21st
  Century:Scenario and Policies Regarding Mobile Waste in India</title><categories>cs.CY</categories><comments>6 pages, 1 figure, 2 tables</comments><journal-ref>(IJCSIT) International Journal of Computer Science and Information
  Technologies, Vol. 2 (5) , 2011, 2198-2203 ISSN:0975-9646</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subscribers base of mobile phones is increasing globally with a rapid
rate.The sale of mobile phones has exceeded those of personal computers.India
is the second largest telecommunication network in the world in terms of number
of wireless connections after China.Telecom companies are ready to tap a large
unexplored market in India with lucrative offerings.Smart phones sale are at
its peak.3G technology is also ready to play a lead role in mobile
revolution.Due to the low average life of the mobile phones,lack of awareness
among users and in absence of government policies,mobile waste is accumulating
in vast amount in India.Without a proper system of recycling,the unsafe
disposal is causing a variety of environmental and health problems.This paper
discusses the various issues related to the worldwide growth of mobile
phones,the insecure methods of disposal and the regulations and policies in
India.We intend to put forward some challenges and advices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4486</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4486</id><created>2013-08-21</created><authors><author><keyname>Kumar</keyname><forenames>Manoj</forenames></author><author><keyname>Rathi</keyname><forenames>Sheshendra</forenames></author></authors><title>Services in Android can Share Your Personal Information in Background</title><categories>cs.OH</categories><comments>4 pages, 3 figures</comments><journal-ref>(IJCSIT) International Journal of Computer Science and Information
  Technologies, Vol. 2 (5) , 2011, 2356-2359 ISSN:0975-9646</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile phones have traveled a very long journey in a very short span of time
since its inception in 1973.This wonderful toy of 20th century has started
playing significant role in daily life.More than 5 billion mobile users are
there around the world and almost 90 percent of the entire earth is under the
mobile coverage now.These days smart phones are equipped with numerous
features,faster processors and high storage capacity.Android is a latest trend
in this series whose popularity is growing by leaps and bounds.Android has a
number of components which helps Application developers to embed distinguish
features in applications.This paper explains how the Service component of
Android can share your personal information to others without users
interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4499</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4499</id><created>2013-08-21</created><authors><author><keyname>Xia</keyname><forenames>Jing</forenames></author><author><keyname>Wang</keyname><forenames>Liuquan</forenames></author><author><keyname>Xiong</keyname><forenames>Maosheng</forenames></author></authors><title>On a question of Babadi and Tarokh II</title><categories>cs.IT math.IT</categories><msc-class>11B99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we continue to study a question proposed by Babadi and Tarokh
\cite{ba2} on the mysterious randomness of Gold sequences. Upon improving their
result, we establish the randomness of product of pseudorandom matrices formed
from two linear block codes with respect to the empirical spectral
distribution, if the dual distance of both codes is at least 5, hence providing
an affirmative answer to the question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4501</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4501</id><created>2013-08-21</created><authors><author><keyname>Han</keyname><forenames>Kai</forenames></author><author><keyname>Zhang</keyname><forenames>Chi</forenames></author><author><keyname>Luo</keyname><forenames>Jun</forenames></author></authors><title>Truthful Scheduling Mechanisms for Powering Mobile Crowdsensing</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile crowdsensing leverages mobile devices (e.g., smart phones) and human
mobility for pervasive information exploration and collection; it has been
deemed as a promising paradigm that will revolutionize various research and
application domains. Unfortunately, the practicality of mobile crowdsensing can
be crippled due to the lack of incentive mechanisms that stimulate human
participation. In this paper, we study incentive mechanisms for a novel Mobile
Crowdsensing Scheduling (MCS) problem, where a mobile crowdsensing application
owner announces a set of sensing tasks, then human users (carrying mobile
devices) compete for the tasks based on their respective sensing costs and
available time periods, and finally the owner schedules as well as pays the
users to maximize its own sensing revenue under a certain budget. We prove that
the MCS problem is NP-hard and propose polynomial-time approximation mechanisms
for it. We also show that our approximation mechanisms (including both offline
and online versions) achieve desirable game-theoretic properties, namely
truthfulness and individual rationality, as well as O(1) performance ratios.
Finally, we conduct extensive simulations to demonstrate the correctness and
effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4506</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4506</id><created>2013-08-21</created><authors><author><keyname>Aboudib</keyname><forenames>Ala</forenames></author><author><keyname>Gripon</keyname><forenames>Vincent</forenames></author><author><keyname>Jiang</keyname><forenames>Xiaoran</forenames></author></authors><title>A study of retrieval algorithms of sparse messages in networks of neural
  cliques</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Associative memories are data structures addressed using part of the content
rather than an index. They offer good fault reliability and biological
plausibility. Among different families of associative memories, sparse ones are
known to offer the best efficiency (ratio of the amount of bits stored to that
of bits used by the network itself). Their retrieval process performance has
been shown to benefit from the use of iterations. However classical algorithms
require having prior knowledge about the data to retrieve such as the number of
nonzero symbols. We introduce several families of algorithms to enhance the
retrieval process performance in recently proposed sparse associative memories
based on binary neural networks. We show that these algorithms provide better
performance, along with better plausibility than existing techniques. We also
analyze the required number of iterations and derive corresponding curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4516</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4516</id><created>2013-08-21</created><authors><author><keyname>Chen</keyname><forenames>Zhe</forenames></author></authors><title>On the Generative Power of Omega-Grammars and Omega-Automata</title><categories>cs.FL cs.LO</categories><acm-class>F.1.1; F.4.3</acm-class><journal-ref>Fundamenta Informaticae 111(2):119-145 (2011)</journal-ref><doi>10.3233/FI-2011-557</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An \omega-grammar is a formal grammar used to generate \omega-words (i.e.
infinite length words), while an \omega-automaton is an automaton used to
recognize \omega-words. This paper gives clean and uniform definitions for
\omega-grammars and \omega-automata, provides a systematic study of the
generative power of \omega-grammars with respect to \omega-automata, and
presents a complete set of results for various types of \omega-grammars and
acceptance modes. We use the tuple (\sigma,\rho,\pi) to denote various
acceptance modes, where \sigma denotes that some designated elements should
appear at least once or infinitely often, \rho denotes some binary relation
between two sets, and \pi denotes normal or leftmost derivations. Technically,
we propose (\sigma,\rho,\pi)-accepting \omega-grammars, and systematically
study their relative generative power with respect to (\sigma,\rho)-accepting
\omega-automata. We show how to construct some special forms of
\omega-grammars, such as \epsilon-production-free \omega-grammars. We study the
equivalence or inclusion relations between \omega$-grammars and \omega-automata
by establishing the translation techniques. In particular, we show that, for
some acceptance modes, the generative power of \omega-CFG is strictly weaker
than \omega-PDA, and the generative power of \omega-CSG is equal to \omega-TM
(rather than linear-bounded \omega-automata-like devices). Furthermore, we
raise some remaining open problems for two of the acceptance modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4526</identifier>
 <datestamp>2015-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4526</id><created>2013-08-21</created><updated>2013-09-10</updated><authors><author><keyname>Benzm&#xfc;ller</keyname><forenames>Christoph</forenames></author><author><keyname>Paleo</keyname><forenames>Bruno Woltzenlogel</forenames></author></authors><title>Formalization, Mechanization and Automation of G\&quot;odel's Proof of God's
  Existence</title><categories>cs.LO cs.AI math.LO</categories><comments>2 pages</comments><msc-class>03Axx, 68T27, 68T30, 68T15</msc-class><acm-class>F.4.1; I.2.3; I.2.4</acm-class><doi>10.3233/978-1-61499-419-0-93</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goedel's ontological proof has been analysed for the first-time with an
unprecedent degree of detail and formality with the help of higher-order
theorem provers. The following has been done (and in this order): A detailed
natural deduction proof. A formalization of the axioms, definitions and
theorems in the TPTP THF syntax. Automatic verification of the consistency of
the axioms and definitions with Nitpick. Automatic demonstration of the
theorems with the provers LEO-II and Satallax. A step-by-step formalization
using the Coq proof assistant. A formalization using the Isabelle proof
assistant, where the theorems (and some additional lemmata) have been automated
with Sledgehammer and Metis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4534</identifier>
 <datestamp>2014-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4534</id><created>2013-08-21</created><updated>2014-05-28</updated><authors><author><keyname>Biro</keyname><forenames>P.</forenames></author><author><keyname>Manlove</keyname><forenames>D. F.</forenames></author><author><keyname>McBride</keyname><forenames>I.</forenames></author></authors><title>The Hospitals / Residents Problem with Couples: Complexity and Integer
  Programming Models</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hospitals / Residents problem with Couples (HRC) is a generalisation of
the classical Hospitals / Resident problem (HR) that is important in practical
applications because it models the case where couples submit joint preference
lists over pairs of (typically geographically close) hospitals. In this paper
we give a new NP-completeness result for the problem of deciding whether a
stable matching exists, in highly restricted instances of HRC. Further, we
present an Integer Programming (IP) model for HRC and extend it the case where
preference lists can include ties. Also, we describe an empirical study of an
IP model or HRC and its extension to the case where preference lists can
include ties. This model was applied to randomly generated instances and also
real-world instances arising from previous matching runs of the Scottish
Foundation Allocation Scheme, used to allocate junior doctors to hospitals in
Scotland.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4560</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4560</id><created>2013-08-21</created><authors><author><keyname>Akin</keyname><forenames>Sami</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>On the Throughput and Energy Efficiency of Cognitive MIMO Transmissions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, throughput and energy efficiency of cognitive multiple-input
multiple-output (MIMO) systems operating under quality-of-service (QoS)
constraints, interference limitations, and imperfect channel sensing, are
studied. It is assumed that transmission power and covariance of the input
signal vectors are varied depending on the sensed activities of primary users
(PUs) in the system. Interference constraints are applied on the transmission
power levels of cognitive radios (CRs) to provide protection for the PUs whose
activities are modeled as a Markov chain. Considering the reliability of the
transmissions and channel sensing results, a state-transition model is
provided. Throughput is determined by formulating the effective capacity. First
derivative of the effective capacity is derived in the low-power regime and the
minimum bit energy requirements in the presence of QoS limitations and
imperfect sensing results are identified. Minimum energy per bit is shown to be
achieved by beamforming in the maximal-eigenvalue eigenspace of certain
matrices related to the channel matrix. In a special case, wideband slope is
determined for more refined analysis of energy efficiency. Numerical results
are provided for the throughput for various levels of buffer constraints and
different number of transmit and receive antennas. The impact of interference
constraints and benefits of multiple-antenna transmissions are determined. It
is shown that increasing the number of antennas when the interference power
constraint is stringent is generally beneficial. On the other hand, it is shown
that under relatively loose interference constraints, increasing the number of
antennas beyond a certain level does not lead to much increase in the
throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4565</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4565</id><created>2013-08-21</created><updated>2013-08-25</updated><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Decentralized Online Big Data Classification - a Bandit Framework</title><categories>cs.LG cs.MA</categories><comments>arXiv admin note: substantial text overlap with arXiv:1307.0781</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed, online data mining systems have emerged as a result of
applications requiring analysis of large amounts of correlated and
high-dimensional data produced by multiple distributed data sources. We propose
a distributed online data classification framework where data is gathered by
distributed data sources and processed by a heterogeneous set of distributed
learners which learn online, at run-time, how to classify the different data
streams either by using their locally available classification functions or by
helping each other by classifying each other's data. Importantly, since the
data is gathered at different locations, sending the data to another learner to
process incurs additional costs such as delays, and hence this will be only
beneficial if the benefits obtained from a better classification will exceed
the costs. We assume that the classification functions available to each
processing element are fixed, but their prediction accuracy for various types
of incoming data are unknown and can change dynamically over time, and thus
they need to be learned online. We model the problem of joint classification by
the distributed and heterogeneous learners from multiple data sources as a
distributed contextual bandit problem where each data is characterized by a
specific context. We develop distributed online learning algorithms for which
we can prove that they have sublinear regret. Compared to prior work in
distributed online data mining, our work is the first to provide analytic
regret results characterizing the performance of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4568</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4568</id><created>2013-08-21</created><updated>2015-03-23</updated><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Distributed Online Learning via Cooperative Contextual Bandits</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel framework for decentralized, online learning
by many learners. At each moment of time, an instance characterized by a
certain context may arrive to each learner; based on the context, the learner
can select one of its own actions (which gives a reward and provides
information) or request assistance from another learner. In the latter case,
the requester pays a cost and receives the reward but the provider learns the
information. In our framework, learners are modeled as cooperative contextual
bandits. Each learner seeks to maximize the expected reward from its arrivals,
which involves trading off the reward received from its own actions, the
information learned from its own actions, the reward received from the actions
requested of others and the cost paid for these actions - taking into account
what it has learned about the value of assistance from each other learner. We
develop distributed online learning algorithms and provide analytic bounds to
compare the efficiency of these with algorithms with the complete knowledge
(oracle) benchmark (in which the expected reward of every action in every
context is known by every learner). Our estimates show that regret - the loss
incurred by the algorithm - is sublinear in time. Our theoretical framework can
be used in many practical applications including Big Data mining, event
detection in surveillance sensor networks and distributed online recommendation
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4572</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4572</id><created>2013-08-21</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Codeword or noise? Exact random coding exponents for slotted
  asynchronism</title><categories>cs.IT math.IT</categories><comments>23 pages; Submitted to IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of slotted asynchronous coded communication, where in
each time frame (slot), the transmitter is either silent or transmits a
codeword from a given (randomly selected) codebook. The task of the decoder is
to decide whether transmission has taken place, and if so, to decode the
message. We derive the optimum detection/decoding rule in the sense of the best
trade-off among the probabilities of decoding error, false alarm, and
misdetection. For this detection/decoding rule, we then derive single-letter
characterizations of the exact exponential rates of these three probabilities
for the average code in the ensemble.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4577</identifier>
 <datestamp>2013-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4577</id><created>2013-08-21</created><authors><author><keyname>Youssef</keyname><forenames>Mina</forenames></author><author><keyname>Khorramzadeh</keyname><forenames>Yasamin</forenames></author><author><keyname>Eubank</keyname><forenames>Stephen</forenames></author></authors><title>Network Reliability: The effect of local network structure on diffusive
  processes</title><categories>physics.soc-ph cs.SI physics.comp-ph</categories><comments>12 pages, 8 figures, 1 table</comments><journal-ref>Phys. Rev. E 88, 052810 (2013)</journal-ref><doi>10.1103/PhysRevE.88.052810</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper re-introduces the network reliability polynomial - introduced by
Moore and Shannon in 1956 -- for studying the effect of network structure on
the spread of diseases. We exhibit a representation of the polynomial that is
well-suited for estimation by distributed simulation. We describe a collection
of graphs derived from Erd\H{o}s-R\'enyi and scale-free-like random graphs in
which we have manipulated assortativity-by-degree and the number of triangles.
We evaluate the network reliability for all these graphs under a reliability
rule that is related to the expected size of a connected component. Through
these extensive simulations, we show that for positively or neutrally
assortative graphs, swapping edges to increase the number of triangles does not
increase the network reliability. Also, positively assortative graphs are more
reliable than neutral or disassortative graphs with the same number of edges.
Moreover, we show the combined effect of both assortativity-by-degree and the
presence of triangles on the critical point and the size of the smallest
subgraph that is reliable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4618</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4618</id><created>2013-08-21</created><authors><author><keyname>Bell</keyname><forenames>Michael J.</forenames></author><author><keyname>Collison</keyname><forenames>Matthew</forenames></author><author><keyname>Lord</keyname><forenames>Phillip</forenames></author></authors><title>Can inferred provenance and its visualisation be used to detect
  erroneous annotation? A case study using UniProtKB</title><categories>cs.CL cs.CE cs.DL q-bio.QM</categories><comments>Paper to shortly appear in PLOS ONE. Composed of 21 pages and 16
  figures</comments><doi>10.1371/journal.pone.0075541</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A constant influx of new data poses a challenge in keeping the annotation in
biological databases current. Most biological databases contain significant
quantities of textual annotation, which often contains the richest source of
knowledge. Many databases reuse existing knowledge, during the curation process
annotations are often propagated between entries. However, this is often not
made explicit. Therefore, it can be hard, potentially impossible, for a reader
to identify where an annotation originated from. Within this work we attempt to
identify annotation provenance and track its subsequent propagation.
Specifically, we exploit annotation reuse within the UniProt Knowledgebase
(UniProtKB), at the level of individual sentences. We describe a visualisation
approach for the provenance and propagation of sentences in UniProtKB which
enables a large-scale statistical analysis. Initially levels of sentence reuse
within UniProtKB were analysed, showing that reuse is heavily prevalent, which
enables the tracking of provenance and propagation. By analysing sentences
throughout UniProtKB, a number of interesting propagation patterns were
identified, covering over 100, 000 sentences. Over 8000 sentences remain in the
database after they have been removed from the entries where they originally
occurred. Analysing a subset of these sentences suggest that approximately 30%
are erroneous, whilst 35% appear to be inconsistent. These results suggest that
being able to visualise sentence propagation and provenance can aid in the
determination of the accuracy and quality of textual annotation. Source code
and supplementary data are available from the authors website.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4643</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4643</id><created>2013-08-20</created><authors><author><keyname>Fioriti</keyname><forenames>Enzo</forenames></author><author><keyname>Chnnici</keyname><forenames>Marta</forenames></author><author><keyname>Arbore</keyname><forenames>Andrea</forenames></author></authors><title>Topological security assessment of technological networks</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spreading of dangerous malware or faults in inter-dependent networks of
electronics devices has raised deep concern, because from the ICT networks
infections may propagate to other Critical Infrastructures producing the
well-known domino or cascading effect. Researchers are attempting to develop a
high level analysis of malware propagation discarding software details, in
order to generalize to the maximum extent the defensive strategies. For
example, it has been suggested that the maximum eigenvalue of the network
adjacency matrix could act as a threshold for the malware's spreading. This
leads naturally to use the spectral graph theory to identify the most critical
and influential nodes in technological networks. Many well-known graph
parameters have been studied in the past years to accomplish the task. Here we
test our AV11 algorithm showing that outperforms degree, closeness, betweenness
centrality and the dynamical importance
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4648</identifier>
 <datestamp>2013-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4648</id><created>2013-08-21</created><updated>2013-10-11</updated><authors><author><keyname>McNeil</keyname><forenames>Nikki</forenames></author><author><keyname>Bridges</keyname><forenames>Robert A.</forenames></author><author><keyname>Iannacone</keyname><forenames>Michael D.</forenames></author><author><keyname>Czejdo</keyname><forenames>Bogdan</forenames></author><author><keyname>Perez</keyname><forenames>Nicolas</forenames></author><author><keyname>Goodall</keyname><forenames>John R.</forenames></author></authors><title>PACE: Pattern Accurate Computationally Efficient Bootstrapping for
  Timely Discovery of Cyber-Security Concepts</title><categories>cs.IR cs.CL</categories><comments>6 pages, 3 figures, ieeeTran conference. International Conference on
  Machine Learning and Applications 2013</comments><msc-class>IEEE</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Public disclosure of important security information, such as knowledge of
vulnerabilities or exploits, often occurs in blogs, tweets, mailing lists, and
other online sources months before proper classification into structured
databases. In order to facilitate timely discovery of such knowledge, we
propose a novel semi-supervised learning algorithm, PACE, for identifying and
classifying relevant entities in text sources. The main contribution of this
paper is an enhancement of the traditional bootstrapping method for entity
extraction by employing a time-memory trade-off that simultaneously circumvents
a costly corpus search while strengthening pattern nomination, which should
increase accuracy. An implementation in the cyber-security domain is discussed
as well as challenges to Natural Language Processing imposed by the security
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4670</identifier>
 <datestamp>2014-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4670</id><created>2013-08-21</created><updated>2014-12-18</updated><authors><author><keyname>Fekete</keyname><forenames>S&#xe1;ndor P.</forenames></author><author><keyname>Friedrichs</keyname><forenames>Stephan</forenames></author><author><keyname>Kr&#xf6;ller</keyname><forenames>Alexander</forenames></author><author><keyname>Schmidt</keyname><forenames>Christiane</forenames></author></authors><title>Facets for Art Gallery Problems</title><categories>cs.CG cs.DS math.OC</categories><comments>29 pages, 18 figures, 1 table</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Art Gallery Problem (AGP) asks for placing a minimum number of stationary
guards in a polygonal region P, such that all points in P are guarded. The
problem is known to be NP-hard, and its inherent continuous structure (with
both the set of points that need to be guarded and the set of points that can
be used for guarding being uncountably infinite) makes it difficult to apply a
straightforward formulation as an Integer Linear Program. We use an iterative
primal-dual relaxation approach for solving AGP instances to optimality. At
each stage, a pair of LP relaxations for a finite candidate subset of primal
covering and dual packing constraints and variables is considered; these
correspond to possible guard positions and points that are to be guarded.
  Particularly useful are cutting planes for eliminating fractional solutions.
We identify two classes of facets, based on Edge Cover and Set Cover (SC)
inequalities. Solving the separation problem for the latter is NP-complete, but
exploiting the underlying geometric structure, we show that large subclasses of
fractional SC solutions cannot occur for the AGP. This allows us to separate
the relevant subset of facets in polynomial time. We also characterize all
facets for finite AGP relaxations with coefficients in {0, 1, 2}.
  Finally, we demonstrate the practical usefulness of our approach. Our cutting
plane technique yields a significant improvement in terms of speed and solution
quality due to considerably reduced integrality gaps as compared to the
approach by Kr\&quot;oller et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4672</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4672</id><created>2013-08-08</created><authors><author><keyname>Sharad</keyname><forenames>Mrigank</forenames></author><author><keyname>Fan</keyname><forenames>Deliang</forenames></author><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author></authors><title>Ultra-low Energy, High-Performance Dynamic Resistive Threshold Logic</title><categories>cs.ET cond-mat.dis-nn cs.AR</categories><comments>arXiv admin note: text overlap with arXiv:1308.4169</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose dynamic resistive threshold-logic (DRTL) design based on
non-volatile resistive memory. A threshold logic gate (TLG) performs summation
of multiple inputs multiplied by a fixed set of weights and compares the sum
with a threshold. DRTL employs resistive memory elements to implement the
weights and the thresholds, while a compact dynamic CMOS latch is used for the
comparison operation. The resulting DRTL gate acts as a low-power, configurable
dynamic logic unit and can be used to build fully pipelined, high-performance
programmable computing blocks. Multiple stages in such a DRTL design can be
connected using energy-efficient low swing programmable interconnect networks
based on resistive switches. Owing to memory-based compact logic and
interconnect design and highspeed dynamic-pipelined operation, DRTL can achieve
more than two orders of magnitude improvement in energy-delay product as
compared to look-up table based CMOS FPGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4675</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4675</id><created>2013-08-16</created><authors><author><keyname>Hermawanto</keyname><forenames>Denny</forenames></author></authors><title>Genetic Algorithm for Solving Simple Mathematical Equality Problem</title><categories>cs.NE</categories><comments>Tutorial paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explains genetic algorithm for novice in this field. Basic
philosophy of genetic algorithm and its flowchart are described. Step by step
numerical computation of genetic algorithm for solving simple mathematical
equality problem will be briefly explained
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4687</identifier>
 <datestamp>2013-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4687</id><created>2013-08-21</created><authors><author><keyname>Sharma</keyname><forenames>Manish</forenames></author><author><keyname>Chaudhary</keyname><forenames>Atul</forenames></author><author><keyname>Kumar</keyname><forenames>Santosh</forenames></author></authors><title>Query Processing Performance and Searching Over Encrypted Data By Using
  An Efficient Algorithm</title><categories>cs.DB cs.CR</categories><comments>4 Pages, 2 Figures, 2 Tables Published With &quot;International Journal of
  Computer Applications (IJCA)&quot;</comments><journal-ref>International Journal of Computer Applications 62(10):5-8, January
  2013</journal-ref><doi>10.5120/10114-4781 10.5120/10114-4781 10.5120/10114-4781</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data is the central asset of today's dynamically operating organization and
their business. This data is usually stored in database. A major consideration
is applied on the security of that data from the unauthorized access and
intruders. Data encryption is a strong option for security of data in database
and especially in those organizations where security risks are high. But there
is a potential disadvantage of performance degradation. When we apply
encryption on database then we should compromise between the security and
efficient query processing. The work of this paper tries to fill this gap. It
allows the users to query over the encrypted column directly without decrypting
all the records. It's improves the performance of the system. The proposed
algorithm works well in the case of range and fuzzy match queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4715</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4715</id><created>2013-08-21</created><authors><author><keyname>Komarov</keyname><forenames>Natasha</forenames></author><author><keyname>Winkler</keyname><forenames>Peter</forenames></author></authors><title>Cops vs. Gambler</title><categories>math.CO cs.DM</categories><comments>6 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a variation of cop vs.\ robber on graph in which the robber is
not restricted by the graph edges; instead, he picks a time-independent
probability distribution on $V(G)$ and moves according to this fixed
distribution. The cop moves from vertex to adjacent vertex with the goal of
minimizing expected capture time. Players move simultaneously. We show that
when the gambler's distribution is known, the expected capture time (with best
play) on any connected $n$-vertex graph is exactly $n$. We also give bounds on
the (generally greater) expected capture time when the gambler's distribution
is unknown to the cop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4718</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4718</id><created>2013-08-21</created><authors><author><keyname>Balan</keyname><forenames>Radu</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author></authors><title>Invertibility and Robustness of Phaseless Reconstruction</title><categories>math.FA cs.CV stat.ML</categories><comments>19 pages</comments><msc-class>15A29, 65H10, 90C26</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the question of reconstructing a vector in a
finite-dimensional real Hilbert space when only the magnitudes of the
coefficients of the vector under a redundant linear map are known. We analyze
various Lipschitz bounds of the nonlinear analysis map and we establish
theoretical performance bounds of any reconstruction algorithm. We show that
robust and stable reconstruction requires additional redundancy than the
critical threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4751</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4751</id><created>2013-08-21</created><authors><author><keyname>Zhou</keyname><forenames>Yaqin</forenames></author><author><keyname>Li</keyname><forenames>Xiang-yang</forenames></author><author><keyname>Li</keyname><forenames>Fan</forenames></author><author><keyname>Liu</keyname><forenames>Min</forenames></author><author><keyname>Li</keyname><forenames>Zhongcheng</forenames></author><author><keyname>Yin</keyname><forenames>Zhiyuan</forenames></author></authors><title>Almost Optimal Channel Access in Multi-Hop Networks With Unknown Channel
  Variables</title><categories>cs.NI</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider distributed channel access in multi-hop cognitive radio networks.
Previous works on opportunistic channel access using multi-armed bandits (MAB)
mainly focus on single-hop networks that assume complete conflicts among all
secondary users. In the multi-hop multi-channel network settings studied here,
there is more general competition among different communication pairs. We
formulate the problem as a linearly combinatorial MAB problem that involves a
maximum weighted independent set (MWIS) problem with unknown weights which need
to learn. Existing methods for MAB where each of $N$ nodes chooses from $M$
channels have exponential time and space complexity $O(M^N)$, and poor
theoretical guarantee on throughput performance. We propose a distributed
channel access algorithm that can achieve $1/\rho$ of the optimum averaged
throughput where each node has communication complexity $O(r^2+D)$ and space
complexity $O(m)$ in the learning process, and time complexity $O(D
m^{\rho^r})$ in strategy decision process for an arbitrary wireless network.
Here $\rho=1+\epsilon$ is the approximation ratio to MWIS for a local $r$-hop
network with $m&lt;N$ nodes,and $D$ is the number of mini-rounds inside each round
of strategy decision. For randomly located networks with an average degree $d$,
the time complexity is $O(d^{\rho^r})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4757</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4757</id><created>2013-08-21</created><updated>2013-09-25</updated><authors><author><keyname>Shi</keyname><forenames>Ziqiang</forenames></author></authors><title>Online Douglas-Rachford splitting method</title><categories>cs.NA cs.LG stat.ML</categories><comments>Ongoing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online learning has emerged as powerful tool in large scale optimization. In
this work, we generalize the Douglas-Rachford splitting method for minimizing
composite functions to online settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4761</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4761</id><created>2013-08-22</created><authors><author><keyname>Wijaya</keyname><forenames>Tri Kurniawan</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author><author><keyname>Aberer</keyname><forenames>Karl</forenames></author></authors><title>Matching Demand with Supply in the Smart Grid using Agent-Based
  Multiunit Auction</title><categories>cs.AI cs.GT</categories><journal-ref>2013 Fifth International Conference on Communication Systems and
  Networks (COMSNETS), vol., no., pp.1,6, 7-10 Jan. 2013</journal-ref><doi>10.1109/COMSNETS.2013.6465595</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has suggested reducing electricity generation cost by cutting the
peak to average ratio (PAR) without reducing the total amount of the loads.
However, most of these proposals rely on consumer's willingness to act. In this
paper, we propose an approach to cut PAR explicitly from the supply side. The
resulting cut loads are then distributed among consumers by the means of a
multiunit auction which is done by an intelligent agent on behalf of the
consumer. This approach is also in line with the future vision of the smart
grid to have the demand side matched with the supply side. Experiments suggest
that our approach reduces overall system cost and gives benefit to both
consumers and the energy provider.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4764</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4764</id><created>2013-08-22</created><authors><author><keyname>Zamani</keyname><forenames>Mohsen</forenames></author><author><keyname>Bottegal</keyname><forenames>Giulio</forenames></author><author><keyname>Anderson</keyname><forenames>Brian D. O.</forenames></author></authors><title>On the Zero-freeness of Tall Multirate Linear Systems</title><categories>cs.SY</categories><comments>This is draft of the paper submitted for possible publication in IEEE
  Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, tall discrete-time linear systems with multirate outputs are
studied. In particular, we focus on their zeros. In systems and control
literature zeros of multirate systems are defined as those of their
corresponding time-invariant blocked systems. Hence, the zeros of tall blocked
systems resulting from blocking of linear systems with multirate outputs are
mainly explored in this work. We specifically investigate zeros of tall blocked
systems formed by blocking tall multirate linear systems with generic parameter
matrices. It is demonstrated that tall blocked systems generically have no
finite nonzero zeros; however, they may have zeros at the origin or at infinity
depending on the choice of blocking delay and the input, state and output
dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4767</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4767</id><created>2013-08-22</created><authors><author><keyname>Hofferek</keyname><forenames>Georg</forenames></author><author><keyname>Gupta</keyname><forenames>Ashutosh</forenames></author><author><keyname>K&#xf6;nighofer</keyname><forenames>Bettina</forenames></author><author><keyname>Jiang</keyname><forenames>Jie-Hong Roland</forenames></author><author><keyname>Bloem</keyname><forenames>Roderick</forenames></author></authors><title>Synthesizing Multiple Boolean Functions using Interpolation on a Single
  Proof</title><categories>cs.LO</categories><comments>This paper originally appeared in FMCAD 2013,
  http://www.cs.utexas.edu/users/hunt/FMCAD/FMCAD13/index.shtml. This version
  includes an appendix that is missing in the conference version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is often difficult to correctly implement a Boolean controller for a
complex system, especially when concurrency is involved. Yet, it may be easy to
formally specify a controller. For instance, for a pipelined processor it
suffices to state that the visible behavior of the pipelined system should be
identical to a non-pipelined reference system (Burch-Dill paradigm). We present
a novel procedure to efficiently synthesize multiple Boolean control signals
from a specification given as a quantified first-order formula (with a specific
quantifier structure). Our approach uses uninterpreted functions to abstract
details of the design. We construct an unsatisfiable SMT formula from the given
specification. Then, from just one proof of unsatisfiability, we use a variant
of Craig interpolation to compute multiple coordinated interpolants that
implement the Boolean control signals. Our method avoids iterative learning and
back-substitution of the control functions. We applied our approach to
synthesize a controller for a simple two-stage pipelined processor, and present
first experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4774</identifier>
 <datestamp>2013-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4774</id><created>2013-08-22</created><authors><author><keyname>Cui</keyname><forenames>Cewei</forenames></author><author><keyname>Dang</keyname><forenames>Zhe</forenames></author><author><keyname>Fischer</keyname><forenames>Thomas R.</forenames></author></authors><title>Bit Rate of Programs</title><categories>cs.SE cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A program can be considered as a device that generates discrete time signals,
where a signal is an execution. Shannon information rate, or bit rate, of the
signals may not be uniformly distributed. When the program is specified by a
finite state transition system, algorithms are provided in identifying
information-rich components. For a black-box program that has a partial
specification or does not even have a specification, a bit rate signal and its
spectrum are studied, which make use of data compression and the Fourier
transform. The signal provides a bit-rate coverage for testing the black-box
while its spectrum indicates a visual representation for execution's
information characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4777</identifier>
 <datestamp>2014-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4777</id><created>2013-08-22</created><updated>2014-01-20</updated><authors><author><keyname>Fei</keyname><forenames>Zesong</forenames></author><author><keyname>Xing</keyname><forenames>Chengwen</forenames></author><author><keyname>Li</keyname><forenames>Na</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>Adaptive Multi-objective Optimization for Energy Efficient Interference
  Coordination in Multi-Cell Networks</title><categories>cs.IT math.IT</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the distributed power allocation for multi-cell
OFDMA networks taking both energy efficiency and inter-cell interference (ICI)
mitigation into account. A performance metric termed as throughput contribution
is exploited to measure how ICI is effectively coordinated. To achieve a
distributed power allocation scheme for each base station (BS), the throughput
contribution of each BS to the network is first given based on a pricing
mechanism. Different from existing works, a biobjective problem is formulated
based on multi-objective optimization theory, which aims at maximizing the
throughput contribution of the BS to the network and minimizing its total power
consumption at the same time. Using the method of Pascoletti and Serafini
scalarization, the relationship between the varying parameters and minimal
solutions is revealed. Furthermore, to exploit the relationship an algorithm is
proposed based on which all the solutions on the boundary of the efficient set
can be achieved by adaptively adjusting the involved parameters. With the
obtained solution set, the decision maker has more choices on power allocation
schemes in terms of both energy consumption and throughput. Finally, the
performance of the algorithm is assessed by the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4786</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4786</id><created>2013-08-22</created><authors><author><keyname>Nezhad</keyname><forenames>Qasem Abdollah</forenames></author><author><keyname>Zand</keyname><forenames>Javad Palizvan</forenames></author><author><keyname>Hoseini</keyname><forenames>Samira Shah</forenames></author></authors><title>An Investigation On Fuzzy Logic Controllers (TAKAGI-SUGENO &amp; MAMDANI) In
  Inverse Pendulum System</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of controlling non-linear systems is one the significant fields
in scientific researches for the purpose of which intelligent approaches can
provide desirable applicability. Fuzzy systems are systems with ambiguous
definition and fuzzy control is an especial type of non-linear control. Inverse
pendulum system is one the most widely popular non-linear systems which is
known for its specific characteristics such as being intrinsically non-linear
and unsteady. Therefore, a controller is required for maintaining stability of
the system Present study tries to compare the obtained results from designing
fuzzy intelligent controllers in similar conditions and also identify the
appropriate controller for holding the inverse pendulum in vertical position on
the cart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4791</identifier>
 <datestamp>2014-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4791</id><created>2013-08-22</created><updated>2014-03-10</updated><authors><author><keyname>Suhyuk</keyname><affiliation>Seokbeop</affiliation></author><author><keyname>Kwon</keyname></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author><author><keyname>Shim</keyname><forenames>Byonghyo</forenames></author></authors><title>Multipath Matching Pursuit</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an algorithm referred to as multipath matching
pursuit that investigates multiple promising candidates to recover sparse
signals from compressed measurements. Our method is inspired by the fact that
the problem to find the candidate that minimizes the residual is readily
modeled as a combinatoric tree search problem and the greedy search strategy is
a good fit for solving this problem. In the empirical results as well as the
restricted isometry property (RIP) based performance guarantee, we show that
the proposed MMP algorithm is effective in reconstructing original sparse
signals for both noiseless and noisy scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4801</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4801</id><created>2013-08-22</created><authors><author><keyname>van Schijndel</keyname><forenames>A. W. M.</forenames></author></authors><title>The Mapping of Simulated Climate-Dependent Building Innovations</title><categories>cs.CE</categories><comments>Preliminary conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performances of building energy innovations are most of the time dependent on
the external climate conditions. This means a high performance of a specific
innovation in a certain part of Europe, does not imply the same performances in
other regions. The mapping of simulated building performances at the EU scale
could prevent the waste of potential good ideas by identifying the best region
for a specific innovation. This paper presents a methodology for obtaining maps
of performances of building innovations that are virtually spread over whole
Europe. It is concluded that these maps are useful for finding regions at the
EU where innovations have the highest expected performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4803</identifier>
 <datestamp>2014-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4803</id><created>2013-08-22</created><updated>2014-03-10</updated><authors><author><keyname>Bourgain</keyname><forenames>Jean</forenames></author><author><keyname>Konyagin</keyname><forenames>Sergei</forenames></author><author><keyname>Shparlinski</keyname><forenames>Igor</forenames></author></authors><title>Character Sums and Deterministic Polynomial Root Finding in Finite
  Fields</title><categories>math.NT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain a new bound of certain double multiplicative character sums. We use
this bound together with some other previously obtained results to obtain new
algorithms for finding roots of polynomials modulo a prime $p$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4809</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4809</id><created>2013-08-22</created><authors><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Liang</keyname><forenames>Chulong</forenames></author><author><keyname>Huang</keyname><forenames>Kechao</forenames></author><author><keyname>Zhuang</keyname><forenames>Qiutao</forenames></author></authors><title>Block Markov Superposition Transmission: Construction of Big
  Convolutional Codes from Short Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A construction of big convolutional codes from short codes called block
Markov superposition transmission (BMST) is proposed. The BMST is very similar
to superposition blockMarkov encoding (SBME), which has been widely used to
prove multiuser coding theorems. The encoding process of BMST can be as fast as
that of the involved short code, while the decoding process can be implemented
as an iterative sliding-window decoding algorithm with a tunable delay. More
importantly, the performance of BMST can be simply lower-bounded in terms of
the transmission memory given that the performance of the short code is
available. Numerical results show that, 1) the lower bounds can be matched with
a moderate decoding delay in the low bit-error-rate (BER) region, implying that
the iterative slidingwindow decoding algorithm is near optimal; 2) BMST with
repetition codes and single parity-check codes can approach the Shannon limit
within 0.5 dB at BER of 10^{-5} for a wide range of code rates; and 3) BMST can
also be applied to nonlinear codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4815</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4815</id><created>2013-08-22</created><updated>2013-08-23</updated><authors><author><keyname>Goss</keyname><forenames>Clinton F.</forenames></author></authors><title>Machine Code Optimization - Improving Executable Object Code</title><categories>cs.PL</categories><comments>Technical Report #246, Courant Institute of Mathematical Sciences,
  New York University. Initially published June 1986; Revised August 22, 2013.
  41 pages, 9 figures, 7 tables</comments><msc-class>68N20</msc-class><acm-class>D.3.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This dissertation explores classes of compiler optimization techniques that
are applicable late in the compilation process, after all executable code for a
program has been linked. I concentrate on techniques which, for various
reasons, cannot be applied earlier in the compilation process. In addition to a
theoretical treatment of this class of optimization techniques, this
dissertation reports on an implementation of these techniques in a production
environment. I describe the details of the implementation which allows these
techniques to be re-targeted easily and report on improvements gained when
optimizing production software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4816</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4816</id><created>2013-08-22</created><authors><author><keyname>Bhattachrya</keyname><forenames>Swapan</forenames></author><author><keyname>Banerjee</keyname><forenames>Devmalya</forenames></author><author><keyname>Biswas</keyname><forenames>Abirlal</forenames></author><author><keyname>Biswas</keyname><forenames>Pijush</forenames></author></authors><title>A secured communication link design using narrow line of sight technique</title><categories>cs.NI</categories><journal-ref>International Conference on Information Technology (INTL-INFOTECH
  2007)</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In recent wireless networking optical communication is an emerging field.
Another novel approach of optical communication using Narrow Line of Sight
technique is discussed. Array of trans receivers are placed on the ceiling to
communicate with the mobile nodes (users / trans receivers) instead of a single
transmitter. An intelligent position tracking technique based on the
informations available from prepositioned sensors and using them in simple
geometric equations is described. Intelligent cell concept is used to
facilitate the tracking system. The whole wide area is divided into several sub
areas and some of the sub areas are designated as boundary sub areas which hold
the data regarding the movement of the mobile nodes. The Diffie Hellman simple
authenticated key agreement is used for secure communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4820</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4820</id><created>2013-08-22</created><updated>2013-08-31</updated><authors><author><keyname>Hussain</keyname><forenames>Shariq</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoshun</forenames></author><author><keyname>Rahim</keyname><forenames>Sabit</forenames></author></authors><title>E-learning Services for Rural Communities</title><categories>cs.CY</categories><comments>6 pages, 6 figures, 3 tables</comments><journal-ref>International Journal of Computer Applications, vol.68, no.5,
  2013, pp.15-20</journal-ref><doi>10.5120/11574-6888</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information and communication technologies brought-in tools and techniques in
the field of education that introduced new concepts of teaching and learning.
Learning management system is one of the key tools used in educational
institutes to facilitate e-learning. There is remarkable digital divide among
urban and rural areas. In this paper, we present a model for providing
e-learning services to remote/rural areas in order to promote and facilitate
modern education. A dedicated resource center, hosting the learning management
system, facilitates e-learning centers through Internet. The overall goal of
this model is to have a cost-effective learning environment equipped with
latest technologies to provide learners an opportunity to get insight into new
information and communication technologies and e-learning environment. The
model offers new teaching methodology with enhance utilization of learning
management system in teaching and learning. Basic characteristics and technical
aspects will be considered as well. The study will also promote development and
usage of open-source technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4826</identifier>
 <datestamp>2014-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4826</id><created>2013-08-22</created><authors><author><keyname>Kim</keyname><forenames>Kyeong Soo</forenames></author></authors><title>A Research Framework for the Clean-Slate Design of Next-Generation
  Optical Access</title><categories>cs.NI stat.AP</categories><comments>8 pages, 10 figures</comments><journal-ref>Fiber and Integrated Optics Special Issue on Second Fiber Optics
  in Access Networks (FOAN), vol. 31, issue 2, pp. 90-110, Apr. 2012</journal-ref><doi>10.1080/01468030.2012.654597</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A comprehensive research framework for a comparative analysis of candidate
network architectures and protocols in the clean-slate design of
next-generation optical access is proposed. The proposed research framework
consists of a comparative analysis framework based on multivariate
non-inferiority testing and a notion of equivalent circuit rate taking into
account user-perceived performances, and a virtual test bed providing a
complete experimental platform for the comparative analysis. The capability of
the research framework is demonstrated through numerical results from the study
of the elasticity of hybrid TDM/WDM-PON based on tunable transceivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4828</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4828</id><created>2013-08-22</created><authors><author><keyname>Lattimore</keyname><forenames>Tor</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Sunehag</keyname><forenames>Peter</forenames></author></authors><title>The Sample-Complexity of General Reinforcement Learning</title><categories>cs.LG</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm for general reinforcement learning where the true
environment is known to belong to a finite class of N arbitrary models. The
algorithm is shown to be near-optimal for all but O(N log^2 N) time-steps with
high probability. Infinite classes are also considered where we show that
compactness is a key criterion for determining the existence of uniform
sample-complexity bounds. A matching lower bound is given for the finite case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4839</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4839</id><created>2013-08-22</created><authors><author><keyname>Pehlivan</keyname><forenames>Zeynep</forenames></author><author><keyname>Piwowarski</keyname><forenames>Benjamin</forenames></author><author><keyname>Gan&#xe7;arski</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Diversification Based Static Index Pruning - Application to Temporal
  Collections</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, web archives preserve the history of large portions of the web. As
medias are shifting from printed to digital editions, accessing these huge
information sources is drawing increasingly more attention from national and
international institutions, as well as from the research community. These
collections are intrinsically big, leading to index files that do not fit into
the memory and an increase query response time. Decreasing the index size is a
direct way to decrease this query response time.
  Static index pruning methods reduce the size of indexes by removing a part of
the postings. In the context of web archives, it is necessary to remove
postings while preserving the temporal diversity of the archive. None of the
existing pruning approaches take (temporal) diversification into account.
  In this paper, we propose a diversification-based static index pruning
method. It differs from the existing pruning approaches by integrating
diversification within the pruning context. We aim at pruning the index while
preserving retrieval effectiveness and diversity by pruning while maximizing a
given IR evaluation metric like DCG. We show how to apply this approach in the
context of web archives. Finally, we show on two collections that search
effectiveness in temporal collections after pruning can be improved using our
approach rather than diversity oblivious approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4840</identifier>
 <datestamp>2015-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4840</id><created>2013-08-22</created><updated>2015-05-07</updated><authors><author><keyname>Stupia</keyname><forenames>Ivan</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Bacci</keyname><forenames>Giacomo</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Power Control in Networks With Heterogeneous Users: A Quasi-Variational
  Inequality Approach</title><categories>cs.IT math.IT</categories><comments>14 pages, 4 figures, submitted to IEEE Trans. Signal Process</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work deals with the power allocation problem in a
multipoint-to-multipoint network, which is heterogenous in the sense that each
transmit and receiver pair can arbitrarily choose whether to selfishly maximize
its own rate or energy efficiency. This is achieved by modeling the transmit
and receiver pairs as rational players that engage in a non-cooperative game in
which the utility function changes according to each player's nature. The
underlying game is reformulated as a quasi variational inequality (QVI) problem
using convex fractional program theory. The equivalence between the QVI and the
non-cooperative game provides us with all the mathematical tools to study the
uniqueness of its Nash equilibrium (NE) points and to derive novel algorithms
that allow the network to converge to these points in an iterative manner both
with and without the need for a centralized processing. A small-cell network is
considered as a possible case study of this heterogeneous scenario. Numerical
results are used to validate the proposed solutions in different operating
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4846</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4846</id><created>2013-08-22</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Chmel&#xed;k</keyname><forenames>Martin</forenames></author></authors><title>POMDPs under Probabilistic Semantics</title><categories>cs.AI</categories><comments>Full version of: POMDPs under Probabilistic Semantics, UAI 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider partially observable Markov decision processes (POMDPs) with
limit-average payoff, where a reward value in the interval [0,1] is associated
to every transition, and the payoff of an infinite path is the long-run average
of the rewards. We consider two types of path constraints: (i) quantitative
constraint defines the set of paths where the payoff is at least a given
threshold {\lambda} in (0, 1]; and (ii) qualitative constraint which is a
special case of quantitative constraint with {\lambda} = 1. We consider the
computation of the almost-sure winning set, where the controller needs to
ensure that the path constraint is satisfied with probability 1. Our main
results for qualitative path constraint are as follows: (i) the problem of
deciding the existence of a finite-memory controller is EXPTIME-complete; and
(ii) the problem of deciding the existence of an infinite-memory controller is
undecidable. For quantitative path constraint we show that the problem of
deciding the existence of a finite-memory controller is undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4847</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4847</id><created>2013-08-22</created><updated>2015-03-24</updated><authors><author><keyname>Zhao</keyname><forenames>Zhi-Dan</forenames></author><author><keyname>Gao</keyname><forenames>Ya-Chun</forenames></author><author><keyname>Cai</keyname><forenames>Shi-Min</forenames></author></authors><title>The dynamic pattern of human attention</title><categories>physics.soc-ph cs.SI</categories><comments>the current manuscript has big statistical errors of results
  resulting from preprocessing of experimental data</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mass of traces of human activities show diverse dynamic patterns. In this
paper, we comprehensively investigate the dynamic pattern of human attention
defined by the quantity of interests on subdisciplines in an online academic
communication forum. Both the expansion and exploration of human attention have
a power-law scaling relation with browsing actions, of which the exponent is
close to that in one-dimension random walk. Furthermore, the memory effect of
human attention is characterized by the power-law distributions of both the
return interval time and return interval steps, which is reinforced by studying
the attention shift that monotonically increase with the interval order between
pairs of continuously segmental sequences of expansion. At last, the observing
dynamic pattern of human attention in the browsing process is analytically
described by a dynamic model whose generic mechanism is analogy to that of
human spatial mobility. Thus, our work not only enlarges the research scope of
human dynamics, but also provides an insight to understand the relationship
between the interest transitivity in online activities and human spatial
mobility in real world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4862</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4862</id><created>2013-08-22</created><authors><author><keyname>Rumi</keyname><forenames>Yeasir Fathah</forenames></author><author><keyname>Prodhan</keyname><forenames>Uzzal Kumar</forenames></author><author><keyname>Hussain</keyname><forenames>Mohammed Ibrahim</forenames></author><author><keyname>Parvez</keyname><forenames>A. H. M. Shahariar</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Ali</forenames></author></authors><title>Strategy For Assessment Of Land And Complex Fields Type Analysis Through
  GIS In Bangladesh</title><categories>cs.CY</categories><comments>13 pages, 7 Figures</comments><journal-ref>International Journal of Information Sciences and Techniques
  (IJIST) Vol.3, No.4, July 2013</journal-ref><doi>10.5121/ijist.2013.3403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bangladesh is an over populated developing country where crisis of food is a
major issue, it faces different infrastructure problem in every sector. For
Poverty Alleviation from the country we have to confirm cultivable land to
increase the crop production for feeding the over population of the country.
This paper focuses on the measurement of cultivable land for cultivation. The
main purpose of this paper is to briefly describe how the GIS, Digital Mapping,
Internet concepts and tools can effectively contribute in the modeling,
analysis and visualization phases within an engineering or research project
according to the crops by using object detection, object tracking and field
mapping in Bangladesh. Through GIS mapping of the agricultural lands, the
statistics can be made of how much land is cultivable and each year how much
land we are losing. Mapping the cultivation land will tell us how much crop we
have to import from other countries. Enabling real-time GIS analysis anytime,
anywhere, the implementation of the GIS information to a wider aspect.
Automation is the indicator of the modern civilizations. The system will
benefit the food stock of the country according to the harvest. For this
research we developed a new interactive system. The system will integrate with
GIS project data in Google Earth, first finds highly accurate cluster images
and partial images, obtains user feedback to merge or correct these digests,
and then the supplementary visual analysis complete the partitioning of the
data. This study was conducted at the software laboratory, Computer Science and
Engineering department, Jahangirnagar University, Dhaka, Bangladesh in 2013.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4880</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4880</id><created>2013-08-22</created><updated>2013-08-30</updated><authors><author><keyname>Sahneh</keyname><forenames>Faryad Darabi</forenames></author><author><keyname>Scoglio</keyname><forenames>Caterina</forenames></author></authors><title>May the Best Meme Win!: New Exploration of Competitive Epidemic
  Spreading over Arbitrary Multi-Layer Networks</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study extends the SIS epidemic model for single virus propagation over
an arbitrary graph to an SI1SI2S epidemic model of two exclusive, competitive
viruses over a two-layer network with generic structure, where network layers
represent the distinct transmission routes of the viruses. We find analytical
results determining extinction, mutual exclusion, and coexistence of the
viruses by introducing the concepts of survival threshold and winning
threshold. Furthermore, we show the possibility of coexistence in SIS-type
competitive spreading over multilayer networks. Not only do we rigorously prove
a region of coexistence, we quantitate it via interrelation of central nodes
across the network layers. Little to no overlapping of layers central nodes is
the key determinant of coexistence. Specifically, we show coexistence is
impossible if network layers are identical yet possible if the network layers
have distinct dominant eigenvectors and node degree vectors. For example, we
show both analytically and numerically that positive correlation of network
layers makes it difficult for a virus to survive while in a network with
negatively correlated layers survival is easier but total removal of the other
virus is more difficult. We believe our methodology has great potentials for
application to broader classes of multi-pathogen spreading over multi-layer and
interconnected networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4894</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4894</id><created>2013-08-22</created><authors><author><keyname>Aldhaheri</keyname><forenames>Abdulrahman</forenames></author><author><keyname>Bach</keyname><forenames>Christian</forenames></author></authors><title>How to implement Marketing 2.0 Successfully</title><categories>cs.OH</categories><journal-ref>International Journal of Business and Social Science, vol. 4, no.
  10, August 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this research is to develop a model that would close the gap
between marketing plans and strategies from one side and the advanced online
collaboration applications platforms known as WEB 2.0 in order to implement
marketing 2.0 smoothly without disrupting the working environment. We started
by examining published articles related to marketing, Web 2.0, Customer
Relationship Management Systems, CRM, and social media in a step to conduct an
extensive review of the available literature. Then, we presented critique of
the articles we have examined. After that, we have been able to develop the
model we are proposing in this research. As this paper shows, the proposed
model will help in transforming marketing plans and strategies from its
traditional approach into, what we would like to call, marketing 2.0 approach
smoothly. There are some unavoidable limitations due to the given time and
scope constrains. The factors included in the proposed model does not cover
every related aspect, however, they cover the most important ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4895</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4895</id><created>2013-08-22</created><authors><author><keyname>Aldhaheri</keyname><forenames>Abdulrahman</forenames></author><author><keyname>Alshammari</keyname><forenames>Hammoud</forenames></author><author><keyname>Alshammari</keyname><forenames>Majid</forenames></author></authors><title>Optimizing Key Distribution in Peer to Peer Network Using B-Trees</title><categories>cs.CR cs.NI</categories><journal-ref>International Journal of Computer Science and Information
  Security, vol. 11, no. 8, p. 6, August 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer to peer network architecture introduces many desired features including
self-scalability that led to achieving higher efficiency rate than the
traditional server-client architecture. This was contributed to the highly
distributed architecture of peer to peer network. Meanwhile, the lack of a
centralized control unit in peer to peer network introduces some challenge. One
of these challenges is key distribution and management in such an architecture.
This research will explore the possibility of developing a novel scheme for
distributing and managing keys in peer to peer network architecture
efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4902</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4902</id><created>2013-08-22</created><authors><author><keyname>Azmi</keyname><forenames>Aini Najwa</forenames></author><author><keyname>Nasien</keyname><forenames>Dewi</forenames></author><author><keyname>Shamsuddin</keyname><forenames>Siti Mariyam</forenames></author></authors><title>A review on handwritten character and numeral recognition for Roman,
  Arabic, Chinese and Indian scripts</title><categories>cs.CV</categories><comments>8 pages</comments><journal-ref>International Journal of advanced studies in Computers, Science &amp;
  Engineering (IJASCSE), Volume 2, Issue 4, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are a lot of intensive researches on handwritten character recognition
(HCR) for almost past four decades. The research has been done on some of
popular scripts such as Roman, Arabic, Chinese and Indian. In this paper we
present a review on HCR work on the four popular scripts. We have summarized
most of the published paper from 2005 to recent and also analyzed the various
methods in creating a robust HCR system. We also added some future direction of
research on HCR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4904</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4904</id><created>2013-08-22</created><authors><author><keyname>Bortolussi</keyname><forenames>Luca</forenames><affiliation>University of Trieste</affiliation></author><author><keyname>Bujorianu</keyname><forenames>Manuela L.</forenames><affiliation>University of Warwick</affiliation></author><author><keyname>Pola</keyname><forenames>Giordano</forenames><affiliation>University of L'Aquila</affiliation></author></authors><title>Proceedings Third International Workshop on Hybrid Autonomous Systems</title><categories>cs.SY cs.CE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013</journal-ref><doi>10.4204/EPTCS.124</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interest on autonomous systems is increasing both in industry and
academia. Such systems must operate with limited human intervention in a
changing environment and must be able to compensate for significant system
failures without external intervention. The most appropriate models of
autonomous systems can be found in the class of hybrid systems (which study
continuous-state dynamic processes via discrete-state controllers) that
interact with their environment. This workshop brings together researchers
interested in all aspects of autonomy and resilience of hybrid systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4908</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4908</id><created>2013-08-22</created><authors><author><keyname>Kronander</keyname><forenames>Joel</forenames></author><author><keyname>Gustavson</keyname><forenames>Stefan</forenames></author><author><keyname>Bonnet</keyname><forenames>Gerhard</forenames></author><author><keyname>Ynnerman</keyname><forenames>Anders</forenames></author><author><keyname>Unger</keyname><forenames>Jonas</forenames></author></authors><title>A Unified Framework for Multi-Sensor HDR Video Reconstruction</title><categories>cs.CV cs.GR cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most successful approaches to modern high quality HDR-video
capture is to use camera setups with multiple sensors imaging the scene through
a common optical system. However, such systems pose several challenges for HDR
reconstruction algorithms. Previous reconstruction techniques have considered
debayering, denoising, resampling (align- ment) and exposure fusion as separate
problems. In contrast, in this paper we present a unifying approach, performing
HDR assembly directly from raw sensor data. Our framework includes a camera
noise model adapted to HDR video and an algorithm for spatially adaptive HDR
reconstruction based on fitting of local polynomial approximations to observed
sensor data. The method is easy to implement and allows reconstruction to an
arbitrary resolution and output mapping. We present an implementation in CUDA
and show real-time performance for an experimental 4 Mpixel multi-sensor HDR
video system. We further show that our algorithm has clear advantages over
existing methods, both in terms of flexibility and reconstruction quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4915</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4915</id><created>2013-08-22</created><updated>2014-05-20</updated><authors><author><keyname>Osting</keyname><forenames>Braxton</forenames></author><author><keyname>White</keyname><forenames>Chris D.</forenames></author><author><keyname>Oudet</keyname><forenames>Edouard</forenames></author></authors><title>Minimal Dirichlet energy partitions for graphs</title><categories>math.OC cs.LG stat.ML</categories><comments>17 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a geometric problem, we introduce a new non-convex graph
partitioning objective where the optimality criterion is given by the sum of
the Dirichlet eigenvalues of the partition components. A relaxed formulation is
identified and a novel rearrangement algorithm is proposed, which we show is
strictly decreasing and converges in a finite number of iterations to a local
minimum of the relaxed objective function. Our method is applied to several
clustering problems on graphs constructed from synthetic data, MNIST
handwritten digits, and manifold discretizations. The model has a
semi-supervised extension and provides a natural representative for the
clusters as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4922</identifier>
 <datestamp>2014-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4922</id><created>2013-08-22</created><updated>2014-01-02</updated><authors><author><keyname>Zhang</keyname><forenames>Xiao-Lei</forenames></author></authors><title>Learning Deep Representation Without Parameter Inference for Nonlinear
  Dimensionality Reduction</title><categories>cs.LG stat.ML</categories><comments>This paper has been withdrawn by the author due to a lack of full
  empirical evaluation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised deep learning is one of the most powerful representation
learning techniques. Restricted Boltzman machine, sparse coding, regularized
auto-encoders, and convolutional neural networks are pioneering building blocks
of deep learning. In this paper, we propose a new building block -- distributed
random models. The proposed method is a special full implementation of the
product of experts: (i) each expert owns multiple hidden units and different
experts have different numbers of hidden units; (ii) the model of each expert
is a k-center clustering, whose k-centers are only uniformly sampled examples,
and whose output (i.e. the hidden units) is a sparse code that only the
similarity values from a few nearest neighbors are reserved. The relationship
between the pioneering building blocks, several notable research branches and
the proposed method is analyzed. Experimental results show that the proposed
deep model can learn better representations than deep belief networks and
meanwhile can train a much larger network with much less time than deep belief
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4941</identifier>
 <datestamp>2014-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4941</id><created>2013-08-22</created><updated>2014-06-09</updated><authors><author><keyname>Bridges</keyname><forenames>Robert A.</forenames></author><author><keyname>Jones</keyname><forenames>Corinne L.</forenames></author><author><keyname>Iannacone</keyname><forenames>Michael D.</forenames></author><author><keyname>Testa</keyname><forenames>Kelly M.</forenames></author><author><keyname>Goodall</keyname><forenames>John R.</forenames></author></authors><title>Automatic Labeling for Entity Extraction in Cyber Security</title><categories>cs.IR cs.CL</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timely analysis of cyber-security information necessitates automated
information extraction from unstructured text. While state-of-the-art
extraction methods produce extremely accurate results, they require ample
training data, which is generally unavailable for specialized applications,
such as detecting security related entities; moreover, manual annotation of
corpora is very costly and often not a viable solution. In response, we develop
a very precise method to automatically label text from several data sources by
leveraging related, domain-specific, structured data and provide public access
to a corpus annotated with cyber-security entities. Next, we implement a
Maximum Entropy Model trained with the average perceptron on a portion of our
corpus ($\sim$750,000 words) and achieve near perfect precision, recall, and
accuracy, with training times under 17 seconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4942</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4942</id><created>2013-08-22</created><updated>2014-07-26</updated><authors><author><keyname>Shuman</keyname><forenames>David I</forenames></author><author><keyname>Faraji</keyname><forenames>Mohammad Javad</forenames></author><author><keyname>Vandergheynst</keyname><forenames>Pierre</forenames></author></authors><title>A Multiscale Pyramid Transform for Graph Signals</title><categories>cs.IT cs.SI math.FA math.IT</categories><comments>13 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiscale transforms designed to process analog and discrete-time signals
and images cannot be directly applied to analyze high-dimensional data residing
on the vertices of a weighted graph, as they do not capture the intrinsic
geometric structure of the underlying graph data domain. In this paper, we
adapt the Laplacian pyramid transform for signals on Euclidean domains so that
it can be used to analyze high-dimensional data residing on the vertices of a
weighted graph. Our approach is to study existing methods and develop new
methods for the four fundamental operations of graph downsampling, graph
reduction, and filtering and interpolation of signals on graphs. Equipped with
appropriate notions of these operations, we leverage the basic multiscale
constructs and intuitions from classical signal processing to generate a
transform that yields both a multiresolution of graphs and an associated
multiresolution of a graph signal on the underlying sequence of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4943</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4943</id><created>2013-08-22</created><updated>2013-11-24</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author><author><keyname>Stolzenburg</keyname><forenames>Frieder</forenames></author></authors><title>David Poole's Specificity Revised</title><categories>cs.AI</categories><comments>ii+34 pages</comments><report-no>SEKI-Report SR-2013-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the middle of the 1980s, David Poole introduced a semantical,
model-theoretic notion of specificity to the artificial-intelligence community.
Since then it has found further applications in non-monotonic reasoning, in
particular in defeasible reasoning. Poole tried to approximate the intuitive
human concept of specificity, which seems to be essential for reasoning in
everyday life with its partial and inconsistent information. His notion,
however, turns out to be intricate and problematic, which --- as we show ---
can be overcome to some extent by a closer approximation of the intuitive human
concept of specificity. Besides the intuitive advantages of our novel
specificity ordering over Poole's specificity relation in the classical
examples of the literature, we also report some hard mathematical facts:
Contrary to what was claimed before, we show that Poole's relation is not
transitive. The present means to decide our novel specificity relation,
however, show only a slight improvement over the known ones for Poole's
relation, and further work is needed in this aspect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4965</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4965</id><created>2013-08-21</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author><author><keyname>Wu</keyname><forenames>Lan</forenames></author></authors><title>A proposal for a Chinese keyboard for cellphones, smartphones, ipads and
  tablets</title><categories>cs.HC cs.CL</categories><comments>28 pages, 40 figures</comments><msc-class>69U99, 94A99</msc-class><acm-class>H.1.2; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the possibility to use two tilings of the
hyperbolic plane as basic frame for devising a way to input texts in Chinese
characters into messages of cellphones, smartphones, ipads and tablets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4969</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4969</id><created>2013-08-22</created><authors><author><keyname>Wang</keyname><forenames>Zhen</forenames></author><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Optimal interdependence between networks for the evolution of
  cooperation</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>8 two-column pages, 7 figures; accepted for publication in Scientific
  Reports</comments><journal-ref>Sci. Rep. 3 (2013) 2470</journal-ref><doi>10.1038/srep02470</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has identified interactions between networks as crucial for
the outcome of evolutionary games taking place on them. While the consensus is
that interdependence does promote cooperation by means of organizational
complexity and enhanced reciprocity that is out of reach on isolated networks,
we here address the question just how much interdependence there should be.
Intuitively, one might assume the more the better. However, we show that in
fact only an intermediate density of sufficiently strong interactions between
networks warrants an optimal resolution of social dilemmas. This is due to an
intricate interplay between the heterogeneity that causes an asymmetric
strategy flow because of the additional links between the networks, and the
independent formation of cooperative patterns on each individual network.
Presented results are robust to variations of the strategy updating rule, the
topology of interdependent networks, and the governing social dilemma, thus
suggesting a high degree of universality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4978</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4978</id><created>2013-08-22</created><authors><author><keyname>Wang</keyname><forenames>Xiaofeng</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author><author><keyname>Graziotin</keyname><forenames>Daniel</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author><author><keyname>Rikkil&#xe4;</keyname><forenames>Juha</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author><author><keyname>Abrahamsson</keyname><forenames>Pekka</forenames><affiliation>Free University of Bozen-Bolzano</affiliation></author></authors><title>Traverse the landscape of the mind by walking: an exploration of a new
  brainstorming practice</title><categories>cs.SE</categories><comments>12 pages, 2 figures. Pilot study conducted to better understand a new
  brainstorming technique. Full study will follow</comments><acm-class>H.1.2; D.2.1; D.2.2; D.2.9</acm-class><doi>10.7287/peerj.preprints.51v1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Group brainstorming is a well-known idea generation technique, which plays a
key role in software development processes. Despite this, the relevant
literature has had little to offer in advancing our understanding of the
effectiveness of group brainstorming sessions. In this paper we present a
research-in-progress on brainstorming while walking, which is a practice built
upon the relationship between thinking and walking. The objective is to better
understand how to conduct group brainstorming effectively. We compared two
brainstorming sessions, one performed during a mountain walk, the other
traditionally in a room. Three preliminary findings are obtained: walking can
lead to an effective idea generation session; brainstorming while walking can
encourage team members to participate in and contribute to the session in an
equal manner; and it can help a team to maintain sustainable mental energy. Our
study opens up an avenue for future exploration of effective group
brainstorming practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4994</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4994</id><created>2013-08-22</created><authors><author><keyname>Kalogerias</keyname><forenames>Dionysios S.</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author></authors><title>Matrix Completion in Colocated MIMO Radar: Recoverability, Bounds &amp;
  Theoretical Guarantees</title><categories>cs.IT math.IT</categories><comments>19 pages, 7 figures, under review in Transactions on Signal
  Processing (2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was recently shown that low rank matrix completion theory can be employed
for designing new sampling schemes in the context of MIMO radars, which can
lead to the reduction of the high volume of data typically required for
accurate target detection and estimation. Employing random samplers at each
reception antenna, a partially observed version of the received data matrix is
formulated at the fusion center, which, under certain conditions, can be
recovered using convex optimization. This paper presents the theoretical
analysis regarding the performance of matrix completion in colocated MIMO radar
systems, exploiting the particular structure of the data matrix. Both Uniform
Linear Arrays (ULAs) and arbitrary 2-dimensional arrays are considered for
transmission and reception. Especially for the ULA case, under some mild
assumptions on the directions of arrival of the targets, it is explicitly shown
that the coherence of the data matrix is both asymptotically and approximately
optimal with respect to the number of antennas of the arrays involved and
further, the data matrix is recoverable using a subset of its entries with
minimal cardinality. Sufficient conditions guaranteeing low matrix coherence
and consequently satisfactory matrix completion performance are also presented,
including the arbitrary 2-dimensional array case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4996</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4996</id><created>2013-08-22</created><authors><author><keyname>Bartal</keyname><forenames>Yair</forenames></author><author><keyname>Gottlieb</keyname><forenames>Lee-Ad</forenames></author><author><keyname>Neiman</keyname><forenames>Ofer</forenames></author></authors><title>On the Impossibility of Dimension Reduction for Doubling Subsets of
  $\ell_p$, $p&gt;2$</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major open problem in the field of metric embedding is the existence of
dimension reduction for $n$-point subsets of Euclidean space, such that both
distortion and dimension depend only on the {\em doubling constant} of the
pointset, and not on its cardinality. In this paper, we negate this possibility
for $\ell_p$ spaces with $p&gt;2$. In particular, we introduce an $n$-point subset
of $\ell_p$ with doubling constant O(1), and demonstrate that any embedding of
the set into $\ell_p^d$ with distortion $D$ must have
$D\ge\Omega\left(\left(\frac{c\log
n}{d}\right)^{\frac{1}{2}-\frac{1}{p}}\right)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.4999</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.4999</id><created>2013-08-22</created><authors><author><keyname>Gliwa</keyname><forenames>Bogdan</forenames></author><author><keyname>Zygmunt</keyname><forenames>Anna</forenames></author><author><keyname>Podg&#xf3;rski</keyname><forenames>Stanis&#x142;aw</forenames></author></authors><title>Incorporating Text Analysis into Evolution of Social Groups in
  Blogosphere</title><categories>cs.SI physics.soc-ph</categories><comments>Federated Conference on Computer Science and Information Systems,
  FedCSIS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data reflecting social and business relations has often form of network of
connections between entities (called social network). In such network important
and influential users can be identified as well as groups of strongly connected
users. Finding such groups and observing their evolution becomes an
increasingly important research problem. One of the significant problems is to
develop method incorporating not only information about connections between
entities but also information obtained from text written by the users. Method
presented in this paper combine social network analysis and text mining in
order to understand groups evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5000</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5000</id><created>2013-08-22</created><updated>2014-01-14</updated><authors><author><keyname>Tan</keyname><forenames>Zhao</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Beck</keyname><forenames>Amir</forenames></author><author><keyname>Nehorai</keyname><forenames>Arye</forenames></author></authors><title>Smoothing and Decomposition for Analysis Sparse Recovery</title><categories>math.OC cs.IT math.IT</categories><comments>Submitted on Aug 22th, 2013; Updated on Dec 1st, 2013</comments><doi>10.1109/TSP.2014.2304932</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider algorithms and recovery guarantees for the analysis sparse model
in which the signal is sparse with respect to a highly coherent frame. We
consider the use of a monotone version of the fast iterative shrinkage-
thresholding algorithm (MFISTA) to solve the analysis sparse recovery problem.
Since the proximal operator in MFISTA does not have a closed-form solution for
the analysis model, it cannot be applied directly. Instead, we examine two
alternatives based on smoothing and decomposition transformations that relax
the original sparse recovery problem, and then implement MFISTA on the relaxed
formulation. We refer to these two methods as smoothing-based and
decomposition-based MFISTA. We analyze the convergence of both algorithms, and
establish that smoothing- based MFISTA converges more rapidly when applied to
general nonsmooth optimization problems. We then derive a performance bound on
the reconstruction error using these techniques. The bound proves that our
methods can recover a signal sparse in a redundant tight frame when the
measurement matrix satisfies a properly adapted restricted isometry property.
Numerical examples demonstrate the performance of our methods and show that
smoothing-based MFISTA converges faster than the decomposition-based
alternative in real applications, such as MRI image reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5010</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5010</id><created>2013-08-22</created><authors><author><keyname>Bertrand</keyname><forenames>Karla Z.</forenames></author><author><keyname>Bialik</keyname><forenames>Maya</forenames></author><author><keyname>Virdee</keyname><forenames>Kawandeep</forenames></author><author><keyname>Gros</keyname><forenames>Andreas</forenames></author><author><keyname>Bar-Yam</keyname><forenames>Yaneer</forenames></author></authors><title>Sentiment in New York City: A High Resolution Spatial and Temporal View</title><categories>physics.soc-ph cs.CL cs.CY</categories><comments>12 pages, 5 figures</comments><report-no>New England Complex Systems Institute (NECSI) Report 2013-08-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measuring public sentiment is a key task for researchers and policymakers
alike. The explosion of available social media data allows for a more
time-sensitive and geographically specific analysis than ever before. In this
paper we analyze data from the micro-blogging site Twitter and generate a
sentiment map of New York City. We develop a classifier specifically tuned for
140-character Twitter messages, or tweets, using key words, phrases and
emoticons to determine the mood of each tweet. This method, combined with
geotagging provided by users, enables us to gauge public sentiment on extremely
fine-grained spatial and temporal scales. We find that public mood is generally
highest in public parks and lowest at transportation hubs, and locate other
areas of strong sentiment such as cemeteries, medical centers, a jail, and a
sewage facility. Sentiment progressively improves with proximity to Times
Square. Periodic patterns of sentiment fluctuate on both a daily and a weekly
scale: more positive tweets are posted on weekends than on weekdays, with a
daily peak in sentiment around midnight and a nadir between 9:00 a.m. and noon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5015</identifier>
 <datestamp>2014-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5015</id><created>2013-08-22</created><authors><author><keyname>Hodas</keyname><forenames>Nathan O.</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>The Simple Rules of Social Contagion</title><categories>cs.SI physics.soc-ph</categories><comments>5 pages, 4 figures, supplement</comments><acm-class>J.4; J.2</acm-class><journal-ref>Scientific Reports 4, Article number: 4343, 2014</journal-ref><doi>10.1038/srep04343</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is commonly believed that information spreads between individuals like a
pathogen, with each exposure by an informed friend potentially resulting in a
naive individual becoming infected. However, empirical studies of social media
suggest that individual response to repeated exposure to information is
significantly more complex than the prediction of the pathogen model. As a
proxy for intervention experiments, we compare user responses to multiple
exposures on two different social media sites, Twitter and Digg. We show that
the position of the exposing messages on the user-interface strongly affects
social contagion. Accounting for this visibility significantly simplifies the
dynamics of social contagion. The likelihood an individual will spread
information increases monotonically with exposure, while explicit feedback
about how many friends have previously spread it increases the likelihood of a
response. We apply our model to real-time forecasting of user behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5029</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5029</id><created>2013-08-22</created><authors><author><keyname>Li</keyname><forenames>Xiaoliang</forenames></author><author><keyname>Wang</keyname><forenames>Dongming</forenames></author></authors><title>Computing Equilibria of Semi-algebraic Economies Using Triangular
  Decomposition and Real Solution Classification</title><categories>cs.SC</categories><comments>24 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we are concerned with the problem of determining the existence
of multiple equilibria in economic models. We propose a general and complete
approach for identifying multiplicities of equilibria in semi-algebraic
economies, which may be expressed as semi-algebraic systems. The approach is
based on triangular decomposition and real solution classification, two
powerful tools of algebraic computation. Its effectiveness is illustrated by
two examples of application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5032</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5032</id><created>2013-08-22</created><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author><author><keyname>DiPaola</keyname><forenames>Steve</forenames></author></authors><title>How Did Humans Become So Creative? A Computational Approach</title><categories>cs.NE cs.AI cs.MA q-bio.NC</categories><comments>8 pages</comments><journal-ref>Proceedings of the International Conference on Computational
  Creativity (pp. 203-210). May 31 - June 1, 2012, Dublin, Ireland</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper summarizes efforts to computationally model two transitions in the
evolution of human creativity: its origins about two million years ago, and the
'big bang' of creativity about 50,000 years ago. Using a computational model of
cultural evolution in which neural network based agents evolve ideas for
actions through invention and imitation, we tested the hypothesis that human
creativity began with onset of the capacity for recursive recall. We compared
runs in which agents were limited to single-step actions to runs in which they
used recursive recall to chain simple actions into complex ones. Chaining
resulted in higher diversity, open-ended novelty, no ceiling on the mean
fitness of actions, and greater ability to make use of learning. Using a
computational model of portrait painting, we tested the hypothesis that the
explosion of creativity in the Middle/Upper Paleolithic was due to onset of
con-textual focus: the capacity to shift between associative and analytic
thought. This resulted in faster convergence on portraits that resembled the
sitter, employed painterly techniques, and were rated as preferable. We
conclude that recursive recall and contextual focus provide a computationally
plausible explanation of how humans evolved the means to transform this planet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5033</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5033</id><created>2013-08-22</created><authors><author><keyname>Huang</keyname><forenames>Guanghui</forenames></author><author><keyname>Pan</keyname><forenames>Zhifeng</forenames></author></authors><title>A hybrid evolutionary algorithm with importance sampling for
  multi-dimensional optimization</title><categories>cs.NE</categories><comments>13 pages,5 tables, 9 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A hybrid evolutionary algorithm with importance sampling method is proposed
for multi-dimensional optimization problems in this paper. In order to make use
of the information provided in the search process, a set of visited solutions
is selected to give scores for intervals in each dimension, and they are
updated as algorithm proceeds. Those intervals with higher scores are regarded
as good intervals, which are used to estimate the joint distribution of optimal
solutions through an interaction between the pool of good genetics, which are
the individuals with smaller fitness values. And the sampling probabilities for
good genetics are determined through an interaction between those estimated
good intervals. It is a cross validation mechanism which determines the
sampling probabilities for good intervals and genetics, and the resulted
probabilities are used to design crossover, mutation and other stochastic
operators with importance sampling method. As the selection of genetics and
intervals is not directly dependent on the values of fitness, the resulted
offsprings may avoid the trap of local optima. And a purely random EA is also
combined into the proposed algorithm to maintain the diversity of population.
30 benchmark test functions are used to evaluate the performance of the
proposed algorithm, and it is found that the proposed hybrid algorithm is an
efficient algorithm for multi-dimensional optimization problems considered in
this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5038</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5038</id><created>2013-08-22</created><updated>2013-11-30</updated><authors><author><keyname>Chen</keyname><forenames>Po-Yu</forenames></author><author><keyname>Selesnick</keyname><forenames>Ivan W.</forenames></author></authors><title>Group-Sparse Signal Denoising: Non-Convex Regularization, Convex
  Optimization</title><categories>cs.CV cs.LG stat.ML</categories><comments>14 pages, 11 figures</comments><doi>10.1109/TSP.2014.2329274</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convex optimization with sparsity-promoting convex regularization is a
standard approach for estimating sparse signals in noise. In order to promote
sparsity more strongly than convex regularization, it is also standard practice
to employ non-convex optimization. In this paper, we take a third approach. We
utilize a non-convex regularization term chosen such that the total cost
function (consisting of data consistency and regularization terms) is convex.
Therefore, sparsity is more strongly promoted than in the standard convex
formulation, but without sacrificing the attractive aspects of convex
optimization (unique minimum, robust algorithms, etc.). We use this idea to
improve the recently developed 'overlapping group shrinkage' (OGS) algorithm
for the denoising of group-sparse signals. The algorithm is applied to the
problem of speech enhancement with favorable results in terms of both SNR and
perceptual quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5045</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5045</id><created>2013-08-23</created><authors><author><keyname>Park</keyname><forenames>Se Yong</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Network Coding meets Decentralized Control: Network Linearization and
  Capacity-Stabilizablilty Equivalence</title><categories>math.OC cs.IT math.IT</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We take a unified view of network coding and decentralized control. Precisely
speaking, we consider both as linear time-invariant systems by appropriately
restricting channels and coding schemes of network coding to be linear
time-invariant, and the plant and controllers of decentralized control to be
linear time-invariant as well. First, we apply linear system theory to network
coding. This gives a novel way of converting an arbitrary relay network to an
equivalent acyclic single-hop relay network, which we call Network
Linearization. Based on network linearization, we prove that the fundamental
design limit, mincut, is achievable by a linear time-invariant network-coding
scheme regardless of the network topology.
  Then, we use the network-coding to view decentralized linear systems. We
argue that linear time-invariant controllers in a decentralized linear system
&quot;communicate&quot; via linear network coding to stabilize the plant. To justify this
argument, we give an algorithm to &quot;externalize&quot; the implicit communication
between the controllers that we believe must be occurring to stabilize the
plant. Based on this, we show that the stabilizability condition for
decentralized linear systems comes from an underlying communication limit,
which can be described by the algebraic mincut-maxflow theorem. With this
re-interpretation in hand, we also consider stabilizability over LTI networks
to emphasize the connection with network coding. In particular, in broadcast
and unicast problems, unintended messages at the receivers will be modeled as
secrecy constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5046</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5046</id><created>2013-08-23</created><authors><author><keyname>Ans&#xf3;tegui</keyname><forenames>C.</forenames><affiliation>DIEI, Univ. de Lleida</affiliation></author><author><keyname>Bonet</keyname><forenames>M. L.</forenames><affiliation>LSI, UPC</affiliation></author><author><keyname>Gir&#xe1;ldez-Cru</keyname><forenames>J.</forenames><affiliation>IIIA-CSIC</affiliation></author><author><keyname>Levy</keyname><forenames>J.</forenames><affiliation>IIIA-CSIC</affiliation></author></authors><title>The Fractal Dimension of SAT Formulas</title><categories>cs.AI</categories><comments>20 pages, 11 Postscript figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern SAT solvers have experienced a remarkable progress on solving
industrial instances. Most of the techniques have been developed after an
intensive experimental testing process. Recently, there have been some attempts
to analyze the structure of these formulas in terms of complex networks, with
the long-term aim of explaining the success of these SAT solving techniques,
and possibly improving them.
  We study the fractal dimension of SAT formulas, and show that most industrial
families of formulas are self-similar, with a small fractal dimension. We also
show that this dimension is not affected by the addition of learnt clauses. We
explore how the dimension of a formula, together with other graph properties
can be used to characterize SAT instances. Finally, we give empirical evidence
that these graph properties can be used in state-of-the-art portfolios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5053</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5053</id><created>2013-08-23</created><authors><author><keyname>Liu</keyname><forenames>Juan</forenames></author><author><keyname>Dai</keyname><forenames>Huaiyu</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author></authors><title>Delay Optimal Scheduling for Energy Harvesting Based Communications</title><categories>cs.ET cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Green communication attracts increasing research interest recently. Equipped
with a rechargeable battery, a source node can harvest energy from ambient
environments and rely on this free and regenerative energy supply to transmit
packets. Due to the uncertainty of available energy from harvesting, however,
intolerably large latency and packet loss could be induced, if the source
always waits for harvested energy. To overcome this problem, one Reliable
Energy Source (RES) can be resorted to for a prompt delivery of backlogged
packets. Naturally, there exists a tradeoff between the packet delivery delay
and power consumption from the RES. In this paper, we address the delay optimal
scheduling problem for a bursty communication link powered by a
capacity-limited battery storing harvested energy together with one RES. The
proposed scheduling scheme gives priority to the usage of harvested energy, and
resorts to the RES when necessary based on the data and energy queueing
processes, with an average power constraint from the RES. Through
twodimensional Markov chain modeling and linear programming formulation, we
derive the optimal threshold-based scheduling policy together with the
corresponding transmission parameters. Our study includes three exemplary cases
that capture some important relations between the data packet arrival process
and energy harvesting capability. Our theoretical analysis is corroborated by
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5063</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5063</id><created>2013-08-23</created><authors><author><keyname>Wang</keyname><forenames>Panqu</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author></authors><title>Suspicious Object Recognition Method in Video Stream Based on Visual
  Attention</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a state of the art method for intelligent object recognition and
video surveillance based on human visual attention. Bottom up and top down
attention are applied respectively in the process of acquiring interested
object(saliency map) and object recognition. The revision of 4 channel PFT
method is proposed for bottom up attention and enhances the speed and accuracy.
Inhibit of return (IOR) is applied in judging the sequence of saliency object
pop out. Euclidean distance of color distribution, object center coordinates
and speed are considered in judging whether the target is match and suspicious.
The extensive tests on videos and images show that our method in video analysis
has high accuracy and fast speed compared with traditional method. The method
can be applied into many fields such as video surveillance and security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5079</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5079</id><created>2013-08-23</created><authors><author><keyname>Brandenburg</keyname><forenames>Franz J.</forenames></author></authors><title>1-Visibility Representations of 1-Planar Graphs</title><categories>cs.CG cs.DM</categories><msc-class>68R10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A visibility representation is a classical drawing style of planar graphs. It
displays the vertices of a graph as horizontal vertex-segments, and each edge
is represented by a vertical edge-segment touching the segments of its end
vertices; beyond that segments do not intersect. We generalize visibility to
1-visibility, where each edge- (vertex-) segment crosses at most one vertex-
(edge-) segment. In other words, a vertex is crossed by at most one edge, and
vice-versa. We show that 1-visibility properly extends 1-planarity and develop
a linear time algorithm to compute a 1-visibility representation of an embedded
1-planar graph on O(n^2) area. A graph is 1-planar if it can be drawn in the
plane such that each edge is crossed at most once. Concerning density, both
1-visible and 1-planar graphs of size $n$ have at most 4n-8 edges. However, for
every n &gt;= 7 there are 1-visible graphs with 4n-8 edge which are not 1-planar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5091</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5091</id><created>2013-08-23</created><updated>2013-09-07</updated><authors><author><keyname>Navaz</keyname><forenames>A. S. Syed</forenames></author><author><keyname>Narayanan</keyname><forenames>H. Iyyappa</forenames></author><author><keyname>Vinoth</keyname><forenames>R.</forenames></author></authors><title>Security Protocol Review Method Analyzer(SPRMAN)</title><categories>cs.CR</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This Paper is designed using J2EE (JSP, SERVLET), HTML as front end and a
Oracle 9i is back end. SPRMAN is been developed for the client British Telecom
(BT) UK., Telecom company. Actually the requirement of BT is, they are
providing Network Security Related Products to their IT customers like
Virtusa,Wipro,HCL etc., This product is framed out by set of protocols and
these protocols are been associated with set of components. By grouping all
these protocols and components together, product is been developed. After
framing out the product, it is been subscribed to their individual customers.
Once a customer subscribed the product, then he will be raising a request to
the client (BT) for updating any policy or component in the product. The
customer has been given read/write access to the subscribed product. The
customer user having read/write access is only allowed to raise a request for
the product, but not the user having only the read access. The group of request
is been managed as manage work queue in client area. Management of this
protocol inside the product is considering as Security Protocol Review Method
Analyzer. SPRMAN helps BT to overcome all the hurdles faced by them while
processing the requests of their various clients using their already existing
software applications. SPRMAN emphasizes on nature of the request and gives
priority to issues based on their degree of future consequences. Thus SPRMAN
builds a good relationship between BT and its customers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5092</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5092</id><created>2013-08-23</created><authors><author><keyname>Sathiyanarayanan</keyname><forenames>Mithileysh</forenames></author><author><keyname>Kim</keyname><forenames>Kyeong Soo</forenames></author></authors><title>Multi-Channel Deficit Round-Robin Scheduling for Hybrid TDM/WDM Optical
  Networks</title><categories>cs.NI</categories><comments>6 pages, 13 figures</comments><journal-ref>Proc. of the 4th International Congress on Ultra Modern
  Telecommunications and Control Systems (ICUMT 2012), St. Petersburg, Russia,
  pp. 552-557, Oct. 2012</journal-ref><doi>10.1109/ICUMT.2012.6459727</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose and investigate the performance of a multi-channel
scheduling algorithm based on the well-known deficit round-robin (DRR), which
we call multi-channel DRR (MCDRR). We extend the original DRR to the case of
multiple channels with tunable transmitters and fixed receivers to provide
efficient fair queueing in hybrid time division multiplexing (TDM)/wavelength
division multiplexing (WDM) optical networks. We take into account the
availability of channels and tunable transmitters in extending the DRR and
allow the overlap of `rounds' in scheduling to efficiently utilize channels and
tunable transmitters. Simulation results show that the proposed MCDRR can
provide nearly perfect fairness with ill-behaved flows for different sets of
conditions for interframe times and frame sizes in hybrid TDM/WDM optical
networks with tunable transmitters and fixed receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5094</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5094</id><created>2013-08-23</created><authors><author><keyname>Kaznatcheev</keyname><forenames>Artem</forenames></author></authors><title>Complexity of evolutionary equilibria in static fitness landscapes</title><categories>q-bio.PE cs.NE</categories><comments>14 pages, 3 figures</comments><acm-class>F.2.2; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fitness landscape is a genetic space -- with two genotypes adjacent if they
differ in a single locus -- and a fitness function. Evolutionary dynamics
produce a flow on this landscape from lower fitness to higher; reaching
equilibrium only if a local fitness peak is found. I use computational
complexity to question the common assumption that evolution on static fitness
landscapes can quickly reach a local fitness peak. I do this by showing that
the popular NK model of rugged fitness landscapes is PLS-complete for K &gt;= 2;
the reduction from Weighted 2SAT is a bijection on adaptive walks, so there are
NK fitness landscapes where every adaptive path from some vertices is of
exponential length. Alternatively -- under the standard complexity theoretic
assumption that there are problems in PLS not solvable in polynomial time --
this means that there are no evolutionary dynamics (known, or to be discovered,
and not necessarily following adaptive paths) that can converge to a local
fitness peak on all NK landscapes with K = 2. Applying results from the
analysis of simplex algorithms, I show that there exist single-peaked
landscapes with no reciprocal sign epistasis where the expected length of an
adaptive path following strong selection weak mutation dynamics is
$e^{O(n^{1/3})}$ even though an adaptive path to the optimum of length less
than n is available from every vertex. The technical results are written to be
accessible to mathematical biologists without a computer science background,
and the biological literature is summarized for the convenience of
non-biologists with the aim to open a constructive dialogue between the two
disciplines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5121</identifier>
 <datestamp>2014-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5121</id><created>2013-08-23</created><authors><author><keyname>Fotouhi</keyname><forenames>Babak</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author></authors><title>Voter Model with Arbitrary Degree Dependence: Clout, Confidence and
  Irreversibility</title><categories>physics.soc-ph cond-mat.stat-mech cs.MA cs.SI</categories><journal-ref>The European Physical Journal B, Vol. 87, eid=55, 2014</journal-ref><doi>10.1140/epjb/e2014-41088-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the voter model with popularity bias. The
influence of each node on its neighbors depends on its degree. We find the
consensus probabilities and expected consensus times for each of the states. We
also find the fixation probability, which is the probability that a single node
whose state differs from every other node imposes its state on the entire
system. In addition, we find the expected fixation time. Then two extensions to
the model are proposed and the motivations behind them are discussed. The first
one is confidence, where in addition to the states of neighbors, nodes take
their own state into account at each update. We repeat the calculations for the
augmented model and investigate the effects of adding confidence to the model.
The second proposed extension is irreversibility, where one of the states is
given the property that once nodes adopt it, they cannot switch back. The
dynamics of densities, fixation times and consensus times are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5125</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5125</id><created>2013-08-23</created><authors><author><keyname>Greene</keyname><forenames>Derek</forenames></author><author><keyname>Cunningham</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>Discovering Latent Patterns from the Analysis of User-Curated Movie
  Lists</title><categories>cs.SI physics.soc-ph</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User content curation is becoming an important source of preference data, as
well as providing information regarding the items being curated. One popular
approach involves the creation of lists. On Twitter, these lists might contain
accounts relevant to a particular topic, whereas on a community site such as
the Internet Movie Database (IMDb), this might take the form of lists of movies
sharing common characteristics. While list curation involves substantial
combined effort on the part of users, researchers have rarely looked at mining
the outputs of this kind of crowdsourcing activity. Here we study a large
collection of movie lists from IMDb. We apply network analysis methods to a
graph that reflects the degree to which pairs of movies are &quot;co-listed&quot;, that
is, assigned to the same lists. This allows us to uncover a more nuanced
grouping of movies that goes beyond categorisation schemes based on attributes
such as genre or director.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5133</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5133</id><created>2013-08-23</created><authors><author><keyname>Benatar</keyname><forenames>Naisan</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibald</keyname><forenames>Jonathan M.</forenames></author></authors><title>Performance Measurement Under Increasing Environmental Uncertainty In
  The Context of Interval Type-2 Fuzzy Logic Based Robotic Sailing</title><categories>cs.RO cs.NE cs.SY</categories><comments>International Conference on Fuzzy Systems 2013 (Fuzz-IEEE 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance measurement of robotic controllers based on fuzzy logic,
operating under uncertainty, is a subject area which has been somewhat ignored
in the current literature. In this paper standard measures such as RMSE are
shown to be inappropriate for use under conditions where the environmental
uncertainty changes significantly between experiments. An overview of current
methods which have been applied by other authors is presented, followed by a
design of a more sophisticated method of comparison. This method is then
applied to a robotic control problem to observe its outcome compared with a
single measure. Results show that the technique described provides a more
robust method of performance comparison than less complex methods allowing
better comparisons to be drawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5136</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5136</id><created>2013-08-23</created><authors><author><keyname>McCulloch</keyname><forenames>Josie</forenames></author><author><keyname>Wagner</keyname><forenames>Christian</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Extending Similarity Measures of Interval Type-2 Fuzzy Sets to General
  Type-2 Fuzzy Sets</title><categories>cs.AI</categories><comments>International Conference on Fuzzy Systems 2013 (Fuzz-IEEE 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarity measures provide one of the core tools that enable reasoning about
fuzzy sets. While many types of similarity measures exist for type-1 and
interval type-2 fuzzy sets, there are very few similarity measures that enable
the comparison of general type-2 fuzzy sets. In this paper, we introduce a
general method for extending existing interval type-2 similarity measures to
similarity measures for general type-2 fuzzy sets. Specifically, we show how
similarity measures for interval type-2 fuzzy sets can be employed in
conjunction with the zSlices based general type-2 representation for fuzzy sets
to provide measures of similarity which preserve all the common properties
(i.e. reflexivity, symmetry, transitivity and overlapping) of the original
interval type-2 similarity measure. We demonstrate examples of such extended
fuzzy measures and provide comparisons between (different types of) interval
and general type-2 fuzzy measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5137</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5137</id><created>2013-08-23</created><authors><author><keyname>McCulloch</keyname><forenames>Josie</forenames></author><author><keyname>Wagner</keyname><forenames>Christian</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Measuring the Directional Distance Between Fuzzy Sets</title><categories>cs.AI</categories><comments>UKCI 2013, the 13th Annual Workshop on Computational Intelligence,
  Surrey University</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The measure of distance between two fuzzy sets is a fundamental tool within
fuzzy set theory. However, current distance measures within the literature do
not account for the direction of change between fuzzy sets; a useful concept in
a variety of applications, such as Computing With Words. In this paper, we
highlight this utility and introduce a distance measure which takes the
direction between sets into account. We provide details of its application for
normal and non-normal, as well as convex and non-convex fuzzy sets. We
demonstrate the new distance measure using real data from the MovieLens dataset
and establish the benefits of measuring the direction between fuzzy sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5138</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5138</id><created>2013-08-23</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Dasgupta</keyname><forenames>Dipankar</forenames></author><author><keyname>Gu</keyname><forenames>Feng</forenames></author></authors><title>Artificial Immune Systems (INTROS 2)</title><categories>cs.NE cs.ET</categories><comments>Search Methodologies: Introductory Tutorials in Optimization and
  Decision Support Techniques, 2nd edition, Springer, Chapter 7, 2014. arXiv
  admin note: substantial text overlap with arXiv:0803.3912, arXiv:0910.4899,
  arXiv:0801.4314</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The biological immune system is a robust, complex, adaptive system that
defends the body from foreign pathogens. It is able to categorize all cells (or
molecules) within the body as self or non-self substances. It does this with
the help of a distributed task force that has the intelligence to take action
from a local and also a global perspective using its network of chemical
messengers for communication. There are two major branches of the immune
system. The innate immune system is an unchanging mechanism that detects and
destroys certain invading organisms, whilst the adaptive immune system responds
to previously unknown foreign cells and builds a response to them that can
remain in the body over a long period of time. This remarkable information
processing biological system has caught the attention of computer science in
recent years.
  A novel computational intelligence technique, inspired by immunology, has
emerged, called Artificial Immune Systems. Several concepts from the immune
system have been extracted and applied for solution to real world science and
engineering problems. In this tutorial, we briefly describe the immune system
metaphors that are relevant to existing Artificial Immune Systems methods. We
will then show illustrative real-world problems suitable for Artificial Immune
Systems and give a step-by-step algorithm walkthrough for one such problem. A
comparison of the Artificial Immune Systems to other well-known algorithms,
areas for future work, tips &amp; tricks and a list of resources will round this
tutorial off. It should be noted that as Artificial Immune Systems is still a
young and evolving field, there is not yet a fixed algorithm template and hence
actual implementations might differ somewhat from time to time and from those
examples given here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5144</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5144</id><created>2013-08-23</created><authors><author><keyname>Liu</keyname><forenames>Yihui</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Detect adverse drug reactions for drug Pioglitazone</title><categories>cs.CE</categories><comments>IEEE 11th International Conference on Signal Processing (ICSP),
  1654-1658, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study we propose a novel method to successfully detect the ADRs using
feature matrix and feature selection. A feature matrix, which characterizes the
medical events before patients take drugs or after patients take drugs, is
created from THIN database. The feature selection method of Student's t-test is
used to detect the significant features from thousands of medical events. The
significant ADRs, which are corresponding to significant features, are
detected. Experiments are performed on the drug Pioglitazone. Compared to other
computerized methods, our proposed method achieves good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5146</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5146</id><created>2013-08-23</created><updated>2014-10-24</updated><authors><author><keyname>Ahmed</keyname><forenames>Ali</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author></authors><title>Compressive Multiplexing of Correlated Signals</title><categories>cs.IT math.IT stat.AP</categories><comments>38 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general architecture for the acquisition of ensembles of
correlated signals. The signals are multiplexed onto a single line by mixing
each one against a different code and then adding them together, and the
resulting signal is sampled at a high rate. We show that if the $M$ signals,
each bandlimited to $W/2$ Hz, can be approximated by a superposition of $R &lt; M$
underlying signals, then the ensemble can be recovered by sampling at a rate
within a logarithmic factor of $RW$ (as compared to the Nyquist rate of $MW$).
This sampling theorem shows that the correlation structure of the signal
ensemble can be exploited in the acquisition process even though it is unknown
a priori.
  The reconstruction of the ensemble is recast as a low-rank matrix recovery
problem from linear measurements. The architectures we are considering impose a
certain type of structure on the linear operators. Although our results depend
on the mixing forms being random, this imposed structure results in a very
different type of random projection than those analyzed in the low-rank
recovery literature to date.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5149</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5149</id><created>2013-08-23</created><authors><author><keyname>Cohen</keyname><forenames>Deborah</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Sub-Nyquist Sampling for Power Spectrum Sensing in Cognitive Radios: A
  Unified Approach</title><categories>cs.IT math.IT</categories><comments>13 pages</comments><doi>10.1109/TSP.2014.2331613</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In light of the ever-increasing demand for new spectral bands and the
underutilization of those already allocated, the concept of Cognitive Radio
(CR) has emerged. Opportunistic users could exploit temporarily vacant bands
after detecting the absence of activity of their owners. One of the crucial
tasks in the CR cycle is therefore spectrum sensing and detection which has to
be precise and efficient. Yet, CRs typically deal with wideband signals whose
Nyquist rates are very high. In this paper, we propose to reconstruct the power
spectrum of such signals from sub-Nyquist samples, rather than the signal
itself as done in previous work, in order to perform detection. We consider
both sparse and non sparse signals as well as blind and non blind detection in
the sparse case. For each one of those scenarii, we derive the minimal sampling
rate allowing perfect reconstruction of the signal's power spectrum in a
noise-free environment and provide power spectrum recovery techniques that
achieve those rates. The analysis is performed for two different signal models
considered in the literature, which we refer to as the analog and digital
models, and shows that both lead to similar results. Simulations demonstrate
power spectrum recovery at the minimal rate in noise-free settings and show the
impact of several parameters on the detector performance, including
signal-to-noise ratio (SNR), sensing time and sampling rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5158</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5158</id><created>2013-08-23</created><authors><author><keyname>Gopalan</keyname><forenames>Parikshit</forenames></author><author><keyname>Vadhan</keyname><forenames>Salil</forenames></author><author><keyname>Zhou</keyname><forenames>Yuan</forenames></author></authors><title>Locally Testable Codes and Cayley Graphs</title><categories>cs.CC</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give two new characterizations of ($\F_2$-linear) locally testable
error-correcting codes in terms of Cayley graphs over $\F_2^h$:
  \begin{enumerate} \item A locally testable code is equivalent to a Cayley
graph over $\F_2^h$ whose set of generators is significantly larger than $h$
and has no short linear dependencies, but yields a shortest-path metric that
embeds into $\ell_1$ with constant distortion. This extends and gives a
converse to a result of Khot and Naor (2006), which showed that codes with
large dual distance imply Cayley graphs that have no low-distortion embeddings
into $\ell_1$.
  \item A locally testable code is equivalent to a Cayley graph over $\F_2^h$
that has significantly more than $h$ eigenvalues near 1, which have no short
linear dependencies among them and which &quot;explain&quot; all of the large
eigenvalues. This extends and gives a converse to a recent construction of
Barak et al. (2012), which showed that locally testable codes imply Cayley
graphs that are small-set expanders but have many large eigenvalues.
\end{enumerate}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5164</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5164</id><created>2013-08-23</created><authors><author><keyname>Boz&#xf3;ki</keyname><forenames>S&#xe1;ndor</forenames></author><author><keyname>Lee</keyname><forenames>Tsung-Lin</forenames></author><author><keyname>R&#xf3;nyai</keyname><forenames>Lajos</forenames></author></authors><title>Seven mutually touching infinite cylinders</title><categories>math.MG cs.CG</categories><comments>13 pages, 2 figures</comments><msc-class>52C17, 52A40, 65H04, 65H20, 65G40</msc-class><journal-ref>Computational Geometry: Theory and Applications 48(2) (2015) 87-93</journal-ref><doi>10.1016/j.comgeo.2014.08.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We confirm a conjecture of Littlewood: there exist seven infinite circular
cylinders of unit radius which mutually touch each other. In fact, we exhibit
two such sets of cylinders. Our approach is algebraic and uses symbolic and
numerical computational techniques. We consider a system of polynomial
equations describing the position of the axes of the cylinders in the 3
dimensional space. To have the same number of equations (namely 20) as the
number of variables, the angle of the first two cylinders is fixed to 90
degrees, and a small family of direction vectors is left out of consideration.
Homotopy continuation method has been applied to solve the system. The number
of paths is about 121 billion, it is hopeless to follow them all. However,
after checking 80 million paths, two solutions are found. Their validity, i.e.,
the existence of exact real solutions close to the approximate solutions at
hand, was verified with the alphaCertified method as well as by the interval
Krawczyk method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5165</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5165</id><created>2013-08-23</created><updated>2013-10-15</updated><authors><author><keyname>Friedmann</keyname><forenames>Oliver</forenames><affiliation>University of Munich</affiliation></author><author><keyname>Lange</keyname><forenames>Martin</forenames><affiliation>University of Kassel</affiliation></author><author><keyname>Latte</keyname><forenames>Markus</forenames><affiliation>University of Munich</affiliation></author></authors><title>Satisfiability Games for Branching-Time Logics</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 4 (October
  16, 2013) lmcs:761</journal-ref><doi>10.2168/LMCS-9(4:5)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The satisfiability problem for branching-time temporal logics like CTL*, CTL
and CTL+ has important applications in program specification and verification.
Their computational complexities are known: CTL* and CTL+ are complete for
doubly exponential time, CTL is complete for single exponential time. Some
decision procedures for these logics are known; they use tree automata,
tableaux or axiom systems. In this paper we present a uniform game-theoretic
framework for the satisfiability problem of these branching-time temporal
logics. We define satisfiability games for the full branching-time temporal
logic CTL* using a high-level definition of winning condition that captures the
essence of well-foundedness of least fixpoint unfoldings. These winning
conditions form formal languages of \omega-words. We analyse which kinds of
deterministic {\omega}-automata are needed in which case in order to recognise
these languages. We then obtain a reduction to the problem of solving parity or
B\&quot;uchi games. The worst-case complexity of the obtained algorithms matches the
known lower bounds for these logics. This approach provides a uniform, yet
complexity-theoretically optimal treatment of satisfiability for branching-time
temporal logics. It separates the use of temporal logic machinery from the use
of automata thus preserving a syntactical relationship between the input
formula and the object that represents satisfiability, i.e. a winning strategy
in a parity or B\&quot;uchi game. The games presented here work on a Fischer-Ladner
closure of the input formula only. Last but not least, the games presented here
come with an attempt at providing tool support for the satisfiability problem
of complex branching-time logics like CTL* and CTL+.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5168</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5168</id><created>2013-08-23</created><authors><author><keyname>Wu</keyname><forenames>Shan-Hung</forenames></author><author><keyname>Chou</keyname><forenames>Man-Ju</forenames></author><author><keyname>Wang</keyname><forenames>Ming-Hung</forenames></author><author><keyname>Tseng</keyname><forenames>Chun-Hsiung</forenames></author><author><keyname>Lee</keyname><forenames>Yuh-Jye</forenames></author><author><keyname>Chen</keyname><forenames>Kuan-Ta</forenames></author></authors><title>Is Somebody Watching Your Facebook Newsfeed?</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the popularity of Social Networking Services (SNS), more and more
sensitive information are stored online and associated with SNS accounts. The
obvious value of SNS accounts motivates the usage stealing problem --
unauthorized, stealthy use of SNS accounts on the devices owned/used by account
owners without any technology hacks. For example, anxious parents may use their
kids' SNS accounts to inspect the kids' social status; husbands/wives may use
their spouses' SNS accounts to spot possible affairs. Usage stealing could
happen anywhere in any form, and seriously invades the privacy of account
owners. However, there is no any currently known defense against such usage
stealing. To an SNS operator (e.g., Facebook Inc.), usage stealing is hard to
detect using traditional methods because such attackers come from the same IP
addresses/devices, use the same credentials, and share the same accounts as the
owners do.
  In this paper, we propose a novel continuous authentication approach that
analyzes user browsing behavior to detect SNS usage stealing incidents. We use
Facebook as a case study and show that it is possible to detect such incidents
by analyzing SNS browsing behavior. Our experiment results show that our
proposal can achieve higher than 80% detection accuracy within 2 minutes, and
higher than 90% detection accuracy after 7 minutes of observation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5169</identifier>
 <datestamp>2014-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5169</id><created>2013-08-23</created><authors><author><keyname>Fotouhi</keyname><forenames>Babak</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author></authors><title>Degree Correlation in Scale-Free Graphs</title><categories>cond-mat.stat-mech cs.SI physics.data-an physics.soc-ph</categories><journal-ref>The European Physical Journal B, Volume 86, eid=510, 2013</journal-ref><doi>10.1140/epjb/e2013-40920-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain closed form expressions for the expected conditional degree
distribution and the joint degree distribution of the linear preferential
attachment model for network growth in the steady state. We consider the
multiple-destination preferential attachment growth model, where incoming nodes
at each timestep attach to $\beta$ existing nodes, selected by
degree-proportional probabilities. By the conditional degree distribution
$p(\ell| k)$, we mean the degree distribution of nodes that are connected to a
node of degree $k$. By the joint degree distribution $p(k,\ell)$, we mean the
proportion of links that connect nodes of degrees $k$ and $\ell$. In addition
to this growth model, we consider the shifted-linear preferential growth model
and solve for the same quantities, as well as a closed form expression for its
steady-state degree distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5170</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5170</id><created>2013-08-23</created><updated>2014-01-11</updated><authors><author><keyname>Kintali</keyname><forenames>Shiva</forenames></author><author><keyname>Zhang</keyname><forenames>Qiuyi</forenames></author></authors><title>Forbidden Directed Minors and Kelly-width</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partial 1-trees are undirected graphs of treewidth at most one. Similarly,
partial 1-DAGs are directed graphs of KellyWidth at most two. It is well-known
that an undirected graph is a partial 1-tree if and only if it has no K_3
minor. In this paper, we generalize this characterization to partial 1-DAGs. We
show that partial 1-DAGs are characterized by three forbidden directed minors,
K_3, N_4 and M_5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5174</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5174</id><created>2013-08-23</created><updated>2013-09-28</updated><authors><author><keyname>Pallister</keyname><forenames>James</forenames></author><author><keyname>Hollis</keyname><forenames>Simon</forenames></author><author><keyname>Bennett</keyname><forenames>Jeremy</forenames></author></authors><title>BEEBS: Open Benchmarks for Energy Measurements on Embedded Platforms</title><categories>cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents and justifies an open benchmark suite named BEEBS,
targeted at evaluating the energy consumption of embedded processors.
  We explore the possible sources of energy consumption, then select individual
benchmarks from contemporary suites to cover these areas. Version one of BEEBS
is presented here and contains 10 benchmarks that cover a wide range of typical
embedded applications. The benchmark suite is portable across diverse
architectures and is freely available.
  The benchmark suite is extensively evaluated, and the properties of its
constituent programs are analysed. Using real hardware platforms we show case
examples which illustrate the difference in power dissipation between three
processor architectures and their related ISAs. We observe significant
differences in the average instruction dissipation between the architectures of
4.4x, specifically 170uW/MHz (ARM Cortex-M0), 65uW/MHz (Adapteva Epiphany) and
88uW/MHz (XMOS XS1-L1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5177</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5177</id><created>2013-08-23</created><authors><author><keyname>Gitanjali</keyname></author><author><keyname>Sehra</keyname><forenames>Sukhjit Singh</forenames></author><author><keyname>Singh</keyname><forenames>Jaiteg</forenames></author></authors><title>Policy Specification in Role based Access Control on Clouds</title><categories>cs.DC cs.CR</categories><journal-ref>International Journal of Computer Applications 75(1):39-43, August
  2013</journal-ref><doi>10.5120/13078-0253</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud Computing is a set of IT Services that are provided to a customer over
a network and these services are delivered by third party provider who owns the
infrastructure and reduce the burden at user's end. Nowadays researchers
devoted their work access control method to enhance the security on Cloud. RBAC
is attractive access model because the number of roles is significantly less
hence users can be easily classified according to their roles. The Role-based
Access Control (RBAC) model provides efficient way to manage access to
information while reducing the cost of security administration and complexity
in large networked applications. This paper specify various policies in RBAC on
clouds such as migration policy which helps the user to migrate the database
schema and roles easily to the Cloud using XML with more security. Restriction
policy provide the security enhancement in Role Based Access Model by
restricting the number of transaction per user and if the number of
transactions will increase the admin will come to know through its monitoring
system that unauthorized access has been made and it would be easier to take
action against such happening. This paper proposes backup and restoration
policy in Role Based Access Model in which if the main cloud is crashed or not
working properly then the backup and restoration facility will be available to
avoid the lost of important data. In this case chances of loss of data are very
less so enhance more security on Cloud Computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5190</identifier>
 <datestamp>2014-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5190</id><created>2013-08-23</created><updated>2014-02-26</updated><authors><author><keyname>Szell</keyname><forenames>Michael</forenames></author><author><keyname>Grauwin</keyname><forenames>Sebastian</forenames></author><author><keyname>Ratti</keyname><forenames>Carlo</forenames></author></authors><title>Contraction of online response to major events</title><categories>physics.soc-ph cs.SI</categories><comments>project page: http://senseable.mit.edu/tweetbursts/</comments><journal-ref>PLOS ONE 9(2): e89052 (2014)</journal-ref><doi>10.1371/journal.pone.0089052</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Quantifying regularities in behavioral dynamics is of crucial interest for
understanding collective social events such as panics or political revolutions.
With the widespread use of digital communication media it has become possible
to study massive data streams of user-created content in which individuals
express their sentiments, often towards a specific topic. Here we investigate
messages from various online media created in response to major, collectively
followed events such as sport tournaments, presidential elections or a large
snow storm. We relate content length and message rate, and find a systematic
correlation during events which can be described by a power law relation - the
higher the excitation the shorter the messages. We show that on the one hand
this effect can be observed in the behavior of most regular users, and on the
other hand is accentuated by the engagement of additional user demographics who
only post during phases of high collective activity. Further, we identify the
distributions of content lengths as lognormals in line with statistical
linguistics, and suggest a phenomenological law for the systematic dependence
of the message rate to the lognormal mean parameter. Our measurements have
practical implications for the design of micro-blogging and messaging services.
In the case of the existing service Twitter, we show that the imposed limit of
140 characters per message currently leads to a substantial fraction of
possibly dissatisfying to compose tweets that need to be truncated by their
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5200</identifier>
 <datestamp>2016-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5200</id><created>2013-08-23</created><authors><author><keyname>Boumal</keyname><forenames>Nicolas</forenames></author><author><keyname>Mishra</keyname><forenames>Bamdev</forenames></author><author><keyname>Absil</keyname><forenames>P. -A.</forenames></author><author><keyname>Sepulchre</keyname><forenames>Rodolphe</forenames></author></authors><title>Manopt, a Matlab toolbox for optimization on manifolds</title><categories>cs.MS cs.LG math.OC stat.ML</categories><journal-ref>The Journal of Machine Learning Research, 15(1), 1455-1459 (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimization on manifolds is a rapidly developing branch of nonlinear
optimization. Its focus is on problems where the smooth geometry of the search
space can be leveraged to design efficient numerical algorithms. In particular,
optimization on manifolds is well-suited to deal with rank and orthogonality
constraints. Such structured constraints appear pervasively in machine learning
applications, including low-rank matrix completion, sensor network
localization, camera network registration, independent component analysis,
metric learning, dimensionality reduction and so on. The Manopt toolbox,
available at www.manopt.org, is a user-friendly, documented piece of software
dedicated to simplify experimenting with state of the art Riemannian
optimization algorithms. We aim particularly at reaching practitioners outside
our field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5202</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5202</id><created>2013-08-23</created><authors><author><keyname>Ozcan</keyname><forenames>Gozde</forenames></author><author><keyname>Gursoy</keyname><forenames>M. Cenk</forenames></author></authors><title>Throughput of Cognitive Radio Systems with Finite Blocklength Codes</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Journal on Selected Areas in Communications-
  Cognitive Radio Series</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, throughput achieved in cognitive radio channels with finite
blocklength codes under buffer limitations is studied. Cognitive users first
determine the activity of the primary users' through channel sensing and then
initiate data transmission at a power level that depends on the channel sensing
decisions. It is assumed that finite blocklength codes are employed in the data
transmission phase. Hence, errors can occur in reception and retransmissions
can be required. Primary users' activities are modeled as a two-state Markov
chain and an eight-state Markov chain is constructed in order to model the
cognitive radio channel. Channel state information (CSI) is assumed to be
perfectly known by either the secondary receiver only or both the secondary
transmitter and receiver. In the absence of CSI at the transmitter, fixed-rate
transmission is performed whereas under perfect CSI knowledge, for a given
target error probability, the transmitter varies the rate according to the
channel conditions. Under these assumptions, throughput in the presence of
buffer constraints is determined by characterizing the maximum constant arrival
rates that can be supported by the cognitive radio channel while satisfying
certain limits on buffer violation probabilities. Tradeoffs between throughput,
buffer constraints, coding blocklength, and sensing duration for both
fixed-rate and variable-rate transmissions are analyzed numerically. The
relations between average error probability, sensing threshold and sensing
duration are studied in the case of variable-rate transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5207</identifier>
 <datestamp>2015-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5207</id><created>2013-08-23</created><updated>2015-10-06</updated><authors><author><keyname>Bandeira</keyname><forenames>Afonso S.</forenames></author><author><keyname>Kennedy</keyname><forenames>Christopher</forenames></author><author><keyname>Singer</keyname><forenames>Amit</forenames></author></authors><title>Approximating the Little Grothendieck Problem over the Orthogonal and
  Unitary Groups</title><categories>cs.DS math.OC</categories><comments>Updates in version 2: extension to the complex valued (unitary group)
  case, sharper lower bounds on the approximation ratios, matching integrality
  gap, and a generalized rank constrained version of the problem. Updates in
  version 3: Improvement on the exposition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The little Grothendieck problem consists of maximizing
$\sum_{ij}C_{ij}x_ix_j$ over binary variables $x_i\in\{\pm1\}$, where C is a
positive semidefinite matrix. In this paper we focus on a natural
generalization of this problem, the little Grothendieck problem over the
orthogonal group. Given C a dn x dn positive semidefinite matrix, the objective
is to maximize $\sum_{ij}Tr (C_{ij}^TO_iO_j^T)$ restricting $O_i$ to take
values in the group of orthogonal matrices, where $C_{ij}$ denotes the (ij)-th
d x d block of C. We propose an approximation algorithm, which we refer to as
Orthogonal-Cut, to solve this problem and show a constant approximation ratio.
Our method is based on semidefinite programming. For a given $d\geq 1$, we show
a constant approximation ratio of $\alpha_{R}(d)^2$, where $\alpha_{R}(d)$ is
the expected average singular value of a d x d matrix with random Gaussian
$N(0,1/d)$ i.i.d. entries. For d=1 we recover the known $\alpha_{R}(1)^2=2/\pi$
approximation guarantee for the classical little Grothendieck problem. Our
algorithm and analysis naturally extends to the complex valued case also
providing a constant approximation ratio for the analogous problem over the
Unitary Group.
  Orthogonal-Cut also serves as an approximation algorithm for several
applications, including the Procrustes problem where it improves over the best
previously known approximation ratio of~$\frac1{2\sqrt{2}}$. The little
Grothendieck problem falls under the class of problems approximated by a recent
algorithm proposed in the context of the non-commutative Grothendieck
inequality. Nonetheless, our approach is simpler and it provides a more
efficient algorithm with better approximation ratios and matching integrality
gaps.
  Finally, we also provide an improved approximation algorithm for the more
general little Grothendieck problem over the orthogonal (or unitary) group with
rank constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5208</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5208</id><created>2013-08-23</created><authors><author><keyname>Datta</keyname><forenames>Dibakar</forenames></author></authors><title>Introduction to eXtended Finite Element (XFEM) Method</title><categories>physics.comp-ph cs.NA math.NA</categories><comments>20 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present study the software CrackComput, based on the Xfem and Xcrack
libraries has been used for three problems- to experiment on the convergence
properties of the method applied to elasto-statics crack problems, comparison
of stress intensity factors to simplified analytical results and study of the
Brazilian fracture test. All the problems are treated in two dimensions under
plane strain assumption and the material is supposed elastic and isotropic. For
the first example, comparison for different parameter-enrichment type and
radius, degree of polynomial has been performed. Second example convergence of
SIF with the L/h ratio has been performed and compared with the analytical
solution. Third example is the study of snapback phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5211</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5211</id><created>2013-08-23</created><updated>2014-08-13</updated><authors><author><keyname>Xie</keyname><forenames>Hongmei</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Two-layer Locally Repairable Codes for Distributed Storage Systems</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to inaccuracy of
  Claim 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose locally repairable codes (LRCs) with optimal
minimum distance for distributed storage systems (DSS). A two-layer encoding
structure is employed to ensure data reconstruction and the designated repair
locality. The data is first encoded in the first layer by any existing maximum
distance separable (MDS) codes, and then the encoded symbols are divided into
non-overlapping groups and encoded by an MDS array code in the second layer.
The encoding in the second layer provides enough redundancy for local repair,
while the overall code performs recovery of the data based on redundancy from
both layers. Our codes can be constructed over a finite field with size growing
linearly with the total number of nodes in the DSS, and facilitate efficient
degraded reads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5215</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5215</id><created>2013-08-23</created><authors><author><keyname>Datta</keyname><forenames>Dibakar</forenames></author><author><keyname>Heres</keyname><forenames>Jacobo Carrasco</forenames></author></authors><title>Numerical Solution of Advection-Diffusion Equation Using Preconditionar
  as Incomplete LU Decomposition and the BiCGSTAB Aceleration Method</title><categories>physics.comp-ph cs.NA math.NA</categories><comments>70 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present study, an advection-diffusion problem has been considered for
the numerical solution. The continuum equation is discretized using both upwind
and centered scheme. The linear system is solved using the ILU preconditioned
BiCGSTAB method. Both Dirichlet and Neumann boundary condition has been
considered. The obtained results have been compared for different cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5218</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5218</id><created>2013-08-23</created><updated>2013-09-06</updated><authors><author><keyname>Gansner</keyname><forenames>Emden R.</forenames></author><author><keyname>Hu</keyname><forenames>Yifan</forenames></author><author><keyname>Krishnan</keyname><forenames>Shankar</forenames></author></authors><title>COAST: A Convex Optimization Approach to Stress-Based Embedding</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visualizing graphs using virtual physical models is probably the most heavily
used technique for drawing graphs in practice. There are many algorithms that
are efficient and produce high-quality layouts. If one requires that the layout
also respect a given set of non-uniform edge lengths, however, force-based
approaches become problematic while energy-based layouts become intractable. In
this paper, we propose a reformulation of the stress function into a two-part
convex objective function to which we can apply semi-definite programming
(SDP). We avoid the high computational cost associated with SDP by a novel,
compact re-parameterization of the objective function using the eigenvectors of
the graph Laplacian. This sparse representation makes our approach scalable. We
provide experimental results to show that this method scales well and produces
reasonable layouts while dealing with the edge length constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5239</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5239</id><created>2013-08-23</created><updated>2013-08-27</updated><authors><author><keyname>Makhdoumi</keyname><forenames>Ali</forenames></author><author><keyname>Huang</keyname><forenames>Shao-Lun</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Polyanskiy</keyname><forenames>Yury</forenames></author></authors><title>On Locally Decodable Source Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Locally decodable channel codes form a special class of error-correcting
codes with the property that the decoder is able to reconstruct any bit of the
input message from querying only a few bits of a noisy codeword. It is well
known that such codes require significantly more redundancy (in particular have
vanishing rate) compared to their non-local counterparts. In this paper, we
define a dual problem, i.e. locally decodable source codes (LDSC). We consider
both almost lossless (block error) and lossy (bit error) cases. In almost
lossless case, we show that optimal compression (to entropy) is possible with
O(log n) queries to compressed string by the decompressor. We also show the
following converse bounds: 1) linear LDSC cannot achieve any rate below one,
with a bounded number of queries, 2) rate of any source coding with linear
decoder (not necessarily local) in one, 3) for 2 queries, any code construction
cannot have a rate below one. In lossy case, we show that any rate above rate
distortion is achievable with a bounded number of queries. We also show that,
rate distortion is achievable with any scaling number of queries. We provide an
achievability bound in the finite block-length regime and compare it with the
existing bounds in succinct data structures literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5249</identifier>
 <datestamp>2014-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5249</id><created>2013-08-23</created><updated>2014-12-19</updated><authors><author><keyname>Baker</keyname><forenames>Christopher A.</forenames></author></authors><title>A Note on Sparsification by Frames</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this note is to establish a new generalized
Dictionary-Restricted Isometry Property (D-RIP) sparsity bound constant for
compressed sensing.
  For fulfilling D-RIP, the constant $\delta_k$ is used in the definition: $(1
-\delta_k)\|D v\|_2^2 \le \|\Phi D v\|_2^2 \le (1 + \delta_k)\|D v\|^2$. We
prove that signals with $k$-sparse $D$-representation can be reconstructed if
$\delta_{2k} &lt; \frac{2}3$.
  The approach in this note can be extended to obtain other D-RIP bounds (i.e.,
$\delta_{tk}$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5256</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5256</id><created>2013-08-23</created><authors><author><keyname>Bandeira</keyname><forenames>Afonso S.</forenames></author><author><keyname>Charikar</keyname><forenames>Moses</forenames></author><author><keyname>Singer</keyname><forenames>Amit</forenames></author><author><keyname>Zhu</keyname><forenames>Andy</forenames></author></authors><title>Multireference Alignment using Semidefinite Programming</title><categories>cs.DS math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multireference alignment problem consists of estimating a signal from
multiple noisy shifted observations. Inspired by existing Unique-Games
approximation algorithms, we provide a semidefinite program (SDP) based
relaxation which approximates the maximum likelihood estimator (MLE) for the
multireference alignment problem. Although we show that the MLE problem is
Unique-Games hard to approximate within any constant, we observe that our
poly-time approximation algorithm for the MLE appears to perform quite well in
typical instances, outperforming existing methods. In an attempt to explain
this behavior we provide stability guarantees for our SDP under a random noise
model on the observations. This case is more challenging to analyze than
traditional semi-random instances of Unique-Games: the noise model is on
vertices of a graph and translates into dependent noise on the edges.
Interestingly, we show that if certain positivity constraints in the SDP are
dropped, its solution becomes equivalent to performing phase correlation, a
popular method used for pairwise alignment in imaging applications. Finally, we
show how symmetry reduction techniques from matrix representation theory can
simplify the analysis and computation of the SDP, greatly decreasing its
computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5261</identifier>
 <datestamp>2014-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5261</id><created>2013-08-23</created><updated>2014-02-13</updated><authors><author><keyname>Rios</keyname><forenames>Dionicio F.</forenames></author><author><keyname>Shirin</keyname><forenames>Afroza</forenames></author><author><keyname>Sorrentino</keyname><forenames>Francesco</forenames></author></authors><title>The Network Observability Problem: Detecting nodes and connections and
  the role of graph symmetries</title><categories>nlin.PS cs.DS physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconstructing the connections between the nodes of a network is a problem of
fundamental importance in the study of neuronal and genetic networks. An
underlying related problem is that of observability, i.e., identifying the
conditions under which such a reconstruction is possible. In this paper we
consider observability of complex dynamical networks,for which we aim at
identifying both node and edge states. We use a graphical approach, which we
apply to both the Node Inference Diagram (NID) and the Node Edge Inference
Diagram (NEID) of the network. We investigate the relationship between the
observability of the NID and that of the NEID network representations and
conclude that the latter can be derived from the former, under general
assumptions. We further consider the effects of graph symmetries on
observability and we show how a minimal set of outputs can be selected to
obtain observability in the presence of graph symmetries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5269</identifier>
 <datestamp>2013-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5269</id><created>2013-08-23</created><updated>2013-11-11</updated><authors><author><keyname>Mesri</keyname><forenames>Hamed Yousefi</forenames></author></authors><title>A comparative analysis of methods for estimating axon diameter using DWI</title><categories>cs.NE</categories><comments>The work needs more details. The complete work will be submitted
  later</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of studying the brain microstructure is described and the
existing and state of the art non-invasive methods for the investigation of the
brain microstructure using Diffusion Weighted Magnetic Resonance Imaging (DWI)
is studied. In the next step, Cramer-Rao Lower Bound (CRLB) analysis is
described and utilised for assessment of the minimum estimation error and
uncertainty level of different Diffusion Weighted Magnetic Resonance (DWMR)
signal decay models. The analyses are performed considering the best scenario
through which, we assume that the models are the appropriate representation of
the measured phenomena. This includes the study of the sensitivity of the
estimations to the measurement and model parameters. It is demonstrated that
none of the existing models can achieve a reasonable minimum uncertainty level
under typical measurement setup. At the end, the practical obstacles for
achieving higher performance in clinical and experimental environments are
studied and their effects on feasibility of the methods are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5272</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5272</id><created>2013-08-23</created><updated>2013-09-23</updated><authors><author><keyname>Garg</keyname><forenames>Jugal</forenames></author><author><keyname>Vazirani</keyname><forenames>Vijay V.</forenames></author></authors><title>On Computability of Equilibria in Markets with Production</title><categories>cs.GT</categories><comments>An extended abstract will appear in SODA 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although production is an integral part of the Arrow-Debreu market model,
most of the work in theoretical computer science has so far concentrated on
markets without production, i.e., the exchange economy. This paper takes a
significant step towards understanding computational aspects of markets with
production.
  We first define the notion of separable, piecewise-linear concave (SPLC)
production by analogy with SPLC utility functions. We then obtain a linear
complementarity problem (LCP) formulation that captures exactly the set of
equilibria for Arrow-Debreu markets with SPLC utilities and SPLC production,
and we give a complementary pivot algorithm for finding an equilibrium. This
settles a question asked by Eaves in 1975 of extending his complementary pivot
algorithm to markets with production.
  Since this is a path-following algorithm, we obtain a proof of membership of
this problem in PPAD, using Todd, 1976. We also obtain an elementary proof of
existence of equilibrium (i.e., without using a fixed point theorem),
rationality, and oddness of the number of equilibria. We further give a proof
of PPAD-hardness for this problem and also for its restriction to markets with
linear utilities and SPLC production. Experiments show that our algorithm runs
fast on randomly chosen examples, and unlike previous approaches, it does not
suffer from issues of numerical instability. Additionally, it is strongly
polynomial when the number of goods or the number of agents and firms is
constant. This extends the result of Devanur and Kannan (2008) to markets with
production.
  Finally, we show that an LCP-based approach cannot be extended to PLC
(non-separable) production, by constructing an example which has only
irrational equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5273</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5273</id><created>2013-08-23</created><authors><author><keyname>de Alfaro</keyname><forenames>Luca</forenames></author><author><keyname>Shavlovsky</keyname><forenames>Michael</forenames></author></authors><title>CrowdGrader: Crowdsourcing the Evaluation of Homework Assignments</title><categories>cs.SI cs.IR</categories><comments>Technical Report UCSC-SOE-13-11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowdsourcing offers a practical method for ranking and scoring large amounts
of items. To investigate the algorithms and incentives that can be used in
crowdsourcing quality evaluations, we built CrowdGrader, a tool that lets
students submit and collaboratively grade solutions to homework assignments. We
present the algorithms and techniques used in CrowdGrader, and we describe our
results and experience in using the tool for several computer-science
assignments.
  CrowdGrader combines the student-provided grades into a consensus grade for
each submission using a novel crowdsourcing algorithm that relies on a
reputation system. The algorithm iterativerly refines inter-dependent estimates
of the consensus grades, and of the grading accuracy of each student. On
synthetic data, the algorithm performs better than alternatives not based on
reputation. On our preliminary experimental data, the performance seems
dependent on the nature of review errors, with errors that can be ascribed to
the reviewer being more tractable than those arising from random external
events. To provide an incentive for reviewers, the grade each student receives
in an assignment is a combination of the consensus grade received by their
submissions, and of a reviewing grade capturing their reviewing effort and
accuracy. This incentive worked well in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5275</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5275</id><created>2013-08-23</created><authors><author><keyname>Iyer</keyname><forenames>Rishabh</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff</forenames></author></authors><title>The Lovasz-Bregman Divergence and connections to rank aggregation,
  clustering, and web ranking</title><categories>cs.LG cs.IR stat.ML</categories><comments>18 pages. A shorter version appeared in Proc. Uncertainty in
  Artificial Intelligence (UAI)-2013, Bellevue, WA</comments><journal-ref>UAI-2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the recently introduced theory of Lovasz-Bregman (LB) divergences
(Iyer &amp; Bilmes, 2012) in several ways. We show that they represent a distortion
between a 'score' and an 'ordering', thus providing a new view of rank
aggregation and order based clustering with interesting connections to web
ranking. We show how the LB divergences have a number of properties akin to
many permutation based metrics, and in fact have as special cases forms very
similar to the Kendall-$\tau$ metric. We also show how the LB divergences
subsume a number of commonly used ranking measures in information retrieval,
like the NDCG and AUC. Unlike the traditional permutation based metrics,
however, the LB divergence naturally captures a notion of &quot;confidence&quot; in the
orderings, thus providing a new representation to applications involving
aggregating scores as opposed to just orderings. We show how a number of
recently used web ranking models are forms of Lovasz-Bregman rank aggregation
and also observe that a natural form of Mallow's model using the LB divergence
has been used as conditional ranking models for the 'Learning to Rank' problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5281</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5281</id><created>2013-08-23</created><authors><author><keyname>Canzian</keyname><forenames>Luca</forenames></author><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Ensemble of Distributed Learners for Online Classification of Dynamic
  Data Streams</title><categories>cs.LG</categories><comments>14 pages, 5 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient distributed online learning scheme to classify data
captured from distributed, heterogeneous, and dynamic data sources. Our scheme
consists of multiple distributed local learners, that analyze different streams
of data that are correlated to a common event that needs to be classified. Each
learner uses a local classifier to make a local prediction. The local
predictions are then collected by each learner and combined using a weighted
majority rule to output the final prediction. We propose a novel online
ensemble learning algorithm to update the aggregation rule in order to adapt to
the underlying data dynamics. We rigorously determine a bound for the worst
case misclassification probability of our algorithm which depends on the
misclassification probabilities of the best static aggregation rule, and of the
best local classifier. Importantly, the worst case misclassification
probability of our algorithm tends asymptotically to 0 if the misclassification
probability of the best static aggregation rule or the misclassification
probability of the best local classifier tend to 0. Then we extend our
algorithm to address challenges specific to the distributed implementation and
we prove new bounds that apply to these settings. Finally, we test our scheme
by performing an evaluation study on several data sets. When applied to data
sets widely used by the literature dealing with dynamic data streams and
concept drift, our scheme exhibits performance gains ranging from 34% to 71%
with respect to state of the art solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5286</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5286</id><created>2013-08-23</created><updated>2013-08-27</updated><authors><author><keyname>Ribas</keyname><forenames>Sabir</forenames></author><author><keyname>Ribeiro-Neto</keyname><forenames>Berthier</forenames></author><author><keyname>Silva</keyname><forenames>Edmundo de Souza e</forenames></author><author><keyname>Ziviani</keyname><forenames>Nivio</forenames></author></authors><title>R-Score: Reputation-based Scoring of Research Groups</title><categories>cs.DL cs.IR</categories><comments>23 pages, 5 tables, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To manage the problem of having a higher demand for resources than
availability of funds, research funding agencies usually rank the major
research groups in their area of knowledge. This ranking relies on a careful
analysis of the research groups in terms of their size, number of PhDs
graduated, research results and their impact, among other variables. While
research results are not the only variable to consider, they are frequently
given special attention because of the notoriety they confer to the researchers
and the programs they are affiliated with. In here we introduce a new metric
for quantifying publication output, called R-Score for reputation-based score,
which can be used in support to the ranking of research groups or programs. The
novelty is that the metric depends solely on the listings of the publications
of the members of a group, with no dependency on citation counts. R-Score has
some interesting properties: (a) it does not require access to the contents of
published material, (b) it can be curated to produce highly accurate results,
and (c) it can be naturally used to compare publication output of research
groups (e.g., graduate programs) inside a same country, geographical area, or
across the world. An experiment comparing the publication output of 25 CS
graduate programs from Brazil suggests that R-Score can be quite useful for
providing early insights into the publication patterns of the various research
groups one wants to compare.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5294</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5294</id><created>2013-08-24</created><authors><author><keyname>Wang</keyname><forenames>Xiangfeng</forenames></author><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Ma</keyname><forenames>Shiqian</forenames></author><author><keyname>Luo</keyname><forenames>Zhi-Quan</forenames></author></authors><title>Solving Multiple-Block Separable Convex Minimization Problems Using
  Two-Block Alternating Direction Method of Multipliers</title><categories>math.OC cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider solving multiple-block separable convex
minimization problems using alternating direction method of multipliers (ADMM).
Motivated by the fact that the existing convergence theory for ADMM is mostly
limited to the two-block case, we analyze in this paper, both theoretically and
numerically, a new strategy that first transforms a multi-block problem into an
equivalent two-block problem (either in the primal domain or in the dual
domain) and then solves it using the standard two-block ADMM. In particular, we
derive convergence results for this two-block ADMM approach to solve
multi-block separable convex minimization problems, including an improved
O(1/\epsilon) iteration complexity result. Moreover, we compare the numerical
efficiency of this approach with the standard multi-block ADMM on several
separable convex minimization problems which include basis pursuit, robust
principal component analysis and latent variable Gaussian graphical model
selection. The numerical results show that the multiple-block ADMM, although
lacks theoretical convergence guarantees, typically outperforms two-block
ADMMs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5304</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5304</id><created>2013-08-24</created><authors><author><keyname>Zhang</keyname><forenames>Xi</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author></authors><title>Enhancing Secrecy with Multi-Antenna Transmission in Wireless Ad Hoc
  Networks</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Information Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study physical-layer security in wireless ad hoc networks and investigate
two types of multi-antenna transmission schemes for providing secrecy
enhancements. To establish secure transmission against malicious eavesdroppers,
we consider the generation of artificial noise with either sectoring or
beamforming. For both approaches, we provide a statistical characterization and
tradeoff analysis of the outage performance of the legitimate communication and
the eavesdropping links. We then investigate the networkwide secrecy throughput
performance of both schemes in terms of the secrecy transmission capacity, and
study the optimal power allocation between the information signal and the
artificial noise. Our analysis indicates that, under transmit power
optimization, the beamforming scheme outperforms the sectoring scheme, except
for the case where the number of transmit antennas are sufficiently large. Our
study also reveals some interesting differences between the optimal power
allocation for the sectoring and beamforming schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5310</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5310</id><created>2013-08-24</created><authors><author><keyname>Navaz</keyname><forenames>A. S. Syed</forenames></author><author><keyname>Gopalakrishnan</keyname><forenames>S.</forenames></author><author><keyname>Meena</keyname><forenames>R.</forenames></author></authors><title>Anomaly Detections in Internet traffic Using Empirical Measures</title><categories>cs.NI</categories><comments>4 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Introducing Internet traffic anomaly detection mechanism based on large
deviations results for empirical measures. Using past traffic traces we
characterize network traffic during various time-of-day intervals, assuming
that it is anomaly-free. Throughout, we compare the two approaches presenting
their advantages and disadvantages to identify and classify temporal network
anomalies. We also demonstrate how our framework can be used to monitor traffic
from multiple network elements in order to identify both spatial and temporal
anomalies. We validate our techniques by analyzing real traffic traces with
time-stamped anomalies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5315</identifier>
 <datestamp>2015-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5315</id><created>2013-08-24</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author></authors><title>Edge-detection applied to moving sand dunes on Mars</title><categories>cs.CV</categories><comments>Keywords: Edge detection, Sobel filter, GIMP, Image processing,
  Google Mars, Dune motion, Mars Reconnaissance Orbiter, Mars Global Surveyor;
  Ref.14 available at
  http://www.scribd.com/doc/162390676/Moving-Sand-Dunes-on-Mars</comments><journal-ref>International Journal of Sciences, 2013, 2(8):102-104</journal-ref><doi>10.18483/ijSci.251</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we discuss the application of an edge detection filter, the Sobel filter
of GIMP, to the recently discovered motion of some sand dunes on Mars. The
filter allows a good comparison of an image HiRISE of 2007 and an image of 1999
recorded by the Mars Global Surveyor of the dunes in the Nili Patera caldera,
measuring therefore the motion of the dunes on a longer period of time than
that previously investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5317</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5317</id><created>2013-08-24</created><authors><author><keyname>Estrada</keyname><forenames>Ernesto</forenames></author><author><keyname>Vargas-Estrada</keyname><forenames>Eusebio</forenames></author></authors><title>Peer Pressure Shapes Consensus, Leadership, and Innovations in Social
  Groups</title><categories>physics.soc-ph cs.SI</categories><comments>58 pages including Supplementary informastion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is the effect of the combined direct and indirect social influences-peer
pressure (PP)-on a social groups collective decisions? We present a model that
captures PP as a function of the socio-cultural distance between individuals in
a social group. Using this model and empirical data from 15 real-world social
networks we found that the PP level determines how fast a social group reaches
consensus. More importantly, the levels of PP determine the leaders who can
achieve full control of their social groups. PP can overcome barriers imposed
upon a consensus by the existence of tightly connected communities with local
leaders or the existence of leaders with poor cohesiveness of opinions. A
moderate level of PP is also necessary to explain the rate at which innovations
diffuse through a variety of social groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5321</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5321</id><created>2013-08-24</created><authors><author><keyname>Tirri</keyname><forenames>Seppo Ilari</forenames></author></authors><title>Evolution Theory of Self-Evolving Autonomous Problem Solving Systems</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present study gives a mathematical framework for self-evolution within
autonomous problem solving systems. Special attention is set on universal
abstraction, thereof generation by net block homomorphism, consequently
multiple order solving systems and the overall decidability of the set of the
solutions. By overlapping presentation of nets new abstraction relation among
nets is formulated alongside with consequent alphabetical net block renetting
system proportional to normal forms of renetting systems regarding the
operational power. A new structure in self-evolving problem solving is
established via saturation by groups of equivalence relations and iterative
closures of generated quotient transducer algebras over the whole evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5326</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5326</id><created>2013-08-24</created><authors><author><keyname>Li</keyname><forenames>Xu</forenames></author><author><keyname>Sun</keyname><forenames>Xingming</forenames></author><author><keyname>Liu</keyname><forenames>Quansheng</forenames></author><author><keyname>Chen</keyname><forenames>Beijing</forenames></author></authors><title>A Novel Method for Image Integrity Authentication Based on Fixed Point
  Theory</title><categories>cs.CR cs.MM</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on fixed point theory, this paper proposes a simple but efficient
method for image integrity authentication, which is different from Digital
Signature and Fragile Watermarking. By this method, any given image can be
transformed into a fixed point of a well-chosen function, which can be
constructed with periodic functions. The authentication can be realized due to
the fragility of the fixed points. The experiments show that 'Fixed Point
Image' performs well in security, transparence, fragility and tampering
localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5329</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5329</id><created>2013-08-24</created><authors><author><keyname>Bartocci</keyname><forenames>Ezio</forenames><affiliation>TU Wien</affiliation></author><author><keyname>Grosu</keyname><forenames>Radu</forenames><affiliation>TU Wien</affiliation></author></authors><title>Monitoring with uncertainty</title><categories>cs.LO cs.LG cs.SY</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 1-4</journal-ref><doi>10.4204/EPTCS.124.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the problem of runtime verification of an instrumented program
that misses to emit and to monitor some events. These gaps can occur when a
monitoring overhead control mechanism is introduced to disable the monitor of
an application with real-time constraints. We show how to use statistical
models to learn the application behavior and to &quot;fill in&quot; the introduced gaps.
Finally, we present and discuss some techniques developed in the last three
years to estimate the probability that a property of interest is violated in
the presence of an incomplete trace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5330</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5330</id><created>2013-08-24</created><authors><author><keyname>Wisniewski</keyname><forenames>Rafael</forenames><affiliation>Aalborg University</affiliation></author></authors><title>Combinatorial Abstractions of Dynamical Systems</title><categories>cs.SY cs.LO</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><acm-class>B.5.3; B.2.2; B.1.4; I.2.8</acm-class><journal-ref>EPTCS 124, 2013, pp. 5-8</journal-ref><doi>10.4204/EPTCS.124.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal verification has been successfully developed in computer science for
verifying combinatorial classes of models and specifications. In like manner,
formal verification methods have been developed for dynamical systems. However,
the verification of system properties, such as safety, is based on reachability
calculations, which are the sources of insurmountable complexity. This talk
addresses indirect verification methods, which are based on abstracting the
dynamical systems by models of reduced complexity and preserving central
properties of the original systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5331</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5331</id><created>2013-08-24</created><authors><author><keyname>Di Benedetto</keyname><forenames>Maria Domenica</forenames><affiliation>University of L'Aquila</affiliation></author><author><keyname>Pola</keyname><forenames>Giordano</forenames><affiliation>University of L'Aquila</affiliation></author></authors><title>Networked Embedded Control Systems: from Modelling to Implementation</title><categories>cs.SY</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 9-13</journal-ref><doi>10.4204/EPTCS.124.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networked Embedded Control Systems are distributed control systems where the
communication among plants, sensors, actuators and controllers occurs in a
shared network. They have been the subject of intensive study in the last few
years. In this paper we survey our contribution to this research topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5332</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5332</id><created>2013-08-24</created><authors><author><keyname>Chanthery</keyname><forenames>Elodie</forenames></author><author><keyname>Ribot</keyname><forenames>Pauline</forenames></author></authors><title>An Integrated Framework for Diagnosis and Prognosis of Hybrid Systems</title><categories>cs.SY cs.AI cs.SE</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 14-25</journal-ref><doi>10.4204/EPTCS.124.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex systems are naturally hybrid: their dynamic behavior is both
continuous and discrete. For these systems, maintenance and repair are an
increasing part of the total cost of final product. Efficient diagnosis and
prognosis techniques have to be adopted to detect, isolate and anticipate
faults. This paper presents an original integrated theoretical framework for
diagnosis and prognosis of hybrid systems. The formalism used for hybrid
diagnosis is enriched in order to be able to follow the evolution of an aging
law for each fault of the system. The paper presents a methodology for
interleaving diagnosis and prognosis in a hybrid framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5333</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5333</id><created>2013-08-24</created><authors><author><keyname>Wisniewski</keyname><forenames>Rafael</forenames><affiliation>Section of Automation &amp; Control</affiliation></author><author><keyname>Sloth</keyname><forenames>Christoffer</forenames><affiliation>Section of Automation &amp; Control</affiliation></author></authors><title>Completeness of Lyapunov Abstraction</title><categories>cs.SY</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 26-42</journal-ref><doi>10.4204/EPTCS.124.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we continue our study on discrete abstractions of dynamical
systems. To this end, we use a family of partitioning functions to generate an
abstraction. The intersection of sub-level sets of the partitioning functions
defines cells, which are regarded as discrete objects. The union of cells makes
up the state space of the dynamical systems. Our construction gives rise to a
combinatorial object - a timed automaton. We examine sound and complete
abstractions. An abstraction is said to be sound when the flow of the time
automata covers the flow lines of the dynamical systems. If the dynamics of the
dynamical system and the time automaton are equivalent, the abstraction is
complete.
  The commonly accepted paradigm for partitioning functions is that they ought
to be transversal to the studied vector field. We show that there is no
complete partitioning with transversal functions, even for particular dynamical
systems whose critical sets are isolated critical points. Therefore, we allow
the directional derivative along the vector field to be non-positive in this
work. This considerably complicates the abstraction technique. For
understanding dynamical systems, it is vital to study stable and unstable
manifolds and their intersections. These objects appear naturally in this work.
Indeed, we show that for an abstraction to be complete, the set of critical
points of an abstraction function shall contain either the stable or unstable
manifold of the dynamical system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5334</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5334</id><created>2013-08-24</created><authors><author><keyname>Casagrande</keyname><forenames>Alberto</forenames><affiliation>University of Trieste</affiliation></author><author><keyname>Dreossi</keyname><forenames>Tommaso</forenames><affiliation>University of Udine</affiliation></author><author><keyname>Piazza</keyname><forenames>Carla</forenames><affiliation>University of Udine</affiliation></author></authors><title>Approximated Symbolic Computations over Hybrid Automata</title><categories>cs.SY cs.FL cs.LO</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><acm-class>C.1.3; F.4.3; I.1.3</acm-class><journal-ref>EPTCS 124, 2013, pp. 43-57</journal-ref><doi>10.4204/EPTCS.124.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid automata are a natural framework for modeling and analyzing systems
which exhibit a mixed discrete continuous behaviour. However, the standard
operational semantics defined over such models implicitly assume perfect
knowledge of the real systems and infinite precision measurements. Such
assumptions are not only unrealistic, but often lead to the construction of
misleading models. For these reasons we believe that it is necessary to
introduce more flexible semantics able to manage with noise, partial
information, and finite precision instruments. In particular, in this paper we
integrate in a single framework based on approximated semantics different over
and under-approximation techniques for hybrid automata. Our framework allows to
both compare, mix, and generalize such techniques obtaining different
approximated reachability algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5335</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5335</id><created>2013-08-24</created><authors><author><keyname>Capiluppi</keyname><forenames>Marta</forenames><affiliation>Universit&#xe0; di Verona</affiliation></author><author><keyname>Segala</keyname><forenames>Roberto</forenames><affiliation>Universit&#xe0; di Verona</affiliation></author></authors><title>World Automata: a compositional approach to model implicit communication
  in hierarchical Hybrid Systems</title><categories>cs.FL cs.MA</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 58-72</journal-ref><doi>10.4204/EPTCS.124.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an extension of Hybrid I/O Automata (HIOAs) to model agent systems
and their implicit communication through perturbation of the environment, like
localization of objects or radio signals diffusion and detection. The new
object, called World Automaton (WA), is built in such a way to preserve as much
as possible of the compositional properties of HIOAs and its underlying theory.
From the formal point of view we enrich classical HIOAs with a set of world
variables whose values are functions both of time and space. World variables
are treated similarly to local variables of HIOAs, except in parallel
composition, where the perturbations produced by world variables are summed. In
such way, we obtain a structure able to model both agents and environments,
thus inducing a hierarchy in the model and leading to the introduction of a new
operator. Indeed this operator, called inplacement, is needed to represent the
possibility of an object (WA) of living inside another object/environment (WA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5336</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5336</id><created>2013-08-24</created><authors><author><keyname>Bresolin</keyname><forenames>Davide</forenames><affiliation>Universit&#xe0; degli Studi di Verona</affiliation></author></authors><title>HyLTL: a temporal logic for model checking hybrid systems</title><categories>cs.LO cs.FL cs.SY</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 73-84</journal-ref><doi>10.4204/EPTCS.124.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The model-checking problem for hybrid systems is a well known challenge in
the scientific community. Most of the existing approaches and tools are limited
to safety properties only, or operates by transforming the hybrid system to be
verified into a discrete one, thus loosing information on the continuous
dynamics of the system. In this paper we present a logic for specifying complex
properties of hybrid systems called HyLTL, and we show how it is possible to
solve the model checking problem by translating the formula into an equivalent
hybrid automaton. In this way the problem is reduced to a reachability problem
on hybrid automata that can be solved by using existing tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5337</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5337</id><created>2013-08-24</created><authors><author><keyname>Bartocci</keyname><forenames>Ezio</forenames><affiliation>Vienna University of Technology</affiliation></author></authors><title>Sampling-based Decentralized Monitoring for Networked Embedded Systems</title><categories>cs.SE cs.LO</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 85-99</journal-ref><doi>10.4204/EPTCS.124.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decentralized monitoring (DM) refers to a monitoring technique, where each
component must infer, based on a set of partial observations if the global
property is satisfied. Our work is inspired by the theoretical results
presented by Baurer and Falcone at FM 2012, where the authors introduced an
algorithm for distributing and monitoring LTL formulae, such that satisfaction
or violation of specifications can be detected by local monitors alone.
However, their work is based on the main assumption that neither the
computation nor communication take time, hence it does not take into account
how to set a sampling time among the components such that their local traces
are consistent. In this work we provide a timed model in UPPAAL and we show a
case study on a networked embedded systems board.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5338</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5338</id><created>2013-08-24</created><authors><author><keyname>Ocone</keyname><forenames>Andrea</forenames><affiliation>School of Informatics, University of Edinburgh</affiliation></author><author><keyname>Sanguinetti</keyname><forenames>Guido</forenames><affiliation>School of Informatics, University of Edinburgh</affiliation></author></authors><title>A stochastic hybrid model of a biological filter</title><categories>cs.LG cs.CE q-bio.MN</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 100-108</journal-ref><doi>10.4204/EPTCS.124.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a hybrid model of a biological filter, a genetic circuit which
removes fast fluctuations in the cell's internal representation of the extra
cellular environment. The model takes the classic feed-forward loop (FFL) motif
and represents it as a network of continuous protein concentrations and binary,
unobserved gene promoter states. We address the problem of statistical
inference and parameter learning for this class of models from partial,
discrete time observations. We show that the hybrid representation leads to an
efficient algorithm for approximate statistical inference in this circuit, and
show its effectiveness on a simulated data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5339</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5339</id><created>2013-08-24</created><authors><author><keyname>Simonsen</keyname><forenames>Maria</forenames></author><author><keyname>Leth</keyname><forenames>John</forenames></author><author><keyname>Schioler</keyname><forenames>Henrik</forenames></author><author><keyname>Cornean</keyname><forenames>Horia</forenames></author></authors><title>A Simple Stochastic Differential Equation with Discontinuous Drift</title><categories>cs.SY math.NA</categories><comments>In Proceedings HAS 2013, arXiv:1308.4904</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 124, 2013, pp. 109-123</journal-ref><doi>10.4204/EPTCS.124.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study solutions to stochastic differential equations (SDEs)
with discontinuous drift. We apply two approaches: The Euler-Maruyama method
and the Fokker-Planck equation and show that a candidate density function based
on the Euler-Maruyama method approximates a candidate density function based on
the stationary Fokker-Planck equation. Furthermore, we introduce a smooth
function which approximates the discontinuous drift and apply the
Euler-Maruyama method and the Fokker-Planck equation with this input. The point
of departure for this work is a particular SDE with discontinuous drift.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5354</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5354</id><created>2013-08-24</created><updated>2014-08-25</updated><authors><author><keyname>Bilen</keyname><forenames>Cagdas</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Puy</keyname><forenames>Gilles</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Gribonval</keyname><forenames>R&#xe9;mi</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Daudet</keyname><forenames>Laurent</forenames></author></authors><title>Convex Optimization Approaches for Blind Sensor Calibration using
  Sparsity</title><categories>cs.IT math.IT</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Signal Processing 62, 18 (2014) 4847-4856</journal-ref><doi>10.1109/TSP.2014.2342651</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a compressive sensing framework in which the sensors introduce
a distortion to the measurements in the form of unknown gains. We focus on
blind calibration, using measures performed on multiple unknown (but sparse)
signals and formulate the joint recovery of the gains and the sparse signals as
a convex optimization problem. We divide this problem in 3 subproblems with
different conditions on the gains, specifially (i) gains with different
amplitude and the same phase, (ii) gains with the same amplitude and different
phase and (iii) gains with different amplitude and phase. In order to solve the
first case, we propose an extension to the basis pursuit optimization which can
estimate the unknown gains along with the unknown sparse signals. For the
second case, we formulate a quadratic approach that eliminates the unknown
phase shifts and retrieves the unknown sparse signals. An alternative form of
this approach is also formulated to reduce complexity and memory requirements
and provide scalability with respect to the number of input signals. Finally
for the third case, we propose a formulation that combines the earlier two
approaches to solve the problem. The performance of the proposed algorithms is
investigated extensively through numerical simulations, which demonstrates that
simultaneous signal recovery and calibration is possible with convex methods
when sufficiently many (unknown, but sparse) calibrating signals are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5356</identifier>
 <datestamp>2014-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5356</id><created>2013-08-24</created><updated>2014-04-10</updated><authors><author><keyname>Katla</keyname><forenames>Satyanarayana</forenames></author><author><keyname>Balagoni</keyname><forenames>Abhinov</forenames></author></authors><title>Technological and Cost based Analysis of Future-Proof Fiber Access
  Passive Networks: GPON and WDM PON</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the key principles of Gigabit Passive Optical Network
(GPON) which is based on Time Division Multiplexing Passive Optical Network
(TDM PON) and Wavelength Division Multiplexing Passive Optical Network (WDM
PON), which is considered to be next generation passive optical network. In the
present day scenario, access to broad- band is increasing at a rapid pace.
Because of the advantages of fiber access in terms of capacity and cost, most
of the countries have started deploying GPON access as an important part of
national strategy. Though GPON is promising, it has few limitations. On the
other hand WDM PON, a next generation network, is quite promising unlike GPON,
it is easily scalable and interoperable with different vendors. This paper
provides an overview of GPON, WDM PON and its key dissimilarities based on
technicalities and cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5360</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5360</id><created>2013-08-24</created><authors><author><keyname>B</keyname><forenames>Arun I</forenames></author><author><keyname>Venkatesh</keyname><forenames>T. G.</forenames></author></authors><title>Adaptive Backoff Algorithm for IEEE 802.11 DCF under MPR Wireless
  Channels</title><categories>cs.NI</categories><comments>7 pages, 8 figures, Proceedings of 22nd International Conference on
  Computer Communications and Networks (ICCCN) 2013, Nassau, Bahamas</comments><acm-class>C.2.1; C.2.5; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a result of the recent advances in physical (PHY) layer communication
techniques, it is possible to receive multiple packets at the receiver
concurrently. This capability of a receiver to decode multiple simultaneous
transmissions is known as multi-packet reception (MPR). In this paper, we
propose a simple Medium Access Control (MAC) protocol for an MPR wireless
channel, where we modify the backoff procedure as a function of number of
ongoing transmissions in the channel. Our protocol is backward compatible with
the IEEE 802.11 DCF protocol. The performance analysis of the proposed protocol
is carried out using extensive simulations and it is compared with some of the
existing MPR MAC protocols. The proposed mechanism improves the throughput and
delay performance of the IEEE 802.11 DCF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5373</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5373</id><created>2013-08-24</created><authors><author><keyname>Ding</keyname><forenames>Cunsheng</forenames></author><author><keyname>Gao</keyname><forenames>Ying</forenames></author><author><keyname>Zhou</keyname><forenames>Zhengchun</forenames></author></authors><title>Five Families of Three-Weight Ternary Cyclic Codes and Their Duals</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a subclass of linear codes, cyclic codes have applications in consumer
electronics, data storage systems, and communication systems as they have
efficient encoding and decoding algorithms. In this paper, five families of
three-weight ternary cyclic codes whose duals have two zeros are presented. The
weight distributions of the five families of cyclic codes are settled. The
duals of two families of the cyclic codes are optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5374</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5374</id><created>2013-08-24</created><authors><author><keyname>Schwartz</keyname><forenames>Daniel G.</forenames></author></authors><title>Dynamic Reasoning Systems</title><categories>cs.AI cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A {\it dynamic reasoning system} (DRS) is an adaptation of a conventional
formal logical system that explicitly portrays reasoning as a temporal
activity, with each extralogical input to the system and each inference rule
application being viewed as occurring at a distinct time step. Every DRS
incorporates some well-defined logic together with a controller that serves to
guide the reasoning process in response to user inputs. Logics are generic,
whereas controllers are application-specific. Every controller does,
nonetheless, provide an algorithm for nonmonotonic belief revision. The general
notion of a DRS comprises a framework within which one can formulate the logic
and algorithms for a given application and prove that the algorithms are
correct, i.e., that they serve to (i) derive all salient information and (ii)
preserve the consistency of the belief set. This paper illustrates the idea
with ordinary first-order predicate calculus, suitably modified for the present
purpose, and two examples. The latter example revisits some classic
nonmonotonic reasoning puzzles (Opus the Penguin, Nixon Diamond) and shows how
these can be resolved in the context of a DRS, using an expanded version of
first-order logic that incorporates typed predicate symbols. All concepts are
rigorously defined and effectively computable, thereby providing the foundation
for a future software implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5380</identifier>
 <datestamp>2014-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5380</id><created>2013-08-25</created><updated>2014-04-10</updated><authors><author><keyname>Xu</keyname><forenames>Qi</forenames></author><author><keyname>Mao</keyname><forenames>Baohua</forenames></author><author><keyname>Feng</keyname><forenames>Xujie</forenames></author><author><keyname>Feng</keyname><forenames>Jia</forenames></author></authors><title>Effects of Crowding Perception on Self-organized Pedestrian Flows Using
  Adaptive Agent-based Model</title><categories>cs.MA</categories><comments>This paper has been withdrawn by the author due to a crucial citation
  error in the sentence 11 in the second paragraph of Section 2.1 on page 8. In
  fact, the referred paper published by PNAS, the circle of radius is r=m/320,
  available at http://www.pnas.org/content/108/17/6884.full. However, our
  manuscript published in arXiv.org, the circle of radius is r=m/160</comments><acm-class>I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pedestrian behavior has much more complicated characteristics in a dense
crowd and thus attracts the widespread interest of scientists and engineers.
However, even successful modeling approaches such as pedestrian models based on
particle systems are still not fully considered the perceptive mechanism
underlying collective pedestrian behavior. This paper extends a behavioral
heuristics-based pedestrian model to an adaptive agent-based model, which
explicitly considers the crowding effect of neighboring individuals and
perception anisotropy on the representation of a pedestrians visual
information. The adaptive agents with crowding perception are constructed to
investigate complex, selforganized collective dynamics of pedestrian motion.
The proposed model simulates selforganized pedestrian flows in good
quantitative agreement with empirical data. The selforganized phenomena include
lane formation in bidirectional flow and fundamental diagrams of unidirectional
flow. Simulation results show that the emergence of lane formation in
bidirectional flow can be well reproduced. To investigate this further,
increasing view distance has a significant effect on reducing the number of
lanes, increasing lane width, and stabilizing the self-organized lanes. The
paper also discusses phase transitions of fundamental diagrams of pedestrian
crowds with unidirectional flow. It is found that the heterogeneity of how
pedestrians perceive crowding in the population has a remarkable impact on the
flow quality, which results in the buildup of congestion and rapidly decreases
the efficiency of pedestrian flows. It also indicates that the concept of
heterogeneity may be used to explain the instability of phase transitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5395</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5395</id><created>2013-08-25</created><authors><author><keyname>Allen</keyname><forenames>Robert B.</forenames></author></authors><title>Toward an Interactive Directory for Norfolk, Nebraska: 1899-1900</title><categories>cs.DL</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We describe steps toward an interactive directory for the town of Norfolk,
Nebraska for the years 1899 and 1900. This directory would extend the
traditional city directory by including a wider range of entities being
described, much richer information about the entities mentioned and linkages to
mentions of the entities in material such as digitized historical newspapers.
Such a directory would be useful to readers who browse the historical
newspapers by providing structured summaries of the entities mentioned. We
describe the occurrence of entities in two years of the Norfolk Weekly News,
focusing on several individuals to better understand the types of information
which can be gleaned from historical newspapers and other historical materials.
We also describe a prototype program which coordinates information about
entities from the traditional city directories, the federal census, and from
newspapers. We discuss the structured coding for these entities, noting that
richer coding would increasingly include descriptions of events and scenarios.
We propose that rich content about individuals and communities could eventually
be modeled with agents and woven into historical narratives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5397</identifier>
 <datestamp>2014-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5397</id><created>2013-08-25</created><authors><author><keyname>Farmer</keyname><forenames>Luke</forenames></author><author><keyname>Kim</keyname><forenames>Kyeong Soo</forenames></author></authors><title>Cooperative ISP Traffic Shaping Schemes in Broadband Shared Access
  Networks</title><categories>cs.NI</categories><comments>5 pages, 2 figures; accepted for presentation at FOAN 2013, Jul. 19,
  2013</comments><doi>10.1109/FOAN.2013.6648820</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic shaping is a mechanism used by Internet Service Providers (ISPs) to
limit subscribers' traffic based on their service contracts. This paper
investigates the current implementation of traffic shaping based on the token
bucket filter (TBF), discusses its advantages and disadvantages, and proposes a
cooperative TBF that can improve subscribers' quality of service (QoS)/quality
of experience (QoE) without compromising business aspects of the service
contract model by proportionally allocating excess bandwidth from inactive
subscribers to active ones based on the long-term bandwidths per their service
contracts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5409</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5409</id><created>2013-08-25</created><authors><author><keyname>Fiore</keyname><forenames>Marcelo</forenames></author><author><keyname>Mahmoud</keyname><forenames>Ola</forenames></author></authors><title>Second-Order Algebraic Theories</title><categories>cs.LO math.CT</categories><journal-ref>In Lecture Notes in Computer In Proceedings of the 35th
  International Symposium on Mathematical Foundations of Computer Science (MFCS
  2010), LNCS 6281, pp. 368-380, Springer Verlag, May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fiore and Hur recently introduced a conservative extension of universal
algebra and equational logic from first to second order. Second-order universal
algebra and second-order equational logic respectively provide a model theory
and a formal deductive system for languages with variable binding and
parameterised metavariables. This work completes the foundations of the subject
from the viewpoint of categorical algebra. Specifically, the paper introduces
the notion of second-order algebraic theory and develops its basic theory. Two
categorical equivalences are established: at the syntactic level, that of
second-order equational presentations and second-order algebraic theories; at
the semantic level, that of second-order algebras and second-order functorial
models. Our development includes a mathematical definition of syntactic
translation between second-order equational presentations. This gives the first
formalisation of notions such as encodings and transforms in the context of
languages with variable binding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5421</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5421</id><created>2013-08-25</created><authors><author><keyname>Ulltveit-Moe</keyname><forenames>Nils</forenames></author><author><keyname>Oleshchuk</keyname><forenames>Vladimir</forenames></author></authors><title>Measuring Privacy Leakage for IDS Rules</title><categories>cs.CR cs.IT math.IT</categories><comments>22 pages, 16 figures</comments><acm-class>D.2.8; D.4.6; K.6.5; K.4.1; H.1.1; I.5.3; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a measurement approach for estimating the privacy leakage
from Intrusion Detection System (IDS) alarms. Quantitative information flow
analysis is used to build a theoretical model of privacy leakage from IDS
rules, based on information entropy. This theoretical model is subsequently
verified empirically both based on simulations and in an experimental study.
The analysis shows that the metric is able to distinguish between IDS rules
that have no or low expected privacy leakage and IDS rules with a significant
risk of leaking sensitive information, for example on user behaviour. The
analysis is based on measurements of number of IDS alarms, data length and data
entropy for relevant parts of IDS rules (for example payload). This is a
promising approach that opens up for privacy benchmarking of Managed Security
Service providers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5423</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5423</id><created>2013-08-25</created><authors><author><keyname>Thangarasu</keyname><forenames>M.</forenames></author><author><keyname>Manavalan</keyname><forenames>R.</forenames></author></authors><title>A Literature Review: Stemming Algorithms for Indian Languages</title><categories>cs.CL</categories><journal-ref>International Journal of Computer Trends and Technology, Vol 4, No
  8, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stemming is the process of extracting root word from the given inflection
word. It also plays significant role in numerous application of Natural
Language Processing (NLP). The stemming problem has addressed in many contexts
and by researchers in many disciplines. This expository paper presents survey
of some of the latest developments on stemming algorithms in data mining and
also presents with some of the solutions for various Indian language stemming
algorithms along with the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5434</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5434</id><created>2013-08-25</created><authors><author><keyname>Geng</keyname><forenames>Chunhua</forenames></author><author><keyname>Sun</keyname><forenames>Hua</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Multilevel Topological Interference Management</title><categories>cs.IT math.IT</categories><comments>To be presented at 2013 IEEE Information Theory Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The robust principles of treating interference as noise (TIN) when it is
sufficiently weak, and avoiding it when it is not, form the background for this
work. Combining TIN with the topological interference management (TIM)
framework that identifies optimal interference avoidance schemes, a baseline
TIM-TIN approach is proposed which decomposes a network into TIN and TIM
components, allocates the signal power levels to each user in the TIN
component, allocates signal vector space dimensions to each user in the TIM
component, and guarantees that the product of the two is an achievable number
of signal dimensions available to each user in the original network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5444</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5444</id><created>2013-08-25</created><authors><author><keyname>Niazadeh</keyname><forenames>Rad</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert D.</forenames></author></authors><title>A Unified Approach to Online Allocation Algorithms via Randomized Dual
  Fitting</title><categories>cs.DS</categories><comments>22 pages, submitted to WINE'13:The 9th Conference on Web and Internet
  Economics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a unified framework for designing and analyzing algorithms for
online budgeted allocation problems (including online matching) and their
generalization, the Online Generalized Assignment Problem (OnGAP). These
problems have been intensively studied as models of how to allocate impressions
for online advertising. In contrast to previous analyses of online budgeted
allocation algorithms (the so-called &quot;balance&quot; or &quot;water-filling&quot; family of
algorithms) our analysis is based on the method of randomized dual fitting,
analogous to the recent analysis of the RANKING algorithm for online matching
due to Devanur et al. Our main contribution is thus to provide a unified method
of proof that simultaneously derives the optimal competitive ratio bounds for
online matching and online fractional budgeted allocation. The same method of
proof also supplies $(1-1/e)$ competitive ratio bounds for greedy algorithms
for both problems, in the random order arrival model; this simplifies existing
analyses of greedy online allocation algorithms with random order of arrivals,
while also strengthening them to apply to a larger family of greedy algorithms.
Finally, for the more general OnGAP problem, we show that no algorithm can be
constant-competitive; instead we present an algorithm whose competitive ratio
depends logarithmically on a certain parameter of the problem instance, and we
show that this dependence cannot be improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5447</identifier>
 <datestamp>2013-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5447</id><created>2013-08-25</created><updated>2013-10-09</updated><authors><author><keyname>Ohlsson</keyname><forenames>Henrik</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>On Conditions for Uniqueness in Sparse Phase Retrieval</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The phase retrieval problem has a long history and is an important problem in
many areas of optics. Theoretical understanding of phase retrieval is still
limited and fundamental questions such as uniqueness and stability of the
recovered solution are not yet fully understood. This paper provides several
additions to the theoretical understanding of sparse phase retrieval. In
particular we show that if the measurement ensemble can be chosen freely, as
few as 4k-1 phaseless measurements suffice to guarantee uniqueness of a
k-sparse M-dimensional real solution. We also prove that 2(k^2-k+1) Fourier
magnitude measurements are sufficient under rather general conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5465</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5465</id><created>2013-08-25</created><authors><author><keyname>Balan</keyname><forenames>Radu</forenames></author></authors><title>Stability of Phase Retrievable Frames</title><categories>math.FA cs.CV stat.ML</categories><comments>13 pages, presented at SPIE 2013 conference</comments><msc-class>15A29, 65H10, 90C26</msc-class><doi>10.1117/12.2026135</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the property of phase retrievability by redundant
sysems of vectors under perturbations of the frame set. Specifically we show
that if a set $\fc$ of $m$ vectors in the complex Hilbert space of dimension n
allows for vector reconstruction from magnitudes of its coefficients, then
there is a perturbation bound $\rho$ so that any frame set within $\rho$ from
$\fc$ has the same property. In particular this proves the recent construction
in \cite{BH13} is stable under perturbations. By the same token we reduce the
critical cardinality conjectured in \cite{BCMN13a} to proving a stability
result for non phase-retrievable frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5470</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5470</id><created>2013-08-25</created><authors><author><keyname>Mukherjee</keyname><forenames>Satyam</forenames></author></authors><title>Ashes 2013 - A network theory analysis of Cricket strategies</title><categories>physics.soc-ph cs.SI physics.pop-ph</categories><comments>8 pages, 1 Figure, 1 Table. arXiv admin note: substantial text
  overlap with arXiv:1206.4835</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate in this paper the use of tools of complex network theory to
describe the strategy of Australia and England in the recently concluded Ashes
2013 Test series. Using partnership data made available by cricinfo during the
Ashes 2013 Test series, we generate batting partnership network (BPN) for each
team, in which nodes correspond to batsmen and links represent runs scored in
partnerships between batsmen. The resulting network display a visual summary of
the pattern of run-scoring by each team, which helps us in identifying
potential weakness in a batting order. We use different centrality scores to
quantify the performance, relative importance and effect of removing a player
from the team. We observe that England is an extremely well connected team, in
which lower order batsmen consistently contributed significantly to the team
score. Contrary to this Australia showed dependence on their top order batsmen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5480</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5480</id><created>2013-08-25</created><updated>2013-09-10</updated><authors><author><keyname>Leistedt</keyname><forenames>Boris</forenames></author><author><keyname>Peiris</keyname><forenames>Hiranya V.</forenames></author><author><keyname>McEwen</keyname><forenames>Jason D.</forenames></author></authors><title>Flaglets for studying the large-scale structure of the Universe</title><categories>cs.IT astro-ph.CO astro-ph.IM math.IT</categories><comments>Proceedings of Wavelets and Sparsity XV, SPIE Optics and Photonics
  2013</comments><journal-ref>Proc. SPIE 8858, Wavelets and Sparsity XV, 88580J (2013)</journal-ref><doi>10.1117/12.2022869</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pressing questions in cosmology such as the nature of dark matter and dark
energy can be addressed using large galaxy surveys, which measure the
positions, properties and redshifts of galaxies in order to map the large-scale
structure of the Universe. We review the Fourier-Laguerre transform, a novel
transform in 3D spherical coordinates which is based on spherical harmonics
combined with damped Laguerre polynomials and appropriate for analysing galaxy
surveys. We also recall the construction of flaglets, 3D wavelets obtained
through a tiling of the Fourier-Laguerre space, which can be used to extract
scale-dependent, spatially localised features on the ball. We exploit a
sampling theorem to obtain exact Fourier-Laguerre and flaglet transforms, such
that band-limited signals can analysed and reconstructed at floating point
accuracy on a finite number of voxels on the ball. We present a potential
application of the flaglet transform for finding voids in galaxy surveys and
studying the large-scale structure of the Universe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5499</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5499</id><created>2013-08-26</created><authors><author><keyname>Winter</keyname><forenames>Bodo</forenames></author></authors><title>Linear models and linear mixed effects models in R with linguistic
  applications</title><categories>cs.CL</categories><comments>42 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This text is a conceptual introduction to mixed effects modeling with
linguistic applications, using the R programming environment. The reader is
introduced to linear modeling and assumptions, as well as to mixed
effects/multilevel modeling, including a discussion of random intercepts,
random slopes and likelihood ratio tests. The example used throughout the text
focuses on the phonetic analysis of voice pitch data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5506</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5506</id><created>2013-08-26</created><authors><author><keyname>Fouch&#xe9;</keyname><forenames>Willem L.</forenames></author></authors><title>Algorithmic randomness and Ramsey properties of countable homogeneous
  structures</title><categories>cs.CC</categories><comments>arXiv admin note: substantial text overlap with arXiv:1205.0386</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study, in the context of algorithmic randomness, the closed amenable
subgroups of the symmetric group $S_\infty$ of a countable set. In this paper
we address this problem by investigating a link between the symmetries
associated with Ramsey Fra\&quot;iss\'e order classes and algorithmic randomness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5513</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5513</id><created>2013-08-26</created><updated>2013-08-28</updated><authors><author><keyname>Wu</keyname><forenames>Lingfei</forenames></author><author><keyname>Zhang</keyname><forenames>Jiang</forenames></author><author><keyname>Zhao</keyname><forenames>Min</forenames></author></authors><title>The Metabolism and Growth of Web Forums</title><categories>physics.soc-ph cs.CY cs.SI</categories><comments>6 figures</comments><doi>10.1371/journal.pone.0102646</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We view web forums as virtual living organisms feeding on user's attention
and investigate how these organisms grow at the expense of collective
attention. We find that the &quot;body mass&quot; ($PV$) and &quot;energy consumption&quot; ($UV$)
of the studied forums exhibits the allometric growth property, i.e., $PV_t \sim
UV_t ^ \theta$. This implies that within a forum, the network transporting
attention flow between threads has a structure invariant of time, despite of
the continuously changing of the nodes (threads) and edges (clickstreams). The
observed time-invariant topology allows us to explain the dynamics of networks
by the behavior of threads. In particular, we describe the clickstream
dissipation on threads using the function $D_i \sim T_i ^ \gamma$, in which
$T_i$ is the clickstreams to node $i$ and $D_i$ is the clickstream dissipated
from $i$. It turns out that $\gamma$, an indicator for dissipation efficiency,
is negatively correlated with $\theta$ and $1/\gamma$ sets the lower boundary
for $\theta$. Our findings have practical consequences. For example, $\theta$
can be used as a measure of the &quot;stickiness&quot; of forums, because it quantifies
the stable ability of forums to convert $UV$ into $PV$, i.e., to remain users
&quot;lock-in&quot; the forum. Meanwhile, the correlation between $\gamma$ and $\theta$
provides a convenient method to evaluate the `stickiness&quot; of forums. Finally,
we discuss an optimized &quot;body mass&quot; of forums at around $10^5$ that minimizes
$\gamma$ and maximizes $\theta$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5546</identifier>
 <datestamp>2013-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5546</id><created>2013-08-26</created><authors><author><keyname>Rapin</keyname><forenames>J&#xe9;r&#xe9;my</forenames></author><author><keyname>Bobin</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Larue</keyname><forenames>Anthony</forenames></author><author><keyname>Starck</keyname><forenames>Jean-Luc</forenames></author></authors><title>Sparse and Non-Negative BSS for Noisy Data</title><categories>stat.ML cs.LG</categories><comments>13 pages, 18 figures, to be published in IEEE Transactions on Signal
  Processing</comments><msc-class>94A12</msc-class><acm-class>I.5.4</acm-class><journal-ref>IEEE Trans. Signal Process. 61 (2013) 5620-5632</journal-ref><doi>10.1109/TSP.2013.2279358</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-negative blind source separation (BSS) has raised interest in various
fields of research, as testified by the wide literature on the topic of
non-negative matrix factorization (NMF). In this context, it is fundamental
that the sources to be estimated present some diversity in order to be
efficiently retrieved. Sparsity is known to enhance such contrast between the
sources while producing very robust approaches, especially to noise. In this
paper we introduce a new algorithm in order to tackle the blind separation of
non-negative sparse sources from noisy measurements. We first show that
sparsity and non-negativity constraints have to be carefully applied on the
sought-after solution. In fact, improperly constrained solutions are unlikely
to be stable and are therefore sub-optimal. The proposed algorithm, named nGMCA
(non-negative Generalized Morphological Component Analysis), makes use of
proximal calculus techniques to provide properly constrained solutions. The
performance of nGMCA compared to other state-of-the-art algorithms is
demonstrated by numerical experiments encompassing a wide variety of settings,
with negligible parameter tuning. In particular, nGMCA is shown to provide
robustness to noise and performs well on synthetic mixtures of real NMR
spectra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5550</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5550</id><created>2013-08-26</created><authors><author><keyname>Aloupis</keyname><forenames>Greg</forenames></author><author><keyname>P&#xe9;rez-Ros&#xe9;s</keyname><forenames>Hebert</forenames></author><author><keyname>Pineda-Villavicencio</keyname><forenames>Guillermo</forenames></author><author><keyname>Taslakian</keyname><forenames>Perouz</forenames></author><author><keyname>Trinchet</keyname><forenames>Dannier</forenames></author></authors><title>Fitting Voronoi Diagrams to Planar Tesselations</title><categories>cs.CG</categories><comments>14 pages, 8 figures, 1 table. Presented at IWOCA 2013 (Int. Workshop
  on Combinatorial Algorithms), Rouen, France, July 2013</comments><msc-class>52C45, 65D18, 68U05</msc-class><acm-class>F.2.2; F.2.m</acm-class><journal-ref>Proceedings of IWOCA 2013, Lecture Notes in Computer Science,
  Springer Verlag</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a tesselation of the plane, defined by a planar straight-line graph
$G$, we want to find a minimal set $S$ of points in the plane, such that the
Voronoi diagram associated with $S$ &quot;fits&quot; \ $G$. This is the Generalized
Inverse Voronoi Problem (GIVP), defined in \cite{Trin07} and rediscovered
recently in \cite{Baner12}. Here we give an algorithm that solves this problem
with a number of points that is linear in the size of $G$, assuming that the
smallest angle in $G$ is constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5571</identifier>
 <datestamp>2013-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5571</id><created>2013-08-26</created><updated>2013-11-26</updated><authors><author><keyname>Tutgun</keyname><forenames>Rasit</forenames></author><author><keyname>Aktas</keyname><forenames>Emre</forenames></author></authors><title>Cooperative Network Coded ARQ Strategies for Two Way Relay Channel</title><categories>cs.IT math.IT</categories><comments>27 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, novel cooperative automatic repeat request (ARQ) methods with
network coding are proposed for two way relaying network. Upon a failed
transmission of a packet, the network enters cooperation phase, where the
retransmission of the packets is aided by the relay node. The proposed approach
integrates network coding into cooperative ARQ, aiming to improve the network
throughput by reducing the number of retransmissions. For successive
retransmission, three different methods for choosing the retransmitting node
are considered. The throughput of the methods are analyzed and compared. The
analysis is based on binary Markov channel which takes the correlation of the
channel coefficients in time into account. Analytical results show that the
proposed use of network coding result in throughput performance superior to
traditional ARQ and cooperative ARQ without network coding. It is also observed
that correlation can have significant effect on the performance of the proposed
cooperative network coded ARQ approach. In particular the proposed approach is
advantageous for slow to moderately fast fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5576</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5576</id><created>2013-08-26</created><authors><author><keyname>Palmieri</keyname><forenames>Francesco A. N.</forenames></author></authors><title>A Comparison of Algorithms for Learning Hidden Variables in Normal
  Graphs</title><categories>stat.ML cs.IT cs.SY math.IT</categories><comments>Submitted for journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Bayesian factor graph reduced to normal form consists in the
interconnection of diverter units (or equal constraint units) and
Single-Input/Single-Output (SISO) blocks. In this framework localized
adaptation rules are explicitly derived from a constrained maximum likelihood
(ML) formulation and from a minimum KL-divergence criterion using KKT
conditions. The learning algorithms are compared with two other updating
equations based on a Viterbi-like and on a variational approximation
respectively. The performance of the various algorithm is verified on synthetic
data sets for various architectures. The objective of this paper is to provide
the programmer with explicit algorithms for rapid deployment of Bayesian graphs
in the applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5585</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5585</id><created>2013-08-26</created><authors><author><keyname>Cautis</keyname><forenames>Bogdan</forenames></author><author><keyname>Deutsch</keyname><forenames>Alin</forenames></author><author><keyname>Ileana</keyname><forenames>Ioana</forenames></author><author><keyname>Onose</keyname><forenames>Nicola</forenames></author></authors><title>Rewriting XPath Queries using View Intersections: Tractability versus
  Completeness</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard approach for optimization of XPath queries by rewriting using
views techniques consists in navigating inside a view's output, thus allowing
the usage of only one view in the rewritten query. Algorithms for richer
classes of XPath rewritings, using intersection or joins on node identifiers,
have been proposed, but they either lack completeness guarantees, or require
additional information about the data. We identify the tightest restrictions
under which an XPath can be rewritten in polynomial time using an intersection
of views and propose an algorithm that works for any documents or type of
identifiers. As a side-effect, we analyze the complexity of the related problem
of deciding if an XPath with intersection can be equivalently rewritten as one
without intersection or union. We extend our formal study of the view-based
rewriting problem for XPath by describing also (i) algorithms for more complex
rewrite plans, with no limitations on the number of intersection and navigation
steps inside view outputs they employ, and (ii) adaptations of our techniques
to deal with XML documents without persistent node Ids, in the presence of XML
keys. Complementing our computational complexity study, we describe a
proof-of-concept implementation of our techniques and possible choices that may
speed up execution in practice, regarding how rewrite plans are built, tested
and executed. We also give a thorough experimental evaluation of these
techniques, focusing on scalability and the running time improvements achieved
by the execution of view-based plans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5586</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5586</id><created>2013-08-26</created><authors><author><keyname>Diekert</keyname><forenames>Volker</forenames></author><author><keyname>Kharlampovich</keyname><forenames>Olga</forenames></author><author><keyname>Moghaddam</keyname><forenames>Atefeh Mohajeri</forenames></author></authors><title>SLP compression for solutions of equations with constraints in free and
  hyperbolic groups</title><categories>math.GR cs.DM cs.LO</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is a part of an ongoing program which aims to show that the
existential theory in free groups (hyperbolic groups or even toral relatively
hyperbolic) is NP-complete. For that we study compression of solutions with
straight-line programs (SLPs) as suggested originally by Plandowski and Rytter
in the context of a single word equation. We review some basic results on SLPs
and give full proofs in order to keep this fundamental part of the program
self-contained. Next we study systems of equations with constraints in free
groups and more generally in free products of abelian groups. We show how to
compress minimal solutions with extended Parikh-constraints. This type of
constraints allows to express semi linear conditions as e.g. alphabetic
information. The result relies on some combinatorial analysis and has not been
shown elsewhere. We show similar compression results for Boolean formula of
equations over a torsion-free $\delta$-hyperbolic group. The situation is much
more delicate than in free groups. As byproduct we improve the estimation of
the &quot;capacity&quot; constant used by Rips and Sela in their paper &quot;Canonical
representatives and equations in hyperbolic groups&quot; from a double-exponential
bound in $\delta$ to some single-exponential bound. The final section shows
compression results for toral relatively hyperbolic group using the work of
Dahmani: We show that given a system of equations over a fixed toral relatively
hyperbolic group, for every solution of length $N$ there is an SLP for another
solution such that the size of the SLP is bounded by some polynomial $p(s+ \log
N)$ where $s$ is the size of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5597</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5597</id><created>2013-08-26</created><authors><author><keyname>Niazadeh</keyname><forenames>Rad</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Masoud</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>Sparse Channel Estimation by Factor Graphs</title><categories>cs.IT cs.SY math.IT</categories><comments>23 pages, 7 figure, submitted to Elsevier Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of estimating a sparse channel, i.e. a channel with a few
non-zero taps, appears in various areas of communications. Recently, we have
developed an algorithm based on iterative alternating minimization which
iteratively detects the location and the value of the taps. This algorithms
involves an approximate Maximum A Posteriori (MAP) probability scheme for
detection of the location of taps, while a least square method is used for
estimating the values at each iteration. In this work, based on the method of
factor graphs and message passing algorithms, we will compute an exact solution
for the MAP estimation problem. Indeed, we first find a factor graph model of
this problem, and then perform the well-known min-sum algorithm on the edges of
this graph. Consequently, we will find an exact estimator for the MAP problem
that its complexity grows linearly with respect to the channel memory. By
substituting this estimator in the mentioned alternating minimization method,
we will propose an estimator that will nearly achieve the Cramer-Rao bound of
the genie-aided estimation of sparse channels (estimation based on knowing the
location of non-zero taps of the channel), while it can perform faster than
most of the proposed algorithms in literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5608</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5608</id><created>2013-08-26</created><updated>2013-10-15</updated><authors><author><keyname>Wang</keyname><forenames>Zi Chao</forenames><affiliation>Charles University in Prague</affiliation></author></authors><title>Implicit Resolution</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 4 (October
  16, 2013) lmcs:1125</journal-ref><doi>10.2168/LMCS-9(4:7)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let \Omega be a set of unsatisfiable clauses, an implicit resolution
refutation of \Omega is a circuit \beta with a resolution proof {\alpha} of the
statement &quot;\beta describes a correct tree-like resolution refutation of
\Omega&quot;. We show that such system is p-equivalent to Extended Frege. More
generally, let {\tau} be a tautology, a [P, Q]-proof of {\tau} is a pair
(\alpha,\beta) s.t. \alpha is a P-proof of the statement &quot;\beta is a circuit
describing a correct Q-proof of \tau&quot;. We prove that [EF,P] \leq p [R,P] for
arbitrary Cook-Reckhow proof system P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5620</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5620</id><created>2013-08-26</created><authors><author><keyname>Sheffer</keyname><forenames>Adam</forenames></author><author><keyname>Zahl</keyname><forenames>Joshua</forenames></author><author><keyname>de Zeeuw</keyname><forenames>Frank</forenames></author></authors><title>Few distinct distances implies no heavy lines or circles</title><categories>math.CO cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the structure of planar point sets that determine a small number of
distinct distances. Specifically, we show that if a set P of n points
determines o(n) distinct distances, then no line contains \Omega(n^{7/8})
points of P and no circle contains \Omega(n^{5/6}) points of P.
  We rely on the bipartite and partial variant of the Elekes-Sharir framework
that was presented by Sharir, Sheffer, and Solymosi in \cite{SSS13}. For the
case of lines we combine this framework with a theorem from additive
combinatorics, and for the case of circles we combine it with some basic
algebraic geometry and a recent incidence bound for plane algebraic curves by
Wang, Yang, and Zhang \cite{WYZ13}. A significant difference between our
approach and that of \cite{SSS13} (and other recent extensions) is that,
instead of dealing with distances between two point sets that are restricted to
one-dimensional curves, we consider distances between one set that is
restricted to a curve and one set with no restrictions on it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5625</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5625</id><created>2013-08-26</created><authors><author><keyname>Ammari</keyname><forenames>Habib</forenames></author><author><keyname>Tran</keyname><forenames>Minh Phuong</forenames></author><author><keyname>Wang</keyname><forenames>Han</forenames></author></authors><title>Shape identification and classification in echolocation</title><categories>cs.NA</categories><msc-class>35R30, 35B30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper aims at proposing the first shape identification and classification
algorithm in echolocation. The approach is based on first extracting geometric
features from the reflected waves and then matching them with precomputed ones
associated with a dictionary of targets. The construction of such
frequency-dependent shape descriptors is based on some important properties of
the scattering coefficients and new invariants. The stability and resolution of
the proposed identification algorithm with respect to measurement noise and the
limited-view aspect are analytically and numerically quantified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5626</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5626</id><created>2013-08-26</created><authors><author><keyname>Ghasemi</keyname><forenames>A.</forenames></author><author><keyname>Taylor</keyname><forenames>L. K.</forenames></author></authors><title>A Progressive Statistical Method for Preconditioning Matrix-Free
  Solution of High-Order Discretization of Linear Time-Dependent Problems</title><categories>math.ST cs.NA math.NA stat.TH</categories><report-no>UTC-CECS-SimCenter-2013-02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preconditioning of a linear system obtained from spectral discretization of
time-dependent PDEs often results in a full matrix which is expensive to
compute and store specially when the problem size increases. A matrix-free
implementation is usually applied to resolve this issue. In this framework,
preconditioning is typically challenging since the entries of the matrix are
not explicitly available. In this short note, we propose a statistical approach
to gradually create a preconditioner matrix by collecting the information
obtained from matrix-vector product in the Arnoldi loop of an unpreconditioned
Krylov subspace algorithm. The gathered information are then correlated using a
multiple regressors estimate where the error is assumed to be normally
distributed. This procedure yields a banded diagonal matrix which is then used
as a preconditioner in the next iterative solve. This is repeated between
iterative solves until a good preconditioner is constructed on fly. This
statistically iterative procedure is progressive since the fidelity of the
preconditioning matrix improves by adding more data obtained from matrix-vector
product during the entire solution procedure. The proposed algorithm is
validated for a sample implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5661</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5661</id><created>2013-08-26</created><authors><author><keyname>Wandji</keyname><forenames>Nathalie Diane</forenames></author><author><keyname>Xingming</keyname><forenames>Sun</forenames></author><author><keyname>Kue</keyname><forenames>Moise Fah</forenames></author></authors><title>Detection of copy-move forgery in digital images based on DCT</title><categories>cs.CV cs.CR</categories><comments>Published in IJCSI (International Journal of Computer Science
  Issues), Volume 10, Issue 2, No 1, March 2013</comments><journal-ref>ISSN (Print): 1694-0814 | ISSN (Online): 1694-0784, International
  Journal of Computer Science Issues (IJCSI), Volume 10, Issue 2, No 1, March
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With rapid advances in digital information processing systems, and more
specifically in digital image processing software, there is a widespread
development of advanced tools and techniques for digital image forgery. One of
the techniques most commonly used is the Copy-move forgery which proceeds by
copying a part of an image and pasting it into the same image, in order to
maliciously hide an object or a region. In this paper, we propose a method to
detect this specific kind of counterfeit. Firstly, the color image is converted
from RGB color space to YCbCr color space and then the R, G, B and Y-component
are splitted into fixed-size overlapping blocks and, features are extracted
from the R, G and B-components image blocks on one hand and on the other, from
the DCT representation of the R, G, B and Ycomponent image block. The feature
vectors obtained are then lexicographically sorted to make similar image blocks
neighbors and duplicated image blocks are identified using Euclidean distance
as similarity criterion. Experimental results showed that the proposed method
can detect the duplicated regions when there is more than one copy move forged
area in the image and even in case of slight rotations, JPEG compression,
shift, scale, blur and noise addition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5673</identifier>
 <datestamp>2014-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5673</id><created>2013-08-25</created><updated>2013-10-09</updated><authors><author><keyname>Pan</keyname><forenames>J. -S.</forenames></author><author><keyname>Zou</keyname><forenames>X. -B.</forenames></author><author><keyname>Zhou</keyname><forenames>Z. -Y.</forenames></author><author><keyname>Ding</keyname><forenames>D. -S.</forenames></author><author><keyname>Shi</keyname><forenames>B. -S.</forenames></author><author><keyname>Guo</keyname><forenames>G. -C.</forenames></author></authors><title>Nonlocal linear compression of two-photon time interval distribution</title><categories>quant-ph cs.IT math.IT</categories><comments>4 pages, 8 figures</comments><journal-ref>Phys. Rev. A 88, 061802 (2013)</journal-ref><doi>10.1103/PhysRevA.88.061802</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a linear compression technique for the time interval distribution
of photon pairs. Using a partially frequency-entangled two-photon (TP) state
with appropriate mean time width, the compressed TP time interval width can be
kept in the minimum limit set by the phase modulation, and is independent of
its initial width. As a result of this effect, ultra-narrow TP time interval
distribution can be compressed with relatively slow phase modulators to
decrease the damage of the phase-instability arising from the phase modulation
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5678</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5678</id><created>2013-08-26</created><authors><author><keyname>Ossada</keyname><forenames>Raul</forenames></author><author><keyname>Grisi-Filho</keyname><forenames>Jos&#xe9; H. H.</forenames></author><author><keyname>Ferreira</keyname><forenames>Fernando</forenames></author><author><keyname>Amaku</keyname><forenames>Marcos</forenames></author></authors><title>Modeling the Dynamics of Infectious Diseases in Different Scale-Free
  Networks with the Same Degree Distribution</title><categories>q-bio.PE cs.SI physics.soc-ph</categories><comments>13 pages, 7 figures</comments><journal-ref>Advanced Studies in Theoretical Physics, Vol. 7, 2013, no. 16, 759
  - 771</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The transmission dynamics of some infectious diseases is related to the
contact structure between individuals in a network. We used five algorithms to
generate contact networks with different topological structure but with the
same scale-free degree distribution. We simulated the spread of acute and
chronic infectious diseases on these networks, using SI (Susceptible -
Infected) and SIS (Susceptible - Infected - Susceptible) epidemic models. In
the simulations, our objective was to observe the effects of the topological
structure of the networks on the dynamics and prevalence of the simulated
diseases. We found that the dynamics of spread of an infectious disease on
different networks with the same degree distribution may be considerably
different.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5697</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5697</id><created>2013-08-26</created><authors><author><keyname>Witten</keyname><forenames>Rafi</forenames></author><author><keyname>Candes</keyname><forenames>Emmanuel</forenames></author></authors><title>Randomized algorithms for low-rank matrix factorizations: sharp
  performance bounds</title><categories>cs.NA stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of randomized algorithms for numerical linear algebra, e.g.
for computing approximate QR and SVD factorizations, has recently become an
intense area of research. This paper studies one of the most frequently
discussed algorithms in the literature for dimensionality
reduction---specifically for approximating an input matrix with a low-rank
element. We introduce a novel and rather intuitive analysis of the algorithm in
Martinsson et al. (2008), which allows us to derive sharp estimates and give
new insights about its performance. This analysis yields theoretical guarantees
about the approximation error and at the same time, ultimate limits of
performance (lower bounds) showing that our upper bounds are tight. Numerical
experiments complement our study and show the tightness of our predictions
compared with empirical observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5703</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5703</id><created>2013-08-26</created><updated>2014-03-04</updated><authors><author><keyname>Arenas</keyname><forenames>Marcelo</forenames></author><author><keyname>Diaz</keyname><forenames>Gonzalo I.</forenames></author><author><keyname>Fokoue</keyname><forenames>Achille</forenames></author><author><keyname>Kementsietsidis</keyname><forenames>Anastasios</forenames></author><author><keyname>Srinivas</keyname><forenames>Kavitha</forenames></author></authors><title>A Principled Approach to Bridging the Gap between Graph Data and their
  Schemas</title><categories>cs.DB</categories><comments>18 pages, 8 figures. To be published in PVLDB Vol. 8, No. 9</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although RDF graphs have schema information associated with them, in practice
it is very common to find cases in which data do not fully conform to their
schema. A prominent example of this is DBpedia, which is RDF data extracted
from Wikipedia, a publicly editable source of information. In such situations,
it becomes interesting to study the structural properties of the actual data,
because the schema gives an incomplete description of the organization of a
dataset. In this paper we have approached the study of the structuredness of an
RDF graph in a principled way: we propose a framework for specifying
structuredness functions, which gauge the degree to which an RDF graph conforms
to a schema. In particular, we first define a formal language for specifying
structuredness functions with expressions we call rules. This language allows a
user or a database administrator to state a rule to which an RDF graph may
fully or partially conform. Then we consider the issue of discovering a
refinement of a sort (type) by partitioning the dataset into subsets whose
structuredness is over a specified threshold. In particular, we prove that the
natural decision problem associated to this refinement problem is NP-complete,
and we provide a natural translation of this problem into Integer Linear
Programming (ILP). Finally, we test this ILP solution with two real world
datasets, DBpedia Persons and WordNet Nouns, and 4 different and intuitive
rules, which gauge the structuredness in different ways. The rules give
meaningful refinements of the datasets, showing that our language can be a
powerful tool for understanding the structure of RDF data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5706</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5706</id><created>2013-08-26</created><authors><author><keyname>McEwen</keyname><forenames>J. D.</forenames></author><author><keyname>Vandergheynst</keyname><forenames>P.</forenames></author><author><keyname>Wiaux</keyname><forenames>Y.</forenames></author></authors><title>On the computation of directional scale-discretized wavelet transforms
  on the sphere</title><categories>cs.IT astro-ph.IM math.IT</categories><comments>13 pages, 3 figures, Proceedings of Wavelets and Sparsity XV, SPIE
  Optics and Photonics 2013, Code is publicly available at http://www.s2dw.org/</comments><journal-ref>Proc. SPIE 8858, Wavelets and Sparsity XV, 88580I (2013)</journal-ref><doi>10.1117/12.2022889</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review scale-discretized wavelets on the sphere, which are directional and
allow one to probe oriented structure in data defined on the sphere.
Furthermore, scale-discretized wavelets allow in practice the exact synthesis
of a signal from its wavelet coefficients. We present exact and efficient
algorithms to compute the scale-discretized wavelet transform of band-limited
signals on the sphere. These algorithms are implemented in the publicly
available S2DW code. We release a new version of S2DW that is parallelized and
contains additional code optimizations. Note that scale-discretized wavelets
can be viewed as a directional generalization of needlets. Finally, we outline
future improvements to the algorithms presented, which can be achieved by
exploiting a new sampling theorem on the sphere developed recently by some of
the authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5724</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5724</id><created>2013-08-26</created><authors><author><keyname>Dang</keyname><forenames>Thao</forenames></author><author><keyname>Piazza</keyname><forenames>Carla</forenames></author></authors><title>Proceedings Second International Workshop on Hybrid Systems and Biology</title><categories>cs.CE cs.LO cs.SY</categories><proxy>EPTCS</proxy><acm-class>I.6.0; I.6.1; I.6.3; I.6.4; I.6.7; I.6.8</acm-class><journal-ref>EPTCS 125, 2013</journal-ref><doi>10.4204/EPTCS.125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Second International Workshop
Hybrid Systems and Biology (HSB 2013) held in Taormina (Italy), on September
2th, 2013. The workshop is affiliated to the 12th European Conference on
Artificial Life (ECAL 2013).
  Systems biology aims at providing a system-level understanding of biological
systems by unveiling their structure, dynamics and control methods. Due to the
intrinsic multi-scale nature of these systems in space, in organization levels
and in time, it is extremely difficult to model them in a uniform way, e.g., by
means of differential equations or discrete stochastic processes. Furthermore,
such models are often not easily amenable to formal analysis, and their
simulations at the organ or even at the cell levels are frequently impractical.
Indeed, an important open problem is finding appropriate computational models
that scale well for both simulation and formal analysis of biological
processes. Hybrid modeling techniques, combining discrete and continuous
processes, are gaining more and more attention in such a context, and they have
been successfully applied to capture the behavior of many biological complex
systems, ranging from genetic networks, biochemical reactions, signaling
pathways, cardiac tissues electro-physiology, and tumor genesis. This workshop
aims at bringing together researchers in computer science, mathematics, and
life sciences, interested in the opportunities and the challenges of hybrid
modeling applied to systems biology.
  The workshop programme included the keynote presentation of Alessandro
Astolfi (Imperial College of London, UK) on Immune response enhancement via
hybrid control. Furthermore, 8 papers were selected out of 13 submissions by
the Program Committee of HSB 2013. The papers in this volume address the hybrid
modeling of a number important biological processes (iron homeostasis network,
mammalian cell cycle, vascular endothelial growth factor (VEGF), genetic
regulatory network in mammalian sclera) and, the formalisms and techniques for
specifying and validating properties of biological systems (such as,
robustness, oscillations).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5728</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5728</id><created>2013-08-26</created><authors><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>Notes on Coherent Feedback Control for Linear Quantum Systems</title><categories>quant-ph cs.SY math.OC</categories><comments>A preliminary version is to appear in the proceedings of the 2013
  Australian Control COnference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers some formulations and possible approaches to the
coherent LQG and $H^\infty$ quantum control problems. Some new results for
these problems are presented in the case of annihilation operator only quantum
systems showing that in this case, the optimal controllers are trivial
controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5737</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5737</id><created>2013-08-26</created><authors><author><keyname>Yuan</keyname><forenames>Pingzhi</forenames></author><author><keyname>Ding</keyname><forenames>Cunsheng</forenames></author></authors><title>Further Results on Permutation Polynomials over Finite Fields</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Permutation polynomials are an interesting subject of mathematics and have
applications in other areas of mathematics and engineering. In this paper, we
develop general theorems on permutation polynomials over finite fields. As a
demonstration of the theorems, we present a number of classes of explicit
permutation polynomials on $\gf_q$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5741</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5741</id><created>2013-08-26</created><authors><author><keyname>Bannister</keyname><forenames>Michael J.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Simons</keyname><forenames>Joseph A.</forenames></author></authors><title>Fixed parameter tractability of crossing minimization of almost-trees</title><categories>cs.CG cs.DS</categories><comments>Graph Drawing 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate exact crossing minimization for graphs that differ from trees
by a small number of additional edges, for several variants of the crossing
minimization problem. In particular, we provide fixed parameter tractable
algorithms for the 1-page book crossing number, the 2-page book crossing
number, and the minimum number of crossed edges in 1-page and 2-page book
drawings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5752</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5752</id><created>2013-08-27</created><authors><author><keyname>Petersen</keyname><forenames>Alexander M.</forenames></author><author><keyname>Succi</keyname><forenames>Sauro</forenames></author></authors><title>The Z-index: A geometric representation of productivity and impact which
  accounts for information in the entire rank-citation profile</title><categories>physics.soc-ph cs.DL physics.data-an</categories><comments>9 pages, 5 figures</comments><journal-ref>J. of Informetrics 7, 823-832 (2013)</journal-ref><doi>10.1016/j.joi.2013.07.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple generalization of Hirsch's h-index, Z =
\sqrt{h^{2}+C}/\sqrt{5}, where C is the total number of citations. Z is aimed
at correcting the potentially excessive penalty made by h on a scientist's
highly cited papers, because for the majority of scientists analyzed, we find
the excess citation fraction (C-h^{2})/C to be distributed closely around the
value 0.75, meaning that 75 percent of the author's impact is neglected.
Additionally, Z is less sensitive to local changes in a scientist's citation
profile, namely perturbations which increase h while only marginally affecting
C. Using real career data for 476 physicists careers and 488 biologist careers,
we analyze both the distribution of $Z$ and the rank stability of Z with
respect to the Hirsch index h and the Egghe index g. We analyze careers
distributed across a wide range of total impact, including top-cited physicists
and biologists for benchmark comparison. In practice, the Z-index requires the
same information needed to calculate h and could be effortlessly incorporated
within career profile databases, such as Google Scholar and ResearcherID.
Because Z incorporates information from the entire publication profile while
being more robust than h and g to local perturbations, we argue that Z is
better suited for ranking comparisons in academic decision-making scenarios
comprising a large number of scientists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5786</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5786</id><created>2013-08-27</created><authors><author><keyname>Tsiaflakis</keyname><forenames>Paschalis</forenames></author><author><keyname>Glineur</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Moonen</keyname><forenames>Marc</forenames></author></authors><title>Real-time dynamic spectrum management for multi-user multi-carrier
  communication systems</title><categories>cs.IT math.IT</categories><comments>14 pages, 9 figures. This work has been submitted to the IEEE for
  possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic spectrum management is recognized as a key technique to tackle
interference in multi-user multi-carrier communication systems and networks.
However existing dynamic spectrum management algorithms may not be suitable
when the available computation time and compute power are limited, i.e., when a
very fast responsiveness is required. In this paper, we present a new paradigm,
theory and algorithm for real-time dynamic spectrum management (RT-DSM) under
tight real-time constraints. Specifically, a RT-DSM algorithm can be stopped at
any point in time while guaranteeing a feasible and improved solution. This is
enabled by the introduction of a novel difference-of-variables (DoV)
transformation and problem reformulation, for which a primal coordinate ascent
approach is proposed with exact line search via a logarithmicly scaled grid
search. The concrete proposed algorithm is referred to as iterative power
difference balancing (IPDB). Simulations for different realistic wireline and
wireless interference limited systems demonstrate its good performance, low
complexity and wide applicability under different configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5788</identifier>
 <datestamp>2015-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5788</id><created>2013-08-27</created><updated>2014-09-30</updated><authors><author><keyname>Gutoski</keyname><forenames>Gus</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Milner</keyname><forenames>Kevin</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Quantum interactive proofs and the complexity of separability testing</title><categories>quant-ph cs.CC</categories><comments>v2: 43 pages, 5 figures, completely rewritten and in Theory of
  Computing (ToC) journal format</comments><journal-ref>Theory of Computing vol. 11, article 3, pages 59-103, March 2015</journal-ref><doi>10.4086/toc.2015.v011a003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify a formal connection between physical problems related to the
detection of separable (unentangled) quantum states and complexity classes in
theoretical computer science. In particular, we show that to nearly every
quantum interactive proof complexity class (including BQP, QMA, QMA(2), and
QSZK), there corresponds a natural separability testing problem that is
complete for that class. Of particular interest is the fact that the problem of
determining whether an isometry can be made to produce a separable state is
either QMA-complete or QMA(2)-complete, depending upon whether the distance
between quantum states is measured by the one-way LOCC norm or the trace norm.
We obtain strong hardness results by proving that for each n-qubit maximally
entangled state there exists a fixed one-way LOCC measurement that
distinguishes it from any separable state with error probability that decays
exponentially in n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5793</identifier>
 <datestamp>2015-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5793</id><created>2013-08-27</created><updated>2015-06-27</updated><authors><author><keyname>Pereg</keyname><forenames>Uzi</forenames></author><author><keyname>Tal</keyname><forenames>Ido</forenames></author></authors><title>Channel Upgradation for Non-Binary Input Alphabets and MACs</title><categories>cs.IT math.IT</categories><comments>18 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a single-user or multiple-access channel with a large output
alphabet. A method to approximate the channel by an upgraded version having a
smaller output alphabet is presented and analyzed. The original channel is not
necessarily symmetric and does not necessarily have a binary input alphabet.
Also, the input distribution is not necessarily uniform. The approximation
method is instrumental when constructing capacity achieving polar codes for an
asymmetric channel with a non-binary input alphabet. Other settings in which
the method is instrumental are the wiretap setting as well as the lossy source
coding setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5798</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5798</id><created>2013-08-27</created><updated>2015-06-24</updated><authors><author><keyname>Gonska</keyname><forenames>Bernd</forenames></author><author><keyname>Padrol</keyname><forenames>Arnau</forenames></author></authors><title>Neighborly inscribed polytopes and Delaunay triangulations</title><categories>math.MG cs.CG math.CO</categories><comments>15 pages, 2 figures. We extended our results to arbitrary smooth
  strictly convex bodies</comments><msc-class>52B11, 52B12, 68U05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a large family of neighborly polytopes that can be realized with
all the vertices on the boundary of any smooth strictly convex body. In
particular, we show that there are superexponentially many combinatorially
distinct neighborly polytopes that admit realizations inscribed on the sphere.
These are the first examples of inscribable neighborly polytopes that are not
cyclic polytopes, and provide the current best lower bound for the number of
combinatorial types of inscribable polytopes (which coincides with the current
best lower bound for the number of combinatorial types of polytopes). Via
stereographic projections, this translates into a superexponential lower bound
for the number of combinatorial types of (neighborly) Delaunay triangulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5807</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5807</id><created>2013-08-27</created><authors><author><keyname>Nassereddine</keyname><forenames>Tarik Mountassir Bouchaib</forenames></author><author><keyname>Haqiq</keyname><forenames>Abdelkrim</forenames></author><author><keyname>Bennani</keyname><forenames>Samir</forenames></author></authors><title>Multi-Objective Particle Swarm Optimization for Facility Location
  Problem in Wireless Mesh Networks</title><categories>cs.NI cs.NE</categories><journal-ref>International Journal of Computer Science Issues, March 2013,
  Volume 10, Number 2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless mesh networks have seen a real progress due of their implementation
at a low cost. They present one of Next Generation Networks technologies and
can serve as home, companies and universities networks. In this paper, we
propose and discuss a new multi-objective model for nodes deployment
optimization in Multi-Radio Multi-Channel Wireless Mesh Networks. We exploit
the trade-off between network cost and the overall network performance. This
optimization problem is solved simultaneously by using a meta-heuristic method
that returns a non-dominated set of near optimal solutions. A comparative study
was driven to evaluate the efficiency of the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5809</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5809</id><created>2013-08-27</created><authors><author><keyname>Tsiaflakis</keyname><forenames>Paschalis</forenames></author><author><keyname>Glineur</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Spectrum optimization in multi-user multi-carrier systems with iterative
  convex and nonconvex approximation methods</title><categories>cs.IT math.IT</categories><comments>33 pages, 7 figures. This work has been submitted for possible
  publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several practical multi-user multi-carrier communication systems are
characterized by a multi-carrier interference channel system model where the
interference is treated as noise. For these systems, spectrum optimization is a
promising means to mitigate interference. This however corresponds to a
challenging nonconvex optimization problem. Existing iterative convex
approximation (ICA) methods consist in solving a series of improving convex
approximations and are typically implemented in a per-user iterative approach.
However they do not take this typical iterative implementation into account in
their design. This paper proposes a novel class of iterative approximation
methods that focuses explicitly on the per-user iterative implementation, which
allows to relax the problem significantly, dropping joint convexity and even
convexity requirements for the approximations. A systematic design framework is
proposed to construct instances of this novel class, where several new
iterative approximation methods are developed with improved per-user convex and
nonconvex approximations that are both tighter and simpler to solve (in
closed-form). As a result, these novel methods display a much faster
convergence speed and require a significantly lower computational cost.
Furthermore, a majority of the proposed methods can tackle the issue of getting
stuck in bad locally optimal solutions, and hence improve solution quality
compared to existing ICA methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5811</identifier>
 <datestamp>2014-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5811</id><created>2013-08-27</created><authors><author><keyname>Kim</keyname><forenames>Kyeong Soo</forenames></author><author><keyname>Ennser</keyname><forenames>Karin</forenames></author><author><keyname>Dwivedi</keyname><forenames>Yogesh K.</forenames></author></authors><title>Clean-Slate Design of Next-Generation Optical Access</title><categories>cs.NI</categories><comments>4 pages, 3 figures</comments><doi>10.1109/ICTON.2011.5970910</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report the current status of our research on the clean-slate design of
next-generation optical access (NGOA). We have been studying candidate
architectures with a major focus on their elasticity to user demands, energy
efficiency, and support of better Quality of Experience (QoE). One of the major
challenges in this study is to establish a comparative analysis framework where
we can assess the performances of candidate architectures in an objective and
quantifiable way. In this paper we describe our efforts to meet this challenge:
(1) the development of a new comparison framework based on integrated QoE and
statistical hypothesis testing and (2) the implementation of a virtual test bed
capturing important aspects from physical layer to application layer to
end-user behaviour governing traffic generation. The comparison framework and
the virtual test bed will provide researchers a sound basis and useful tools
for comparative analysis in the clean-slate design of NGOA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5820</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5820</id><created>2013-08-27</created><authors><author><keyname>Babaei</keyname><forenames>E.</forenames></author><author><keyname>Niapour</keyname><forenames>S. A. KH. Mozaffari</forenames></author><author><keyname>Tabarraie</keyname><forenames>Mehrdad</forenames></author></authors><title>Design of a non-linear power system stabiliser using the concept of the
  feedback linearisation based on the back-stepping technique</title><categories>cs.SY</categories><comments>14 pages, to appear in the IET Generation, Transmission &amp;
  Distribution</comments><doi>10.1049/iet-gtd.2010.0624</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study proposes a feedback linearisation based on the back-stepping
method with simple implementation and unique design process to design a
non-linear controller with a goal of improving both steady-state and transient
stability. The proposed method is designed based on a standard third-order
model of synchronous generator. A comparison based on simulation is then
performed between the proposed method and two conventional control schemes
(i.e. conventional power system stabiliser and direct feedback linearisation).
The simulation results demonstrate that fast response, robustness, damping,
steady-state and transient stability as well as voltage regulation are all
achieved satisfactorily.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5835</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5835</id><created>2013-08-27</created><authors><author><keyname>Samarakoon</keyname><forenames>Sumudu</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Latva-aho</keyname><forenames>Matti</forenames></author></authors><title>Backhaul-Aware Interference Management in the Uplink of Wireless Small
  Cell Networks</title><categories>cs.NI cs.GT cs.LG</categories><comments>14 pages, 9 figures, journal article to be appeared in Transaction of
  Wireless Communication</comments><doi>10.1109/TWC.2013.092413.130221</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of distributed mechanisms for interference management is one of
the key challenges in emerging wireless small cell networks whose backhaul is
capacity limited and heterogeneous (wired, wireless and a mix thereof). In this
paper, a novel, backhaul-aware approach to interference management in wireless
small cell networks is proposed. The proposed approach enables macrocell user
equipments (MUEs) to optimize their uplink performance, by exploiting the
presence of neighboring small cell base stations. The problem is formulated as
a noncooperative game among the MUEs that seek to optimize their delay-rate
tradeoff, given the conditions of both the radio access network and the --
possibly heterogeneous -- backhaul. To solve this game, a novel, distributed
learning algorithm is proposed using which the MUEs autonomously choose their
optimal uplink transmission strategies, given a limited amount of available
information. The convergence of the proposed algorithm is shown and its
properties are studied. Simulation results show that, under various types of
backhauls, the proposed approach yields significant performance gains, in terms
of both average throughput and delay for the MUEs, when compared to existing
benchmark algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5841</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5841</id><created>2013-08-27</created><authors><author><keyname>Olabiyisi</keyname><forenames>Olatunde</forenames></author><author><keyname>Akingboye</keyname><forenames>Yusuff</forenames></author><author><keyname>Abayomi-Alli</keyname><forenames>Adebayo</forenames></author><author><keyname>Izilein</keyname><forenames>Fred</forenames></author><author><keyname>Adeleke</keyname><forenames>Iyiola</forenames></author></authors><title>An Investigation of the Incidences of Repetitive Strain Injury among
  computer Users in Nigeria</title><categories>cs.HC</categories><comments>8 pages, 7 Tables</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 4, No 1, July 2013 ISSN (Print): 1694-0814 | ISSN (Online): 1694-0784
  www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer has been incorporated into day to day activities of almost every
field of human endeavour, offices to different shops. Therefore many people are
now working with computer for longer hours of time. There is no doubt that this
incorporation of computer has helped users a lot but it also brings problems to
the users. One of the problems is Repetitive Strain Injury (RSI). Five hundred
and thirty one (531) questionnaires were personally administered to different
categories of people that use computer in various works of life, ranging from
banking sector, civil service, educational sector, health sector to private
sector. The distribution cut across different professions. A statistical
analysis was conducted on the data obtained using frequency distribution,
Pearson Correlation and Linear Regression. The result obtained showed that
94.3% of the respondents suffered pain from one or more parts of the body.
86.8% of the respondents suffered from eyestrain, 63.9% suffered from low back
pain, 67.4% with wrist pain, 64.7% finger pain while the least suffered pain
was foot pain which only 19% responded positively to it. There are significant
relationships between duration of computer usage, type of chair used, type and
size of monitor used and the incidence of RSI. RSI modeled was formulated
through linear regression which showed that a unit change in computer will
result in corresponding 1.76 unit increases in RSI and a unit change in
ergonomic deficiency will also result in corresponding 0.66 increases in RSI.
The existence of RSI was established and it was discovered that the more time
spent on the computer system, the more the proximity of having strain or pain
in one or more part(s) of the body.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5843</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5843</id><created>2013-08-27</created><authors><author><keyname>Maleshkov</keyname><forenames>Stoyan</forenames></author><author><keyname>Chotrov</keyname><forenames>Dimo</forenames></author></authors><title>Affordable Virtual Reality System Architecture for Representation of
  Implicit Object Properties</title><categories>cs.GR</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 4, No 2, July 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A flexible, scalable and affordable virtual reality software system
architecture is proposed. This solution can be easily implemented on different
hardware configurations: on a single computer or on a computer cluster. The
architecture is aimed to be integrated in the workflow for solving engineering
tasks and oriented towards presenting implicit object properties through
multiple sensorial channels (visual, audio and haptic). Implicit properties
represent hidden object features (i.e. magnetization, radiation, humidity,
toxicity, etc.) which cannot be perceived by the observer through his or her
senses but require specialized equipment in order to expand the sensory ability
of the observer. Our approach extends the underlying general scene graph
structure incorporating additional effects nodes for implicit properties
representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5846</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5846</id><created>2013-08-27</created><authors><author><keyname>Aagaard</keyname><forenames>Brad T.</forenames></author><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author><author><keyname>Williams</keyname><forenames>Charles A.</forenames></author></authors><title>A Domain Decomposition Approach to Implementing Fault Slip in
  Finite-Element Models of Quasi-static and Dynamic Crustal Deformation</title><categories>physics.geo-ph cs.CE cs.MS</categories><comments>14 pages, 15 figures</comments><journal-ref>Journal of Geophysical Research, 118(6), pp.3059-3079, 2013</journal-ref><doi>10.1002/jgrb.50217</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We employ a domain decomposition approach with Lagrange multipliers to
implement fault slip in a finite-element code, PyLith, for use in both
quasi-static and dynamic crustal deformation applications. This integrated
approach to solving both quasi-static and dynamic simulations leverages common
finite-element data structures and implementations of various boundary
conditions, discretization schemes, and bulk and fault rheologies. We have
developed a custom preconditioner for the Lagrange multiplier portion of the
system of equations that provides excellent scalability with problem size
compared to conventional additive Schwarz methods. We demonstrate application
of this approach using benchmarks for both quasi-static viscoelastic
deformation and dynamic spontaneous rupture propagation that verify the
numerical implementation in PyLith.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5847</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5847</id><created>2013-08-27</created><authors><author><keyname>Maleshkov</keyname><forenames>Stoyan</forenames></author><author><keyname>Chotrov</keyname><forenames>Dimo</forenames></author></authors><title>Post-processing of Engineering Analysis Results for Visualization in VR
  Systems</title><categories>cs.GR</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 2, March 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The applicability of Virtual Reality for evaluating engineering analysis
results is beginning to receive increased appreciation in the last years. The
problem many engineers are still facing is how to import their model together
with the analysis results in a virtual reality environment for exploration and
results validation. In this paper we propose an algorithm for transforming
model data and results from finite element analysis (FEA) solving application
to a format easily interpretable by a virtual reality application. The
algorithm includes also steps for reducing the face-count of the resulting mesh
by eliminating faces from the inner part of the model in the cases when only
the surfaces of the model is analyzed. We also describe a possibility for
simultaneously assessing multiple analysis results relying on multimodal
results presentation by stimulating different senses of the operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5858</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5858</id><created>2013-08-27</created><authors><author><keyname>Power</keyname><forenames>James F.</forenames></author></authors><title>Thue's 1914 paper: a translation</title><categories>cs.FL</categories><acm-class>F.4.2; K.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper includes notes to accompany a reading of Thue's 1914 paper
&quot;Probleme uber Veranderungen von Zeichenreihen nach gegebenen Reglen&quot;, along
with a translation of that paper. Thue's 1914 paper is mainly famous for
proving an early example of an undecidable problem, cited prominently by Post.
However, Post's paper principally makes use of the definition of Thue systems,
described on the first two pages of Thue's paper, and does not depend on the
more specific results in the remainder of Thue's paper. A closer study of the
remaining parts of that paper highlight a number of important themes in the
history of computing: the transition from algebra to formal language theory,
the analysis of the &quot;computational power&quot; (in a pre-1936 sense) of rules, and
the development of algorithms to generate rule-sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5865</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5865</id><created>2013-08-23</created><authors><author><keyname>Hu</keyname><forenames>Pili</forenames></author><author><keyname>Lau</keyname><forenames>Wing Cheong</forenames></author></authors><title>A Survey and Taxonomy of Graph Sampling</title><categories>cs.SI math.PR stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph sampling is a technique to pick a subset of vertices and/ or edges from
original graph. It has a wide spectrum of applications, e.g. survey hidden
population in sociology [54], visualize social graph [29], scale down Internet
AS graph [27], graph sparsification [8], etc. In some scenarios, the whole
graph is known and the purpose of sampling is to obtain a smaller graph. In
other scenarios, the graph is unknown and sampling is regarded as a way to
explore the graph. Commonly used techniques are Vertex Sampling, Edge Sampling
and Traversal Based Sampling. We provide a taxonomy of different graph sampling
objectives and graph sampling approaches. The relations between these
approaches are formally argued and a general framework to bridge theoretical
analysis and practical implementation is provided. Although being smaller in
size, sampled graphs may be similar to original graphs in some way. We are
particularly interested in what graph properties are preserved given a sampling
procedure. If some properties are preserved, we can estimate them on the
sampled graphs, which gives a way to construct efficient estimators. If one
algorithm relies on the perserved properties, we can expect that it gives
similar output on original and sampled graphs. This leads to a systematic way
to accelerate a class of graph algorithms. In this survey, we discuss both
classical text-book type properties and some advanced properties. The landscape
is tabularized and we see a lot of missing works in this field. Some
theoretical studies are collected in this survey and simple extensions are
made. Most previous numerical evaluation works come in an ad hoc fashion, i.e.
evaluate different type of graphs, different set of properties, and different
sampling algorithms. A systematical and neutral evaluation is needed to shed
light on further graph sampling studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5876</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5876</id><created>2013-08-27</created><authors><author><keyname>Rebollo-Neira</keyname><forenames>Laura</forenames></author><author><keyname>Maciol</keyname><forenames>Ryszard</forenames></author><author><keyname>Bibi</keyname><forenames>Shabnam</forenames></author></authors><title>Hierarchized block wise image approximation by greedy pursuit strategies</title><categories>cs.CV</categories><comments>4 pages. An example and the computing routines for implementing the
  approach are available on
  http://www.nonlinear-approx.info/examples/node0.html</comments><msc-class>68U10, 94A08</msc-class><acm-class>G.1.2</acm-class><doi>10.1109/LSP.2013.2283510</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approach for effective implementation of greedy selection methodologies,
to approximate an image partitioned into blocks, is proposed. The method is
specially designed for approximating partitions on a transformed image. It
evolves by selecting, at each iteration step, i) the elements for approximating
each of the blocks partitioning the image and ii) the hierarchized sequence in
which the blocks are approximated to reach the required global condition on
sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5884</identifier>
 <datestamp>2014-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5884</id><created>2013-08-27</created><authors><author><keyname>Ciganovi&#x107;</keyname><forenames>Nikola</forenames></author><author><keyname>Beaudry</keyname><forenames>Normand J.</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>Smooth Max-Information as One-Shot Generalization for Mutual Information</title><categories>quant-ph cs.IT math.IT</categories><comments>15 pages</comments><journal-ref>IEEE Trans. Inf. Theory 60(3), 1573-1581, 2014</journal-ref><doi>10.1109/TIT.2013.2295314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study formal properties of smooth max-information, a generalization of von
Neumann mutual information derived from the max-relative entropy. Recent work
suggests that it is a useful quantity in one-shot channel coding, quantum rate
distortion theory and the physics of quantum many-body systems.
  Max-information can be defined in multiple ways. We demonstrate that
different smoothed definitions are essentially equivalent (up to logarithmic
terms in the smoothing parameters). These equivalence relations allow us to
derive new chain rules for the max-information in terms of min- and
max-entropies, thus extending the smooth entropy formalism to mutual
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5885</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5885</id><created>2013-08-27</created><authors><author><keyname>Li</keyname><forenames>Chunlei</forenames></author><author><keyname>Li</keyname><forenames>Nian</forenames></author><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author><author><keyname>Ding</keyname><forenames>Cunsheng</forenames></author></authors><title>On the weight distributions of several classes of cyclic codes from APN
  monomials</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $m\geq 3$ be an odd integer and $p$ be an odd prime. % with $p-1=2^rh$,
where $h$ is an odd integer.
  In this paper, many classes of three-weight cyclic codes over
$\mathbb{F}_{p}$ are presented via an examination of the condition for the
cyclic codes $\mathcal{C}_{(1,d)}$ and $\mathcal{C}_{(1,e)}$, which have
parity-check polynomials $m_1(x)m_d(x)$ and $m_1(x)m_e(x)$ respectively, to
have the same weight distribution, where $m_i(x)$ is the minimal polynomial of
$\pi^{-i}$ over $\mathbb{F}_{p}$ for a primitive element $\pi$ of
$\mathbb{F}_{p^m}$. %For $p=3$, the duals of five classes of the proposed
cyclic codes are optimal in the sense that they meet certain bounds on linear
codes. Furthermore, for $p\equiv 3 \pmod{4}$ and positive integers $e$ such
that there exist integers $k$ with $\gcd(m,k)=1$ and $\tau\in\{0,1,\cdots,
m-1\}$ satisfying $(p^k+1)\cdot e\equiv 2 p^{\tau}\pmod{p^m-1}$, the value
distributions of the two exponential sums $T(a,b)=\sum\limits_{x\in
\mathbb{F}_{p^m}}\omega^{\Tr(ax+bx^e)}$ and $ S(a,b,c)=\sum\limits_{x\in
\mathbb{F}_{p^m}}\omega^{\Tr(ax+bx^e+cx^s)}, $ where $s=(p^m-1)/2$, are
settled. As an application, the value distribution of $S(a,b,c)$ is utilized to
investigate the weight distribution of the cyclic codes $\mathcal{C}_{(1,e,s)}$
with parity-check polynomial $m_1(x)m_e(x)m_s(x)$. In the case of $p=3$ and
even $e$ satisfying the above condition, the duals of the cyclic codes
$\mathcal{C}_{(1,e,s)}$ have the optimal minimum distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5896</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5896</id><created>2013-08-27</created><authors><author><keyname>Baelde</keyname><forenames>David</forenames><affiliation>LSV, ENS Cachan</affiliation></author><author><keyname>Carayol</keyname><forenames>Arnaud</forenames><affiliation>CNRS, Universit&#xe9; Paris-Est, Marne-la-Vall&#xe9;e</affiliation></author></authors><title>Proceedings Workshop on Fixed Points in Computer Science</title><categories>cs.LO cs.FL cs.PL</categories><proxy>EPTCS</proxy><acm-class>F.4.1</acm-class><journal-ref>EPTCS 126, 2013</journal-ref><doi>10.4204/EPTCS.126</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Ninth Workshop on Fixed Points in
Computer Science which took place on the September 1st, 2013 in Torino, Italy
as a CSL-affiliated workshop. Past workshops have been held in Brno (1998,
MFCS/CSL workshop), Paris (2000, LC workshop), Florence (2001, PLI workshop),
Copenhagen (2002, LICS (FLoC) workshop), Warsaw (2003, ETAPS workshop), Coimbra
(2009, CSL workshop), Brno (2010, MFCS-CSL workshop), Tallinn (2012, CSL
workshop). Fixed points play a fundamental role in several areas of computer
science. They are used to justify (co)recursive definitions and associated
reasoning techniques. The construction and properties of fixed points have been
investigated in many different settings such as: design and implementation of
programming languages, logics, verification, databases. The aim of this
workshop is to provide a forum for researchers to present their results to
those members of the computer science and logic communities who study or apply
the theory of fixed points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5906</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5906</id><created>2013-08-23</created><authors><author><keyname>Voyant</keyname><forenames>Cyril</forenames><affiliation>SPE, CHD Castellucio</affiliation></author><author><keyname>Julian</keyname><forenames>Daniel</forenames><affiliation>CHD Castellucio</affiliation></author><author><keyname>Roustit</keyname><forenames>Rudy</forenames><affiliation>CHD Castellucio</affiliation></author><author><keyname>Biffi</keyname><forenames>Katia</forenames><affiliation>CHD Castellucio</affiliation></author><author><keyname>Marcovici</keyname><forenames>Celine Lantieri</forenames><affiliation>CHD Castellucio</affiliation></author></authors><title>Biological effects and equivalent doses in radiotherapy: a software
  solution</title><categories>cs.CE physics.med-ph</categories><proxy>ccsd</proxy><journal-ref>reports of practical oncology and radiotherapy (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The limits of TDF (time, dose, and fractionation) and linear quadratic models
have been known for a long time. Medical physicists and physicians are required
to provide fast and reliable interpretations regarding the delivered doses or
any future prescriptions relating to treatment changes. We therefore propose a
calculation interface under the GNU license to be used for equivalent doses,
biological doses, and normal tumor complication probability (Lyman model). The
methodology used draws from several sources: the linear-quadratic-linear model
of Astrahan, the repopulation effects of Dale, and the prediction of
multi-fractionated treatments of Thames. The results are obtained from an
algorithm that minimizes an ad-hoc cost function, and then compared to the
equivalent dose computed using standard calculators in seven French
radiotherapy centers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5915</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5915</id><created>2013-08-27</created><authors><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>Borokhovich</keyname><forenames>Michael</forenames></author><author><keyname>Haddad</keyname><forenames>Yoram</forenames></author><author><keyname>Kantor</keyname><forenames>Erez</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author><author><keyname>Parter</keyname><forenames>Merav</forenames></author><author><keyname>Peleg</keyname><forenames>David</forenames></author></authors><title>Generalized Perron--Frobenius Theorem for Nonsquare Matrices</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The celebrated Perron--Frobenius (PF) theorem is stated for irreducible
nonnegative square matrices, and provides a simple characterization of their
eigenvectors and eigenvalues. The importance of this theorem stems from the
fact that eigenvalue problems on such matrices arise in many fields of science
and engineering, including dynamical systems theory, economics, statistics and
optimization. However, many real-life scenarios give rise to nonsquare
matrices. A natural question is whether the PF Theorem (along with its
applications) can be generalized to a nonsquare setting. Our paper provides a
generalization of the PF Theorem to nonsquare matrices. The extension can be
interpreted as representing client-server systems with additional degrees of
freedom, where each client may choose between multiple servers that can
cooperate in serving it (while potentially interfering with other clients).
This formulation is motivated by applications to power control in wireless
networks, economics and others, all of which extend known examples for the use
of the original PF Theorem.
  We show that the option of cooperation between servers does not improve the
situation, in the sense that in the optimal solution no cooperation is needed,
and only one server needs to serve each client. Hence, the additional power of
having several potential servers per client translates into \emph{choosing} the
best single server and not into \emph{sharing} the load between the servers in
some way, as one might have expected.
  The two main contributions of the paper are (i) a generalized PF Theorem that
characterizes the optimal solution for a non-convex nonsquare problem, and (ii)
an algorithm for finding the optimal solution in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5923</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5923</id><created>2013-08-27</created><updated>2014-03-25</updated><authors><author><keyname>Miszczak</keyname><forenames>Jaros&#x142;aw Adam</forenames></author><author><keyname>Sadowski</keyname><forenames>Przemys&#x142;aw</forenames></author></authors><title>Quantum network exploration with a faulty sense of direction</title><categories>quant-ph cs.MA</categories><comments>12 pages, 5 figures, accepted to QIC</comments><journal-ref>Quantum Information &amp; Computation, Vol.14, No.13&amp;14 (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a model which can be used to analyse the scenario of exploring
quantum network with a distracted sense of direction. Using this model we
analyse the behaviour of quantum mobile agents operating with non-adaptive and
adaptive strategies which can be employed in this scenario. We introduce the
notion of node visiting suitable for analysing quantum superpositions of states
by distinguishing between visiting and attaining a position. We show that
without a proper model of adaptiveness, it is not possible for the party
representing the distraction in the sense of direction, to obtain the results
analogous to the classical case. Moreover, with additional control resources
the total number of attained positions is maintained if the number of visited
positions is strictly limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5933</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5933</id><created>2013-08-27</created><authors><author><keyname>Al-Mughrabi</keyname><forenames>Ala'a Atallah</forenames></author><author><keyname>Owaied</keyname><forenames>Hussein</forenames></author></authors><title>Framework Model for Database Replication within the Availability Zones</title><categories>cs.DB</categories><journal-ref>International Journal of Computer Science Issues,VOL 10,Issue 2,NO
  1,March 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a proposed model for database replication model in
private cloud availability regions, which is an enhancement of the SQL Server
AlwaysOn Layers of Protection Model presents by Microsoft in 2012. The
enhancement concentrates in the database replication for private cloud
availability regions through the use of primary and secondary servers. The
processes of proposed model during the client send Write/Read Request to the
server, in synchronous and semi synchronous replication level has been
described in details also the processes of proposed model when the client send
Write/Read Request to the Primary Server presented in details. All the types of
automatic failover situations are presented in this thesis. Using the proposed
models will increase the performance because each one of the secondary servers
will open for Read / Write and allow the clients to connect to the nearby
secondary and less loading on each server. Keywords: Availability Regions,
Cloud Computing, Database Replication, SQL Server AlwaysOn, Synchronization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5937</identifier>
 <datestamp>2014-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5937</id><created>2013-08-27</created><updated>2014-10-14</updated><authors><author><keyname>Balagoni</keyname><forenames>Abhinov</forenames></author><author><keyname>Chavala</keyname><forenames>Vinay Kumar</forenames></author></authors><title>A Multilayered Approach to Estimate Business Performance</title><categories>cs.CY</categories><comments>4 pages. 6th International Conference on Advanced Computing and
  Communication Technologies (ICACCT-2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of a business is chiefly determined by the business model
adopted and its environment of operation. This paper emphasizes on the
integration of Web 2.0 services like social networking to your existing
business, which helps in the progressive sustainability of the business
organization. The usage of Web 2.0 tools, such as Wikipedia, blogs and social
networking services such as Facebook, LinkedIn, Orkut by individuals in all
societies, has been pervasive and very successful in proliferating their use at
the professional or business levels. This paper puts forth the discussion which
helps in better understanding of what social networking encompasses for present
day business. It also aims to educate business decision makers about the
benefits and risks associated in incorporating business model with social
networking. Thus, the paper focuses on the implementation of social networking
platforms in business operations and discusses the different attributes of
business performance and gives an overview in choosing a social networking
platform for its business purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5938</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5938</id><created>2013-08-27</created><authors><author><keyname>Achtenberg</keyname><forenames>Stella</forenames></author><author><keyname>Raphaeli</keyname><forenames>Dan</forenames></author></authors><title>Theoretic Shaping Bounds for Single Letter Constraints and Mismatched
  Decoding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shaping gain is attained in schemes where a shaped subcode is chosen from a
larger codebook by a codeword selection process. This includes the popular
method of Trellis Shaping (TS), originally proposed by Forney for average power
reduction. The decoding process of such schemes is mismatched, since it is
aware of only the large codebook. This study models such schemes by a random
code construction and derives achievable bounds on the transmission rate under
matched and mismatched decoding. For matched decoding the bound is obtained
using a modified asymptotic equipartition property (AEP) theorem derived to
suit this particular code construction. For mismatched decoding, relying on the
large codebook performance is generally wrong, since the performance of the
non-typical codewords within the large codebook may differ substantially from
the typical ones. Hence, we present two novel lower bounds on the capacity
under mismatched decoding. The first is based upon Gallager's random exponent,
whereas the second on a modified version of the joint-typicality decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5952</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5952</id><created>2013-08-27</created><authors><author><keyname>Dolgov</keyname><forenames>S. V.</forenames></author><author><keyname>Smirnov</keyname><forenames>A. P.</forenames></author><author><keyname>Tyrtyshnikov</keyname><forenames>E. E.</forenames></author></authors><title>Low-rank approximation in the numerical modeling of the Farley-Buneman
  instability in ionospheric plasma</title><categories>cs.NA math.NA physics.comp-ph physics.plasm-ph</categories><msc-class>65K10, 82B28, 65M22, 65M06, 65K10</msc-class><doi>10.1016/j.jcp.2014.01.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the numerical modeling of the Farley-Buneman instability
development in the earth's ionosphere plasma. The ion behavior is governed by
the kinetic Landau equation in the four-dimensional phase space, and since the
finite difference discretization on a tensor product grid is used, this
equation becomes the most computationally challenging part of the scheme. To
relax the complexity and memory consumption, an adaptive model reduction using
the low-rank separation of variables, namely the Tensor Train format, is
employed.
  The approach was verified via the prototype MATLAB implementation. Numerical
experiments demonstrate the possibility of efficient separation of space and
velocity variables, resulting in the solution storage reduction by a factor of
order tens.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5964</identifier>
 <datestamp>2013-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5964</id><created>2013-08-27</created><authors><author><keyname>Wang</keyname><forenames>Timothy</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Automated, Credible Autocoding of An Unmanned Aggressive Maneuvering Car
  Controller</title><categories>cs.SY</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This article describes the application of a credible autocoding framework for
control systems towards a nonlinear car controller example. The framework
generates code, along with guarantees of high level functional properties about
the code that can be independently verified. These high-level functional
properties not only serves as a certificate of good system behvaior but also
can be used to guarantee the absence of runtime errors. In one of our previous
works, we have constructed a prototype autocoder with proofs that demonstrates
this framework in a fully automatic fashion for linear and quasi-nonlinear
controllers. With the nonlinear car example, we propose to further extend the
prototype's dataflow annotation language environment with with several new
annotation symbols to enable the expression of general predicates and dynamical
systems. We demonstrate manually how the new extensions to the prototype
autocoder work on the car controller using the output language Matlab. Finally,
we discuss the requirements and scalability issues of the automatic analysis
and verification of the documented output code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5996</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5996</id><created>2013-08-27</created><authors><author><keyname>Shah</keyname><forenames>Harit</forenames></author><author><keyname>Anandane</keyname><forenames>Sharma Shankar</forenames></author><author><keyname>Shrikanth</keyname></author></authors><title>Security Issues on Cloud Computing</title><categories>cs.CR</categories><comments>arXiv admin note: text overlap with arXiv:1206.2597 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Cloud Computing concept offers dynamically scalable resources provisioned
as a service over the Internet.Economic benefits are the main driver for the
Cloud, since it promises the reduction of capital expenditure and operational
expenditure.In order for this to become reality, however, there are still some
challenges to be solved. Amongst these are security and trust issues, since the
user data has to be released to the Cloud and thus leaves the protection sphere
of the data owner. Most of the discussions on these topics are mainly driven by
arguments related to organisational means. This paper focuses on various
security issues arising from the usage of Cloud services and especially by the
rapid development of Cloud computing arena. It also discusses basic security
model followed by various High Level Security threats in the industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.5999</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.5999</id><created>2013-08-27</created><authors><author><keyname>Selvaradjou</keyname><forenames>Ka.</forenames></author><author><keyname>Shankar</keyname><forenames>A. Sharma</forenames></author><author><keyname>Anandakumar</keyname><forenames>U.</forenames></author><author><keyname>Sivasundar</keyname><forenames>N.</forenames></author></authors><title>Optimization of Bluetooth Audio Stream based on the Estimation of
  Proximity</title><categories>cs.NI</categories><journal-ref>International Journal of Computer and Electrical Engineering,
  VOL.2, No.3, June 2010 pp.550-555</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of Bluetooth wireless technology makes it possible to transmit
real-time audio in mobile devices. Bluetooth is cost-efficient and
power-efficient, but it is not suitable for traditional audio encoding and
real-time streaming due to limited bandwidth, high degree of error rates, and
the time-varying nature of the radio link. Therefore, audio streaming over
Bluetooth poses problems such as guzzling of both power and bandwidth. In order
to overcome the above mentioned problems, an algorithm is proposed in this work
to optimize the audio stream from the source to the sink by estimating the
proximity between them. The optimization is achieved by adjusting the bit rate
of the audio stream thus conserving power. We considered carefully various
Bluetooth signal parameters and the most suitable parameter for estimating the
proximity has been determined experimentally. The experiments were carried out
using Class II BS003 Bluesoleil dongle. This work will enable the Bluetooth
users to perform a seamless and optimized streaming of MP3 stereo audio data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6003</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6003</id><created>2013-08-27</created><authors><author><keyname>Yao</keyname><forenames>Zhe</forenames></author><author><keyname>Gripon</keyname><forenames>Vincent</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael</forenames></author></authors><title>Improving Sparse Associative Memories by Escaping from Bogus Fixed
  Points</title><categories>cs.NE cs.IT math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gripon-Berrou neural network (GBNN) is a recently invented recurrent
neural network embracing a LDPC-like sparse encoding setup which makes it
extremely resilient to noise and errors. A natural use of GBNN is as an
associative memory. There are two activation rules for the neuron dynamics,
namely sum-of-sum and sum-of-max. The latter outperforms the former in terms of
retrieval rate by a huge margin. In prior discussions and experiments, it is
believed that although sum-of-sum may lead the network to oscillate, sum-of-max
always converges to an ensemble of neuron cliques corresponding to previously
stored patterns. However, this is not entirely correct. In fact, sum-of-max
often converges to bogus fixed points where the ensemble only comprises a small
subset of the converged state. By taking advantage of this overlooked fact, we
can greatly improve the retrieval rate. We discuss this particular issue and
propose a number of heuristics to push sum-of-max beyond these bogus fixed
points. To tackle the problem directly and completely, a novel post-processing
algorithm is also developed and customized to the structure of GBNN.
Experimental results show that the new algorithm achieves a huge performance
boost in terms of both retrieval rate and run-time, compared to the standard
sum-of-max and all the other heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6007</identifier>
 <datestamp>2013-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6007</id><created>2013-08-27</created><updated>2013-12-09</updated><authors><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Schulman</keyname><forenames>Leonard J.</forenames></author></authors><title>Tree Codes and a Conjecture on Exponential Sums</title><categories>cs.CC cs.IT math.IT math.NT</categories><comments>Proc. ITCS 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new conjecture on some exponential sums. These particular sums
have not apparently been considered in the literature. Subject to the
conjecture we obtain the first effective construction of asymptotically good
tree codes. The available numerical evidence is consistent with the conjecture
and is sufficient to certify codes for significant-length communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6021</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6021</id><created>2013-08-27</created><authors><author><keyname>Jarollahi</keyname><forenames>Hooman</forenames></author><author><keyname>Onizawa</keyname><forenames>Naoya</forenames></author><author><keyname>Gross</keyname><forenames>Warren J.</forenames></author></authors><title>Selective Decoding in Associative Memories Based on Sparse-Clustered
  Networks</title><categories>cs.AR</categories><comments>4 pages, Accepted in IEEE Global SIP 2013 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Associative memories are structures that can retrieve previously stored
information given a partial input pattern instead of an explicit address as in
indexed memories. A few hardware approaches have recently been introduced for a
new family of associative memories based on Sparse-Clustered Networks (SCN)
that show attractive features. These architectures are suitable for
implementations with low retrieval latency, but are limited to small networks
that store a few hundred data entries. In this paper, a new hardware
architecture of SCNs is proposed that features a new data-storage technique as
well as a method we refer to as Selective Decoding (SD-SCN). The SD-SCN has
been implemented using a similar FPGA used in the previous efforts and achieves
two orders of magnitude higher capacity, with no error-performance penalty but
with the cost of few extra clock cycles per data access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6025</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6025</id><created>2013-08-27</created><authors><author><keyname>Babichenko</keyname><forenames>Yakov</forenames></author><author><keyname>Barman</keyname><forenames>Siddharth</forenames></author><author><keyname>Peretz</keyname><forenames>Ron</forenames></author></authors><title>Small-Support Approximate Correlated Equilibria</title><categories>cs.GT</categories><comments>16 pages</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the existence of approximate correlated equilibrium of support size
polylogarithmic in the number of players and the number of actions per player.
In particular, using the probabilistic method, we show that there exists a
multiset of polylogarithmic size such that the uniform distribution over this
multiset forms an approximate correlated equilibrium. Along similar lines, we
establish the existence of approximate coarse correlated equilibrium with
logarithmic support.
  We complement these results by considering the computational complexity of
determining small-support approximate equilibria. We show that random sampling
can be used to efficiently determine an approximate coarse correlated
equilibrium with logarithmic support. But, such a tight result does not hold
for correlated equilibrium, i.e., sampling might generate an approximate
correlated equilibrium of support size \Omega(m) where m is the number of
actions per player. Finally, we show that finding an exact correlated
equilibrium with smallest possible support is NP-hard under Cook reductions,
even in the case of two-player zero-sum games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6029</identifier>
 <datestamp>2015-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6029</id><created>2013-08-27</created><updated>2015-06-12</updated><authors><author><keyname>Wittek</keyname><forenames>Peter</forenames></author></authors><title>Algorithm 950: Ncpol2sdpa---Sparse Semidefinite Programming Relaxations
  for Polynomial Optimization Problems of Noncommuting Variables</title><categories>cs.MS math.OC physics.comp-ph quant-ph</categories><comments>17 pages, 3 figures, 1 table, 2 algorithms, the algorithm is
  available at http://peterwittek.github.io/ncpol2sdpa/</comments><acm-class>G.4</acm-class><journal-ref>ACM Transactions on Mathematical Software, 2015, 41(3), 21</journal-ref><doi>10.1145/2699464</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hierarchy of semidefinite programming (SDP) relaxations approximates the
global optimum of polynomial optimization problems of noncommuting variables.
Generating the relaxation, however, is a computationally demanding task, and
only problems of commuting variables have efficient generators. We develop an
implementation for problems of noncommuting problems that creates the
relaxation to be solved by SDPA -- a high-performance solver that runs in a
distributed environment. We further exploit the inherent sparsity of
optimization problems in quantum physics to reduce the complexity of the
resulting relaxations. Constrained problems with a relaxation of order two may
contain up to a hundred variables. The implementation is available in Python.
The tool helps solve problems such as finding the ground state energy or
testing quantum correlations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6038</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6038</id><created>2013-08-27</created><updated>2013-08-29</updated><authors><author><keyname>Xu</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>On sparse interpolation and the design of deterministic interpolation
  points</title><categories>math.NA cs.IT math.IT</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we build up a framework for sparse interpolation. We first
investigate the theoretical limit of the number of unisolvent points for sparse
interpolation under a general setting and try to answer some basic questions of
this topic. We also explore the relation between classical interpolation and
sparse interpolation. We second consider the design of the interpolation points
for the $s$-sparse functions in high dimensional Chebyshev bases, for which the
possible applications include uncertainty quantification, numerically solving
stochastic or parametric PDEs and compressed sensing. Unlike the traditional
random sampling method, we present in this paper a deterministic method to
produce the interpolation points, and show its performance with $\ell_1$
minimization by analyzing the mutual incoherence of the interpolation matrix.
Numerical experiments show that the deterministic points have a similar
performance with that of the random points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6056</identifier>
 <datestamp>2014-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6056</id><created>2013-08-28</created><authors><author><keyname>Moreno</keyname><forenames>Juan C.</forenames></author><author><keyname>Prasath</keyname><forenames>V. B. S.</forenames></author><author><keyname>Proenca</keyname><forenames>Hugo</forenames></author><author><keyname>Palaniappan</keyname><forenames>K.</forenames></author></authors><title>Brain MRI Segmentation with Fast and Globally Convex Multiphase Active
  Contours</title><categories>cs.CV</categories><msc-class>68U10</msc-class><acm-class>I.4.6</acm-class><journal-ref>Computer Vision and Image Understanding, 125, 237-250, 2014</journal-ref><doi>10.1016/j.cviu.2014.04.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiphase active contour based models are useful in identifying multiple
regions with different characteristics such as the mean values of regions. This
is relevant in brain magnetic resonance images (MRIs), allowing the
differentiation of white matter against gray matter. We consider a well defined
globally convex formulation of Vese and Chan multiphase active contour model
for segmenting brain MRI images. A well-established theory and an efficient
dual minimization scheme are thoroughly described which guarantees optimal
solutions and provides stable segmentations. Moreover, under the dual
minimization implementation our model perfectly describes disjoint regions by
avoiding local minima solutions. Experimental results indicate that the
proposed approach provides better accuracy than other related multiphase active
contour algorithms even under severe noise, intensity inhomogeneities, and
partial volume effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6058</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6058</id><created>2013-08-28</created><authors><author><keyname>Navaz</keyname><forenames>A. S. Syed</forenames></author><author><keyname>Prabhadevi</keyname><forenames>C.</forenames></author><author><keyname>Sangeetha</keyname><forenames>V.</forenames></author></authors><title>Data Grid Concepts for Data Security in Distributed Computing</title><categories>cs.DC</categories><comments>6 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data grid is a distributed computing architecture that integrates a large
number of data and computing resources into a single virtual data management
system. It enables the sharing and coordinated use of data from various
resources and provides various services to fit the needs of high performance
distributed and data-intensive computing. Here data partitioning and dynamic
replication in data grid are considered. In which security and access
performance of a system are efficient. There are several important requirements
for data grids, including information survivability, security, and access
performance. More specifically, the investigation is the problem of optimal
allocation of sensitive data objects that are partitioned by using secret
sharing scheme or erasure coding scheme and replicated. DATA PARTITIONING is
known as the single data can be divided into multiple objects. REPLICATION is
known as process of sharing information. storing same data in multiple systems.
Replication techniques are frequently used to improve data availability. Single
point failure does not affect this system. Where the data will be secured.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6062</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6062</id><created>2013-08-28</created><authors><author><keyname>Nurdin</keyname><forenames>Hendra I.</forenames></author></authors><title>Structures and Transformations for Model Reduction of Linear Quantum
  Stochastic Systems</title><categories>quant-ph cs.SY math.OC</categories><comments>28 pages, 3 figures. Preliminary parts of this paper have been
  presented at the 2013 American Control Conference
  (http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=06580217) and 2012
  Australian Control Conference
  (http://search.informit.com.au/fullText;dn=230324713737486;res=IELENG).
  Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to develop a model reduction theory for linear
quantum stochastic systems that are commonly encountered in quantum optics and
related fields, modeling devices such as optical cavities and optical
parametric amplifiers, as well as quantum networks composed of such devices.
Results are derived on subsystem truncation of such systems and it is shown
that this truncation preserves the physical realizability property of linear
quantum stochastic systems. It is also shown that the property of complete
passivity of linear quantum stochastic systems is preserved under subsystem
truncation. A necessary and sufficient condition for the existence of a
balanced realization of a linear quantum stochastic system under sympletic
transformations is derived. Such a condition turns out to be very restrictive
and will not be satisfied by generic linear quantum stochastic systems, thus
necessary and sufficient conditions for relaxed notions of simultaneous
diagonalization of the controllability and observability Gramians of linear
quantum stochastic systems under symplectic transformations are also obtained.
The notion of a quasi-balanced realization is introduced and it is shown that
all asymptotically stable completely passive linear quantum stochastic systems
have a quasi-balanced realization. Moreover, an explicit bound for the
subsystem truncation error on a quasi-balanceable linear quantum stochastic
system is provided. The results are applied in an example of model reduction in
the context of low-pass optical filtering of coherent light using a network of
optical cavities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6067</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6067</id><created>2013-08-28</created><authors><author><keyname>Lutomirski</keyname><forenames>Andrew</forenames></author></authors><title>Sealed States And Quantum Blackmail</title><categories>quant-ph cs.CR</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a protocol in which Belinda seals a (classical) message. She gives
the resulting sealed message to Charlie, who can either unseal and read the
message or return it unopened to Belinda. If he returns it unopened, Belinda
should be able to verify that Charlie neither read the message nor made a copy
that would allow him to read it later. Such a protocol is impossible with
classical cryptography: Charlie can copy a message and do anything he likes to
that copy without damaging the original. With quantum cryptography, on the
other hand, the no cloning theorem implies that Charlie cannot simply copy a
message and unseal the copy.
  Abstract In this paper, I prove that any conventional quantum cryptographic
protocol can give at best a very weak security guarantee. However, quantum
cryptography in conjunction with classical functions that can only be inverted
by humans (i.e. CAPTCHAs) can potentially give exponential security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6074</identifier>
 <datestamp>2014-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6074</id><created>2013-08-28</created><updated>2014-04-03</updated><authors><author><keyname>Seth</keyname><forenames>Sohan</forenames></author><author><keyname>V&#xe4;lim&#xe4;ki</keyname><forenames>Niko</forenames></author><author><keyname>Kaski</keyname><forenames>Samuel</forenames></author><author><keyname>Honkela</keyname><forenames>Antti</forenames></author></authors><title>Exploration and retrieval of whole-metagenome sequencing samples</title><categories>q-bio.GN cs.CE cs.IR</categories><comments>16 pages; additional results</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Over the recent years, the field of whole metagenome shotgun sequencing has
witnessed significant growth due to the high-throughput sequencing technologies
that allow sequencing genomic samples cheaper, faster, and with better coverage
than before. This technical advancement has initiated the trend of sequencing
multiple samples in different conditions or environments to explore the
similarities and dissimilarities of the microbial communities. Examples include
the human microbiome project and various studies of the human intestinal tract.
With the availability of ever larger databases of such measurements, finding
samples similar to a given query sample is becoming a central operation. In
this paper, we develop a content-based exploration and retrieval method for
whole metagenome sequencing samples. We apply a distributed string mining
framework to efficiently extract all informative sequence $k$-mers from a pool
of metagenomic samples and use them to measure the dissimilarity between two
samples. We evaluate the performance of the proposed approach on two human gut
metagenome data sets as well as human microbiome project metagenomic samples.
We observe significant enrichment for diseased gut samples in results of
queries with another diseased sample and very high accuracy in discriminating
between different body sites even though the method is unsupervised. A software
implementation of the DSM framework is available at
https://github.com/HIITMetagenomics/dsm-framework
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6075</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6075</id><created>2013-08-28</created><authors><author><keyname>Kondor</keyname><forenames>D&#xe1;niel</forenames></author><author><keyname>M&#xe1;tray</keyname><forenames>P&#xe9;ter</forenames></author><author><keyname>Csabai</keyname><forenames>Istv&#xe1;n</forenames></author><author><keyname>Vattay</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Measuring the dimension of partially embedded networks</title><categories>physics.soc-ph cs.SI physics.data-an</categories><journal-ref>Physica A: Statistical Mechanics and its Applications 392 (2013),
  pp. 4160-4171</journal-ref><doi>10.1016/j.physa.2013.04.046</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scaling phenomena have been intensively studied during the past decade in the
context of complex networks. As part of these works, recently novel methods
have appeared to measure the dimension of abstract and spatially embedded
networks. In this paper we propose a new dimension measurement method for
networks, which does not require global knowledge on the embedding of the
nodes, instead it exploits link-wise information (link lengths, link delays or
other physical quantities). Our method can be regarded as a generalization of
the spectral dimension, that grasps the network's large-scale structure through
local observations made by a random walker while traversing the links. We apply
the presented method to synthetic and real-world networks, including road maps,
the Internet infrastructure and the Gowalla geosocial network. We analyze the
theoretically and empirically designated case when the length distribution of
the links has the form P(r) ~ 1/r. We show that while previous dimension
concepts are not applicable in this case, the new dimension measure still
exhibits scaling with two distinct scaling regimes. Our observations suggest
that the link length distribution is not sufficient in itself to entirely
control the dimensionality of complex networks, and we show that the proposed
measure provides information that complements other known measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6086</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6086</id><created>2013-08-28</created><updated>2014-08-06</updated><authors><author><keyname>Patterson</keyname><forenames>Stacy</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Keidar</keyname><forenames>Idit</forenames></author></authors><title>Distributed Compressed Sensing For Static and Time-Varying Networks</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2014.2340812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of in-network compressed sensing from distributed
measurements. Every agent has a set of measurements of a signal $x$, and the
objective is for the agents to recover $x$ from their collective measurements
using only communication with neighbors in the network. Our distributed
approach to this problem is based on the centralized Iterative Hard
Thresholding algorithm (IHT). We first present a distributed IHT algorithm for
static networks that leverages standard tools from distributed computing to
execute in-network computations with minimized bandwidth consumption. Next, we
address distributed signal recovery in networks with time-varying topologies.
The network dynamics necessarily introduce inaccuracies to our in-network
computations. To accommodate these inaccuracies, we show how centralized IHT
can be extended to include inexact computations while still providing the same
recovery guarantees as the original IHT algorithm. We then leverage these new
theoretical results to develop a distributed version of IHT for time-varying
networks. Evaluations show that our distributed algorithms for both static and
time-varying networks outperform previously proposed solutions in time and
bandwidth by several orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6096</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6096</id><created>2013-08-28</created><authors><author><keyname>Dewar</keyname><forenames>Robert B. K.</forenames></author><author><keyname>Golumbic</keyname><forenames>Martin Charles</forenames></author><author><keyname>Goss</keyname><forenames>Clinton F.</forenames></author></authors><title>Micro Spitbol</title><categories>cs.PL</categories><comments>Initially published October 1979; Revised August 28, 2013. 8 pages, 3
  figures</comments><msc-class>68N20</msc-class><acm-class>D.3.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A compact version of MACRO SPITBOL, a compiler/ interpreter for a variant of
SNOBOL4, has been developed for use on microcomputer systems. The techniques
for producing an implementation are largely automatic in order to preserve the
integrity and portability of the SPITBOL system. These techniques are discussed
along with a description of an initial implementation on a 65K byte
minicomputer. An interesting theoretical problem which arises when using
procedures which compact the interpretive object code is also analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6111</identifier>
 <datestamp>2014-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6111</id><created>2013-08-28</created><updated>2014-04-08</updated><authors><author><keyname>Dai</keyname><forenames>Xiongping</forenames></author></authors><title>Finer filtration for matrix-valued cocycle based on Oseledec's
  multiplicative ergodic theorem</title><categories>math.DS cs.SY</categories><comments>18 pages</comments><msc-class>37H15, 93D20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we improve the classical multiplicative ergodic theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6118</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6118</id><created>2013-08-28</created><authors><author><keyname>Alupoaie</keyname><forenames>Sorin</forenames></author><author><keyname>Cunningham</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>Using tf-idf as an edge weighting scheme in user-object bipartite
  networks</title><categories>cs.SI cs.IR physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bipartite user-object networks are becoming increasingly popular in
representing user interaction data in a web or e-commerce environment. They
have certain characteristics and challenges that differentiates them from other
bipartite networks. This paper analyzes the properties of five real world
user-object networks. In all cases we found a heavy tail object degree
distribution with popular objects connecting together a large part of the users
causing significant edge inflation in the projected users network. We propose a
novel edge weighting strategy based on tf-idf and show that the new scheme
improves both the density and the quality of the community structure in the
projections. The improvement is also noticed when comparing to partially random
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6138</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6138</id><created>2013-08-28</created><updated>2013-08-29</updated><authors><author><keyname>Phemius</keyname><forenames>K&#xe9;vin</forenames></author><author><keyname>Bouet</keyname><forenames>Mathieu</forenames></author><author><keyname>Leguay</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author></authors><title>DISCO: Distributed Multi-domain SDN Controllers</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern multi-domain networks now span over datacenter networks, enterprise
networks, customer sites and mobile entities. Such networks are critical and,
thus, must be resilient, scalable and easily extensible. The emergence of
Software-Defined Networking (SDN) protocols, which enables to decouple the data
plane from the control plane and dynamically program the network, opens up new
ways to architect such networks. In this paper, we propose DISCO, an open and
extensible DIstributed SDN COntrol plane able to cope with the distributed and
heterogeneous nature of modern overlay networks and wide area networks. DISCO
controllers manage their own network domain and communicate with each others to
provide end-to-end network services. This communication is based on a unique
lightweight and highly manageable control channel used by agents to
self-adaptively share aggregated network-wide information. We implemented DISCO
on top of the Floodlight OpenFlow controller and the AMQP protocol. We
demonstrated how DISCO's control plane dynamically adapts to heterogeneous
network topologies while being resilient enough to survive to disruptions and
attacks and providing classic functionalities such as end-point migration and
network-wide traffic engineering. The experimentation results we present are
organized around three use cases: inter-domain topology disruption, end-to-end
priority service request and virtual machine migration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6145</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6145</id><created>2013-08-28</created><authors><author><keyname>Bonnichsen</keyname><forenames>Lars F.</forenames></author><author><keyname>Karlsson</keyname><forenames>Sven</forenames></author><author><keyname>Probst</keyname><forenames>Christian W.</forenames></author></authors><title>ELB-Trees, An Efficient and Lock-free B-tree Derivative</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical report is an extension of the paper of the same title, which
is to appear at MUCOCOS'13. The technical report proves correctness of the
ELB-trees operations' semantics and that the operations are lock-free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6149</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6149</id><created>2013-08-28</created><authors><author><keyname>O'Callaghan</keyname><forenames>Derek</forenames></author><author><keyname>Greene</keyname><forenames>Derek</forenames></author><author><keyname>Conway</keyname><forenames>Maura</forenames></author><author><keyname>Carthy</keyname><forenames>Joe</forenames></author><author><keyname>Cunningham</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>The Extreme Right Filter Bubble</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>10 pages, 7 figures</comments><acm-class>H.3.3; H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to its status as the most popular video sharing platform, YouTube plays
an important role in the online strategy of extreme right groups, where it is
often used to host associated content such as music and other propaganda. In
this paper, we develop a categorization suitable for the analysis of extreme
right channels found on YouTube. By combining this with an NMF-based topic
modelling method, we categorize channels originating from links propagated by
extreme right Twitter accounts. This method is also used to categorize related
channels, which are determined using results returned by YouTube's related
video service. We identify the existence of a &quot;filter bubble&quot;, whereby users
who access an extreme right YouTube video are highly likely to be recommended
further extreme right content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6166</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6166</id><created>2013-08-28</created><authors><author><keyname>Grigoriev</keyname><forenames>Alexander</forenames></author><author><keyname>Koutsonas</keyname><forenames>Athanassios</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Bidimensionality of Geometric Intersection Graphs</title><categories>cs.DM math.CO</categories><msc-class>05C10, 05C85, 68R10</msc-class><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let B be a finite collection of geometric (not necessarily convex) bodies in
the plane. Clearly, this class of geometric objects naturally generalizes the
class of disks, lines, ellipsoids, and even convex polygons. We consider
geometric intersection graphs GB where each body of the collection B is
represented by a vertex, and two vertices of GB are adjacent if the
intersection of the corresponding bodies is non-empty. For such graph classes
and under natural restrictions on their maximum degree or subgraph exclusion,
we prove that the relation between their treewidth and the maximum size of a
grid minor is linear. These combinatorial results vastly extend the
applicability of all the meta-algorithmic results of the bidimensionality
theory to geometrically defined graph classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6175</identifier>
 <datestamp>2014-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6175</id><created>2013-08-26</created><updated>2014-01-02</updated><authors><author><keyname>Kositwattanarerk</keyname><forenames>Wittawat</forenames></author><author><keyname>Oggier</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames></author></authors><title>Connections Between Construction D and Related Constructions of Lattices</title><categories>cs.IT math.IT</categories><comments>Submitted to Designs, Codes and Cryptography</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most practical constructions of lattice codes with high coding gains are
multilevel constructions where each level corresponds to an underlying code
component. Construction D, Construction D$'$, and Forney's code formula are
classical constructions that produce such lattices explicitly from a family of
nested binary linear codes. In this paper, we investigate these three closely
related constructions along with the recently developed Construction A$'$ of
lattices from codes over the polynomial ring $\mathbb{F}_2[u]/u^a$. We show
that Construction by Code Formula produces a lattice packing if and only if the
nested codes being used are closed under Schur product, thus proving the
similarity of Construction D and Construction by Code Formula when applied to
Reed-Muller codes. In addition, we relate Construction by Code Formula to
Construction A$'$ by finding a correspondence between nested binary codes and
codes over $\mathbb{F}_2[u]/u^a$. This proves that any lattice constructible
using Construction by Code Formula is also constructible using Construction
A$'$. Finally, we show that Construction A$'$ produces a lattice if and only if
the corresponding code over $\mathbb{F}_2[u]/u^a$ is closed under shifted Schur
product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6181</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6181</id><created>2013-08-28</created><authors><author><keyname>Bellon</keyname><forenames>Victor</forenames></author><author><keyname>Cerquides</keyname><forenames>Jesus</forenames></author><author><keyname>Grosse</keyname><forenames>Ivo</forenames></author></authors><title>Bayesian Conditional Gaussian Network Classifiers with Applications to
  Mass Spectra Classification</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classifiers based on probabilistic graphical models are very effective. In
continuous domains, maximum likelihood is usually used to assess the
predictions of those classifiers. When data is scarce, this can easily lead to
overfitting. In any probabilistic setting, Bayesian averaging (BA) provides
theoretically optimal predictions and is known to be robust to overfitting. In
this work we introduce Bayesian Conditional Gaussian Network Classifiers, which
efficiently perform exact Bayesian averaging over the parameters. We evaluate
the proposed classifiers against the maximum likelihood alternatives proposed
so far over standard UCI datasets, concluding that performing BA improves the
quality of the assessed probabilities (conditional log likelihood) whilst
maintaining the error rate.
  Overfitting is more likely to occur in domains where the number of data items
is small and the number of variables is large. These two conditions are met in
the realm of bioinformatics, where the early diagnosis of cancer from mass
spectra is a relevant task. We provide an application of our classification
framework to that problem, comparing it with the standard maximum likelihood
alternative, where the improvement of quality in the assessed probabilities is
confirmed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6198</identifier>
 <datestamp>2015-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6198</id><created>2013-08-28</created><updated>2015-09-25</updated><authors><author><keyname>Jung</keyname><forenames>Taeho</forenames></author><author><keyname>Han</keyname><forenames>Junze</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author></authors><title>PDA: Semantically Secure Time-Series Data Analytics with Dynamic
  Subgroups</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Third-party analysis on private records is becoming increasingly important
due to the widespread data collection for various analysis purposes. However,
the data in its original form often contains sensitive information about
individuals, and its publication will severely breach their privacy. In this
paper, we present a novel Privacy-preserving Data Analytics framework PDA,
which allows a third-party aggregator to obliviously conduct many different
types of polynomial-based analysis on private data records provided by a
dynamic sub-group of users. Notably, every user needs to keep only O(n) keys to
join data analysis among O(2^n) different groups of users, and any data
analysis that is represented by polynomials is supported by our framework.
Besides, a real implementation shows the performance of our framework is
comparable to the peer works who present ad-hoc solutions for specific data
analysis applications. Despite such nice properties of PDA, it is provably
secure against a very powerful attacker (chosen-plaintext attack) even in the
Dolev-Yao network model where all communication channels are insecure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6202</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6202</id><created>2013-08-28</created><updated>2015-01-21</updated><authors><author><keyname>Jung</keyname><forenames>Taeho</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author></authors><title>Enabling Privacy-preserving Auctions in Big Data</title><categories>cs.CR</categories><journal-ref>2015 IEEE Conference on Computer Communications Workshops (INFOCOM
  WKSHPS), pp 173-178</journal-ref><doi>10.1109/INFCOMW.2015.7179380</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We study how to enable auctions in the big data context to solve many
upcoming data-based decision problems in the near future. We consider the
characteristics of the big data including, but not limited to, velocity,
volume, variety, and veracity, and we believe any auction mechanism design in
the future should take the following factors into consideration: 1) generality
(variety); 2) efficiency and scalability (velocity and volume); 3) truthfulness
and verifiability (veracity). In this paper, we propose a privacy-preserving
construction for auction mechanism design in the big data, which prevents
adversaries from learning unnecessary information except those implied in the
valid output of the auction. More specifically, we considered one of the most
general form of the auction (to deal with the variety), and greatly improved
the the efficiency and scalability by approximating the NP-hard problems and
avoiding the design based on garbled circuits (to deal with velocity and
volume), and finally prevented stakeholders from lying to each other for their
own benefit (to deal with the veracity). We achieve these by introducing a
novel privacy-preserving winner determination algorithm and a novel payment
mechanism. Additionally, we further employ a blind signature scheme as a
building block to let bidders verify the authenticity of their payment reported
by the auctioneer. The comparison with peer work shows that we improve the
asymptotic performance of peer works' overhead from the exponential growth to a
linear growth and from linear growth to a logarithmic growth, which greatly
improves the scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6203</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6203</id><created>2013-08-28</created><authors><author><keyname>Georgiou</keyname><forenames>Harris V.</forenames></author></authors><title>Adaptive detection and severity level characterization algorithm for
  Obstructive Sleep Apnea Hypopnea Syndrome (OSAHS) via oximetry signal
  analysis</title><categories>cs.DS</categories><comments>13 pages</comments><report-no>HG/BIOINF.0813.28v1</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, an abstract definition and formal specification is presented
for the task of adaptive-threshold OSAHS events detection and severity
characterization. Specifically, a low-level pseudocode is designed for the
algorithm of raw oximetry signal pre-processing, calculation of the 'drop' and
'rise' frames in the related time series, detection of valid apnea/hypopnea
events via SpO2 saturation level tracking, as well as calculation of
corresponding event rates for OSAHS severity characterization. The designed
algorithm can be used as the first module in a machine learning application
where these data can be used as inputs or encoded into higher-level statistics
(features) for pattern classifiers, in the context of computer-aided or fully
automated diagnosis of OSAHS and related pathologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6206</identifier>
 <datestamp>2013-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6206</id><created>2013-08-28</created><updated>2013-10-17</updated><authors><author><keyname>Teppan</keyname><forenames>Erich Christian</forenames></author><author><keyname>Friedrich</keyname><forenames>Gerhard</forenames></author></authors><title>The Partner Units Configuration Problem: Completing the Picture</title><categories>cs.AI cs.CC</categories><comments>30 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The partner units problem (PUP) is an acknowledged hard benchmark problem for
the Logic Programming community with various industrial application fields like
surveillance, electrical engineering, computer networks or railway safety
systems. However, computational complexity remained widely unclear so far. In
this paper we provide all missing complexity results making the PUP better
exploitable for benchmark testing. Furthermore, we present QuickPup, a
heuristic search algorithm for PUP instances which outperforms all
state-of-the-art solving approaches and which is already in use in real world
industrial configuration environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6207</identifier>
 <datestamp>2014-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6207</id><created>2013-08-28</created><authors><author><keyname>Delfosse</keyname><forenames>Nicolas</forenames></author></authors><title>Decoding color codes by projection onto surface codes</title><categories>quant-ph cs.IT math.IT</categories><comments>24 pages</comments><journal-ref>Phys. Rev. A 89, 012317 (2014)</journal-ref><doi>10.1103/PhysRevA.89.012317</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new strategy to decode color codes, which is based on the
projection of the error onto three surface codes. This provides a method to
transform every decoding algorithm of surface codes into a decoding algorithm
of color codes. Applying this idea to a family of hexagonal color codes, with
the perfect matching decoding algorithm for the three corresponding surface
codes, we find a phase error threshold of approximately 8.7%. Finally, our
approach enables us to establish a general lower bound on the error threshold
of a family of color codes depending on the threshold of the three
corresponding surface codes. These results are based on a chain complex
interpretation of surface codes and color codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6208</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6208</id><created>2013-08-28</created><authors><author><keyname>Yu</keyname><forenames>Rong</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Gjessing</keyname><forenames>Stein</forenames></author><author><keyname>Xia</keyname><forenames>Wenlong</forenames></author><author><keyname>Yang</keyname><forenames>Kun</forenames></author></authors><title>Toward Cloud-based Vehicular Networks with Efficient Resource Management</title><categories>cs.DC cs.NI</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the era of Internet of Things, all components in intelligent
transportation systems will be connected to improve transport safety, relieve
traffic congestion, reduce air pollution and enhance the comfort of driving.
The vision of all vehicles connected poses a significant challenge to the
collection and storage of large amounts of traffic-related data. In this
article, we propose to integrate cloud computing into vehicular networks such
that the vehicles can share computation resources, storage resources and
bandwidth resources. The proposed architecture includes a vehicular cloud, a
roadside cloud, and a central cloud. Then, we study cloud resource allocation
and virtual machine migration for effective resource management in this
cloud-based vehicular network. A game-theoretical approach is presented to
optimally allocate cloud resources. Virtual machine migration due to vehicle
mobility is solved based on a resource reservation scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6216</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6216</id><created>2013-08-28</created><authors><author><keyname>Yu</keyname><forenames>Rong</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Liu</keyname><forenames>Yi</forenames></author><author><keyname>Gjessing</keyname><forenames>Stein</forenames></author><author><keyname>Guizani</keyname><forenames>Mohsen</forenames></author></authors><title>Securing Cognitive Radio Networks against Primary User Emulation Attacks</title><categories>cs.ET cs.NI</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive Radio (CR) is a promising technology for next-generation wireless
networks in order to efficiently utilize the limited spectrum resources and
satisfy the rapidly increasing demand for wireless applications and services.
Security is a very important but not well addressed issue in CR networks. In
this paper we focus on security problems arising from Primary User Emulation
(PUE) attacks in CR networks. We present a comprehensive introduction to PUE
attacks, from the attacking rationale and its impact on CR networks, to
detection and defense approaches. In order to secure CR networks against PUE
attacks, a two-level database-assisted detection approach is proposed to detect
such attacks. Energy detection and location verification are combined for fast
and reliable detection. An admission control based defense approach is proposed
to mitigate the performance degradation of a CR network under a PUE attack.
Illustrative results are presented to demonstrate the effectiveness of the
proposed detection and defense approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6217</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6217</id><created>2013-08-28</created><authors><author><keyname>Kim</keyname><forenames>Sang Hyun</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Numerical Analysis of Gate Conflict Duration and Passenger Transit Time
  in Airport</title><categories>cs.OH</categories><comments>Submitted to Transportation Research Part B, and presented at AIAA
  Guidance, Navigation, and Control Conference in 2011 in part</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robustness is as important as efficiency in air transportation. All
components in the air traffic system are connected to form an interactive
network. So, a disturbance that occurs in one component, for example, a severe
delay at an airport, can influence the entire network. Delays are easily
propagated between flights through gates, but the propagation can be reduced if
gate assignments are robust against stochastic delays. In this paper, we
analyze gate delays and suggest an approach that involves assigning gates while
making them robust against stochastic delays. We extract an example flight
schedule from data source and generate schedules with increased traffic to
analyze how the compact flight schedules impact the robustness of gate
assignment. Simulation results show that our approach improves the robustness
of gate assignment. Particularly, the robust gate assignment reduces average
duration of gate conflicts by 96.3% and the number of gate conflicts by 96.7%
compared to the baseline assignment. However, the robust gate assignment
results in longer transit time for passengers, and a trade-off between the
robustness of gate assignment and passenger transit time is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6220</identifier>
 <datestamp>2014-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6220</id><created>2013-08-28</created><authors><author><keyname>Zhang</keyname><forenames>Jiapu</forenames></author></authors><title>Simulated annealing: in mathematical global optimization computation,
  hybrid with local or global search, and practical applications in
  crystallography and molecular modelling</title><categories>math.OC cs.CE physics.comp-ph</categories><journal-ref>[Simulated Annealing: Strategies, Potential Uses and Advantages,
  Editors Prof. Dr. Marcos Tsuzuki &amp; Prof. Dr. Thiago de Castro Martins, NOVA
  Science Publishers, 2014, ISBN 978-1-63117-268-7], Chapter 1, pp. 1-34</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Simulated annealing (SA) was inspired from annealing in metallurgy, a
technique involving heating and controlled cooling of a material to increase
the size of its crystals and reduce their defects, both are attributes of the
material that depend on its thermodynamic free energy. In this Paper, firstly
we will study SA in details on its practical implementation. Then, hybrid pure
SA with local (or global) search optimization methods allows us to be able to
design several effective and efficient global search optimization methods. In
order to keep the original sense of SA, we clarify our understandings of SA in
crystallography and molecular modeling field through the studies of prion
amyloid fibrils.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6242</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6242</id><created>2013-08-28</created><authors><author><keyname>Mohammad</keyname><forenames>Saif M.</forenames></author><author><keyname>Kiritchenko</keyname><forenames>Svetlana</forenames></author><author><keyname>Zhu</keyname><forenames>Xiaodan</forenames></author></authors><title>NRC-Canada: Building the State-of-the-Art in Sentiment Analysis of
  Tweets</title><categories>cs.CL</categories><journal-ref>In Proceedings of the seventh international workshop on Semantic
  Evaluation Exercises (SemEval-2013), June 2013, Atlanta, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe how we created two state-of-the-art SVM
classifiers, one to detect the sentiment of messages such as tweets and SMS
(message-level task) and one to detect the sentiment of a term within a
submissions stood first in both tasks on tweets, obtaining an F-score of 69.02
in the message-level task and 88.93 in the term-level task. We implemented a
variety of surface-form, semantic, and sentiment features. with sentiment-word
hashtags, and one from tweets with emoticons. In the message-level task, the
lexicon-based features provided a gain of 5 F-score points over all others.
Both of our systems can be replicated us available resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6250</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6250</id><created>2013-08-28</created><authors><author><keyname>Cao</keyname><forenames>Yongcan</forenames></author><author><keyname>Muse</keyname><forenames>Jonathan</forenames></author><author><keyname>Casbeer</keyname><forenames>David</forenames></author><author><keyname>Kingston</keyname><forenames>Derek</forenames></author></authors><title>Circumnavigation of an Unknown Target Using UAVs with Range and Range
  Rate Measurements</title><categories>cs.SY cs.RO math.OC</categories><comments>To appear in IEEE Conference on Decision and Control, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents two control algorithms enabling a UAV to circumnavigate
an unknown target using range and range rate (i.e., the derivative of range)
measurements. Given a prescribed orbit radius, both control algorithms (i) tend
to drive the UAV toward the tangent of prescribed orbit when the UAV is outside
or on the orbit, and (ii) apply zero control input if the UAV is inside the
desired orbit. The algorithms differ in that, the first algorithm is smooth and
unsaturated while the second algorithm is non-smooth and saturated. By
analyzing properties associated with the bearing angle of the UAV relative to
the target and through proper design of Lyapunov functions, it is shown that
both algorithms produce the desired orbit for an arbitrary initial state. Three
examples are provided as a proof of concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6251</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6251</id><created>2013-08-25</created><authors><author><keyname>Niazadeh</keyname><forenames>Rad</forenames></author><author><keyname>Nassirpour</keyname><forenames>Sahar</forenames></author><author><keyname>Shamsollahi</keyname><forenames>Mohammad B.</forenames></author></authors><title>Implementation and optimization of Wavelet modulation in Additive
  Gaussian channels</title><categories>cs.OH</categories><journal-ref>Advanced Communication Technology, 2009. ICACT 2009. 11th
  International Conference on, Pages 1940 - 1943</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the implementation of wavelet modulation (WM)
in a digital communication system and propose novel methods to improve its
performance. We will put particular focus on the structure of an optimal
detector in AWGN channels and address two main methods for inserting the
samples of the message signal in different frequency layers. Finally, computer
based algorithms are described in order to implement and optimize receivers and
transmitters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6255</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6255</id><created>2013-08-28</created><authors><author><keyname>Skibski</keyname><forenames>Oskar</forenames></author><author><keyname>Michalak</keyname><forenames>Tomasz P.</forenames></author><author><keyname>Wooldridge</keyname><forenames>Michael</forenames></author></authors><title>The Shapley Axiomatization for Values in Partition Function Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the long-debated issues in coalitional game theory is how to extend
the Shapley value to games with externalities (partition-function games). When
externalities are present, not only can a player's marginal contribution - a
central notion to the Shapley value - be defined in a variety of ways, but it
is also not obvious which axiomatization should be used. Consequently, a number
of authors extended the Shapley value using complex and often unintuitive
axiomatizations. Furthermore, no algorithm to approximate any extension of the
Shapley value to partition-function games has been proposed to date. Given this
background, we prove in this paper that, for any well-defined measure of
marginal contribution, Shapley's original four axioms imply a unique value for
games with externalities. As an consequence of this general theorem, we show
that values proposed by Macho-Stadler et al., McQuillin and Bolger can be
derived from Shapley's axioms. Building upon our analysis of marginal
contribution, we develop a general algorithm to approximate extensions of the
Shapley value to games with externalities using a Monte Carlo simulation
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6273</identifier>
 <datestamp>2014-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6273</id><created>2013-08-28</created><updated>2014-05-26</updated><authors><author><keyname>Arora</keyname><forenames>Sanjeev</forenames></author><author><keyname>Ge</keyname><forenames>Rong</forenames></author><author><keyname>Moitra</keyname><forenames>Ankur</forenames></author></authors><title>New Algorithms for Learning Incoherent and Overcomplete Dictionaries</title><categories>cs.DS cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sparse recovery we are given a matrix $A$ (the dictionary) and a vector of
the form $A X$ where $X$ is sparse, and the goal is to recover $X$. This is a
central notion in signal processing, statistics and machine learning. But in
applications such as sparse coding, edge detection, compression and super
resolution, the dictionary $A$ is unknown and has to be learned from random
examples of the form $Y = AX$ where $X$ is drawn from an appropriate
distribution --- this is the dictionary learning problem. In most settings, $A$
is overcomplete: it has more columns than rows. This paper presents a
polynomial-time algorithm for learning overcomplete dictionaries; the only
previously known algorithm with provable guarantees is the recent work of
Spielman, Wang and Wright who gave an algorithm for the full-rank case, which
is rarely the case in applications. Our algorithm applies to incoherent
dictionaries which have been a central object of study since they were
introduced in seminal work of Donoho and Huo. In particular, a dictionary is
$\mu$-incoherent if each pair of columns has inner product at most $\mu /
\sqrt{n}$.
  The algorithm makes natural stochastic assumptions about the unknown sparse
vector $X$, which can contain $k \leq c \min(\sqrt{n}/\mu \log n, m^{1/2
-\eta})$ non-zero entries (for any $\eta &gt; 0$). This is close to the best $k$
allowable by the best sparse recovery algorithms even if one knows the
dictionary $A$ exactly. Moreover, both the running time and sample complexity
depend on $\log 1/\epsilon$, where $\epsilon$ is the target accuracy, and so
our algorithms converge very quickly to the true dictionary. Our algorithm can
also tolerate substantial amounts of noise provided it is incoherent with
respect to the dictionary (e.g., Gaussian). In the noisy setting, our running
time and sample complexity depend polynomially on $1/\epsilon$, and this is
necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6276</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6276</id><created>2013-08-28</created><authors><author><keyname>Browet</keyname><forenames>Arnaud</forenames></author><author><keyname>Absil</keyname><forenames>P. -A.</forenames></author><author><keyname>Van Dooren</keyname><forenames>Paul</forenames></author></authors><title>Fast community detection using local neighbourhood search</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communities play a crucial role to describe and analyse modern networks.
However, the size of those networks has grown tremendously with the increase of
computational power and data storage. While various methods have been developed
to extract community structures, their computational cost or the difficulty to
parallelize existing algorithms make partitioning real networks into
communities a challenging problem. In this paper, we propose to alter an
efficient algorithm, the Louvain method, such that communities are defined as
the connected components of a tree-like assignment graph. Within this
framework, we precisely describe the different steps of our algorithm and
demonstrate its highly parallelizable nature. We then show that despite its
simplicity, our algorithm has a partitioning quality similar to the original
method on benchmark graphs and even outperforms other algorithms. We also show
that, even on a single processor, our method is much faster and allows the
analysis of very large networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6292</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6292</id><created>2013-08-28</created><authors><author><keyname>Hariri</keyname><forenames>Babak Bagheri</forenames></author><author><keyname>Calvanese</keyname><forenames>Diego</forenames></author><author><keyname>Montali</keyname><forenames>Marco</forenames></author><author><keyname>Santoso</keyname><forenames>Ario</forenames></author><author><keyname>Solomakhin</keyname><forenames>Dmitry</forenames></author></authors><title>Verification of Semantically-Enhanced Artifact Systems (Extended
  Version)</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artifact-Centric systems have emerged in the last years as a suitable
framework to model business-relevant entities, by combining their static and
dynamic aspects. In particular, the Guard-Stage-Milestone (GSM) approach has
been recently proposed to model artifacts and their lifecycle in a declarative
way. In this paper, we enhance GSM with a Semantic Layer, constituted by a
full-fledged OWL 2 QL ontology linked to the artifact information models
through mapping specifications. The ontology provides a conceptual view of the
domain under study, and allows one to understand the evolution of the artifact
system at a higher level of abstraction. In this setting, we present a
technique to specify temporal properties expressed over the Semantic Layer, and
verify them according to the evolution in the underlying GSM model. This
technique has been implemented in a tool that exploits state-of-the-art
ontology-based data access technologies to manipulate the temporal properties
according to the ontology and the mappings, and that relies on the GSMC model
checker for verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6295</identifier>
 <datestamp>2015-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6295</id><created>2013-08-28</created><updated>2015-02-06</updated><authors><author><keyname>Amancio</keyname><forenames>Diego R.</forenames></author><author><keyname>Oliveira</keyname><forenames>Osvaldo N.</forenames><suffix>Jr.</suffix></author><author><keyname>Costa</keyname><forenames>Luciano da F.</forenames></author></authors><title>Robustness of community structure to node removal</title><categories>physics.soc-ph cs.SI</categories><journal-ref>J. Stat. Mech. (2015) P03003</journal-ref><doi>10.1088/1742-5468/2015/03/P03003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The identification of modular structures is essential for characterizing real
networks formed by a mesoscopic level of organization where clusters contain
nodes with a high internal degree of connectivity. Many methods have been
developed to unveil community structures, but only a few studies have probed
their suitability in incomplete networks. Here we assess the accuracy of
community detection techniques in incomplete networks generated in sampling
processes. We show that the walktrap and fast greedy algorithms are highly
accurate for detecting the modular structure of incomplete complex networks
even if many of their nodes are removed. Furthermore, we implemented an
approach that improved the time performance of the walktrap and fast greedy
algorithms, while retaining the accuracy rate in identifying the community
membership of nodes. Taken together our results show that this new approach can
be applied to speed up virtually any community detection method in dense
complex networks, as it is the case of similarity networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6297</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6297</id><created>2013-08-28</created><authors><author><keyname>Mohammad</keyname><forenames>Saif M.</forenames></author><author><keyname>Turney</keyname><forenames>Peter D.</forenames></author></authors><title>Crowdsourcing a Word-Emotion Association Lexicon</title><categories>cs.CL</categories><journal-ref>Computational Intelligence, 29 (3), 436-465, Wiley Blackwell
  Publishing Ltd, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even though considerable attention has been given to the polarity of words
(positive and negative) and the creation of large polarity lexicons, research
in emotion analysis has had to rely on limited and small emotion lexicons. In
this paper we show how the combined strength and wisdom of the crowds can be
used to generate a large, high-quality, word-emotion and word-polarity
association lexicon quickly and inexpensively. We enumerate the challenges in
emotion annotation in a crowdsourcing scenario and propose solutions to address
them. Most notably, in addition to questions about emotions associated with
terms, we show how the inclusion of a word choice question can discourage
malicious data entry, help identify instances where the annotator may not be
familiar with the target term (allowing us to reject such annotations), and
help obtain annotations at sense level (rather than at word level). We
conducted experiments on how to formulate the emotion-annotation questions, and
show that asking if a term is associated with an emotion leads to markedly
higher inter-annotator agreement than that obtained by asking if a term evokes
an emotion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6300</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6300</id><created>2013-08-28</created><authors><author><keyname>Mohammad</keyname><forenames>Saif M.</forenames></author><author><keyname>Dorr</keyname><forenames>Bonnie J.</forenames></author><author><keyname>Hirst</keyname><forenames>Graeme</forenames></author><author><keyname>Turney</keyname><forenames>Peter D.</forenames></author></authors><title>Computing Lexical Contrast</title><categories>cs.CL</categories><journal-ref>Computational Linguistics, 39 (3), 555-590, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowing the degree of semantic contrast between words has widespread
application in natural language processing, including machine translation,
information retrieval, and dialogue systems. Manually-created lexicons focus on
opposites, such as {\rm hot} and {\rm cold}. Opposites are of many kinds such
as antipodals, complementaries, and gradable. However, existing lexicons often
do not classify opposites into the different kinds. They also do not explicitly
list word pairs that are not opposites but yet have some degree of contrast in
meaning, such as {\rm warm} and {\rm cold} or {\rm tropical} and {\rm
freezing}. We propose an automatic method to identify contrasting word pairs
that is based on the hypothesis that if a pair of words, $A$ and $B$, are
contrasting, then there is a pair of opposites, $C$ and $D$, such that $A$ and
$C$ are strongly related and $B$ and $D$ are strongly related. (For example,
there exists the pair of opposites {\rm hot} and {\rm cold} such that {\rm
tropical} is related to {\rm hot,} and {\rm freezing} is related to {\rm
cold}.) We will call this the contrast hypothesis. We begin with a large
crowdsourcing experiment to determine the amount of human agreement on the
concept of oppositeness and its different kinds. In the process, we flesh out
key features of different kinds of opposites. We then present an automatic and
empirical measure of lexical contrast that relies on the contrast hypothesis,
corpus statistics, and the structure of a {\it Roget}-like thesaurus. We show
that the proposed measure of lexical contrast obtains high precision and large
coverage, outperforming existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6309</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6309</id><created>2013-08-28</created><authors><author><keyname>Zaghden</keyname><forenames>Nizar</forenames></author><author><keyname>Khelifi</keyname><forenames>Badreddine</forenames></author><author><keyname>Alimi</keyname><forenames>Adel M.</forenames></author><author><keyname>Mullot</keyname><forenames>Remy</forenames></author></authors><title>Text recognition in both ancient and cartographic documents</title><categories>cs.CV</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the recognition and matching of text in both
cartographic maps and ancient documents. The purpose of this work is to find
similar text regions based on statistical and global features. A phase of
normalization is done first, in object to well categorize the same quantity of
information. A phase of wordspotting is done next by combining local and global
features. We make different experiments by combining the different techniques
of extracting features in order to obtain better results in recognition phase.
We applied fontspotting on both ancient documents and cartographic ones. We
also applied the wordspotting in which we adopted a new technique which tries
to compare the images of character and not the entire images words. We present
the precision and recall values obtained with three methods for the new method
of wordspotting applied on characters only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6311</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6311</id><created>2013-08-28</created><authors><author><keyname>Zaghden</keyname><forenames>Nizar</forenames></author><author><keyname>Mullot</keyname><forenames>Remy</forenames></author><author><keyname>Alimi</keyname><forenames>Mohamed Adel</forenames></author></authors><title>Categorizing ancient documents</title><categories>cs.CV</categories><comments>10 pages</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 2, No 2, March 2013 ISSN (Print): 1694-0814 | ISSN (Online): 1694-0784
  www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of historical documents is still a topical issue given the
importance of information that can be extracted and also the importance given
by the institutions to preserve their heritage. The main idea in order to
characterize the content of the images of ancient documents after attempting to
clean the image is segmented blocks texts from the same image and tries to find
similar blocks in either the same image or the entire image database. Most
approaches of offline handwriting recognition proceed by segmenting words into
smaller pieces (usually characters) which are recognized separately.
Recognition of a word then requires the recognition of all characters (OCR)
that compose it. Our work focuses mainly on the characterization of classes in
images of old documents. We use Som toolbox for finding classes in documents.
We applied also fractal dimensions and points of interest to categorize and
match ancient documents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6316</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6316</id><created>2013-08-28</created><authors><author><keyname>Amuru</keyname><forenames>SaiDhiraj</forenames></author><author><keyname>Tandon</keyname><forenames>Ravi</forenames></author><author><keyname>Buehrer</keyname><forenames>R. Michael</forenames></author><author><keyname>Clancy</keyname><forenames>T. Charles</forenames></author></authors><title>Retroactive Anti-Jamming for MISO Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Jamming attacks can significantly impact the performance of wireless
communication systems. In addition to reducing the capacity, such attacks may
lead to insurmountable overhead in terms of re-transmissions and increased
power consumption. In this paper, we consider the multiple-input single-output
(MISO) broadcast channel (BC) in the presence of a jamming attack in which a
subset of the receivers can be jammed at any given time. Further,
countermeasures for mitigating the effects of such jamming attacks are
presented. The effectiveness of these anti-jamming countermeasures is
quantified in terms of the degrees-of-freedom (DoF) of the MISO BC under
various assumptions regarding the availability of the channel state information
(CSIT) and the jammer state information at the transmitter (JSIT). The main
contribution of this paper is the characterization of the DoF region of the two
user MISO BC under various assumptions on the availability of CSIT and JSIT.
Partial extensions to the multi-user broadcast channels are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6319</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6319</id><created>2013-08-28</created><authors><author><keyname>Zaghden</keyname><forenames>Nizar</forenames></author><author><keyname>Mullot</keyname><forenames>Remy</forenames></author><author><keyname>Alimi</keyname><forenames>Mohamed Adel</forenames></author></authors><title>A proposition of a robust system for historical document images
  indexation</title><categories>cs.CV</categories><comments>7 pages</comments><journal-ref>International Journal of Computer Applications, volume 11 N 2,
  December 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Characterizing noisy or ancient documents is a challenging problem up to now.
Many techniques have been done in order to effectuate feature extraction and
image indexation for such documents. Global approaches are in general less
robust and exact than local approaches. That's why, we propose in this paper, a
hybrid system based on global approach(fractal dimension), and a local one
based on SIFT descriptor. The Scale Invariant Feature Transform seems to do
well with our application since it's rotation invariant and relatively robust
to changing illumination.In the first step the calculation of fractal dimension
is applied to images in order to eliminate images which have distant features
than image request characteristics. Next, the SIFT is applied to show which
images match well the request. However the average matching time using the
hybrid approach is better than &quot;fractal dimension&quot; and &quot;SIFT descriptor&quot; if
they are used alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6320</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6320</id><created>2013-08-28</created><authors><author><keyname>Lemoine</keyname><forenames>Grady I.</forenames></author></authors><title>Three-Dimensional Mapped-Grid Finite Volume Modeling of
  Poroelastic-Fluid Wave Propagation</title><categories>math.NA cs.NA</categories><comments>28 pages, 7 tables, 4 figures</comments><msc-class>65M08, 74S10, 74F10, 74J10, 74L05, 74L15, 86-08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends the author's previous two-dimensional work with Ou and
LeVeque to high-resolution finite volume modeling of systems of fluids and
poroelastic media in three dimensions, using logically rectangular mapped
grids. A method is described for calculating consistent cell face areas and
normal vectors for a finite volume method on a general non-rectilinear
hexahedral grid. A novel limiting algorithm is also developed to cope with
difficulties encountered in implementing high-resolution finite volume methods
for anisotropic media on non-rectilinear grids; the new limiting approach is
compatible with any limiter function, and typically reduces solution error even
in situations where it is not necessary for correct functioning of the
numerical method. Dimensional splitting is used to reduce the computational
cost of the solution. The code implementing the three-dimensional algorithms is
verified against known plane wave solutions, with particular attention to the
performance of the new limiter algorithm in comparison to the classical one. An
acoustic wave in brine striking an uneven bed of orthotropic layered sandstone
is also simulated in order to demonstrate the capabilities of the simulation
code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6324</identifier>
 <datestamp>2013-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6324</id><created>2013-08-28</created><updated>2013-10-30</updated><authors><author><keyname>Tomczak</keyname><forenames>Jakub M.</forenames></author></authors><title>Prediction of breast cancer recurrence using Classification Restricted
  Boltzmann Machine with Dropping</title><categories>cs.LG</categories><comments>technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we apply Classification Restricted Boltzmann Machine
(ClassRBM) to the problem of predicting breast cancer recurrence. According to
the Polish National Cancer Registry, in 2010 only, the breast cancer caused
almost 25% of all diagnosed cases of cancer in Poland. We propose how to use
ClassRBM for predicting breast cancer return and discovering relevant inputs
(symptoms) in illness reappearance. Next, we outline a general probabilistic
framework for learning Boltzmann machines with masks, which we refer to as
Dropping. The fashion of generating masks leads to different learning methods,
i.e., DropOut, DropConnect. We propose a new method called DropPart which is a
generalization of DropConnect. In DropPart the Beta distribution instead of
Bernoulli distribution in DropConnect is used. At the end, we carry out an
experiment using real-life dataset consisting of 949 cases, provided by the
Institute of Oncology Ljubljana.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6337</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6337</id><created>2013-08-28</created><authors><author><keyname>Zhang</keyname><forenames>Hui</forenames></author><author><keyname>Cheng</keyname><forenames>Lizhi</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>A dual algorithm for a class of augmented convex models</title><categories>math.OC cs.IT math.IT</categories><comments>9 pages, submitted</comments><msc-class>65K05, 65F22</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convex optimization models find interesting applications, especially in
signal/image processing and compressive sensing. We study some augmented convex
models, which are perturbed by strongly convex functions, and propose a dual
gradient algorithm. The proposed algorithm includes the linearized Bregman
algorithm and the singular value thresholding algorithm as special cases. Based
on fundamental properties of proximal operators, we present a concise approach
to establish the convergence of both primal and dual sequences, improving the
results in the existing literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6339</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6339</id><created>2013-08-28</created><authors><author><keyname>Zhang</keyname><forenames>Hui</forenames></author><author><keyname>Cheng</keyname><forenames>Lizhi</forenames></author></authors><title>New bounds for circulant Johnson-Lindenstrauss embeddings</title><categories>cs.IT math.FA math.IT</categories><comments>11 pages; accepted by Communications in Mathematical Sciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes circulant Johnson-Lindenstrauss (JL) embeddings which, as
an important class of structured random JL embeddings, are formed by
randomizing the column signs of a circulant matrix generated by a random
vector. With the help of recent decoupling techniques and matrix-valued
Bernstein inequalities, we obtain a new bound
$k=O(\epsilon^{-2}\log^{(1+\delta)} (n))$ for Gaussian circulant JL embeddings.
Moreover, by using the Laplace transform technique (also called Bernstein's
trick), we extend the result to subgaussian case. The bounds in this paper
offer a small improvement over the current best bounds for Gaussian circulant
JL embeddings for certain parameter regimes and are derived using more direct
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6342</identifier>
 <datestamp>2014-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6342</id><created>2013-08-28</created><updated>2014-02-05</updated><authors><author><keyname>Mizrahi</keyname><forenames>Yariv Dror</forenames></author><author><keyname>Denil</keyname><forenames>Misha</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>Linear and Parallel Learning of Markov Random Fields</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new embarrassingly parallel parameter learning algorithm for
Markov random fields with untied parameters which is efficient for a large
class of practical models. Our algorithm parallelizes naturally over cliques
and, for graphs of bounded degree, its complexity is linear in the number of
cliques. Unlike its competitors, our algorithm is fully parallel and for
log-linear models it is also data efficient, requiring only the local
sufficient statistics of the data to estimate parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6356</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6356</id><created>2013-08-28</created><authors><author><keyname>Homan</keyname><forenames>Christopher M.</forenames></author><author><keyname>Silenzio</keyname><forenames>Vincent</forenames></author><author><keyname>Sell</keyname><forenames>Randall</forenames></author></authors><title>Respondent-Driven Sampling in Online Social Networks</title><categories>cs.SI stat.AP</categories><journal-ref>Social Computing, Behavioral-Cultural Modeling and Prediction
  Lecture Notes in Computer Science Volume 7812, 2013, pp 403-411</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Respondent-driven sampling (RDS) is a commonly used method for acquiring data
on hidden communities, i.e., those that lack unbiased sampling frames or face
social stigmas that make their mem- bers unwilling to identify themselves.
Obtaining accurate statistical data about such communities is important
because, for instance, they often have different health burdens from the
greater population, and without good statistics it is hard and expensive to
effectively reach them for pre- vention or treatment interventions. Online
social networks (OSN) have the potential to transform RDS for the better. We
present a new RDS recruitment protocol for (OSNs) and show via simulation that
it out- performs the standard RDS protocol in terms of sampling accuracy and
approaches the accuracy of Markov chain Monte Carlo random walks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6363</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6363</id><created>2013-08-29</created><authors><author><keyname>James</keyname><forenames>Joshua I.</forenames></author><author><keyname>Jang</keyname><forenames>Yunsik Jake</forenames></author></authors><title>Measuring digital crime investigation capacity to guide international
  crime prevention strategies</title><categories>cs.CY</categories><comments>7 pages, 3 figures, Presented at FutureTech 2013</comments><journal-ref>Future Information Technology. Springer Berlin Heidelberg, 2014.
  361-366</journal-ref><doi>10.1007/978-3-642-40861-8_51</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This work proposes a method for the measurement of a country's digital
investigation capacity and saturation for the assessment of future capacity
expansion. The focus is on external, or international, partners being a factor
that could negatively affect the return on investment when attempting to expand
investigation capacity nationally. This work concludes with the argument that
when dealing with digital crime, target international partners should be a
consideration in expansion, and could potentially be a bottleneck of
investigation requests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6368</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6368</id><created>2013-08-29</created><authors><author><keyname>Kieffer</keyname><forenames>Steve</forenames></author><author><keyname>Dwyer</keyname><forenames>Tim</forenames></author><author><keyname>Marriott</keyname><forenames>Kim</forenames></author><author><keyname>Wybrow</keyname><forenames>Michael</forenames></author></authors><title>Incremental Grid-like Layout Using Soft and Hard Constraints</title><categories>cs.HC</categories><comments>Accepted to Graph Drawing 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore various techniques to incorporate grid-like layout conventions
into a force-directed, constraint-based graph layout framework. In doing so we
are able to provide high-quality layout---with predominantly axis-aligned
edges---that is more flexible than previous grid-like layout methods and which
can capture layout conventions in notations such as SBGN (Systems Biology
Graphical Notation). Furthermore, the layout is easily able to respect
user-defined constraints and adapt to interaction in online systems and diagram
editors such as Dunnart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6373</identifier>
 <datestamp>2014-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6373</id><created>2013-08-29</created><updated>2014-05-22</updated><authors><author><keyname>Wolfmann</keyname><forenames>Jacques</forenames><affiliation>IMATH</affiliation></author></authors><title>Special Bent and Near-bent Functions</title><categories>cs.IT math.IT</categories><proxy>ccsd</proxy><journal-ref>Advances in Mathematics of Communications, 8, 1 (2014) 21-33</journal-ref><doi>10.3934/amc.2013.8.21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting from special near-bent functions in dimension 2t-1 we construct bent
functions in dimension 2t having a specific derivative. We deduce new famillies
of bent functions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6384</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6384</id><created>2013-08-29</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Doerr</keyname><forenames>Carola</forenames></author></authors><title>Collecting Coupons with Random Initial Stake</title><categories>cs.DM cs.DS cs.NE</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a problem in the theory of randomized search heuristics, we give
a very precise analysis for the coupon collector problem where the collector
starts with a random set of coupons (chosen uniformly from all sets).
  We show that the expected number of rounds until we have a coupon of each
type is $nH_{n/2} - 1/2 \pm o(1)$, where $H_{n/2}$ denotes the $(n/2)$th
harmonic number when $n$ is even, and $H_{n/2}:= (1/2) H_{\lfloor n/2 \rfloor}
+ (1/2) H_{\lceil n/2 \rceil}$ when $n$ is odd. Consequently, the coupon
collector with random initial stake is by half a round faster than the one
starting with exactly $n/2$ coupons (apart from additive $o(1)$ terms).
  This result implies that classic simple heuristic called \emph{randomized
local search} needs an expected number of $nH_{n/2} - 1/2 \pm o(1)$ iterations
to find the optimum of any monotonic function defined on bit-strings of length
$n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6388</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6388</id><created>2013-08-29</created><authors><author><keyname>Liu</keyname><forenames>Zhi-Yong</forenames></author><author><keyname>Qiao</keyname><forenames>Hong</forenames></author></authors><title>GNCGCP - Graduated NonConvexity and Graduated Concavity Procedure</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose the Graduated NonConvexity and Graduated Concavity
Procedure (GNCGCP) as a general optimization framework to approximately solve
the combinatorial optimization problems on the set of partial permutation
matrices. GNCGCP comprises two sub-procedures, graduated nonconvexity (GNC)
which realizes a convex relaxation and graduated concavity (GC) which realizes
a concave relaxation. It is proved that GNCGCP realizes exactly a type of
convex-concave relaxation procedure (CCRP), but with a much simpler formulation
without needing convex or concave relaxation in an explicit way. Actually,
GNCGCP involves only the gradient of the objective function and is therefore
very easy to use in practical applications. Two typical NP-hard problems,
(sub)graph matching and quadratic assignment problem (QAP), are employed to
demonstrate its simplicity and state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6401</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6401</id><created>2013-08-29</created><authors><author><keyname>Hammoudi</keyname><forenames>Karim</forenames></author><author><keyname>Dornaika</keyname><forenames>Fadi</forenames></author><author><keyname>Soheilian</keyname><forenames>Bahman</forenames></author><author><keyname>Vallet</keyname><forenames>Bruno</forenames></author><author><keyname>McDonald</keyname><forenames>John</forenames></author><author><keyname>Paparoditis</keyname><forenames>Nicolas</forenames></author></authors><title>A Synergistic Approach for Recovering Occlusion-Free Textured 3D Maps of
  Urban Facades from Heterogeneous Cartographic Data</title><categories>cs.CV</categories><acm-class>I.4; I.5</acm-class><journal-ref>International Journal of Advanced Robotic Systems, vol. 10, 10p.,
  2013</journal-ref><doi>10.5772/56570</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we present a practical approach for generating an
occlusion-free textured 3D map of urban facades by the synergistic use of
terrestrial images, 3D point clouds and area-based information. Particularly in
dense urban environments, the high presence of urban objects in front of the
facades causes significant difficulties for several stages in computational
building modeling. Major challenges lie on the one hand in extracting complete
3D facade quadrilateral delimitations and on the other hand in generating
occlusion-free facade textures. For these reasons, we describe a
straightforward approach for completing and recovering facade geometry and
textures by exploiting the data complementarity of terrestrial multi-source
imagery and area-based information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6413</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6413</id><created>2013-08-29</created><authors><author><keyname>Pantazoglou</keyname><forenames>Michael</forenames></author></authors><title>Development of a language and its enacting engine for the unified
  discovery of heterogeneous services</title><categories>cs.SE</categories><comments>PhD Dissertation, November 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service orientation fosters a high-level model for distributed applications
development, which is based on the discovery, composition and reuse of existing
software services. However, the heterogeneity among current service-oriented
technologies renders the important task of service discovery tedious and
ineffective. This dissertation proposes a new approach to address this
challenge. Specifically, it contributes a framework supporting the unified
discovery of heterogeneous services, with a focus on web, peer-to-peer, and
grid services. The framework comprises a service query language and its
enacting service discovery engine. Overall, the proposed solution is
characterized by generality and flexibility, which are ensured by appropriate
abstractions, extension points, and their sup- porting mechanisms. The
viability, performance, and effectiveness of the proposed framework are
demonstrated by experimental measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6415</identifier>
 <datestamp>2013-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6415</id><created>2013-08-29</created><updated>2013-10-09</updated><authors><author><keyname>Roberts</keyname><forenames>Jonathan</forenames></author><author><keyname>Chen</keyname><forenames>Ke</forenames></author></authors><title>Learning-Based Procedural Content Generation</title><categories>cs.AI cs.HC cs.LG cs.NE</categories><comments>13 pages, 9 figures, manuscript submitted to IEEE Transactions on
  Computational Intelligence and AI Games (Also a technical report, School of
  Computer Science, The University of Manchester)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Procedural content generation (PCG) has recently become one of the hottest
topics in computational intelligence and AI game researches. Among a variety of
PCG techniques, search-based approaches overwhelmingly dominate PCG development
at present. While SBPCG leads to promising results and successful applications,
it poses a number of challenges ranging from representation to evaluation of
the content being generated. In this paper, we present an alternative yet
generic PCG framework, named learning-based procedure content generation
(LBPCG), to provide potential solutions to several challenging problems in
existing PCG techniques. By exploring and exploiting information gained in game
development and public beta test via data-driven learning, our framework can
generate robust content adaptable to end-user or target players on-line with
minimal interruption to their experience. Furthermore, we develop enabling
techniques to implement the various models required in our framework. For a
proof of concept, we have developed a prototype based on the classic open
source first-person shooter game, Quake. Simulation results suggest that our
framework is promising in generating quality content.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6432</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6432</id><created>2013-08-29</created><updated>2013-12-30</updated><authors><author><keyname>Tabarraie</keyname><forenames>Mehrdad</forenames></author></authors><title>Robust L_infinity-induced deconvolution filtering for linear stochastic
  systems and its application to fault reconstruction</title><categories>cs.SY</categories><comments>Corrected typos</comments><doi>10.1016/j.sigpro.2012.10.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of stationary robust L_infinity-induced deconvolution filtering
for the uncertain continuous-time linear stochastic systems is addressed. The
state space model of the system contains state- and input-dependent noise and
deterministic parameter uncertainties residing in a given polytope. In the
presence of input-dependent noise, we extend the derived lemma in Berman and
Shaked (2010) characterizing the induced L_infinity norm by linear matrix
inequalities (LMIs), according to which we solve the deconvolution problem in
the quadratic framework. By decoupling product terms between the Lyapunov
matrix and system matrices, an improved version of the proposed
L_infinity-induced norm bound lemma for continuous-time stochastic systems is
obtained, which allows us to realize exploit parameter-dependent stability idea
in the deconvolution filter design. The theories presented are utilized for
sensor fault reconstruction in uncertain linear stochastic systems. The
effectiveness and advantages of the proposed design methods are shown via two
numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6433</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6433</id><created>2013-08-29</created><authors><author><keyname>Diot</keyname><forenames>Emilie</forenames></author><author><keyname>Tavenas</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>Detecting wheels</title><categories>cs.DM math.CO</categories><msc-class>05C75</msc-class><journal-ref>Applicable Analysis and Discrete Mathematics, 8:111-122, 2014</journal-ref><doi>10.2298/AADM131128023D</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A \emph{wheel} is a graph made of a cycle of length at least~4 together with
a vertex that has at least three neighbors in the cycle. We prove that the
problem whose instance is a graph $G$ and whose question is &quot;does $G$ contains
a wheel as an induced subgraph&quot; is NP-complete. We also settle the complexity
of several similar problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6437</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6437</id><created>2013-08-29</created><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Bianchi</keyname><forenames>Marco</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author></authors><title>Coding with Scrambling, Concatenation, and HARQ for the AWGN Wire-Tap
  Channel: A Security Gap Analysis</title><categories>cs.IT math.IT</categories><comments>29 pages, 10 figures</comments><journal-ref>IEEE Transactions on Information Forensics &amp; Security, ISSN
  1556-6013, Vol. 7, No. 3, pp. 883-894, June 2012</journal-ref><doi>10.1109/TIFS.2012.2187515</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study examines the use of nonsystematic channel codes to obtain secure
transmissions over the additive white Gaussian noise (AWGN) wire-tap channel.
Unlike the previous approaches, we propose to implement nonsystematic coded
transmission by scrambling the information bits, and characterize the bit error
rate of scrambled transmissions through theoretical arguments and numerical
simulations. We have focused on some examples of Bose-Chaudhuri-Hocquenghem
(BCH) and low-density parity-check (LDPC) codes to estimate the security gap,
which we have used as a measure of physical layer security, in addition to the
bit error rate. Based on a number of numerical examples, we found that such a
transmission technique can outperform alternative solutions. In fact, when an
eavesdropper (Eve) has a worse channel than the authorized user (Bob), the
security gap required to reach a given level of security is very small. The
amount of degradation of Eve's channel with respect to Bob's that is needed to
achieve sufficient security can be further reduced by implementing scrambling
and descrambling operations on blocks of frames, rather than on single frames.
While Eve's channel has a quality equal to or better than that of Bob's
channel, we have shown that the use of a hybrid automatic repeat-request (HARQ)
protocol with authentication still allows achieving a sufficient level of
security. Finally, the secrecy performance of some practical schemes has also
been measured in terms of the equivocation rate about the message at the
eavesdropper and compared with that of ideal codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6444</identifier>
 <datestamp>2015-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6444</id><created>2013-08-29</created><authors><author><keyname>Chudnovsky</keyname><forenames>Maria</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author><author><keyname>Trunck</keyname><forenames>Th&#xe9;ophile</forenames></author><author><keyname>Vuskovic</keyname><forenames>Kristina</forenames></author></authors><title>Coloring perfect graphs with no balanced skew-partitions</title><categories>cs.DM</categories><msc-class>05C17</msc-class><journal-ref>Journal of Combinatorial Theory, Series B 115:26-65, 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an $O(n^5)$ algorithm that computes a maximum stable set of any
perfect graph with no balanced skew-partition. We present $O(n^7)$ time
algorithm that colors them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6447</identifier>
 <datestamp>2015-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6447</id><created>2013-08-29</created><updated>2015-05-17</updated><authors><author><keyname>Rahaman</keyname><forenames>Ramij</forenames></author><author><keyname>Parker</keyname><forenames>Matthew G.</forenames></author><author><keyname>Mironowicz</keyname><forenames>Piotr</forenames></author><author><keyname>Paw&#x142;owski</keyname><forenames>Marcin</forenames></author></authors><title>Device-independent quantum key distribution based on measurement inputs</title><categories>quant-ph cs.CR</categories><comments>10 pages, 5 figure: In this modified version of the manuscript we
  have added a new section to show fact that our protocol is much better than
  the standard ones when the random number generators used by the parties are
  imperfect</comments><journal-ref>Phys. Rev. A 92, 062304 (2015)</journal-ref><doi>10.1103/PhysRevA.92.062304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an analysis of a new family of device independent quantum key
distribution (QKD) protocols with several novel features: (a) The bits used for
the secret key do not come from the results of the measurements on an entangled
state but from the choices of settings; (b) Instead of a single security
parameter (a violation of some Bell inequality) a set of them is used to
estimate the level of trust in the secrecy of the key. The main advantage of
these protocols is a smaller vulnerability to imperfect random number
generators made possible by feature (a). We prove the security and the
robustness of such protocols. We show that using our method it is possible to
construct a QKD protocol which retains its security even if the source of
randomness used by communicating parties is strongly biased. As a proof of
principle, an explicit example of a protocol based on the Hardy's paradox is
presented. Moreover, in the noiseless case, the protocol is secure in a natural
way against any type of memory attack, and thus allows to reuse the device in
subsequent rounds. We also analyse the robustness of the protocol using
semi-definite programming methods. Finally, we present a post-processing
method, and observe a paradoxical property that rejecting some random part of
the private data can increase the key rate of the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6464</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6464</id><created>2013-08-29</created><authors><author><keyname>Sau</keyname><forenames>Buddhadeb</forenames></author><author><keyname>Mukhopadhyaya</keyname><forenames>Krishnendu</forenames></author></authors><title>Localizability of Wireless Sensor Networks: Beyond Wheel Extension</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network is called localizable if the positions of all the nodes of the
network can be computed uniquely. If a network is localizable and embedded in
plane with generic configuration, the positions of the nodes may be computed
uniquely in finite time. Therefore, identifying localizable networks is an
important function. If the complete information about the network is available
at a single place, localizability can be tested in polynomial time. In a
distributed environment, networks with trilateration orderings (popular in real
applications) and wheel extensions (a specific class of localizable networks)
embedded in plane can be identified by existing techniques. We propose a
distributed technique which efficiently identifies a larger class of
localizable networks. This class covers both trilateration and wheel
extensions. In reality, exact distance is almost impossible or costly. The
proposed algorithm based only on connectivity information. It requires no
distance information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6469</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6469</id><created>2013-08-29</created><authors><author><keyname>van Stralen</keyname><forenames>P.</forenames></author></authors><title>Using Chip Multithreading to Speed Up Scenario-Based Design Space
  Exploration</title><categories>cs.PF</categories><msc-class>68U07</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To cope with the complex embedded system design, early design space
exploration (DSE) is used to make design decisions early in the design phase.
For early DSE it is crucial that the running time of the exploration is as
small as possible. In this paper, we describe both the porting of our
scenario-based DSE to the SPARC T3-4 server and the analysis of its performance
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6475</identifier>
 <datestamp>2014-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6475</id><created>2013-08-29</created><updated>2014-03-25</updated><authors><author><keyname>Petig</keyname><forenames>Thomas</forenames></author><author><keyname>Schiller</keyname><forenames>Elad M.</forenames></author><author><keyname>Tsigas</keyname><forenames>Philippas</forenames></author></authors><title>Self-stabilizing TDMA Algorithms for Wireless Ad-hoc Networks without
  External Reference</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time division multiple access (TDMA) is a method for sharing communication
media. In wireless communications, TDMA algorithms often divide the radio time
into timeslots of uniform size, $\xi$, and then combine them into frames of
uniform size, $\tau$. We consider TDMA algorithms that allocate at least one
timeslot in every frame to every node. Given a maximal node degree, $\delta$,
and no access to external references for collision detection, time or position,
we consider the problem of collision-free self-stabilizing TDMA algorithms that
use constant frame size.
  We demonstrate that this problem has no solution when the frame size is $\tau
&lt; \max\{2\delta,\chi_2\}$, where $\chi_2$ is the chromatic number for
distance-$2$ vertex coloring. As a complement to this lower bound, we focus on
proving the existence of collision-free self-stabilizing TDMA algorithms that
use constant frame size of $\tau$. We consider basic settings (no hardware
support for collision detection and no prior clock synchronization), and the
collision of concurrent transmissions from transmitters that are at most two
hops apart. In the context of self-stabilizing systems that have no external
reference, we are the first to study this problem (to the best of our
knowledge), and use simulations to show convergence even with computation time
uncertainties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6481</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6481</id><created>2013-08-29</created><authors><author><keyname>Sreedharan</keyname><forenames>Jithin K.</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author></authors><title>Nonparametric Decentralized Sequential Detection via Universal Source
  Coding</title><categories>cs.IT math.IT</categories><comments>40 pages, 12 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider nonparametric or universal sequential hypothesis testing problem
when the distribution under the null hypothesis is fully known but the
alternate hypothesis corresponds to some other unknown distribution. These
algorithms are primarily motivated from spectrum sensing in Cognitive Radios
and intruder detection in wireless sensor networks. We use easily implementable
universal lossless source codes to propose simple algorithms for such a setup.
The algorithms are first proposed for discrete alphabet. Their performance and
asymptotic properties are studied theoretically. Later these are extended to
continuous alphabets. Their performance with two well known universal source
codes, Lempel-Ziv code and Krichevsky-Trofimov estimator with Arithmetic
Encoder are compared. These algorithms are also compared with the tests using
various other nonparametric estimators. Finally a decentralized version
utilizing spatial diversity is also proposed. Its performance is analysed and
asymptotic properties are proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6487</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6487</id><created>2013-08-29</created><authors><author><keyname>Torres</keyname><forenames>Leonardo</forenames></author><author><keyname>Cavalcante</keyname><forenames>Tamer</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>A New Algorithm of Speckle Filtering using Stochastic Distances</title><categories>cs.IT cs.CV cs.GR math.IT stat.AP stat.ML</categories><comments>Accepted for publication on the proceedings of the IEEE Geoscience
  and Remote Sensing Symposium (IGARSS 2012), to be published in IEEE Press.
  Available: http://www.igarss2012.org/Papers/viewpapers.asp?papernum=4877</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach for filter design based on stochastic
distances and tests between distributions. A window is defined around each
pixel, overlapping samples are compared and only those which pass a
goodness-of-fit test are used to compute the filtered value. The technique is
applied to intensity SAR data with homogeneous regions using the Gamma model.
The proposal is compared with the Lee's filter using a protocol based on Monte
Carlo. Among the criteria used to quantify the quality of filters, we employ
the equivalent number of looks, line and edge preservation. Moreover, we also
assessed the filters by the Universal Image Quality Index and the Pearson's
correlation on edges regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6494</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6494</id><created>2013-08-29</created><authors><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>Spectral community detection in sparse networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral methods based on the eigenvectors of matrices are widely used in the
analysis of network data, particularly for community detection and graph
partitioning. Standard methods based on the adjacency matrix and related
matrices, however, break down for very sparse networks, which includes many
networks of practical interest. As a solution to this problem it has been
recently proposed that we focus instead on the spectrum of the non-backtracking
matrix, an alternative matrix representation of a network that shows better
behavior in the sparse limit. Inspired by this suggestion, we here make use of
a relaxation method to derive a spectral community detection algorithm that
works well even in the sparse regime where other methods break down.
Interestingly, however, the matrix at the heart of the method, it turns out, is
not exactly the non-backtracking matrix, but a variant of it with a somewhat
different definition. We study the behavior of this variant matrix for both
artificial and real-world networks and find it to have desirable properties,
especially in the common case of networks with broad degree distributions, for
which it appears to have a better behaved spectrum and eigenvectors than the
original non-backtracking matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6498</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6498</id><created>2013-08-29</created><updated>2013-11-19</updated><authors><author><keyname>Bliek</keyname><forenames>Laurens</forenames></author></authors><title>Universal Approximation Using Shuffled Linear Models</title><categories>math.DS cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a specific type of Local Linear Model, the Shuffled
Linear Model (SLM), that can be used as a universal approximator. Local
operating points are chosen randomly and linear models are used to approximate
a function or system around these points. The model can also be interpreted as
an extension to Extreme Learning Machines with Radial Basis Function nodes, or
as a specific way of using Takagi-Sugeno fuzzy models. Using the available
theory of Extreme Learning Machines, universal approximation of the SLM and an
upper bound on the number of models are proved mathematically, and an efficient
algorithm is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6503</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6503</id><created>2013-08-29</created><updated>2015-02-17</updated><authors><author><keyname>Tomamichel</keyname><forenames>Marco</forenames></author><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author></authors><title>Second-Order Asymptotics for the Classical Capacity of Image-Additive
  Quantum Channels</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>v2: main results significantly generalized and improved; v3: extended
  to image-additive channels, change of title, journal version</comments><journal-ref>Communication in Mathematical Physics 338(1), 103-137 (2015)</journal-ref><doi>10.1007/s00220-015-2382-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study non-asymptotic fundamental limits for transmitting classical
information over memoryless quantum channels, i.e. we investigate the amount of
classical information that can be transmitted when a quantum channel is used a
finite number of times and a fixed, non-vanishing average error is permissible.
We consider the classical capacity of quantum channels that are image-additive,
including all classical to quantum channels, as well as the product state
capacity of arbitrary quantum channels. In both cases we show that the
non-asymptotic fundamental limit admits a second-order approximation that
illustrates the speed at which the rate of optimal codes converges to the
Holevo capacity as the blocklength tends to infinity. The behavior is governed
by a new channel parameter, called channel dispersion, for which we provide a
geometrical interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6504</identifier>
 <datestamp>2014-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6504</id><created>2013-08-29</created><updated>2014-02-22</updated><authors><author><keyname>Pan</keyname><forenames>Zheng</forenames></author><author><keyname>Hou</keyname><forenames>Guangdong</forenames></author><author><keyname>Zhang</keyname><forenames>Changshui</forenames></author></authors><title>On the Conditions of Sparse Parameter Estimation via Log-Sum Penalty
  Regularization</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to an error in the
  the proof of Theorem 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For high-dimensional sparse parameter estimation problems, Log-Sum Penalty
(LSP) regularization effectively reduces the sampling sizes in practice.
However, it still lacks theoretical analysis to support the experience from
previous empirical study. The analysis of this article shows that, like
$\ell_0$-regularization, $O(s)$ sampling size is enough for proper LSP, where
$s$ is the non-zero components of the true parameter. We also propose an
efficient algorithm to solve LSP regularization problem. The solutions given by
the proposed algorithm give consistent parameter estimations under less
restrictive conditions than $\ell_1$-regularization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6505</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6505</id><created>2013-08-29</created><authors><author><keyname>Huber</keyname><forenames>Anna</forenames></author><author><keyname>Krokhin</keyname><forenames>Andrei</forenames></author></authors><title>Oracle Tractability of Skew Bisubmodular Functions</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider skew bisubmodular functions as introduced in [9].
We construct a convex extension of a skew bisubmodular function which we call
Lov\'asz extension in correspondence to the submodular case. We use this
extension to show that skew bisubmodular functions given by an oracle can be
minimised in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6509</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6509</id><created>2013-08-29</created><updated>2013-09-19</updated><authors><author><keyname>Gawrychowski</keyname><forenames>Pawel</forenames></author><author><keyname>Straszak</keyname><forenames>Damian</forenames></author></authors><title>Beating O(nm) in approximate LZW-compressed pattern matching</title><categories>cs.DS</categories><comments>This is the full version of an extended abstract to appear in
  ISAAC'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an LZW/LZ78 compressed text, we want to find an approximate occurrence
of a given pattern of length m. The goal is to achieve time complexity
depending on the size n of the compressed representation of the text instead of
its length. We consider two specific definitions of approximate matching,
namely the Hamming distance and the edit distance, and show how to achieve
O(nm^0.5k^2) and O(nm^0.5k^3) running time, respectively, where k is the bound
on the distance. Both algorithms use just linear space. Even for very small
values of k, the best previously known solutions required O(nm) time. Our main
contribution is applying a periodicity-based argument in a way that is
computationally effective even if we need to operate on a compressed
representation of a string, while the previous solutions were either based on a
dynamic programming, or a black-box application of tools developed for
uncompressed strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6523</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6523</id><created>2013-08-29</created><authors><author><keyname>England</keyname><forenames>M.</forenames></author><author><keyname>Cheb-Terrab</keyname><forenames>E.</forenames></author><author><keyname>Bradford</keyname><forenames>R.</forenames></author><author><keyname>Davenport</keyname><forenames>J. H.</forenames></author><author><keyname>Wilson</keyname><forenames>D.</forenames></author></authors><title>Branch Cuts in Maple 17</title><categories>cs.SC cs.MS</categories><msc-class>I.1.1, G.4</msc-class><acm-class>I.1.1; I.1.2; G.4</acm-class><journal-ref>ACM Communications in Computer Algebra 48:1 pp. 24-27, ACM, 2014</journal-ref><doi>10.1145/2644288.2644293</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate and comprehensible knowledge about the position of branch cuts is
essential for correctly working with multi-valued functions, such as the square
root and logarithm. We discuss the new tools in Maple 17 for calculating and
visualising the branch cuts of such functions, and others built up from them.
The cuts are described in an intuitive and accurate form, offering substantial
improvement on the descriptions previously available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6526</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6526</id><created>2013-08-29</created><updated>2013-08-30</updated><authors><author><keyname>Vila&#xe7;a</keyname><forenames>Xavier</forenames></author><author><keyname>Rodrigues</keyname><forenames>Lu&#xed;s</forenames></author></authors><title>On the Effectiveness of Punishments in a Repeated Epidemic Dissemination
  Game</title><categories>cs.DC cs.GT</categories><comments>76 pages, extended technical report, original paper is expected to
  appear on Proceedings of the 15th International Symposium on Stabilization,
  Safety, and Security of Distributed Systems (SSS 2013), corrected typo in
  abstract, corrected citation to Kreps:82, improved description of the stage
  game to justify fixed stage strategy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work uses Game Theory to study the effectiveness of punishments as an
incentive for rational nodes to follow an epidemic dissemination protocol. The
dissemination process is modeled as an infinite repetition of a stage game. At
the end of each stage, a monitoring mechanism informs each player of the
actions of other nodes. The effectiveness of a punishing strategy is measured
as the range of values for the benefit-to-cost ratio that sustain cooperation.
This paper studies both public and private monitoring. Under public monitoring,
we show that direct reciprocity is not an effective incentive, whereas full
indirect reciprocity provides a nearly optimal effectiveness. Under private
monitoring, we identify necessary conditions regarding the topology of the
graph in order for punishments to be effective. When punishments are
coordinated, full indirect reciprocity is also effective with private
monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6537</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6537</id><created>2013-08-29</created><updated>2013-09-30</updated><authors><author><keyname>H&#xe9;bert-Dufresne</keyname><forenames>Laurent</forenames></author><author><keyname>Allard</keyname><forenames>Antoine</forenames></author><author><keyname>Young</keyname><forenames>Jean-Gabriel</forenames></author><author><keyname>Dub&#xe9;</keyname><forenames>Louis J.</forenames></author></authors><title>Percolation on random networks with arbitrary k-core structure</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>9 pages, 5 figures</comments><journal-ref>Phys. Rev. E 88, 062820 (2013)</journal-ref><doi>10.1103/PhysRevE.88.062820</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-core decomposition of a network has thus far mainly served as a
powerful tool for the empirical study of complex networks. We now propose its
explicit integration in a theoretical model. We introduce a Hard-core Random
Network model that generates maximally random networks with arbitrary degree
distribution and arbitrary k-core structure. We then solve exactly the bond
percolation problem on the HRN model and produce fast and precise analytical
estimates for the corresponding real networks. Extensive comparison with
selected databases reveals that our approach performs better than existing
models, while requiring less input information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6543</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6543</id><created>2013-08-29</created><authors><author><keyname>Garcia</keyname><forenames>Nil</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames></author><author><keyname>Coulon</keyname><forenames>Martial</forenames></author><author><keyname>Lops</keyname><forenames>Marco</forenames></author></authors><title>Resource Allocation in MIMO Radar With Multiple Targets for Non-Coherent
  Localization</title><categories>cs.IT math.IT</categories><comments>10 pages, 4 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a MIMO radar network the multiple transmit elements may emit waveforms
that differ on power and bandwidth. In this paper, we are asking, given that
these two resources are limited, what is the optimal power, optimal bandwidth
and optimal joint power and bandwidth allocation for best localization of
multiple targets. The well known Cr\'amer-Rao lower bound for target
localization accuracy is used as a figure of merit and approximate solutions
are found by minimizing a sequence of convex problems. Their quality is
assessed through extensive numerical simulations and with the help of a
lower-bound on the true solution. Simulations results reveal that bandwidth
allocation policies have a definitely stronger impact on performance than
power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6552</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6552</id><created>2013-08-29</created><authors><author><keyname>Ordentlich</keyname><forenames>Or</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>Integer-Forcing Source Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integer-Forcing (IF) is a new framework, based on compute-and-forward, for
decoding multiple integer linear combinations from the output of a Gaussian
multiple-input multiple-output channel. This work applies the IF approach to
arrive at a new low-complexity scheme, IF source coding, for distributed lossy
compression of correlated Gaussian sources under a minimum mean squared error
distortion measure. All encoders use the same nested lattice codebook. Each
encoder quantizes its observation using the fine lattice as a quantizer and
reduces the result modulo the coarse lattice, which plays the role of binning.
Rather than directly recovering the individual quantized signals, the decoder
first recovers a full-rank set of judiciously chosen integer linear
combinations of the quantized signals, and then inverts it. In general, the
linear combinations have smaller average powers than the original signals. This
allows to increase the density of the coarse lattice, which in turn translates
to smaller compression rates. We also propose and analyze a one-shot version of
IF source coding, that is simple enough to potentially lead to a new design
principle for analog-to-digital converters that can exploit spatial
correlations between the sampled signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6566</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6566</id><created>2013-08-29</created><authors><author><keyname>Kennedy</keyname><forenames>Rodney A.</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author><author><keyname>Khalid</keyname><forenames>Zubair</forenames></author><author><keyname>McEwen</keyname><forenames>Jason D.</forenames></author></authors><title>Classification and construction of closed-form kernels for signal
  representation on the 2-sphere</title><categories>cs.IT math.IT</categories><comments>15 pages, 6 figures, Proceedings of Wavelets and Sparsity XV, SPIE
  Optics and Photonics 2013</comments><journal-ref>Proc. SPIE 8858, Wavelets and Sparsity XV, 88580M (2013)</journal-ref><doi>10.1117/12.2026126</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the construction of Reproducing Kernel Hilbert Spaces
(RKHS) on the sphere as an alternative to the conventional Hilbert space using
the inner product that yields the L^2(S^2) function space of finite energy
signals. In comparison with wavelet representations, which have
multi-resolution properties on L^2(S^2), the representations that arise from
the RKHS approach, which uses different inner products, have an overall
smoothness constraint, which may offer advantages and simplifications in
certain contexts. The key contribution of this paper is to construct classes of
closed-form kernels, such as one based on the von Mises-Fisher distribution,
which permits efficient inner product computation using kernel evaluations.
Three classes of RKHS are defined: isotropic kernels and non-isotropic kernels
both with spherical harmonic eigenfunctions, and general anisotropic kernels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6604</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6604</id><created>2013-08-29</created><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author></authors><title>A smart local moving algorithm for large-scale modularity-based
  community detection</title><categories>physics.soc-ph cs.SI physics.data-an</categories><doi>10.1140/epjb/e2013-40829-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new algorithm for modularity-based community detection in
large networks. The algorithm, which we refer to as a smart local moving
algorithm, takes advantage of a well-known local moving heuristic that is also
used by other algorithms. Compared with these other algorithms, our proposed
algorithm uses the local moving heuristic in a more sophisticated way. Based on
an analysis of a diverse set of networks, we show that our smart local moving
algorithm identifies community structures with higher modularity values than
other algorithms for large-scale modularity optimization, among which the
popular 'Louvain algorithm' introduced by Blondel et al. (2008). The
computational efficiency of our algorithm makes it possible to perform
community detection in networks with tens of millions of nodes and hundreds of
millions of edges. Our smart local moving algorithm also performs well in small
and medium-sized networks. In short computing times, it identifies community
structures with modularity values equally high as, or almost as high as, the
highest values reported in the literature, and sometimes even higher than the
highest values found in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6627</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6627</id><created>2013-08-29</created><authors><author><keyname>Zhao</keyname><forenames>James Y.</forenames></author></authors><title>Expand and Contract: Sampling graphs with given degrees and other
  combinatorial families</title><categories>cs.DS math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling from combinatorial families can be difficult. However, complicated
families can often be embedded within larger, simpler ones, for which easy
sampling algorithms are known. We take advantage of such a relationship to
describe a sampling algorithm for the smaller family, via a Markov chain
started at a random sample of the larger family. The utility of the method is
demonstrated via several examples, with particular emphasis on sampling
labelled graphs with given degree sequence, a well-studied problem for which
existing algorithms leave much room for improvement. For graphs with given
degrees, with maximum degree $O(m^{1/4})$ where $m$ is the number of edges, we
obtain an asymptotically uniform sample in $O(m)$ steps, which substantially
improves upon existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6628</identifier>
 <datestamp>2014-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6628</id><created>2013-08-29</created><updated>2014-02-21</updated><authors><author><keyname>Tu</keyname><forenames>Kewei</forenames></author><author><keyname>Meng</keyname><forenames>Meng</forenames></author><author><keyname>Lee</keyname><forenames>Mun Wai</forenames></author><author><keyname>Choe</keyname><forenames>Tae Eun</forenames></author><author><keyname>Zhu</keyname><forenames>Song-Chun</forenames></author></authors><title>Joint Video and Text Parsing for Understanding Events and Answering
  Queries</title><categories>cs.CV cs.CL cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for parsing video and text jointly for understanding
events and answering user queries. Our framework produces a parse graph that
represents the compositional structures of spatial information (objects and
scenes), temporal information (actions and events) and causal information
(causalities between events and fluents) in the video and text. The knowledge
representation of our framework is based on a spatial-temporal-causal And-Or
graph (S/T/C-AOG), which jointly models possible hierarchical compositions of
objects, scenes and events as well as their interactions and mutual contexts,
and specifies the prior probabilistic distribution of the parse graphs. We
present a probabilistic generative model for joint parsing that captures the
relations between the input video/text, their corresponding parse graphs and
the joint parse graph. Based on the probabilistic model, we propose a joint
parsing system consisting of three modules: video parsing, text parsing and
joint inference. Video parsing and text parsing produce two parse graphs from
the input video and text respectively. The joint inference module produces a
joint parse graph by performing matching, deduction and revision on the video
and text parse graphs. The proposed framework has the following objectives:
Firstly, we aim at deep semantic parsing of video and text that goes beyond the
traditional bag-of-words approaches; Secondly, we perform parsing and reasoning
across the spatial, temporal and causal dimensions based on the joint S/T/C-AOG
representation; Thirdly, we show that deep joint parsing facilitates subsequent
applications such as generating narrative text descriptions and answering
queries in the forms of who, what, when, where and why. We empirically
evaluated our system based on comparison against ground-truth as well as
accuracy of query answering and obtained satisfactory results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6633</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6633</id><created>2013-08-29</created><authors><author><keyname>Ikeda</keyname><forenames>Yuichi</forenames></author><author><keyname>Ogimoto</keyname><forenames>Kazuhiko</forenames></author></authors><title>Cross-Correlation of Photovoltaic Output Fluctuation in Power System
  Operation for Large-Scale Photovoltaic Integration</title><categories>cs.SY</categories><comments>The 3rd Solar Integration Workshop in London on October 21-22, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyzed the cross-correlation of Photovoltaic (PV) output fluctuation for
the actual PV output time series data in both the Tokyo area and the whole of
Japan using the principal component analysis with the random matrix theory.
Based on the obtained cross-correlation coefficients, the forecast error for PV
output was estimated with/without considering the cross-correlations. Then
operation schedule of thermal plants is calculated to integrate PV output using
our unit commitment model with the estimated forecast error. The cost for grid
integration of PV system was also estimated. Finally, validity of the concept
of &quot;local production for local consumption of renewable energy&quot; and alternative
policy implications were also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6635</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6635</id><created>2013-08-29</created><authors><author><keyname>Ferreira</keyname><forenames>Rui</forenames></author></authors><title>Efficiently Listing Combinatorial Patterns in Graphs</title><categories>cs.DS</categories><comments>PhD Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphs are extremely versatile and ubiquitous mathematical structures with
potential to model a wide range of domains. For this reason, graph problems
have been of interest since the early days of computer science. Some of these
problems consider substructures of a graph that have certain properties. These
substructures of interest, generally called patterns, are often meaningful in
the domain being modeled. Classic examples of patterns include spanning trees,
cycles and subgraphs.
  This thesis focuses on the topic of explicitly listing all the patterns
existing in an input graph. One of the defining features of this problem is
that the number of patterns is frequently exponential on the size of the input
graph. Thus, the time complexity of listing algorithms is parameterized by the
size of the output.
  The main contribution of this work is the presentation of optimal algorithms
for four different problems of listing patterns in graphs, namely the listing
of k-subtrees, k-subgraphs, st-paths and cycles. The algorithms presented are
framed within the same generic approach, based in a recursive partition of the
search space that divides the problem into subproblems. The key to an efficient
implementation of this approach is to avoid recursing into subproblems that do
not list any patterns. With this goal in sight, a dynamic data structure,
called the certificate, is introduced and maintained throughout the recursion.
Moreover, properties of the recursion tree and lower bounds on the number of
patterns are used to amortize the cost of the algorithm on the size of the
output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6641</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6641</id><created>2013-08-29</created><authors><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Anderson</keyname><forenames>Brian D. O.</forenames></author><author><keyname>Yu</keyname><forenames>Changbin</forenames></author><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author></authors><title>Local Average Consensus in Distributed Measurement of Spatial-Temporal
  Varying Parameters: 1D Case</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a new variant of consensus problems, termed `local average
consensus', in networks of agents. We consider the task of using sensor
networks to perform distributed measurement of a parameter which has both
spatial (in this paper 1D) and temporal variations. Our idea is to maintain
potentially useful local information regarding spatial variation, as contrasted
with reaching a single, global consensus, as well as to mitigate the effect of
measurement errors. We employ two schemes for computation of local average
consensus: exponential weighting and uniform finite window. In both schemes, we
design local average consensus algorithms to address first the case where the
measured parameter has spatial variation but is constant in time, and then the
case where the measured parameter has both spatial and temporal variations. Our
designed algorithms are distributed, in that information is exchanged only
among neighbors. Moreover, we analyze both spatial and temporal frequency
responses and noise propagation associated with the algorithms. The tradeoffs
of using local consensus, as compared to standard global consensus, include
higher memory requirement and degraded noise performance. Arbitrary updating
weights and random spacing between sensors are analyzed in the proposed
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6646</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6646</id><created>2013-08-29</created><authors><author><keyname>Keinert</keyname><forenames>Fritz</forenames></author><author><keyname>Kwon</keyname><forenames>Soon-Geol</forenames></author></authors><title>Point values and normalization of two-direction multiwavelets and their
  derivatives</title><categories>cs.IT math.IT</categories><comments>19 pages, 8 figures. arXiv admin note: text overlap with
  arXiv:1205.4056</comments><msc-class>42C40</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Two-direction multiscaling functions $\boldsymbol{\phi}$ and two-direction
multiwavelets $\boldsymbol{\psi}$ associated with $\boldsymbol{\phi}$ are more
general and more flexible setting than one-direction multiscaling functions and
multiwavelets. In this paper, we investigate how to find and normalize point
values and those of derivatives of the two-direction multiscaling functions
$\boldsymbol{\phi}$ and multiwavelets $\boldsymbol{\psi}$. %associated with
$\boldsymbol{\phi}$. For finding point values, we investigate the eigenvalue
approach. For normalization, we investigate the normalizing conditions for them
by normalizing the zeroth continuous moment of $\boldsymbol{\phi}$. Examples
for illustrating the general theory are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6659</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6659</id><created>2013-08-30</created><authors><author><keyname>Khalid</keyname><forenames>Zubair</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney A.</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author></authors><title>Spatio-spectral Formulation and Design of Spatially-Varying Filters for
  Signal Estimation on the 2-Sphere</title><categories>astro-ph.IM cs.IT math.IT</categories><comments>14 pages, 5 figures, Proceedings of Wavelets and Sparsity XV, SPIE
  Optics and Photonics 2013</comments><doi>10.1117/12.2023932</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an optimal filter for the enhancement or estimation
of signals on the 2-sphere corrupted by noise, when both the signal and noise
are realizations of anisotropic processes on the 2-sphere. The estimation of
such a signal in the spatial or spectral domain separately can be shown to be
inadequate. Therefore, we develop an optimal filter in the joint
spatio-spectral domain by using a framework recently presented in the
literature --- the spatially localized spherical harmonic transform ---
enabling such processing. Filtering of a signal in the spatio-spectral domain
facilitates taking into account anisotropic properties of both the signal and
noise processes. The proposed spatio-spectral filtering is optimal under the
mean-square error criterion. The capability of the proposed filtering framework
is demonstrated with by an example to estimate a signal corrupted by an
anisotropic noise process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6663</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6663</id><created>2013-08-30</created><authors><author><keyname>Wu</keyname><forenames>Chenshu</forenames></author><author><keyname>Yang</keyname><forenames>Zheng</forenames></author><author><keyname>Zhou</keyname><forenames>Zimu</forenames></author><author><keyname>Liu</keyname><forenames>Yunhao</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>DorFin: WiFi Fingerprint-based Localization Revisited</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although WiFi fingerprint-based indoor localization is attractive, its
accuracy remains a primary challenge especially in mobile environments.
Existing approaches either appeal to physical layer information or rely on
extra wireless signals for high accuracy. In this paper, we revisit the RSS
fingerprint-based localization scheme and reveal crucial observations that act
as the root causes of localization errors, yet are surprisingly overlooked or
even unseen in previous works. Specifically, we recognize APs' diverse
discrimination for fingerprinting a specific location, observe the RSS
inconsistency caused by signal fluctuations and human body blockages, and
uncover the RSS outdated problem on commodity smartphones. Inspired by these
insights, we devise a discrimination factor to quantify different APs'
discrimination, incorporate robust regression to tolerate outlier measurements,
and reassemble different fingerprints to cope with outdated RSSs. Combining
these techniques in a unified solution, we propose DorFin, a novel scheme of
fingerprint generation, representation, and matching, which yields remarkable
accuracy without incurring extra cost. Extensive experiments demonstrate that
DorFin achieves mean error of 2 meters and more importantly, bounds the 95th
percentile error under 5.5 meters; these are about 56% and 69% lower,
respectively, compared with the state-of-the-art schemes such as Horus and
RADAR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6682</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6682</id><created>2013-08-30</created><authors><author><keyname>Hachicha</keyname><forenames>Marouane</forenames><affiliation>ERIC</affiliation></author><author><keyname>Kit</keyname><forenames>Chantola</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>A Novel Query-Based Approach for Addressing Summarizability Issues in
  XOLAP</title><categories>cs.DB</categories><comments>18th International Conference on Management of Data (COMAD 2012),
  Pune : India (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The business intelligence and decision-support systems used in many
application domains casually rely on data warehouses, which are
decision-oriented data repositories modeled as multidimensional (MD)
structures. MD structures help navigate data through hierarchical levels of
detail. In many real-world situations, hierarchies in MD models are complex,
which causes data aggregation issues, collectively known as the summarizability
problem. This problem leads to incorrect analyses and critically affects
decision making. To enforce summarizability, existing approaches alter either
MD models or data, and must be applied a priori, on a case-by-case basis, by an
expert. To alter neither models nor data, a few query-time approaches have been
proposed recently, but they only detect summarizability issues without solving
them. Thus, we propose in this paper a novel approach that automatically
detects and processes summarizability issues at query time, without requiring
any particular expertise from the user. Moreover, while most existing
approaches are based on the relational model, our approach focus on an XML MD
model, since XML data is customarily used to represent business data and its
format better copes with complex hierarchies than the relational model.
Finally, our experiments show that our method is likely to scale better than a
reference approach for addressing the summarizability problem in the MD
context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6683</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6683</id><created>2013-08-30</created><authors><author><keyname>Kit</keyname><forenames>Chantola</forenames><affiliation>ERIC</affiliation></author><author><keyname>Hachicha</keyname><forenames>Marouane</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>Benchmarking Summarizability Processing in XML Warehouses with Complex
  Hierarchies</title><categories>cs.DB</categories><comments>15th International Workshop on Data Warehousing and OLAP (DOLAP
  2012), Maui : United States (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Business Intelligence plays an important role in decision making. Based on
data warehouses and Online Analytical Processing, a business intelligence tool
can be used to analyze complex data. Still, summarizability issues in data
warehouses cause ineffective analyses that may become critical problems to
businesses. To settle this issue, many researchers have studied and proposed
various solutions, both in relational and XML data warehouses. However, they
find difficulty in evaluating the performance of their proposals since the
available benchmarks lack complex hierarchies. In order to contribute to
summarizability analysis, this paper proposes an extension to the XML warehouse
benchmark (XWeB) with complex hierarchies. The benchmark enables us to generate
XML data warehouses with scalable complex hierarchies as well as
summarizability processing. We experimentally demonstrated that complex
hierarchies can definitely be included into a benchmark dataset, and that our
benchmark is able to compare two alternative approaches dealing with
summarizability issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6687</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6687</id><created>2013-08-30</created><authors><author><keyname>Zhu</keyname><forenames>Pengfei</forenames></author><author><keyname>Zuo</keyname><forenames>Wangmeng</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Shiu</keyname><forenames>Simon C. K.</forenames></author><author><keyname>Zhang</keyname><forenames>David</forenames></author></authors><title>Image Set based Collaborative Representation for Face Recognition</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  With the rapid development of digital imaging and communication technologies,
image set based face recognition (ISFR) is becoming increasingly important. One
key issue of ISFR is how to effectively and efficiently represent the query
face image set by using the gallery face image sets. The set-to-set distance
based methods ignore the relationship between gallery sets, while representing
the query set images individually over the gallery sets ignores the correlation
between query set images. In this paper, we propose a novel image set based
collaborative representation and classification method for ISFR. By modeling
the query set as a convex or regularized hull, we represent this hull
collaboratively over all the gallery sets. With the resolved representation
coefficients, the distance between the query set and each gallery set can then
be calculated for classification. The proposed model naturally and effectively
extends the image based collaborative representation to an image set based one,
and our extensive experiments on benchmark ISFR databases show the superiority
of the proposed method to state-of-the-art ISFR methods under different set
sizes in terms of both recognition rate and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6693</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6693</id><created>2013-08-30</created><authors><author><keyname>Biedl</keyname><forenames>Therese</forenames></author></authors><title>Transforming planar graph drawings while maintaining height</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are numerous styles of planar graph drawings, notably straight-line
drawings, poly-line drawings, orthogonal graph drawings and visibility
representations. In this note, we show that many of these drawings can be
transformed from one style to another without changing the height of the
drawing. We then give some applications of these transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6694</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6694</id><created>2013-08-30</created><authors><author><keyname>Delecroix</keyname><forenames>Vincent</forenames><affiliation>IMJ</affiliation></author><author><keyname>Hejda</keyname><forenames>Tom&#xe1;&#x161;</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Steiner</keyname><forenames>Wolfgang</forenames><affiliation>LIAFA</affiliation></author></authors><title>Balancedness of Arnoux-Rauzy and Brun words</title><categories>cs.FL math.DS</categories><proxy>ccsd</proxy><journal-ref>9th International Conference, WORDS 2013, Turku : Finland (2013)</journal-ref><doi>10.1007/978-3-642-40579-2_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study balancedness properties of words given by the Arnoux-Rauzy and Brun
multi-dimensional continued fraction algorithms. We show that almost all Brun
words on 3 letters and Arnoux-Rauzy words over arbitrary alphabets are finitely
balanced; in particular, boundedness of the strong partial quotients implies
balancedness. On the other hand, we provide examples of unbalanced Brun words
on 3 letters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6697</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6697</id><created>2013-08-30</created><authors><author><keyname>Liu</keyname><forenames>Yihui</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Detect adverse drug reactions for drug Atorvastatin</title><categories>cs.CE</categories><comments>Fifth International Symposium on Computational Intelligence and
  Design (ISCID), 213-216, 2012. arXiv admin note: substantial text overlap
  with arXiv:1308.5144</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adverse drug reactions (ADRs) are big concern for public health. ADRs are one
of most common causes to withdraw some drugs from markets. Now two major
methods for detecting ADRs are spontaneous reporting system (SRS), and
prescription event monitoring (PEM). The World Health Organization (WHO)
defines a signal in pharmacovigilance as &quot;any reported information on a
possible causal relationship between an adverse event and a drug, the
relationship being unknown or incompletely documented previously&quot;. For
spontaneous reporting systems, many machine learning methods are used to detect
ADRs, such as Bayesian confidence propagation neural network (BCPNN), decision
support methods, genetic algorithms, knowledge based approaches, etc. One
limitation is the reporting mechanism to submit ADR reports, which has serious
underreporting and is not able to accurately quantify the corresponding risk.
Another limitation is hard to detect ADRs with small number of occurrences of
each drug-event association in the database. In this paper we propose feature
selection approach to detect ADRs from The Health Improvement Network (THIN)
database. First a feature matrix, which represents the medical events for the
patients before and after taking drugs, is created by linking patients'
prescriptions and corresponding medical events together. Then significant
features are selected based on feature selection methods, comparing the feature
matrix before patients take drugs with one after patients take drugs. Finally
the significant ADRs can be detected from thousands of medical events based on
corresponding features. Experiments are carried out on the drug Atorvastatin.
Good performance is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6701</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6701</id><created>2013-08-30</created><authors><author><keyname>Olteanu</keyname><forenames>Adriana</forenames></author><author><keyname>Stamatescu</keyname><forenames>Grigore</forenames></author><author><keyname>Ionita</keyname><forenames>Anca Daniela</forenames></author><author><keyname>Sgarciu</keyname><forenames>Valentin</forenames></author></authors><title>Enhanced Data Integration for LabVIEW Laboratory Systems</title><categories>cs.DB</categories><comments>6 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrating data is a basic concern in many accredited laboratories that
perform a large variety of measurements. However, the present working style in
engineering faculties does not focus much on this aspect. To deal with this
challenge, we developed an educational platform that allows characterization of
acquisition ensembles, generation of Web pages for lessons, as well as
transformation of measured data and storage in a common format. As generally we
had to develop individual parsers for each instrument, we also added the
possibility to integrate the LabVIEW workbench, often used for rapid
development of applications in electrical engineering and automatic control.
This paper describes how we configure the platform for specific equipment, i.e.
how we model it, how we create the learning material and how we integrate the
results in a central database. It also introduces a case study for collecting
data from a thermocouple-based acquisition system based on LabVIEW, used by
students for a laboratory of measurement technologies and transducers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6702</identifier>
 <datestamp>2014-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6702</id><created>2013-08-30</created><updated>2013-10-17</updated><authors><author><keyname>Brandao</keyname><forenames>Fernando G. S. L.</forenames></author><author><keyname>Harrow</keyname><forenames>Aram W.</forenames></author><author><keyname>Lee</keyname><forenames>James R.</forenames></author><author><keyname>Peres</keyname><forenames>Yuval</forenames></author></authors><title>Adversarial hypothesis testing and a quantum Stein's Lemma for
  restricted measurements</title><categories>cs.IT math.IT math.PR quant-ph</categories><comments>23 pages</comments><journal-ref>Proc. of 5th ITCS, pp. 183-194 (2014)</journal-ref><doi>10.1145/2554797.2554816</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recall the classical hypothesis testing setting with two convex sets of
probability distributions P and Q. One receives either n i.i.d. samples from a
distribution p in P or from a distribution q in Q and wants to decide from
which set the points were sampled. It is known that the optimal exponential
rate at which errors decrease can be achieved by a simple maximum-likelihood
ratio test which does not depend on p or q, but only on the sets P and Q.
  We consider an adaptive generalization of this model where the choice of p in
P and q in Q can change in each sample in some way that depends arbitrarily on
the previous samples. In other words, in the k'th round, an adversary, having
observed all the previous samples in rounds 1,...,k-1, chooses p_k in P and q_k
in Q, with the goal of confusing the hypothesis test. We prove that even in
this case, the optimal exponential error rate can be achieved by a simple
maximum-likelihood test that depends only on P and Q.
  We then show that the adversarial model has applications in hypothesis
testing for quantum states using restricted measurements. For example, it can
be used to study the problem of distinguishing entangled states from the set of
all separable states using only measurements that can be implemented with local
operations and classical communication (LOCC). The basic idea is that in our
setup, the deleterious effects of entanglement can be simulated by an adaptive
classical adversary.
  We prove a quantum Stein's Lemma in this setting: In many circumstances, the
optimal hypothesis testing rate is equal to an appropriate notion of quantum
relative entropy between two states. In particular, our arguments yield an
alternate proof of Li and Winter's recent strengthening of strong subadditivity
for quantum relative entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6705</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6705</id><created>2013-08-30</created><authors><author><keyname>Holleczek</keyname><forenames>Thomas</forenames></author><author><keyname>Yu</keyname><forenames>Liang</forenames></author><author><keyname>Lee</keyname><forenames>Joseph K.</forenames></author><author><keyname>Senn</keyname><forenames>Oliver</forenames></author><author><keyname>Kloeckl</keyname><forenames>Kristian</forenames></author><author><keyname>Ratti</keyname><forenames>Carlo</forenames></author><author><keyname>Jaillet</keyname><forenames>Patrick</forenames></author></authors><title>Digital breadcrumbs: Detecting urban mobility patterns and transport
  mode choices from cellphone networks</title><categories>cs.SI physics.data-an physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many modern and growing cities are facing declines in public transport usage,
with few efficient methods to explain why. In this article, we show that urban
mobility patterns and transport mode choices can be derived from cellphone call
detail records coupled with public transport data recorded from smart cards.
Specifically, we present new data mining approaches to determine the spatial
and temporal variability of public and private transportation usage and
transport mode preferences across Singapore. Our results, which were validated
by Singapore's quadriennial Household Interview Travel Survey (HITS), revealed
that there are 3.5 (HITS: 3.5 million) million and 4.3 (HITS: 4.4 million)
million inter-district passengers by public and private transport,
respectively. Along with classifying which transportation connections are weak
or underserved, the analysis shows that the mode share of public transport use
increases from 38 percent in the morning to 44 percent around mid-day and 52
percent in the evening.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6706</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6706</id><created>2013-08-30</created><updated>2014-08-07</updated><authors><author><keyname>Angelini</keyname><forenames>Patrizio</forenames></author><author><keyname>Binucci</keyname><forenames>Carla</forenames></author><author><keyname>Da Lozzo</keyname><forenames>Giordano</forenames></author><author><keyname>Didimo</keyname><forenames>Walter</forenames></author><author><keyname>Grilli</keyname><forenames>Luca</forenames></author><author><keyname>Montecchiani</keyname><forenames>Fabrizio</forenames></author><author><keyname>Patrignani</keyname><forenames>Maurizio</forenames></author><author><keyname>Tollis</keyname><forenames>Ioannis G.</forenames></author></authors><title>Algorithms and Bounds for Drawing Non-planar Graphs with Crossing-free
  Subgraphs</title><categories>cs.CG</categories><comments>21 pages, 9 figures, extended version of 'Drawing Non-planar Graphs
  with Crossing-free Subgraphs' (21st International Symposium on Graph Drawing,
  2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of the following problem: Given a non-planar graph G
and a planar subgraph S of G, does there exist a straight-line drawing {\Gamma}
of G in the plane such that the edges of S are not crossed in {\Gamma} by any
edge of G? We give positive and negative results for different kinds of
connected spanning subgraphs S of G. Moreover, in order to enlarge the subset
of instances that admit a solution, we consider the possibility of bending the
edges of G not in S; in this setting we discuss different trade-offs between
the number of bends and the required drawing area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6709</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6709</id><created>2013-08-30</created><authors><author><keyname>Wen</keyname><forenames>Guanghui</forenames></author><author><keyname>Ugrinovskii</keyname><forenames>Valery</forenames></author></authors><title>Distributed H-infinity Tracking Control for Discrete-Time Multi-Agent
  Systems with a High-Dimensional Leader</title><categories>cs.SY</categories><comments>The paper will appear in the Proceedings of the 52nd IEEE Conference
  on Decision and Control, 2013, Florence, Italy</comments><journal-ref>Proceedings of the 52nd IEEE Conference on Decision and Control,
  2013, Florence, Italy</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the distributed H-infinity leader-following tracking
problem for a class of discrete time multi-agent systems with a
high-dimensional dynamic leader. It is assumed that output information about
the leader is only available to designated followers, and the dynamics of the
followers are subject to perturbations. To achieve distributed H-infinity
leader-following tracking, a new class of control protocols is proposed which
is based on the feedback from the nearest neighbors as well as a distributed
state estimator. Under the assumptions that dynamics of the leader are
detectable and the communication topology contains a directed spanning tree,
sufficient conditions are obtained that enable all followers to track the
leader while achieving a desired H-infinity leader-following tracking
performance. Numerical simulations illustrate the effectiveness of the
theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6711</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6711</id><created>2013-08-30</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Pszona</keyname><forenames>Pawe&#x142;</forenames></author></authors><title>Streamed Graph Drawing and the File Maintenance Problem</title><categories>cs.DS</categories><comments>16 pages, 9 figures; to appear at the 21st International Symposium on
  Graph Drawing (GD 2013)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In streamed graph drawing, a planar graph, G, is given incrementally as a
data stream and a straight-line drawing of G must be updated after each new
edge is released. To preserve the mental map, changes to the drawing should be
minimized after each update, and Binucci et al.show that exponential area is
necessary and sufficient for a number of streamed graph drawings for trees if
edges are not allowed to move at all. We show that a number of streamed graph
drawings can, in fact, be done with polynomial area, including planar streamed
graph drawings of trees, tree-maps, and outerplanar graphs, if we allow for a
small number of coordinate movements after each update. Our algorithms involve
an interesting connection to a classic algorithmic problem - the file
maintenance problem - and we also give new algorithms for this problem in a
framework where bulk memory moves are allowed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6721</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6721</id><created>2013-08-30</created><authors><author><keyname>Baudin</keyname><forenames>Pierre-Yves</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Goodman</keyname><forenames>Danny</forenames><affiliation>INRIA Saclay - Ile de France, CVN</affiliation></author><author><keyname>Kumar</keyname><forenames>Puneet</forenames><affiliation>INRIA Saclay - Ile de France, CVN</affiliation></author><author><keyname>Azzabou</keyname><forenames>Noura</forenames><affiliation>MIRCEN, UPMC</affiliation></author><author><keyname>Carlier</keyname><forenames>Pierre G.</forenames><affiliation>UPMC</affiliation></author><author><keyname>Paragios</keyname><forenames>Nikos</forenames><affiliation>INRIA Saclay - Ile de France, MAS, LIGM, ENPC</affiliation></author><author><keyname>Kumar</keyname><forenames>M. Pawan</forenames><affiliation>INRIA Saclay - Ile de France, CVN</affiliation></author></authors><title>Discriminative Parameter Estimation for Random Walks Segmentation</title><categories>cs.CV cs.LG</categories><comments>Medical Image Computing and Computer Assisted Interventaion (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Random Walks (RW) algorithm is one of the most e - cient and easy-to-use
probabilistic segmentation methods. By combining contrast terms with prior
terms, it provides accurate segmentations of medical images in a fully
automated manner. However, one of the main drawbacks of using the RW algorithm
is that its parameters have to be hand-tuned. we propose a novel discriminative
learning framework that estimates the parameters using a training dataset. The
main challenge we face is that the training samples are not fully supervised.
Speci cally, they provide a hard segmentation of the images, instead of a
proba- bilistic segmentation. We overcome this challenge by treating the opti-
mal probabilistic segmentation that is compatible with the given hard
segmentation as a latent variable. This allows us to employ the latent support
vector machine formulation for parameter estimation. We show that our approach
signi cantly outperforms the baseline methods on a challenging dataset
consisting of real clinical 3D MRI volumes of skeletal muscles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6728</identifier>
 <datestamp>2014-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6728</id><created>2013-08-30</created><updated>2014-06-09</updated><authors><author><keyname>Li</keyname><forenames>Borui</forenames></author><author><keyname>Mu</keyname><forenames>Chundi</forenames></author><author><keyname>Han</keyname><forenames>Shuli</forenames></author><author><keyname>Bai</keyname><forenames>Tianming</forenames></author></authors><title>Extension of &quot;Model Parameter Adaptive Approach of Extended Object
  Tracking Using Random Matrix&quot;</title><categories>cs.SY</categories><comments>This paper has been withdrawn by the authors due to an error in
  simulation parameter seeting, which might be misleading</comments><journal-ref>Sensors, vol. 14, no. 4: 7505-7523, 2014</journal-ref><doi>10.3390/s140407505</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a draft of summary of multi-model algorithm of extended object
tracking based on random matrix (RMF-MM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6730</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6730</id><created>2013-08-30</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Pszona</keyname><forenames>Pawe&#x142;</forenames></author></authors><title>Achieving Good Angular Resolution in 3D Arc Diagrams</title><categories>cs.DS cs.CG</categories><comments>12 pages, 5 figures; to appear at the 21st International Symposium on
  Graph Drawing (GD 2013)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a three-dimensional analogue to the well-known graph visualization
approach known as arc diagrams. We provide several algorithms that achieve good
angular resolution for 3D arc diagrams, even for cases when the arcs must
project to a given 2D straight-line drawing of the input graph. Our methods
make use of various graph coloring algorithms, including an algorithm for a new
coloring problem, which we call localized edge coloring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6732</identifier>
 <datestamp>2014-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6732</id><created>2013-08-30</created><updated>2013-12-16</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Strong converse for the classical capacity of the pure-loss bosonic
  channel</title><categories>quant-ph cs.IT math.IT</categories><comments>18 pages, 1 figure; accepted for publication in Problems of
  Information Transmission</comments><journal-ref>Problems of Information Transmission vol. 50, no. 2, pages
  117-132, April 2014</journal-ref><doi>10.1134/S003294601402001X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper strengthens the interpretation and understanding of the classical
capacity of the pure-loss bosonic channel, first established in [Giovannetti et
al., Physical Review Letters 92, 027902 (2004), arXiv:quant-ph/0308012]. In
particular, we first prove that there exists a trade-off between communication
rate and error probability if one imposes only a mean-photon number constraint
on the channel inputs. That is, if we demand that the mean number of photons at
the channel input cannot be any larger than some positive number N_S, then it
is possible to respect this constraint with a code that operates at a rate
g(\eta N_S / (1-p)) where p is the code's error probability, \eta\ is the
channel transmissivity, and g(x) is the entropy of a bosonic thermal state with
mean photon number x. We then prove that a strong converse theorem holds for
the classical capacity of this channel (that such a rate-error trade-off cannot
occur) if one instead demands for a maximum photon number constraint, in such a
way that mostly all of the &quot;shadow&quot; of the average density operator for a given
code is required to be on a subspace with photon number no larger than n N_S,
so that the shadow outside this subspace vanishes as the number n of channel
uses becomes large. Finally, we prove that a small modification of the
well-known coherent-state coding scheme meets this more demanding constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6736</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6736</id><created>2013-08-30</created><updated>2014-08-14</updated><authors><author><keyname>Cohen</keyname><forenames>Alejandro</forenames></author><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author></authors><title>Wiretap Channel With Causal State Information and Secure Rate-Limited
  Feedback</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the secrecy capacity of a wiretap channel in the
presence of causal state information and secure rate-limited feedback. In this
scenario, the causal state information from the channel is available to both
the legitimate transmitter and legitimate receiver. In addition, the legitimate
receiver can send secure feedback to the transmitter at a limited rate Rf . We
shown that the secrecy capacity is bounded. Moreover, when the channel to the
legitimate receiver is less noisy than the channel to the eavesdropper, the
bound is shown to be tight. The capacity achieving scheme is based on both the
Wyner wiretap coding and two steps of shared-key generation: one from the state
information and one via the noiseless feedback. Finally, we consider several
special cases. When state information is available only at the legitimate
receiver, the analysis suggests that unlike previous results involving
feedback, it is better to use the feedback to send the state information to the
transmitter (when possible), rather than send a random key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6739</identifier>
 <datestamp>2014-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6739</id><created>2013-08-30</created><updated>2014-08-27</updated><authors><author><keyname>Noel</keyname><forenames>Jonathan A.</forenames></author><author><keyname>West</keyname><forenames>Douglas B.</forenames></author><author><keyname>Wu</keyname><forenames>Hehui</forenames></author><author><keyname>Zhu</keyname><forenames>Xuding</forenames></author></authors><title>Beyond Ohba's Conjecture: A bound on the choice number of $k$-chromatic
  graphs with $n$ vertices</title><categories>math.CO cs.DM</categories><comments>14 pages</comments><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\text{ch}(G)$ denote the choice number of a graph $G$ (also called &quot;list
chromatic number&quot; or &quot;choosability&quot; of $G$). Noel, Reed, and Wu proved the
conjecture of Ohba that $\text{ch}(G)=\chi(G)$ when $|V(G)|\le 2\chi(G)+1$. We
extend this to a general upper bound: $\text{ch}(G)\le
\max\{\chi(G),\lceil({|V(G)|+\chi(G)-1})/{3}\rceil\}$. Our result is sharp for
$|V(G)|\le 3\chi(G)$ using Ohba's examples, and it improves the best-known
upper bound for $\text{ch}(K_{4,\dots,4})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6744</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6744</id><created>2013-08-28</created><authors><author><keyname>Navaz</keyname><forenames>A. S. Syed</forenames></author><author><keyname>Ravi</keyname><forenames>M.</forenames></author><author><keyname>Prabhu</keyname><forenames>T.</forenames></author></authors><title>Preventing Disclosure of Sensitive Knowledge by Hiding Inference</title><categories>cs.CR cs.DB cs.LG</categories><comments>7 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data Mining is a way of extracting data or uncovering hidden patterns of
information from databases. So, there is a need to prevent the inference rules
from being disclosed such that the more secure data sets cannot be identified
from non sensitive attributes. This can be done through removing or adding
certain item sets in the transactions Sanitization. The purpose is to hide the
Inference rules, so that the user may not be able to discover any valuable
information from other non sensitive data and any organisation can release all
samples of their data without the fear of Knowledge Discovery In Databases
which can be achieved by investigating frequently occurring item sets, rules
that can be mined from them with the objective of hiding them. Another way is
to release only limited samples in the new database so that there is no
information loss and it also satisfies the legitimate needs of the users. The
major problem is uncovering hidden patterns, which causes a threat to the
database security. Sensitive data are inferred from non-sensitive data based on
the semantics of the application the user has, commonly known as the inference
problem. Two fundamental approaches to protect sensitive rules from disclosure
are that, preventing rules from being generated by hiding the frequent sets of
data items and reducing the importance of the rules by setting their confidence
below a user-specified threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6745</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6745</id><created>2013-08-28</created><authors><author><keyname>Navaz</keyname><forenames>A. S. Syed</forenames></author><author><keyname>Sangeetha</keyname><forenames>V.</forenames></author><author><keyname>Prabhadevi</keyname><forenames>C.</forenames></author></authors><title>Entropy based Anomaly Detection System to Prevent DDoS Attacks in Cloud</title><categories>cs.CR cs.DC</categories><comments>6 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud Computing is a recent computing model provides consistent access to
wide area distributed resources. It revolutionized the IT world with its
services provision infrastructure, less maintenance cost, data and service
availability assurance, rapid accessibility and scalability. Grid and Cloud
Computing Intrusion Detection System detects encrypted node communication and
find the hidden attack trial which inspects and detects those attacks that
network based and host based cant identify. It incorporates Knowledge and
behavior analysis to identify specific intrusions. Signature based IDS monitor
the packets in the network and identifies those threats by matching with
database but It fails to detect those attacks that are not included in
database. Signature based IDS will perform poor capturing in large volume of
anomalies. Another problem is that Cloud Service Provider hides the attack that
is caused by intruder, due to distributed nature cloud environment has high
possibility for vulnerable resources. By impersonating legitimate users, the
intruders can use a services abundant resources maliciously. In Proposed System
we combine few concepts which are available with new intrusion detection
techniques. Here to merge Entropy based System with Anomaly detection System
for providing multilevel Distributed Denial of Service. This is done in two
steps: First, Users are allowed to pass through router in network site in that
it incorporates Detection Algorithm and detects for legitimate user. Second,
again it pass through router placed in cloud site in that it incorporates
confirmation Algorithm and checks for threshold value, if its beyond the
threshold value it considered as legitimate user, else its an intruder found in
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6750</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6750</id><created>2013-08-30</created><updated>2014-08-11</updated><authors><author><keyname>Schreck</keyname><forenames>Jan</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author><author><keyname>Jung</keyname><forenames>Peter</forenames></author></authors><title>Robust Iterative Interference Alignment for Cellular Networks with
  Limited Feedback</title><categories>cs.IT math.IT</categories><comments>29 pages, 2 figures, submitted to IEEE Transaction on Wireless
  Communications, Presented in parts at Globecom Workshop on Emerging
  Technologies for LTE-Advanced and Beyond-4G</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In theory coordinated multi-point transmission (CoMP) promises vast gains in
spectral efficiency. But industrial field trials show rather disappointing
throughput gains, whereby the major limiting factor is proper sharing of
channel state information. Many recent papers consider this so-called limited
feedback problem in the context of CoMP. Usually taking the assumptions: 1)
infinite SNR regime, 2) no user selection and 3) ideal link adaptation;
rendering the analysis too optimistic. In this paper we make a step forward
towards a more realistic assessment of the limited feedback problem by
introducing an improved metric for the performance evaluation which better
captures the throughput degradation. We find the relevant scaling laws (lower
and upper bounds) and how that they are different from existing ones. Moreover,
we provide a robust iterative interference alignment algorithm and
corresponding feedback strategies achieving the obtained scaling laws. The main
idea is that instead of sending the complete channel matrix each user fixes a
receive filter and feeds back a quantized version of the effective channel.
Finally we underline our findings with simulations for the proposed system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6760</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6760</id><created>2013-08-30</created><authors><author><keyname>Sorge</keyname><forenames>Artus Krohn-Grimberghe Christoph</forenames></author></authors><title>Practical Aspects of the Bitcoin System</title><categories>cs.CY cs.CR</categories><comments>Covers content till end of May 2013. Was submitted to Communications
  of the ACM but got rejected (&quot;well written but out of scope&quot;)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital payment schemes show an ever increasing importance. Out of the
countless different schemes available this article focuses on the popular
Bitcoin system. The authors provide a description of Bitcoin's unique
technological basis and its accompanying ecosystem of users, miners, trading
platforms and vendors. Furthermore, this article discusses Bitcoin's
currency-like features and the first regulatory actions take in the European
Union and in the United States of America.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6768</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6768</id><created>2013-08-30</created><updated>2014-11-17</updated><authors><author><keyname>Biryukov</keyname><forenames>Alex</forenames></author><author><keyname>Pustogarov</keyname><forenames>Ivan</forenames></author><author><keyname>Thill</keyname><forenames>Fabrice</forenames></author><author><keyname>Weinmann</keyname><forenames>Ralf-Philipp</forenames></author></authors><title>Content and popularity analysis of Tor hidden services</title><categories>cs.CR</categories><comments>6 pages, 3 figures, 2 tables</comments><msc-class>C.2.0, K.6.5</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tor hidden services allow running Internet services while protecting the
location of the servers. Their main purpose is to enable freedom of speech even
in situations in which powerful adversaries try to suppress it. However,
providing location privacy and client anonymity also makes Tor hidden services
an attractive platform for every kind of imaginable shady service. The ease
with which Tor hidden services can be set up has spurred a huge growth of
anonymously provided Internet services of both types. In this paper we analyse
the landscape of Tor hidden services. We have studied Tor hidden services after
collecting 39824 hidden service descriptors on 4th of Feb 2013 by exploiting
protocol and implementation flaws in Tor: we scanned them for open ports; in
the case of HTTP services, we analysed and classified their content. We also
estimated the popularity of hidden services by looking at the request rate for
hidden service descriptors by clients. We found that while the content of Tor
hidden services is rather varied, the most popular hidden services are related
to botnets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6774</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6774</id><created>2013-08-30</created><authors><author><keyname>Tappenden</keyname><forenames>Rachael</forenames></author><author><keyname>Richtarik</keyname><forenames>Peter</forenames></author><author><keyname>Buke</keyname><forenames>Burak</forenames></author></authors><title>Separable Approximations and Decomposition Methods for the Augmented
  Lagrangian</title><categories>math.OC cs.DC cs.NA stat.ML</categories><comments>28 pages, 6 algorithms, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study decomposition methods based on separable
approximations for minimizing the augmented Lagrangian. In particular, we study
and compare the Diagonal Quadratic Approximation Method (DQAM) of Mulvey and
Ruszczy\'{n}ski and the Parallel Coordinate Descent Method (PCDM) of
Richt\'arik and Tak\'a\v{c}. We show that the two methods are equivalent for
feasibility problems up to the selection of a single step-size parameter.
Furthermore, we prove an improved complexity bound for PCDM under strong
convexity, and show that this bound is at least $8(L'/\bar{L})(\omega-1)^2$
times better than the best known bound for DQAM, where $\omega$ is the degree
of partial separability and $L'$ and $\bar{L}$ are the maximum and average of
the block Lipschitz constants of the gradient of the quadratic penalty
appearing in the augmented Lagrangian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6778</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6778</id><created>2013-08-30</created><updated>2015-02-16</updated><authors><author><keyname>Biedl</keyname><forenames>Therese</forenames></author><author><keyname>Bl&#xe4;sius</keyname><forenames>Thomas</forenames></author><author><keyname>Niedermann</keyname><forenames>Benjamin</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author><author><keyname>Prutkin</keyname><forenames>Roman</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author></authors><title>Using ILP/SAT to determine pathwidth, visibility representations, and
  other grid-based graph drawings</title><categories>cs.CG cs.DS</categories><comments>Full version of GD 2013 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple and versatile formulation of grid-based graph
representation problems as an integer linear program (ILP) and a corresponding
SAT instance. In a grid-based representation vertices and edges correspond to
axis-parallel boxes on an underlying integer grid; boxes can be further
constrained in their shapes and interactions by additional problem-specific
constraints. We describe a general d-dimensional model for grid representation
problems. This model can be used to solve a variety of NP-hard graph problems,
including pathwidth, bandwidth, optimum st-orientation, area-minimal (bar-k)
visibility representation, boxicity-k graphs and others. We implemented
SAT-models for all of the above problems and evaluated them on the Rome graphs
collection. The experiments show that our model successfully solves NP-hard
problems within few minutes on small to medium-size Rome graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6783</identifier>
 <datestamp>2014-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6783</id><created>2013-08-30</created><updated>2014-12-02</updated><authors><author><keyname>Roncaglia</keyname><forenames>Marco</forenames></author><author><keyname>Montorsi</keyname><forenames>Arianna</forenames></author><author><keyname>Genovese</keyname><forenames>Marco</forenames></author></authors><title>Bipartite entanglement of quantum states in a pair basis</title><categories>quant-ph cond-mat.quant-gas cs.IT math.IT</categories><comments>8 pages, 10 figures</comments><journal-ref>Phys. Rev. A 90, 062303 (2014)</journal-ref><doi>10.1103/PhysRevA.90.062303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The unambiguous detection and quantification of entanglement is a hot topic
of scientific research, though it is limited to low dimensions or specific
classes of states. Here we identify an additional class of quantum states, for
which bipartite entanglement measures can be efficiently computed, providing
new rigorous results. Such states are written in arbitrary $d\times d$
dimensions, where each basis state in the subsystem A is paired with only one
state in B. This new class, that we refer to as pair basis states, is
remarkably relevant in many physical situations, including quantum optics. We
find that negativity is a necessary and sufficient measure of entanglement for
mixtures of states written in the same pair basis. We also provide analytical
expressions for a tight lower-bound estimation of the entanglement of
formation, a central quantity in quantum information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6797</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6797</id><created>2013-08-30</created><updated>2013-10-14</updated><authors><author><keyname>Ailon</keyname><forenames>Nir</forenames></author></authors><title>Online Ranking: Discrete Choice, Spearman Correlation and Other Feedback</title><categories>cs.LG cs.GT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set $V$ of $n$ objects, an online ranking system outputs at each time
step a full ranking of the set, observes a feedback of some form and suffers a
loss. We study the setting in which the (adversarial) feedback is an element in
$V$, and the loss is the position (0th, 1st, 2nd...) of the item in the
outputted ranking. More generally, we study a setting in which the feedback is
a subset $U$ of at most $k$ elements in $V$, and the loss is the sum of the
positions of those elements.
  We present an algorithm of expected regret $O(n^{3/2}\sqrt{Tk})$ over a time
horizon of $T$ steps with respect to the best single ranking in hindsight. This
improves previous algorithms and analyses either by a factor of either
$\Omega(\sqrt{k})$, a factor of $\Omega(\sqrt{\log n})$ or by improving running
time from quadratic to $O(n\log n)$ per round. We also prove a matching lower
bound. Our techniques also imply an improved regret bound for online rank
aggregation over the Spearman correlation measure, and to other more complex
ranking loss functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6801</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6801</id><created>2013-08-30</created><authors><author><keyname>Bekos</keyname><forenames>Michael A.</forenames></author><author><keyname>Cornelsen</keyname><forenames>Sabine</forenames></author><author><keyname>Fink</keyname><forenames>Martin</forenames></author><author><keyname>Hong</keyname><forenames>Seokhee</forenames></author><author><keyname>Kaufmann</keyname><forenames>Michael</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author><author><keyname>Symvonis</keyname><forenames>Antonios</forenames></author></authors><title>Many-to-One Boundary Labeling with Backbones</title><categories>cs.CG cs.DS</categories><comments>23 pages, 10 figures, this is the full version of a paper that is
  about to appear in GD'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study \emph{many-to-one boundary labeling with backbone
leaders}. In this new many-to-one model, a horizontal backbone reaches out of
each label into the feature-enclosing rectangle. Feature points that need to be
connected to this label are linked via vertical line segments to the backbone.
We present dynamic programming algorithms for label number and total leader
length minimization of crossing-free backbone labelings. When crossings are
allowed, we aim to obtain solutions with the minimum number of crossings. This
can be achieved efficiently in the case of fixed label order, however, in the
case of flexible label order we show that minimizing the number of leader
crossings is NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6804</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6804</id><created>2013-08-30</created><updated>2014-01-13</updated><authors><author><keyname>Brunton</keyname><forenames>Alan</forenames></author><author><keyname>Wand</keyname><forenames>Michael</forenames></author><author><keyname>Wuhrer</keyname><forenames>Stefanie</forenames></author><author><keyname>Seidel</keyname><forenames>Hans-Peter</forenames></author><author><keyname>Weinkauf</keyname><forenames>Tino</forenames></author></authors><title>A Low-Dimensional Representation for Robust Partial Isometric
  Correspondences Computation</title><categories>cs.CV cs.GR</categories><comments>17 pages, 12 figures</comments><journal-ref>Graphical Models, 76(2), pp. 70--85, March 2014</journal-ref><doi>10.1016/j.gmod.2013.11.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intrinsic isometric shape matching has become the standard approach for pose
invariant correspondence estimation among deformable shapes. Most existing
approaches assume global consistency, i.e., the metric structure of the whole
manifold must not change significantly. While global isometric matching is well
understood, only a few heuristic solutions are known for partial matching.
Partial matching is particularly important for robustness to topological noise
(incomplete data and contacts), which is a common problem in real-world 3D
scanner data. In this paper, we introduce a new approach to partial, intrinsic
isometric matching. Our method is based on the observation that isometries are
fully determined by purely local information: a map of a single point and its
tangent space fixes an isometry for both global and the partial maps. From this
idea, we develop a new representation for partial isometric maps based on
equivalence classes of correspondences between pairs of points and their
tangent spaces. From this, we derive a local propagation algorithm that find
such mappings efficiently. In contrast to previous heuristics based on RANSAC
or expectation maximization, our method is based on a simple and sound
theoretical model and fully deterministic. We apply our approach to register
partial point clouds and compare it to the state-of-the-art methods, where we
obtain significant improvements over global methods for real-world data and
stronger guarantees than previous heuristic partial matching algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6805</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6805</id><created>2013-08-30</created><authors><author><keyname>Han</keyname><forenames>Jinsong</forenames></author><author><keyname>Qian</keyname><forenames>Chen</forenames></author><author><keyname>Ma</keyname><forenames>Dan</forenames></author><author><keyname>Wang</keyname><forenames>Xing</forenames></author><author><keyname>Zhao</keyname><forenames>Jizhong</forenames></author><author><keyname>Zhang</keyname><forenames>Pengfeng</forenames></author><author><keyname>Xi</keyname><forenames>Wei</forenames></author><author><keyname>Jiang</keyname><forenames>Zhiping</forenames></author></authors><title>Twins:Device-free Object Tracking using Passive Tags</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Without requiring objects to carry any transceiver, device-free based object
tracking provides a promising solution for many localization and tracking
systems to monitor non-cooperative objects such as intruders. However, existing
device-free solutions mainly use sensors and active RFID tags, which are much
more expensive compared to passive tags. In this paper, we propose a novel
motion detection and tracking method using passive RFID tags, named Twins. The
method leverages a newly observed phenomenon called critical state caused by
interference among passive tags. We contribute to both theory and practice of
such phenomenon by presenting a new interference model that perfectly explains
this phenomenon and using extensive experiments to validate it. We design a
practical Twins based intrusion detection scheme and implement a real prototype
with commercial off-the-shelf reader and tags. The results show that Twins is
effective in detecting the moving object, with low location error of 0.75m in
average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6807</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6807</id><created>2013-08-30</created><authors><author><keyname>Kim</keyname><forenames>Joohwan</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Achieving the Optimal Steaming Capacity and Delay Using Random Regular
  Digraphs in P2P Networks</title><categories>cs.NI cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In earlier work, we showed that it is possible to achieve $O(\log N)$
streaming delay with high probability in a peer-to-peer network, where each
peer has as little as four neighbors, while achieving any arbitrary fraction of
the maximum possible streaming rate. However, the constant in the $O(log N)$
delay term becomes rather large as we get closer to the maximum streaming rate.
In this paper, we design an alternative pairing and chunk dissemination
algorithm that allows us to transmit at the maximum streaming rate while
ensuring that all, but a negligible fraction of the peers, receive the data
stream with $O(\log N)$ delay with high probability. The result is established
by examining the properties of graph formed by the union of two or more random
1-regular digraphs, i.e., directed graphs in which each node has an incoming
and an outgoing node degree both equal to one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6810</identifier>
 <datestamp>2014-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6810</id><created>2013-08-30</created><updated>2014-01-09</updated><authors><author><keyname>Alglave</keyname><forenames>Jade</forenames></author><author><keyname>Maranget</keyname><forenames>Luc</forenames></author><author><keyname>Tautschnig</keyname><forenames>Michael</forenames></author></authors><title>Herding Cats - Modelling, simulation, testing, and data-mining for weak
  memory</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an axiomatic generic framework for modelling weak memory. We show
how to instantiate this framework for SC, TSO, C++ restricted to
release-acquire atomics, and Power. For Power, we compare our model to a
preceding operational model in which we found a flaw. To do so, we define an
operational model that we show equivalent to our axiomatic model.
  We also propose a model for ARM. Our testing on this architecture revealed a
behaviour later acknowledged as a bug by ARM, and more recently 33 additional
anomalies.
  We offer a new simulation tool, called herd, which allows the user to specify
the model of his choice in a concise way. Given a specification of a model, the
tool becomes a simulator for that model. The tool relies on an axiomatic
description; this choice allows us to outperform all previous simulation tools.
Additionally, we confirm that verification time is vastly improved, in the case
of bounded model-checking.
  Finally, we put our models in perspective, in the light of empirical data
obtained by analysing the C and C++ code of a Debian Linux distribution. We
present our new analysis tool, called mole, which explores a piece of code to
find the weak memory idioms that it uses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6823</identifier>
 <datestamp>2014-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6823</id><created>2013-08-30</created><authors><author><keyname>Miao</keyname><forenames>Hui</forenames></author><author><keyname>Liu</keyname><forenames>Xiangyang</forenames></author><author><keyname>Huang</keyname><forenames>Bert</forenames></author><author><keyname>Getoor</keyname><forenames>Lise</forenames></author></authors><title>A Hypergraph-Partitioned Vertex Programming Approach for Large-scale
  Consensus Optimization</title><categories>cs.AI cs.DC</categories><doi>10.1109/BigData.2013.6691623</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In modern data science problems, techniques for extracting value from big
data require performing large-scale optimization over heterogenous, irregularly
structured data. Much of this data is best represented as multi-relational
graphs, making vertex programming abstractions such as those of Pregel and
GraphLab ideal fits for modern large-scale data analysis. In this paper, we
describe a vertex-programming implementation of a popular consensus
optimization technique known as the alternating direction of multipliers
(ADMM). ADMM consensus optimization allows elegant solution of complex
objectives such as inference in rich probabilistic models. We also introduce a
novel hypergraph partitioning technique that improves over state-of-the-art
partitioning techniques for vertex programming and significantly reduces the
communication cost by reducing the number of replicated nodes up to an order of
magnitude. We implemented our algorithm in GraphLab and measure scaling
performance on a variety of realistic bipartite graph distributions and a large
synthetic voter-opinion analysis application. In our experiments, we are able
to achieve a 50% improvement in runtime over the current state-of-the-art
GraphLab partitioning scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6824</identifier>
 <datestamp>2013-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6824</id><created>2013-08-30</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Holten</keyname><forenames>Danny</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author><author><keyname>Speckmann</keyname><forenames>Bettina</forenames></author><author><keyname>Verbeek</keyname><forenames>Kevin</forenames></author></authors><title>Strict Confluent Drawing</title><categories>cs.CG</categories><comments>20 pages, 14 figures, Extended version of a paper to appear at Graph
  Drawing 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define strict confluent drawing, a form of confluent drawing in which the
existence of an edge is indicated by the presence of a smooth path through a
system of arcs and junctions (without crossings), and in which such a path, if
it exists, must be unique. We prove that it is NP-complete to determine whether
a given graph has a strict confluent drawing but polynomial to determine
whether it has an outerplanar strict confluent drawing with a fixed vertex
ordering (a drawing within a disk, with the vertices placed in a given order on
the boundary).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1308.6833</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1308.6833</id><created>2013-08-30</created><authors><author><keyname>Ahmadi</keyname><forenames>Amir Ali</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author></authors><title>Stability of Polynomial Differential Equations: Complexity and Converse
  Lyapunov Questions</title><categories>math.OC cs.CC cs.SY math.CA math.DS</categories><comments>30 pages. arXiv admin note: substantial text overlap with
  arXiv:1112.0741, arXiv:1210.7420</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider polynomial differential equations and make a number of
contributions to the questions of (i) complexity of deciding stability, (ii)
existence of polynomial Lyapunov functions, and (iii) existence of sum of
squares (sos) Lyapunov functions.
  (i) We show that deciding local or global asymptotic stability of cubic
vector fields is strongly NP-hard. Simple variations of our proof are shown to
imply strong NP-hardness of several other decision problems: testing local
attractivity of an equilibrium point, stability of an equilibrium point in the
sense of Lyapunov, invariance of the unit ball, boundedness of trajectories,
convergence of all trajectories in a ball to a given equilibrium point,
existence of a quadratic Lyapunov function, local collision avoidance, and
existence of a stabilizing control law.
  (ii) We present a simple, explicit example of a globally asymptotically
stable quadratic vector field on the plane which does not admit a polynomial
Lyapunov function (joint work with M. Krstic). For the subclass of homogeneous
vector fields, we conjecture that asymptotic stability implies existence of a
polynomial Lyapunov function, but show that the minimum degree of such a
Lyapunov function can be arbitrarily large even for vector fields in fixed
dimension and degree. For the same class of vector fields, we further establish
that there is no monotonicity in the degree of polynomial Lyapunov functions.
  (iii) We show via an explicit counterexample that if the degree of the
polynomial Lyapunov function is fixed, then sos programming may fail to find a
valid Lyapunov function even though one exists. On the other hand, if the
degree is allowed to increase, we prove that existence of a polynomial Lyapunov
function for a planar or a homogeneous vector field implies existence of a
polynomial Lyapunov function that is sos and that the negative of its
derivative is also sos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0003</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0003</id><created>2013-08-30</created><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>Concentration Inequalities for Bounded Random Vectors</title><categories>math.PR cs.LG math.ST stat.TH</categories><comments>9 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive simple concentration inequalities for bounded random vectors, which
generalize Hoeffding's inequalities for bounded scalar random variables. As
applications, we apply the general results to multinomial and Dirichlet
distributions to obtain multivariate concentration inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0029</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0029</id><created>2013-08-30</created><updated>2014-07-31</updated><authors><author><keyname>Feit</keyname><forenames>Sidnie</forenames></author></authors><title>A Canonical Partition of the Primes of Logic Functions</title><categories>math.CO cs.DM</categories><msc-class>05E99 (Primary), 06E30 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents algorithms that relate to the problem of finding a
minimum-cost sum-of-primes representation of a Boolean function f when the cost
function C is positive and additive. A set of primes whose sum equals f is
called a basis for f, so a solution to the problem is a minimum-cost basis.
  The algorithms construct the following canonical partition of the complete
set of primes and identify the members of sets 1, 2, and 3:
  (1) Essential Primes, which must be part of any basis for f,
  (2) Unnecessary Primes that cannot be part of a minimum-cost basis for f for
any positive additive cost function,
  (3) Unique disjoint sets of primes, PS1,...,PSN with associated &quot;covering&quot;
tables TS1,..., TSN such that any minimum-cost basis consists of the union of
the sets
  Essential Primes, QS1(C), ..., QSN(C) where QSi(C) is contained in PSi and
QSi(C) is a minimum-cost &quot;cover&quot; for PSi. Covering is defined by operation
Cascade(QS, TS), which has the property that QS covers PS if and only if
Cascade(QS, TS) is empty.
  The key to the results is the study of objects called Ancestor Sets. The
Ancestor Theorem proves that if A is an Ancestor Set for f, every minimum-cost
basis includes a minimum-cost cover for the set of primes PS in Ancestor Set A
and a minimum-cost cover for the set of primes that are not in A (and are not
covered by the the union of the Essentials with PS). The PSi in the partition
are the sets of primes in canonical disjoint Independent Ancestor Sets Ai,
which are easy to generate when the calculation of the primes (and their
consensus combinations) is within computational scope. The paper also presents
a condition under which QSi(C) can be easily determined, and another condition
such that PSi can be broken into disjoint pieces that can be minimized
separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0038</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0038</id><created>2013-08-30</created><updated>2013-11-15</updated><authors><author><keyname>Goedgebeur</keyname><forenames>Jan</forenames></author><author><keyname>Radziszowski</keyname><forenames>Stanis&#x142;aw P.</forenames></author></authors><title>The Ramsey Number $R(3,K_{10}-e)$ and Computational Bounds for $R(3,G)$</title><categories>math.CO cs.DM</categories><comments>25 pages</comments><msc-class>05C55, 05C30, 68R10</msc-class><journal-ref>Electronic Journal of Combinatorics, 20(4) (2013) #P19</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using computer algorithms we establish that the Ramsey number $R(3,K_{10}-e)$
is equal to 37, which solves the smallest open case for Ramsey numbers of this
type. We also obtain new upper bounds for the cases of $R(3,K_k-e)$ for $11 \le
k \le 16$, and show by construction a new lower bound $55 \le R(3,K_{13}-e)$.
  The new upper bounds on $R(3,K_k-e)$ are obtained by using the values and
lower bounds on $e(3,K_l-e,n)$ for $l \le k$, where $e(3,K_k-e,n)$ is the
minimum number of edges in any triangle-free graph on $n$ vertices without
$K_k-e$ in the complement. We complete the computation of the exact values of
$e(3,K_k-e,n)$ for all $n$ with $k \leq 10$ and for $n \leq 34$ with $k = 11$,
and establish many new lower bounds on $e(3,K_k-e,n)$ for higher values of $k$.
  Using the maximum triangle-free graph generation method, we determine two
other previously unknown Ramsey numbers, namely $R(3,K_{10}-K_3-e)=31$ and
$R(3,K_{10}-P_3-e)=31$. For graphs $G$ on 10 vertices, %besides $G=K_{10}$,
this leaves 6 other open besides $G=K_{10}$, this leaves 6 open cases of the
form $R(3,G)$. The hardest among them appears to be $G=K_{10}-2K_2$, for which
we establish the bounds $31 \le R(3,K_{10}-2K_2) \le 33$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0040</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0040</id><created>2013-08-30</created><authors><author><keyname>Oliveira</keyname><forenames>Cl&#xe1;udio L. N.</forenames></author><author><keyname>Morais</keyname><forenames>Pablo A.</forenames></author><author><keyname>Moreira</keyname><forenames>Andr&#xe9; A.</forenames></author><author><keyname>Andrade</keyname><forenames>Jos&#xe9; S.</forenames><suffix>Jr</suffix></author></authors><title>Enhanced Flow in Small-World Networks</title><categories>cond-mat.dis-nn cs.SI physics.soc-ph</categories><doi>10.1103/PhysRevLett.112.148701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The small-world property is known to have a profound effect on the navigation
efficiency of complex networks [J. M. Kleinberg, Nature 406, 845 (2000)].
Accordingly, the proper addition of shortcuts to a regular substrate can lead
to the formation of a highly efficient structure for information propagation.
Here we show that enhanced flow properties can also be observed in these
complex topologies. Precisely, our model is a network built from an underlying
regular lattice over which long-range connections are randomly added according
to the probability, $P_{ij}\sim r_{ij}^{-\alpha}$, where $r_{ij}$ is the
Manhattan distance between nodes $i$ and $j$, and the exponent $\alpha$ is a
controlling parameter. The mean two-point global conductance of the system is
computed by considering that each link has a local conductance given by
$g_{ij}\propto r_{ij}^{-\delta}$, where $\delta$ determines the extent of the
geographical limitations (costs) on the long-range connections. Our results
show that the best flow conditions are obtained for $\delta=0$ with $\alpha=0$,
while for $\delta \gg 1$ the overall conductance always increases with
$\alpha$. For $\delta\approx 1$, $\alpha=d$ becomes the optimal exponent, where
$d$ is the topological dimension of the substrate. Interestingly, this exponent
is identical to the one obtained for optimal navigation in small-world networks
using decentralized algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0052</identifier>
 <datestamp>2013-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0052</id><created>2013-08-30</created><updated>2013-10-15</updated><authors><author><keyname>Karimi</keyname><forenames>Kamran</forenames></author><author><keyname>Pamir</keyname><forenames>Aleks G.</forenames></author><author><keyname>Afzal</keyname><forenames>M. Haris</forenames></author></authors><title>Accelerating a Cloud-Based Software GNSS Receiver</title><categories>cs.PF cs.CE cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discuss ways to reduce the execution time of a software
Global Navigation Satellite System (GNSS) receiver that is meant for offline
operation in a cloud environment. Client devices record satellite signals they
receive, and send them to the cloud, to be processed by this software. The goal
of this project is for each client request to be processed as fast as possible,
but also to increase total system throughput by making sure as many requests as
possible are processed within a unit of time. The characteristics of our
application provided both opportunities and challenges for increasing
performance. We describe the speedups we obtained by enabling the software to
exploit multi-core CPUs and GPGPUs. We mention which techniques worked for us
and which did not. To increase throughput, we describe how we control the
resources allocated to each invocation of the software to process a client
request, such that multiple copies of the application can run at the same time.
We use the notion of effective running time to measure the system's throughput
when running multiple instances at the same time, and show how we can determine
when the system's computing resources have been saturated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0065</identifier>
 <datestamp>2014-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0065</id><created>2013-08-31</created><updated>2014-01-22</updated><authors><author><keyname>Dhungana</keyname><forenames>Deepak</forenames></author><author><keyname>Tang</keyname><forenames>Ching Hoo</forenames></author><author><keyname>Weidenbach</keyname><forenames>Christoph</forenames></author><author><keyname>Wischnewski</keyname><forenames>Patrick</forenames></author></authors><title>Automated Verification of Interactive Rule-Based Configuration Systems
  (Additional Material)</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Additional material for the original paper &quot;Automated Verification of
Interactive Rule-Based Configuration Systems&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0066</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0066</id><created>2013-08-31</created><authors><author><keyname>Narayan</keyname><forenames>Onuttom</forenames></author><author><keyname>Saniee</keyname><forenames>Iraj</forenames></author><author><keyname>Marbukh</keyname><forenames>Vladimir</forenames></author></authors><title>Congestion Due to Random Walk Routing</title><categories>cond-mat.dis-nn cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we derive an analytical expression for the mean load at each
node of an arbitrary undirected graph for the uniform multicommodity flow
problem under random walk routing. We show the mean load is linearly dependent
on the nodal degree with a common multiplier equal to the sum of the inverses
of the non-zero eigenvalue of the graph Laplacian. Even though some aspects of
the mean load value, such as linear dependence on the nodal degree, are
intuitive and may be derived from the equilibrium distribution of the random
walk on the undirected graph, the exact expression for the mean load in terms
of the full spectrum of the graph has not been known before. Using the explicit
expression for the mean load, we give asymptotic estimates for the load on a
variety of graphs whose spectral density are well known. We conclude with
numerical computation of the mean load for other well-known graphs without
known spectral densities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0073</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0073</id><created>2013-08-31</created><authors><author><keyname>Bo</keyname><forenames>Cheng</forenames></author><author><keyname>Zhang</keyname><forenames>Lan</forenames></author><author><keyname>Li</keyname><forenames>Xiang-Yang</forenames></author></authors><title>SilentSense: Silent User Identification via Dynamics of Touch and
  Movement Behavioral Biometrics</title><categories>cs.CR cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increased popularity of smartphones, various security threats and
privacy leakages targeting them are discovered and investigated. In this work,
we present \ourprotocoltight, a framework to authenticate users silently and
transparently by exploiting dynamics mined from the user touch behavior
biometrics and the micro-movement of the device caused by user's screen-touch
actions. We build a &quot;touch-based biometrics&quot; model of the owner by extracting
some principle features, and then verify whether the current user is the owner
or guest/attacker. When using the smartphone, the unique operating dynamics of
the user is detected and learnt by collecting the sensor data and touch events
silently. When users are mobile, the micro-movement of mobile devices caused by
touch is suppressed by that due to the large scale user-movement which will
render the touch-based biometrics ineffective. To address this, we integrate a
movement-based biometrics for each user with previous touch-based biometrics.
We conduct extensive evaluations of our approaches on the Android smartphone,
we show that the user identification accuracy is over 99%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0081</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0081</id><created>2013-08-31</created><authors><author><keyname>Nip</keyname><forenames>Kameng</forenames></author><author><keyname>Wang</keyname><forenames>Zhenbo</forenames></author><author><keyname>Nobibon</keyname><forenames>Fabrice Talla</forenames></author><author><keyname>Leus</keyname><forenames>Roel</forenames></author></authors><title>A Combination of Flow Shop Scheduling and the Shortest Path Problem</title><categories>cs.DS</categories><comments>18 pages, 5 figures</comments><report-no>KBI_1316</report-no><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a combinatorial optimization problem which is obtained by
combining the flow shop scheduling problem and the shortest path problem. The
objective of the obtained problem is to select a subset of jobs that
constitutes a feasible solution to the shortest path problem, and to execute
the selected jobs on the flow shop machines to minimize the makespan. We argue
that this problem is NP-hard even if the number of machines is two, and is
NP-hard in the strong sense for the general case. We propose an intuitive
approximation algorithm for the case where the number of machines is an input,
and an improved approximation algorithm for fixed number of machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0082</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0082</id><created>2013-08-31</created><authors><author><keyname>Nip</keyname><forenames>Kameng</forenames></author><author><keyname>Wang</keyname><forenames>Zhenbo</forenames></author><author><keyname>Xing</keyname><forenames>Wenxun</forenames></author></authors><title>Combinations of Some Shop Scheduling Problems and the Shortest Path
  Problem: Complexity and Approximation Algorithms</title><categories>cs.DS</categories><comments>19 pages, 1 figure</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider several combinatorial optimization problems which combine the
classic shop scheduling problems, namely open shop scheduling or job shop
scheduling, and the shortest path problem. The objective of the obtained
problem is to select a subset of jobs that forms a feasible solution of the
shortest path problem, and to execute the selected jobs on the open (or job)
shop machines to minimize the makespan. We show that these problems are NP-hard
even if the number of machines is two, and cannot be approximated within a
factor less than 2 if the number of machines is an input unless P=NP. We
present several approximation algorithms for these combination problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0085</identifier>
 <datestamp>2015-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0085</id><created>2013-08-31</created><authors><author><keyname>Qadir</keyname><forenames>Junaid</forenames></author></authors><title>Artificial Intelligence Based Cognitive Routing for Cognitive Radio
  Networks</title><categories>cs.NI cs.AI</categories><comments>28 pages, submitted to IEEE Communications Surveys and Tutorials</comments><journal-ref>Artificial Intelligence Review pp 1-72 First online: 03 September
  2015</journal-ref><doi>10.1007/s10462-015-9438-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio networks (CRNs) are networks of nodes equipped with cognitive
radios that can optimize performance by adapting to network conditions. While
cognitive radio networks (CRN) are envisioned as intelligent networks,
relatively little research has focused on the network level functionality of
CRNs. Although various routing protocols, incorporating varying degrees of
adaptiveness, have been proposed for CRNs, it is imperative for the long term
success of CRNs that the design of cognitive routing protocols be pursued by
the research community. Cognitive routing protocols are envisioned as routing
protocols that fully and seamless incorporate AI-based techniques into their
design. In this paper, we provide a self-contained tutorial on various AI and
machine-learning techniques that have been, or can be, used for developing
cognitive routing protocols. We also survey the application of various classes
of AI techniques to CRNs in general, and to the problem of routing in
particular. We discuss various decision making techniques and learning
techniques from AI and document their current and potential applications to the
problem of routing in CRNs. We also highlight the various inference, reasoning,
modeling, and learning sub tasks that a cognitive routing protocol must solve.
Finally, open research issues and future directions of work are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0088</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0088</id><created>2013-08-31</created><authors><author><keyname>Shariatpanahi</keyname><forenames>Seyed Pooya</forenames></author><author><keyname>Shah-Mansouri</keyname><forenames>Hamed</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak Hossein</forenames></author></authors><title>Caching Gain in Wireless Networks with Fading: A Multi-User Diversity
  Perspective</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the effect of caching in wireless networks where fading is the
dominant channel effect. First, we propose a one-hop transmission strategy for
cache-enabled wireless networks, which is based on exploiting multi-user
diversity gain. Then, we derive a closed-form result for throughput scaling of
the proposed scheme in large networks, which reveals the inherent trade-off
between cache memory size and network throughput. Our results show that
substantial throughput improvements are achievable in networks with sources
equipped with large cache size. We also verify our analytical result through
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0111</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0111</id><created>2013-08-31</created><authors><author><keyname>Miyazako</keyname><forenames>Hiroki</forenames></author><author><keyname>Hori</keyname><forenames>Yutaka</forenames></author><author><keyname>Hara</keyname><forenames>Shinji</forenames></author></authors><title>Turing Instability in Reaction-Diffusion Systems with a Single Diffuser:
  Characterization Based on Root Locus</title><categories>cs.SY nlin.PS q-bio.QM</categories><journal-ref>Proceedings of IEEE Conference on Decision and Control, pp. 2671 -
  2676, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative behaviors arising from bacterial cell-to-cell communication can
be modeled by reaction-diffusion equations having only a single diffusible
component. This paper presents the following three contributions for the
systematic analysis of Turing instability in such reaction-diffusion systems.
(i) We first introduce a unified framework to formulate the reaction-diffusion
system as an interconnected multi-agent dynamical system. (ii) Then, we
mathematically classify biologically plausible and implausible Turing
instabilities and characterize them by the root locus of each agent's dynamics,
or the local reaction dynamics. (iii) Using this characterization, we derive
analytic conditions for biologically plausible Turing instability, which
provide useful guidance for the design and the analysis of biological networks.
These results are demonstrated on an extended Gray-Scott model with a single
diffuser.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0113</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0113</id><created>2013-08-31</created><authors><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author></authors><title>Non-Asymptotic Convergence Analysis of Inexact Gradient Methods for
  Machine Learning Without Strong Convexity</title><categories>math.OC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many recent applications in machine learning and data fitting call for the
algorithmic solution of structured smooth convex optimization problems.
Although the gradient descent method is a natural choice for this task, it
requires exact gradient computations and hence can be inefficient when the
problem size is large or the gradient is difficult to evaluate. Therefore,
there has been much interest in inexact gradient methods (IGMs), in which an
efficiently computable approximate gradient is used to perform the update in
each iteration. Currently, non-asymptotic linear convergence results for IGMs
are typically established under the assumption that the objective function is
strongly convex, which is not satisfied in many applications of interest; while
linear convergence results that do not require the strong convexity assumption
are usually asymptotic in nature. In this paper, we combine the best of these
two types of results and establish---under the standard assumption that the
gradient approximation errors decrease linearly to zero---the non-asymptotic
linear convergence of IGMs when applied to a class of structured convex
optimization problems. Such a class covers settings where the objective
function is not necessarily strongly convex and includes the least squares and
logistic regression problems. We believe that our techniques will find further
applications in the non-asymptotic convergence analysis of other first-order
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0123</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0123</id><created>2013-08-31</created><updated>2013-10-01</updated><authors><author><keyname>Liu</keyname><forenames>Ryan Wen</forenames></author><author><keyname>Xu</keyname><forenames>Tian</forenames></author></authors><title>A Robust Alternating Direction Method for Constrained Hybrid Variational
  Deblurring Model</title><categories>cs.CV</categories><comments>4 pages, 5 figures</comments><msc-class>65K10, 68U10</msc-class><acm-class>I.4.4; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, a new constrained hybrid variational deblurring model is
developed by combining the non-convex first- and second-order total variation
regularizers. Moreover, a box constraint is imposed on the proposed model to
guarantee high deblurring performance. The developed constrained hybrid
variational model could achieve a good balance between preserving image details
and alleviating ringing artifacts. In what follows, we present the
corresponding numerical solution by employing an iteratively reweighted
algorithm based on alternating direction method of multipliers. The
experimental results demonstrate the superior performance of the proposed
method in terms of quantitative and qualitative image quality assessments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0129</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0129</id><created>2013-08-31</created><authors><author><keyname>Zeng</keyname><forenames>An</forenames></author><author><keyname>Vidmer</keyname><forenames>Alexandre</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Information filtering via hybridization of similarity preferential
  diffusion processes</title><categories>cs.IR cs.SI physics.soc-ph</categories><comments>6 pages, 4 figures, 2 tables</comments><doi>10.1209/0295-5075/105/58002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recommender system is one of the most promising ways to address the
information overload problem in online systems. Based on the personal
historical record, the recommender system can find interesting and relevant
objects for the user within a huge information space. Many physical processes
such as the mass diffusion and heat conduction have been applied to design the
recommendation algorithms. The hybridization of these two algorithms has been
shown to provide both accurate and diverse recommendation results. In this
paper, we proposed two similarity preferential diffusion processes. Extensive
experimental analyses on two benchmark data sets demonstrate that both
recommendation and accuracy and diversity are improved duet to the similarity
preference in the diffusion. The hybridization of the similarity preferential
diffusion processes is shown to significantly outperform the state-of-art
recommendation algorithm. Finally, our analysis on network sparsity show that
there is significant difference between dense and sparse system, indicating
that all the former conclusions on recommendation in the literature should be
reexamined in sparse system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0136</identifier>
 <datestamp>2014-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0136</id><created>2013-08-31</created><updated>2014-07-19</updated><authors><author><keyname>Breiten</keyname><forenames>Tobias</forenames></author><author><keyname>Beattie</keyname><forenames>Christopher</forenames></author><author><keyname>Gugercin</keyname><forenames>Serkan</forenames></author></authors><title>Near-optimal Frequency-weighted Interpolatory Model Reduction</title><categories>cs.SY math.DS math.NA</categories><report-no>Max Planck Institute Magdeburg Preprint MPIMD/13-15</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops an interpolatory framework for weighted-$\mathcal{H}_2$
model reduction of MIMO dynamical systems. A new representation of the
weighted-$\mathcal{H}_2$ inner products in MIMO settings is introduced and used
to derive associated first-order necessary conditions satisfied by optimal
weighted-$\mathcal{H}_2$ reduced-order models. Equivalence of these new
interpolatory conditions with earlier Riccati-based conditions given by Halevi
is also shown. An examination of realizations for equivalent
weighted-$\mathcal{H}_2$ systems leads then to an algorithm that remains
tractable for large state-space dimension. Several numerical examples
illustrate the effectiveness of this approach and its competitiveness with
Frequency Weighted Balanced Truncation and an earlier interpolatory approach,
the Weighted Iterative Rational Krylov Algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0141</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0141</id><created>2013-08-31</created><authors><author><keyname>Polyanskiy</keyname><forenames>Yury</forenames></author><author><keyname>Verdu</keyname><forenames>Sergio</forenames></author></authors><title>Empirical distribution of good channel codes with non-vanishing error
  probability (extended version)</title><categories>cs.IT math.IT math.PR</categories><comments>Extended version of the article submitted to IEEE Trans. Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies several properties of channel codes that approach the
fundamental limits of a given (discrete or Gaussian) memoryless channel with a
non-vanishing probability of error. The output distribution induced by an
$\epsilon$-capacity-achieving code is shown to be close in a strong sense to
the capacity achieving output distribution. Relying on the concentration of
measure (isoperimetry) property enjoyed by the latter, it is shown that regular
(Lipschitz) functions of channel outputs can be precisely estimated and turn
out to be essentially non-random and independent of the actual code. It is also
shown that the output distribution of a good code and the capacity achieving
one cannot be distinguished with exponential reliability. The random process
produced at the output of the channel is shown to satisfy the asymptotic
equipartition property. Using related methods it is shown that quadratic forms
and sums of $q$-th powers when evaluated at codewords of good AWGN codes
approach the values obtained from a randomly generated Gaussian codeword.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0145</identifier>
 <datestamp>2014-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0145</id><created>2013-08-31</created><updated>2014-07-08</updated><authors><author><keyname>Douik</keyname><forenames>Ahmed</forenames></author><author><keyname>Sorour</keyname><forenames>Sameh</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author></authors><title>Delay Minimization for Instantly Decodable Network Coding in Persistent
  Channels with Feedback Intermittence</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of minimizing the multicast decoding
delay of generalized instantly decodable network coding (G-IDNC) over
persistent forward and feedback erasure channels with feedback intermittence.
In such an environment, the sender does not always receive acknowledgement from
the receivers after each transmission. Moreover, both the forward and feedback
channels are subject to persistent erasures, which can be modelled by a two
state (good and bad states) Markov chain known as Gilbert-Elliott channel
(GEC). Due to such feedback imperfections, the sender is unable to determine
subsequent instantly decodable packets combination for all receivers. Given
this harsh channel and feedback model, we first derive expressions for the
probability distributions of decoding delay increments and then employ these
expressions in formulating the minimum decoding problem in such environment as
a maximum weight clique problem in the G-IDNC graph. We also show that the
problem formulations in simpler channel and feedback models are special cases
of our generalized formulation. Since this problem is NP-hard, we design a
greedy algorithm to solve it and compare it to blind approaches proposed in
literature. Through extensive simulations, our adaptive algorithm is shown to
outperform the blind approaches in all situations and to achieve significant
improvement in the decoding delay, especially when the channel is highly
persistent
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0157</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0157</id><created>2013-08-31</created><updated>2013-12-04</updated><authors><author><keyname>Wu</keyname><forenames>Gaofei</forenames></author><author><keyname>Parker</keyname><forenames>Matthew G.</forenames></author></authors><title>A complementary construction using mutually unbiased bases</title><categories>cs.IT cs.DM math.IT</categories><comments>25 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a construction for complementary pairs of arrays that exploits a
set of mutually-unbiased bases, and enumerate these arrays as well as the
corresponding set of complementary sequences obtained from the arrays by
projection. We also sketch an algorithm to uniquely generate these sequences.
The pairwise squared inner-product of members of the sequence set is shown to
be $\frac{1}{2}$. Moreover, a subset of the set can be viewed as a codebook
that asymptotically achieves $\sqrt{\frac{3}{2}}$ times the Welch bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0158</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0158</id><created>2013-08-31</created><updated>2015-05-16</updated><authors><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author></authors><title>Robustness of large-scale stochastic matrices to localized perturbations</title><categories>math.PR cs.DM cs.SI cs.SY</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Upper bounds are derived on the total variation distance between the
invariant distributions of two stochastic matrices differing on a subset W of
rows. Such bounds depend on three parameters: the mixing time and the minimal
expected hitting time on W for the Markov chain associated to one of the
matrices; and the escape time from W for the Markov chain associated to the
other matrix. These results, obtained through coupling techniques, prove
particularly useful in scenarios where W is a small subset of the state space,
even if the difference between the two matrices is not small in any norm.
Several applications to large-scale network problems are discussed, including
robustness of Google's PageRank algorithm, distributed averaging and consensus
algorithms, and interacting particle systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0165</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0165</id><created>2013-08-31</created><authors><author><keyname>Georgiou</keyname><forenames>Tryphon T.</forenames></author><author><keyname>Lindquist</keyname><forenames>Anders</forenames></author></authors><title>On time-reversibility of linear stochastic models</title><categories>cs.SY math.PR</categories><comments>10 pages, 4 figures</comments><msc-class>93E03, 60G12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversal of the time direction in stochastic systems driven by white noise
has been central throughout the development of stochastic realization theory,
filtering and smoothing. Similar ideas were developed in connection with
certain problems in the theory of moments, where a duality induced by time
reversal was introduced to parametrize solutions. In this latter work it was
shown that stochastic systems driven by arbitrary second-order stationary
processes can be similarly time-reversed. By combining these two sets of ideas
we present herein a generalization of time-reversal in stochastic realization
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0185</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0185</id><created>2013-09-01</created><authors><author><keyname>Yadav</keyname><forenames>S. Sri Gurudatta</forenames></author><author><keyname>Krishnaiah</keyname><forenames>R. V.</forenames></author></authors><title>Haptic Science and Technology</title><categories>cs.HC</categories><comments>8 Pages</comments><journal-ref>International Journal of Computer Engineering and Technology,
  August, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Haptic technology, or haptics, is a tactile feedback technology which takes
advantage of a user's sense of touch by applying forces, vibrations, and/or
motions upon the user. This mechanical stimulation may be used to assist in the
creation of virtual objects (objects existing only in a computer simulation),
for control of such virtual objects, and for the enhancement of the remote
control of machines and devices. It has been described as for the sense of
touch what computer graphics does for vision. Although haptic devices are
capable of measuring bulk or reactive forces that are applied by the user, it
should not be confused with touch or tactile sensors that measure the pressure
or force exerted by the user to the interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0186</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0186</id><created>2013-09-01</created><authors><author><keyname>Rashmi</keyname><forenames>K. V.</forenames></author><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Gu</keyname><forenames>Dikang</forenames></author><author><keyname>Kuang</keyname><forenames>Hairong</forenames></author><author><keyname>Borthakur</keyname><forenames>Dhruba</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>A Solution to the Network Challenges of Data Recovery in Erasure-coded
  Distributed Storage Systems: A Study on the Facebook Warehouse Cluster</title><categories>cs.NI cs.DC cs.IT math.IT</categories><comments>In proceedings of USENIX HotStorage, San Jose, June 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Erasure codes, such as Reed-Solomon (RS) codes, are being increasingly
employed in data centers to combat the cost of reliably storing large amounts
of data. Although these codes provide optimal storage efficiency, they require
significantly high network and disk usage during recovery of missing data. In
this paper, we first present a study on the impact of recovery operations of
erasure-coded data on the data-center network, based on measurements from
Facebook's warehouse cluster in production. To the best of our knowledge, this
is the first study of its kind available in the literature. Our study reveals
that recovery of RS-coded data results in a significant increase in network
traffic, more than a hundred terabytes per day, in a cluster storing multiple
petabytes of RS-coded data.
  To address this issue, we present a new storage code using our recently
proposed &quot;Piggybacking&quot; framework, that reduces the network and disk usage
during recovery by 30% in theory, while also being storage optimal and
supporting arbitrary design parameters. The implementation of the proposed code
in the Hadoop Distributed File System (HDFS) is underway. We use the
measurements from the warehouse cluster to show that the proposed code would
lead to a reduction of close to fifty terabytes of cross-rack traffic per day.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0188</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0188</id><created>2013-09-01</created><authors><author><keyname>Olusegun</keyname><forenames>Oyelami Julius</forenames></author><author><keyname>Ithnin</keyname><forenames>Norafida Binti</forenames></author></authors><title>People Are the Answer to Security: Establishing a Sustainable
  Information Security Awareness Training (ISAT) Program in Organization</title><categories>cs.CY</categories><journal-ref>International Journal of Computer Science and Information
  Security, Vol.11, No 8, August 2013, Paper ID 31071337</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Educating the users on the essential of information security is very vital
and important to the mission of establishing a sustainable information security
in any organization and institute. At the University Technology Malaysia (UTM),
we have recognized the fact that, it is about time information security should
no longer be a lacking factor in productivity, both information security and
productivity must work together in closed proximity. We have recently
implemented a broad campus information security awareness program to educate
faculty member, staff, students and non-academic staff on this essential topic
of information security. The program consists of training based on web,
personal or individual training with a specific monthly topic, campus
campaigns, guest speakers and direct presentations to specialized groups. The
goal and the objective are to educate the users on the challenges that are
specific to information security and to create total awareness that will change
the perceptions of people thinking and ultimately their reactions when it comes
to information security. In this paper, we explain how we created and
implemented our information security awareness training (ISAT) program and
discuss the impediment we encountered along the process. We explore different
methods of deliveries such as target audiences, and probably the contents as we
believe might be vital to a successful information security program. Finally,
we discuss the importance and the flexibility of establishing a sustainable
information security training program that could be adopted to meet current and
future needs and demands while still relevant to our current users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0189</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0189</id><created>2013-09-01</created><authors><author><keyname>Olusegun</keyname><forenames>Oyelami Julius</forenames></author><author><keyname>Ithnin</keyname><forenames>Norafida Binti</forenames></author></authors><title>Enhancing the Conventional Information Security Management Maturity
  Model (ISM3) in Resolving Human Factors in Organization Information Sharing</title><categories>cs.CY</categories><journal-ref>International Journal of Computer Science and Information
  Security, Vol.11, No.8, August 2013, Paper ID 31071338</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Information sharing in organization has been considered as an important
approach in increasing organizational efficiency, performance and decision
making. With the present and advances in information and communication
technology, sharing information and exchanging of data across organizations has
become more feasible in organization. However, information sharing has been a
complex task over the years and identifying factors that influence information
sharing across organization has becomes crucial and critical. Researchers have
taken several methods and approaches to resolve problems in information sharing
at all levels without a lasting solution, as sharing is best understood as a
practice that reflects behavior, social, economic, legal and technological
influences. Due to the limitation of the conventional ISM3 standards to address
culture, social, legislation and human behavior, the findings in this paper
suggest that, a centralized information structure without human practice,
distribution of information and coordination is not effective. This paper
reviews the previous information sharing research, outlines the factors
affecting information sharing and the different practices needed to improve the
management of information security by recommending several combinations of
information security and coordination mechanism for reducing uncertainty during
sharing of information .This thesis proposes information security management
protocol (ISMP) as an enhancement towards ISM3 to resolve the above problems.
This protocol provides a means for practitioners to identify key factors
involved in successful information sharing.....
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0192</identifier>
 <datestamp>2014-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0192</id><created>2013-09-01</created><updated>2014-01-16</updated><authors><author><keyname>Lozev</keyname><forenames>Kamen M.</forenames></author></authors><title>Reconstruction and uniqueness of moving obstacles</title><categories>cs.DS cs.GR</categories><comments>21 pages, 6 figures, 3 tables. arXiv admin note: text overlap with
  arXiv:1111.6321</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the uniqueness and accuracy of the numerical solution of the problem
of reconstruction of the shape and trajectory of a reflecting obstacle moving
in an inhomogeneous medium from travel times, start and end points, and initial
angles of ultrasonic rays reflecting at the obstacle. The speed of sound in the
domain when there is no obstacle present is known and provided as an input
parameter which together with the other initial data enables the algorithm to
trace ray paths and find their reflection points. The reflection points
determine with high-resolution the shape and trajectory of the obstacle. The
method has predictable computational complexity and performance and is very
efficient when it is parallelized and optimized because only a small portion of
the domain is reconstructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0193</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0193</id><created>2013-09-01</created><authors><author><keyname>Chauhan</keyname><forenames>Ram Chandra Singh</forenames></author><author><keyname>Singh</keyname><forenames>Yatindra Nath</forenames></author><author><keyname>Asthana</keyname><forenames>Rachna</forenames></author></authors><title>Design of Minimum Correlated, Maximal Clique Sets of One-Dimensional
  Uni-polar (Optical) Orthogonal Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an algorithm to search a family of multiple sets of
minimum correlated one dimensional uni-polar (optical) orthogonal codes
(1-DUOC) or optical orthogonal codes (OOC) with fixed as well as variable code
parameters. The cardinality of each set is equal to upper bound. The codes
within a set can be searched for general values of code length, code weight,
auto-correlation constraint and cross-correlation constraint. Each set forms a
maximal clique of the codes within given range of correlation properties .
These one-dimensional uni-polar orthogonal codes can find their application as
signature sequences for spectral spreading purpose in incoherent optical code
division multiple access (CDMA) systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0195</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0195</id><created>2013-09-01</created><authors><author><keyname>Mertzios</keyname><forenames>George B.</forenames></author><author><keyname>Shalom</keyname><forenames>Mordechai</forenames></author><author><keyname>Wong</keyname><forenames>Prudence W. H.</forenames></author><author><keyname>Zaks</keyname><forenames>Shmuel</forenames></author></authors><title>Online Regenerator Placement</title><categories>cs.NI cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connections between nodes in optical networks are realized by lightpaths. Due
to the decay of the signal, a regenerator has to be placed on every lightpath
after at most $d$ hops, for some given positive integer $d$. A regenerator can
serve only one lightpath. The placement of regenerators has become an active
area of research during recent years, and various optimization problems have
been studied. The first such problem is the Regeneration Location Problem
($\prb$), where the goal is to place the regenerators so as to minimize the
total number of nodes containing them. We consider two extreme cases of online
$\prb$ regarding the value of $d$ and the number $k$ of regenerators that can
be used in any single node. (1) $d$ is arbitrary and $k$ unbounded. In this
case a feasible solution always exists. We show an $O(\log \abs{X} \cdot \log
d)$-competitive randomized algorithm for any network topology, where $X$ is the
set of paths of length $d$. The algorithm can be made deterministic in some
cases. We show a deterministic lower bound of $\Omega \lb$, where $E$ is the
edge set. (2) $d=2$ and $k=1$. In this case there is not necessarily a solution
for a given input. We distinguish between feasible inputs (for which there is a
solution) and infeasible ones. In the latter case, the objective is to satisfy
the maximum number of lightpaths. For a path topology we show a lower bound of
$\sqrt{l}/2$ for the competitive ratio (where $l$ is the number of internal
nodes of the longest lightpath) on infeasible inputs, and a tight bound of 3
for the competitive ratio on feasible inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0199</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0199</id><created>2013-09-01</created><authors><author><keyname>Wu</keyname><forenames>Baofeng</forenames></author><author><keyname>Lin</keyname><forenames>Dongdai</forenames></author></authors><title>New constructions of quaternary bent functions</title><categories>cs.DM math.CO</categories><msc-class>11T23, 11T71, 13M10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new construction of quaternary bent functions from
quaternary quadratic forms over Galois rings of characteristic 4 is proposed.
Based on this construction, several new classes of quaternary bent functions
are obtained, and as a consequence, several new classes of quadratic binary
bent and semi-bent functions in polynomial forms are derived. This work
generalizes the recent work of N. Li, X. Tang and T. Helleseth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0212</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0212</id><created>2013-09-01</created><authors><author><keyname>Cui</keyname><forenames>Tao</forenames></author><author><keyname>Xu</keyname><forenames>Jinchao</forenames></author><author><keyname>Zhang</keyname><forenames>Chen-Song</forenames></author></authors><title>An Error-Resilient Redundant Subspace Correction Method</title><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As we stride toward the exascale era, due to increasing complexity of
supercomputers, hard and soft errors are causing more and more problems in
high-performance scientific and engineering computation. In order to improve
reliability (increase the mean time to failure) of computing systems, a lot of
efforts have been devoted to developing techniques to forecast, prevent, and
recover from errors at different levels, including architecture, application,
and algorithm. In this paper, we focus on algorithmic error resilient iterative
linear solvers and introduce a redundant subspace correction method. Using a
general framework of redundant subspace corrections, we construct iterative
methods, which have the following properties: (1) Maintain convergence when
error occurs assuming it is detectable; (2) Introduce low computational
overhead when no error occurs; (3) Require only small amount of local
(point-to-point) communication compared to traditional methods and maintain
good load balance; (4) Improve the mean time to failure. With the proposed
method, we can improve reliability of many scientific and engineering
applications. Preliminary numerical experiments demonstrate the efficiency and
effectiveness of the new subspace correction method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0213</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0213</id><created>2013-09-01</created><updated>2013-09-02</updated><authors><author><keyname>Gao</keyname><forenames>Fei</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author><author><keyname>Gao</keyname><forenames>Xinbo</forenames></author><author><keyname>Li</keyname><forenames>Xuelong</forenames></author></authors><title>Learning to Rank for Blind Image Quality Assessment</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blind image quality assessment (BIQA) aims to predict perceptual image
quality scores without access to reference images. State-of-the-art BIQA
methods typically require subjects to score a large number of images to train a
robust model. However, the acquisition of image quality scores has several
limitations: 1) scores are not precise, because subjects are usually uncertain
about which score most precisely represents the perceptual quality of a given
image; 2) subjective judgements of quality may be biased by image content; 3)
the quality scales between different distortion categories are inconsistent;
and 4) it is challenging to obtain a large scale database, or to extend
existing databases, because of the inconvenience of collecting sufficient
images, training the subjects, conducting subjective experiments, and
realigning human quality evaluations. To combat these limitations, this paper
explores and exploits preference image pairs such as &quot;the quality of image Ia
is better than that of image Ib&quot; for training a robust BIQA model. The
preference label, representing the relative quality of two images, is generally
precise and consistent, and is not sensitive to image content, distortion type,
or subject identity; such PIPs can be generated at very low cost. The proposed
BIQA method is one of learning to rank. We first formulate the problem of
learning the mapping from the image features to the preference label as one of
classification. In particular, we investigate the utilization of a multiple
kernel learning algorithm based on group lasso (MKLGL) to provide a solution. A
simple but effective strategy to estimate perceptual image quality scores is
then presented. Experiments show that the proposed BIQA method is highly
effective and achieves comparable performance to state-of-the-art BIQA
algorithms. Moreover, the proposed method can be easily extended to new
distortion categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0215</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0215</id><created>2013-09-01</created><authors><author><keyname>Lu</keyname><forenames>Mian</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Huynh</keyname><forenames>Huynh Phung</forenames></author><author><keyname>Ong</keyname><forenames>Zhongliang</forenames></author><author><keyname>Liang</keyname><forenames>Yun</forenames></author><author><keyname>He</keyname><forenames>Bingsheng</forenames></author><author><keyname>Goh</keyname><forenames>Rick Siow Mong</forenames></author><author><keyname>Huynh</keyname><forenames>Richard</forenames></author></authors><title>Optimizing the MapReduce Framework on Intel Xeon Phi Coprocessor</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the ease-of-programming, flexibility and yet efficiency, MapReduce has
become one of the most popular frameworks for building big-data applications.
MapReduce was originally designed for distributed-computing, and has been
extended to various architectures, e,g, multi-core CPUs, GPUs and FPGAs. In
this work, we focus on optimizing the MapReduce framework on Xeon Phi, which is
the latest product released by Intel based on the Many Integrated Core
Architecture. To the best of our knowledge, this is the first work to optimize
the MapReduce framework on the Xeon Phi.
  In our work, we utilize advanced features of the Xeon Phi to achieve high
performance. In order to take advantage of the SIMD vector processing units, we
propose a vectorization friendly technique for the map phase to assist the
auto-vectorization as well as develop SIMD hash computation algorithms.
Furthermore, we utilize MIMD hyper-threading to pipeline the map and reduce to
improve the resource utilization. We also eliminate multiple local arrays but
use low cost atomic operations on the global array for some applications, which
can improve the thread scalability and data locality due to the coherent L2
caches. Finally, for a given application, our framework can either
automatically detect suitable techniques to apply or provide guideline for
users at compilation time. We conduct comprehensive experiments to benchmark
the Xeon Phi and compare our optimized MapReduce framework with a
state-of-the-art multi-core based MapReduce framework (Phoenix++). By
evaluating six real-world applications, the experimental results show that our
optimized framework is 1.2X to 38X faster than Phoenix++ for various
applications on the Xeon Phi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0225</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0225</id><created>2013-09-01</created><authors><author><keyname>Noel</keyname><forenames>Jonathan A.</forenames></author></authors><title>Choosability of Graphs with Bounded Order: Ohba's Conjecture and Beyond</title><categories>math.CO cs.DM</categories><comments>Master's Thesis, McGill University</comments><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \emph{choice number} of a graph $G$, denoted $\ch(G)$, is the minimum
integer $k$ such that for any assignment of lists of size $k$ to the vertices
of $G$, there is a proper colouring of $G$ such that every vertex is mapped to
a colour in its list. For general graphs, the choice number is not bounded
above by a function of the chromatic number.
  In this thesis, we prove a conjecture of Ohba which asserts that
$\ch(G)=\chi(G)$ whenever $|V(G)|\leq 2\chi(G)+1$. We also prove a
strengthening of Ohba's Conjecture which is best possible for graphs on at most
$3\chi(G)$ vertices, and pose several conjectures related to our work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0238</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0238</id><created>2013-09-01</created><authors><author><keyname>Buitinck</keyname><forenames>Lars</forenames><affiliation>ILPS</affiliation></author><author><keyname>Louppe</keyname><forenames>Gilles</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Blondel</keyname><forenames>Mathieu</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Pedregosa</keyname><forenames>Fabian</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Mueller</keyname><forenames>Andreas</forenames><affiliation>INRIA Saclay - Ile de France, LTCI</affiliation></author><author><keyname>Grisel</keyname><forenames>Olivier</forenames><affiliation>INRIA Saclay - Ile de France, LTCI</affiliation></author><author><keyname>Niculae</keyname><forenames>Vlad</forenames><affiliation>INRIA Saclay - Ile de France, LTCI</affiliation></author><author><keyname>Prettenhofer</keyname><forenames>Peter</forenames><affiliation>INRIA Saclay - Ile de France, LTCI</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>INRIA Saclay - Ile de France, LTCI</affiliation></author><author><keyname>Grobler</keyname><forenames>Jaques</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Layton</keyname><forenames>Robert</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Vanderplas</keyname><forenames>Jake</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Joly</keyname><forenames>Arnaud</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Holt</keyname><forenames>Brian</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author></authors><title>API design for machine learning software: experiences from the
  scikit-learn project</title><categories>cs.LG cs.MS</categories><proxy>ccsd</proxy><journal-ref>European Conference on Machine Learning and Principles and
  Practices of Knowledge Discovery in Databases (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scikit-learn is an increasingly popular machine learning li- brary. Written
in Python, it is designed to be simple and efficient, accessible to
non-experts, and reusable in various contexts. In this paper, we present and
discuss our design choices for the application programming interface (API) of
the project. In particular, we describe the simple and elegant interface shared
by all learning and processing units in the library and then discuss its
advantages in terms of composition and reusability. The paper also comments on
implementation details specific to the Python ecosystem and analyzes obstacles
faced by users and developers of the library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0239</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0239</id><created>2013-09-01</created><updated>2014-02-09</updated><authors><author><keyname>Castiglione</keyname><forenames>Paolo</forenames></author><author><keyname>Matz</keyname><forenames>Gerald</forenames></author></authors><title>Energy-Neutral Source-Channel Coding with Battery and Memory Size
  Constraints</title><categories>cs.IT math.IT</categories><comments>This work has been accepted for publication in IEEE Transactions on
  Communications. IEEE Copyright rules apply</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study energy management policies for the compression and transmission of
source data collected by an energy-harvesting sensor node with a finite energy
buffer (e.g., rechargeable battery) and a finite data buffer (memory) between
source encoder and channel encoder. The sensor node can adapt the source and
channel coding rates depending on the observation and channel states. In such a
system, the absence of precise information about the amount of energy available
in the future is a key challenge. We provide analytical bounds and scaling laws
for the average distortion that depend on the size of the energy and data
buffers. We furthermore design a resource allocation policy that achieves
almost optimal distortion scaling. Our results demonstrate that the energy
leakage of state of art energy management policies can be avoided by jointly
controlling the source and channel coding rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0242</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0242</id><created>2013-09-01</created><authors><author><keyname>Dahlin</keyname><forenames>Johan</forenames></author><author><keyname>Svenson</keyname><forenames>Pontus</forenames></author></authors><title>Ensemble approaches for improving community detection methods</title><categories>physics.soc-ph cs.LG cs.SI stat.ML</categories><comments>12 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical estimates can often be improved by fusion of data from several
different sources. One example is so-called ensemble methods which have been
successfully applied in areas such as machine learning for classification and
clustering. In this paper, we present an ensemble method to improve community
detection by aggregating the information found in an ensemble of community
structures. This ensemble can found by re-sampling methods, multiple runs of a
stochastic community detection method, or by several different community
detection algorithms applied to the same network. The proposed method is
evaluated using random networks with community structures and compared with two
commonly used community detection methods. The proposed method when applied on
a stochastic community detection algorithm performs well with low computational
complexity, thus offering both a new approach to community detection and an
additional community detection method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0245</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0245</id><created>2013-09-01</created><authors><author><keyname>Vidakovic</keyname><forenames>Dragan</forenames></author><author><keyname>Parezanovic</keyname><forenames>Dusko</forenames></author></authors><title>Generating Keys in Elliptic Curve Cryptosystems</title><categories>cs.CR</categories><comments>9 pages</comments><acm-class>D.4.6</acm-class><journal-ref>International Journal of Computer Sciece and Busines Informatics
  (IJCSBI),Vol 4, No 1 (2013): August 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we will present how to find keys elliptic curve cryptosystems
(ECC) with simple tools of Delphi 7 console application, using the software
problem solving of the scalar point multiplication in the field GF(p), where p
is an arbitrary prime number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0249</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0249</id><created>2013-09-01</created><authors><author><keyname>Oliveira</keyname><forenames>Igor C.</forenames></author></authors><title>Algorithms versus Circuit Lower Bounds</title><categories>cs.CC cs.DM cs.DS</categories><comments>32 pages</comments><msc-class>68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different techniques have been used to prove several transference theorems of
the form &quot;nontrivial algorithms for a circuit class C yield circuit lower
bounds against C&quot;. In this survey we revisit many of these results. We discuss
how circuit lower bounds can be obtained from derandomization, compression,
learning, and satisfiability algorithms. We also cover the connection between
circuit lower bounds and useful properties, a notion that turns out to be
fundamental in the context of these transference theorems. Along the way, we
obtain a few new results, simplify several proofs, and show connections
involving different frameworks. We hope that our presentation will serve as a
self-contained introduction for those interested in pursuing research in this
area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0251</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0251</id><created>2013-09-01</created><authors><author><keyname>Azar</keyname><forenames>Yossi</forenames></author><author><keyname>Vardi</keyname><forenames>Adi</forenames></author></authors><title>Colored Packets with Deadlines and Metric Space Transition Cost</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider scheduling of colored packets with transition costs which form a
general metric space. We design a $1 - O(\sqrt{MST(G) / L})$ competitive
algorithm. Our main result is a hardness result of $1 - \Omega(\sqrt{MST(G) /
L})$ which matches the competitive ratio of the algorithm for each metric space
separately. In particular, we improve the hardness result of Azar at el. 2009
for uniform metric spaces.
  We also extend our result to weighted directed graphs which obey the
triangular inequality and show a $1 - O(\sqrt{TSP(G) / L})$ competitive
algorithm and a nearly-matching hardness result. In proving our hardness
results we use some interesting non-standard embedding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0261</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0261</id><created>2013-09-01</created><authors><author><keyname>Cire&#x15f;an</keyname><forenames>Dan</forenames></author><author><keyname>Schmidhuber</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Multi-Column Deep Neural Networks for Offline Handwritten Chinese
  Character Classification</title><categories>cs.CV</categories><comments>5 pages, 1 figure, IDSIA tech report</comments><report-no>IDSIA-05-13</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our Multi-Column Deep Neural Networks achieve best known recognition rates on
Chinese characters from the ICDAR 2011 and 2013 offline handwriting
competitions, approaching human performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0262</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0262</id><created>2013-09-01</created><authors><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author><author><keyname>Xiao</keyname><forenames>Yuanzhang</forenames></author><author><keyname>Zame</keyname><forenames>William</forenames></author></authors><title>Designing Efficient Resource Sharing For Impatient Players Using Limited
  Monitoring</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of efficient sharing of a resource is nearly ubiquitous. Except
for pure public goods, each agent's use creates a negative externality; often
the negative externality is so strong that efficient sharing is impossible in
the short run. We show that, paradoxically, the impossibility of efficient
sharing in the short run enhances the possibility of efficient sharing in the
long run, even if outcomes depend stochastically on actions, monitoring is
limited and users are not patient. We base our analysis on the familiar
framework of repeated games with imperfect public monitoring, but we extend the
framework to view the monitoring structure as chosen by a designer who balances
the benefits and costs of more accurate observations and reports. Our
conclusions are much stronger than in the usual folk theorems: we do not
require a rich signal structure or patient users and provide an explicit online
construction of equilibrium strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0270</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0270</id><created>2013-09-01</created><updated>2014-03-04</updated><authors><author><keyname>Hosseini</keyname><forenames>Mahdi S.</forenames></author><author><keyname>Plataniotis</keyname><forenames>Konstantinos N.</forenames></author></authors><title>High-Accuracy Total Variation for Compressed Video Sensing</title><categories>math.OC cs.CV</categories><comments>Submitted to IEEE Transaction on Image Processing, Revised</comments><doi>10.1109/TIP.2014.2332755</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous total variation (TV) regularizers, engaged in image restoration
problem, encode the gradients by means of simple $[-1,1]$ FIR filter. Despite
its low computational processing, this filter severely deviates signal's high
frequency components pertinent to edge/discontinuous information and cause
several deficiency issues known as texture and geometric loss. This paper
addresses this problem by proposing an alternative model to the TV
regularization problem via high order accuracy differential FIR filters to
preserve rapid transitions in signal recovery. A numerical encoding scheme is
designed to extend the TV model into multidimensional representation (tensorial
decomposition). We adopt this design to regulate the spatial and temporal
redundancy in compressed video sensing problem to jointly recover frames from
under-sampled measurements. We then seek the solution via alternating direction
methods of multipliers and find a unique solution to quadratic minimization
step with capability of handling different boundary conditions. The resulting
algorithm uses much lower sampling rate and highly outperforms alternative
state-of-the-art methods. This is evaluated both in terms of restoration
accuracy and visual quality of the recovered frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0276</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0276</id><created>2013-09-01</created><updated>2013-09-03</updated><authors><author><keyname>Khan</keyname><forenames>Kamran</forenames></author><author><keyname>Syed</keyname><forenames>Affan</forenames></author><author><keyname>Khayam</keyname><forenames>Ali</forenames></author></authors><title>Traffic analyzer for differentiating BitTorrent handshake failures from
  port-scans</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to improve the accuracy of port-scan detectors by analyzing
traffic of BitTorrent hosts and differentiating their respective BitTorrent
connection (attempts) from port-scans.
  It is shown that by looking at BitTorrent coordination traffic and modelling
port-scanning behavior the number of BitTorrent-related false positives can be
reduced by 80% without any loss of IDS accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0277</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0277</id><created>2013-09-01</created><authors><author><keyname>Sidiropoulos</keyname><forenames>Antonis</forenames></author><author><keyname>Katsaros</keyname><forenames>Dimitrios</forenames></author><author><keyname>Manolopoulos</keyname><forenames>Yannis</forenames></author></authors><title>Categorizing Influential Authors Using Penalty Areas</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of h-index has been proposed to easily assess a researcher's
performance with a single two-dimensional number. However, by using only this
single number, we lose significant information about the distribution of the
number of citations per article of an author's publication list. Two authors
with the same h-index may have totally different distributions of the number of
citations per article. One may have a very long &quot;tail&quot; in the citation curve,
i.e. he may have published a great number of articles, which did not receive
relatively many citations. Another researcher may have a short tail, i.e.
almost all his publications got a relatively large number of citations. In this
article, we study an author's citation curve and we define some areas appearing
in this curve. These areas are used to further evaluate authors' research
performance from quantitative and qualitative point of view. We call these
areas as &quot;penalty&quot; ones, since the greater they are, the more an author's
performance is penalized. Moreover, we use these areas to establish new metrics
aiming at categorizing researchers in two distinct categories: &quot;influential&quot;
ones vs. &quot;mass producers&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0296</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0296</id><created>2013-09-01</created><authors><author><keyname>Vuckovac</keyname><forenames>Rade</forenames></author></authors><title>A new kind of complexity</title><categories>cs.CC</categories><comments>20 pages, 4 figures, 1 listing</comments><msc-class>11Y16</msc-class><acm-class>G.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new class of functions is presented. The structure of the algorithm,
particularly the selection criteria (branching), is used to define the
fundamental property of the new class. The most interesting property of the new
functions is that instances are easy to compute but if input to the function is
vague the description of a function is exponentially complex. This property
puts a new light on randomness especially on the random oracle model with a
couple of practical examples of random oracle implementation. Consequently,
there is a new interesting viewpoint on computational complexity in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0302</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0302</id><created>2013-09-02</created><authors><author><keyname>Zhou</keyname><forenames>Tianyi</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author></authors><title>Unmixing Incoherent Structures of Big Data by Randomized or Greedy
  Decomposition</title><categories>stat.ML cs.DS cs.LG</categories><comments>42 pages, 5 figures, 4 tables, 5 algorithms</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Learning big data by matrix decomposition always suffers from expensive
computation, mixing of complicated structures and noise. In this paper, we
study more adaptive models and efficient algorithms that decompose a data
matrix as the sum of semantic components with incoherent structures. We firstly
introduce &quot;GO decomposition (GoDec)&quot;, an alternating projection method
estimating the low-rank part $L$ and the sparse part $S$ from data matrix
$X=L+S+G$ corrupted by noise $G$. Two acceleration strategies are proposed to
obtain scalable unmixing algorithm on big data: 1) Bilateral random projection
(BRP) is developed to speed up the update of $L$ in GoDec by a closed-form
built from left and right random projections of $X-S$ in lower dimensions; 2)
Greedy bilateral (GreB) paradigm updates the left and right factors of $L$ in a
mutually adaptive and greedy incremental manner, and achieve significant
improvement in both time and sample complexities. Then we proposes three
nontrivial variants of GoDec that generalizes GoDec to more general data type
and whose fast algorithms can be derived from the two strategies......
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0303</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0303</id><created>2013-09-02</created><updated>2013-11-24</updated><authors><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author><author><keyname>Huang</keyname><forenames>Tianyao</forenames></author></authors><title>Fundamental Limits of HRR Profiling and Velocity Compensation For
  Stepped-Frequency Waveforms</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to some typos</comments><doi>10.1109/TSP.2014.2337279</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stepped-frequency (SF) waveform is an effective way to achieve high range
resolution (HRR) in modern radars. In this paper, we determine some fundamental
limits of SF waveforms on ambiguity, stability and accuracy of stable targets
profiling, and velocity compensation accuracy of moving targets. The
investigation shows that via using the information contained in both phase and
envelop of the echo signal, the radar can achieve HRR profiles without
ambiguity under a looser criterion, and can compensate the range shift caused
by targets' radial velocity. The results of this paper can help the SF waveform
design and the processing algorithm development for HRR profiling and velocity
compensation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0305</identifier>
 <datestamp>2014-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0305</id><created>2013-09-02</created><updated>2014-01-23</updated><authors><author><keyname>Razak</keyname><forenames>Fatimah Abdul</forenames></author><author><keyname>Jensen</keyname><forenames>Henrik Jeldtoft</forenames></author></authors><title>Quantifying 'causality' in complex systems: Understanding Transfer
  Entropy</title><categories>cond-mat.stat-mech cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  'Causal' direction is of great importance when dealing with complex systems.
Often big volumes of data in the form of time series are available and it is
important to develop methods that can inform about possible causal connections
between the different observables. Here we investigate the ability of the
Transfer Entropy measure to identify causal relations embedded in emergent
coherent correlations. We do this by firstly applying Transfer Entropy to an
amended Ising model. In addition we use a simple Random Transition model to
test the reliability of Transfer Entropy as a measure of `causal' direction in
the presence of stochastic fluctuations. In particular we systematically study
the effect of the finite size of data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0309</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0309</id><created>2013-09-02</created><authors><author><keyname>Peng</keyname><forenames>Xiaojiang</forenames></author><author><keyname>Peng</keyname><forenames>Qiang</forenames></author><author><keyname>Qiao</keyname><forenames>Yu</forenames></author><author><keyname>Chen</keyname><forenames>Junzhou</forenames></author><author><keyname>Afzal</keyname><forenames>Mehtab</forenames></author></authors><title>A Study on Unsupervised Dictionary Learning and Feature Encoding for
  Action Classification</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many efforts have been devoted to develop alternative methods to traditional
vector quantization in image domain such as sparse coding and soft-assignment.
These approaches can be split into a dictionary learning phase and a feature
encoding phase which are often closely connected. In this paper, we investigate
the effects of these phases by separating them for video-based action
classification. We compare several dictionary learning methods and feature
encoding schemes through extensive experiments on KTH and HMDB51 datasets.
Experimental results indicate that sparse coding performs consistently better
than the other encoding methods in large complex dataset (i.e., HMDB51), and it
is robust to different dictionaries. For small simple dataset (i.e., KTH) with
less variation, however, all the encoding strategies perform competitively. In
addition, we note that the strength of sophisticated encoding approaches comes
not from their corresponding dictionaries but the encoding mechanisms, and we
can just use randomly selected exemplars as dictionaries for video-based action
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0316</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0316</id><created>2013-09-02</created><authors><author><keyname>Fiandrotti</keyname><forenames>Attilio</forenames></author><author><keyname>Bioglio</keyname><forenames>Valerio</forenames></author><author><keyname>Grangetto</keyname><forenames>Marco</forenames></author><author><keyname>Gaeta</keyname><forenames>Rossano</forenames></author><author><keyname>Magli</keyname><forenames>Enrico</forenames></author></authors><title>Band Codes for Energy-Efficient Network Coding with Application to P2P
  Mobile Streaming</title><categories>cs.MM cs.NI</categories><comments>To be published in IEEE Transacions on Multimedia</comments><acm-class>H.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key problem in random network coding (NC) lies in the complexity and energy
consumption associated with the packet decoding processes, which hinder its
application in mobile environments. Controlling and hence limiting such factors
has always been an important but elusive research goal, since the packet degree
distribution, which is the main factor driving the complexity, is altered in a
non-deterministic way by the random recombinations at the network nodes. In
this paper we tackle this problem proposing Band Codes (BC), a novel class of
network codes specifically designed to preserve the packet degree distribution
during packet encoding, ecombination and decoding. BC are random codes over
GF(2) that exhibit low decoding complexity, feature limited and controlled
degree distribution by construction, and hence allow to effectively apply NC
even in energy-constrained scenarios. In particular, in this paper we motivate
and describe our new design and provide a thorough analysis of its performance.
We provide numerical simulations of the performance of BC in order to validate
the analysis and assess the overhead of BC with respect to a onventional NC
scheme. Moreover, peer-to-peer media streaming experiments with a random-push
protocol show that BC reduce the decoding complexity by a factor of two, to a
point where NC-based mobile streaming to mobile devices becomes practically
feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0326</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0326</id><created>2013-09-02</created><updated>2014-11-03</updated><authors><author><keyname>&#x141;opuszy&#x144;ski</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Bolikowski</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>Tagging Scientific Publications using Wikipedia and Natural Language
  Processing Tools. Comparison on the ArXiv Dataset</title><categories>cs.CL cs.DL</categories><journal-ref>Communications in Computer and Information Science Volume 416,
  Springer 2014, pp 16-27</journal-ref><doi>10.1007/978-3-319-08425-1_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we compare two simple methods of tagging scientific
publications with labels reflecting their content. As a first source of labels
Wikipedia is employed, second label set is constructed from the noun phrases
occurring in the analyzed corpus. We examine the statistical properties and the
effectiveness of both approaches on the dataset consisting of abstracts from
0.7 million of scientific documents deposited in the ArXiv preprint collection.
We believe that obtained tags can be later on applied as useful document
features in various machine learning tasks (document similarity, clustering,
topic modelling, etc.).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0337</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0337</id><created>2013-09-02</created><authors><author><keyname>Houlsby</keyname><forenames>Neil</forenames></author><author><keyname>Ciaramita</keyname><forenames>Massimiliano</forenames></author></authors><title>Scalable Probabilistic Entity-Topic Modeling</title><categories>stat.ML cs.IR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an LDA approach to entity disambiguation. Each topic is associated
with a Wikipedia article and topics generate either content words or entity
mentions. Training such models is challenging because of the topic and
vocabulary size, both in the millions. We tackle these problems using a novel
distributed inference and representation framework based on a parallel Gibbs
sampler guided by the Wikipedia link graph, and pipelines of MapReduce allowing
fast and memory-frugal processing of large datasets. We report state-of-the-art
performance on a public dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0339</identifier>
 <datestamp>2014-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0339</id><created>2013-09-02</created><updated>2013-09-17</updated><authors><author><keyname>Sato</keyname><forenames>Taisuke</forenames></author><author><keyname>Meyer</keyname><forenames>Philipp</forenames></author></authors><title>Infinite probability computation by cyclic explanation graphs</title><categories>cs.PL</categories><comments>29 pages</comments><doi>10.1017/S1471068413000562</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tabling in logic programming has been used to eliminate redundant computation
and also to stop infinite loop. In this paper we investigate another
possibility of tabling, i.e. to compute an infinite sum of probabilities for
probabilistic logic programs. Using PRISM, a logic-based probabilistic modeling
language with a tabling mechanism, we generalize prefix probability computation
for probabilistic context free grammars (PCFGs) to probabilistic logic
programs. Given a top-goal, we search for all proofs with tabling and obtain an
explanation graph which compresses them and may be cyclic. We then convert the
explanation graph to a set of linear probability equations and solve them by
matrix operation. The solution gives us the probability of the top-goal, which,
in nature, is an infinite sum of probabilities. Our general approach to prefix
probability computation through tabling not only allows to deal with non-PCFGs
such as probabilistic left-corner grammars (PLCGs) but has applications such as
plan recognition and probabilistic model checking and makes it possible to
compute probability for probabilistic models describing cyclic relations. To
appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0346</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0346</id><created>2013-09-02</created><authors><author><keyname>Biazzo</keyname><forenames>Indaco</forenames></author><author><keyname>Braunstein</keyname><forenames>Alfredo</forenames></author><author><keyname>Zecchina</keyname><forenames>Riccardo</forenames></author></authors><title>On the performance of a cavity method based algorithm for the
  Prize-Collecting Steiner Tree Problem on graphs</title><categories>cs.DS cond-mat.stat-mech</categories><journal-ref>Phys. Rev. E 86, 026706 (2012)</journal-ref><doi>10.1103/PhysRevE.86.026706</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the behavior of an algorithm derived from the cavity method for the
Prize-Collecting Steiner Tree (PCST) problem on graphs. The algorithm is based
on the zero temperature limit of the cavity equations and as such is formally
simple (a fixed point equation resolved by iteration) and distributed
(parallelizable). We provide a detailed comparison with state-of-the-art
algorithms on a wide range of existing benchmarks networks and random graphs.
Specifically, we consider an enhanced derivative of the Goemans-Williamson
heuristics and the DHEA solver, a Branch and Cut Linear/Integer Programming
based approach. The comparison shows that the cavity algorithm outperforms the
two algorithms in most large instances both in running time and quality of the
solution. Finally we prove a few optimality properties of the solutions
provided by our algorithm, including optimality under the two post-processing
procedures defined in the Goemans-Williamson derivative and global optimality
in some limit cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0361</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0361</id><created>2013-09-02</created><authors><author><keyname>Hines</keyname><forenames>Peter</forenames></author></authors><title>Girard's $!()$ as a reversible fixed-point operator</title><categories>math.CT cs.LO math.LO</categories><comments>15 pages, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a categorical description of the treatment of the !() exponential in
the Geometry of Interaction system, with particular emphasis on the fact that
the GoI interpretation 'forgets types'. We demonstrate that it may be thought
of as a fixed-point operation for reversible logic &amp; computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0363</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0363</id><created>2013-09-02</created><updated>2013-11-17</updated><authors><author><keyname>Meyer</keyname><forenames>Florian</forenames></author><author><keyname>Hlinka</keyname><forenames>Ondrej</forenames></author><author><keyname>Hlawatsch</keyname><forenames>Franz</forenames></author></authors><title>Sigma Point Belief Propagation</title><categories>cs.AI cs.DC</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sigma point (SP) filter, also known as unscented Kalman filter, is an
attractive alternative to the extended Kalman filter and the particle filter.
Here, we extend the SP filter to nonsequential Bayesian inference corresponding
to loopy factor graphs. We propose sigma point belief propagation (SPBP) as a
low-complexity approximation of the belief propagation (BP) message passing
scheme. SPBP achieves approximate marginalizations of posterior distributions
corresponding to (generally) loopy factor graphs. It is well suited for
decentralized inference because of its low communication requirements. For a
decentralized, dynamic sensor localization problem, we demonstrate that SPBP
can outperform nonparametric (particle-based) BP while requiring significantly
less computations and communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0364</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0364</id><created>2013-09-02</created><updated>2013-09-03</updated><authors><author><keyname>Ploumidis</keyname><forenames>Manolis</forenames></author><author><keyname>Pappas</keyname><forenames>Nikolaos</forenames></author><author><keyname>Traganitis</keyname><forenames>Apostolos</forenames></author></authors><title>Throughput Optimal Flow Allocation on Multiple Paths for Random Access
  Wireless Multi-hop Networks</title><categories>cs.NI</categories><comments>Accepted for publication at the 9th IEEE BROADBAND WIRELESS ACCESS
  WORKSHOP (BWA2013), IEEE Globecom 2013 Workshops</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider random access wireless multi-hop mesh networks with
multi-packet reception capabilities where multiple flows are forwarded to the
gateways through node disjoint paths. We address the issue of aggregate
throughput-optimal flow rate allocation with bounded delay guarantees. We
propose a distributed flow rate allocation scheme that formulates flow rate
allocation as an optimization problem and derive the conditions for
non-convexity for an illustrative topology. We also employ a simple model for
the average aggregate throughput achieved by all flows that captures both
intra- and inter-path interference. The proposed scheme is evaluated through
NS-2 simulations. Our preliminary results are derived from a grid topology and
show that the proposed flow allocation scheme slightly underestimates the
average aggregate throughput observed in two simulated scenarios with two and
three flows respectively. Moreover it achieves significantly higher average
aggregate throughput than single path utilization in two different traffic
scenarios examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0365</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0365</id><created>2013-09-02</created><authors><author><keyname>Cheng</keyname><forenames>Yi</forenames></author><author><keyname>Ugrinovskii</keyname><forenames>V.</forenames></author><author><keyname>Wen</keyname><forenames>Guanghui</forenames></author></authors><title>Guaranteed Cost Tracking for Uncertain Coupled Multi-agent Systems Using
  Consensus over a Directed Graph</title><categories>cs.SY</categories><comments>Accepted for presentation at the 2013 Australian Control conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the leader-follower control problem for a linear
multi-agent system with directed communication topology and linear nonidentical
uncertain coupling subject to integral quadratic constraints (IQCs). A
consensus-type control protocol is proposed based on each agent's states
relative to its neighbors and leader's state relative to agents which observe
the leader. A sufficient condition is obtained by overbounding the cost
function. Based on this sufficient condition, a computational algorithm is
introduced to minimize the proposed guaranteed bound on tracking performance,
which yields a suboptimal bound on the system consensus control and tracking
performance. The effectiveness of the proposed method is demonstrated using a
simulation example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0369</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0369</id><created>2013-09-02</created><updated>2013-12-02</updated><authors><author><keyname>Lano</keyname><forenames>K.</forenames><affiliation>King's College London</affiliation></author><author><keyname>Rahimi</keyname><forenames>S. Kolahdouz</forenames><affiliation>King's College London</affiliation></author></authors><title>Case study: Class diagram restructuring</title><categories>cs.SE</categories><comments>In Proceedings TTC 2013, arXiv:1311.7536</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 135, 2013, pp. 8-15</journal-ref><doi>10.4204/EPTCS.135.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This case study is an update-in-place refactoring transformation on UML class
diagrams. Its aim is to remove clones of attributes from a class diagram, and
to identify new classes which abstract groups of classes that share common data
features.
  It is used as one of a general collection of transformations (such as the
removal of redundant inheritance, or multiple inheritance) which aim to improve
the quality of a specification or design level class diagram.
  The transformation is a typical example of a model refactoring, and
illustrates the issues involved in such transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0373</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0373</id><created>2013-09-02</created><authors><author><keyname>van Schaik</keyname><forenames>Sebastiaan J.</forenames></author><author><keyname>Olteanu</keyname><forenames>Dan</forenames></author><author><keyname>Fink</keyname><forenames>Robert</forenames></author></authors><title>ENFrame: A Platform for Processing Probabilistic Data</title><categories>cs.DB</categories><comments>12 pages</comments><acm-class>H.2.4; H.2.8; H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces ENFrame, a unified data processing platform for
querying and mining probabilistic data. Using ENFrame, users can write programs
in a fragment of Python with constructs such as bounded-range loops, list
comprehension, aggregate operations on lists, and calls to external database
engines. The program is then interpreted probabilistically by ENFrame.
  The realisation of ENFrame required novel contributions along several
directions. We propose an event language that is expressive enough to
succinctly encode arbitrary correlations, trace the computation of user
programs, and allow for computation of discrete probability distributions of
program variables. We exemplify ENFrame on three clustering algorithms:
k-means, k-medoids, and Markov Clustering. We introduce sequential and
distributed algorithms for computing the probability of interconnected events
exactly or approximately with error guarantees. Experiments with k-medoids
clustering of sensor readings from energy networks show orders-of-magnitude
improvements of exact clustering using ENFrame over na\&quot;ive clustering in each
possible world, of approximate over exact, and of distributed over sequential
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0386</identifier>
 <datestamp>2015-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0386</id><created>2013-08-23</created><updated>2014-05-15</updated><authors><author><keyname>Ku&#x142;akowski</keyname><forenames>Konrad</forenames></author></authors><title>Heuristic Rating Estimation Approach to The Pairwise Comparisons Method</title><categories>cs.DM</categories><comments>15 pages, 2 figures</comments><msc-class>62C99</msc-class><acm-class>H.4.2; G.1.3</acm-class><journal-ref>Fundamenta Informaticae, Volume 133, Issue 4, October 2014, Pages
  367-386</journal-ref><doi>10.3233/FI-2014-1081</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Heuristic Ratio Estimation (HRE) approach proposes a new way of using the
pairwise comparisons matrix. It allows the assumption that the weights of some
alternatives (herein referred to as concepts) are known and fixed, hence the
weight vector needs to be estimated only for the other unknown values. The main
purpose of this paper is to extend the previously proposed iterative HRE
algorithm and present all the heuristics that create a generalized approach.
Theoretical considerations are accompanied by a few numerical examples
demonstrating how the selected heuristics can be used in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0392</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0392</id><created>2013-08-12</created><authors><author><keyname>Hupp</keyname><forenames>Philipp</forenames></author></authors><title>Hierarchization for the Sparse Grid Combination Technique</title><categories>cs.DC cs.NA</categories><comments>7 pages, 9 figures, 1 algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sparse grid combination technique provides a framework to solve high
dimensional numerical problems with standard solvers. Hierarchization is
preprocessing step facilitating the communication needed for the combination
technique. The derived hierarchization algorithm outperforms the baseline by up
to 30x and achieves close to 5% of peak performance. It also shows stable
performance for the tested data sets of up to 1 GB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0395</identifier>
 <datestamp>2016-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0395</id><created>2013-09-02</created><updated>2016-01-27</updated><authors><author><keyname>Suk</keyname><forenames>Andrew</forenames></author><author><keyname>Walczak</keyname><forenames>Bartosz</forenames></author></authors><title>New bounds on the maximum number of edges in $k$-quasi-planar graphs</title><categories>math.CO cs.CG</categories><comments>Final version, minor corrections</comments><msc-class>05C35, 05C62</msc-class><journal-ref>Comput.Geom. 50 (2015) 24-33</journal-ref><doi>10.1016/j.comgeo.2015.06.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A topological graph is $k$-quasi-planar if it does not contain $k$ pairwise
crossing edges. A 20-year-old conjecture asserts that for every fixed $k$, the
maximum number of edges in a $k$-quasi-planar graph on $n$ vertices is $O(n)$.
Fox and Pach showed that every $k$-quasi-planar graph with $n$ vertices has at
most $n(\log n)^{O(\log k)}$ edges. We improve this upper bound to
$2^{\alpha(n)^c}n\log n$, where $\alpha(n)$ denotes the inverse Ackermann
function and $c$ depends only on $k$, for $k$-quasi-planar graphs in which any
two edges intersect in a bounded number of points. We also show that every
$k$-quasi-planar graph with $n$ vertices in which any two edges have at most
one point in common has at most $O(n\log n)$ edges. This improves the
previously known upper bound of $2^{\alpha(n)^c}n\log n$ obtained by Fox, Pach,
and Suk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0403</identifier>
 <datestamp>2014-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0403</id><created>2013-09-02</created><updated>2014-02-04</updated><authors><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author><author><keyname>Trautmann</keyname><forenames>Anna-Lena</forenames></author></authors><title>On the Geometry of Balls in the Grassmannian and List Decoding of Lifted
  Gabidulin Codes</title><categories>cs.IT math.AG math.IT</categories><comments>To be published in Designs, Codes and Cryptography (Springer)</comments><doi>10.1007/s10623-014-9932-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The finite Grassmannian $\mathcal{G}_{q}(k,n)$ is defined as the set of all
$k$-dimensional subspaces of the ambient space $\mathbb{F}_{q}^{n}$. Subsets of
the finite Grassmannian are called constant dimension codes and have recently
found an application in random network coding. In this setting codewords from
$\mathcal{G}_{q}(k,n)$ are sent through a network channel and, since errors may
occur during transmission, the received words can possible lie in
$\mathcal{G}_{q}(k',n)$, where $k'\neq k$. In this paper, we study the balls in
$\mathcal{G}_{q}(k,n)$ with center that is not necessarily in
$\mathcal{G}_{q}(k,n)$. We describe the balls with respect to two different
metrics, namely the subspace and the injection metric. Moreover, we use two
different techniques for describing these balls, one is the Pl\&quot;ucker embedding
of $\mathcal{G}_{q}(k,n)$, and the second one is a rational parametrization of
the matrix representation of the codewords.
  With these results, we consider the problem of list decoding a certain family
of constant dimension codes, called lifted Gabidulin codes. We describe a way
of representing these codes by linear equations in either the matrix
representation or a subset of the Pl\&quot;ucker coordinates. The union of these
equations and the equations which arise from the description of the ball of a
given radius in the Grassmannian describe the list of codewords with distance
less than or equal to the given radius from the received word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0422</identifier>
 <datestamp>2015-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0422</id><created>2013-09-02</created><updated>2015-01-08</updated><authors><author><keyname>Lagoutte</keyname><forenames>Aur&#xe9;lie</forenames></author><author><keyname>Tavenas</keyname><forenames>S&#xe9;bastien</forenames></author></authors><title>The complexity of Shortest Common Supersequence for inputs with no
  identical consecutive letters</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shortest Common Supersequence problem (SCS for short) consists in finding
a shortest common supersequence of a finite set of words on a fixed alphabet
Sigma. It is well-known that its decision version denoted [SR8] in [Garey and
Johnson] is NP-complete. Many variants have been studied in the literature. In
this paper we settle the complexity of two such variants of SCS where inputs do
not contain identical consecutive letters. We prove that those variants denoted
\varphi SCS and MSCS both have a decision version which remains NP-complete
when |\Sigma| is at least 3. Note that it was known for MSCS when |\Sigma| is
at least 4 [Fleisher and Woeginger] and we discuss how [Darte] states a similar
result for |\Sigma| at least 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0429</identifier>
 <datestamp>2015-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0429</id><created>2013-09-02</created><updated>2014-05-27</updated><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>Constant-Space Quantum Interactive Proofs Against Multiple Provers</title><categories>quant-ph cs.CC</categories><comments>A4, 10pt, 10 pages. The results of this paper were first reported at
  the 4th Central European Quantum Information Processing Workshop (CEQIS
  2007), June 24--27, 2007, Valtice, Czech Republic</comments><journal-ref>Information Processing Letters, vol.114, pp.611-619, 2014</journal-ref><doi>10.1016/j.ipl.2014.05.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present upper and lower bounds of the computational complexity of the
two-way communication model of multiple-prover quantum interactive proof
systems whose verifiers are limited to measure-many two-way quantum finite
automata. We prove that (i) the languages recognized by those multiple-prover
systems running in expected polynomial time are exactly the ones in NEXP, the
nondeterministic exponential-time complexity class, (ii) if we further require
verifiers to be one-way quantum automata, then their associated proof systems
recognize context-free languages but not beyond languages in NE, the
nondeterministic linear exponential-time complexity class, and moreover, (iii)
when no time bound is imposed, the proof systems become as powerful as Turing
machines. The first two results answer affirmatively an open question, posed by
Nishimura and Yamakami [J. Comput. System Sci, 75, pp.255--269, 2009], of
whether multiple-prover quantum interactive proof systems are more powerful
than single-prover ones. Our proofs are simple and intuitive, although they
heavily rely on an earlier result on multiple-prover interactive proof systems
of Feige and Shamir [J. Comput. System Sci., 44, pp.259--271, 1992].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0435</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0435</id><created>2013-09-02</created><authors><author><keyname>Maffray</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>Algorithms for perfectly contractile graphs</title><categories>cs.DM math.CO</categories><msc-class>05C85</msc-class><journal-ref>SIAM Journal on Discrete Mathematics, 19(3):553-574, 2005</journal-ref><doi>10.1137/S0895480104442522</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the class ${\cal A}$ of graphs that contain no odd hole, no
antihole of length at least 5, and no &quot;prism&quot; (a graph consisting of two
disjoint triangles with three disjoint paths between them) and the class ${\cal
A}'$ of graphs that contain no odd hole, no antihole of length at least 5 and
no odd prism (prism whose three paths are odd). These two classes were
introduced by Everett and Reed and are relevant to the study of perfect graphs.
We give polynomial-time recognition algorithms for these two classes. We proved
previously that every graph $G\in{\cal A}$ is &quot;perfectly contractile&quot;, as
conjectured by Everett and Reed [see the chapter &quot;Even pairs&quot; in the book {\it
Perfect Graphs}, J.L. Ram\'{\i}rez-Alfons\'{\i}n and B.A. Reed, eds., Wiley
Interscience, 2001]. The analogous conjecture concerning graphs in ${\cal A}'$
is still open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0436</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0436</id><created>2013-09-02</created><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>A Non-Interactive Quantum Bit Commitment Scheme that Exploits the
  Computational Hardness of Quantum State Distinction</title><categories>quant-ph cs.CC cs.CR</categories><comments>A4, 10pt, 14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient quantum protocol performing quantum bit commitment,
which is a simple cryptographic primitive involved with two parties, called a
committer and a verifier. Our protocol is non-interactive, uses no supplemental
shared information, and achieves computational concealing and statistical
binding under a natural complexity-theoretical assumption. An earlier protocol
in the literature relies on the existence of an efficient quantum one-way
function. Our protocol, on the contrary, exploits a seemingly weaker assumption
on computational difficulty of distinguishing two specific ensembles of reduced
quantum states. This assumption is guaranteed by, for example, computational
hardness of solving the graph automorphism problem efficiently on a quantum
computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0442</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0442</id><created>2013-09-02</created><authors><author><keyname>Bensalem</keyname><forenames>Saddek</forenames></author><author><keyname>de Silva</keyname><forenames>Lavindra</forenames></author><author><keyname>Ingrand</keyname><forenames>F&#xe9;lix</forenames></author><author><keyname>Yan</keyname><forenames>Rongjie</forenames></author></authors><title>A Verifiable and Correct-by-Construction Controller for Robot Functional
  Levels</title><categories>cs.RO cs.SE</categories><journal-ref>Journal of Software Engineering for Robotics, 2(1), September
  2011, pages 1-19</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous robots are complex systems that require the interaction and
cooperation between numerous heterogeneous software components. In recent
times, robots are being increasingly used for complex and safety-critical
tasks, such as exploring Mars and assisting/replacing humans. Consequently,
robots are becoming critical systems that must meet safety properties, in
particular, logical, temporal and real-time constraints. To this end, we
present an evolution of the LAAS architecture for autonomous systems, in
particular its GenoM tool. This evolution relies on the BIP component-based
design framework, which has been successfully used in other domains such as
embedded systems. We show how we integrate BIP into our existing methodology
for developing the lowest (functional) level of robots. Particularly, we
discuss the componentization of the functional level, the synthesis of an
execution controller for it, and how we verify whether the resulting functional
level conforms to properties such as deadlock-freedom. We also show through
experimentation that the verification is feasible and usable for complex, real
world robotic systems, and that the BIP-based functional levels resulting from
our new methodology are, despite an overhead during execution, still practical
on real world robotic platforms. Our approach has been fully implemented in the
LAAS architecture, and the implementation has been used in several experiments
on a real robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0448</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0448</id><created>2013-09-02</created><authors><author><keyname>&#xdc;nsal</keyname><forenames>Ay&#x15f;e</forenames></author><author><keyname>Knopp</keyname><forenames>Raymond</forenames></author></authors><title>Distributed Sensing and Transmission of Sporadic Random Samples in a
  Multiple-Access Channel</title><categories>cs.IT math.IT</categories><comments>This paper was presented [in part] at ISIT 2013, IEEE International
  Symposium on Information Theory, July 7-12, 2013, Istanbul, Turkey</comments><doi>10.1109/TCOMM.2015.2466547</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers distributed sensing and transmission of sporadic random
samples. Lower bounds are derived for the reconstruction error of a single
normally or uniformly-distributed finite-dimensional vector imperfectly
measured by a network of sensors and transmitted with finite energy to a common
receiver via an additive white Gaussian noise asynchronous multiple-access
channel. Transmission makes use of a perfect causal feedback link to the
encoder connected to each sensor. A retransmission protocol inspired by the
classical scheme in [1] applied to the transmission of single and bi-variate
analog samples analyzed in [2] and [3] is extended to the more general network
scenario, for which asymptotic upper-bounds on the reconstruction error are
provided. Both the upper and lower-bounds show that collaboration can be
achieved through energy accumulation under certain circumstances. In order to
investigate the practical performance of the proposed retransmission protocol
we provide a numerical evaluation of the upper-bounds in the non-asymptotic
energy regime using low-order quantization in the sensors. The latter includes
a minor modification of the protocol to improve reconstruction fidelity.
Numerical results show that an increase in the size of the network brings
benefit in terms of performance, but that the gain in terms of energy
efficiency diminishes quickly at finite energies due to a non-coherent
combining loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0456</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0456</id><created>2013-09-02</created><authors><author><keyname>Falleri</keyname><forenames>Jean-R&#xe9;my</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Teyton</keyname><forenames>C&#xe9;dric</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Foucault</keyname><forenames>Matthieu</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Palyart</keyname><forenames>Marc</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Morandat</keyname><forenames>Flor&#xe9;al</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Blanc</keyname><forenames>Xavier</forenames><affiliation>LaBRI</affiliation></author></authors><title>The Harmony Platform</title><categories>cs.SE</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to Wikipedia, The Mining Software Repositories (MSR) field analyzes
the rich data available in software repositories, such as version control
repositories, mailing list archives, bug tracking systems, issue tracking
systems, etc. to uncover interesting and actionable information about software
systems, projects and software engineering. The MSR field has received a great
deal of attention and has now its own research conference :
http://www.msrconf.org/. However performing MSR studies is still a technical
challenge. Indeed, data sources (such as version control system or bug tracking
systems) are highly heterogeneous. Moreover performing a study on a lot of data
sources is very expensive in terms of execution time. Surprisingly, there are
not so many tools able to help researchers in their MSR quests. This is why we
created the Harmony platform, as a mean to assist researchers in performing MSR
studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0458</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0458</id><created>2013-09-02</created><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author></authors><title>Capacity of Non-Malleable Codes</title><categories>cs.IT cs.CC cs.CR math.IT</categories><comments>Keywords: Probabilistic method; Coding theory; Error detection;
  Tamper-resilient storage; Cryptography; Information theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-malleable codes, introduced by Dziembowski, Pietrzak and Wichs (ICS
2010), encode messages $s$ in a manner so that tampering the codeword causes
the decoder to either output $s$ or a message that is independent of $s$. While
this is an impossible goal to achieve against unrestricted tampering functions,
rather surprisingly non-malleable coding becomes possible against every fixed
family $F$ of tampering functions that is not too large (for instance, when
$|F| \le \exp(2^{\alpha n})$ for some $\alpha \in [0, 1)$ where $n$ is the
number of bits in a codeword).
  In this work, we study the &quot;capacity of non-malleable coding&quot;, and establish
optimal bounds on the achievable rate as a function of the family size,
answering an open problem from Dziembowski et al. (ICS 2010). Specifically,
  1. We prove that for every family $F$ with $|F| \le \exp(2^{\alpha n})$,
there exist non-malleable codes against $F$ with rate arbitrarily close to
$1-\alpha$ (this is achieved w.h.p. by a randomized construction).
  2. We show the existence of families of size $\exp(n^{O(1)} 2^{\alpha n})$
against which there is no non-malleable code of rate $1-\alpha$ (in fact this
is the case w.h.p for a random family of this size).
  3. We also show that $1-\alpha$ is the best achievable rate for the family of
functions which are only allowed to tamper the first $\alpha n$ bits of the
codeword, which is of special interest.
  As a corollary, this implies that the capacity of non-malleable coding in the
split-state model (where the tampering function acts independently but
arbitrarily on the two halves of the codeword) equals 1/2.
  We also give an efficient Monte Carlo construction of codes of rate close to
1 with polynomial time encoding and decoding that is non-malleable against any
fixed $c &gt; 0$ and family $F$ of size $\exp(n^c)$, in particular tampering
functions with, say, cubic size circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0482</identifier>
 <datestamp>2015-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0482</id><created>2013-09-02</created><authors><author><keyname>Cai</keyname><forenames>T. Tony</forenames></author><author><keyname>Liang</keyname><forenames>Tengyuan</forenames></author><author><keyname>Zhou</keyname><forenames>Harrison H.</forenames></author></authors><title>Law of Log Determinant of Sample Covariance Matrix and Optimal
  Estimation of Differential Entropy for High-Dimensional Gaussian
  Distributions</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>19 pages</comments><report-no>YJMVA3886</report-no><journal-ref>Journal of Multivariate Analysis 137 (2015) 161-172</journal-ref><doi>10.1016/j.jmva.2015.02.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential entropy and log determinant of the covariance matrix of a
multivariate Gaussian distribution have many applications in coding,
communications, signal processing and statistical inference. In this paper we
consider in the high dimensional setting optimal estimation of the differential
entropy and the log-determinant of the covariance matrix. We first establish a
central limit theorem for the log determinant of the sample covariance matrix
in the high dimensional setting where the dimension $p(n)$ can grow with the
sample size $n$. An estimator of the differential entropy and the log
determinant is then considered. Optimal rate of convergence is obtained. It is
shown that in the case $p(n)/n \rightarrow 0$ the estimator is asymptotically
sharp minimax. The ultra-high dimensional setting where $p(n) &gt; n$ is also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0486</identifier>
 <datestamp>2013-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0486</id><created>2013-09-02</created><authors><author><keyname>Koiran</keyname><forenames>Pascal</forenames></author><author><keyname>Portier</keyname><forenames>Natacha</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author></authors><title>Counting Tropically Degenerate Valuations and p-adic Approaches to the
  Hardness of the Permanent</title><categories>math.NT cs.CC</categories><comments>17 pages, 7 figures. Submitted for publication. Dedicated to Mike
  Shub on his 70th birthday</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shub-Smale Tau Conjecture is a hitherto unproven statement (on integer
roots of polynomials) whose truth implies both a variant of $P\neq NP$ (for the
BSS model over C) and the hardness of the permanent. We give alternative
conjectures, some potentially easier to prove, whose truth still implies the
hardness of the permanent. Along the way, we discuss new upper bounds on the
number of $p$-adic valuations of roots of certain sparse polynomial systems,
culminating in a connection between quantitative p-adic geometry and complexity
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0489</identifier>
 <datestamp>2014-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0489</id><created>2013-09-02</created><updated>2014-04-15</updated><authors><author><keyname>Heim</keyname><forenames>Eric</forenames><affiliation>University of Pittsburgh</affiliation></author><author><keyname>Valizadegan</keyname><forenames>Hamed</forenames><affiliation>NASA Ames Research Center</affiliation></author><author><keyname>Hauskrecht</keyname><forenames>Milos</forenames><affiliation>University of Pittsburgh</affiliation></author></authors><title>Relative Comparison Kernel Learning with Auxiliary Kernels</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we consider the problem of learning a positive semidefinite
kernel matrix from relative comparisons of the form: &quot;object A is more similar
to object B than it is to C&quot;, where comparisons are given by humans. Existing
solutions to this problem assume many comparisons are provided to learn a high
quality kernel. However, this can be considered unrealistic for many real-world
tasks since relative assessments require human input, which is often costly or
difficult to obtain. Because of this, only a limited number of these
comparisons may be provided. In this work, we explore methods for aiding the
process of learning a kernel with the help of auxiliary kernels built from more
easily extractable information regarding the relationships among objects. We
propose a new kernel learning approach in which the target kernel is defined as
a conic combination of auxiliary kernels and a kernel whose elements are
learned directly. We formulate a convex optimization to solve for this target
kernel that adds only minor overhead to methods that use no auxiliary
information. Empirical results show that in the presence of few training
relative comparisons, our method can learn kernels that generalize to more
out-of-sample comparisons than methods that do not utilize auxiliary
information, as well as similar methods that learn metrics over objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0521</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0521</id><created>2013-08-21</created><authors><author><keyname>Glisson</keyname><forenames>William Bradley</forenames></author><author><keyname>Storer</keyname><forenames>Tim</forenames></author></authors><title>Investigating Information Security Risks of Mobile Device Use within
  Organizations</title><categories>cs.CR cs.CY</categories><comments>Published in AMCIS 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile devices, such as phones, tablets and laptops, expose businesses and
governments to a multitude of information security risks. While Information
Systems research has focused on the security and privacy aspects from the
end-user perspective regarding mobile devices, very little research has been
conducted within corporate environments. In this work, thirty-two mobile
devices were returned by employees in a global Fortune 500 company. In the
empirical analysis, a number of significant security risks were uncovered which
may have led to leakage of valuable intellectual property or exposed the
organization to future legal conflicts. The research contribution is an initial
empirical report highlighting examples of corporate policy breaches by users
along with providing a foundation for future research on the security risks of
the pervasive presence of mobile devices in corporate environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0522</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0522</id><created>2013-08-13</created><authors><author><keyname>Pau</keyname><forenames>L-F</forenames></author></authors><title>Botnet economics and devising defence schemes from attackers own reward
  processes</title><categories>cs.CR cs.GT</categories><journal-ref>International Journal of Network Security and its applications
  (IJNSA), Vol 5, no 4, July 2013</journal-ref><doi>10.5121/ijnsa.2013.5407</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on botnet economics and design of defensive strategies. It
takes the view that by combining scarce information on the attackers business
models, with rational economic analysis of these business processes, one can
identify design rules for economic defense mechanisms which the target can
implement, often in a cheap way in addition to technical means. A short survey
of game theory in the security area, is followed by a real case of an Internet
casino. This leads to develop a model, applicable to this case and others,
which is presented first qualitatively then quantitatively. This allows
carrying out different analyses based on different equilibrium or termination
principles; the ones studied are reward break-even analysis, and Max-Min
analysis from game theory, for the target and the attackers. On that basis, a
number of specific economic and information led defense strategies are
identified which can be further studied using the model and specific
adaptations to other data or cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0534</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0534</id><created>2013-09-02</created><authors><author><keyname>Poss</keyname><forenames>Raphael 'kena'</forenames></author></authors><title>Machines are benchmarked by code, not algorithms</title><categories>cs.SE cs.PF</categories><comments>34 pages, 11 figures, 11 listings, 17 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article highlights how small modifications to either the source code of
a benchmark program or the compilation options may impact its behavior on a
specific machine. It argues that for evaluating machines, benchmark providers
and users be careful to ensure reproducibility of results based on the machine
code actually running on the hardware and not just source code. The article
uses color to grayscale conversion of digital images as a running example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0535</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0535</id><created>2013-09-02</created><updated>2014-09-04</updated><authors><author><keyname>Zelazo</keyname><forenames>Daniel</forenames></author><author><keyname>Franchi</keyname><forenames>Antonio</forenames></author><author><keyname>B&#xfc;lthoff</keyname><forenames>Heinrich H.</forenames></author><author><keyname>Giordano</keyname><forenames>Paolo Robuffo</forenames></author></authors><title>Decentralized Rigidity Maintenance Control with Range Measurements for
  Multi-Robot Systems</title><categories>cs.SY cs.MA cs.RO math.OC</categories><comments>Preprint submitted to The International Journal of Robotics Research</comments><doi>10.1177/0278364914546173</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a fully decentralized strategy for maintaining the
formation rigidity of a multi-robot system using only range measurements, while
still allowing the graph topology to change freely over time. In this
direction, a first contribution of this work is an extension of rigidity theory
to weighted frameworks and the rigidity eigenvalue, which when positive ensures
the infinitesimal rigidity of the framework. We then propose a distributed
algorithm for estimating a common relative position reference frame amongst a
team of robots with only range measurements in addition to one agent endowed
with the capability of measuring the bearing to two other agents. This first
estimation step is embedded into a subsequent distributed algorithm for
estimating the rigidity eigenvalue associated with the weighted framework. The
estimate of the rigidity eigenvalue is finally used to generate a local control
action for each agent that both maintains the rigidity property and enforces
additional con- straints such as collision avoidance and sensing/communication
range limits and occlusions. As an additional feature of our approach, the
communication and sensing links among the robots are also left free to change
over time while preserving rigidity of the whole framework. The proposed scheme
is then experimentally validated with a robotic testbed consisting of 6
quadrotor UAVs operating in a cluttered environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0542</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0542</id><created>2013-09-02</created><updated>2015-11-25</updated><authors><author><keyname>Habak</keyname><forenames>Karim</forenames></author><author><keyname>Harras</keyname><forenames>Khaled A.</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Bandwidth Aggregation Techniques in Heterogeneous Multi-homed Devices: A
  Survey</title><categories>cs.NI</categories><journal-ref>Computer Networks 92P1 (December 2015) 168-188</journal-ref><doi>10.1016/j.comnet.2015.08.039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread deployment of various networking technologies, coupled with
the exponential increase in end- user data demand, have led to the
proliferation of multi-homed, or multi-interface enabled, devices. These trends
drove researchers to investigate a wide spectrum of solutions, at different
layers of the protocol stack, that utilize available interfaces in such devices
by aggregating their bandwidth. In this survey paper, we provide an overview
and examine the evolution of bandwidth aggregation solutions over time. We
begin by describing the bandwidth aggregation problem. We investigate the
common features of proposed bandwidth aggregation systems and break them down
into two major categories: layer-dependent and layer-independent features.
Afterwards, we discuss the evolution trends in the literature and discuss some
open challenges requiring further research. We end the survey with a brief
presentation of related work in tangential research areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0551</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0551</id><created>2013-09-02</created><authors><author><keyname>Srinivasan</keyname><forenames>Shyam</forenames></author></authors><title>Optimizing the performance of Lattice Gauge Theory simulations with
  Streaming SIMD extensions</title><categories>cs.CE cs.PF physics.comp-ph</categories><comments>Technical report of results of optimization of physics (lattice gauge
  theory) simulations for Intel Architectures</comments><acm-class>B.2.2; B.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two factors, which affect simulation quality are the amount of computing
power and implementation. The Streaming SIMD (single instruction multiple data)
extensions (SSE) present a technique for influencing both by exploiting the
processor's parallel functionalism. In this paper, we show how SSE improves
performance of lattice gauge theory simulations. We identified two significant
trends through an analysis of data from various runs. The speed-ups were higher
for single precision than double precision floating point numbers. Notably,
though the use of SSE significantly improved simulation time, it did not
deliver the theoretical maximum. There are a number of reasons for this:
architectural constraints imposed by the FSB speed, the spatial and temporal
patterns of data retrieval, ratio of computational to non-computational
instructions, and the need to interleave miscellaneous instructions with
computational instructions. We present a model for analyzing the SSE
performance, which could help factor in the bottlenecks or weaknesses in the
implementation, the computing architecture, and the mapping of software to the
computing substrate while evaluating the improvement in efficiency. The model
or framework would be useful in evaluating the use of other computational
frameworks, and in predicting the benefits that can be derived from future
hardware or architectural improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0563</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0563</id><created>2013-09-02</created><updated>2016-02-08</updated><authors><author><keyname>Chan</keyname><forenames>Siu On</forenames></author><author><keyname>Lee</keyname><forenames>James R.</forenames></author><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author><author><keyname>Steurer</keyname><forenames>David</forenames></author></authors><title>Approximate Constraint Satisfaction Requires Large LP Relaxations</title><categories>cs.CC cs.DS math.CO math.OC</categories><comments>29 pages; significant revisions, new references, simpler proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove super-polynomial lower bounds on the size of linear programming
relaxations for approximation versions of constraint satisfaction problems. We
show that for these problems, polynomial-sized linear programs are exactly as
powerful as programs arising from a constant number of rounds of the
Sherali-Adams hierarchy.
  In particular, any polynomial-sized linear program for Max Cut has an
integrality gap of 1/2 and any such linear program for Max 3-Sat has an
integrality gap of 7/8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0566</identifier>
 <datestamp>2014-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0566</id><created>2013-09-02</created><updated>2014-02-18</updated><authors><author><keyname>Wang</keyname><forenames>Jiadong</forenames></author><author><keyname>Vakilinia</keyname><forenames>Kasra</forenames></author><author><keyname>Chen</keyname><forenames>Tsung-Yi</forenames></author><author><keyname>Courtade</keyname><forenames>Thomas</forenames></author><author><keyname>Dong</keyname><forenames>Guiqiang</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author><author><keyname>Shankar</keyname><forenames>Hari</forenames></author><author><keyname>Wesel</keyname><forenames>Richard</forenames></author></authors><title>Enhanced Precision Through Multiple Reads for LDPC Decoding in Flash
  Memories</title><categories>cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1210.0149</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple reads of the same Flash memory cell with distinct word-line voltages
provide enhanced precision for LDPC decoding. In this paper, the word-line
voltages are optimized by maximizing the mutual information (MI) of the
quantized channel. The enhanced precision from a few additional reads allows
FER performance to approach that of full-precision soft information and enables
an LDPC code to significantly outperform a BCH code. A constant-ratio
constraint provides a significant simplification in the optimization with no
noticeable loss in performance. For a well-designed LDPC code, the quantization
that maximizes the mutual information also minimizes the frame error rate in
our simulations. However, for an example LDPC code with a high error floor
caused by small absorbing sets, the MMI quantization does not provide the
lowest frame error rate. The best quantization in this case introduces more
erasures than would be optimal for the channel MI in order to mitigate the
absorbing sets of the poorly designed code. The paper also identifies a
trade-off in LDPC code design when decoding is performed with multiple
precision levels; the best code at one level of precision will typically not be
the best code at a different level of precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0569</identifier>
 <datestamp>2015-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0569</id><created>2013-09-02</created><authors><author><keyname>Dai</keyname><forenames>Wanyang</forenames></author></authors><title>Product-form solutions for integrated services packet networks and cloud
  computing systems</title><categories>math.PR cs.IT cs.NI cs.PF math.IT math.OC</categories><comments>26 pages, 3 figures, short conference version is reported at MICAI
  2006</comments><journal-ref>Mathematical Problems in Engineering, Vol. 2014 (Regular Issue),
  Article ID 767651, 16 pages, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We iteratively derive the product-form solutions of stationary distributions
of priority multiclass queueing networks with multi-sever stations. The
networks are Markovian with exponential interarrival and service time
distributions. These solutions can be used to conduct performance analysis or
as comparison criteria for approximation and simulation studies of large scale
networks with multi-processor shared-memory switches and cloud computing
systems with parallel-server stations. Numerical comparisons with existing
Brownian approximating model are provided to indicate the effectiveness of our
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0576</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0576</id><created>2013-09-02</created><authors><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>Robust Stability of Quantum Systems with Nonlinear Dynamic Uncertainties</title><categories>quant-ph cs.SY math.OC</categories><comments>A shortened version is to appear in the proceedings of the 2013 IEEE
  Conference on Decision and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of robust stability for a class of uncertain
nonlinear quantum systems subject to unknown perturbations in the system
Hamiltonian. The nominal system is a linear quantum system defined by a linear
vector of coupling operators and a quadratic Hamiltonian. This paper extends
previous results on the robust stability of nonlinear quantum systems to allow
for quantum systems with dynamic uncertainties. These dynamic uncertainties are
required to satisfy a certain quantum stochastic integral quadratic constraint.
The robust stability condition is given in terms of a strict bounded real
condition. This result is applied to the robust stability analysis of an
optical parametric amplifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0578</identifier>
 <datestamp>2013-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0578</id><created>2013-09-02</created><updated>2013-10-21</updated><authors><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>Coherent-Classical Estimation for Quantum Linear Systems</title><categories>quant-ph cs.SY math.OC</categories><comments>A version of this paper will appear in the Proceedings of the 2013
  Australian Control Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a problem of coherent-classical estimation for a class
of linear quantum systems. In this problem, the estimator is a mixed
quantum-classical system which produces a classical estimate of a system
variable. The coherent-classical estimator may also involve coherent feedback.
An example involving optical squeezers is given to illustrate the efficacy of
this idea.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0589</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0589</id><created>2013-09-03</created><authors><author><keyname>Shaji</keyname><forenames>K. P.</forenames></author><author><keyname>Alsheba</keyname><forenames>I.</forenames></author><author><keyname>Khadar</keyname><forenames>Y. A. Syed</forenames></author><author><keyname>Kannan</keyname><forenames>S.</forenames></author></authors><title>Multiparameter Monitoring and Fault Indication Using Inductive Power
  Transfer System</title><categories>cs.OH</categories><comments>6 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper aims at demonstrating communication capabilities of IPT. For this
data communication is performed between two modules using the concept of IPT.
IPT was deemed to be the best solution to the system houses a multi parameter
acquisition module such as temperature, speed, voltage, current and data
transfer from the motor. The receiver side is another microcontroller coupled
to an inductive coil that gets the data and displays in the LCD. A brief
background to IPT Inductive Power Transfer technology and its applications is
given and the design criteria for the paper are defined in detail. To be
accurate, IPT data communication helps to reduce unnecessary wire connections
and data is transmitted without any touch. Further the paper can be enhanced by
looking for fault analysis inside the motor. This can be done by analyzing
various parameters of the motor. A novel two-way IPT communication system was
designed, which worked on the concept of pulsing the system on and off to send
data serially. The paper involves transmission of data through inductive flux
without any contact between the two modules. Further as no frequency tunings or
any calibration is required between different modules a single system can be
used with multiple clients. This reduces a lot of hazards such as interference
with other modules and RF transmitters in the vicinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0598</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0598</id><created>2013-09-03</created><authors><author><keyname>Borges</keyname><forenames>Vijay</forenames></author><author><keyname>Jeberson</keyname><forenames>Wilson</forenames></author></authors><title>Survey of Context Information Fusion for Sensor Networks based
  Ubiquitous Systems</title><categories>cs.NI</categories><comments>27 pages, 9 figures, To be submitted to Journal of Sensor and
  Actuator Networks. arXiv admin note: text overlap with arXiv:1305.0982 by
  other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor Networks produce a large amount of data. According to the needs this
data requires to be processed, delivered and accessed. This processed data when
made available with the physical device location, user preferences, time
constraints; generically called as context-awareness; is widely referred to as
the core function for ubiquitous systems. To our best knowledge there is lack
of analysis of context information fusion for ubiquitous sensor networks.
Adopting appropriate information fusion techniques can help in screening noisy
measurements, control data in the network and take necessary inferences that
can help in contextual computing. In this paper we try and explore different
context information fusion techniques by comparing a large number of solutions,
their methods, architectures and models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0604</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0604</id><created>2013-09-03</created><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames></author><author><keyname>Goseling</keyname><forenames>Jasper</forenames></author></authors><title>Coding for Caches in the Plane</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider wireless caches located in the plane according to general point
process and specialize the results for the homogeneous Poisson process. A large
data file is stored at the caches, which have limited storage capabilities.
Hence, they can only store parts of the data. Clients can contact the caches to
retrieve the data. We compare the expected cost of obtaining the complete data
under uncoded as well as coded data allocation strategies. It is shown that for
the general class of cost measures where the cost of retrieving data is
increasing with the distance between client and caches, coded allocation
outperforms uncoded allocation. The improvement offered by coding is quantified
for two more specific classes of performance measures. Finally, our results are
validated by computing the costs of the allocation strategies for the case that
caches coincide with currently deployed mobile base stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0607</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0607</id><created>2013-09-03</created><authors><author><keyname>Yu</keyname><forenames>Mingchao</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author><author><keyname>Aboutorab</keyname><forenames>Neda</forenames></author></authors><title>On Throughput and Decoding Delay Performance of Instantly Decodable
  Network Coding</title><categories>cs.IT math.IT</categories><comments>This is a 14-page paper submitted to IEEE/ACM Transaction on
  Networking. arXiv admin note: text overlap with arXiv:1208.2387</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a comprehensive study of packet-based instantly decodable
network coding (IDNC) for single-hop wireless broadcast is presented. The
optimal IDNC solution in terms of throughput is proposed and its packet
decoding delay performance is investigated. Lower and upper bounds on the
achievable throughput and decoding delay performance of IDNC are derived and
assessed through extensive simulations. Furthermore, the impact of receivers'
feedback frequency on the performance of IDNC is studied and optimal IDNC
solutions are proposed for scenarios where receivers' feedback is only
available after and IDNC round, composed of several coded transmissions.
However, since finding these IDNC optimal solutions is computational complex,
we further propose simple yet efficient heuristic IDNC algorithms. The impact
of system settings and parameters such as channel erasure probability, feedback
frequency, and the number of receivers is also investigated and simple
guidelines for practical implementations of IDNC are proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0632</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0632</id><created>2013-09-03</created><authors><author><keyname>Rimondini</keyname><forenames>Massimo</forenames><affiliation>Roma Tre University</affiliation></author><author><keyname>Squarcella</keyname><forenames>Claudio</forenames><affiliation>Roma Tre University</affiliation></author><author><keyname>Di Battista</keyname><forenames>Giuseppe</forenames><affiliation>Roma Tre University</affiliation></author></authors><title>From BGP to RTT and Beyond: Matching BGP Routing Changes and Network
  Delay Variations with an Eye on Traceroute Paths</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many organizations have the mission of assessing the quality of broadband
access services offered by Internet Service Providers (ISPs). They deploy
network probes that periodically perform network measures towards selected
Internet services. By analyzing the data collected by the probes it is often
possible to gain a reasonable estimate of the bandwidth made available by the
ISP. However, it is much more difficult to use such data to explain who is
responsible of the fluctuations of other network qualities. This is especially
true for latency, that is fundamental for several nowadays network services. On
the other hand, there are many publicly accessible BGP routers that collect the
history of routing changes and that are good candidates to be used for
understanding if latency fluctuations depend on interdomain routing.
  In this paper we provide a methodology that, given a probe that is located
inside the network of an ISP and that executes latency measures and given a set
of publicly accessible BGP routers located inside the same ISP, decides which
routers are best candidates (if any) for studying the relationship between
variations of network performance recorded by the probe and interdomain routing
changes. We validate the methodology with experimental studies based on data
gathered by the RIPE NCC, an organization that is well-known to be independent
and that publishes both BGP data within the Routing Information Service (RIS)
and probe measurement data within the Atlas project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0633</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0633</id><created>2013-09-03</created><authors><author><keyname>Vagvolgyi</keyname><forenames>Sandor</forenames></author></authors><title>Threefold Post Correspondence System</title><categories>cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of a threefold Post correspondence system (3PCS for
short) and we consider it as an instance of the threefold Post correspondence
problem. With each 3PCS, we associate three Post correspondence systems, i.e.,
three instances of the Post correspondence problem. We conjecture that for each
3PCS, the question of the threefold Post correspondence problem or for some
associated Post correspondence system the question of the Post correspondence
problem is decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0634</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0634</id><created>2013-09-03</created><authors><author><keyname>Koutsoumpakis</keyname><forenames>Georgios</forenames></author><author><keyname>Koutsoumpakis</keyname><forenames>Iakovos</forenames></author><author><keyname>Gounaris</keyname><forenames>Anastasios</forenames></author></authors><title>Skew Handling in Aggregate Streaming Queries on GPUs</title><categories>cs.DB cs.DC</categories><comments>11 pages, 11 Postscript figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the data to be processed by database systems has grown so large
that any conventional, centralized technique is inadequate. At the same time,
general purpose computation on GPU (GPGPU) recently has successfully drawn
attention from the data management community due to its ability to achieve
significant speed-ups at a small cost. Efficient skew handling is a well-known
problem in parallel queries, independently of the execution environment. In
this work, we investigate solutions to the problem of load imbalances in
parallel aggregate queries on GPUs that are caused by skewed data. We present a
generic load-balancing framework along with several instantiations, which we
experimentally evaluate. To the best of our knowledge, this is the first
attempt to present runtime load-balancing techniques for database operations on
GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0647</identifier>
 <datestamp>2014-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0647</id><created>2013-09-03</created><updated>2014-07-18</updated><authors><author><keyname>Fran&#xe7;ois</keyname><forenames>Nathana&#xeb;l</forenames></author><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Magniez</keyname><forenames>Frederic</forenames></author></authors><title>Unidirectional Input/Output Streaming Complexity of Reversal and Sorting</title><categories>cs.DS cs.CC</categories><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider unidirectional data streams with restricted access, such as
read-only and write-only streams. For read-write streams, we also introduce a
new complexity measure called expansion, the ratio between the space used on
the stream and the input size. We give tight bounds for the complexity of
reversing a stream of length $n$ in several of the possible models. In the
read-only and write-only model, we show that $p$-pass algorithms need memory
space ${\Theta}(n/p)$. But if either the output stream or the input stream is
read-write, then the complexity falls to ${\Theta}(n/p^2)$. It becomes
$polylog(n)$ if $p = O(log n)$ and both streams are read-write. We also study
the complexity of sorting a stream and give two algorithms with small
expansion. Our main sorting algorithm is randomized and has $O(1)$ expansion,
$O(log n)$ passes and $O(log n)$ memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0659</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0659</id><created>2013-09-03</created><authors><author><keyname>Zhou</keyname><forenames>Yi</forenames></author></authors><title>Majority Rule for Belief Evolution in Social Networks</title><categories>cs.AI cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study how an agent's belief is affected by her neighbors in
a social network. We first introduce a general framework, where every agent has
an initial belief on a statement, and updates her belief according to her and
her neighbors' current beliefs under some belief evolution functions, which,
arguably, should satisfy some basic properties. Then, we focus on the majority
rule belief evolution function, that is, an agent will (dis)believe the
statement iff more than half of her neighbors (dis)believe it. We consider some
fundamental issues about majority rule belief evolution, for instance, whether
the belief evolution process will eventually converge. The answer is no in
general. However, for random asynchronous belief evolution, this is indeed the
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0671</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0671</id><created>2013-09-03</created><authors><author><keyname>Martinez-Cantin</keyname><forenames>Ruben</forenames></author></authors><title>BayesOpt: A Library for Bayesian optimization with Robotics Applications</title><categories>cs.RO cs.AI cs.LG cs.MS</categories><comments>Robotics: Science and Systems, Workshop on Active Learning in
  Robotics: Exploration, Curiosity, and Interaction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is twofold. On one side, we present a general
framework for Bayesian optimization and we compare it with some related fields
in active learning and Bayesian numerical analysis. On the other hand, Bayesian
optimization and related problems (bandits, sequential experimental design) are
highly dependent on the surrogate model that is selected. However, there is no
clear standard in the literature. Thus, we present a fast and flexible toolbox
that allows to test and combine different models and criteria with little
effort. It includes most of the state-of-the-art contributions, algorithms and
models. Its speed also removes part of the stigma that Bayesian optimization
methods are only good for &quot;expensive functions&quot;. The software is free and it
can be used in many operating systems and computer languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0683</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0683</id><created>2013-09-03</created><authors><author><keyname>Angelini</keyname><forenames>Patrizio</forenames></author><author><keyname>Da Lozzo</keyname><forenames>Giordano</forenames></author><author><keyname>Di Battista</keyname><forenames>Giuseppe</forenames></author><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author></authors><title>Strip Planarity Testing of Embedded Planar Graphs</title><categories>cs.CG cs.DM</categories><comments>24 pages, 12 figures, extended version of 'Strip Planarity Testing'
  (21st International Symposium on Graph Drawing, 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce and study the strip planarity testing problem,
which takes as an input a planar graph $G(V,E)$ and a function $\gamma:V
\rightarrow \{1,2,\dots,k\}$ and asks whether a planar drawing of $G$ exists
such that each edge is monotone in the $y$-direction and, for any $u,v\in V$
with $\gamma(u)&lt;\gamma(v)$, it holds $y(u)&lt;y(v)$. The problem has strong
relationships with some of the most deeply studied variants of the planarity
testing problem, such as clustered planarity, upward planarity, and level
planarity. We show that the problem is polynomial-time solvable if $G$ has a
fixed planar embedding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0691</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0691</id><created>2013-09-03</created><updated>2014-02-10</updated><authors><author><keyname>Zhang</keyname><forenames>Chu-Xu</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Yu</keyname><forenames>Lu</forenames></author><author><keyname>Liu</keyname><forenames>Chuang</forenames></author><author><keyname>Liu</keyname><forenames>Hao</forenames></author><author><keyname>Yan</keyname><forenames>Xiao-Yong</forenames></author></authors><title>Information Filtering via Collaborative User Clustering Modeling</title><categories>cs.IR cs.SI physics.soc-ph</categories><doi>10.1016/j.physa.2013.11.024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past few years have witnessed the great success of recommender systems,
which can significantly help users find out personalized items for them from
the information era. One of the most widely applied recommendation methods is
the Matrix Factorization (MF). However, most of researches on this topic have
focused on mining the direct relationships between users and items. In this
paper, we optimize the standard MF by integrating the user clustering
regularization term. Our model considers not only the user-item rating
information, but also takes into account the user interest. We compared the
proposed model with three typical other methods: User-Mean (UM), Item-Mean (IM)
and standard MF. Experimental results on a real-world dataset,
\emph{MovieLens}, show that our method performs much better than other three
methods in the accuracy of recommendation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0694</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0694</id><created>2013-09-03</created><authors><author><keyname>Maffray</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author><author><keyname>Vu\vskovi&#x107;</keyname><forenames>Kristina</forenames></author></authors><title>Algorithms for square-$3PC(\cdot, \cdot)$-free Berge graphs</title><categories>cs.DM math.CO</categories><journal-ref>SIAM Journal on Discrete Mathematics, 22(1):51-71, 2008</journal-ref><doi>10.1137/050628520</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the class of graphs containing no odd hole, no odd antihole, and
no configuration consisting of three paths between two nodes such that any two
of the paths induce a hole, and at least two of the paths are of length 2. This
class generalizes claw-free Berge graphs and square-free Berge graphs. We give
a combinatorial algorithm of complexity $O(n^{7})$ to find a clique of maximum
weight in such a graph. We also consider several subgraph-detection problems
related to this class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0700</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0700</id><created>2013-09-03</created><authors><author><keyname>Tofighi</keyname><forenames>Mohammad</forenames></author><author><keyname>Kose</keyname><forenames>Kivanc</forenames></author><author><keyname>Cetin</keyname><forenames>Ahmet Enis</forenames></author></authors><title>Denoising Using Projection Onto Convex Sets (POCS) Based Framework</title><categories>cs.DS math.OC</categories><comments>arXiv admin note: substantial text overlap with arXiv:1306.2516</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two new optimization techniques based on projections onto convex space (POCS)
framework for solving convex optimization problems are presented. The dimension
of the minimization problem is lifted by one and sets corresponding to the cost
function are defined. If the cost function is a convex function in R^N the
corresponding set is also a convex set in R^{N+1}. The iterative optimization
approach starts with an arbitrary initial estimate in R^{N+1} and an orthogonal
projection is performed onto one of the sets in a sequential manner at each
step of the optimization problem. The method provides globally optimal
solutions in total-variation (TV), filtered variation (FV), L_1, and entropic
cost functions. A new denoising algorithm using the TV framework is developed.
The new algorithm does not require any of the regularization parameter
adjustment. Simulation examples are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0707</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0707</id><created>2013-09-03</created><authors><author><keyname>Chen</keyname><forenames>Tsung-Yi</forenames></author><author><keyname>Williamson</keyname><forenames>Adam R.</forenames></author><author><keyname>Seshadri</keyname><forenames>Nambi</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>Feedback Communication Systems with Limitations on Incremental
  Redundancy</title><categories>cs.IT math.IT</categories><comments>23 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores feedback systems using incremental redundancy (IR) with
noiseless transmitter confirmation (NTC). For IR-NTC systems based on {\em
finite-length} codes (with blocklength $N$) and decoding attempts only at {\em
certain specified decoding times}, this paper presents the asymptotic expansion
achieved by random coding, provides rate-compatible sphere-packing (RCSP)
performance approximations, and presents simulation results of tail-biting
convolutional codes.
  The information-theoretic analysis shows that values of $N$ relatively close
to the expected latency yield the same random-coding achievability expansion as
with $N = \infty$. However, the penalty introduced in the expansion by limiting
decoding times is linear in the interval between decoding times. For binary
symmetric channels, the RCSP approximation provides an efficiently-computed
approximation of performance that shows excellent agreement with a family of
rate-compatible, tail-biting convolutional codes in the short-latency regime.
For the additive white Gaussian noise channel, bounded-distance decoding
simplifies the computation of the marginal RCSP approximation and produces
similar results as analysis based on maximum-likelihood decoding for latencies
greater than 200. The efficiency of the marginal RCSP approximation facilitates
optimization of the lengths of incremental transmissions when the number of
incremental transmissions is constrained to be small or the length of the
incremental transmissions is constrained to be uniform after the first
transmission. Finally, an RCSP-based decoding error trajectory is introduced
that provides target error rates for the design of rate-compatible code
families for use in feedback communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0714</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0714</id><created>2013-09-02</created><authors><author><keyname>Sureka</keyname><forenames>Ashish</forenames></author><author><keyname>Gupta</keyname><forenames>Monika</forenames></author><author><keyname>Sarkar</keyname><forenames>Dipto</forenames></author><author><keyname>Chaudhary</keyname><forenames>Vidushi</forenames></author></authors><title>A Case-Study on Teaching Undergraduate-Level Software Engineering Course
  Using Inverted-Classroom, Large-Group, Real-Client and Studio-Based
  Instruction Model</title><categories>cs.CY cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a case-study on teaching an undergraduate level course on Software
Engineering (second year and fifth semester of bachelors program in Computer
Science) at a State University (New Delhi, India) using a novel teaching
instruction model. Our approach has four main elements: inverted or flipped
classroom, studio-based learning, real-client projects and deployment, large
team and peer evaluation. We present our motivation and approach, challenges
encountered, pedagogical benefits, findings (both positive and negative) and
recommendations. Our motivation was to teach Software Engineering using an
active learning (significantly increasing the engagement and collaboration with
the Instructor and other students in the class), team-work, balance between
theory and practice, imparting both technical and managerial skills encountered
in real-world and problem-based learning (through an intensive semester-long
project). We conduct a detailed survey (anonymous, optional and online) and
present the results of student responses. Survey results reveal that for nearly
every students (class size: 89) the instruction model was new, interesting and
had a positive impact on the motivation in addition to meeting the learning
outcome of the course.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0717</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0717</id><created>2013-09-03</created><updated>2013-09-16</updated><authors><author><keyname>Khomenko</keyname><forenames>Victor</forenames><affiliation>School of Computing Science, Newcastle University</affiliation></author><author><keyname>Meyer</keyname><forenames>Roland</forenames><affiliation>Department of Computer Science, University of Kaiserslautern</affiliation></author><author><keyname>H&#xfc;chting</keyname><forenames>Reiner</forenames><affiliation>Department of Computer Science, University of Kaiserslautern</affiliation></author></authors><title>A Polynomial Translation of pi-calculus FCPs to Safe Petri Nets</title><categories>cs.LO</categories><comments>To appear in special issue on best papers of CONCUR'12 of Logical
  Methods in Computer Science</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  17, 2013) lmcs:932</journal-ref><doi>10.2168/LMCS-9(3:18)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a polynomial translation from finite control pi-calculus processes
to safe low-level Petri nets. To our knowledge, this is the first such
translation. It is natural in that there is a close correspondence between the
control flows, enjoys a bisimulation result, and is suitable for practical
model checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0718</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0718</id><created>2013-09-03</created><authors><author><keyname>Bianchi</keyname><forenames>G.</forenames></author><author><keyname>Melazzi</keyname><forenames>N. Blefari</forenames></author><author><keyname>Caponi</keyname><forenames>A.</forenames></author><author><keyname>Detti</keyname><forenames>A.</forenames></author></authors><title>A General, Tractable and Accurate Model for a Cascade of Caches</title><categories>cs.NI cs.PF</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance evaluation of caching systems is an old and widely investigated
research topic. The research community is once again actively working on this
topic because the Internet is evolving towards new transfer modes, which
envisage to cache both contents and instructions within the network. In
particular, there is interest in characterizing multi-cache systems, in which
requests not satisfied by a cache are forwarded to other caches.
  In this field, this paper contributes as follows. First, we devise a simple
but accurate approximate analysis for caches fed by general &quot;renewal&quot; traffic
patterns. Second, we characterize and model the traffic statistics for the
output (miss) stream. Third, we show in the simple example case of tandem
caches how the resulting output stream model can be conveniently exploited to
analyze the performance of subsequent cache stages. The main novelty of our
work stems in the ability to handle traffic patterns beyond the traditional
independent reference model, thus permitting simple assessment of cascade of
caches as well as improved understanding of the phenomena involved in cache
hierarchies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0719</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0719</id><created>2013-09-03</created><updated>2013-10-28</updated><authors><author><keyname>Bryson</keyname><forenames>David M.</forenames></author><author><keyname>Ofria</keyname><forenames>Charles</forenames></author></authors><title>Understanding Evolutionary Potential in Virtual CPU Instruction Set
  Architectures</title><categories>cs.NE</categories><journal-ref>PLOS ONE 8(12): e83242. (2013)</journal-ref><doi>10.1371/journal.pone.0083242</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate fundamental decisions in the design of instruction set
architectures for linear genetic programs that are used as both model systems
in evolutionary biology and underlying solution representations in evolutionary
computation. We subjected digital organisms with each tested architecture to
seven different computational environments designed to present a range of
evolutionary challenges. Our goal was to engineer a general purpose
architecture that would be effective under a broad range of evolutionary
conditions. We evaluated six different types of architectural features for the
virtual CPUs: (1) genetic flexibility: we allowed digital organisms to more
precisely modify the function of genetic instructions, (2) memory: we provided
an increased number of registers in the virtual CPUs, (3) decoupled sensors and
actuators: we separated input and output operations to enable greater control
over data flow. We also tested a variety of methods to regulate expression: (4)
explicit labels that allow programs to dynamically refer to specific genome
positions, (5) position-relative search instructions, and (6) multiple new flow
control instructions, including conditionals and jumps. Each of these features
also adds complication to the instruction set and risks slowing evolution due
to epistatic interactions. Two features (multiple argument specification and
separated I/O) demonstrated substantial improvements int the majority of test
environments. Some of the remaining tested modifications were detrimental,
thought most exhibit no systematic effects on evolutionary potential,
highlighting the robustness of digital evolution. Combined, these observations
enhance our understanding of how instruction architecture impacts evolutionary
potential, enabling the creation of architectures that support more rapid
evolution of complex solutions to a broad range of challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0745</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0745</id><created>2013-09-03</created><authors><author><keyname>Yeung</keyname><forenames>Chi Ho</forenames></author><author><keyname>Saad</keyname><forenames>David</forenames></author><author><keyname>Wong</keyname><forenames>K. Y. Michael</forenames></author></authors><title>From the Physics of Interacting Polymers to Optimizing Routes on the
  London Underground</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.NI nlin.AO</categories><comments>6 pages, 6 figures. Supplementary information available at:
  http://www.pnas.org/content/suppl/2013/07/29/1301111110.DCSupplemental</comments><journal-ref>PNAS Vol. 110, No. 34, P. 13717-13722 (August 20, 2013)</journal-ref><doi>10.1073/pnas.1301111110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimizing paths on networks is crucial for many applications, from subway
traffic to Internet communication. As global path optimization that takes
account of all path-choices simultaneously is computationally hard, most
existing routing algorithms optimize paths individually, thus providing
sub-optimal solutions. We employ the physics of interacting polymers and
disordered systems to analyze macroscopic properties of generic
path-optimization problems and derive a simple, principled, generic and
distributed routing algorithm capable of considering simultaneously all
individual path choices. We demonstrate the efficacy of the new algorithm by
applying it to: (i) random graphs resembling Internet overlay networks; (ii)
travel on the London underground network based on Oyster-card data; and (iii)
the global airport network. Analytically derived macroscopic properties give
rise to insightful new routing phenomena, including phase transitions and
scaling laws, which facilitate better understanding of the appropriate
operational regimes and their limitations that are difficult to obtain
otherwise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0750</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0750</id><created>2013-09-03</created><authors><author><keyname>Noshad</keyname><forenames>Mohammad</forenames></author><author><keyname>Brandt-Pearce</keyname><forenames>Maite</forenames></author></authors><title>Application of Expurgated PPM to Indoor Visible Light Communications -
  Part I: Single-User Systems</title><categories>cs.IT math.IT</categories><comments>Journal of Lightwave Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visible light communications (VLC) in indoor environments suffer from the
limited bandwidth of LEDs as well as from the inter-symbol interference (ISI)
imposed by multipath. In this work, transmission schemes to improve the
performance of indoor optical wireless communication (OWC) systems are
introduced. Expurgated pulse-position modulation (EPPM) is proposed for this
application since it can provide a wide range of peak to average power ratios
(PAPR) needed for dimming of the indoor illumination. A correlation decoder
used at the receiver is shown to be optimal for indoor VLC systems, which are
shot noise and background-light limited. Interleaving applied on EPPM in order
to decrease the ISI effect in dispersive VLC channels can significantly
decrease the error probability. The proposed interleaving technique makes EPPM
a better modulation option compared to PPM for VLC systems or any other
dispersive OWC system. An overlapped EPPM pulse technique is proposed to
increase the transmission rate when bandwidth-limited white LEDs are used as
sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0752</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0752</id><created>2013-09-03</created><authors><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Rehman</keyname><forenames>O.</forenames></author><author><keyname>Alrajeh</keyname><forenames>N.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Manzoor</keyname><forenames>B.</forenames></author><author><keyname>Ahmed</keyname><forenames>S.</forenames></author></authors><title>AID: An Energy Efficient Decoding Scheme for LDPC Codes in Wireless Body
  Area Sensor Networks</title><categories>cs.NI</categories><comments>2013 International Workshop on Communications and Sensor Networks
  (ComSense-2013), Niagara Falls, Ontario, Canada on October 21-24, 2013 in
  conjunction with 4th International Conference on Emerging Ubiquitous Systems
  and Pervasive Networks (EUSPN-2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major challenges in Wireless Body Area Networks (WBANs) is to
prolong the lifetime of network. Traditional research work focuses on
minimizing transmit power, however, in the case of short range communication
the consumption power in decoding is significantly larger than transmit power.
This paper investigates the minimization of total power consumption by reducing
the decoding power consumption. For achieving a desired Bit Error Rate (BER),
we introduce some fundamental results on the basis of iterative message-passing
algorithms for Low Density Parity Check Code (LDPC). To reduce energy
dissipation in decoder, LDPC based coded communications between sensors are
considered. Moreover, we evaluate the performance of LDPC at different code
rates and introduce Adaptive Iterative Decoding (AID) by exploiting threshold
on the number of iterations for a certain BER. In iterative LDPC decoding, the
total energy consumption of network is reduced by 20 to 25 percent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0766</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0766</id><created>2013-09-03</created><authors><author><keyname>Havlak</keyname><forenames>Frank</forenames></author><author><keyname>Campbell</keyname><forenames>Mark</forenames></author></authors><title>Discrete and Continuous, Probabilistic Anticipation for Autonomous
  Robots in Urban Environments</title><categories>cs.RO</categories><comments>In review IEEE: T-RO</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a probabilistic anticipation algorithm for dynamic
objects observed by an autonomous robot in an urban environment. Predictive
Gaussian mixture models are used due to their ability to probabilistically
capture continuous and discrete obstacle decisions and behaviors; the
predictive system uses the probabilistic output (state estimate and covariance)
of a tracking system, and map of the environment to compute the probability
distribution over future obstacle states for a specified anticipation horizon.
A Gaussian splitting method is proposed based on the sigma-point transform and
the nonlinear dynamics function, which enables increased accuracy as the number
of mixands grows. An approach to caching elements of this optimal splitting
method is proposed, in order to enable real-time implementation. Simulation
results and evaluations on data from the research community demonstrate that
the proposed algorithm can accurately anticipate the probability distributions
over future states of nonlinear systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0775</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0775</id><created>2013-09-03</created><authors><author><keyname>Noshad</keyname><forenames>Mohammad</forenames></author><author><keyname>Brandt-Pearce</keyname><forenames>Maite</forenames></author></authors><title>Application of Expurgated PPM to Indoor Visible Light Communications -
  Part II: Access Networks</title><categories>cs.IT math.IT</categories><comments>Journal of Lightwave Technology. arXiv admin note: substantial text
  overlap with arXiv:1308.0743</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing network access for multiple users in a visible light communication
(VLC) system that utilizes white light emitting diodes (LED) as sources
requires new networking techniques adapted to the lighting features. In this
paper we introduce two multiple access techniques using expurgated PPM (EPPM)
that can be implemented using LEDs and support lighting features such as
dimming. Multilevel symbols are used to provide M-ary signaling for multiple
users using multilevel EPPM (MEPPM). Using these multiple-access schemes we are
able to control the optical peak to average power ratio (PAPR) in the system,
and hereby control the dimming level. In the first technique, the M-ary data of
each user is first encoded using an optical orthogonal code (OOC) assigned to
the user, and the result is fed into a EPPM encoder to generate a multilevel
signal. The second multiple access method uses sub-sets of the EPPM
constellation to apply MEPPM to the data of each user. While the first approach
has a larger Hamming distance between the symbols of each user, the latter can
provide higher bit-rates for users in VLC systems using bandwidth-limited LEDs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0781</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0781</id><created>2013-08-30</created><authors><author><keyname>Williams</keyname><forenames>Nick</forenames></author></authors><title>An Exploratory Data Survey of Drug Name Incidence and Prevalence From
  the FDA's Adverse Event Reporting System, 2004 to 2012Q2</title><categories>cs.CE stat.AP</categories><comments>14 Figures 19 Pages</comments><msc-class>20 90 2</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drug Names, Population Level Surveillance and the FDA's Adverse Event
Reporting System: An Exploratory Data Survey of Drug Name Incidence and
Prevalence, 2004-2012Q2 Purpose: To count and monitor the drug names reported
in the publicly available version of the Federal Adverse Event Reporting System
(FAERS) from 2004 to 2012Q2 in a maximized sensitivity relational model.
Methods: Data mining and data modeling was conducted and event based summary
statistics with plots were created from over nine continuous years of
continuous FAERS data. Results: This FAERS model contains 344,452 individual
drug names and 432,541,994 count references which occurred across 4,148,761
human subjects in the 34 quarter study period. Plots for the top 100 scoring
drug name references are reported by year and quarter; the top 100 drug names
contain 143,384,240 references or 33% of all drug name references over 34
quarters of continuous FAERS data. Conclusions: While FAERS contains many drugs
and adverse event reports, its data pertains to very few of them. Drug name
incidence lends timely and effective surveillance of large populations of
Averse Event Reports and does not require the cause of the AE, nor its validity
to be known to detect a mass poisoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0787</identifier>
 <datestamp>2015-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0787</id><created>2013-09-03</created><updated>2015-10-03</updated><authors><author><keyname>Huang</keyname><forenames>Furong</forenames></author><author><keyname>Niranjan</keyname><forenames>U. N.</forenames></author><author><keyname>Hakeem</keyname><forenames>Mohammad Umar</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author></authors><title>Online Tensor Methods for Learning Latent Variable Models</title><categories>cs.LG cs.DC cs.SI stat.ML</categories><comments>JMLR 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an online tensor decomposition based approach for two latent
variable modeling problems namely, (1) community detection, in which we learn
the latent communities that the social actors in social networks belong to, and
(2) topic modeling, in which we infer hidden topics of text articles. We
consider decomposition of moment tensors using stochastic gradient descent. We
conduct optimization of multilinear operations in SGD and avoid directly
forming the tensors, to save computational and storage costs. We present
optimized algorithm in two platforms. Our GPU-based implementation exploits the
parallelism of SIMD architectures to allow for maximum speed-up by a careful
optimization of storage and data transfer, whereas our CPU-based implementation
uses efficient sparse matrix computations and is suitable for large sparse
datasets. For the community detection problem, we demonstrate accuracy and
computational efficiency on Facebook, Yelp and DBLP datasets, and for the topic
modeling problem, we also demonstrate good performance on the New York Times
dataset. We compare our results to the state-of-the-art algorithms such as the
variational method, and report a gain of accuracy and a gain of several orders
of magnitude in the execution time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0790</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0790</id><created>2013-09-03</created><updated>2014-01-27</updated><authors><author><keyname>Graff</keyname><forenames>Philip</forenames></author><author><keyname>Feroz</keyname><forenames>Farhan</forenames></author><author><keyname>Hobson</keyname><forenames>Michael P.</forenames></author><author><keyname>Lasenby</keyname><forenames>Anthony N.</forenames></author></authors><title>SKYNET: an efficient and robust neural network training tool for machine
  learning in astronomy</title><categories>astro-ph.IM cs.LG cs.NE physics.data-an stat.ML</categories><comments>19 pages, 21 figures, 7 tables; this version is re-submission to
  MNRAS in response to referee comments; software available at
  http://www.mrao.cam.ac.uk/software/skynet/</comments><doi>10.1093/mnras/stu642</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first public release of our generic neural network training
algorithm, called SkyNet. This efficient and robust machine learning tool is
able to train large and deep feed-forward neural networks, including
autoencoders, for use in a wide range of supervised and unsupervised learning
applications, such as regression, classification, density estimation,
clustering and dimensionality reduction. SkyNet uses a `pre-training' method to
obtain a set of network parameters that has empirically been shown to be close
to a good solution, followed by further optimisation using a regularised
variant of Newton's method, where the level of regularisation is determined and
adjusted automatically; the latter uses second-order derivative information to
improve convergence, but without the need to evaluate or store the full Hessian
matrix, by using a fast approximate method to calculate Hessian-vector
products. This combination of methods allows for the training of complicated
networks that are difficult to optimise using standard backpropagation
techniques. SkyNet employs convergence criteria that naturally prevent
overfitting, and also includes a fast algorithm for estimating the accuracy of
network outputs. The utility and flexibility of SkyNet are demonstrated by
application to a number of toy problems, and to astronomical problems focusing
on the recovery of structure from blurred and noisy images, the identification
of gamma-ray bursters, and the compression and denoising of galaxy images. The
SkyNet software, which is implemented in standard ANSI C and fully parallelised
using MPI, is available at http://www.mrao.cam.ac.uk/software/skynet/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0799</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0799</id><created>2013-09-03</created><updated>2014-02-01</updated><authors><author><keyname>Lashgari</keyname><forenames>Sina</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author><author><keyname>Suh</keyname><forenames>Changho</forenames></author></authors><title>Linear Degrees of Freedom of the X-Channel with Delayed CSIT</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish the degrees of freedom of the two-user X-channel with delayed
channel knowledge at transmitters (i.e., delayed CSIT), assuming linear coding
strategies at the transmitters. We derive a new upper bound and characterize
the linear degrees of freedom of this network to be 6/5. The converse builds
upon our development of a general lemma that shows that, if two distributed
transmitters employ linear strategies, the ratio of the dimensions of received
linear subspaces at the two receivers cannot exceed 3/2, due to delayed CSIT.
As a byproduct, we also apply this general lemma to the three-user interference
channel with delayed CSIT, thereby deriving a new upper bound of 9/7 on its
linear degrees of freedom. This is the first bound that captures the impact of
delayed CSIT on the degrees of freedom of this network, under the assumption of
linear encoding strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0806</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0806</id><created>2013-09-03</created><authors><author><keyname>Sithic</keyname><forenames>H. Lookman</forenames></author><author><keyname>Balasubramanian</keyname><forenames>T.</forenames></author></authors><title>Survey of Insurance Fraud Detection Using Data Mining Techniques</title><categories>cs.OH</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With an increase in financial accounting fraud in the current economic
scenario experienced, financial accounting fraud detection has become an
emerging topics of great importance for academics, research and industries.
Financial fraud is a deliberate act that is contrary to law, rule or policy
with intent to obtain unauthorized financial benefit and intentional
misstatements or omission of amounts by deceiving users of financial
statements, especially investors and creditors. Data mining techniques are
providing great aid in financial accounting fraud detection, since dealing with
the large data volumes and complexities of financial data are big challenges
for forensic accounting. Financial fraud can be classified into four: bank
fraud, insurance fraud, securities and commodities fraud. Fraud is nothing but
wrongful or criminal trick planned to result in financial or personal gains.
This paper describes the more details on insurance sector related frauds and
related solutions. In finance, insurance sector is doing important role and
also it is unavoidable sector of every human being.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0829</identifier>
 <datestamp>2015-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0829</id><created>2013-09-03</created><authors><author><keyname>Marinkovi&#x107;</keyname><forenames>Bojan</forenames></author><author><keyname>Ognjanovi&#x107;</keyname><forenames>Zoran</forenames></author><author><keyname>Doder</keyname><forenames>Dragan</forenames></author><author><keyname>Perovi&#x107;</keyname><forenames>Aleksandar</forenames></author></authors><title>A Propositional Linear Time Logic with Time Flow Isomorphic to \omega^2</title><categories>math.LO cs.LO</categories><journal-ref>Journal of Applied Logic 12 (2). p. 208 -- 229, 2014</journal-ref><doi>10.1016/j.jal.2014.03.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Primarily guided with the idea to express zero-time transitions by means of
temporal propositional language, we have developed a temporal logic where the
time flow is isomorphic to ordinal $\omega^2$ (concatenation of $\omega$ copies
of $\omega$). If we think of $\omega^2$ as lexicographically ordered
$\omega\times \omega$, then any particular zero-time transition can be
represented by states whose indices are all elements of some
$\{n\}\times\omega$. In order to express non-infinitesimal transitions, we have
introduced a new unary temporal operator $[\omega] $ ($\omega$-jump), whose
effect on the time flow is the same as the effect of $\alpha\mapsto
\alpha+\omega$ in $\omega^2$. In terms of lexicographically ordered
$\omega\times \omega$, $[\omega] \phi$ is satisfied in $\ &lt; i,j\ &gt;$-th time
instant iff $\phi$ is satisfied in $\ &lt; i+1,0\ &gt;$-th time instant. Moreover, in
order to formally capture the natural semantics of the until operator $\mathtt
U$, we have introduced a local variant $\mathtt u$ of the until operator. More
precisely, $\phi\,\mathtt u \psi$ is satisfied in $\ &lt; i,j\ &gt;$-th time instant
iff $\psi$ is satisfied in $\ &lt; i,j+k\ &gt;$-th time instant for some nonnegative
integer $k$, and $\phi$ is satisfied in $\ &lt; i,j+l\ &gt;$-th time instant for all
$0\leqslant l&lt;k$. As in many of our previous publications, the leitmotif is the
usage of infinitary inference rules in order to achieve the strong
completeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0834</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0834</id><created>2013-09-03</created><authors><author><keyname>Kammoun</keyname><forenames>Abla</forenames></author><author><keyname>Abed-Meraim</keyname><forenames>Karim</forenames></author></authors><title>Performance Analysis and Optimal Power Allocation for Linear Receivers
  Based on Superimposed Training</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive a performance comparison between two training-based
schemes for Multiple-Input Multiple-Output (MIMO) systems. The two schemes are
thetime-division multiplexing scheme and the recently proposed data-dependent
superimposed pilot scheme. For both schemes, a closed-form expressions for the
Bit Error Rate (BER) is provided. We also determine, for both schemes, the
optimal allocation of power between pilot and data that minimizes the BER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0844</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0844</id><created>2013-09-03</created><updated>2013-09-20</updated><authors><author><keyname>Jacobs</keyname><forenames>Bart</forenames><affiliation>Institute for Computing and Information Sciences</affiliation></author></authors><title>Bases as Coalgebras</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  18, 2013) lmcs:741</journal-ref><doi>10.2168/LMCS-9(3:23)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The free algebra adjunction, between the category of algebras of a monad and
the underlying category, induces a comonad on the category of algebras. The
coalgebras of this comonad are the topic of study in this paper (following
earlier work). It is illustrated how such coalgebras-on-algebras can be
understood as bases, decomposing each element x into primitives elements from
which x can be reconstructed via the operations of the algebra. This holds in
particular for the free vector space monad, but also for other monads, like
powerset or distribution. For instance, continuous dcpos or stably continuous
frames, where each element is the join of the elements way below it, can be
described as such coalgebras. Further, it is shown how these
coalgebras-on-algebras give rise to a comonoid structure for copy and delete,
and thus to diagonalisation of endomaps like in linear algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0858</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0858</id><created>2013-09-03</created><updated>2014-07-24</updated><authors><author><keyname>Tan</keyname><forenames>Zhao</forenames></author><author><keyname>Yang</keyname><forenames>Peng</forenames></author><author><keyname>Nehorai</keyname><forenames>Arye</forenames></author></authors><title>Joint Sparse Recovery Method for Compressed Sensing with Structured
  Dictionary Mismatches</title><categories>cs.IT math.IT</categories><comments>Submitted on Aug 27th, 2013(Revise on Feb 16th, 2014, Accepted on
  July 21th, 2014)</comments><doi>10.1109/TSP.2014.2343940</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In traditional compressed sensing theory, the dictionary matrix is given a
priori, whereas in real applications this matrix suffers from random noise and
fluctuations. In this paper we consider a signal model where each column in the
dictionary matrix is affected by a structured noise. This formulation is common
in direction-of-arrival (DOA) estimation of off-grid targets, encountered in
both radar systems and array processing. We propose to use joint sparse signal
recovery to solve the compressed sensing problem with structured dictionary
mismatches and also give an analytical performance bound on this joint sparse
recovery. We show that, under mild conditions, the reconstruction error of the
original sparse signal is bounded by both the sparsity and the noise level in
the measurement model. Moreover, we implement fast first-order algorithms to
speed up the computing process. Numerical examples demonstrate the good
performance of the proposed algorithm, and also show that the joint-sparse
recovery method yields a better reconstruction result than existing methods. By
implementing the joint sparse recovery method, the accuracy and efficiency of
DOA estimation are improved in both passive and active sensing cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0861</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0861</id><created>2013-09-03</created><updated>2016-02-14</updated><authors><author><keyname>Islam</keyname><forenames>Muhammad Nazmul</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan B.</forenames></author><author><keyname>Kompella</keyname><forenames>Sastry</forenames></author><author><keyname>Seskar</keyname><forenames>Ivan</forenames></author></authors><title>System Power Minimization to Access Non-Contiguous Spectrum in Cognitive
  Radio Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Cognitive Communications and
  Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless transmission using non-contiguous chunks of spectrum is becoming
increasingly important due to a variety of scenarios such as: secondary users
avoiding incumbent users in TV white space; anticipated spectrum sharing
between commercial and military systems; and spectrum sharing among
uncoordinated interferers in unlicensed bands. Multi-Channel Multi-Radio (MCMR)
platforms and Non-Contiguous Orthogonal Frequency Division Multiple Access
(NC-OFDMA) technology are the two commercially viable transmission choices to
access these non-contiguous spectrum chunks. Fixed MC-MRs do not scale with
increasing number of non-contiguous spectrum chunks due to their fixed set of
supporting radio front ends. NC-OFDMA allows nodes to access these
non-contiguous spectrum chunks and put null sub-carriers in the remaining
chunks. However, nulling sub-carriers increases the sampling rate (spectrum
span) which, in turn, increases the power consumption of radio front ends. Our
work characterizes this trade-off from a cross-layer perspective, specifically
by showing how the slope of ADC/DAC power consumption versus sampling rate
curve influences scheduling decisions in a multi-hop network. Specifically, we
provide a branch and bound algorithm based mixed integer linear programming
solution that performs joint power control, spectrum span selection, scheduling
and routing in order to minimize the system power of multi-hop NC-OFDMA
networks. We also provide a low complexity (O(E^2 M^2)) greedy algorithm where
M and E denote the number of channels and links respectively. Numerical
simulations suggest that our approach reduces system power by 30% over
classical transmit power minimization based cross-layer algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0866</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0866</id><created>2013-09-03</created><authors><author><keyname>Bartocci</keyname><forenames>Ezio</forenames><affiliation>TU Wien, Austria</affiliation></author><author><keyname>Bortolussi</keyname><forenames>Luca</forenames><affiliation>University of Trieste, Italy</affiliation></author><author><keyname>Nenzi</keyname><forenames>Laura</forenames><affiliation>IMT Lucca, Italy</affiliation></author><author><keyname>Sanguinetti</keyname><forenames>Guido</forenames><affiliation>University of Edinburgh, UK</affiliation></author></authors><title>On the Robustness of Temporal Properties for Stochastic Models</title><categories>cs.LO cs.AI cs.LG cs.SY</categories><comments>In Proceedings HSB 2013, arXiv:1308.5724</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 125, 2013, pp. 3-19</journal-ref><doi>10.4204/EPTCS.125.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic models such as Continuous-Time Markov Chains (CTMC) and Stochastic
Hybrid Automata (SHA) are powerful formalisms to model and to reason about the
dynamics of biological systems, due to their ability to capture the
stochasticity inherent in biological processes. A classical question in formal
modelling with clear relevance to biological modelling is the model checking
problem. i.e. calculate the probability that a behaviour, expressed for
instance in terms of a certain temporal logic formula, may occur in a given
stochastic process. However, one may not only be interested in the notion of
satisfiability, but also in the capacity of a system to mantain a particular
emergent behaviour unaffected by the perturbations, caused e.g. from extrinsic
noise, or by possible small changes in the model parameters. To address this
issue, researchers from the verification community have recently proposed
several notions of robustness for temporal logic providing suitable definitions
of distance between a trajectory of a (deterministic) dynamical system and the
boundaries of the set of trajectories satisfying the property of interest. The
contributions of this paper are twofold. First, we extend the notion of
robustness to stochastic systems, showing that this naturally leads to a
distribution of robustness scores. By discussing two examples, we show how to
approximate the distribution of the robustness score and its key indicators:
the average robustness and the conditional average robustness. Secondly, we
show how to combine these indicators with the satisfaction probability to
address the system design problem, where the goal is to optimize some control
parameters of a stochastic model in order to best maximize robustness of the
desired specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0867</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0867</id><created>2013-09-03</created><authors><author><keyname>Brim</keyname><forenames>L.</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>Vejpustek</keyname><forenames>T.</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>&#x160;afr&#xe1;nek</keyname><forenames>D.</forenames><affiliation>Masaryk University</affiliation></author><author><keyname>Fabrikov&#xe1;</keyname><forenames>J.</forenames><affiliation>Masaryk University</affiliation></author></authors><title>Robustness Analysis for Value-Freezing Signal Temporal Logic</title><categories>cs.LO cs.CE cs.SY</categories><comments>In Proceedings HSB 2013, arXiv:1308.5724</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 125, 2013, pp. 20-36</journal-ref><doi>10.4204/EPTCS.125.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our previous work we have introduced the logic STL*, an extension of
Signal Temporal Logic (STL) that allows value freezing. In this paper, we
define robustness measures for STL* by adapting the robustness measures
previously introduced for Metric Temporal Logic (MTL). Furthermore, we present
an algorithm for STL* robustness computation, which is implemented in the tool
Parasim. Application of STL* robustness analysis is demonstrated on case
studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0868</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0868</id><created>2013-09-03</created><authors><author><keyname>Chen</keyname><forenames>Ye</forenames><affiliation>West Virginia University</affiliation></author><author><keyname>Short</keyname><forenames>Christopher</forenames><affiliation>West Virginia University</affiliation></author><author><keyname>Hal&#xe1;sz</keyname><forenames>&#xc1;d&#xe1;m M.</forenames><affiliation>West Virginia University</affiliation></author><author><keyname>Edwards</keyname><forenames>Jeremy S.</forenames><affiliation>University of New Mexico</affiliation></author></authors><title>The impact of high density receptor clusters on VEGF signaling</title><categories>cs.SY q-bio.MN</categories><comments>In Proceedings HSB 2013, arXiv:1308.5724</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 125, 2013, pp. 37-52</journal-ref><doi>10.4204/EPTCS.125.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vascular endothelial growth factor (VEGF) signaling is involved in the
process of blood vessel development and maintenance. Signaling is initiated by
binding of the bivalent VEGF ligand to the membrane-bound receptors (VEGFR),
which in turn stimulates receptor dimerization. Herein, we discuss experimental
evidence that VEGF receptors localize in caveloae and other regions of the
plasma membrane, and for other receptors, it has been shown that receptor
clustering has an impact on dimerization and thus also on signaling. Overall,
receptor clustering is part of a complex ecosystem of interactions and how
receptor clustering impacts dimerization is not well understood. To address
these questions, we have formulated the simplest possible model. We have
postulated the existence of a single high affinity region in the cell membrane,
which acts as a transient trap for receptors. We have defined an ODE model by
introducing high- and low-density receptor variables and introduce the
corresponding reactions from a realistic model of VEGF signal initiation.
Finally, we use the model to investigate the relation between the degree of
VEGFR concentration, ligand availability, and signaling. In conclusion, our
simulation results provide a deeper understanding of the role of receptor
clustering in cell signaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0869</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0869</id><created>2013-09-03</created><authors><author><keyname>Dang</keyname><forenames>Thao</forenames><affiliation>CNRS-VERIMAG</affiliation></author><author><keyname>Dreossi</keyname><forenames>Tommaso</forenames><affiliation>VERIMAG, University of Udine</affiliation></author></authors><title>Falsifying Oscillation Properties of Parametric Biological Models</title><categories>cs.LO cs.CE cs.SY</categories><comments>In Proceedings HSB 2013, arXiv:1308.5724</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 125, 2013, pp. 53-67</journal-ref><doi>10.4204/EPTCS.125.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an approach to falsification of oscillation properties of
parametric biological models, based on the recently developed techniques for
testing continuous and hybrid systems. In this approach, an oscillation
property can be specified using a hybrid automaton, which is then used to guide
the exploration in the state and input spaces to search for the behaviors that
do not satisfy the property. We illustrate the approach with the Laub-Loomis
model for spontaneous oscillations during the aggregation stage of
Dictyostelium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0870</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0870</id><created>2013-09-03</created><authors><author><keyname>No&#xeb;l</keyname><forenames>Vincent</forenames><affiliation>Universit&#xe9; de Rennes 1</affiliation></author><author><keyname>Vakulenko</keyname><forenames>Sergey</forenames><affiliation>Saint Petersburg State University of Technology and Design</affiliation></author><author><keyname>Radulescu</keyname><forenames>Ovidiu</forenames><affiliation>Universit&#xe9; de Montpellier 2</affiliation></author></authors><title>A hybrid mammalian cell cycle model</title><categories>cs.CE q-bio.MN</categories><comments>In Proceedings HSB 2013, arXiv:1308.5724</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 125, 2013, pp. 68-83</journal-ref><doi>10.4204/EPTCS.125.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid modeling provides an effective solution to cope with multiple time
scales dynamics in systems biology. Among the applications of this method, one
of the most important is the cell cycle regulation. The machinery of the cell
cycle, leading to cell division and proliferation, combines slow growth,
spatio-temporal re-organisation of the cell, and rapid changes of regulatory
proteins concentrations induced by post-translational modifications. The
advancement through the cell cycle comprises a well defined sequence of stages,
separated by checkpoint transitions. The combination of continuous and discrete
changes justifies hybrid modelling approaches to cell cycle dynamics. We
present a piecewise-smooth version of a mammalian cell cycle model, obtained by
hybridization from a smooth biochemical model. The approximate hybridization
scheme, leading to simplified reaction rates and binary event location
functions, is based on learning from a training set of trajectories of the
smooth model. We discuss several learning strategies for the parameters of the
hybrid model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0871</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0871</id><created>2013-09-03</created><authors><author><keyname>Maler</keyname><forenames>Oded</forenames><affiliation>CNRS-VERIMAG, University of Grenoble</affiliation></author><author><keyname>Hal&#xe1;sz</keyname><forenames>&#xc1;d&#xe1;m M.</forenames><affiliation>Department of Methematics, West Virginia University</affiliation></author><author><keyname>Lebeltel</keyname><forenames>Olivier</forenames><affiliation>CNRS-VERIMAG, University of Grenoble</affiliation></author><author><keyname>Maler</keyname><forenames>Ouri</forenames><affiliation>Grenoble</affiliation></author></authors><title>Exploring the Dynamics of Mass Action Systems</title><categories>cs.CE cs.CY</categories><comments>In Proceedings HSB 2013, arXiv:1308.5724</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 125, 2013, pp. 84-91</journal-ref><doi>10.4204/EPTCS.125.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the Populus toolkit for exploring the dynamics of mass action
systems under different assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0872</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0872</id><created>2013-09-03</created><authors><author><keyname>Mobilia</keyname><forenames>Nicolas</forenames></author><author><keyname>Donz&#xe9;</keyname><forenames>Alexandre</forenames></author><author><keyname>Moulis</keyname><forenames>Jean Marc</forenames></author><author><keyname>Fanchon</keyname><forenames>&#xc9;ric</forenames></author></authors><title>Producing a Set of Models for the Iron Homeostasis Network</title><categories>cs.CE cs.LO q-bio.MN</categories><comments>In Proceedings HSB 2013, arXiv:1308.5724</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 125, 2013, pp. 92-98</journal-ref><doi>10.4204/EPTCS.125.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for modeling biological systems which combines
formal techniques on intervals, numerical simulations and satisfaction of
Signal Temporal Logic (STL) formulas. The main modeling challenge addressed by
this approach is the large uncertainty in the values of the parameters due to
the experimental difficulties of getting accurate biological data. This method
considers intervals for each parameter and a formal description of the expected
behavior of the model. In a first step, it produces reduced intervals of
possible parameter values. Then by performing a systematic search in these
intervals, it defines sets of parameter values used in the next step. This
procedure aims at finding a sub-space where the model robustly behaves as
expected. We apply this method to the modeling of the cellular iron homeostasis
network in erythroid progenitors. The produced model describes explicitly the
regulation mechanism which acts at the translational level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0873</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0873</id><created>2013-09-03</created><authors><author><keyname>Shu</keyname><forenames>Qin</forenames><affiliation>Department of Aerospace and Mechanical Engineering, University of Arizona, USA</affiliation></author><author><keyname>Ardila</keyname><forenames>Diana Catalina</forenames><affiliation>Department of Aerospace and Mechanical Engineering, University of Arizona, USA</affiliation></author><author><keyname>Sanfelice</keyname><forenames>Ricardo G.</forenames><affiliation>Department of Aerospace and Mechanical Engineering, University of Arizona, USA</affiliation></author><author><keyname>Geest</keyname><forenames>Jonathan P. Vande</forenames><affiliation>Department of Aerospace and Mechanical Engineering, University of Arizona, USA</affiliation></author></authors><title>A Hybrid Model of a Genetic Regulatory Network in Mammalian Sclera</title><categories>cs.SY q-bio.MN</categories><comments>In Proceedings HSB 2013, arXiv:1308.5724</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 125, 2013, pp. 99-105</journal-ref><doi>10.4204/EPTCS.125.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Myopia in human and animals is caused by the axial elongation of the eye and
is closely linked to the thinning of the sclera which supports the eye tissue.
This thinning has been correlated with the overproduction of matrix
metalloproteinase (MMP-2), an enzyme that degrades the collagen structure of
the sclera. In this short paper, we propose a descriptive model of a regulatory
network with hysteresis, which seems necessary for creating oscillatory
behavior in the hybrid model between MMP-2, MT1-MMP and TIMP-2. Numerical
results provide insight on the type of equilibria present in the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0874</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0874</id><created>2013-09-03</created><authors><author><keyname>Agarwal</keyname><forenames>Rachit</forenames></author><author><keyname>Caesar</keyname><forenames>Matthew</forenames></author><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author><author><keyname>Zhao</keyname><forenames>Ben Y.</forenames></author></authors><title>Shortest Paths in Microseconds</title><categories>cs.DC cs.DS cs.SI physics.soc-ph</categories><comments>Extended version of WOSN'12 paper: new techniques (reduced memory,
  faster computations), distributed (MapReduce) algorithm, multiple paths
  between a source-destination pair</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing shortest paths is a fundamental primitive for several social
network applications including socially-sensitive ranking, location-aware
search, social auctions and social network privacy. Since these applications
compute paths in response to a user query, the goal is to minimize latency
while maintaining feasible memory requirements. We present ASAP, a system that
achieves this goal by exploiting the structure of social networks.
  ASAP preprocesses a given network to compute and store a partial shortest
path tree (PSPT) for each node. The PSPTs have the property that for any two
nodes, each edge along the shortest path is with high probability contained in
the PSPT of at least one of the nodes. We show that the structure of social
networks enable the PSPT of each node to be an extremely small fraction of the
entire network; hence, PSPTs can be stored efficiently and each shortest path
can be computed extremely quickly.
  For a real network with 5 million nodes and 69 million edges, ASAP computes a
shortest path for most node pairs in less than 49 microseconds per pair. ASAP,
unlike any previous technique, also computes hundreds of paths (along with
corresponding distances) between any node pair in less than 100 microseconds.
Finally, ASAP admits efficient implementation on distributed programming
frameworks like MapReduce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0890</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0890</id><created>2013-09-03</created><authors><author><keyname>Berardi</keyname><forenames>Stefano</forenames><affiliation>Universit&#xe0; di Torino</affiliation></author><author><keyname>Liguoro</keyname><forenames>Ugo de'</forenames><affiliation>Universit&#xe0; di Torino</affiliation></author></authors><title>Non-monotonic Pre-fixed Points and Learning</title><categories>cs.LO</categories><comments>In Proceedings FICS 2013, arXiv:1308.5896</comments><proxy>EPTCS</proxy><acm-class>Theory</acm-class><journal-ref>EPTCS 126, 2013, pp. 1-10</journal-ref><doi>10.4204/EPTCS.126.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding pre-fixed points of interactive realizers
over arbitrary knowledge spaces, obtaining a relative recursive procedure.
Knowledge spaces and interactive realizers are an abstract setting to represent
learning processes, that can interpret non-constructive proofs. Atomic pieces
of information of a knowledge space are stratified into levels, and evaluated
into truth values depending on knowledge states. Realizers are then used to
define operators that extend a given state by adding and possibly removing
atoms: in a learning process states of knowledge change nonmonotonically.
Existence of a pre-fixed point of a realizer is equivalent to the termination
of the learning process with some state of knowledge which is free of patent
contradictions and such that there is nothing to add. In this paper we
generalize our previous results in the case of level 2 knowledge spaces and
deterministic operators to the case of omega-level knowledge spaces and of
non-deterministic operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0891</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0891</id><created>2013-09-03</created><authors><author><keyname>Cirstea</keyname><forenames>Corina</forenames><affiliation>University of Southampton</affiliation></author></authors><title>From Branching to Linear Time, Coalgebraically</title><categories>cs.LO</categories><comments>In Proceedings FICS 2013, arXiv:1308.5896</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 126, 2013, pp. 11-27</journal-ref><doi>10.4204/EPTCS.126.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider state-based systems modelled as coalgebras whose type
incorporates branching, and show that by suitably adapting the definition of
coalgebraic bisimulation, one obtains a general and uniform account of the
linear-time behaviour of a state in such a coalgebra. By moving away from a
boolean universe of truth values, our approach can measure the extent to which
a state in a system with branching is able to exhibit a particular linear-time
behaviour. This instantiates to measuring the probability of a specific
behaviour occurring in a probabilistic system, or measuring the minimal cost of
exhibiting a specific behaviour in the case of weighted computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0892</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0892</id><created>2013-09-03</created><authors><author><keyname>Santo</keyname><forenames>Jos&#xe9; Esp&#xed;rito</forenames><affiliation>Centro de Matem&#xe1;tica, Universidade do Minho, Braga, Portugal</affiliation></author><author><keyname>Matthes</keyname><forenames>Ralph</forenames><affiliation>Institut de Recherche en Informatique de Toulouse</affiliation></author><author><keyname>Pinto</keyname><forenames>Lu&#xed;s</forenames><affiliation>Centro de Matem&#xe1;tica, Universidade do Minho, Braga, Portugal</affiliation></author></authors><title>A Coinductive Approach to Proof Search</title><categories>cs.LO</categories><comments>In Proceedings FICS 2013, arXiv:1308.5896</comments><proxy>EPTCS</proxy><acm-class>F.4.1</acm-class><journal-ref>EPTCS 126, 2013, pp. 28-43</journal-ref><doi>10.4204/EPTCS.126.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to study proof search from a coinductive point of view. In this
paper, we consider intuitionistic logic and a focused system based on
Herbelin's LJT for the implicational fragment. We introduce a variant of lambda
calculus with potentially infinitely deep terms and a means of expressing
alternatives for the description of the &quot;solution spaces&quot; (called B\&quot;ohm
forests), which are a representation of all (not necessarily well-founded but
still locally well-formed) proofs of a given formula (more generally: of a
given sequent).
  As main result we obtain, for each given formula, the reduction of a
coinductive definition of the solution space to a effective coinductive
description in a finitary term calculus with a formal greatest fixed-point
operator. This reduction works in a quite direct manner for the case of Horn
formulas. For the general case, the naive extension would not even be true. We
need to study &quot;co-contraction&quot; of contexts (contraction bottom-up) for dealing
with the varying contexts needed beyond the Horn fragment, and we point out the
appropriate finitary calculus, where fixed-point variables are typed with
sequents. Co-contraction enters the interpretation of the formal greatest fixed
points - curiously in the semantic interpretation of fixed-point variables and
not of the fixed-point operator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0893</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0893</id><created>2013-09-03</created><authors><author><keyname>Grathwohl</keyname><forenames>Niels Bj&#xf8;rn Bugge</forenames><affiliation>University of Copenhagen</affiliation></author><author><keyname>Henglein</keyname><forenames>Fritz</forenames><affiliation>University of Copenhagen</affiliation></author><author><keyname>Kozen</keyname><forenames>Dexter</forenames><affiliation>Cornell University</affiliation></author></authors><title>Infinitary Axiomatization of the Equational Theory of Context-Free
  Languages</title><categories>cs.FL cs.LO</categories><comments>In Proceedings FICS 2013, arXiv:1308.5896</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 126, 2013, pp. 44-55</journal-ref><doi>10.4204/EPTCS.126.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a natural complete infinitary axiomatization of the equational theory
of the context-free languages, answering a question of Lei{\ss} (1992).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0894</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0894</id><created>2013-09-03</created><authors><author><keyname>Matsikoudis</keyname><forenames>Eleftherios</forenames><affiliation>University of California, Berkeley</affiliation></author><author><keyname>Lee</keyname><forenames>Edward A.</forenames><affiliation>University of California, Berkeley</affiliation></author></authors><title>The Fixed-Point Theory of Strictly Contracting Functions on Generalized
  Ultrametric Semilattices</title><categories>cs.LO</categories><comments>In Proceedings FICS 2013, arXiv:1308.5896</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 126, 2013, pp. 56-71</journal-ref><doi>10.4204/EPTCS.126.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of abstract structures, which we call generalized
ultrametric semilattices, and in which the meet operation of the semilattice
coexists with a generalized distance function in a tightly coordinated way. We
prove a constructive fixed-point theorem for strictly contracting functions on
directed-complete generalized ultrametric semilattices, and introduce a
corresponding induction principle. We cite examples of application in the
semantics of logic programming and timed computation, where, until now, the
only tool available has been the non-constructive fixed-point theorem of
Priess-Crampe and Ribenboim for strictly contracting functions on spherically
complete generalized ultrametric semilattices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0895</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0895</id><created>2013-09-03</created><authors><author><keyname>Milius</keyname><forenames>Stefan</forenames><affiliation>FAU Erlangen-N&#xfc;rnberg</affiliation></author><author><keyname>Litak</keyname><forenames>Tadeusz</forenames><affiliation>FAU Erlangen-N&#xfc;rnberg</affiliation></author></authors><title>Guard Your Daggers and Traces: On The Equational Properties of Guarded
  (Co-)recursion</title><categories>cs.LO</categories><comments>In Proceedings FICS 2013, arXiv:1308.5896</comments><proxy>EPTCS</proxy><acm-class>F.3.2</acm-class><journal-ref>EPTCS 126, 2013, pp. 72-86</journal-ref><doi>10.4204/EPTCS.126.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the recent interest in models of guarded (co-)recursion we study
its equational properties. We formulate axioms for guarded fixpoint operators
generalizing the axioms of iteration theories of Bloom and Esik. Models of
these axioms include both standard (e.g., cpo-based) models of iteration
theories and models of guarded recursion such as complete metric spaces or the
topos of trees studied by Birkedal et al. We show that the standard result on
the satisfaction of all Conway axioms by a unique dagger operation generalizes
to the guarded setting. We also introduce the notion of guarded trace operator
on a category, and we prove that guarded trace and guarded fixpoint operators
are in one-to-one correspondence. Our results are intended as first steps
leading to the description of classifying theories for guarded recursion and
hence completeness results involving our axioms of guarded fixpoint operators
in future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0896</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0896</id><created>2013-09-03</created><authors><author><keyname>Mio</keyname><forenames>Matteo</forenames><affiliation>CWI</affiliation></author><author><keyname>Simpson</keyname><forenames>Alex</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>{\L}ukasiewicz mu-Calculus</title><categories>cs.LO cs.DS</categories><comments>In Proceedings FICS 2013, arXiv:1308.5896</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 126, 2013, pp. 87-104</journal-ref><doi>10.4204/EPTCS.126.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper explores properties of {\L}ukasiewicz mu-calculus, a version of the
quantitative/probabilistic modal mu-calculus containing both weak and strong
conjunctions and disjunctions from {\L}ukasiewicz (fuzzy) logic. We show that
this logic encodes the well-known probabilistic temporal logic PCTL. And we
give a model-checking algorithm for computing the rational denotational value
of a formula at any state in a finite rational probabilistic nondeterministic
transition system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0897</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0897</id><created>2013-09-03</created><updated>2013-11-23</updated><authors><author><keyname>Ma</keyname><forenames>Yutao</forenames></author><author><keyname>Wu</keyname><forenames>Yang</forenames></author><author><keyname>Xu</keyname><forenames>Youwei</forenames></author></authors><title>Dynamics of Open-Source Software Developer's Commit Behavior: An
  Empirical Investigation of Subversion</title><categories>cs.SE</categories><comments>8 pages, 3 figures, 6 tables</comments><msc-class>68Nxx</msc-class><acm-class>D.2.9; K.6.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commit is an important operation of revision control for open-source software
(OSS). Recent research has been pursued to explore the statistical laws of such
an operation, but few of those papers conduct empirical investigations on
commit interval (i.e., the waiting time between two consecutive commits). In
this paper, we investigated software developer's collective and individual
commit behavior in terms of the distribution of commit intervals, and found
that 1) the data sets of project-level commit interval within both the
lifecycle and each release of the projects analyzed roughly follow power-law
distributions; and 2) lifecycle- and release-level collective commit interval
on class files can also be best fitted with power laws. These findings reveal
some general (collective) collaborative development patterns of OSS projects,
e.g., most of the waiting times between two consecutive commits to a central
repository are short, but only a few of them experience a long duration of
waiting. Then, the implications of what we found for OSS research were
outlined, which could provide an insight into understanding OSS development
processes better based on software developers' historical commit behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0898</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0898</id><created>2013-09-03</created><authors><author><keyname>Issa</keyname><forenames>Ibrahim</forenames></author><author><keyname>Fong</keyname><forenames>Silas L.</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author></authors><title>Two-Hop Interference Channels: Impact of Linear Schemes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the two-hop interference channel (IC), which consists of two
source-destination pairs communicating with each other via two relays. We
analyze the degrees of freedom (DoF) of this network when the relays are
restricted to perform linear schemes, and the channel gains are constant (i.e.,
slow fading). We show that, somewhat surprisingly, by using vector-linear
strategies at the relays, it is possible to achieve 4/3 sum-DoF when the
channel gains are real. The key achievability idea is to alternate relaying
coefficients across time, to create different end-to-end interference
structures (or topologies) at different times. Although each of these
topologies has only 1 sum-DoF, we manage to achieve 4/3 by coding across them.
Furthermore, we develop a novel outer bound that matches our achievability,
hence characterizing the sum-DoF of two-hop interference channels with linear
schemes. As for the case of complex channel gains, we characterize the sum-DoF
with linear schemes to be 5/3. We also generalize the results to the
multi-antenna setting, characterizing the sum-DoF with linear schemes to be
2M-1/3 (for complex channel gains), where M is the number of antennas at each
node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0924</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0924</id><created>2013-09-04</created><authors><author><keyname>de'Liguoro</keyname><forenames>Ugo</forenames><affiliation>Turin University</affiliation></author><author><keyname>Saurin</keyname><forenames>Alexis</forenames><affiliation>CNRS, PPS UMR 7126, Univ Paris Diderot</affiliation></author></authors><title>Proceedings First Workshop on Control Operators and their Semantics</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><acm-class>F.3.1, F.3.2, F.3.3</acm-class><journal-ref>EPTCS 127, 2013</journal-ref><doi>10.4204/EPTCS.127</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of the papers presented in this volume is on the interplay between
syntax and semantics in case of languages, namely the central question of what
a program means and how it does define the intended procedure. This is a
crucial issue especially in the case of control operators, since they are as
powerful as potentially obscure, and programs that use them are usually more
error-prone than purely declarative ones. The included contributions provide
perspectives on the topic of control operators via operational semantics of
formal calculi as well as type assignment systems, denotational semantics, game
semantics, category theory and logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0958</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0958</id><created>2013-09-04</created><authors><author><keyname>Corrigan-Gibbs</keyname><forenames>Henry</forenames></author><author><keyname>Ford</keyname><forenames>Bryan</forenames></author></authors><title>Conscript Your Friends into Larger Anonymity Sets with JavaScript</title><categories>cs.CR</categories><comments>An abbreviated version of this paper will appear at the WPES 2013
  workshop</comments><acm-class>K.4.1; C.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the design and prototype implementation of ConScript, a framework
for using JavaScript to allow casual Web users to participate in an anonymous
communication system. When a Web user visits a cooperative Web site, the site
serves a JavaScript application that instructs the browser to create and submit
&quot;dummy&quot; messages into the anonymity system. Users who want to send non-dummy
messages through the anonymity system use a browser plug-in to replace these
dummy messages with real messages. Creating such conscripted anonymity sets can
increase the anonymity set size available to users of remailer, e-voting, and
verifiable shuffle-style anonymity systems. We outline ConScript's
architecture, we address a number of potential attacks against ConScript, and
we discuss the ethical issues related to deploying such a system. Our
implementation results demonstrate the practicality of ConScript: a workstation
running our ConScript prototype JavaScript client generates a dummy message for
a mix-net in 81 milliseconds and it generates a dummy message for a
DoS-resistant DC-net in 156 milliseconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0961</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0961</id><created>2013-09-04</created><updated>2014-11-16</updated><authors><author><keyname>Zhang</keyname><forenames>Linjun</forenames></author><author><keyname>Small</keyname><forenames>Michael</forenames></author><author><keyname>Judd</keyname><forenames>Kevin</forenames></author></authors><title>Exactly scale-free scale-free networks</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>Draft, in preparation. An experimental/computational paper to follow
  on from 1305.7296. Okay - this has been a long time in development, but now
  it has converged to something that looks like a final version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many complex natural and physical systems exhibit patterns of interconnection
that conform, approximately, to a network structure referred to as scale-free.
Preferential attachment is one of many algorithms that have been introduced to
model the growth and structure of scale-free networks. With so many different
models of scale-free networks it is unclear what properties of scale-free
networks are typical, and what properties are peculiarities of a particular
growth or construction process. We propose a simple maximum entropy process
which provides the best representation of what are typical properties of
scale-free networks, and provides a standard against which real and
algorithmically generated networks can be compared. As an example we consider
preferential attachment and find that this particular growth model does not
yield typical realizations of scale-free networks. In particular, the widely
discussed &quot;fragility&quot; of scale-free networks is actually found to be due to the
peculiar &quot;hub-centric&quot; structure of preferential attachment networks. We
provide a method to generate or remove this latent hub-centric bias --- thereby
demonstrating exactly which features of preferential attachment networks are
atypical of the broader class of scale-free networks. We are also able to
statistically demonstrate whether real networks are typical realizations of
scale-free networks, or networks with that particular degree distribution;
using a new surrogate generation method for complex networks, exactly analogous
the the widely used surrogate tests of nonlinear time series analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0962</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0962</id><created>2013-09-04</created><updated>2015-01-23</updated><authors><author><keyname>Dzhafarov</keyname><forenames>Ehtibar N.</forenames></author><author><keyname>Kujala</keyname><forenames>Janne V.</forenames></author></authors><title>Random Variables Recorded under Mutually Exclusive Conditions:
  Contextuality-by-Default</title><categories>quant-ph cs.AI math.PR q-bio.QM</categories><comments>In H. Liljenstr\&quot;om (Ed.) Advances in Cognitive Neurodynamics IV (pp.
  405-410) (2015)</comments><msc-class>60A99, 81P13</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present general principles underlying analysis of the dependence of random
variables (outputs) on deterministic conditions (inputs). Random outputs
recorded under mutually exclusive input values are labeled by these values and
considered stochastically unrelated, possessing no joint distribution. An input
that does not directly influence an output creates a context for the latter.
Any constraint imposed on the dependence of random outputs on inputs can be
characterized by considering all possible couplings (joint distributions)
imposed on stochastically unrelated outputs. The target application of these
principles is a quantum mechanical system of entangled particles, with
directions of spin measurements chosen for each particle being inputs and the
spins recorded outputs. The sphere of applicability, however, spans systems
across physical, biological, and behavioral sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0971</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0971</id><created>2013-09-04</created><authors><author><keyname>L&#xe9;v&#xea;que</keyname><forenames>Benjamin</forenames></author><author><keyname>Lin</keyname><forenames>David Y.</forenames></author><author><keyname>Maffray</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>Detecting induced subgraphs</title><categories>cs.DM math.CO</categories><comments>arXiv admin note: text overlap with arXiv:1308.6678</comments><msc-class>05C85</msc-class><journal-ref>B. L\'ev\^eque, D. Lin, F. Maffray, and N. Trotignon. Detecting
  induced subgraphs. Discrete Applied Mathematics, 157:3540-3551, 2009</journal-ref><doi>10.1016/j.dam.2009.02.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An \emph{s-graph} is a graph with two kinds of edges: \emph{subdivisible}
edges and \emph{real} edges. A \emph{realisation} of an s-graph $B$ is any
graph obtained by subdividing subdivisible edges of $B$ into paths of arbitrary
length (at least one). Given an s-graph $B$, we study the decision problem
$\Pi_B$ whose instance is a graph $G$ and question is &quot;Does $G$ contain a
realisation of $B$ as an induced subgraph?&quot;. For several $B$'s, the complexity
of $\Pi_B$ is known and here we give the complexity for several more. Our
NP-completeness proofs for $\Pi_B$'s rely on the NP-completeness proof of the
following problem. Let $\cal S$ be a set of graphs and $d$ be an integer. Let
$\Gamma_{\cal S}^d$ be the problem whose instance is $(G, x, y)$ where $G$ is a
graph whose maximum degree is at most d, with no induced subgraph in $\cal S$
and $x, y \in V(G)$ are two non-adjacent vertices of degree 2. The question is
&quot;Does $G$ contain an induced cycle passing through $x, y$?&quot;. Among several
results, we prove that $\Gamma^3_{\emptyset}$ is NP-complete. We give a simple
criterion on a connected graph $H$ to decide whether $\Gamma^{+\infty}_{\{H\}}$
is polynomial or NP-complete. The polynomial cases rely on the algorithm
three-in-a-tree, due to Chudnovsky and Seymour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0978</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0978</id><created>2013-09-04</created><authors><author><keyname>Derhy</keyname><forenames>Nicolas</forenames></author><author><keyname>Picouleau</keyname><forenames>Christophe</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>The four-in-a-tree problem in triangle-free graphs</title><categories>cs.DM math.CO</categories><msc-class>05C85</msc-class><journal-ref>N. Derhy, C. Picouleau and N. Trotignon. The four-in-a-tree
  problem for triangle-free graphs. Graphs and Combinatorics, 25:489-502, 2009</journal-ref><doi>10.1007/s00373-009-0867-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The three-in-a-tree algorithm of Chudnovsky and Seymour decides in time
$O(n^4)$ whether three given vertices of a graph belong to an induced tree.
Here, we study four-in-a-tree for triangle-free graphs. We give a structural
answer to the following question: what does a triangle-free graph look like if
no induced tree covers four given vertices? Our main result says that any such
graph must have the &quot;same structure&quot;, in a sense to be defined precisely, as a
square or a cube.
  We provide an $O(nm)$-time algorithm that given a triangle-free graph $G$
together with four vertices outputs either an induced tree that contains them
or a partition of $V(G)$ certifying that no such tree exists. We prove that the
problem of deciding whether there exists a tree $T$ covering the four vertices
such that at most one vertex of $T$ has degree at least 3 is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0985</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0985</id><created>2013-09-04</created><authors><author><keyname>Roux</keyname><forenames>Stephane</forenames><affiliation>LMT</affiliation></author><author><keyname>Leclerc</keyname><forenames>Hugo</forenames><affiliation>LMT</affiliation></author><author><keyname>Hild</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LMT</affiliation></author></authors><title>Efficient binary tomographic reconstruction</title><categories>physics.class-ph cs.CV</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tomographic reconstruction of a binary image from few projections is
considered. A novel {\em heuristic} algorithm is proposed, the central element
of which is a nonlinear transformation $\psi(p)=\log(p/(1-p))$ of the
probability $p$ that a pixel of the sought image be 1-valued. It consists of
backprojections based on $\psi(p)$ and iterative corrections. Application of
this algorithm to a series of artificial test cases leads to exact binary
reconstructions, (i.e recovery of the binary image for each single pixel) from
the knowledge of projection data over a few directions. Images up to $10^6$
pixels are reconstructed in a few seconds. A series of test cases is performed
for comparison with previous methods, showing a better efficiency and reduced
computation times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.0999</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.0999</id><created>2013-09-04</created><authors><author><keyname>Seal</keyname><forenames>Ayan</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>Minutiae Based Thermal Face Recognition using Blood Perfusion Data</title><categories>cs.CV</categories><comments>4 pages, Image Information Processing (ICIIP)</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper describes an efficient approach for human face recognition based
on blood perfusion data from infra-red face images. Blood perfusion data are
characterized by the regional blood flow in human tissue and therefore do not
depend entirely on surrounding temperature. These data bear a great potential
for deriving discriminating facial thermogram for better classification and
recognition of face images in comparison to optical image data. Blood perfusion
data are related to distribution of blood vessels under the face skin. A
distribution of blood vessels are unique for each person and as a set of
extracted minutiae points from a blood perfusion data of a human face should be
unique for that face. There may be several such minutiae point sets for a
single face but all of these correspond to that particular face only. Entire
face image is partitioned into equal blocks and the total number of minutiae
points from each block is computed to construct final vector. Therefore, the
size of the feature vectors is found to be same as total number of blocks
considered. For classification, a five layer feed-forward backpropagation
neural network has been used. A number of experiments were conducted to
evaluate the performance of the proposed face recognition system with varying
block sizes. Experiments have been performed on the database created at our own
laboratory. The maximum success of 91.47% recognition has been achieved with
block size 8X8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1000</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1000</id><created>2013-09-04</created><authors><author><keyname>Seal</keyname><forenames>Ayan</forenames></author><author><keyname>Ganguly</keyname><forenames>Suranjan</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kr.</forenames></author></authors><title>Automated Thermal Face recognition based on Minutiae Extraction</title><categories>cs.CV</categories><comments>29 pages, Int. J. Computational Intelligence Studies</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper an efficient approach for human face recognition based on the
use of minutiae points in thermal face image is proposed. The thermogram of
human face is captured by thermal infra-red camera. Image processing methods
are used to pre-process the captured thermogram, from which different
physiological features based on blood perfusion data are extracted. Blood
perfusion data are related to distribution of blood vessels under the face
skin. In the present work, three different methods have been used to get the
blood perfusion image, namely bit-plane slicing and medial axis transform,
morphological erosion and medial axis transform, sobel edge operators.
Distribution of blood vessels is unique for each person and a set of extracted
minutiae points from a blood perfusion data of a human face should be unique
for that face. Two different methods are discussed for extracting minutiae
points from blood perfusion data. For extraction of features entire face image
is partitioned into equal size blocks and the total number of minutiae points
from each block is computed to construct final feature vector. Therefore, the
size of the feature vectors is found to be same as total number of blocks
considered. A five layer feed-forward back propagation neural network is used
as the classification tool. A number of experiments were conducted to evaluate
the performance of the proposed face recognition methodologies with varying
block size on the database created at our own laboratory. It has been found
that the first method supercedes the other two producing an accuracy of 97.62%
with block size 16X16 for bit-plane 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1007</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1007</id><created>2013-09-04</created><updated>2013-09-11</updated><authors><author><keyname>Kontorovich</keyname><forenames>Aryeh</forenames></author></authors><title>Concentration in unbounded metric spaces and algorithmic stability</title><categories>math.PR cs.LG math.FA</categories><msc-class>60D99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove an extension of McDiarmid's inequality for metric spaces with
unbounded diameter. To this end, we introduce the notion of the {\em
subgaussian diameter}, which is a distribution-dependent refinement of the
metric diameter. Our technique provides an alternative approach to that of
Kutin and Niyogi's method of weakly difference-bounded functions, and yields
nontrivial, dimension-free results in some interesting cases where the former
does not. As an application, we give apparently the first generalization bound
in the algorithmic stability setting that holds for unbounded loss functions.
We furthermore extend our concentration inequality to strongly mixing
processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1009</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1009</id><created>2013-09-04</created><authors><author><keyname>Seal</keyname><forenames>Ayan</forenames></author><author><keyname>Ganguly</keyname><forenames>Suranjan</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>A Comparative Study of Human thermal face recognition based on Haar
  wavelet transform (HWT) and Local Binary Pattern (LBP)</title><categories>cs.CV</categories><comments>17 pages Computational Intelligence and Neuroscience 2012</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Thermal infra-red (IR) images focus on changes of temperature distribution on
facial muscles and blood vessels. These temperature changes can be regarded as
texture features of images. A comparative study of face recognition methods
working in thermal spectrum is carried out in this paper. In these study two
local-matching methods based on Haar wavelet transform and Local Binary Pattern
(LBP) are analyzed. Wavelet transform is a good tool to analyze multi-scale,
multi-direction changes of texture. Local binary patterns (LBP) are a type of
feature used for classification in computer vision. Firstly, human thermal IR
face image is preprocessed and cropped the face region only from the entire
image. Secondly, two different approaches are used to extract the features from
the cropped face region. In the first approach, the training images and the
test images are processed with Haar wavelet transform and the LL band and the
average of LH/HL/HH bands sub-images are created for each face image. Then a
total confidence matrix is formed for each face image by taking a weighted sum
of the corresponding pixel values of the LL band and average band. For LBP
feature extraction, each of the face images in training and test datasets is
divided into 161 numbers of sub images, each of size 8X8 pixels. For each such
sub images, LBP features are extracted which are concatenated in row wise
manner. PCA is performed separately on the individual feature set for
dimensionality reeducation. Finally two different classifiers are used to
classify face images. One such classifier multi-layer feed forward neural
network and another classifier is minimum distance classifier. The Experiments
have been performed on the database created at our own laboratory and Terravic
Facial IR Database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1014</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1014</id><created>2013-09-04</created><authors><author><keyname>Mery</keyname><forenames>Bruno</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Retor&#xe9;</keyname><forenames>Christian</forenames><affiliation>LaBRI</affiliation></author></authors><title>Advances in the Logical Representation of Lexical Semantics</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>NLCS'13 - Natural Language and Computer Science - 2013 (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of lexical semantics and pragmatics in the analysis of the
meaning of natural lan- guage has prompted changes to the global framework
derived from Montague. In those works, the original lexicon, in which words
were assigned an atomic type of a single-sorted logic, has been re- placed by a
set of many-facetted lexical items that can compose their meaning with salient
contextual properties using a rich typing system as a guide. Having related our
proposal for such an expanded framework \LambdaTYn, we present some recent
advances in the logical formalisms associated, including constraints on lexical
transformations and polymorphic quantifiers, and ongoing discussions and
research on the granularity of the type system and the limits of transitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1026</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1026</id><created>2013-09-04</created><authors><author><keyname>Li</keyname><forenames>Bin</forenames></author><author><keyname>Shen</keyname><forenames>Hui</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Parallel Decoders of Polar Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we propose parallel SC (Successive Cancellation) decoder and
parallel SC-List decoder for polar codes. The parallel decoder is composed of
M=2^m(m&gt;=1) component decoders working in parallel and each component decoder
decodes a Polar code of a block size of 1/M of the original Polar code.
Therefore the parallel decoder has M times faster decoding speed. Our
simulation results show that the parallel decoder has almost the same
error-rate performance as the conventional non-parallel decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1029</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1029</id><created>2013-09-04</created><updated>2013-09-10</updated><authors><author><keyname>Ranneberg</keyname><forenames>Maximilian</forenames></author></authors><title>Sensor Setups for State and Wind Estimation for Airborne Wind Energy
  Converters</title><categories>cs.SY cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An unscented Kalman filter with joint state and parameter estimation is
proposed for aerodynamics, states and wind conditions for airborne wind energy
converters. The proposed estimator relies on different measurement setups. Due
to the strict economic constraints of wind energy converters, the sensor setups
are chosen with minimal cost and reliability issues in mind. Simulation data
with a high fidelity system model and experimental tests using flight data,
together with wind measurements obtained using a lidar system for altitude wind
measurements, are used for validation. The data was obtained during test
flights of the EnerK\'ite EK30, an airborne wind energy converter currently in
research operation in Brandenburg, Germany. Feasible accuracies were achieved
even with the simplest of setups and illustrate the gain achievable by airborne
sensors. Additionally, the results encourage further research into use of the
obtained wind estimates for site assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1043</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1043</id><created>2013-09-04</created><authors><author><keyname>Neary</keyname><forenames>Turlough</forenames><affiliation>University of Z&#xfc;rich and ETH Z&#xfc;rich</affiliation></author><author><keyname>Cook</keyname><forenames>Matthew</forenames><affiliation>University of Z&#xfc;rich and ETH Z&#xfc;rich</affiliation></author></authors><title>Proceedings Machines, Computations and Universality 2013</title><categories>cs.FL cs.CC</categories><proxy>EPTCS</proxy><acm-class>F.1.1; F.4.2</acm-class><journal-ref>EPTCS 128, 2013</journal-ref><doi>10.4204/EPTCS.128</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the 6th conference on Machines,
Computations and Universality (MCU 2013). MCU 2013 was held in Zurich,
Switzerland, September 9-11, 2013. The MCU series began in Paris in 1995 and
has since been concerned with gaining a deeper understanding of computation
through the study of models of general purpose computation. This volume
continues in this tradition and includes new simple universal models of
computation, and other results that clarify the relationships between models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1049</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1049</id><created>2013-09-04</created><updated>2013-09-10</updated><authors><author><keyname>Vaquero</keyname><forenames>Luis</forenames></author><author><keyname>Cuadrado</keyname><forenames>Felix</forenames></author><author><keyname>Logothetis</keyname><forenames>Dionysios</forenames></author><author><keyname>Martella</keyname><forenames>Claudio</forenames></author></authors><title>xDGP: A Dynamic Graph Processing System with Adaptive Partitioning</title><categories>cs.DC</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world systems, such as social networks, rely on mining efficiently
large graphs, with hundreds of millions of vertices and edges. This volume of
information requires partitioning the graph across multiple nodes in a
distributed system. This has a deep effect on performance, as traversing edges
cut between partitions incurs a significant performance penalty due to the cost
of communication. Thus, several systems in the literature have attempted to
improve computational performance by enhancing graph partitioning, but they do
not support another characteristic of real-world graphs: graphs are inherently
dynamic, their topology evolves continuously, and subsequently the optimum
partitioning also changes over time.
  In this work, we present the first system that dynamically repartitions
massive graphs to adapt to structural changes. The system optimises graph
partitioning to prevent performance degradation without using data replication.
The system adopts an iterative vertex migration algorithm that relies on local
information only, making complex coordination unnecessary. We show how the
improvement in graph partitioning reduces execution time by over 50%, while
adapting the partitioning to a large number of changes to the graph in three
real-world scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1051</identifier>
 <datestamp>2014-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1051</id><created>2013-09-04</created><updated>2014-11-27</updated><authors><author><keyname>Dias</keyname><forenames>Elis&#xe2;ngela Silva</forenames></author><author><keyname>Castonguay</keyname><forenames>Diane</forenames></author><author><keyname>Longo</keyname><forenames>Humberto</forenames></author><author><keyname>Jradi</keyname><forenames>Walid Abdala Rfaei</forenames></author></authors><title>Efficient Enumeration of Chordless Cycles</title><categories>cs.DS cs.DM</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a finite undirected simple graph, a {\it chordless cycle} is an induced
subgraph which is a cycle. We propose two algorithms to enumerate all chordless
cycles of such a graph. Compared to other similar algorithms, the proposed
algorithms have the advantage of finding each chordless cycle only once. To
ensure this, we introduced the concepts of vertex labeling and initial valid
vertex triplet. To guarantee that the expansion of a given chordless path will
always lead to a chordless cycle, we use a breadth-first search in a subgraph
obtained by the elimination of many of the vertices from the original graph.
The resulting algorithm has time complexity $\mathcal{O}(n + m)$ in the output
size, where $n$ is the number of vertices and $m$ is the number of edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1066</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1066</id><created>2013-09-04</created><authors><author><keyname>Andro</keyname><forenames>Mathieu</forenames><affiliation>DV/IST</affiliation></author><author><keyname>Tr&#xf6;ger</keyname><forenames>Ga&#xeb;tan</forenames><affiliation>ENPC</affiliation></author></authors><title>Statistiques et visibilit\'e des biblioth\`eques num\'eriques : quelles
  strat\'egies de diffusion ?</title><categories>cs.DL</categories><comments>7 p, in French</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compared statistics of major digital libraries and we tried to see if
there is a relationship between the volume of digital libraries and online
visibility of each digitized document. Finally, we analyzed the consequences of
the diffusion strategies of French digital libraries. The statistics were
obtained by survey, gray literature, alexa.com, and Google Trends.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1080</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1080</id><created>2013-09-04</created><authors><author><keyname>Eads</keyname><forenames>Damian</forenames></author><author><keyname>Helmbold</keyname><forenames>David</forenames></author><author><keyname>Rosten</keyname><forenames>Ed</forenames></author></authors><title>Boosting in Location Space</title><categories>cs.CV</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of object detection is to find objects in an image. An object
detector accepts an image and produces a list of locations as $(x,y)$ pairs.
Here we introduce a new concept: {\bf location-based boosting}. Location-based
boosting differs from previous boosting algorithms because it optimizes a new
spatial loss function to combine object detectors, each of which may have
marginal performance, into a single, more accurate object detector. A
structured representation of object locations as a list of $(x,y)$ pairs is a
more natural domain for object detection than the spatially unstructured
representation produced by classifiers. Furthermore, this formulation allows us
to take advantage of the intuition that large areas of the background are
uninteresting and it is not worth expending computational effort on them. This
results in a more scalable algorithm because it does not need to take measures
to prevent the background data from swamping the foreground data such as
subsampling or applying an ad-hoc weighting to the pixels. We first present the
theory of location-based boosting, and then motivate it with empirical results
on a challenging data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1089</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1089</id><created>2013-09-04</created><authors><author><keyname>Guo</keyname><forenames>Zeyu</forenames></author></authors><title>Randomness-efficient Curve Samplers</title><categories>cs.CC</categories><comments>Random 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Curve samplers are sampling algorithms that proceed by viewing the domain as
a vector space over a finite field, and randomly picking a low-degree curve in
it as the sample. Curve samplers exhibit a nice property besides the sampling
property: the restriction of low-degree polynomials over the domain to the
sampled curve is still low-degree. This property is often used in combination
with the sampling property and has found many applications, including PCP
constructions, local decoding of codes, and algebraic PRG constructions.
  The randomness complexity of curve samplers is a crucial parameter for its
applications. It is known that (non-explicit) curve samplers using $O(\log
N+\log(1/\delta))$ random bits exist, where $N$ is the domain size and $\delta$
is the confidence error. The question of explicitly constructing
randomness-efficient curve samplers was first raised in \cite{TU06} where they
obtained curve samplers with near-optimal randomness complexity.
  We present an explicit construction of low-degree curve samplers with {\em
optimal} randomness complexity (up to a constant factor), sampling curves of
degree $\left(m\log_q(1/\delta)\right)^{O(1)}$ in $\mathbb{F}_q^m$. Our
construction is a delicate combination of several components, including
extractor machinery, limited independence, iterated sampling, and
list-recoverable codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1101</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1101</id><created>2013-09-04</created><authors><author><keyname>Cohen</keyname><forenames>Jeremy</forenames></author><author><keyname>Cantwell</keyname><forenames>Chris</forenames></author><author><keyname>Hong</keyname><forenames>Neil Chue</forenames></author><author><keyname>Moxey</keyname><forenames>David</forenames></author><author><keyname>Illingworth</keyname><forenames>Malcolm</forenames></author><author><keyname>Turner</keyname><forenames>Andrew</forenames></author><author><keyname>Darlington</keyname><forenames>John</forenames></author><author><keyname>Sherwin</keyname><forenames>Spencer</forenames></author></authors><title>Simplifying the Development, Use and Sustainability of HPC Software</title><categories>cs.DC cs.SE</categories><comments>4 page position paper, submission to WSSSPE13 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing software to undertake complex, compute-intensive scientific
processes requires a challenging combination of both specialist domain
knowledge and software development skills to convert this knowledge into
efficient code. As computational platforms become increasingly heterogeneous
and newer types of platform such as Infrastructure-as-a-Service (IaaS) cloud
computing become more widely accepted for HPC computations, scientists require
more support from computer scientists and resource providers to develop
efficient code and make optimal use of the resources available to them. As part
of the libhpc stage 1 and 2 projects we are developing a framework to provide a
richer means of job specification and efficient execution of complex scientific
software on heterogeneous infrastructure. The use of such frameworks has
implications for the sustainability of scientific software. In this paper we
set out our developing understanding of these challenges based on work carried
out in the libhpc project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1110</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1110</id><created>2013-09-04</created><authors><author><keyname>Huang</keyname><forenames>Longbo</forenames></author><author><keyname>Zhang</keyname><forenames>Shaoquan</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Liu</keyname><forenames>Xin</forenames></author></authors><title>When Backpressure Meets Predictive Scheduling</title><categories>math.OC cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the increasing popularity of learning and predicting human user
behavior in communication and computing systems, in this paper, we investigate
the fundamental benefit of predictive scheduling, i.e., predicting and
pre-serving arrivals, in controlled queueing systems. Based on a lookahead
window prediction model, we first establish a novel equivalence between the
predictive queueing system with a \emph{fully-efficient} scheduling scheme and
an equivalent queueing system without prediction. This connection allows us to
analytically demonstrate that predictive scheduling necessarily improves system
delay performance and can drive it to zero with increasing prediction power. We
then propose the \textsf{Predictive Backpressure (PBP)} algorithm for achieving
optimal utility performance in such predictive systems. \textsf{PBP}
efficiently incorporates prediction into stochastic system control and avoids
the great complication due to the exponential state space growth in the
prediction window size. We show that \textsf{PBP} can achieve a utility
performance that is within $O(\epsilon)$ of the optimal, for any $\epsilon&gt;0$,
while guaranteeing that the system delay distribution is a
\emph{shifted-to-the-left} version of that under the original Backpressure
algorithm. Hence, the average packet delay under \textsf{PBP} is strictly
better than that under Backpressure, and vanishes with increasing prediction
window size. This implies that the resulting utility-delay tradeoff with
predictive scheduling beats the known optimal $[O(\epsilon),
O(\log(1/\epsilon))]$ tradeoff for systems without prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1114</identifier>
 <datestamp>2014-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1114</id><created>2013-09-04</created><updated>2014-03-23</updated><authors><author><keyname>Rivi</keyname><forenames>Marzia</forenames></author><author><keyname>Gheller</keyname><forenames>Claudio</forenames></author><author><keyname>Dykes</keyname><forenames>Tim</forenames></author><author><keyname>Krokos</keyname><forenames>Mel</forenames></author><author><keyname>Dolag</keyname><forenames>Klaus</forenames></author></authors><title>GPU Accelerated Particle Visualization with Splotch</title><categories>astro-ph.IM cs.DC</categories><comments>25 pages, 9 figures. Astronomy and Computing (2014)</comments><journal-ref>Astronomy and Computing (2014)</journal-ref><doi>10.1016/j.ascom.2014.03.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Splotch is a rendering algorithm for exploration and visual discovery in
particle-based datasets coming from astronomical observations or numerical
simulations. The strengths of the approach are production of high quality
imagery and support for very large-scale datasets through an effective mix of
the OpenMP and MPI parallel programming paradigms. This article reports our
experiences in re-designing Splotch for exploiting emerging HPC architectures
nowadays increasingly populated with GPUs. A performance model is introduced
for data transfers, computations and memory access, to guide our re-factoring
of Splotch. A number of parallelization issues are discussed, in particular
relating to race conditions and workload balancing, towards achieving optimal
performances. Our implementation was accomplished by using the CUDA programming
paradigm. Our strategy is founded on novel schemes achieving optimized data
organisation and classification of particles. We deploy a reference simulation
to present performance results on acceleration gains and scalability. We
finally outline our vision for future work developments including possibilities
for further optimisations and exploitation of emerging technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1125</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1125</id><created>2013-09-04</created><authors><author><keyname>Mendes</keyname><forenames>Ana Cristina</forenames></author><author><keyname>Coheur</keyname><forenames>Lu&#xed;sa</forenames></author><author><keyname>Curto</keyname><forenames>S&#xe9;rgio</forenames></author></authors><title>Learning to answer questions</title><categories>cs.CL</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an open-domain Question-Answering system that learns to answer
questions based on successful past interactions. We follow a pattern-based
approach to Answer-Extraction, where (lexico-syntactic) patterns that relate a
question to its answer are automatically learned and used to answer future
questions. Results show that our approach contributes to the system's best
performance when it is conjugated with typical Answer-Extraction strategies.
Moreover, it allows the system to learn with the answered questions and to
rectify wrong or unsolved past questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1129</identifier>
 <datestamp>2013-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1129</id><created>2013-09-04</created><authors><author><keyname>Gupta</keyname><forenames>Rashmi</forenames></author><author><keyname>Joshi</keyname><forenames>Nisheeth</forenames></author><author><keyname>Mathur</keyname><forenames>Iti</forenames></author></authors><title>Analysing Quality of English-Hindi Machine Translation Engine Outputs
  Using Bayesian Classification</title><categories>cs.CL</categories><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA), Vol. 4, No. 4, July 2013</journal-ref><doi>10.5121/ijaia.2013.4415</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem for estimating the quality of machine
translation outputs which are independent of human intervention and are
generally addressed using machine learning techniques.There are various
measures through which a machine learns translations quality. Automatic
Evaluation metrics produce good co-relation at corpus level but cannot produce
the same results at the same segment or sentence level. In this paper 16
features are extracted from the input sentences and their translations and a
quality score is obtained based on Bayesian inference produced from training
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1131</identifier>
 <datestamp>2014-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1131</id><created>2013-09-04</created><updated>2014-06-16</updated><authors><author><keyname>Fern&#xe1;ndez-Gracia</keyname><forenames>Juan</forenames></author><author><keyname>Suchecki</keyname><forenames>Krzysztof</forenames></author><author><keyname>Ramasco</keyname><forenames>Jos&#xe9; J.</forenames></author><author><keyname>Miguel</keyname><forenames>Maxi San</forenames></author><author><keyname>Egu&#xed;luz</keyname><forenames>V&#xed;ctor M.</forenames></author></authors><title>Is the Voter Model a model for voters?</title><categories>physics.soc-ph cs.SI</categories><comments>13 pages, 13 figures</comments><journal-ref>Physical Review Letters 112, 158701 (2014)</journal-ref><doi>10.1103/PhysRevLett.112.158701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The voter model has been studied extensively as a paradigmatic opinion
dynamics' model. However, its ability for modeling real opinion dynamics has
not been addressed. We introduce a noisy voter model (accounting for social
influence) with agents' recurrent mobility (as a proxy for social context),
where the spatial and population diversity are taken as inputs to the model. We
show that the dynamics can be described as a noisy diffusive process that
contains the proper anysotropic coupling topology given by population and
mobility heterogeneity. The model captures statistical features of the US
presidential elections as the stationary vote-share fluctuations across
counties, and the long-range spatial correlations that decay logarithmically
with the distance. Furthermore, it recovers the behavior of these properties
when a real-space renormalization is performed by coarse-graining the
geographical scale from county level through congressional districts and up to
states. Finally, we analyze the role of the mobility range and the randomness
in decision making which are consistent with the empirical observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1151</identifier>
 <datestamp>2014-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1151</id><created>2013-09-04</created><updated>2014-08-29</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author></authors><title>Non-Malleable Coding Against Bit-wise and Split-State Tampering</title><categories>cs.IT cs.CC cs.CR math.IT</categories><comments>Coding theory, Cryptography, Error Detection, Information Theory,
  Tamper-resilient Storage, Randomness Extractors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-malleable coding, introduced by Dziembowski, Pietrzak and Wichs (ICS
2010), aims for protecting the integrity of information against tampering
attacks in situations where error-detection is impossible. Intuitively,
information encoded by a non-malleable code either decodes to the original
message or, in presence of any tampering, to an unrelated message. Dziembowski
et al. show existence of non-malleable codes for any class of tampering
functions of bounded size.
  We consider constructions of coding schemes against two well-studied classes
of tampering functions: bit-wise tampering functions (where the adversary
tampers each bit of the encoding independently) and split-state adversaries
(where two independent adversaries arbitrarily tamper each half of the encoded
sequence).
  1. For bit-tampering, we obtain explicit and efficiently encodable and
decodable codes of length $n$ achieving rate $1-o(1)$ and error (security)
$\exp(-\tilde{\Omega}(n^{1/7}))$. We improve the error to
$\exp(-\tilde{\Omega}(n))$ at the cost of making the construction Monte Carlo
with success probability $1-\exp(-\Omega(n))$. Previously, the best known
construction of bit-tampering codes was the Monte Carlo construction of
Dziembowski et al. (ICS 2010) achieving rate ~.1887.
  2. We initiate the study of seedless non-malleable extractors as a variation
of non-malleable extractors introduced by Dodis and Wichs (STOC 2009). We show
that construction of non-malleable codes for the split-state model reduces to
construction of non-malleable two-source extractors. We prove existence of such
extractors, which implies that codes obtained from our reduction can achieve
rates arbitrarily close to 1/5 and exponentially small error. Currently, the
best known explicit construction of split-state coding schemes is due to
Aggarwal, Dodis and Lovett (ECCC TR13-081) which only achieves vanishing
(polynomially small) rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1155</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1155</id><created>2013-09-04</created><authors><author><keyname>Seal</keyname><forenames>Ayan</forenames></author><author><keyname>Ganguly</keyname><forenames>Suranjan</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>Minutiae Based Thermal Human Face Recognition using Label Connected
  Component Algorithm</title><categories>cs.CV</categories><comments>7 pages, Conference. arXiv admin note: substantial text overlap with
  arXiv:1309.1000, arXiv:1309.0999, arXiv:1309.1009</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, a thermal infra red face recognition system for human
identification and verification using blood perfusion data and back propagation
feed forward neural network is proposed. The system consists of three steps. At
the very first step face region is cropped from the colour 24-bit input images.
Secondly face features are extracted from the croped region, which will be
taken as the input of the back propagation feed forward neural network in the
third step and classification and recognition is carried out. The proposed
approaches are tested on a number of human thermal infra red face images
created at our own laboratory. Experimental results reveal the higher degree
performance
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1156</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1156</id><created>2013-09-04</created><authors><author><keyname>Seal</keyname><forenames>Ayan</forenames></author><author><keyname>Ganguly</keyname><forenames>Suranjan</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak kr.</forenames></author></authors><title>Thermal Human face recognition based on Haar wavelet transform and
  series matching technique</title><categories>cs.CV</categories><comments>12 pages. arXiv admin note: substantial text overlap with
  arXiv:1309.1009</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Thermal infrared (IR) images represent the heat patterns emitted from hot
object and they do not consider the energies reflected from an object. Objects
living or non-living emit different amounts of IR energy according to their
body temperature and characteristics. Humans are homoeothermic and hence
capable of maintaining constant temperature under different surrounding
temperature. Face recognition from thermal (IR) images should focus on changes
of temperature on facial blood vessels. These temperature changes can be
regarded as texture features of images and wavelet transform is a very good
tool to analyze multi-scale and multi-directional texture. Wavelet transform is
also used for image dimensionality reduction, by removing redundancies and
preserving original features of the image. The sizes of the facial images are
normally large. So, the wavelet transform is used before image similarity is
measured. Therefore this paper describes an efficient approach of human face
recognition based on wavelet transform from thermal IR images. The system
consists of three steps. At the very first step, human thermal IR face image is
preprocessed and the face region is only cropped from the entire image.
Secondly, Haar wavelet is used to extract low frequency band from the cropped
face region. Lastly, the image classification between the training images and
the test images is done, which is based on low-frequency components. The
proposed approach is tested on a number of human thermal infrared face images
created at our own laboratory and Terravic Facial IR Database. Experimental
results indicated that the thermal infra red face images can be recognized by
the proposed system effectively. The maximum success of 95% recognition has
been achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1184</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1184</id><created>2013-09-02</created><authors><author><keyname>Mongia</keyname><forenames>Puneet Kumar</forenames></author><author><keyname>Singh</keyname><forenames>B. J.</forenames></author></authors><title>Planning and Optimization of Wireless LANs through Field Measurements</title><categories>cs.NI</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the field measurements of signal strength taken at the
frequency of 2432 MHz in indoor &amp; outdoor environments are presented and
analyzed. The received signal levels from the base station were monitored
manually. Total coverage area considered for the measurement campaign consisted
of a mixture of different propagation environments. Based on the experimental
data obtained, path loss exponent and standard deviation of signal strength
variability are derived. It is shown that the values of these parameters vary
from region to region in the coverage area. The analysis is purely statistical
&amp; is compared with the existing propagation model to determine the path loss
exponent &amp; deviation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1193</identifier>
 <datestamp>2013-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1193</id><created>2013-09-04</created><updated>2013-10-09</updated><authors><author><keyname>Chunikhina</keyname><forenames>E.</forenames></author><author><keyname>Raich</keyname><forenames>R.</forenames></author><author><keyname>Nguyen</keyname><forenames>T.</forenames></author></authors><title>Confidence-constrained joint sparsity recovery under the Poisson noise
  model</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work is focused on the joint sparsity recovery problem where the common
sparsity pattern is corrupted by Poisson noise. We formulate the
confidence-constrained optimization problem in both least squares (LS) and
maximum likelihood (ML) frameworks and study the conditions for perfect
reconstruction of the original row sparsity and row sparsity pattern. However,
the confidence-constrained optimization problem is non-convex. Using convex
relaxation, an alternative convex reformulation of the problem is proposed. We
evaluate the performance of the proposed approach using simulation results on
synthetic data and show the effectiveness of proposed row sparsity and row
sparsity pattern recovery framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1199</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1199</id><created>2013-09-04</created><authors><author><keyname>Heien</keyname><forenames>Eric M.</forenames></author><author><keyname>Miller</keyname><forenames>Todd L.</forenames></author><author><keyname>Gietzel</keyname><forenames>Becky</forenames></author><author><keyname>Kellogg</keyname><forenames>Louise H.</forenames></author></authors><title>Experiences with Automated Build and Test for Geodynamics Simulation
  Codes</title><categories>cs.CE cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Computational Infrastructure for Geodynamics (CIG) is an NSF funded
project that develops, supports, and disseminates community-accessible software
for the geodynamics research community. CIG software supports a variety of
computational geodynamic research from mantle and core dynamics, to crustal and
earthquake dynamics, to magma migration and seismology. To support this type of
project a backend computational infrastructure is necessary.
  Part of this backend infrastructure is an automated build and testing system
to ensure codes and changes to them are compatible with multiple platforms and
that the changes do not significantly affect the scientific results. In this
paper we describe the build and test infrastructure for CIG based on the BaTLab
system, how it is organized, and how it assists in operations. We demonstrate
the use of this type of testing for a suite of geophysics codes, show why codes
may compile on one platform but not on another, and demonstrate how minor
changes may alter the computed results in unexpected ways that can influence
the scientific interpretation. Finally, we examine result comparison between
platforms and show how the compiler or operating system may affect results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1200</identifier>
 <datestamp>2014-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1200</id><created>2013-09-04</created><updated>2014-04-24</updated><authors><author><keyname>Ashour</keyname><forenames>Mahmoud</forenames></author><author><keyname>El-Sherif</keyname><forenames>Amr A.</forenames></author><author><keyname>ElBatt</keyname><forenames>Tamer</forenames></author><author><keyname>Mohamed</keyname><forenames>Amr</forenames></author></authors><title>Cooperative Access in Cognitive Radio Networks: Stable Throughput and
  Delay Tradeoffs</title><categories>cs.NI</categories><comments>accepted for publication in IEEE 12th Intl. Symposium on Modeling and
  Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt), 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study and analyze fundamental throughput-delay tradeoffs in
cooperative multiple access for cognitive radio systems. We focus on the class
of randomized cooperative policies, whereby the secondary user (SU) serves
either the queue of its own data or the queue of the primary user (PU) relayed
data with certain service probabilities. The proposed policy opens room for
trading the PU delay for enhanced SU delay. Towards this objective, stability
conditions for the queues involved in the system are derived. Furthermore, a
moment generating function approach is employed to derive closed-form
expressions for the average delay encountered by the packets of both users.
Results reveal that cooperation expands the stable throughput region of the
system and significantly reduces the delay at both users. Moreover, we quantify
the gain obtained in terms of the SU delay under the proposed policy, over
conventional relaying that gives strict priority to the relay queue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1204</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1204</id><created>2013-09-04</created><updated>2013-09-06</updated><authors><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author><author><keyname>Brown</keyname><forenames>Jed</forenames></author><author><keyname>Rupp</keyname><forenames>Karl</forenames></author><author><keyname>Smith</keyname><forenames>Barry F.</forenames></author></authors><title>Achieving High Performance with Unified Residual Evaluation</title><categories>cs.MS cs.CE</categories><comments>4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine residual evaluation, perhaps the most basic operation in numerical
simulation. By raising the level of abstraction in this operation, we can
eliminate specialized code, enable optimization, and greatly increase the
extensibility of existing code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1208</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1208</id><created>2013-09-04</created><authors><author><keyname>Sharkh</keyname><forenames>Mohamed Abu</forenames></author><author><keyname>Jammal</keyname><forenames>Manar</forenames></author><author><keyname>Shami</keyname><forenames>Abdallah</forenames></author><author><keyname>Ouda</keyname><forenames>Abdelkader</forenames></author></authors><title>Resource Allocation in a Network-Based Cloud Computing Environment:
  Design Challenges</title><categories>cs.NI cs.DC</categories><comments>To appear in IEEE Communications Magazine, November 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is an increasingly popular computing paradigm, now proving a
necessity for utility computing services. Each provider offers a unique service
portfolio with a range of resource configurations. Resource provisioning for
cloud services in a comprehensive way is crucial to any resource allocation
model. Any model should consider both computational resources and network
resources to accurately represent and serve practical needs. Another aspect
that should be considered while provisioning resources is energy consumption.
This aspect is getting more attention from industry and governments parties.
Calls of support for the green clouds are gaining momentum. With that in mind,
resource allocation algorithms aim to accomplish the task of scheduling virtual
machines on data center servers and then scheduling connection requests on the
network paths available while complying with the problem constraints. Several
external and internal factors that affect the performance of resource
allocation models are introduced in this paper. These factors are discussed in
detail and research gaps are pointed out. Design challenges are discussed with
the aim of providing a reference to be used when designing a comprehensive
energy aware resource allocation model for cloud computing data centers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1218</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1218</id><created>2013-09-04</created><authors><author><keyname>Li</keyname><forenames>Nian</forenames></author><author><keyname>Li</keyname><forenames>Chunlei</forenames></author><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author><author><keyname>Ding</keyname><forenames>Cunsheng</forenames></author><author><keyname>Tang</keyname><forenames>Xiaohu</forenames></author></authors><title>Optimal Ternary Cyclic Codes with Minimum Distance Four and Five</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyclic codes are an important subclass of linear codes and have wide
applications in data storage systems, communication systems and consumer
electronics. In this paper, two families of optimal ternary cyclic codes are
presented. The first family of cyclic codes has parameters $[3^m-1, 3^m-1-2m,
4]$ and contains a class of conjectured cyclic codes and several new classes of
optimal cyclic codes. The second family of cyclic codes has parameters $[3^m-1,
3^m-2-2m, 5]$ and contains a number of classes of cyclic codes that are
obtained from perfect nonlinear functions over $\fthreem$, where $m&gt;1$ and is a
positive integer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1220</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1220</id><created>2013-09-04</created><authors><author><keyname>Manjrekar</keyname><forenames>Mayank</forenames></author><author><keyname>Ramaswamy</keyname><forenames>Vinod</forenames></author><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author></authors><title>A Mean Field Game Approach to Scheduling in Cellular Systems</title><categories>cs.GT cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study auction-theoretic scheduling in cellular networks using the idea of
mean field equilibrium (MFE). Here, agents model their opponents through a
distribution over their action spaces and play the best response. The system is
at an MFE if this action is itself a sample drawn from the assumed
distribution. In our setting, the agents are smart phone apps that generate
service requests, experience waiting costs, and bid for service from base
stations. We show that if we conduct a second-price auction at each base
station, there exists an MFE that would schedule the app with the longest queue
at each time. The result suggests that auctions can attain the same desirable
results as queue-length-based scheduling. We present results on the asymptotic
convergence of a system with a finite number of agents to the mean field case,
and conclude with simulation results illustrating the simplicity of computation
of the MFE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1226</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1226</id><created>2013-09-04</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Hitchcock</keyname><forenames>Christopher</forenames></author></authors><title>Graded Causation and Defaults</title><categories>cs.AI</categories><comments>To appear, British Journal for the Philosophy of Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work in psychology and experimental philosophy has shown that
judgments of actual causation are often influenced by consideration of
defaults, typicality, and normality. A number of philosophers and computer
scientists have also suggested that an appeal to such factors can help deal
with problems facing existing accounts of actual causation. This paper develops
a flexible formal framework for incorporating defaults, typicality, and
normality into an account of actual causation. The resulting account takes
actual causation to be both graded and comparative. We then show how our
account would handle a number of standard cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1227</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1227</id><created>2013-09-04</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Hitchcock</keyname><forenames>Christopher</forenames></author></authors><title>Compact Representations of Extended Causal Models</title><categories>cs.AI</categories><journal-ref>Cognitive Science 37:6, 2013, pp. 986-1010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Judea Pearl was the first to propose a definition of actual causation using
causal models. A number of authors have suggested that an adequate account of
actual causation must appeal not only to causal structure, but also to
considerations of normality. In earlier work, we provided a definition of
actual causation using extended causal models, which include information about
both causal structure and normality. Extended causal models are potentially
very complex. In this paper, we show how it is possible to achieve a compact
representation of extended causal models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1228</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1228</id><created>2013-09-04</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Weighted regret-based likelihood: a new approach to describing
  uncertainty</title><categories>cs.AI</categories><comments>Appeared in 12th European Conference on Symbolic and Quantitative
  Approaches to Reasoning with Uncertainty (ECSQARU)}, 2013, pp. 266--277</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Halpern and Leung suggested representing uncertainty by a weighted
set of probability measures, and suggested a way of making decisions based on
this representation of uncertainty: maximizing weighted regret. Their paper
does not answer an apparently simpler question: what it means, according to
this representation of uncertainty, for an event E to be more likely than an
event E'. In this paper, a notion of comparative likelihood when uncertainty is
represented by a weighted set of probability measures is defined. It
generalizes the ordering defined by probability (and by lower probability) in a
natural way; a generalization of upper probability can also be defined. A
complete axiomatic characterization of this notion of regret-based likelihood
is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1230</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1230</id><created>2013-09-05</created><authors><author><keyname>Seitz</keyname><forenames>Kerry A.</forenames><suffix>Jr.</suffix><affiliation>Department of Computer Science, University of California, Davis</affiliation></author><author><keyname>Kennedy</keyname><forenames>Alex</forenames><affiliation>Department of Computer Science, University of California, Davis</affiliation></author><author><keyname>Ransom</keyname><forenames>Owen</forenames><affiliation>Department of Civil and Environmental Engineering, University of California, Davis</affiliation></author><author><keyname>Younis</keyname><forenames>Bassam A.</forenames><affiliation>Department of Civil and Environmental Engineering, University of California, Davis</affiliation></author><author><keyname>Owens</keyname><forenames>John D.</forenames><affiliation>Department of Electrical and Computer Engineering, University of California, Davis</affiliation></author></authors><title>A GPU Implementation for Two-Dimensional Shallow Water Modeling</title><categories>cs.DC</categories><comments>9 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a GPU implementation of a two-dimensional shallow
water model. Water simulations are useful for modeling floods, river/reservoir
behavior, and dam break scenarios. Our GPU implementation shows vast
performance improvements over the original Fortran implementation. By taking
advantage of the GPU, researchers and engineers will be able to study water
systems more efficiently and in greater detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1232</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1232</id><created>2013-09-05</created><authors><author><keyname>Fiaz</keyname><forenames>A. S. Syed</forenames></author><author><keyname>Devi</keyname><forenames>N.</forenames></author><author><keyname>Aarthi</keyname><forenames>S.</forenames></author></authors><title>Bug Tracking and Reporting System</title><categories>cs.SE</categories><comments>4 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the world of information. The ever growing field Information
Technology has its many advanced notable features which made it what it was now
today. In this world, the information has to be processed, clearly distributed
and must be efficiently reachable to the end users intended for that. Otherwise
we know it lead to disastrous situations. The other coin of the same phase is
it is absolutely necessary to know any bugs that are hither to faced by the end
users. The project Bug Tracking and Reporting System aims to provide the
solution for that. The Bug Tracker can be made from any two types. The first
one being the system side, the other being the services side. Our project deals
with the second one. The paper is wholly dedicated to tracking the bugs that
are hither by arise. The administrator maintains the master details regarding
to the bugs id, bugs type, bugs description, bugs severity, bugs status, user
details. The administrator too has the authority to update the master details
of severity level, status level, etc, modules of the paper. The administrator
adds the users and assign them responsibility of completing the paper. Finally
on analyzing the paper assigned to the particular user, the administrator can
track the bugs, and it is automatically added to the tables containing the
bugs, by order of severity and status. The administrator can know the
information in tact the various paper s assigned to various users, their bug
tracking status, their description etc in the form of reports from time to
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1248</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1248</id><created>2013-09-05</created><authors><author><keyname>Balko</keyname><forenames>Martin</forenames></author><author><keyname>Klav&#xed;k</keyname><forenames>Pavel</forenames></author><author><keyname>Otachi</keyname><forenames>Yota</forenames></author></authors><title>Bounded Representations of Interval and Proper Interval Graphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Klavik et al. [arXiv:1207.6960] recently introduced a generalization of
recognition called the bounded representation problem which we study for the
classes of interval and proper interval graphs. The input gives a graph G and
in addition for each vertex v two intervals L_v and R_v called bounds. We ask
whether there exists a bounded representation in which each interval I_v has
its left endpoint in L_v and its right endpoint in R_v. We show that the
problem can be solved in linear time for interval graphs and in quadratic time
for proper interval graphs.
  Robert's Theorem states that the classes of proper interval graphs and unit
interval graphs are equal. Surprisingly the bounded representation problem is
polynomially solvable for proper interval graphs and NP-complete for unit
interval graphs [Klav\'{\i}k et al., arxiv:1207.6960]. So unless P = NP, the
proper and unit interval representations behave very differently.
  The bounded representation problem belongs to a wider class of restricted
representation problems. These problems are generalizations of the
well-understood recognition problem, and they ask whether there exists a
representation of G satisfying some additional constraints. The bounded
representation problems generalize many of these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1251</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1251</id><created>2013-09-05</created><authors><author><keyname>Kwon</keyname><forenames>Keehang</forenames></author></authors><title>Pattern Matching via Choice Existential Quantifications in Imperative
  Languages</title><categories>cs.PL</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Selection statements -- if-then-else, switch and try-catch -- are commonly
used in modern imperative programming languages. We propose another selection
statement called a {\it choice existentially quantified statement}. This
statement turns out to be quite useful for pattern matching among several
merits. Examples will be provided for this statement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1254</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1254</id><created>2013-09-05</created><authors><author><keyname>Aschieri</keyname><forenames>Federico</forenames><affiliation>ENS de Lyon, Universit&#xe9; de Lyon</affiliation></author></authors><title>Strong Normalization for HA + EM1 by Non-Deterministic Choice</title><categories>cs.LO</categories><comments>In Proceedings COS 2013, arXiv:1309.0924</comments><proxy>EPTCS</proxy><acm-class>F.4.1</acm-class><journal-ref>EPTCS 127, 2013, pp. 1-14</journal-ref><doi>10.4204/EPTCS.127.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the strong normalization of a new Curry-Howard correspondence for HA
+ EM1, constructive Heyting Arithmetic with the excluded middle on
Sigma01-formulas. The proof-term language of HA + EM1 consists in the lambda
calculus plus an operator ||_a which represents, from the viewpoint of
programming, an exception operator with a delimited scope, and from the
viewpoint of logic, a restricted version of the excluded middle. We give a
strong normalization proof for the system based on a technique of
&quot;non-deterministic immersion&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1255</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1255</id><created>2013-09-05</created><authors><author><keyname>Birolo</keyname><forenames>Giovanni</forenames><affiliation>University of Turin</affiliation></author></authors><title>Interpreting a Classical Geometric Proof with Interactive Realizability</title><categories>cs.LO cs.CG</categories><comments>In Proceedings COS 2013, arXiv:1309.0924</comments><proxy>EPTCS</proxy><acm-class>F.4.1</acm-class><journal-ref>EPTCS 127, 2013, pp. 30-44</journal-ref><doi>10.4204/EPTCS.127.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to extract a monotonic learning algorithm from a classical proof
of a geometric statement by interpreting the proof by means of interactive
realizability, a realizability sematics for classical logic.
  The statement is about the existence of a convex angle including a finite
collections of points in the real plane and it is related to the existence of a
convex hull. We define real numbers as Cauchy sequences of rational numbers,
therefore equality and ordering are not decidable. While the proof looks
superficially constructive, it employs classical reasoning to handle
undecidable comparisons between real numbers, making the underlying algorithm
non-effective.
  The interactive realizability interpretation transforms the non-effective
linear algorithm described by the proof into an effective one that uses
backtracking to learn from its mistakes. The effective algorithm exhibits a
&quot;smart&quot; behavior, performing comparisons only up to the precision required to
prove the final statement. This behavior is not explicitly planned but arises
from the interactive interpretation of comparisons between Cauchy sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1256</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1256</id><created>2013-09-05</created><authors><author><keyname>Eades</keyname><forenames>Harley</forenames><affiliation>University of Iowa</affiliation></author><author><keyname>Stump</keyname><forenames>Aaron</forenames><affiliation>University of Iowa</affiliation></author></authors><title>Hereditary Substitution for the \lambda\Delta-Calculus</title><categories>cs.LO cs.PL</categories><comments>In Proceedings COS 2013, arXiv:1309.0924</comments><proxy>EPTCS</proxy><acm-class>D.3.1, D.3.3, F.3.1, F.3.3, F.4.1</acm-class><journal-ref>EPTCS 127, 2013, pp. 45-65</journal-ref><doi>10.4204/EPTCS.127.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hereditary substitution is a form of type-bounded iterated substitution,
first made explicit by Watkins et al. and Adams in order to show normalization
of proof terms for various constructive logics. This paper is the first to
apply hereditary substitution to show normalization of a type theory
corresponding to a non-constructive logic, namely the lambda-Delta calculus as
formulated by Rehof. We show that there is a non-trivial extension of the
hereditary substitution function of the simply-typed lambda calculus to one for
the lambda-Delta calculus. Then hereditary substitution is used to prove
normalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1257</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1257</id><created>2013-09-05</created><authors><author><keyname>Geron</keyname><forenames>Bram</forenames></author><author><keyname>Geuvers</keyname><forenames>Herman</forenames></author></authors><title>Continuation calculus</title><categories>cs.LO cs.PL</categories><comments>In Proceedings COS 2013, arXiv:1309.0924</comments><proxy>EPTCS</proxy><acm-class>D.3.1; F.1.1; F.3.1; F.3.2; F.3.3; F.4.2</acm-class><journal-ref>EPTCS 127, 2013, pp. 66-85</journal-ref><doi>10.4204/EPTCS.127.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Programs with control are usually modeled using lambda calculus extended with
control operators. Instead of modifying lambda calculus, we consider a
different model of computation. We introduce continuation calculus, or CC, a
deterministic model of computation that is evaluated using only head reduction,
and argue that it is suitable for modeling programs with control. It is
demonstrated how to define programs, specify them, and prove them correct. This
is shown in detail by presenting in CC a list multiplication program that
prematurely returns when it encounters a zero. The correctness proof includes
termination of the program. In continuation calculus we can model both
call-by-name and call-by-value. In addition, call-by-name functions can be
applied to call-by-value results, and conversely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1258</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1258</id><created>2013-09-05</created><authors><author><keyname>Kakutani</keyname><forenames>Yoshihiko</forenames></author><author><keyname>Kimura</keyname><forenames>Daisuke</forenames></author></authors><title>Induction by Coinduction and Control Operators in Call-by-Name</title><categories>cs.LO cs.PL</categories><comments>In Proceedings COS 2013, arXiv:1309.0924</comments><proxy>EPTCS</proxy><acm-class>F.3.3; D.3.3; F.4.1</acm-class><journal-ref>EPTCS 127, 2013, pp. 101-112</journal-ref><doi>10.4204/EPTCS.127.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies emulation of induction by coinduction in a call-by-name
language with control operators. Since it is known that call-by-name
programming languages with control operators cannot have general initial
algebras, interaction of induction and control operators is often restricted to
effect-free functions. We show that some class of such restricted inductive
types can be derived from full coinductive types by the power of control
operators. As a typical example of our results, the type of natural numbers is
represented by the type of streams. The underlying idea is a counterpart of the
fact that some coinductive types can be expressed by inductive types in
call-by-name pure language without side-effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1259</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1259</id><created>2013-09-05</created><authors><author><keyname>Laird</keyname><forenames>James</forenames><affiliation>University of Bath</affiliation></author></authors><title>Combining and Relating Control Effects and their Semantics</title><categories>cs.LO cs.PL</categories><comments>In Proceedings COS 2013, arXiv:1309.0924</comments><proxy>EPTCS</proxy><acm-class>F.3.2, F.3.3</acm-class><journal-ref>EPTCS 127, 2013, pp. 113-129</journal-ref><doi>10.4204/EPTCS.127.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining local exceptions and first class continuations leads to programs
with complex control flow, as well as the possibility of expressing powerful
constructs such as resumable exceptions. We describe and compare games models
for a programming language which includes these features, as well as
higher-order references. They are obtained by contrasting methodologies: by
annotating sequences of moves with &quot;control pointers&quot; indicating where
exceptions are thrown and caught, and by composing the exceptions and
continuations monads.
  The former approach allows an explicit representation of control flow in
games for exceptions, and hence a straightforward proof of definability (full
abstraction) by factorization, as well as offering the possibility of a
semantic approach to control flow analysis of exception-handling. However,
establishing soundness of such a concrete and complex model is a non-trivial
problem. It may be resolved by establishing a correspondence with the monad
semantics, based on erasing explicit exception moves and replacing them with
control pointers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1261</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1261</id><created>2013-09-05</created><authors><author><keyname>Biernacka</keyname><forenames>Ma&#x142;gorzata</forenames></author><author><keyname>Biernacki</keyname><forenames>Dariusz</forenames></author><author><keyname>Lenglet</keyname><forenames>Sergue&#xef;</forenames></author><author><keyname>Materzok</keyname><forenames>Marek</forenames></author></authors><title>Proving termination of evaluation for System F with control operators</title><categories>cs.PL cs.LO</categories><comments>In Proceedings COS 2013, arXiv:1309.0924</comments><proxy>EPTCS</proxy><acm-class>F.3.1, F.3.3</acm-class><journal-ref>EPTCS 127, 2013, pp. 15-29</journal-ref><doi>10.4204/EPTCS.127.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new proofs of termination of evaluation in reduction semantics
(i.e., a small-step operational semantics with explicit representation of
evaluation contexts) for System F with control operators. We introduce a
modified version of Girard's proof method based on reducibility candidates,
where the reducibility predicates are defined on values and on evaluation
contexts as prescribed by the reduction semantics format. We address both
abortive control operators (callcc) and delimited-control operators (shift and
reset) for which we introduce novel polymorphic type systems, and we consider
both the call-by-value and call-by-name evaluation strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1264</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1264</id><created>2013-09-05</created><authors><author><keyname>Morita</keyname><forenames>Kenichi</forenames><affiliation>Hiroshima University</affiliation></author></authors><title>Reversible Logic Elements with Memory and Their Universality</title><categories>cs.FL</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><acm-class>F.1.1; B.6.1</acm-class><journal-ref>EPTCS 128, 2013, pp. 3-14</journal-ref><doi>10.4204/EPTCS.128.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible computing is a paradigm of computation that reflects physical
reversibility, one of the fundamental microscopic laws of Nature. In this
survey, we discuss topics on reversible logic elements with memory (RLEM),
which can be used to build reversible computing systems, and their
universality. An RLEM is called universal, if any reversible sequential machine
(RSM) can be realized as a circuit composed only of it. Since a finite-state
control and a tape cell of a reversible Turing machine (RTM) are formalized as
RSMs, any RTM can be constructed from a universal RLEM. Here, we investigate
2-state RLEMs, and show that infinitely many kinds of non-degenerate RLEMs are
all universal besides only four exceptions. Non-universality of these
exceptional RLEMs is also argued.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1265</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1265</id><created>2013-09-05</created><authors><author><keyname>Woods</keyname><forenames>Damien</forenames><affiliation>California Institute of Technology</affiliation></author></authors><title>Intrinsic universality and the computational power of self-assembly</title><categories>cs.CG cs.CC cs.ET</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><acm-class>F.1.1; I.3.5</acm-class><journal-ref>EPTCS 128, 2013, pp. 16-22</journal-ref><doi>10.4204/EPTCS.128.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short survey of recent work in tile self-assembly discusses the use of
simulation to classify and separate the computational and expressive power of
self-assembly models. The journey begins with the result that there is a single
universal tile set that, with proper initialization and scaling, simulates any
tile assembly system. This universal tile set exhibits something stronger than
Turing universality: it captures the geometry and dynamics of any simulated
system. From there we find that there is no such tile set in the
noncooperative, or temperature 1, model, proving it weaker than the full tile
assembly model. In the two-handed or hierarchal model, where large assemblies
can bind together on one step, we encounter an infinite set, of infinite
hierarchies, each with strictly increasing simulation power. Towards the end of
our trip, we find one tile to rule them all: a single rotatable flipable
polygonal tile that can simulate any tile assembly system. It seems this could
be the beginning of a much longer journey, so directions for future work are
suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1266</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1266</id><created>2013-09-05</created><authors><author><keyname>Aubrun</keyname><forenames>Nathalie</forenames><affiliation>LIP, ENS de Lyon, CNRS, INRIA, UCBL, Universit&#xe9; de Lyon</affiliation></author><author><keyname>Kari</keyname><forenames>Jarkko</forenames><affiliation>Department of Mathematics and Statistics, University of Turku</affiliation></author></authors><title>Tiling Problems on Baumslag-Solitar groups</title><categories>cs.DM math.CO</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><acm-class>F.1.1, G.2.m</acm-class><journal-ref>EPTCS 128, 2013, pp. 35-46</journal-ref><doi>10.4204/EPTCS.128.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit a weakly aperiodic tile set for Baumslag-Solitar groups, and prove
that the domino problem is undecidable on these groups. A consequence of our
construction is the existence of an arecursive tile set on Baumslag-Solitar
groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1267</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1267</id><created>2013-09-05</created><authors><author><keyname>Freund</keyname><forenames>Rudolf</forenames><affiliation>TU Wien</affiliation></author><author><keyname>P&#x103;un</keyname><forenames>Gheorghe</forenames></author></authors><title>How to Obtain Computational Completeness in P Systems with One Catalyst</title><categories>cs.FL</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 128, 2013, pp. 47-61</journal-ref><doi>10.4204/EPTCS.128.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whether P systems with only one catalyst can already be computationally
complete, is still an open problem. Here we establish computational
completeness by using specific variants of additional control mechanisms. At
each step using only multiset rewriting rules from one set of a finite number
of sets of multiset rewriting rules allows for obtaining computational
completeness with one catalyst and only one membrane. If the targets are used
for choosing the multiset of rules to be applied, for getting computational
completeness with only one catalyst more than one membrane is needed. If the
available sets of rules change periodically with time, computational
completeness can be obtained with one catalyst in one membrane. Moreover, we
also improve existing computational completeness results for P systems with
mobile catalysts and for P systems with membrane creation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1268</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1268</id><created>2013-09-05</created><authors><author><keyname>Freund</keyname><forenames>Rudolf</forenames><affiliation>TU Wien</affiliation></author><author><keyname>Ivanov</keyname><forenames>Sergiu</forenames><affiliation>TU Wien</affiliation></author><author><keyname>Oswald</keyname><forenames>Marion</forenames><affiliation>TU Wien</affiliation></author><author><keyname>Subramanian</keyname><forenames>K. G.</forenames></author></authors><title>One-dimensional Array Grammars and P Systems with Array Insertion and
  Deletion Rules</title><categories>cs.FL</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 128, 2013, pp. 62-75</journal-ref><doi>10.4204/EPTCS.128.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the (one-dimensional) array counterpart of contextual as well as
insertion and deletion string grammars and consider the operations of array
insertion and deletion in array grammars. First we show that the emptiness
problem for P systems with (one-dimensional) insertion rules is undecidable.
Then we show computational completeness of P systems using (one-dimensional)
array insertion and deletion rules even of norm one only. The main result of
the paper exhibits computational completeness of one-dimensional array grammars
using array insertion and deletion rules of norm at most two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1269</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1269</id><created>2013-09-05</created><authors><author><keyname>Gasperin</keyname><forenames>Anthony</forenames><affiliation>University of Geneva</affiliation></author></authors><title>Topology and Non-Deterministic Polynomial Time Computation : Avoidance
  of The Misbehaviour of Hub-Free Diagrams and Consequences</title><categories>cs.CC</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 128, 2013, pp. 76-84</journal-ref><doi>10.4204/EPTCS.128.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To study groups with small Dehn's function, Olshanskii and Sapir developed a
new invariant of bipartite chords diagrams and applied it to hub-free
realization of S-machines. In this paper we consider this new invariant
together with groups constructed from S-machines containing the hub relation.
The idea is to study the links between the topology of the asymptotic cones and
polynomial time computations. Indeed it is known that the topology of such
metric space depends on diagrams without hubs that do not correspond to the
computations of the considered S-machine. This work gives sufficient conditions
that avoid this misbehaviour, but as we shall see the method has a significant
drawback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1270</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1270</id><created>2013-09-05</created><authors><author><keyname>Herrmann</keyname><forenames>Christian</forenames></author><author><keyname>Sokoli</keyname><forenames>Johanna</forenames></author><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Satisfiability of cross product terms is complete for real
  nondeterministic polytime Blum-Shub-Smale machines</title><categories>cs.CC cs.LO</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><acm-class>F.1.3; F.2.2</acm-class><journal-ref>EPTCS 128, 2013, pp. 85-92</journal-ref><doi>10.4204/EPTCS.128.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nondeterministic polynomial-time Blum-Shub-Smale Machines over the reals give
rise to a discrete complexity class between NP and PSPACE. Several problems,
mostly from real algebraic geometry / polynomial systems, have been shown
complete (under many-one reduction by polynomial-time Turing machines) for this
class. We exhibit a new one based on questions about expressions built from
cross products only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1271</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1271</id><created>2013-09-05</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames><affiliation>Universit&#xe9; de Lorraine</affiliation></author><author><keyname>Subramamian</keyname><forenames>K. G.</forenames><affiliation>Universiti Sains Malaysia</affiliation></author></authors><title>Hyperbolic tilings and formal language theory</title><categories>cs.FL</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><acm-class>F.2.2., F.4.1, I.3.5</acm-class><journal-ref>EPTCS 128, 2013, pp. 126-136</journal-ref><doi>10.4204/EPTCS.128.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we try to give the appropriate class of languages to which
belong various objects associated with tessellations in the hyperbolic plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1272</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1272</id><created>2013-09-05</created><authors><author><keyname>Martiel</keyname><forenames>Simon</forenames><affiliation>Universit&#xe9; Nice Sophia Antipolis</affiliation></author><author><keyname>Martin</keyname><forenames>Bruno</forenames><affiliation>Universit&#xe9; Nice Sophia Antipolis</affiliation></author></authors><title>Intrinsic Universality of Causal Graph Dynamics</title><categories>cs.DM cs.DC</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><acm-class>B.6.1;F.1.1;F.4.2</acm-class><journal-ref>EPTCS 128, 2013, pp. 137-149</journal-ref><doi>10.4204/EPTCS.128.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Causal graph dynamics are transformations over graphs that capture two
important symmetries of physics, namely causality and homogeneity. They can be
equivalently defined as continuous and translation invariant transformations or
functions induced by a local rule applied simultaneously on every vertex of the
graph. Intrinsic universality is the ability of an instance of a model to
simulate every other instance of the model while preserving the structure of
the computation at every step of the simulation. In this work we present the
construction of a family of intrinsically universal instances of causal graphs
dynamics, each instance being able to simulate a subset of instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1273</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1273</id><created>2013-09-05</created><authors><author><keyname>Hendricks</keyname><forenames>Jacob</forenames><affiliation>University of Arkansas</affiliation></author><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames><affiliation>University of Arkansas</affiliation></author></authors><title>On the Equivalence of Cellular Automata and the Tile Assembly Model</title><categories>cs.ET cs.FL cs.LO nlin.CG</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 128, 2013, pp. 167-189</journal-ref><doi>10.4204/EPTCS.128.21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore relationships between two models of systems which
are governed by only the local interactions of large collections of simple
components: cellular automata (CA) and the abstract Tile Assembly Model (aTAM).
While sharing several similarities, the models have fundamental differences,
most notably the dynamic nature of CA (in which every cell location is allowed
to change state an infinite number of times) versus the static nature of the
aTAM (in which tiles are static components that can never change or be removed
once they attach to a growing assembly). We work with 2-dimensional systems in
both models, and for our results we first define what it means for CA systems
to simulate aTAM systems, and then for aTAM systems to simulate CA systems. We
use notions of simulate which are similar to those used in the study of
intrinsic universality since they are in some sense strict, but also
intuitively natural notions of simulation. We then demonstrate a particular
nondeterministic CA which can be configured so that it can simulate any
arbitrary aTAM system, and finally an aTAM tile set which can be configured so
that it can be used to simulate any arbitrary nondeterministic CA system which
begins with a finite initial configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1274</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1274</id><created>2013-09-05</created><authors><author><keyname>Zaitsev</keyname><forenames>Dmitry A.</forenames><affiliation>International Humanitarian University, Professor</affiliation></author></authors><title>A Small Universal Petri Net</title><categories>cs.FL cs.CC cs.DC cs.NE</categories><comments>In Proceedings MCU 2013, arXiv:1309.1043. the smallest known
  universal Petri net</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 128, 2013, pp. 190-202</journal-ref><doi>10.4204/EPTCS.128.22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A universal deterministic inhibitor Petri net with 14 places, 29 transitions
and 138 arcs was constructed via simulation of Neary and Woods' weakly
universal Turing machine with 2 states and 4 symbols; the total time complexity
is exponential in the running time of their weak machine. To simulate the blank
words of the weakly universal Turing machine, a couple of dedicated transitions
insert their codes when reaching edges of the working zone. To complete a chain
of a given Petri net encoding to be executed by the universal Petri net, a
translation of a bi-tag system into a Turing machine was constructed. The
constructed Petri net is universal in the standard sense; a weaker form of
universality for Petri nets was not introduced in this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1279</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1279</id><created>2013-09-05</created><authors><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>The $k$-in-a-tree problem for graphs of girth at least~$k$</title><categories>cs.DM math.CO</categories><msc-class>05C75</msc-class><journal-ref>Discrete Applied Mathematics, 158:1644-1649, 2010</journal-ref><doi>10.1016/j.dam.2010.06.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For all integers $k\geq 3$, we give an $O(n^4)$ time algorithm for the
problem whose instance is a graph $G$ of girth at least $k$ together with $k$
vertices and whose question is &quot;Does $G$ contains an induced subgraph
containing the $k$ vertices and isomorphic to a tree?&quot;. This directly follows
for $k=3$ from the three-in-a-tree algorithm of Chudnovsky and Seymour and for
$k=4$ from a result of Derhy, Picouleau and Trotignon. Here we solve the
problem for $k\geq 5$. Our algorithm relies on a structural description of
graphs of girth at least $k$ that do not contain an induced tree covering $k$
given vertices ($k\geq 5$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1286</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1286</id><created>2013-09-05</created><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Bambozzi</keyname><forenames>Federico</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author></authors><title>On a Family of Circulant Matrices for Quasi-Cyclic Low-Density Generator
  Matrix Codes</title><categories>cs.IT math.IT</categories><comments>27 pages, 7 figures</comments><journal-ref>IEEE Transactions on Information Theory, ISSN 0018-9448, Vol. 57,
  No. 9, pp. 6052-6067, Sep. 2011</journal-ref><doi>10.1109/TIT.2011.2161953</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new class of sparse and easily invertible circulant matrices
that can have a sparse inverse though not being permutation matrices. Their
study is useful in the design of quasi-cyclic low-density generator matrix
codes, that are able to join the inner structure of quasi-cyclic codes with
sparse generator matrices, so limiting the number of elementary operations
needed for encoding. Circulant matrices of the proposed class permit to hit
both targets without resorting to identity or permutation matrices that may
penalize the code minimum distance and often cause significant error floors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1290</identifier>
 <datestamp>2014-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1290</id><created>2013-09-05</created><updated>2014-05-16</updated><authors><author><keyname>Diekert</keyname><forenames>Volker</forenames></author><author><keyname>Kausch</keyname><forenames>Jonathan</forenames></author></authors><title>Logspace computations in graph products</title><categories>cs.DM math.CO</categories><acm-class>F.2.2; I.1.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider three important and well-studied algorithmic problems in group
theory: the word, geodesic, and conjugacy problem. We show transfer results
from individual groups to graph products. We concentrate on logspace complexity
because the challenge is actually in small complexity classes, only. The most
difficult transfer result is for the conjugacy problem. We have a general
result for graph products, but even in the special case of a graph group the
result is new. Graph groups are closely linked to the theory of Mazurkiewicz
traces which form an algebraic model for concurrent processes. Our proofs are
combinatorial and based on well-known concepts in trace theory. We also use
rewriting techniques over traces. For the group-theoretical part we apply
Bass-Serre theory. But as we need explicit formulae and as we design concrete
algorithms all our group-theoretical calculations are completely explicit and
accessible to non-specialists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1300</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1300</id><created>2013-09-05</created><authors><author><keyname>Nagananda</keyname><forenames>K. G.</forenames></author></authors><title>Electrical Structure-Based PMU Placement in Electric Power Systems</title><categories>cs.SY</categories><comments>8 pages, 10 figures, submitted to IEEE Transactions on Smart Grid,
  August 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work on complex networks compared the topological and electrical
structures of the power grid, taking into account the underlying physical laws
that govern the electrical connectivity between various components in the
network. A distance metric, namely, resistance distance was introduced to
provide a more comprehensive description of interconnections in power systems
compared with the topological structure, which is based only on geographic
connections between network components. Motivated by these studies, in this
paper we revisit the phasor measurement unit (PMU) placement problem by
deriving the connectivity matrix of the network using resistance distances
between buses in the grid, and use it in the integer program formulations for
several standard IEEE bus systems. The main result of this paper is rather
discouraging: more number of PMUs are required, compared with those obtained
using the topological structure, to meet the desired objective of complete
network observability without zero injection measurements. However, in light of
recent advances in the electrical structure of the grid, our study provides a
more realistic perspective of PMU placement in power systems. By further
exploring the connectivity matrix derived using the electrical structure, we
devise a procedure to solve the placement problem without resorting to linear
programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1307</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1307</id><created>2013-09-05</created><authors><author><keyname>Beling</keyname><forenames>Piotr</forenames></author></authors><title>C++11 -- idea r-warto\'sci i przenoszenia</title><categories>cs.PL</categories><comments>7 pages, in Polish</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a review of some new futures introduced to C++ language
by ISO/IEC 14882:2011 standard (known as C++11). It describes the ideas of
r-values and move constructors.
  ----
  Niniejszy artyku{\l} jest jednym z serii artyku{\l}\'ow w kt\'orych zawarto
przegl{\ka}d nowych element\'ow j{\ke}zyka C++ wprowadzonych przez standard
ISO/IEC 14882:2011, znany pod nazw{\ka} C++11. W artykule przedstawiono nowe
mo\.zliwo\'sci zwi{\ka}zane z przekazywaniem parametr\'ow i pisaniem
konstruktor\'ow. Zawarto w nim dok{\l}adne om\'owienie idei r-warto\'sci i
przenoszenia obiekt\'ow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1319</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1319</id><created>2013-09-05</created><authors><author><keyname>F&#xfa;ster-Sabater</keyname><forenames>Amparo</forenames></author></authors><title>Characterization of the Least Periods of the Generalized Self-Shrinking
  Sequences</title><categories>cs.IT math.IT</categories><comments>Submitted at IEEE Transactions on Information Theory</comments><msc-class>94A60, 11T71, 14G50, 11T99</msc-class><acm-class>E.3; B.6.1; F.1.1; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2004, Y. Hu and G. Xiao introduced the generalized self-shrinking
generator, a simple bit-stream generator considered as a specialization of the
shrinking generator as well as a generalization of the self-shrinking
generator. The authors conjectured that the family of generalized
self-shrinking sequences took their least periods in the set {1, 2, 2**(L-1)},
where L is the length of the Linear Feedback Shift Register included in the
generator. In this correspondence, it is proved that the least periods of such
generated sequences take values exclusively in such a set. As a straight
consequence of this result, other characteristics of such sequences (linear
complexity or pseudorandomness) and their potential use in cryptography are
also analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1323</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1323</id><created>2013-09-05</created><authors><author><keyname>Yu</keyname><forenames>Mingchao</forenames></author><author><keyname>Aboutorab</keyname><forenames>Neda</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author></authors><title>From Instantly Decodable to Random Linear Network Coding</title><categories>cs.IT math.IT</categories><comments>30 pages with double space, 14 color figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our primary goal in this paper is to traverse the performance gap between two
linear network coding schemes: random linear network coding (RLNC) and
instantly decodable network coding (IDNC) in terms of throughput and decoding
delay. We first redefine the concept of packet generation and use it to
partition a block of partially-received data packets in a novel way, based on
the coding sets in an IDNC solution. By varying the generation size, we obtain
a general coding framework which consists of a series of coding schemes, with
RLNC and IDNC identified as two extreme cases. We then prove that the
throughput and decoding delay performance of all coding schemes in this coding
framework are bounded between the performance of RLNC and IDNC and hence
throughput-delay tradeoff becomes possible. We also propose implementations of
this coding framework to further improve its throughput and decoding delay
performance, to manage feedback frequency and coding complexity, or to achieve
in-block performance adaption. Extensive simulations are then provided to
verify the performance of the proposed coding schemes and their
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1328</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1328</id><created>2013-09-05</created><updated>2014-04-08</updated><authors><author><keyname>Kramer</keyname><forenames>Simon</forenames></author></authors><title>Logic of Intuitionistic Interactive Proofs (Formal Theory of Perfect
  Knowledge Transfer)</title><categories>math.LO cs.CR cs.LO</categories><comments>continuation of arXiv:1201.3667; extended start of Section 1 and 2.1;
  extended paragraph after Fact 1; dropped the N-rule as primitive and proved
  it derivable; other, non-intuitionistic family members: arXiv:1208.1842,
  arXiv:1208.5913</comments><journal-ref>ACM Transactions on Computational Logic, Volume 16, Number 4,
  September 2015, Pages 35:1--35:32</journal-ref><doi>10.1145/2811263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We produce a decidable super-intuitionistic normal modal logic of
internalised intuitionistic (and thus disjunctive and monotonic) interactive
proofs (LIiP) from an existing classical counterpart of classical monotonic
non-disjunctive interactive proofs (LiP). Intuitionistic interactive proofs
effect a durable epistemic impact in the possibly adversarial communication
medium CM (which is imagined as a distinguished agent), and only in that, that
consists in the permanent induction of the perfect and thus disjunctive
knowledge of their proof goal by means of CM's knowledge of the proof: If CM
knew my proof then CM would persistently and also disjunctively know that my
proof goal is true. So intuitionistic interactive proofs effect a lasting
transfer of disjunctive propositional knowledge (disjunctively knowable facts)
in the communication medium of multi-agent distributed systems via the
transmission of certain individual knowledge (knowable intuitionistic proofs).
Our (necessarily) CM-centred notion of proof is also a disjunctive explicit
refinement of KD45-belief, and yields also such a refinement of standard
S5-knowledge. Monotonicity but not communality is a commonality of LiP, LIiP,
and their internalised notions of proof. As a side-effect, we offer a short
internalised proof of the Disjunction Property of Intuitionistic Logic
(originally proved by Goedel).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1333</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1333</id><created>2013-09-05</created><authors><author><keyname>Pappas</keyname><forenames>Nikolaos</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author></authors><title>The Stability Region of the Two-User Interference Channel</title><categories>cs.IT math.IT</categories><comments>Accepted for publication at IEEE Information Theory Workshop 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stable throughput region of the two-user interference channel is
investigated here. First, the stability region for the general case is
characterized. Second, we study the cases where the receivers treat
interference as noise or perform successive interference cancelation. Finally,
we provide conditions for the convexity/concavity of the stability region and
for which a certain interference management strategy leads to broader stability
region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1334</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1334</id><created>2013-09-05</created><updated>2013-09-10</updated><authors><author><keyname>Green</keyname><forenames>Todd J.</forenames></author><author><keyname>Schmitt</keyname><forenames>Alan</forenames></author></authors><title>Proceedings of the 14th International Symposium on Database Programming
  Languages (DBPL 2013), August 30, 2013, Riva del Garda, Trento, Italy</title><categories>cs.DB cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the 14th Symposium on Database
Programming Languages (DBPL 2013) held on August 30th, 2013, in Riva del Garda,
co-located with the 39th International Conference on Very Large Databases (VLDB
2013). They cover a wide range of topics including the application of
programming language techniques to further the expressiveness of database
languages, schema management, and the practical use of XPath. To complement
this technical program, DBPL 2013 featured three invited talks by Serge
Abiteboul (Inria), J\'er\^ome Sim\'eon (IBM), and Soren Lassen (Facebook).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1338</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1338</id><created>2013-09-05</created><authors><author><keyname>Pappas</keyname><forenames>Nikolaos</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author><author><keyname>Traganitis</keyname><forenames>Apostolos</forenames></author></authors><title>On the Stability Region of a Relay-Assisted Multiple Access Scheme</title><categories>cs.IT math.IT</categories><comments>Accepted for publication at IEEE Information Theory Workshop 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the impact of a relay node in a two-user network. We
assume a random access collision channel model with erasures. In particular we
obtain an inner and an outer bound for the stability region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1347</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1347</id><created>2013-09-05</created><authors><author><keyname>Arulselvan</keyname><forenames>Ashwin</forenames></author><author><keyname>Karch</keyname><forenames>Daniel</forenames></author></authors><title>A proof for Padberg's conjecture on rank of matching polytope</title><categories>math.CO cs.DS</categories><msc-class>90C10, 90C57</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Padberg introduced a geometric notion of ranks for (mixed) integer rational
polyhedrons and conjectured that the geometric rank of the matching polytope is
one. In this work, we prove that this conjecture is true.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1349</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1349</id><created>2013-09-05</created><updated>2013-12-16</updated><authors><author><keyname>Ravazzi</keyname><forenames>Chiara</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Tempo</keyname><forenames>Roberto</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author></authors><title>Ergodic Randomized Algorithms and Dynamics over Networks</title><categories>cs.SY</categories><comments>11 pages; submitted for publication. revised version with fixed
  technical flaw and updated references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms and dynamics over networks often involve randomization, and
randomization may result in oscillating dynamics which fail to converge in a
deterministic sense. In this paper, we observe this undesired feature in three
applications, in which the dynamics is the randomized asynchronous counterpart
of a well-behaved synchronous one. These three applications are network
localization, PageRank computation, and opinion dynamics. Motivated by their
formal similarity, we show the following general fact, under the assumptions of
independence across time and linearities of the updates: if the expected
dynamics is stable and converges to the same limit of the original synchronous
dynamics, then the oscillations are ergodic and the desired limit can be
locally recovered via time-averaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1365</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1365</id><created>2013-09-05</created><authors><author><keyname>Kavitha</keyname><forenames>Veeraruna</forenames></author><author><keyname>Combes</keyname><forenames>Richard</forenames></author></authors><title>Mixed Polling with Rerouting and Applications</title><categories>cs.PF</categories><comments>to appear in Performance Evaluation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Queueing systems with a single server in which customers wait to be served at
a finite number of distinct locations (buffers/queues) are called discrete
polling systems. Polling systems in which arrivals of users occur anywhere in a
continuum are called continuous polling systems. Often one encounters a
combination of the two systems: the users can either arrive in a continuum or
wait in a finite set (i.e. wait at a finite number of queues). We call these
systems mixed polling systems. Also, in some applications, customers are
rerouted to a new location (for another service) after their service is
completed. In this work, we study mixed polling systems with rerouting. We
obtain their steady state performance by discretization using the known pseudo
conservation laws of discrete polling systems. Their stationary expected
workload is obtained as a limit of the stationary expected workload of a
discrete system. The main tools for our analysis are: a) the fixed point
analysis of infinite dimensional operators and; b) the convergence of Riemann
sums to an integral.
  We analyze two applications using our results on mixed polling systems and
discuss the optimal system design. We consider a local area network, in which a
moving ferry facilitates communication (data transfer) using a wireless link.
We also consider a distributed waste collection system and derive the optimal
collection point. In both examples, the service requests can arrive anywhere in
a subset of the two dimensional plane. Namely, some users arrive in a
continuous set while others wait for their service in a finite set. The only
polling systems that can model these applications are mixed systems with
rerouting as introduced in this manuscript.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1369</identifier>
 <datestamp>2014-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1369</id><created>2013-09-05</created><updated>2014-02-17</updated><authors><author><keyname>Aravkin</keyname><forenames>Aleksandr Y.</forenames></author><author><keyname>Choromanska</keyname><forenames>Anna</forenames></author><author><keyname>Jebara</keyname><forenames>Tony</forenames></author><author><keyname>Kanevsky</keyname><forenames>Dimitri</forenames></author></authors><title>Semistochastic Quadratic Bound Methods</title><categories>stat.ML cs.LG math.NA stat.CO</categories><comments>11 pages, 1 figure</comments><msc-class>90C55, 90C15, 62H30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partition functions arise in a variety of settings, including conditional
random fields, logistic regression, and latent gaussian models. In this paper,
we consider semistochastic quadratic bound (SQB) methods for maximum likelihood
inference based on partition function optimization. Batch methods based on the
quadratic bound were recently proposed for this class of problems, and
performed favorably in comparison to state-of-the-art techniques.
Semistochastic methods fall in between batch algorithms, which use all the
data, and stochastic gradient type methods, which use small random selections
at each iteration. We build semistochastic quadratic bound-based methods, and
prove both global convergence (to a stationary point) under very weak
assumptions, and linear convergence rate under stronger assumptions on the
objective. To make the proposed methods faster and more stable, we consider
inexact subproblem minimization and batch-size selection schemes. The efficacy
of SQB methods is demonstrated via comparison with several state-of-the-art
techniques on commonly used datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1380</identifier>
 <datestamp>2015-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1380</id><created>2013-09-05</created><updated>2015-04-30</updated><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Neeman</keyname><forenames>Joe</forenames></author><author><keyname>Sly</keyname><forenames>Allan</forenames></author></authors><title>Belief Propagation, Robust Reconstruction, and Optimal Recovery of Block
  Models</title><categories>math.PR cs.SI</categories><comments>49 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reconstructing sparse symmetric block models with
two blocks and connection probabilities $a/n$ and $b/n$ for inter- and
intra-block edge probabilities respectively. It was recently shown that one can
do better than a random guess if and only if $(a-b)^2 &gt; 2(a+b)$. Using a
variant of Belief Propagation, we give a reconstruction algorithm that is
\emph{optimal} in the sense that if $(a-b)^2 &gt; C (a+b)$ for some constant $C$
then our algorithm maximizes the fraction of the nodes labelled correctly.
Along the way we prove some results of independent interest regarding {\em
robust reconstruction} for the Ising model on regular and Poisson trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1392</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1392</id><created>2013-09-05</created><updated>2013-12-09</updated><authors><author><keyname>Strelioff</keyname><forenames>Christopher C.</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>Bayesian Structural Inference for Hidden Processes</title><categories>stat.ML cs.LG math.ST nlin.CD physics.data-an stat.TH</categories><comments>20 pages, 11 figures, 1 table; supplementary materials, 15 pages, 11
  figures, 6 tables; http://csc.ucdavis.edu/~cmg/compmech/pubs/bsihp.htm</comments><report-no>Santa Fe Institute Working Paper 13-09-027</report-no><journal-ref>Phys. Rev. E 89, 042119 (2014)</journal-ref><doi>10.1103/PhysRevE.89.042119</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a Bayesian approach to discovering patterns in structurally
complex processes. The proposed method of Bayesian Structural Inference (BSI)
relies on a set of candidate unifilar HMM (uHMM) topologies for inference of
process structure from a data series. We employ a recently developed exact
enumeration of topological epsilon-machines. (A sequel then removes the
topological restriction.) This subset of the uHMM topologies has the added
benefit that inferred models are guaranteed to be epsilon-machines,
irrespective of estimated transition probabilities. Properties of
epsilon-machines and uHMMs allow for the derivation of analytic expressions for
estimating transition probabilities, inferring start states, and comparing the
posterior probability of candidate model topologies, despite process internal
structure being only indirectly present in data. We demonstrate BSI's
effectiveness in estimating a process's randomness, as reflected by the Shannon
entropy rate, and its structure, as quantified by the statistical complexity.
We also compare using the posterior distribution over candidate models and the
single, maximum a posteriori model for point estimation and show that the
former more accurately reflects uncertainty in estimated values. We apply BSI
to in-class examples of finite- and infinite-order Markov processes, as well to
an out-of-class, infinite-state hidden process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1410</identifier>
 <datestamp>2014-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1410</id><created>2013-09-05</created><authors><author><keyname>Graham</keyname><forenames>Benjamin</forenames></author></authors><title>A binary deletion channel with a fixed number of deletions</title><categories>math.PR cs.IT math.CO math.IT</categories><comments>4 pages</comments><msc-class>60C05, 68P30</msc-class><doi>10.1017/S0963548314000522</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose a binary string x = x_1...x_n is being broadcast repeatedly over a
faulty communication channel. Each time, the channel delivers a fixed number m
of the digits (m&lt;n) with the lost digits chosen uniformly at random, and the
order of the surviving digits preserved. How large does m have to be to
reconstruct the message?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1416</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1416</id><created>2013-09-05</created><authors><author><keyname>Gonzalez</keyname><forenames>Raul</forenames></author><author><keyname>Chen</keyname><forenames>Eric Y.</forenames></author><author><keyname>Jackson</keyname><forenames>Collin</forenames></author></authors><title>Automated Password Extraction Attack on Modern Password Managers</title><categories>cs.CR</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To encourage users to use stronger and more secure passwords, modern web
browsers offer users password management services, allowing users to save
previously entered passwords locally onto their hard drives. We present Lupin,
a tool that automatically extracts these saved passwords without the user's
knowledge. Lupin allows a network adversary to obtain passwords as long as the
login form appears on a non-HTTPS page. Unlike existing password sniffing
tools, Lupin can obtain passwords for websites users are not visiting.
Furthermore, Lupin can extract passwords embedded in login forms with a
destination address served in HTTPS. To determine the number of websites
vulnerable to our attack, we crawled the top 45,000 most popular websites from
Alexa's top website list and discovered that at least 28% of these sites are
vulnerable. To further demonstrate the feasibility of our attack, we tested
Lupin under controlled conditions using one of the authors' computers. Lupin
was able to extract passwords from 1,000 websites in less than 35 seconds. We
suggest techniques for web developers to protect their web applications from
attack, and we propose alternative designs for a secure password manager.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1418</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1418</id><created>2013-09-05</created><updated>2016-03-02</updated><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>Algorithmic Data Analytics, Small Data Matters and Correlation versus
  Causation</title><categories>cs.CE cs.CC cs.IT math.IT</categories><comments>Predictability in the world: philosophy and science in the complex
  world of Big Data} edited by J. Wernecke on the occasion of retirement Prof.
  Dr. Klaus Mainzer, Springer Verlag. Chapter based on an invited talk
  delivered to UNAM-CEIICH via videoconference from The University of Sheffield
  in the U.K. for the Alan Turing colloquium &quot;From computers to life&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a review of aspects of the theory of algorithmic information that may
contribute to a framework for formulating questions related to complex highly
unpredictable systems. We start by contrasting Shannon Entropy and
Kolmogorov-Chaitin complexity epitomizing the difference between correlation
and causation to then move onto surveying classical results from algorithmic
complexity and algorithmic probability, highlighting their deep connection to
the study of automata frequency distributions. We end showing how long-range
algorithmic predicting models for economic and biological systems may require
infinite computation but locally approximated short-range estimations are
possible thereby showing how small data can deliver important insights into
important features of complex &quot;Big Data&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1419</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1419</id><created>2013-09-05</created><authors><author><keyname>Sasanian</keyname><forenames>Zahra</forenames></author><author><keyname>Wille</keyname><forenames>Robert</forenames></author><author><keyname>Miller</keyname><forenames>D. Michael</forenames></author></authors><title>Clarification on the Mapping of Reversible Circuits to the NCV-v1
  Library</title><categories>cs.ET quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work and motivated by a theoretical discussion on physical
realizations, a new quantum gate library (the NCV-v1 library) for electronic
design automation of quantum circuits has been proposed. Here, qudits instead
of qubits are assumed, i.e. a basic building block which does not rely on a two
level quantum system but a (multiple-valued) d-level quantum system is assumed.
However, the descriptions on the foundation of this new library remained brief.
This technical report provides an extended description of the applied ideas and
concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1428</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1428</id><created>2013-09-05</created><authors><author><keyname>Ferenbaugh</keyname><forenames>Charles R.</forenames></author></authors><title>Experiments in Sustainable Software Practices for Future Architectures</title><categories>cs.SE cs.DC</categories><comments>4 pages. Submitted to &quot;Workshop on Sustainable Software for Science:
  Practice and Experiences,&quot; November, 2013, Denver, CO, USA</comments><report-no>LA-UR-13-26936</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the process of rewriting large physics codes at Los Alamos National
Laboratory to perform well on new architectures such as many-core, GPU, and
Intel MIC, we have found a number of areas in which sustainable software
practices can provide significant advantages. We describe several specific
advantages of sustainable practices for future architectures, and report on two
small experimental projects at LANL intended to raise awareness of new software
practices and programming approaches for new architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1432</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1432</id><created>2013-08-31</created><authors><author><keyname>Cao</keyname><forenames>Zhengjun</forenames></author><author><keyname>Liu</keyname><forenames>Lihua</forenames></author></authors><title>Ordered Probability Mass Function</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose that in the four tests Alice's scores are 90, 95, 85, 90, and Bob's
scores are 85, 95, 90, 90. How to evaluate their scores? In this paper, we
introduce the concept of ordered probability mass function which can be used to
find a probability mass function with smaller variance. More interestingly, we
can use it to distinguish sequences of positive numbers statistically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1453</identifier>
 <datestamp>2013-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1453</id><created>2013-09-01</created><authors><author><keyname>Guo</keyname><forenames>Peng</forenames></author><author><keyname>Cheng</keyname><forenames>Wenming</forenames></author><author><keyname>Wang</keyname><forenames>Yi</forenames></author></authors><title>Parallel machine scheduling with step deteriorating jobs and setup times
  by a hybrid discrete cuckoo search algorithm</title><categories>math.OC cs.DS cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article considers the parallel machine scheduling problem with
step-deteriorating jobs and sequence-dependent setup times. The objective is to
minimize the total tardiness by determining the allocation and sequence of jobs
on identical parallel machines. In this problem, the processing time of each
job is a step function dependent upon its starting time. An individual extended
time is penalized when the starting time of a job is later than a specific
deterioration date. The possibility of deterioration of a job makes the
parallel machine scheduling problem more challenging than ordinary ones. A
mixed integer programming model for the optimal solution is derived. Due to its
NP-hard nature, a hybrid discrete cuckoo search algorithm is proposed to solve
this problem. In order to generate a good initial swarm, a modified heuristic
named the MBHG is incorporated into the initialization of population. Several
discrete operators are proposed in the random walk of L\'{e}vy Flights and the
crossover search. Moreover, a local search procedure based on variable
neighborhood descent is integrated into the algorithm as a hybrid strategy in
order to improve the quality of elite solutions. Computational experiments are
executed on two sets of randomly generated test instances. The results show
that the proposed hybrid algorithm can yield better solutions in comparison
with the commercial solver CPLEX with one hour time limit, discrete cuckoo
search algorithm and the existing variable neighborhood search algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1485</identifier>
 <datestamp>2013-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1485</id><created>2013-09-05</created><updated>2013-12-03</updated><authors><author><keyname>Ashari</keyname><forenames>Alireza Esna</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Formally expressing the semantics of observer-based fault detection
  software</title><categories>cs.SE math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim is to create reliable and verifiable fault detection software to
detect abrupt changes in safety-critical dynamic systems. Fault detection
methods are implemented as software on digital computers that monitor and
control the system. We implement three observer-based fault detection methods
on a 3 degrees of freedom (3DOF) laboratory helicopter, in the form of
software. We examine the performance of those methods to detect different
faults during flight in a closed-loop setup. All selected methods show
acceptable detection performance. However, it is not possible to repeat the
test for every possible conditions, inputs and fault scenarios. In this paper,
we translate fault detection properties and mathematical proofs into a formal
language, previously used in software validation and verification. We include
the translated properties in software in the form of non-executable annotations
that can be read by machine. Consequently, some high level functional
properties of the code can be verified by automatic software verification
tools. This certifies fault detection software for a set of bounded data and
increases the reliability in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1496</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1496</id><created>2013-09-05</created><updated>2013-09-09</updated><authors><author><keyname>Ely</keyname><forenames>Gregory</forenames></author><author><keyname>Aeron</keyname><forenames>Shuchin</forenames></author></authors><title>Methods for Large Scale Hydraulic Fracture Monitoring</title><categories>physics.geo-ph cs.CE</categories><comments>arXiv admin note: text overlap with arXiv:1305.0060</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose computationally efficient and robust methods for
estimating the moment tensor and location of micro-seismic event(s) for large
search volumes. Our contribution is two-fold. First, we propose a novel
joint-complexity measure, namely the sum of nuclear norms which while imposing
sparsity on the number of fractures (locations) over a large spatial volume,
also captures the rank-1 nature of the induced wavefield pattern. This
wavefield pattern is modeled as the outer-product of the source signature with
the amplitude pattern across the receivers from a seismic source. A rank-1
factorization of the estimated wavefield pattern at each location can therefore
be used to estimate the seismic moment tensor using the knowledge of the array
geometry. In contrast to existing work this approach allows us to drop any
other assumption on the source signature. Second, we exploit the recently
proposed first-order incremental projection algorithms for a fast and efficient
implementation of the resulting optimization problem and develop a hybrid
stochastic &amp; deterministic algorithm which results in significant computational
savings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1501</identifier>
 <datestamp>2013-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1501</id><created>2013-09-05</created><updated>2013-12-10</updated><authors><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Kingsbury</keyname><forenames>Brian</forenames></author><author><keyname>Mohamed</keyname><forenames>Abdel-rahman</forenames></author><author><keyname>Dahl</keyname><forenames>George E.</forenames></author><author><keyname>Saon</keyname><forenames>George</forenames></author><author><keyname>Soltau</keyname><forenames>Hagen</forenames></author><author><keyname>Beran</keyname><forenames>Tomas</forenames></author><author><keyname>Aravkin</keyname><forenames>Aleksandr Y.</forenames></author><author><keyname>Ramabhadran</keyname><forenames>Bhuvana</forenames></author></authors><title>Improvements to deep convolutional neural networks for LVCSR</title><categories>cs.LG cs.CL cs.NE math.OC stat.ML</categories><comments>6 pages, 1 figure</comments><msc-class>65K05, 90C15, 90C90</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Convolutional Neural Networks (CNNs) are more powerful than Deep Neural
Networks (DNN), as they are able to better reduce spectral variation in the
input signal. This has also been confirmed experimentally, with CNNs showing
improvements in word error rate (WER) between 4-12% relative compared to DNNs
across a variety of LVCSR tasks. In this paper, we describe different methods
to further improve CNN performance. First, we conduct a deep analysis comparing
limited weight sharing and full weight sharing with state-of-the-art features.
Second, we apply various pooling strategies that have shown improvements in
computer vision to an LVCSR speech task. Third, we introduce a method to
effectively incorporate speaker adaptation, namely fMLLR, into log-mel
features. Fourth, we introduce an effective strategy to use dropout during
Hessian-free sequence training. We find that with these improvements,
particularly with fMLLR and dropout, we are able to achieve an additional 2-3%
relative improvement in WER on a 50-hour Broadcast News task over our previous
best CNN baseline. On a larger 400-hour BN task, we find an additional 4-5%
relative improvement over our previous best CNN baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1507</identifier>
 <datestamp>2015-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1507</id><created>2013-09-05</created><updated>2015-07-22</updated><authors><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author></authors><title>A Quantized Johnson Lindenstrauss Lemma: The Finding of Buffon's Needle</title><categories>cs.IT cs.DS math.IT math.PR</categories><comments>27 pages, 2 figures (note: this version corrects a few typos in the
  abstract)</comments><report-no>TR-LJ-2013.03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1733, Georges-Louis Leclerc, Comte de Buffon in France, set the ground of
geometric probability theory by defining an enlightening problem: What is the
probability that a needle thrown randomly on a ground made of equispaced
parallel strips lies on two of them? In this work, we show that the solution to
this problem, and its generalization to $N$ dimensions, allows us to discover a
quantized form of the Johnson-Lindenstrauss (JL) Lemma, i.e., one that combines
a linear dimensionality reduction procedure with a uniform quantization of
precision $\delta&gt;0$. In particular, given a finite set $\mathcal S \subset
\mathbb R^N$ of $S$ points and a distortion level $\epsilon&gt;0$, as soon as $M &gt;
M_0 = O(\epsilon^{-2} \log S)$, we can (randomly) construct a mapping from
$(\mathcal S, \ell_2)$ to $(\delta\mathbb Z^M, \ell_1)$ that approximately
preserves the pairwise distances between the points of $\mathcal S$.
Interestingly, compared to the common JL Lemma, the mapping is quasi-isometric
and we observe both an additive and a multiplicative distortions on the
embedded distances. These two distortions, however, decay as $O(\sqrt{(\log
S)/M})$ when $M$ increases. Moreover, for coarse quantization, i.e., for high
$\delta$ compared to the set radius, the distortion is mainly additive, while
for small $\delta$ we tend to a Lipschitz isometric embedding. Finally, we
prove the existence of a &quot;nearly&quot; quasi-isometric embedding of $(\mathcal S,
\ell_2)$ into $(\delta\mathbb Z^M, \ell_2)$. This one involves a non-linear
distortion of the $\ell_2$-distance in $\mathcal S$ that vanishes for distant
points in this set. Noticeably, the additive distortion in this case is slower,
and decays as $O(\sqrt[4]{(\log S)/M})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1508</identifier>
 <datestamp>2013-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1508</id><created>2013-09-05</created><updated>2013-12-10</updated><authors><author><keyname>Sainath</keyname><forenames>Tara N.</forenames></author><author><keyname>Horesh</keyname><forenames>Lior</forenames></author><author><keyname>Kingsbury</keyname><forenames>Brian</forenames></author><author><keyname>Aravkin</keyname><forenames>Aleksandr Y.</forenames></author><author><keyname>Ramabhadran</keyname><forenames>Bhuvana</forenames></author></authors><title>Accelerating Hessian-free optimization for deep neural networks by
  implicit preconditioning and sampling</title><categories>cs.LG cs.CL cs.NE math.OC stat.ML</categories><comments>this paper is not supposed to be posted publically before the
  conference in December due to company policy. another co-author was not
  informed of this and posted without the permission of the first author. pls
  remove</comments><msc-class>65K05, 90C15, 90C90</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hessian-free training has become a popular parallel second or- der
optimization technique for Deep Neural Network training. This study aims at
speeding up Hessian-free training, both by means of decreasing the amount of
data used for training, as well as through reduction of the number of Krylov
subspace solver iterations used for implicit estimation of the Hessian. In this
paper, we develop an L-BFGS based preconditioning scheme that avoids the need
to access the Hessian explicitly. Since L-BFGS cannot be regarded as a
fixed-point iteration, we further propose the employment of flexible Krylov
subspace solvers that retain the desired theoretical convergence guarantees of
their conventional counterparts. Second, we propose a new sampling algorithm,
which geometrically increases the amount of data utilized for gradient and
Krylov subspace iteration calculations. On a 50-hr English Broadcast News task,
we find that these methodologies provide roughly a 1.5x speed-up, whereas, on a
300-hr Switchboard task, these techniques provide over a 2.3x speedup, with no
loss in WER. These results suggest that even further speed-up is expected, as
problems scale and complexity grows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1515</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1515</id><created>2013-09-05</created><authors><author><keyname>Perera</keyname><forenames>Charith</forenames></author><author><keyname>Zaslavsky</keyname><forenames>Arkady</forenames></author><author><keyname>Compton</keyname><forenames>Michael</forenames></author><author><keyname>Christen</keyname><forenames>Peter</forenames></author><author><keyname>Georgakopoulos</keyname><forenames>Dimitrios</forenames></author></authors><title>Semantic-driven Configuration of Internet of Things Middleware</title><categories>cs.NI cs.SE</categories><comments>9th International Conference on Semantics, Knowledge &amp; Grids (SKG),
  Beijing, China, October, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are currently observing emerging solutions to enable the Internet of
Things (IoT). Efficient and feature rich IoT middeware platforms are key
enablers for IoT. However, due to complexity, most of these middleware
platforms are designed to be used by IT experts. In this paper, we propose a
semantics-driven model that allows non-IT experts (e.g. plant scientist, city
planner) to configure IoT middleware components easier and faster. Such tools
allow them to retrieve the data they want without knowing the underlying
technical details of the sensors and the data processing components. We propose
a Context Aware Sensor Configuration Model (CASCoM) to address the challenge of
automated context-aware configuration of filtering, fusion, and reasoning
mechanisms in IoT middleware according to the problems at hand. We incorporate
semantic technologies in solving the above challenges. We demonstrate the
feasibility and the scalability of our approach through a prototype
implementation based on an IoT middleware called Global Sensor Networks (GSN),
though our model can be generalized into any other middleware platform. We
evaluate CASCoM in agriculture domain and measure both performance in terms of
usability and computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1516</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1516</id><created>2013-09-05</created><authors><author><keyname>Lin</keyname><forenames>Shih-Chun</forenames></author><author><keyname>Lin</keyname><forenames>Cheng-Liang</forenames></author></authors><title>On Secrecy Capacity of Fast Fading MIMOME Wiretap Channels With
  Statistical CSIT</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Wireless Communications</comments><doi>10.1109/TWC.2014.041714.11654</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider secure transmissions in ergodic Rayleigh
fast-faded multiple-input multiple-output multiple-antenna-eavesdropper
(MIMOME) wiretap channels with only statistical channel state information at
the transmitter (CSIT). When the legitimate receiver has more (or equal)
antennas than the eavesdropper, we prove the first MIMOME secrecy capacity with
partial CSIT by establishing a new secrecy capacity upper-bound. The key step
is to form an MIMOME degraded channel by dividing the legitimate receiver's
channel matrix into two submatrices, and setting one of the submatrices to be
the same as the eavesdropper's channel matrix. Next, under the total power
constraint over all transmit antennas, we analytically solve the channel-input
covariance matrix optimization problem to fully characterize the MIMOME secrecy
capacity. Typically, the MIMOME optimization problems are non-concave. However,
thank to the proposed degraded channel, we can transform the stochastic MIMOME
optimization problem to be a Schur-concave one and then find its solution.
Besides total power constraint, we also investigate the secrecy capacity when
the transmitter is subject to the practical per-antenna power constraint. The
corresponding optimization problem is even more difficult since it is not
Schuar-concave. Under the two power constraints considered, the corresponding
MIMOME secrecy capacities can both scale with the signal-to-noise ratios (SNR)
when the difference between numbers of antennas at legitimate receiver and
eavesdropper are large enough. However, when the legitimate receiver and
eavesdropper have a single antenna each, such SNR scalings do not exist for
both cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1517</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1517</id><created>2013-09-05</created><authors><author><keyname>Thakor</keyname><forenames>Satyajit</forenames></author><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author></authors><title>On the Capacity of Networks with Correlated Sources</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Characterizing the capacity region for a network can be extremely difficult.
Even with independent sources, determining the capacity region can be as hard
as the open problem of characterizing all information inequalities. The
majority of computable outer bounds in the literature are relaxations of the
Linear Programming bound which involves entropy functions of random variables
related to the sources and link messages. When sources are not independent, the
problem is even more complicated. Extension of linear programming bounds to
networks with correlated sources is largely open. Source dependence is usually
specified via a joint probability distribution, and one of the main challenges
in extending linear programming bounds is the difficulty (or impossibility) of
characterizing arbitrary dependencies via entropy functions. This paper tackles
the problem by answering the question of how well entropy functions can
characterize correlation among sources. We show that by using carefully chosen
auxiliary random variables, the characterization can be fairly &quot;accurate&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1518</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1518</id><created>2013-09-05</created><authors><author><keyname>Lin</keyname><forenames>Xingqin</forenames></author><author><keyname>Ratasuk</keyname><forenames>Rapeepat</forenames></author><author><keyname>Ghosh</keyname><forenames>Amitava</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Modeling, Analysis and Optimization of Multicast Device-to-Device
  Transmission</title><categories>cs.IT math.IT</categories><comments>14 pages; 8 figures; submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multicast device-to-device (D2D) transmission is important for applications
like local file transfer in commercial networks and is also a required feature
in public safety networks. In this paper we propose a tractable baseline
multicast D2D model, and use it to analyze important multicast metrics like the
coverage probability, mean number of covered receivers and throughput. In
addition, we examine how the multicast performance would be affected by certain
factors like mobility and network assistance. Take the mean number of covered
receivers as an example. We find that simple repetitive transmissions help but
the gain quickly diminishes as the repetition time increases. Meanwhile,
mobility and network assistance (i.e. allowing the network to relay the
multicast signals) can help cover more receivers. We also explore how to
optimize multicasting, e.g. by choosing the optimal multicast rate and the
optimal number of retransmission times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1521</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1521</id><created>2013-09-05</created><authors><author><keyname>Obst</keyname><forenames>Oliver</forenames></author><author><keyname>Trinchi</keyname><forenames>Adrian</forenames></author><author><keyname>Hardin</keyname><forenames>Simon G.</forenames></author><author><keyname>Chadwick</keyname><forenames>Matthew</forenames></author><author><keyname>Cole</keyname><forenames>Ivan</forenames></author><author><keyname>Muster</keyname><forenames>Tim H.</forenames></author><author><keyname>Hoschke</keyname><forenames>Nigel</forenames></author><author><keyname>Ostry</keyname><forenames>Diet</forenames></author><author><keyname>Price</keyname><forenames>Don</forenames></author><author><keyname>Pham</keyname><forenames>Khoa N.</forenames></author><author><keyname>Wark</keyname><forenames>Tim</forenames></author></authors><title>Nano-scale reservoir computing</title><categories>cs.ET cs.NE nlin.AO</categories><comments>8 pages, 9 figures, accepted for publication in Nano Communication
  Networks, http://www.journals.elsevier.com/nano-communication-networks/. An
  earlier version was presented at the 3rd IEEE International Workshop on
  Molecular and Nanoscale Communications (IEEE MoNaCom 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work describes preliminary steps towards nano-scale reservoir computing
using quantum dots. Our research has focused on the development of an
accumulator-based sensing system that reacts to changes in the environment, as
well as the development of a software simulation. The investigated systems
generate nonlinear responses to inputs that make them suitable for a physical
implementation of a neural network. This development will enable
miniaturisation of the neurons to the molecular level, leading to a range of
applications including monitoring of changes in materials or structures. The
system is based around the optical properties of quantum dots. The paper will
report on experimental work on systems using Cadmium Selenide (CdSe) quantum
dots and on the various methods to render the systems sensitive to pH, redox
potential or specific ion concentration. Once the quantum dot-based systems are
rendered sensitive to these triggers they can provide a distributed array that
can monitor and transmit information on changes within the material.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1524</identifier>
 <datestamp>2014-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1524</id><created>2013-09-05</created><authors><author><keyname>Obst</keyname><forenames>Oliver</forenames></author><author><keyname>Boedecker</keyname><forenames>Joschka</forenames></author></authors><title>Guided Self-Organization of Input-Driven Recurrent Neural Networks</title><categories>cs.NE cs.AI nlin.AO</categories><comments>23 pages, to appear in M. Prokopenko (ed.), Guided Self-Organization:
  Inception, Springer, 2014</comments><doi>10.1007/978-3-642-53734-9_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review attempts that have been made towards understanding the
computational properties and mechanisms of input-driven dynamical systems like
RNNs, and reservoir computing networks in particular. We provide details on
methods that have been developed to give quantitative answers to the questions
above. Following this, we show how self-organization may be used to improve
reservoirs for better performance, in some cases guided by the measures
presented before. We also present a possible way to quantify task performance
using an information-theoretic approach, and finally discuss promising future
directions aimed at a better understanding of how these systems perform their
computations and how to best guide self-organized processes for their
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1536</identifier>
 <datestamp>2014-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1536</id><created>2013-09-06</created><updated>2014-01-26</updated><authors><author><keyname>Deng</keyname><forenames>W. B.</forenames></author><author><keyname>Allahverdyan</keyname><forenames>A. E.</forenames></author><author><keyname>Li</keyname><forenames>B.</forenames></author><author><keyname>Wang</keyname><forenames>Q. A.</forenames></author></authors><title>Rank-frequency relation for Chinese characters</title><categories>cs.CL physics.data-an</categories><comments>To appear in European Physical Journal B (EPJ B), 2014 (22 pages, 7
  figures)</comments><journal-ref>Eur. Phys. J. B (2014) 87: 47</journal-ref><doi>10.1140/epjb/e2014-40805-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Zipf's law for Chinese characters perfectly holds for
sufficiently short texts (few thousand different characters). The scenario of
its validity is similar to the Zipf's law for words in short English texts. For
long Chinese texts (or for mixtures of short Chinese texts), rank-frequency
relations for Chinese characters display a two-layer, hierarchic structure that
combines a Zipfian power-law regime for frequent characters (first layer) with
an exponential-like regime for less frequent characters (second layer). For
these two layers we provide different (though related) theoretical descriptions
that include the range of low-frequency characters (hapax legomena). The
comparative analysis of rank-frequency relations for Chinese characters versus
English words illustrates the extent to which the characters play for Chinese
writers the same role as the words for those writing within alphabetical
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1539</identifier>
 <datestamp>2014-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1539</id><created>2013-09-06</created><updated>2014-10-27</updated><authors><author><keyname>Wang</keyname><forenames>Yu-Xiang</forenames></author><author><keyname>Lee</keyname><forenames>Choon Meng</forenames></author><author><keyname>Cheong</keyname><forenames>Loong-Fah</forenames></author><author><keyname>Toh</keyname><forenames>Kim-Chuan</forenames></author></authors><title>Practical Matrix Completion and Corruption Recovery using Proximal
  Alternating Robust Subspace Minimization</title><categories>cs.CV</categories><comments>Published at IJCV</comments><doi>10.1007/s11263-014-0746-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-rank matrix completion is a problem of immense practical importance.
Recent works on the subject often use nuclear norm as a convex surrogate of the
rank function. Despite its solid theoretical foundation, the convex version of
the problem often fails to work satisfactorily in real-life applications. Real
data often suffer from very few observations, with support not meeting the
random requirements, ubiquitous presence of noise and potentially gross
corruptions, sometimes with these simultaneously occurring.
  This paper proposes a Proximal Alternating Robust Subspace Minimization
(PARSuMi) method to tackle the three problems. The proximal alternating scheme
explicitly exploits the rank constraint on the completed matrix and uses the
$\ell_0$ pseudo-norm directly in the corruption recovery step. We show that the
proposed method for the non-convex and non-smooth model converges to a
stationary point. Although it is not guaranteed to find the global optimal
solution, in practice we find that our algorithm can typically arrive at a good
local minimizer when it is supplied with a reasonably good starting point based
on convex optimization. Extensive experiments with challenging synthetic and
real data demonstrate that our algorithm succeeds in a much larger range of
practical problems where convex optimization fails, and it also outperforms
various state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1541</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1541</id><created>2013-09-06</created><authors><author><keyname>Wang</keyname><forenames>Weiran</forenames></author><author><keyname>Carreira-Perpi&#xf1;&#xe1;n</keyname><forenames>Miguel &#xc1;.</forenames></author></authors><title>Projection onto the probability simplex: An efficient algorithm with a
  simple proof, and an application</title><categories>cs.LG math.OC stat.ML</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an elementary proof of a simple, efficient algorithm for computing
the Euclidean projection of a point onto the probability simplex. We also show
an application in Laplacian K-modes clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1542</identifier>
 <datestamp>2014-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1542</id><created>2013-09-06</created><authors><author><keyname>Ogunduyile</keyname><forenames>O. O.</forenames></author><author><keyname>Zuva</keyname><forenames>K.</forenames></author><author><keyname>Randle</keyname><forenames>O. A.</forenames></author><author><keyname>Zuva</keyname><forenames>T.</forenames></author></authors><title>Ubiquitous healthcare monitoring system using integrated triaxial
  accelerometer,spo2 and location sensors</title><categories>cs.NI</categories><comments>13 pages, 6 figures, International Journal of UbiComp (IJU), Vol.4,
  No.2</comments><msc-class>14J26 (Secondary)</msc-class><journal-ref>International Journal of UbiComp (IJU), Vol.4, No.2,April 2013</journal-ref><doi>10.5121/iju.2013.4201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ubiquitous healthcare has become one of the prominent areas of research
inorder to address the challenges encountered in healthcare environment. In
contribution to this area, this study developed a system prototype that
recommends diagonostic services based on physiological data collected in real
time from a distant patient. The prototype uses WBAN body sensors to be worn by
the individual and an android smart phone as a personal server. Physiological
data is collected and uploaded to a Medical Health Server (MHS) via
GPRS/internet to be analysed. Our implemented prototype monitors the activity,
location and physiological data such as SpO2 and Heart Rate (HR) of the elderly
and patients in rehabilitation. The uploaded information can be accessed in
real time by medical practitioners through a web application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1543</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1543</id><created>2013-09-06</created><authors><author><keyname>Randle</keyname><forenames>O. A.</forenames></author><author><keyname>Ogunduyile</keyname><forenames>O. O.</forenames></author><author><keyname>Zuva</keyname><forenames>T.</forenames></author><author><keyname>Fashola</keyname><forenames>N. A.</forenames></author></authors><title>A Comparism of the Performance of Supervised and Unsupervised Machine
  Learning Techniques in evolving Awale/Mancala/Ayo Game Player</title><categories>cs.LG cs.GT</categories><comments>10 pages, 2 figures</comments><journal-ref>International Journal of Game Theory and Technology (IJGTT),
  Vol.1, No.1, June 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Awale games have become widely recognized across the world, for their
innovative strategies and techniques which were used in evolving the agents
(player) and have produced interesting results under various conditions. This
paper will compare the results of the two major machine learning techniques by
reviewing their performance when using minimax, endgame database, a combination
of both techniques or other techniques, and will determine which are the best
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1547</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1547</id><created>2013-09-06</created><authors><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author><author><keyname>Vu\vskovi&#x107;</keyname><forenames>Kristina</forenames></author></authors><title>Combinatorial optimization with 2-joins</title><categories>cs.DM math.CO</categories><msc-class>05C17</msc-class><journal-ref>N. Trotignon and K. Vuskovic. Combinatorial optimization with
  2-joins. Journal of Combinatorial Theory, Series B, 102:153-185, 2012</journal-ref><doi>10.1016/j.jctb.2011.06.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 2-join is an edge cutset that naturally appears in decomposition of several
classes of graphs closed under taking induced subgraphs, such as perfect graphs
and claw-free graphs. In this paper we construct combinatorial polynomial time
algorithms for finding a maximum weighted clique, a maximum weighted stable set
and an optimal coloring for a class of perfect graphs decomposable by 2-joins:
the class of perfect graphs that do not have a balanced skew partition, a
2-join in the complement, nor a homogeneous pair. The techniques we develop are
general enough to be easily applied to finding a maximum weighted stable set
for another class of graphs known to be decomposable by 2-joins, namely the
class of even-hole-free graphs that do not have a star cutset.
  We also give a simple class of graphs decomposable by 2-joins into bipartite
graphs and line graphs, and for which finding a maximum stable set is NP-hard.
This shows that having holes all of the same parity gives essential properties
for the use of 2-joins in computing stable sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1550</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1550</id><created>2013-09-06</created><updated>2014-04-28</updated><authors><author><keyname>Ouaknine</keyname><forenames>Joel</forenames></author><author><keyname>Worrell</keyname><forenames>James</forenames></author></authors><title>On the Positivity Problem for Simple Linear Recurrence Sequences</title><categories>cs.DM</categories><comments>arXiv admin note: substantial text overlap with arXiv:1307.2779</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a linear recurrence sequence (LRS) over the integers, the Positivity
Problem} asks whether all terms of the sequence are positive. We show that, for
simple LRS (those whose characteristic polynomial has no repeated roots) of
order 9 or less, Positivity is decidable, with complexity in the Counting
Hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1553</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1553</id><created>2013-09-06</created><authors><author><keyname>Bang-Jensen</keyname><forenames>J\orgen</forenames></author><author><keyname>Havet</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>Finding an induced subdivision of a digraph</title><categories>cs.DM math.CO</categories><msc-class>05C85</msc-class><journal-ref>J. Bang-Jensen, F. Havet and N. Trotignon. Finding an induced
  subdivision of a digraph. Theoretical Computer Science, 443:10-24, 2012</journal-ref><doi>10.1016/j.tcs.2012.03.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following problem for oriented graphs and digraphs: Given an
oriented graph (digraph) $G$, does it contain an induced subdivision of a
prescribed digraph $D$? The complexity of this problem depends on $D$ and on
whether $G$ must be an oriented graph or is allowed to contain 2-cycles. We
give a number of examples of polynomial instances as well as several
NP-completeness proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1555</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1555</id><created>2013-09-06</created><updated>2013-12-03</updated><authors><author><keyname>Tang</keyname><forenames>Siyun</forenames></author><author><keyname>Member</keyname><forenames>Xiao Ma</forenames></author></authors><title>A New Chase-type Soft-decision Decoding Algorithm for Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses three relevant issues arising in designing Chase-type
algorithms for Reed-Solomon codes: 1) how to choose the set of testing
patterns; 2) given the set of testing patterns, what is the optimal testing
order in the sense that the most-likely codeword is expected to appear earlier;
and 3) how to identify the most-likely codeword. A new Chase-type soft-decision
decoding algorithm is proposed, referred to as tree-based Chase-type algorithm.
The proposed algorithm takes the set of all vectors as the set of testing
patterns, and hence definitely delivers the most-likely codeword provided that
the computational resources are allowed. All the testing patterns are arranged
in an ordered rooted tree according to the likelihood bounds of the possibly
generated codewords. While performing the algorithm, the ordered rooted tree is
constructed progressively by adding at most two leafs at each trial. The
ordered tree naturally induces a sufficient condition for the most-likely
codeword. That is, whenever the proposed algorithm exits before a preset
maximum number of trials is reached, the output codeword must be the
most-likely one. When the proposed algorithm is combined with Guruswami-Sudan
(GS) algorithm, each trial can be implement in an extremely simple way by
removing one old point and interpolating one new point. Simulation results show
that the proposed algorithm performs better than the recently proposed
Chase-type algorithm by Bellorado et al with less trials given that the maximum
number of trials is the same. Also proposed are simulation-based performance
bounds on the MLD algorithm, which are utilized to illustrate the
near-optimality of the proposed algorithm in the high SNR region. In addition,
the proposed algorithm admits decoding with a likelihood threshold, that
searches the most-likely codeword within an Euclidean sphere rather than a
Hamming sphere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1556</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1556</id><created>2013-09-06</created><authors><author><keyname>cao</keyname><forenames>Yu</forenames></author><author><keyname>Guo</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Todd</keyname><forenames>Stephen</forenames></author></authors><title>Hyper-Graph Based Database Partitioning for Transactional Workloads</title><categories>cs.DB</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A common approach to scaling transactional databases in practice is
horizontal partitioning, which increases system scalability, high availability
and self-manageability. Usu- ally it is very challenging to choose or design an
optimal partitioning scheme for a given workload and database. In this
technical report, we propose a fine-grained hyper-graph based database
partitioning system for transactional work- loads. The partitioning system
takes a database, a workload, a node cluster and partitioning constraints as
input and out- puts a lookup-table encoding the final database partitioning
decision. The database partitioning problem is modeled as a multi-constraints
hyper-graph partitioning problem. By deriving a min-cut of the hyper-graph, our
system can min- imize the total number of distributed transactions in the
workload, balance the sizes and workload accesses of the partitions and satisfy
all the partition constraints imposed. Our system is highly interactive as it
allows users to im- pose partition constraints, watch visualized partitioning
ef- fects, and provide feedback based on human expertise and indirect domain
knowledge for generating better partition- ing schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1559</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1559</id><created>2013-09-06</created><authors><author><keyname>Fomin</keyname><forenames>Fedor</forenames></author><author><keyname>Todinca</keyname><forenames>Ioan</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>Large induced subgraphs via triangulations and CMSO</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain an algorithmic meta-theorem for the following optimization problem.
Let \phi\ be a Counting Monadic Second Order Logic (CMSO) formula and t be an
integer. For a given graph G, the task is to maximize |X| subject to the
following: there is a set of vertices F of G, containing X, such that the
subgraph G[F] induced by F is of treewidth at most t, and structure (G[F],X)
models \phi.
  Some special cases of this optimization problem are the following generic
examples. Each of these cases contains various problems as a special subcase:
  1) &quot;Maximum induced subgraph with at most l copies of cycles of length 0
modulo m&quot;, where for fixed nonnegative integers m and l, the task is to find a
maximum induced subgraph of a given graph with at most l vertex-disjoint cycles
of length 0 modulo m.
  2) &quot;Minimum \Gamma-deletion&quot;, where for a fixed finite set of graphs \Gamma\
containing a planar graph, the task is to find a maximum induced subgraph of a
given graph containing no graph from \Gamma\ as a minor.
  3) &quot;Independent \Pi-packing&quot;, where for a fixed finite set of connected
graphs \Pi, the task is to find an induced subgraph G[F] of a given graph G
with the maximum number of connected components, such that each connected
component of G[F] is isomorphic to some graph from \Pi.
  We give an algorithm solving the optimization problem on an n-vertex graph G
in time O(#pmc n^{t+4} f(t,\phi)), where #pmc is the number of all potential
maximal cliques in G and f is a function depending of t and \phi\ only. We also
show how a similar running time can be obtained for the weighted version of the
problem. Pipelined with known bounds on the number of potential maximal
cliques, we deduce that our optimization problem can be solved in time
O(1.7347^n) for arbitrary graphs, and in polynomial time for graph classes with
polynomial number of minimal separators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1567</identifier>
 <datestamp>2013-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1567</id><created>2013-09-06</created><updated>2013-11-05</updated><authors><author><keyname>Idrobo</keyname><forenames>Andres Hoyos</forenames><affiliation>I2BM</affiliation></author><author><keyname>Weiss</keyname><forenames>Pierre</forenames><affiliation>ITAV</affiliation></author><author><keyname>Massire</keyname><forenames>Aur&#xe9;lien</forenames><affiliation>I2BM</affiliation></author><author><keyname>Amadon</keyname><forenames>Alexis</forenames><affiliation>I2BM</affiliation></author><author><keyname>Boulant</keyname><forenames>Nicolas</forenames><affiliation>I2BM</affiliation></author></authors><title>On Variant Strategies To Solve The Magnitude Least Squares Optimization
  Problem In Parallel Transmission Pulse Design And Under Strict SAR And Power
  Constraints</title><categories>physics.ins-det cs.CE</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel transmission has been a very promising candidate technology to
mitigate the inevitable radio-frequency field inhomogeneity in magnetic
resonance imaging (MRI) at ultra-high field (UHF). For the first few years,
pulse design utilizing this technique was expressed as a least squares problem
with crude power regularizations aimed at controlling the specific absorption
rate (SAR), hence the patient safety. This approach being suboptimal for many
applications sensitive mostly to the magnitude of the spin excitation, and not
its phase, the magnitude least squares (MLS) problem then was first formulated
in 2007. Despite its importance and the availability of other powerful
numerical optimization methods, this problem yet has been faced exclusively by
the pulse designer with the so-called variable exchange method. In this paper,
we investigate other strategies and incorporate directly the strict SAR and
hardware constraints. Different schemes such as sequential quadratic
programming (SQP), interior point (I-P) methods, semi-definite programming
(SDP) and magnitude squared least squares (MSLS) relaxations are studied both
in the small and large tip angle regimes with real data sets obtained in-vivo
on a human brain at 7 Tesla. Convergence and robustness of the different
approaches are analyzed, and recommendations to tackle this specific problem
are finally given. Small tip angle and inversion pulses are returned in a few
seconds and in under a minute respectively while respecting the constraints,
allowing the use of the proposed approach in routine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1574</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1574</id><created>2013-09-06</created><authors><author><keyname>Fagiano</keyname><forenames>Lorenzo</forenames></author><author><keyname>Novara</keyname><forenames>Carlo</forenames></author></authors><title>Identification of nonlinear controllers from data: theory and
  computation</title><categories>cs.SY math.DS math.OC</categories><comments>The material contained in this manuscript is part of a paper
  submitted for possible publication on the IEEE Transactions on Automatic
  Control and is subject to IEEE Copyright. If accepted, the copy of record
  will be available at IEEEXplore library: http://ieeexplore.ieee.org/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript contains technical details and proofs of recent results
developed by the authors, pertaining to the design of nonlinear controllers
from the experimental data measured on an existing feedback control system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1585</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1585</id><created>2013-09-06</created><authors><author><keyname>Pappas</keyname><forenames>Nikolaos</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Jeon</keyname><forenames>Jeongho</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author><author><keyname>Traganitis</keyname><forenames>Apostolos</forenames></author></authors><title>Network-Level Cooperation in Energy Harvesting Wireless Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>1st IEEE Global Conference on Signal and Information Processing
  (GlobalSIP) 2013, Symposium on Energy Harvesting and Green Wireless
  Communications. arXiv admin note: text overlap with arXiv:1309.1338</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two-hop communication network consisted of a source node, a
relay and a destination node in which the source and the relay node have
external traffic arrivals. The relay forwards a fraction of the source node's
traffic to the destination and the cooperation is performed at the network
level. In addition, both source and relay nodes have energy harvesting
capabilities and an unlimited battery to store the harvested energy. We study
the impact of the energy constraints on the stability region. Specifically, we
provide inner and outer bounds on the stability region of the two-hop network
with energy harvesting source and relay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1588</identifier>
 <datestamp>2014-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1588</id><created>2013-09-06</created><updated>2014-04-24</updated><authors><author><keyname>Wilson</keyname><forenames>David</forenames></author><author><keyname>Davenport</keyname><forenames>James H.</forenames></author><author><keyname>England</keyname><forenames>Matthew</forenames></author><author><keyname>Bradford</keyname><forenames>Russell</forenames></author></authors><title>A &quot;Piano Movers&quot; Problem Reformulated</title><categories>cs.CG cs.SC</categories><comments>8 pages. Copyright IEEE 2014</comments><msc-class>68W30</msc-class><acm-class>I.1.4; I.2.9</acm-class><journal-ref>Proceedings of the 15th International Symposium on Symbolic and
  Numeric Algorithms for Scientific Computing (SYNASC '13), pp. 53-60. IEEE,
  2013</journal-ref><doi>10.1109/SYNASC.2013.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has long been known that cylindrical algebraic decompositions (CADs) can
in theory be used for robot motion planning. However, in practice even the
simplest examples can be too complicated to tackle. We consider in detail a
&quot;Piano Mover's Problem&quot; which considers moving an infinitesimally thin piano
(or ladder) through a right-angled corridor.
  Producing a CAD for the original formulation of this problem is still
infeasible after 25 years of improvements in both CAD theory and computer
hardware. We review some alternative formulations in the literature which use
differing levels of geometric analysis before input to a CAD algorithm. Simpler
formulations allow CAD to easily address the question of the existence of a
path. We provide a new formulation for which both a CAD can be constructed and
from which an actual path could be determined if one exists, and analyse the
CADs produced using this approach for variations of the problem.
  This emphasises the importance of the precise formulation of such problems
for CAD. We analyse the formulations and their CADs considering a variety of
heuristics and general criteria, leading to conclusions about tackling other
problems of this form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1596</identifier>
 <datestamp>2014-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1596</id><created>2013-09-06</created><updated>2014-11-27</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Security analysis of epsilon-almost dual universal2 hash functions:
  smoothing of min entropy vs. smoothing of R\'enyi entropy of order 2</title><categories>cs.IT cs.CR math.IT</categories><comments>Several errors are fixed. Introduction and presentation have been
  improved. This paper consists of a part of the older version of
  arXiv:1202.0322 and several additional result. This part of the older version
  of arXiv:1202.0322 has been removed in the current version of
  arXiv:1202.0322. So, there is no overlap between this paper and the current
  version of arXiv:1202.0322</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, $\varepsilon$-almost dual universal$_2$ hash functions has been
proposed as a new and wider class of hash functions. Using this class of hash
functions, several efficient hash functions were proposed. This paper evaluates
the security performance when we apply this kind of hash functions. We evaluate
the security in several kinds of setting based on the $L_1$ distinguishability
criterion and the modified mutual information criterion. The obtained
evaluation is based on smoothing of R\'{e}nyi entropy of order 2 and/or min
entropy. We clarify the difference between these two methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1613</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1613</id><created>2013-09-06</created><authors><author><keyname>Pourranjbar</keyname><forenames>Alireza</forenames></author><author><keyname>Hillston</keyname><forenames>Jane</forenames></author></authors><title>An Aggregation Technique For Large-Scale PEPA Models With Non-Uniform
  Populations</title><categories>cs.PF</categories><acm-class>C.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Performance analysis based on modelling consists of two major steps: model
construction and model analysis. Formal modelling techniques significantly aid
model construction but can exacerbate model analysis. In particular, here we
consider the analysis of large-scale systems which consist of one or more
entities replicated many times to form large populations. The replication of
entities in such models can cause their state spaces to grow exponentially to
the extent that their exact stochastic analysis becomes computationally
expensive or even infeasible.
  In this paper, we propose a new approximate aggregation algorithm for a class
of large-scale PEPA models. For a given model, the method quickly checks if it
satisfies a syntactic condition, indicating that the model may be solved
approximately with high accuracy. If so, an aggregated CTMC is generated
directly from the model description. This CTMC can be used for efficient
derivation of an approximate marginal probability distribution over some of the
model's populations. In the context of a large-scale client-server system, we
demonstrate the usefulness of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1621</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1621</id><created>2013-09-06</created><authors><author><keyname>Gao</keyname><forenames>Jian</forenames></author><author><keyname>Shen</keyname><forenames>Linzhi</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>Skew Generalized Quasi-Cyclic Codes over Finite Fields</title><categories>cs.IT math.IT</categories><comments>19</comments><msc-class>94B05, 94B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study a class of generalized quasi-cyclic (GQC) codes called
skew GQC codes. By the factorization theory of ideals, we give the Chinese
Remainder Theorem over the skew polynomial ring, which leads to a canonical
decomposition of skew GQC codes. We also focus on some characteristics of skew
GQC codes in details. For a 1-generator skew GQC code, we define the
parity-check polynomial, determine the dimension and give a lower bound on the
minimum Hamming distance. The skew quasi-cyclic (QC) codes are also discussed
briefly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1623</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1623</id><created>2013-09-06</created><authors><author><keyname>Gao</keyname><forenames>Jian</forenames></author><author><keyname>Shen</keyname><forenames>Linzhi</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>Quasi-Cyclic Codes Over Finite Chain Rings</title><categories>cs.IT math.IT</categories><comments>26</comments><msc-class>11T71, 94B05, 94B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we mainly consider quasi-cyclic (QC) codes over finite chain
rings. We study module structures and trace representations of QC codes, which
lead to some lower bounds on the minimum Hamming distance of QC codes.
Moreover, we investigate the structural properties of 1-generator QC codes.
Under some conditions, we discuss the enumeration of 1-generator QC codes and
describe how to obtain the one and only one generator for each 1-generator QC
code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1625</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1625</id><created>2013-09-06</created><authors><author><keyname>Xiong</keyname><forenames>Hai</forenames></author><author><keyname>Qu</keyname><forenames>Longjiang</forenames></author><author><keyname>Li</keyname><forenames>Chao</forenames></author></authors><title>A New Method to Compute the 2-adic Complexity of Binary Sequences</title><categories>cs.CR</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new method is presented to compute the 2-adic complexity of
pseudo-random sequences. With this method, the 2-adic complexities of all the
known sequences with ideal 2-level autocorrelation are uniformly determined.
Results show that their 2-adic complexities equal their periods. In other
words, their 2-adic complexities attain the maximum. Moreover, 2-adic
complexities of two classes of optimal autocorrelation sequences with period
$N\equiv1\mod4$, namely Legendre sequences and Ding-Helleseth-Lam sequences,
are investigated. Besides, this method also can be used to compute the linear
complexity of binary sequences regarded as sequences over other finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1628</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1628</id><created>2013-09-06</created><updated>2014-02-25</updated><authors><author><keyname>D&#x142;otko</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Specogna</keyname><forenames>Ruben</forenames></author></authors><title>Topology preserving thinning for cell complexes</title><categories>cs.CV</categories><doi>10.1109/TIP.2014.2348799</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A topology preserving skeleton is a synthetic representation of an object
that retains its topology and many of its significant morphological properties.
The process of obtaining the skeleton, referred to as skeletonization or
thinning, is a very active research area. It plays a central role in reducing
the amount of information to be processed during image analysis and
visualization, computer-aided diagnosis or by pattern recognition algorithms.
  This paper introduces a novel topology preserving thinning algorithm which
removes \textit{simple cells}---a generalization of simple points---of a given
cell complex. The test for simple cells is based on \textit{acyclicity tables}
automatically produced in advance with homology computations. Using acyclicity
tables render the implementation of thinning algorithms straightforward.
Moreover, the fact that tables are automatically filled for all possible
configurations allows to rigorously prove the generality of the algorithm and
to obtain fool-proof implementations. The novel approach enables, for the first
time, according to our knowledge, to thin a general unstructured simplicial
complex. Acyclicity tables for cubical and simplicial complexes and an open
source implementation of the thinning algorithm are provided as additional
material to allow their immediate use in the vast number of practical
applications arising in medical imaging and beyond.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1630</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1630</id><created>2013-09-06</created><authors><author><keyname>Casanova</keyname><forenames>Henri</forenames></author><author><keyname>Giersch</keyname><forenames>Arnaud</forenames></author><author><keyname>Legrand</keyname><forenames>Arnaud</forenames></author><author><keyname>Quinson</keyname><forenames>Martin</forenames></author><author><keyname>Suter</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author></authors><title>SimGrid: a Sustained Effort for the Versatile Simulation of Large Scale
  Distributed Systems</title><categories>cs.DC</categories><comments>4 pages, submission to WSSSPE'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present Simgrid, a toolkit for the versatile simulation of
large scale distributed systems, whose development effort has been sustained
for the last fifteen years. Over this time period SimGrid has evolved from a
one-laboratory project in the U.S. into a scientific instrument developed by an
international collaboration. The keys to making this evolution possible have
been securing of funding, improving the quality of the software, and increasing
the user base. In this paper we describe how we have been able to make advances
on all three fronts, on which we plan to intensify our efforts over the
upcoming years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1640</identifier>
 <datestamp>2014-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1640</id><created>2013-09-06</created><updated>2014-01-22</updated><authors><author><keyname>Calero</keyname><forenames>Coral</forenames></author><author><keyname>Moraga</keyname><forenames>M. Angeles</forenames></author><author><keyname>Bertoa</keyname><forenames>Manuel F.</forenames></author></authors><title>Towards a Software Product Sustainability Model</title><categories>cs.SE</categories><comments>4 pages, 3 figures. Paper sent to Workshop on Sustainable Software
  for Science: Practice and Experiences 2013.
  http://wssspe.researchcomputing.org.uk/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The necessity to adapt current products and services into a way of working
environmentally friendly is already a social and economic demand. Although the
GreenIT can be considered a mature discipline, software sustainability, both in
its process and its use, has not begun to be a topic of interest until the last
few years. In this sense we think is fundamental to define what we consider
that is software sustainability and how to evaluate it properly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1644</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1644</id><created>2013-09-06</created><updated>2013-12-29</updated><authors><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Alnuweiri</keyname><forenames>Hussein</forenames></author></authors><title>Power Efficient MISO Beamforming for Secure Layered Transmission</title><categories>cs.IT math.IT</categories><comments>Accepted for presentation at the IEEE Wireless Communications and
  Networking Conference (WCNC), Istanbul, Turkey, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies secure layered video transmission in a multiuser
multiple-input single-output (MISO) beamforming downlink communication system.
The power allocation algorithm design is formulated as a non-convex
optimization problem for minimizing the total transmit power while guaranteeing
a minimum received signal-to-interference-plus-noise ratio (SINR) at the
desired receiver. In particular, the proposed problem formulation takes into
account the self-protecting architecture of layered transmission and artificial
noise generation to prevent potential information eavesdropping. A
semi-definite programming (SDP) relaxation based power allocation algorithm is
proposed to obtain an upper bound solution. A sufficient condition for the
global optimal solution is examined to reveal the tightness of the upper bound
solution. Subsequently, two suboptimal power allocation schemes with low
computational complexity are proposed for enabling secure layered video
transmission. Simulation results demonstrate significant transmit power savings
achieved by the proposed algorithms and layered transmission compared to the
baseline schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1645</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1645</id><created>2013-09-06</created><authors><author><keyname>Hong</keyname><forenames>Dohy</forenames></author></authors><title>Fast ranking algorithm for very large data</title><categories>cs.DS</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new ranking method inspired from previous results
on the diffusion approach to solve linear equation. We describe new
mathematical equations corresponding to this method and show through
experimental results the potential computational gain. This ranking method is
also compared to the well known PageRank model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1649</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1649</id><created>2013-09-06</created><updated>2013-09-10</updated><authors><author><keyname>Choi</keyname><forenames>Jinho D.</forenames></author></authors><title>Preparing Korean Data for the Shared Task on Parsing Morphologically
  Rich Languages</title><categories>cs.CL</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document gives a brief description of Korean data prepared for the SPMRL
2013 shared task. A total of 27,363 sentences with 350,090 tokens are used for
the shared task. All constituent trees are collected from the KAIST Treebank
and transformed to the Penn Treebank style. All dependency trees are converted
from the transformed constituent trees using heuristics and labeling rules de-
signed specifically for the KAIST Treebank. In addition to the gold-standard
morphological analysis provided by the KAIST Treebank, two sets of automatic
morphological analysis are provided for the shared task, one is generated by
the HanNanum morphological analyzer, and the other is generated by the Sejong
morphological analyzer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1656</identifier>
 <datestamp>2015-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1656</id><created>2013-09-06</created><updated>2015-02-23</updated><authors><author><keyname>Mendl</keyname><forenames>Christian B.</forenames></author></authors><title>Matrix-valued Quantum Lattice Boltzmann Method</title><categories>physics.comp-ph cs.NA physics.flu-dyn quant-ph</categories><comments>18 pages</comments><msc-class>65Z05, 76Y05, 82D40, 81-08</msc-class><journal-ref>Int. J. Mod. Phys. C 26, 1550113 (2015)</journal-ref><doi>10.1142/S0129183115501132</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We devise a lattice Boltzmann method (LBM) for a matrix-valued quantum
Boltzmann equation, with the classical Maxwell distribution replaced by
Fermi-Dirac functions. To accommodate the spin density matrix, the distribution
functions become 2 x 2 matrix-valued. From an analytic perspective, the
efficient, commonly used BGK approximation of the collision operator is valid
in the present setting. The numerical scheme could leverage the principles of
LBM for simulating complex spin systems, with applications to spintronics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1677</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1677</id><created>2013-09-06</created><authors><author><keyname>Heiland</keyname><forenames>Randy</forenames></author><author><keyname>Thomas</keyname><forenames>Betsy</forenames></author><author><keyname>Welch</keyname><forenames>Von</forenames></author><author><keyname>Jackson</keyname><forenames>Craig</forenames></author></authors><title>Toward a Research Software Security Maturity Model</title><categories>cs.CR cs.SE</categories><comments>Submission to Workshop on Sustainable Software for Science: Practice
  and Experiences: http://wssspe.researchcomputing.org.uk/</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In its Vision and Strategy for Software for Science, Engineering, and
Education the NSF states that it will invest in activities that: &quot;Recognize
that software strategies must include the secure and reliable deployment and
operation of services, for example by campuses or national facilities or
industry, where identity, authentication, authorization and assurance are
crucial operational capabilities.&quot; and &quot;Result in high-quality, usable, secure,
vulnerability-free, sustainable, robust, well-tested, and
maintainable/evolvable software; and which promotes the sustainability of solid
and useful on-going investments.&quot;
  Such statements evidence that security should indeed be a first-class
consideration of the software ecosystem. In this position paper, we share some
thoughts related to research software security. Our thoughts are based on the
observation that security is not a binary, all-or-nothing attribute, but a
range of practices and requirements depending on how the software is expected
to be deployed and used. We propose that the community leverage the concept of
a maturity model, and work to agree on a research software security maturity
model. This model would categorize different sets of security needs of the
deployment community, and provide software developers a roadmap for advancing
the security maturity of their software. The intent of this paper is not to
express such a comprehensive maturity model, but instead to start a
conversation and set some initial requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1700</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1700</id><created>2013-09-06</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author></authors><title>Towards a Unified Belief Structure in Games with indeterminate
  probabilities</title><categories>cs.GT</categories><comments>Preliminary versions of different parts of this paper were at the 4th
  Formal Epistemology Festival (Konstanz 2012) and the 67th European meeting of
  the Econometric Society (EEA|ESEM 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an analysis of different formal representations of
beliefs in epistemic game theory. The aim is to attempt a synthesis of
different structures of beliefs in the presence of indeterminate probabilities.
Special attention is also paid to the decision-theoretic principle known as the
thesis of no subjective probability for self-action. Conditions in cope with
this principle are given which underlie the interrelationships between
different models of beliefs, and it is shown that under these conditions
different doxastic structures can be coherently unified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1714</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1714</id><created>2013-09-06</created><authors><author><keyname>Olivier</keyname><forenames>Pierre</forenames><affiliation>Lab-STICC</affiliation></author><author><keyname>Boukhobza</keyname><forenames>Jalil</forenames><affiliation>Lab-STICC</affiliation></author><author><keyname>Senn</keyname><forenames>Eric</forenames><affiliation>Lab-STICC</affiliation></author></authors><title>Flashmon V2: Monitoring Raw NAND Flash Memory I/O Requests on Embedded
  Linux</title><categories>cs.OS cs.PF</categories><comments>EWiLi, the Embedded Operating Systems Workshop, Toulouse : France
  (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents Flashmon version 2, a tool for monitoring embedded Linux
NAND flash memory I/O requests. It is designed for embedded boards based
devices containing raw flash chips. Flashmon is a kernel module and stands for
&quot;flash monitor&quot;. It traces flash I/O by placing kernel probes at the NAND
driver level. It allows tracing at runtime the 3 main flash operations: page
reads / writes and block erasures. Flashmon is (1) generic as it was
successfully tested on the three most widely used flash file systems that are
JFFS2, UBIFS and YAFFS, and several NAND chip models. Moreover, it is (2) non
intrusive, (3) has a controllable memory footprint, and (4) exhibits a low
overhead (&lt;6%) on the traced system. Finally, it is (5) simple to integrate and
used as a standalone module or as a built-in function / module in existing
kernel sources. Monitoring flash memory operations allows a better
understanding of existing flash management systems by studying and analyzing
their behavior. Moreover it is useful in development phase for prototyping and
validating new solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1732</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1732</id><created>2013-09-06</created><authors><author><keyname>Angel</keyname><forenames>Eric</forenames></author><author><keyname>Bampis</keyname><forenames>Evripidis</forenames></author><author><keyname>Chau</keyname><forenames>Vincent</forenames></author></authors><title>Throughput Maximization in the Speed-Scaling Setting</title><categories>cs.DS</categories><comments>submitted to SODA 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are given a set of $n$ jobs and a single processor that can vary its speed
dynamically. Each job $J_j$ is characterized by its processing requirement
(work) $p_j$, its release date $r_j$ and its deadline $d_j$. We are also given
a budget of energy $E$ and we study the scheduling problem of maximizing the
throughput (i.e. the number of jobs which are completed on time). We propose a
dynamic programming algorithm that solves the preemptive case of the problem,
i.e. when the execution of the jobs may be interrupted and resumed later, in
pseudo-polynomial time. Our algorithm can be adapted for solving the weighted
version of the problem where every job is associated with a weight $w_j$ and
the objective is the maximization of the sum of the weights of the jobs that
are completed on time. Moreover, we provide a strongly polynomial time
algorithm to solve the non-preemptive unweighed case when the jobs have the
same processing requirements. For the weighted case, our algorithm can be
adapted for solving the non-preemptive version of the problem in
pseudo-polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1737</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1737</id><created>2013-09-02</created><updated>2014-09-12</updated><authors><author><keyname>Katsevich</keyname><forenames>Gene</forenames></author><author><keyname>Katsevich</keyname><forenames>Alexander</forenames></author><author><keyname>Singer</keyname><forenames>Amit</forenames></author></authors><title>Covariance Matrix Estimation for the Cryo-EM Heterogeneity Problem</title><categories>math.NA cs.NA physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cryo-electron microscopy (cryo-EM), a microscope generates a top view of a
sample of randomly-oriented copies of a molecule. The problem of single
particle reconstruction (SPR) from cryo-EM is to use the resulting set of noisy
2D projection images taken at unknown directions to reconstruct the 3D
structure of the molecule. In some situations, the molecule under examination
exhibits structural variability, which poses a fundamental challenge in SPR.
The heterogeneity problem is the task of mapping the space of conformational
states of a molecule. It has been previously suggested that the leading
eigenvectors of the covariance matrix of the 3D molecules can be used to solve
the heterogeneity problem. Estimating the covariance matrix is challenging,
since only projections of the molecules are observed, but not the molecules
themselves. In this paper, we formulate a general problem of covariance
estimation from noisy projections of samples. This problem has intimate
connections with matrix completion problems and high-dimensional principal
component analysis. We propose an estimator and prove its consistency. When
there are finitely many heterogeneity classes, the spectrum of the estimated
covariance matrix reveals the number of classes. The estimator can be found as
the solution to a certain linear system. In the cryo-EM case, the linear
operator to be inverted, which we term the projection covariance transform, is
an important object in covariance estimation for tomographic problems involving
structural variation. Inverting it involves applying a filter akin to the ramp
filter in tomography. We design a basis in which this linear operator is sparse
and thus can be tractably inverted despite its large size. We demonstrate via
numerical experiments on synthetic datasets the robustness of our algorithm to
high levels of noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1747</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1747</id><created>2013-09-06</created><authors><author><keyname>Bernstein</keyname><forenames>Garrett</forenames></author><author><keyname>O'Brien</keyname><forenames>Kyle</forenames></author></authors><title>Stochastic Agent-Based Simulations of Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>Won Best Paper Award. This work is sponsored by the Assistant
  Secretary of Defense for Research &amp; Engineering under Air Force Contract
  #FA8721-05-C-0002. Opinions, interpretations, conclusions and recommendations
  are those of the author and are not necessarily endorsed by the United States
  Government</comments><journal-ref>Bernstein, G. and O'Brien, K. 'Stochastic Agent-Based Simulations
  of Social Networks.' Proceedings of 46th Annual Simulation Symposium, San
  Diego, 7-10 April 2013. 33-40. Print</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapidly growing field of network analytics requires data sets for use in
evaluation. Real world data often lack truth and simulated data lack narrative
fidelity or statistical generality. This paper presents a novel,
mixed-membership, agentbased simulation model to generate activity data with
narrative power while providing statistical diversity through random draws. The
model generalizes to a variety of network activity types such as Internet and
cellular communications, human mobility, and social network interactions. The
simulated actions over all agents can then drive an application specific
observational model to render measurements as one would collect in real-world
experiments. We apply this framework to human mobility and demonstrate its
utility in generating high fidelity traffic data for network analytics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1761</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1761</id><created>2013-09-06</created><authors><author><keyname>Joseph</keyname><forenames>Shaun N.</forenames></author><author><keyname>Bakr</keyname><forenames>Seif Omar Abu</forenames></author><author><keyname>Lugo</keyname><forenames>Gabriel</forenames></author></authors><title>Convergence of Nearest Neighbor Pattern Classification with Selective
  Sampling</title><categories>cs.LG stat.ML</categories><comments>18 pages, 2 figures, mZeal Communications Technical Report</comments><msc-class>60G25</msc-class><acm-class>F.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the panoply of pattern classification techniques, few enjoy the intuitive
appeal and simplicity of the nearest neighbor rule: given a set of samples in
some metric domain space whose value under some function is known, we estimate
the function anywhere in the domain by giving the value of the nearest sample
per the metric. More generally, one may use the modal value of the m nearest
samples, where m is a fixed positive integer (although m=1 is known to be
admissible in the sense that no larger value is asymptotically superior in
terms of prediction error). The nearest neighbor rule is nonparametric and
extremely general, requiring in principle only that the domain be a metric
space. The classic paper on the technique, proving convergence under
independent, identically-distributed (iid) sampling, is due to Cover and Hart
(1967). Because taking samples is costly, there has been much research in
recent years on selective sampling, in which each sample is selected from a
pool of candidates ranked by a heuristic; the heuristic tries to guess which
candidate would be the most &quot;informative&quot; sample. Lindenbaum et al. (2004)
apply selective sampling to the nearest neighbor rule, but their approach
sacrifices the austere generality of Cover and Hart; furthermore, their
heuristic algorithm is complex and computationally expensive. Here we report
recent results that enable selective sampling in the original Cover-Hart
setting. Our results pose three selection heuristics and prove that their
nearest neighbor rule predictions converge to the true pattern. Two of the
algorithms are computationally cheap, with complexity growing linearly in the
number of samples. We believe that these results constitute an important
advance in the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1776</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1776</id><created>2013-09-06</created><authors><author><keyname>Grochow</keyname><forenames>Joshua A.</forenames></author><author><keyname>Qiao</keyname><forenames>Youming</forenames></author></authors><title>Algorithms for group isomorphism via group extensions and cohomology</title><categories>cs.DS cs.CC math.GR</categories><comments>34 pages + 7-page appendix</comments><msc-class>20C40, 68Q25</msc-class><acm-class>I.1.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The isomorphism problem for groups given by multiplication tables (GpI) is
well-known to be solvable in n^O(log n) time, but only recently has there been
significant progress. For example, in 2012 Babai et al. gave a polynomial-time
algorithm for groups with no abelian normal subgroups. Thus it is crucial to
understand groups with abelian normal subgroups to develop n^o(log n)-time
algorithms.
  We advocate a strategy via the extension theory of groups, which describes
how a normal subgroup N is related to G/N via G. This strategy &quot;splits&quot; GpI
into two subproblems: one on group actions and one on group cohomology. The
solution of these problems is essentially necessary and sufficient to solve
GpI. Previous works naturally align with this strategy, and it thus helps
explain in a unified way the recent successes on other group classes. In
particular, most results in the Cayley table model focus on the group action
aspect, despite the general necessity of cohomology.
  To make progress on the cohomology aspect we consider central-radical groups,
proposed by Babai et al.: groups whose solvable normal subgroups are contained
in the center. (Babai et al. considered groups with no solvable normal
subgroups.) Following the above strategy, we solve GpI in n^O(log log n) time
for central-radical groups, and in polynomial time for several prominent
subclasses of central-radical groups. We achieve the same time bounds for
groups whose solvable normal subgroups are elementary abelian but not central.
  Prior to our work, the easy n^O(log n) algorithm was the best known even for
groups with a central radical of size 2. We use several mathematical results on
the detailed structure of cohomology classes, as well as algorithms for code
equivalence, coset intersection and cyclicity testing of modules over
finite-dimensional algebras. We also suggest several promising directions for
future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1779</identifier>
 <datestamp>2014-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1779</id><created>2013-09-06</created><updated>2014-04-11</updated><authors><author><keyname>Joosten</keyname><forenames>Joost J.</forenames></author><author><keyname>Soler-Toscano</keyname><forenames>Fernando</forenames></author><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>Fractal dimension versus computational complexity</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we look at small Turing machines (TMs) that work with just two
colors (alphabet symbols) and either two or three states. For any particular
such machine $\tau$ and any particular input $x$ we consider what we call the
\emph{space-time} diagram which basically is just the collection of consecutive
tape configurations of the computation $\tau(x)$.
  In our setting it makes sense to define a fractal dimension for a Turing
machine as the limiting fractal dimension for the corresponding space-time
diagrams. It turns out that there is a very strong relation between the fractal
dimension of a Turing machine of the above specified type and its runtime
complexity.
  In particular, a TM with three states and two colors runs in at most linear
time iff its dimension is 2, and its dimension is 1 iff it runs in
super-polynomial time and it uses polynomial space. If a TM runs in time
${\mathcal O} {(x^n)}$ we have empirically verified that the corresponding
dimension is $\frac{n+1}{n}$, a result that we can only partially prove.
  We find the results presented here remarkable because they relate two
completely different complexity measures: the geometrical fractal dimension on
the one side versus the time complexity of a computation on the other side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1780</identifier>
 <datestamp>2014-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1780</id><created>2013-09-06</created><authors><author><keyname>Dubey</keyname><forenames>A.</forenames></author><author><keyname>Brandt</keyname><forenames>S.</forenames></author><author><keyname>Brower</keyname><forenames>R.</forenames></author><author><keyname>Giles</keyname><forenames>M.</forenames></author><author><keyname>Hovland</keyname><forenames>P.</forenames></author><author><keyname>Lamb</keyname><forenames>D. Q.</forenames></author><author><keyname>Loffler</keyname><forenames>F.</forenames></author><author><keyname>Norris</keyname><forenames>B.</forenames></author><author><keyname>OShea</keyname><forenames>B.</forenames></author><author><keyname>Rebbi</keyname><forenames>C.</forenames></author><author><keyname>Snir</keyname><forenames>M.</forenames></author><author><keyname>Thakur</keyname><forenames>R.</forenames></author></authors><title>Software Abstractions and Methodologies for HPC Simulation Codes on
  Future Architectures</title><categories>cs.CE cs.MS cs.SE</categories><comments>Position Paper</comments><doi>10.5334/jors.aw</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large, complex, multi-scale, multi-physics simulation codes, running on high
performance com-puting (HPC) platforms, have become essential to advancing
science and engineering. These codes simulate multi-scale, multi-physics
phenomena with unprecedented fidelity on petascale platforms, and are used by
large communities. Continued ability of these codes to run on future platforms
is as crucial to their communities as continued improvements in instruments and
facilities are to experimental scientists. However, the ability of code
developers to do these things faces a serious challenge with the paradigm shift
underway in platform architecture. The complexity and uncertainty of the future
platforms makes it essential to approach this challenge cooperatively as a
community. We need to develop common abstractions, frameworks, programming
models and software development methodologies that can be applied across a
broad range of complex simulation codes, and common software infrastructure to
support them. In this position paper we express and discuss our belief that
such an infrastructure is critical to the deployment of existing and new large,
multi-scale, multi-physics codes on future HPC platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1781</identifier>
 <datestamp>2014-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1781</id><created>2013-09-06</created><authors><author><keyname>Dubey</keyname><forenames>A.</forenames></author><author><keyname>Van Straalen</keyname><forenames>B.</forenames></author></authors><title>Experiences from Software Engineering of Large Scale AMR Multiphysics
  Code Frameworks</title><categories>cs.CE cs.MS cs.SE</categories><comments>Experience Report</comments><doi>10.5334/jors.am</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among the present generation of multiphysics HPC simulation codes there are
many that are built upon general infrastructural frameworks. This is especially
true of the codes that make use of structured adaptive mesh refinement (SAMR)
because of unique demands placed on the housekeeping aspects of the code. They
have varying degrees of abstractions between the infrastructure such as mesh
management and IO and the numerics of the physics solvers. In this experience
report we summarize the experiences and lessons learned from two of such major
software efforts, FLASH and Chombo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1783</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1783</id><created>2013-09-06</created><updated>2013-09-15</updated><authors><author><keyname>Blatt</keyname><forenames>Makus</forenames></author></authors><title>DUNE as an Example of Sustainable Open Source Scientific Software
  Development</title><categories>cs.MS cs.SE</categories><acm-class>D.2.9; K.6.1; K.6.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we describe how DUNE, an open source scientific software
framework, is developed. Having a sustainable software framework for the
solution of partial differential equations is the main driver of DUNE's
development. We take a look how DUNE strives to stay sustainable software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1784</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1784</id><created>2013-09-06</created><updated>2013-12-14</updated><authors><author><keyname>Koop</keyname><forenames>David</forenames></author><author><keyname>Freire</keyname><forenames>Juliana</forenames></author><author><keyname>Silva</keyname><forenames>Claudio T.</forenames></author></authors><title>Enabling Reproducible Science with VisTrails</title><categories>cs.SE cs.DB</categories><comments>Accepted for WSSSPE 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing amount of data and use of computation in science,
software has become an important component in many different domains. Computing
is now being used more often and in more aspects of scientific work including
data acquisition, simulation, analysis, and visualization. To ensure
reproducibility, it is important to capture the different computational
processes used as well as their executions. VisTrails is an open-source
scientific workflow system for data analysis and visualization that seeks to
address the problem of integrating varied tools as well as automatically
documenting the methods and parameters employed. Growing from a specific
project need to supporting a wide array of users required close collaborations
in addition to new research ideas to design a usable and efficient system. The
VisTrails project now includes standard software processes like unit testing
and developer documentation while serving as a base for further research. In
this paper, we describe how VisTrails has developed and how our efforts in
structuring and advertising the system have contributed to its adoption in many
domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1785</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1785</id><created>2013-09-06</created><authors><author><keyname>Graells-Garrido</keyname><forenames>Eduardo</forenames></author><author><keyname>Poblete</keyname><forenames>Barbara</forenames></author></authors><title>#Santiago is not #Chile, or is it? A Model to Normalize Social Media
  Impact</title><categories>cs.SI physics.soc-ph</categories><comments>Accepted in ChileCHI 2013, I Chilean Conference on Human-Computer
  Interaction</comments><acm-class>H.3.3</acm-class><doi>10.1145/2535597.2535611</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Online social networks are known to be demographically biased. Currently
there are questions about what degree of representativity of the physical
population they have, and how population biases impact user-generated content.
In this paper we focus on centralism, a problem affecting Chile. Assuming that
local differences exist in a country, in terms of vocabulary, we built a
methodology based on the vector space model to find distinctive content from
different locations, and use it to create classifiers to predict whether the
content of a micro-post is related to a particular location, having in mind a
geographically diverse selection of micro-posts. We evaluate them in a case
study where we analyze the virtual population of Chile that participated in the
Twitter social network during an event of national relevance: the municipal
(local governments) elections held in 2012. We observe that the participating
virtual population is spatially representative of the physical population,
implying that there is centralism in Twitter. Our classifiers out-perform a non
geographically-diverse baseline at the regional level, and have the same
accuracy at a provincial level. However, our approach makes assumptions that
need to be tested in multi-thematic and more general datasets. We leave this
for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1788</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1788</id><created>2013-09-06</created><authors><author><keyname>Remy</keyname><forenames>Sekou L.</forenames></author></authors><title>Web Standards as Standard Pieces in Robotics</title><categories>cs.SY cs.RO</categories><comments>9th Annual IEEE International Conference on Automation Science and
  Engineering (IEEE CASE 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern robotics often involves the use of web technologies as a means to cope
with the complexity of design and operation. Many of these technologies have
been formalized into standards, which are often avoided by those in robotics
and controls because of a sometimes warranted fear that &quot;the web&quot; is too slow,
or too uncertain for meaningful control applications.
  In this work we argue that while web technologies may not be applicable for
all control, they should not be dismissed outright because they can provide
critical help with system integration. Web technologies have also advanced
significantly over the past decade. We present the details of an application of
a web server to perform open and close-loop control (between 3Hz and 1kHz) over
a variety of different network topologies. In our study we also consider the
impact of a web browser to implement the control of the plant. Our results
confirm that meaningful control can be performed using web technologies, and
also highlight design choices that can limit their applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1792</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1792</id><created>2013-09-06</created><authors><author><keyname>Johnson</keyname><forenames>Troy</forenames></author><author><keyname>Seeling</keyname><forenames>Patrick</forenames></author></authors><title>Desktop and Mobile Web Page Comparison: Characteristics, Trends, and
  Implications</title><categories>cs.HC cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The broad proliferation of mobile devices in recent years has drastically
changed the means of accessing the World Wide Web. Describing a shift away from
the desktop computer era for content consumption, predictions indicate that the
main access of web-based content will come from mobile devices. Concurrently,
the manner of content presentation has changed as well; web artifacts are
allowing for richer media and higher levels of user interaction which is
enabled through increasing access networks speeds. This article provides an
overview of more than two years of high level web page characteristics by
comparing the desktop and mobile client versions. Our study is the first
long-term evaluation of differences as seen by desktop and mobile web browser
clients. We showcase the main differentiating factors with respect to the
number of web page object requests, their sizes, relationships, and web page
object caching. We additionally highlight long-term trends and discuss their
future implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1794</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1794</id><created>2013-09-06</created><authors><author><keyname>Shafi</keyname><forenames>S. Yusef</forenames></author><author><keyname>Arcak</keyname><forenames>Murat</forenames></author></authors><title>An Adaptive Algorithm for Synchronization in Diffusively Coupled Systems</title><categories>math.DS cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an adaptive algorithm that guarantees synchronization in
diffusively coupled systems. We first consider compartmental systems of ODEs,
where each compartment represents a spatial domain of components interconnected
through diffusion terms with like components in different compartments. Each
set of like components may have its own weighted undirected graph describing
the topology of the interconnection between compartments. The link weights are
updated adaptively according to the magnitude of the difference between
neighboring agents connected by the link. We next consider reaction-diffusion
PDEs with Neumann boundary conditions, and derive an analogous algorithm
guaranteeing spatial homogenization of solutions. We provide a numerical
example demonstrating the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1795</identifier>
 <datestamp>2014-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1795</id><created>2013-09-06</created><authors><author><keyname>Beguerisse-D&#xed;az</keyname><forenames>Mariano</forenames></author><author><keyname>Vangelov</keyname><forenames>Borislav</forenames></author><author><keyname>Barahona</keyname><forenames>Mauricio</forenames></author></authors><title>Finding role communities in directed networks using Role-Based
  Similarity, Markov Stability and the Relaxed Minimum Spanning Tree</title><categories>cs.SI physics.soc-ph q-bio.NC</categories><comments>4 pages, 2 figures</comments><journal-ref>Global Conference on Signal and Information Processing
  (GlobalSIP), 2013 IEEE, pp.937,940, 3-5 Dec. 2013</journal-ref><doi>10.1109/GlobalSIP.2013.6737046</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework to cluster nodes in directed networks according to
their roles by combining Role-Based Similarity (RBS) and Markov Stability, two
techniques based on flows. First we compute the RBS matrix, which contains the
pairwise similarities between nodes according to the scaled number of in- and
out-directed paths of different lengths. The weighted RBS similarity matrix is
then transformed into an undirected similarity network using the Relaxed
Minimum-Spanning Tree (RMST) algorithm, which uses the geometric structure of
the RBS matrix to unblur the network, such that edges between nodes with high,
direct RBS are preserved. Finally, we partition the RMST similarity network
into role-communities of nodes at all scales using Markov Stability to find a
robust set of roles in the network. We showcase our framework through a
biological and a man-made network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1796</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1796</id><created>2013-09-06</created><authors><author><keyname>Ahern</keyname><forenames>Sean</forenames></author><author><keyname>Brugger</keyname><forenames>Eric</forenames></author><author><keyname>Whitlock</keyname><forenames>Brad</forenames></author><author><keyname>Meredith</keyname><forenames>Jeremy S.</forenames></author><author><keyname>Biagas</keyname><forenames>Kathleen</forenames></author><author><keyname>Miller</keyname><forenames>Mark C.</forenames></author><author><keyname>Childs</keyname><forenames>Hank</forenames></author></authors><title>VisIt: Experiences with Sustainable Software</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The success of the VisIt visualization system has been wholly dependent upon
the culture and practices of software development that have fostered its
welcome by users and embrace by developers and researchers. In the following
paper, we, the founding developers and designers of VisIt, summarize some of
the major efforts, both successful and unsuccessful, that we have undertaken in
the last thirteen years to foster community, encourage research, create a
sustainable open-source development model, measure impact, and support
production software. We also provide commentary about the career paths that our
development work has engendered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1805</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1805</id><created>2013-09-06</created><updated>2013-09-11</updated><authors><author><keyname>Zentner</keyname><forenames>Lynn</forenames></author><author><keyname>Zentner</keyname><forenames>Michael</forenames></author><author><keyname>Farnsworth</keyname><forenames>Victoria</forenames></author><author><keyname>McLennan</keyname><forenames>Michael</forenames></author><author><keyname>Madhavan</keyname><forenames>Krishna</forenames></author><author><keyname>Klimeck</keyname><forenames>Gerhard</forenames></author></authors><title>nanoHUB.org: Experiences and Challenges in Software Sustainability for a
  Large Scientific Community</title><categories>cs.SE cs.CE cs.DL</categories><comments>4 pages, 1 figure, this version contains minor revisions to correct
  an acronym, update a quotation, improve grammar, and add a reference</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Managing and growing a successful cyberinfrastructure such as nanoHUB.org
presents a variety of opportunities and challenges, particularly in regard to
software. This position paper details a number of those issues and how we have
approached them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1806</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1806</id><created>2013-09-06</created><authors><author><keyname>Huang</keyname><forenames>Daisie</forenames></author><author><keyname>Lapp</keyname><forenames>Hilmar</forenames></author></authors><title>Software Engineering as Instrumentation for the Long Tail of Scientific
  Software</title><categories>cs.SE</categories><comments>4 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The vast majority of the long tail of scientific software, the myriads of
tools that implement the many analysis and visualization methods for different
scientific fields, is highly specialized, purpose-built for a research project,
and has to rely on community uptake and reuse for its continued development and
maintenance. Although uptake cannot be controlled over even guaranteed, some of
the key factors that influence whether new users or developers decide to adopt
an existing tool or start a new one are about how easy or difficult it is to
use or enhance a tool for a purpose for which it was not originally designed.
The science of software engineering has produced techniques and practices that
would reduce or remove a variety of barriers to community uptake of software,
but for a variety of reasons employing trained software engineers as part of
the development of long tail scientific software has proven to be challenging.
As a consequence, community uptake of long tail tools is often far more
difficult than it would need to be, even though opportunities for reuse abound.
We discuss likely reasons why employing software engineering in the long tail
is challenging, and propose that many of those obstacles could be addressed in
the form of a cross-cutting non-profit center of excellence that makes software
engineering broadly accessible as a shared service, conceptually and in its
effect similar to shared instrumentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1807</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1807</id><created>2013-09-06</created><authors><author><keyname>Wang</keyname><forenames>Haitao</forenames></author></authors><title>Aggregate-Max Nearest Neighbor Searching in the Plane</title><categories>cs.CG cs.DB cs.DS</categories><comments>17 pages, 14 figures; preliminary results appeared in CCCG 2013, and
  in this new version we extend the top-1 queries to top-k queries for the L_1
  case</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the aggregate/group nearest neighbor searching for the MAX operator
in the plane. For a set $P$ of $n$ points and a query set $Q$ of $m$ points,
the query asks for a point of $P$ whose maximum distance to the points in $Q$
is minimized. We present data structures for answering such queries for both
$L_1$ and $L_2$ distance measures. Previously, only heuristic and approximation
algorithms were given for both versions. For the $L_1$ version, we build a data
structure of O(n) size in $O(n\log n)$ time, such that each query can be
answered in $O(m+\log n)$ time. For the $L_2$ version, we build a data
structure in $O(n\log n)$ time and $O(n\log \log n)$ space, such that each
query can be answered in $O(m\sqrt{n}\log^{O(1)} n)$ time, and alternatively,
we build a data structure in $O(n^{2+\epsilon})$ time and space for any
$\epsilon&gt;0$, such that each query can be answered in $O(m\log n)$ time.
Further, we extend our result for the $L_1$ version to the top-$k$ queries
where each query asks for the $k$ points of $P$ whose maximum distances to $Q$
are the smallest for any $k$ with $1\leq k\leq n$: We build a data structure of
O(n) size in $O(n\log n)$ time, such that each top-$k$ query can be answered in
$O(m+k\log n)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1810</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1810</id><created>2013-09-06</created><authors><author><keyname>Weber</keyname><forenames>Nicholas</forenames></author><author><keyname>Thomer</keyname><forenames>Andrea</forenames></author><author><keyname>Twidale</keyname><forenames>Michael</forenames></author></authors><title>Niche Modeling: Ecological Metaphors for Sustainable Software in Science</title><categories>cs.SE cs.CY</categories><comments>Position paper submitted to: Workshop on Sustainable Software for
  Science: Practice and Experiences (WSSSPE) SC13, Sunday, 17 November 2013,
  Denver, CO, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This position paper is aimed at providing some history and provocations for
the use of an ecological metaphor to describe software development
environments. We do not claim that the ecological metaphor is the best or only
way of looking at software - rather we want to ask if it can indeed be a
productive and thought provoking one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1811</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1811</id><created>2013-09-06</created><authors><author><keyname>Perera</keyname><forenames>Charith</forenames></author><author><keyname>Zaslavsky</keyname><forenames>Arkady</forenames></author><author><keyname>Compton</keyname><forenames>Michael</forenames></author><author><keyname>Christen</keyname><forenames>Peter</forenames></author><author><keyname>Georgakopoulos</keyname><forenames>Dimitrios</forenames></author></authors><title>Context Aware Sensor Configuration Model for Internet of Things</title><categories>cs.NI cs.SE</categories><comments>12th International Semantic Web Conference (Posters &amp; Demos) (ISWC),
  Sydney, Australia, October, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a Context Aware Sensor Configuration Model (CASCoM) to address the
challenge of automated context-aware configuration of filtering, fusion, and
reasoning mechanisms in IoT middleware according to the problems at hand. We
incorporate semantic technologies in solving the above challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1812</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1812</id><created>2013-09-06</created><updated>2013-09-15</updated><authors><author><keyname>L&#xf6;ffler</keyname><forenames>Frank</forenames></author><author><keyname>Brandt</keyname><forenames>Steven R.</forenames></author><author><keyname>Allen</keyname><forenames>Gabrielle</forenames></author><author><keyname>Schnetter</keyname><forenames>Erik</forenames></author></authors><title>Cactus: Issues for Sustainable Simulation Software</title><categories>cs.CE cs.MS cs.SE</categories><comments>submitted to the Workshop on Sustainable Software for Science:
  Practice and Experiences 2013</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Cactus Framework is an open-source, modular, portable programming
environment for the collaborative development and deployment of scientific
applications using high-performance computing. Its roots reach back to 1996 at
the National Center for Supercomputer Applications and the Albert Einstein
Institute in Germany, where its development jumpstarted. Since then, the Cactus
framework has witnessed major changes in hardware infrastructure as well as its
own community. This paper describes its endurance through these past changes
and, drawing upon lessons from its past, also discusses future
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1813</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1813</id><created>2013-09-06</created><authors><author><keyname>Maheshwari</keyname><forenames>Ketan</forenames></author><author><keyname>Kelly</keyname><forenames>David</forenames></author><author><keyname>Krieder</keyname><forenames>Scott J.</forenames></author><author><keyname>Wozniak</keyname><forenames>Justin M.</forenames></author><author><keyname>Katz</keyname><forenames>Daniel S.</forenames></author><author><keyname>Zhi-Gang</keyname><forenames>Mei</forenames></author><author><keyname>Mookherjee</keyname><forenames>Mainak</forenames></author></authors><title>Reusability in Science: From Initial User Engagement to Dissemination of
  Results</title><categories>cs.SE cs.DC</categories><comments>5 pages, WSSSPE 2013 workshop</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Effective use of parallel and distributed computing in science depends upon
multiple interdependent entities and activities that form an ecosystem. Active
engagement between application users and technology catalysts is a crucial
activity that forms an integral part of this ecosystem. Technology catalysts
play a crucial role benefiting communities beyond a single user group. An
effective user-engagement, use and reuse of tools and techniques has a broad
impact on software sustainability. From our experience, we sketch a life-cycle
for user-engagement activity in scientific computational environment and posit
that application level reusability promotes software sustainability. We
describe our experience in engaging two user groups from different scientific
domains reusing a common software and configuration on different computational
infrastructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1815</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1815</id><created>2013-09-06</created><updated>2013-09-16</updated><authors><author><keyname>Xu</keyname><forenames>Jie</forenames></author><author><keyname>Song</keyname><forenames>Yangbo</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Information Sharing in Networks of Strategic Agents</title><categories>cs.GT</categories><doi>10.1109/JSTSP.2014.2316597</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To ensure that social networks (e.g. opinion consensus, cooperative
estimation, distributed learning and adaptation etc.) proliferate and
efficiently operate, the participating agents need to collaborate with each
other by repeatedly sharing information. However, sharing information is often
costly for the agents while resulting in no direct immediate benefit for them.
Hence, lacking incentives to collaborate, strategic agents who aim to maximize
their own individual utilities will withhold rather than share information,
leading to inefficient operation or even collapse of networks. In this paper,
we develop a systematic framework for designing distributed rating protocols
aimed at incentivizing the strategic agents to collaborate with each other by
sharing information. The proposed incentive protocols exploit the ongoing
nature of the agents' interactions to assign ratings and through them,
determine future rewards and punishments: agents that have behaved as directed
enjoy high ratings -- and hence greater future access to the information of
others; agents that have not behaved as directed enjoy low ratings -- and hence
less future access to the information of others. Unlike existing rating
protocols, the proposed protocol operates in a distributed manner, online, and
takes into consideration the underlying interconnectivity of agents as well as
their heterogeneity. We prove that in many deployment scenarios the price of
anarchy (PoA) obtained by adopting the proposed rating protocols is one. In
settings in which the PoA is larger than one, we show that the proposed rating
protocol still significantly outperforms existing incentive mechanisms such as
Tit-for-Tat. Importantly, the proposed rating protocols can also operate
efficiently in deployment scenarios where the strategic agents interact over
time-varying network topologies where new agents join the network over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1817</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1817</id><created>2013-09-07</created><authors><author><keyname>Stewart</keyname><forenames>Craig A.</forenames></author><author><keyname>Wernert</keyname><forenames>Julie</forenames></author><author><keyname>Wernert</keyname><forenames>Eric A.</forenames></author><author><keyname>Barnett</keyname><forenames>William K.</forenames></author><author><keyname>Welch</keyname><forenames>Von</forenames></author></authors><title>Initial Findings from a Study of Best Practices and Models for
  Cyberinfrastructure Software Sustainability</title><categories>cs.SE</categories><comments>Workshop on Sustainable Software: Practices and Experiences, 4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a set of common themes and recommendations extracted from in depth
interviews with the leaders of 12 distinct cyberinfrastructure software
projects. These interviews were conducted as part of a larger study to identify
and elucidate the best practices and management models that lead to
sustainability for cyberinfrastructure software. Respondents in a formal survey
of cyberinfrastructure users identified these projects as good examples of
sustained software initiatives. While there is clearly no single method or plan
that will guarantee sustainability for all projects, we can draw general
guidance from these exemplars. This paper presents the common themes, ideas,
and recommendations that emerged from those interviews.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1818</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1818</id><created>2013-09-07</created><authors><author><keyname>Mehdi</keyname><forenames>Haider</forenames></author><author><keyname>Soomro</keyname><forenames>Safeeullah</forenames></author><author><keyname>Khan</keyname><forenames>W. R.</forenames></author><author><keyname>Memon</keyname><forenames>Abdul Ghafoor</forenames></author><author><keyname>Hafeez</keyname><forenames>Abdul</forenames></author></authors><title>Error-Rate Performance Analysis of Wireless Sensor Networks over Fading
  Channels</title><categories>cs.NI</categories><comments>Four figures</comments><journal-ref>SURJ (Science Series) Volume 45 Pages 177-182 (2013)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we analyze the bit-error-rate (BER) performance of wireless
sensor networks. A wireless sensor node with a single transmitter antenna and
multiple receiver antennas is considered here. We consider M (M greater or
equal ro 1) receiver antennas to mitigate channel fading effects. BER
performance is analyzed in the presence of a co-channel interference source.
Wireless channel is assumed to follow independently Nakagami fading for the
wireless sensor network and Rayleigh fading for the interference signal. Based
on the derived analytical expressions, the effects of different fading channel
and co-channel interference parameters on the BER performance of wireless
sensor networks are assessed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1823</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1823</id><created>2013-09-07</created><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author><author><keyname>Karwan</keyname><forenames>M. H.</forenames></author></authors><title>On Limits to the Scope of the Extended Formulations &quot;Barriers&quot;</title><categories>cs.DM cs.CC math.CO math.OC</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce the notion of augmentation for polytopes and use
it to show the error in two presumptions that have been key in arriving at
over-reaching/over-scoped claims of &quot;impossibility&quot; in recent extended
formulations (EF) developments. One of these presumptions is that: &quot;If
Polytopes P and Q are described in the spaces of variables x and y
respectively, and there exists a linear map x=Ay between the feasible sets of P
and Q, then Q is an EF of P&quot;. The other is: &quot;(An augmentation of Polytope A
projects to Polytope B) ==&gt; (The external descriptions of A and B are
related)&quot;. We provide counter-examples to these presumptions, and show that in
general: (1) If polytopes can always be arbitrarily augmented for the purpose
of establishing EF relations, then the notion of EF becomes
degenerate/meaningless in some cases, and that: (2) The statement: &quot;(Polytope B
is the projection of an augmentation of Polytope A) ==&gt; (Polytope B is the
projection of Polytope A)&quot; is not true in general (although, as we show, the
converse statement, &quot;(B is the projection of A) ==&gt; (B is the projection of
every augmentation of A)&quot;, is true in general). We illustrate some of the ideas
using the minimum spanning tree problem, as well as the &quot;lower bounds&quot;
developments in Fiorini et al. (2011; 2012), in particular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1825</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1825</id><created>2013-09-07</created><authors><author><keyname>Anari</keyname><forenames>Fatemeh</forenames></author><author><keyname>Asemi</keyname><forenames>Asefeh</forenames></author><author><keyname>Asemi</keyname><forenames>Adeleh</forenames></author><author><keyname>Bakar</keyname><forenames>Munir Abu</forenames></author></authors><title>Social Interactive Media Tools and Knowledge Sharing: A Case Study</title><categories>cs.DL cs.SI</categories><comments>17 pages, 23 Tables</comments><msc-class>91D30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Social Media Tools (SMT) have provided new opportunities for
libraries and librarians in the world. In academic libraries, we can use of
them as a powerful tool for communication. This study is to determine the use
of the social interactive media tools [Social Networking Tools (SNT), Social
Bookmarking Tools (SBT), Image or Video Sharing Tools (IVShT), and Mashup Tools
(MT)] in disseminating knowledge and information among librarians in the
Limerick University, Ireland. Methodology: The study was a descriptive survey.
The research population included all librarians in Glucksman library. A
questionnaire survey was done to collect data. Statistical software, SPSS16 was
used at two levels (descriptive and inferential statistics) for data analyzing.
Findings: The findings show that the mean (out of 5.00) of using each of SMT in
sharing knowledge by the librarians of Glucksman library is as the following:
SNT (2.49), SBT (2.92), IVShT (2.99) and MT (2.5). It shows that most of their
interaction related to share of image or video. Originality: SMT provides an
excellent platform for the exchange information between students, faculty
members, and the librarians themselves. The Glucksman library at the University
of Limerick is using this technology. This paper gives an example of how using
these tools in the field of Library and Information Science in Ireland. The
issues expressed could be beneficial for the development of library services in
general and knowledge sharing among librarians in particular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1828</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1828</id><created>2013-09-07</created><updated>2013-10-26</updated><authors><author><keyname>Swenson</keyname><forenames>Shel</forenames></author><author><keyname>Simmhan</keyname><forenames>Yogesh</forenames></author><author><keyname>Prasanna</keyname><forenames>Viktor</forenames></author><author><keyname>Parashar</keyname><forenames>Manish</forenames></author><author><keyname>Riedy</keyname><forenames>Jason</forenames></author><author><keyname>Bader</keyname><forenames>David</forenames></author><author><keyname>Vuduc</keyname><forenames>Richard</forenames></author></authors><title>Sustainable Software Development for Next-Gen Sequencing (NGS)
  Bioinformatics on Emerging Platforms</title><categories>cs.CE cs.DC</categories><comments>4 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  DNA sequence analysis is fundamental to life science research. The rapid
development of next generation sequencing (NGS) technologies, and the richness
and diversity of applications it makes feasible, have created an enormous gulf
between the potential of this technology and the development of computational
methods to realize this potential. Bridging this gap holds possibilities for
broad impacts toward multiple grand challenges and offers unprecedented
opportunities for software innovation and research. We argue that NGS-enabled
applications need a critical mass of sustainable software to benefit from
emerging computing platforms' transformative potential. Accumulating the
necessary critical mass will require leaders in computational biology,
bioinformatics, computer science, and computer engineering work together to
identify core opportunity areas, critical software infrastructure, and software
sustainability challenges. Furthermore, due to the quickly changing nature of
both bioinformatics software and accelerator technology, we conclude that
creating sustainable accelerated bioinformatics software means constructing a
sustainable bridge between the two fields. In particular, sustained
collaboration between domain developers and technology experts is needed to
develop the accelerated kernels, libraries, frameworks and middleware that
could provide the needed flexible link from NGS bioinformatics applications to
emerging platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1829</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1829</id><created>2013-09-07</created><authors><author><keyname>Zhou</keyname><forenames>Jianqin</forenames></author><author><keyname>Liu</keyname><forenames>Wanquan</forenames></author></authors><title>On the $k$-error linear complexity for $2^n$-periodic binary sequences
  via Cube Theory</title><categories>cs.CR cs.IT math.IT</categories><comments>11 pages. arXiv admin note: substantial text overlap with
  arXiv:1109.4455, arXiv:1108.5793, arXiv:1112.6047</comments><msc-class>94A55, 94A60, 11B50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear complexity and k-error linear complexity of a sequence have been
used as important measures of keystream strength, hence designing a sequence
with high linear complexity and $k$-error linear complexity is a popular
research topic in cryptography. In this paper, the concept of stable $k$-error
linear complexity is proposed to study sequences with stable and large
$k$-error linear complexity. In order to study k-error linear complexity of
binary sequences with period $2^n$, a new tool called cube theory is developed.
By using the cube theory, one can easily construct sequences with the maximum
stable $k$-error linear complexity. For such purpose, we first prove that a
binary sequence with period $2^n$ can be decomposed into some disjoint cubes
and further give a general decomposition approach. Second, it is proved that
the maximum $k$-error linear complexity is $2^n-(2^l-1)$ over all
$2^n$-periodic binary sequences, where $2^{l-1}\le k&lt;2^{l}$. Thirdly, a
characterization is presented about the $t$th ($t&gt;1$) decrease in the $k$-error
linear complexity for a $2^n$-periodic binary sequence $s$ and this is a
continuation of Kurosawa et al. recent work for the first decrease of k-error
linear complexity. Finally, A counting formula for $m$-cubes with the same
linear complexity is derived, which is equivalent to the counting formula for
$k$-error vectors. The counting formula of $2^n$-periodic binary sequences
which can be decomposed into more than one cube is also investigated, which
extends an important result by Etzion et al..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1830</identifier>
 <datestamp>2014-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1830</id><created>2013-09-07</created><authors><author><keyname>Prasath</keyname><forenames>V. B. S.</forenames></author><author><keyname>Haddad</keyname><forenames>O.</forenames></author></authors><title>Radar shadow detection in SAR images using DEM and projections</title><categories>cs.CV</categories><comments>10 pages, 6 figures</comments><msc-class>68U10</msc-class><acm-class>I.4.8</acm-class><journal-ref>J. Appl. Remote Sens. 8(1), 083628 (May 19, 2014)</journal-ref><doi>10.1117/1.JRS.8.083628</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthetic aperture radar (SAR) images are widely used in target recognition
tasks nowadays. In this letter, we propose an automatic approach for radar
shadow detection and extraction from SAR images utilizing geometric projections
along with the digital elevation model (DEM) which corresponds to the given
geo-referenced SAR image. First, the DEM is rotated into the radar geometry so
that each row would match that of a radar line of sight. Next, we extract the
shadow regions by processing row by row until the image is covered fully. We
test the proposed shadow detection approach on different DEMs and a simulated
1D signals and 2D hills and volleys modeled by various variance based Gaussian
functions. Experimental results indicate the proposed algorithm produces good
results in detecting shadows in SAR images with high resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1832</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1832</id><created>2013-09-07</created><authors><author><keyname>U.</keyname><forenames>Prashanth B.</forenames><suffix>V</suffix></author></authors><title>Design and Implementation of Wireless Energy Meter System for Monitoring
  the Single Phase Supply</title><categories>cs.OH</categories><comments>4 pages, 10 figures, journal</comments><journal-ref>IJCA 41(2):26-29,March 2012</journal-ref><doi>10.5120/5514-7511</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Wireless energy meter is a system developed to serve as a basic single-phase
energy meter with advanced functionalities such as Peak hour setting, Peak load
setting Wireless reading transmission; further the system eliminates the role
of a Meter Reader.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1841</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1841</id><created>2013-09-07</created><authors><author><keyname>Aboulker</keyname><forenames>Pierre</forenames></author><author><keyname>Radovanovi&#x107;</keyname><forenames>Marko</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author><author><keyname>Vu\vskovi&#x107;</keyname><forenames>Kristina</forenames></author></authors><title>Graphs that do not contain a cycle with a node that has at least two
  neighbors on it</title><categories>cs.DM math.CO</categories><msc-class>05C75</msc-class><journal-ref>P. Aboulker, M. Radovanovic, N. Trotignon and K. Vuskovic. Graphs
  that do not contain a cycle with a node that has at least two neighbors on
  it. SIAM Journal on Discrete Mathematics, 26(4):1510-1531, 2012</journal-ref><doi>10.1137/11084933X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We recall several known results about minimally 2-connected graphs, and show
that they all follow from a decomposition theorem. Starting from an analogy
with critically 2-connected graphs, we give structural characterizations of the
classes of graphs that do not contain as a subgraph and as an induced subgraph,
a cycle with a node that has at least two neighbors on the cycle. From these
characterizations we get polynomial time recognition algorithms for these
classes, as well as polynomial time algorithms for vertex-coloring and
edge-coloring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1842</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1842</id><created>2013-09-07</created><authors><author><keyname>Machado</keyname><forenames>Raphael C. S.</forenames></author><author><keyname>de Figueiredo</keyname><forenames>Celina M. H.</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>Edge-colouring and total-colouring chordless graphs</title><categories>cs.DM math.CO</categories><msc-class>05C75</msc-class><journal-ref>R.C.S. Machado, C.M.H. de Figueiredo and N. Trotignon.
  Edge-colouring and total-colouring chordless graphs, Discrete Mathematics,
  313:1547-1552, 2013</journal-ref><doi>10.1016/j.disc.2013.03.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G$ is \emph{chordless} if no cycle in $G$ has a chord. In the
present work we investigate the chromatic index and total chromatic number of
chordless graphs. We describe a known decomposition result for chordless graphs
and use it to establish that every chordless graph of maximum degree
$\Delta\geq 3$ has chromatic index $\Delta$ and total chromatic number $\Delta
+ 1$. The proofs are algorithmic in the sense that we actually output an
optimal colouring of a graph instance in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1844</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1844</id><created>2013-09-07</created><updated>2014-02-03</updated><authors><author><keyname>Huu</keyname><forenames>Adrien Nguyen</forenames><affiliation>FiME Lab, IMPA</affiliation></author></authors><title>Investment under uncertainty, competition and regulation</title><categories>q-fin.PM cs.GT math.OC q-fin.RM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a randomization procedure undertaken in real option games
which can serve as a basic model of regulation in a duopoly model of preemptive
investment. We recall the rigorous framework of [M. Grasselli, V. Lecl\`ere and
M. Ludkovsky, Priority Option: the value of being a leader, International
Journal of Theoretical and Applied Finance, 16, 2013], and extend it to a
random regulator. This model generalizes and unifies the different competitive
frameworks proposed in the literature, and creates a new one similar to a
Stackelberg leadership. We fully characterize strategic interactions in the
several situations following from the parametrization of the regulator.
Finally, we study the effect of the coordination game and uncertainty of
outcome when agents are risk-averse, providing new intuitions for the standard
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1846</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1846</id><created>2013-09-07</created><authors><author><keyname>Fallah</keyname><forenames>Haniyeh</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author><author><keyname>Rahmati</keyname><forenames>Farhad</forenames></author><author><keyname>Yusefikhoshbakht</keyname><forenames>Majid</forenames></author></authors><title>Approximation Algorithms for a Balanced Capacity and Distance
  Constrained Vehicle Routing Problem</title><categories>cs.DS</categories><comments>7pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current paper we have investigated the capacitated distance constraint
vehicle routing problem for the standard approximation algorithm. This problem
consists of a number of different types of vehicles at the depot which differ
at their capacity, cost and maximum distance bound. We have designed an
approximation algorithm for this problem in the case that the tours are
balanced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1853</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1853</id><created>2013-09-07</created><authors><author><keyname>Lin</keyname><forenames>Guosheng</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Suter</keyname><forenames>David</forenames></author><author><keyname>Hengel</keyname><forenames>Anton van den</forenames></author></authors><title>A General Two-Step Approach to Learning-Based Hashing</title><categories>cs.LG cs.CV</categories><comments>13 pages. Appearing in Int. Conf. Computer Vision (ICCV) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most existing approaches to hashing apply a single form of hash function, and
an optimization process which is typically deeply coupled to this specific
form. This tight coupling restricts the flexibility of the method to respond to
the data, and can result in complex optimization problems that are difficult to
solve. Here we propose a flexible yet simple framework that is able to
accommodate different types of loss functions and hash functions. This
framework allows a number of existing approaches to hashing to be placed in
context, and simplifies the development of new problem-specific hashing
methods. Our framework decomposes hashing learning problem into two steps: hash
bit learning and hash function learning based on the learned bits. The first
step can typically be formulated as binary quadratic problems, and the second
step can be accomplished by training standard binary classifiers. Both problems
have been extensively studied in the literature. Our extensive experiments
demonstrate that the proposed framework is effective, flexible and outperforms
the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1859</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1859</id><created>2013-09-07</created><authors><author><keyname>Mahalanobis</keyname><forenames>Ayan</forenames></author></authors><title>The MOR cryptosystem and finite $p$-groups</title><categories>math.GR cs.CR</categories><msc-class>94A60, 20D15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ElGamal cryptosystem is the most widely used public key cryptosystem. It
uses the discrete logarithm problem as the cryptographic primitive. The MOR
cryptosystem is a similar cryptosystem. It uses the discrete logarithm problem
in the automorphism group as the cryptographic primitive. In this paper, we
study the MOR cryptosystem for finite $p$-groups. The study is complete for
$p^\prime$-automorphisms. For $p$-automorphisms there are some interesting open
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1862</identifier>
 <datestamp>2013-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1862</id><created>2013-09-07</created><updated>2013-10-15</updated><authors><author><keyname>Hasegawa</keyname><forenames>Takehisa</forenames></author><author><keyname>Takaguchi</keyname><forenames>Taro</forenames></author><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author></authors><title>Observability transitions in correlated networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>14 pages, 5 figures</comments><journal-ref>Phys. Rev. E 88, 042809 (2013)</journal-ref><doi>10.1103/PhysRevE.88.042809</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Yang, Wang, and Motter [Phys. Rev. Lett. 109, 258701 (2012)] analyzed a model
for network observability transitions in which a sensor placed on a node makes
the node and the adjacent nodes observable. The size of the connected
components comprising the observable nodes is a major concern of the model. We
analyze this model in random heterogeneous networks with degree correlation.
With numerical simulations and analytical arguments based on generating
functions, we find that negative degree correlation makes networks more
observable. This result holds true both when the sensors are placed on nodes
one by one in a random order and when hubs preferentially receive the sensors.
Finally, we numerically optimize networks with a fixed degree sequence with
respect to the size of the largest observable component. Optimized networks
have negative degree correlation induced by the resulting hub-repulsive
structure; the largest hubs are rarely connected to each other, in contrast to
the rich-club phenomenon of networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1863</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1863</id><created>2013-09-07</created><authors><author><keyname>Egger</keyname><forenames>Jan</forenames></author><author><keyname>Tokuda</keyname><forenames>Junichi</forenames></author><author><keyname>Chauvin</keyname><forenames>Laurent</forenames></author><author><keyname>Freisleben</keyname><forenames>Bernd</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author><author><keyname>Kapur</keyname><forenames>Tina</forenames></author><author><keyname>Wells</keyname><forenames>William M.</forenames><suffix>III</suffix></author></authors><title>Integration of the OpenIGTLink Network Protocol for Image-Guided Therapy
  with the Medical Platform MeVisLab</title><categories>cs.SE</categories><comments>18 pages, 5 figures, 1 table, 30 references</comments><journal-ref>Int J Med Robot. 2012 September, 8(3). pp. 282-290</journal-ref><doi>10.1002/rcs.1415</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the integration of the OpenIGTLink network protocol for
image-guided therapy (IGT) with the medical prototyping platform MeVisLab.
OpenIGTLink is a new, open, simple and extensible network communication
protocol for IGT. The protocol provides a standardized mechanism to connect
hardware and software by the transfer of coordinate transforms, images, and
status messages. MeVisLab is a framework for the development of image
processing algorithms and visualization and interaction methods, with a focus
on medical imaging. The integration of OpenIGTLink into MeVisLab has been
realized by developing a software module using the C++ programming language. As
a result, researchers using MeVisLab can interface their software to hardware
devices that already support the OpenIGTLink protocol, such as the NDI Aurora
magnetic tracking system. In addition, the OpenIGTLink module can also be used
to communicate directly with Slicer, a free, open source software package for
visualization and image analysis. The integration has been tested with tracker
clients available online and a real tracking system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1864</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1864</id><created>2013-09-07</created><authors><author><keyname>Nilsson</keyname><forenames>John-Olof</forenames></author><author><keyname>H&#xe4;ndel</keyname><forenames>Peter</forenames></author></authors><title>Timing estimation in distributed sensor and control systems with central
  processing</title><categories>cs.SY stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating timing of measurements and actuation in
distributed sensor and control systems with central processing. The focus is on
direct timing estimation for scenarios where clock synchronization is not
feasible or desirable. Models of the timing and central and peripheral time
stamps are motivated and derived from underlying clock and communication delay
definitions and models. Heuristics for constructing a system time is presented
and it is outlined how the joint timing and the plant state estimation can be
handled. For a simple set of underlying clock and communication delay models,
inclusion of peripheral unit time stamps is shown to reduce jitter, and it is
argued that in general it will give significant jitter reduction. Finally, a
numerical example is given of a contemporary system design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1884</identifier>
 <datestamp>2014-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1884</id><created>2013-09-07</created><updated>2014-04-06</updated><authors><author><keyname>Bertossi</keyname><forenames>Leopoldo</forenames></author><author><keyname>Gardezi</keyname><forenames>Jaffer</forenames></author></authors><title>Tractable vs. Intractable Cases of Matching Dependencies for Query
  Answering under Entity Resolution</title><categories>cs.DB cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching Dependencies (MDs) are a relatively recent proposal for declarative
entity resolution. They are rules that specify, on the basis of similarities
satisfied by values in a database, what values should be considered duplicates,
and have to be matched. On the basis of a chase-like procedure for MD
enforcement, we can obtain clean (duplicate-free) instances; actually possibly
several of them. The resolved answers to queries are those that are invariant
under the resulting class of resolved instances. Previous work identified
certain classes of queries and sets of MDs for which resolved query answering
is tractable. Special emphasis was placed on cyclic sets of MDs. In this work
we further investigate the complexity of this problem, identifying intractable
cases, and exploring the frontier between tractability and intractability. We
concentrate mostly on acyclic sets of MDs. For a special case we obtain a
dichotomy result relative to NP-hardness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1886</identifier>
 <datestamp>2014-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1886</id><created>2013-09-07</created><updated>2014-04-03</updated><authors><author><keyname>Harju</keyname><forenames>Tero</forenames></author><author><keyname>Huova</keyname><forenames>Mari</forenames></author><author><keyname>Zamboni</keyname><forenames>L. Q.</forenames></author></authors><title>On Generating Binary Words Palindromically</title><categories>math.CO cs.DM</categories><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We regard a finite word $u=u_1u_2\cdots u_n$ up to word isomorphism as an
equivalence relation on $\{1,2,\ldots, n\}$ where $i$ is equivalent to $j$ if
and only if $x_i=x_j.$ Some finite words (in particular all binary words) are
generated by &quot;{\it palindromic}&quot; relations of the form $k\sim j+i-k$ for some
choice of $1\leq i\leq j\leq n$ and $k\in \{i,i+1,\ldots,j\}.$ That is to say,
some finite words $u$ are uniquely determined up to word isomorphism by the
position and length of some of its palindromic factors. In this paper we study
the function $\mu(u)$ defined as the least number of palindromic relations
required to generate $u.$ We show that every aperiodic infinite word must
contain a factor $u$ with $\mu(u)\geq 3,$ and that some infinite words $x$ have
the property that $\mu(u)\leq 3$ for each factor $u$ of $x.$ We obtain a
complete classification of such words on a binary alphabet (which includes the
well known class of Sturmian words). In contrast for the Thue-Morse word, we
show that the function $\mu$ is unbounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1889</identifier>
 <datestamp>2013-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1889</id><created>2013-09-07</created><updated>2013-10-18</updated><authors><author><keyname>Paz&#xfa;rikov&#xe1;</keyname><forenames>Jana</forenames></author><author><keyname>Matyska</keyname><forenames>Lud&#x11b;k</forenames></author></authors><title>Parallel-in-time method for calculation of long-range electrostatic
  interactions</title><categories>cs.NA cs.DC physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large molecular dynamics simulations (millions of atoms, tens of
microseconds, thousands of processors) hit the strong scalability wall:
simulation on twice as many processors does not take half the time. Inspired by
large N-body space simulations, we suggest to calculate the bottleneck---the
long-range interactions---parallel in time. This technical report aims to
present the combination of parareal method and multilevel summation method. We
thoroughly describe both methods and reasons for their particular combination.
We also propose several optimizations that should provide the acceleration by
an order of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1890</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1890</id><created>2013-09-07</created><authors><author><keyname>Graells-Garrido</keyname><forenames>Eduardo</forenames></author><author><keyname>Baeza-Yates</keyname><forenames>Ricardo</forenames></author></authors><title>Evolution of the Chilean Web: A Larger Study</title><categories>cs.SI physics.soc-ph</categories><comments>Presented at the Sixth Latin American Web Congress, 2008, Vila Velha,
  Esp\'irito Santo, Brazil</comments><doi>10.1109/LA-WEB.2008.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we extend our previous and only study on the dynamics of the
Chilean Web. This new study doubles the time period and to the best of our
knowledge is the only study of its type known about any country in the Web. The
new results corroborate the trends found before, in particular the exponential
growth of the Web, and reinforce the conclusion that the Web is more chaotic
than we would like. Hence, modeling most Web characteristics is not trivial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1894</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1894</id><created>2013-09-07</created><authors><author><keyname>Mametjanov</keyname><forenames>Azamat</forenames></author><author><keyname>Norris</keyname><forenames>Boyana</forenames></author></authors><title>Software Autotuning for Sustainable Performance Portability</title><categories>cs.PF</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Scientific software applications are increasingly developed by large
interdiscplinary teams operating on functional modules organized around a
common software framework, which is capable of integrating new functional
capabilities without modifying the core of the framework. In such environment,
software correctness and modularity take precedence at the expense of code
performance, which is an important concern during execution on supercomputing
facilities, where the allocation of core-hours is a valuable resource. To
alleviate the performance problems, we propose automated performance tuning
(autotuning) of software to extract the maximum performance on a given hardware
platform and to enable performance portability across heterogeneous hardware
platforms. The resulting code remains generic without committing to a
particular software stack and yet is compile-time specializable for maximal
sustained performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1913</identifier>
 <datestamp>2013-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1913</id><created>2013-09-07</created><updated>2013-10-10</updated><authors><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author><author><keyname>Ahmed</keyname><forenames>Nasir U.</forenames></author></authors><title>Dynamic Team Theory of Stochastic Differential Decision Systems with
  Decentralized Noisy Information Structures via Girsanov's Measure
  Transformation</title><categories>math.OC cs.SY math.ST stat.TH</categories><comments>50 pages</comments><msc-class>49J55, 49K45, 93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present two methods which generalize static team theory to
dynamic team theory, in the context of continuous-time stochastic nonlinear
differential decentralized decision systems, with relaxed strategies, which are
measurable to different noisy information structures. For both methods we apply
Girsanov's measure transformation to obtain an equivalent dynamic team problem
under a reference probability measure, so that the observations and information
structures available for decisions, are not affected by any of the team
decisions. The first method is based on function space integration with respect
to products of Wiener measures, and generalizes Witsenhausen's [1] definition
of equivalence between discrete-time static and dynamic team problems. The
second method is based on stochastic Pontryagin's maximum principle. The team
optimality conditions are given by a &quot;Hamiltonian System&quot; consisting of forward
and backward stochastic differential equations, and a conditional variational
Hamiltonian with respect to the information structure of each team member,
expressed under the initial and a reference probability space via Girsanov's
measure transformation. Under global convexity conditions, we show that that
PbP optimality implies team optimality. In addition, we also show existence of
team and PbP optimal relaxed decentralized strategies (conditional
distributions), in the weak$^*$ sense, without imposing convexity on the action
spaces of the team members. Moreover, using the embedding of regular strategies
into relaxed strategies, we also obtain team and PbP optimality conditions for
regular team strategies, which are measurable functions of decentralized
information structures, and we use the Krein-Millman theorem to show
realizability of relaxed strategies by regular strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1914</identifier>
 <datestamp>2013-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1914</id><created>2013-09-07</created><updated>2013-11-15</updated><authors><author><keyname>Ouaknine</keyname><forenames>Joel</forenames></author><author><keyname>Worrell</keyname><forenames>James</forenames></author></authors><title>Ultimate Positivity is Decidable for Simple Linear Recurrence Sequences</title><categories>cs.CC cs.DM cs.FL</categories><acm-class>F.2.1; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the decidability and complexity of the Ultimate Positivity
Problem, which asks whether all but finitely many terms of a given rational
linear recurrence sequence (LRS) are positive. Using lower bounds in
Diophantine approximation concerning sums of S-units, we show that for simple
LRS (those whose characteristic polynomial has no repeated roots) the Ultimate
Positivity Problem is decidable in polynomial space. If we restrict to simple
LRS of a fixed order then we obtain a polynomial-time decision procedure. As a
complexity lower bound we show that Ultimate Positivity for simple LRS is hard
for co$\exists\mathbb{R}$, i.e., the class of problems solvable in the
universal theory of the reals (which lies between coNP and PSPACE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1917</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1917</id><created>2013-09-07</created><authors><author><keyname>Graells-Garrido</keyname><forenames>Eduardo</forenames></author><author><keyname>Rivara</keyname><forenames>Mar&#xed;a Cecilia</forenames></author></authors><title>Zahir: a Object-Oriented Framework for Computer Graphics</title><categories>cs.GR</categories><comments>Tech report, 2009, Santiago, Chile</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this article we present Zahir, a framework for experimentation in Computer
Graphics that provides a group of object-oriented base components that take
care of common tasks in rendering techniques and algorithms, specially those of
Non Photo-realistic Rendering (NPR). These components allow developers to
implement rendering techniques and algorithms over static and animated meshes.
Currently, Zahir is being used in a Master's Thesis and as support material in
the undergraduate Computer Graphics course in University of Chile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1921</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1921</id><created>2013-09-07</created><authors><author><keyname>Palem</keyname><forenames>Gopalakrishna</forenames></author></authors><title>Condition-Based Maintenance using Sensor Arrays and Telematics</title><categories>cs.OH physics.data-an</categories><journal-ref>International Journal of Mobile Network Communications &amp;
  Telematics. 06 (2013) 3(3):19-28</journal-ref><doi>10.5121/ijmnct.2013.3303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emergence of uniquely addressable embeddable devices has raised the bar on
Telematics capabilities. Though the technology itself is not new, its
application has been quite limited until now. Sensor based telematics
technologies generate volumes of data that are orders of magnitude larger than
what operators have dealt with previously. Real-time big data computation
capabilities have opened the flood gates for creating new predictive analytics
capabilities into an otherwise simple data log systems, enabling real-time
control and monitoring to take preventive action in case of any anomalies.
Condition-based-maintenance, usage-based-insurance, smart metering and
demand-based load generation etc. are some of the predictive analytics use
cases for Telematics. This paper presents the approach of condition-based
maintenance using real-time sensor monitoring, Telematics and predictive data
analytics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1928</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1928</id><created>2013-09-08</created><authors><author><keyname>Parida</keyname><forenames>Nigam Chandra</forenames></author><author><keyname>Raha</keyname><forenames>Soumyendu</forenames></author><author><keyname>Ramani</keyname><forenames>Anand</forenames></author></authors><title>Rollover Preventive Force Synthesis at Active Suspensions in a Vehicle
  Performing a Severe Maneuver with Wheels Lifted off</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among the intelligent safety technologies for road vehicles, active
suspensions controlled by embedded computing elements for preventing rollover
have received a lot of attention. The existing models for synthesizing and
allocating forces in such suspensions are conservatively based on the
constraint that no wheels lift off the ground. However, in practice,
smart/active suspensions are more necessary in the situation where the wheels
have just lifted off the ground. The difficulty in computing control in the
last situation is that the problem requires satisfying disjunctive constraints
on the dynamics. To the authors',knowledge, no efficient solution method is
available for the simulation of dynamics with disjunctive constraints and thus
hardware realizable and accurate force allocation in an active suspension tends
to be a difficulty. In this work we give an algorithm for and simulate
numerical solutions of the force allocation problem as an optimal control
problem constrained by dynamics with disjunctive constraints. In particular we
study the allocation and synthesis of time-dependent active suspension forces
in terms of sensor output data in order to stabilize the roll motion of the
road vehicle. An equivalent constraint in the form of a convex combination
(hull) is proposed to satisfy the disjunctive constraints. The validated
numerical simulations show that it is possible to allocate and synthesize
control forces at the active suspensions from sensor output data such that the
forces stabilize the roll moment of the vehicle with its wheels just lifted off
the ground during arbitrary fish-hook maneuvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1937</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1937</id><created>2013-09-08</created><authors><author><keyname>Higuchi</keyname><forenames>Kojiro</forenames></author><author><keyname>Kihara</keyname><forenames>Takayuki</forenames></author></authors><title>Inside the Muchnik Degrees II: The Degree Structures induced by the
  Arithmetical Hierarchy of Countably Continuous Functions</title><categories>math.LO cs.LO</categories><msc-class>(2010): 03D30 (Primary), 03D78, 03E15, 26A21, 68Q32 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that infinitely many Medvedev degrees exist inside the Muchnik
degree of any nontrivial $\Pi^0_1$ subset of Cantor space. We shed light on the
fine structures inside these Muchnik degrees related to learnability and
piecewise computability. As for nonempty $\Pi^0_1$ subsets of Cantor space, we
show the existence of a finite-$\Delta^0_2$-piecewise degree containing
infinitely many finite-$(\Pi^0_1)_2$-piecewise degrees, and a
finite-$(\Pi^0_2)_2$-piecewise degree containing infinitely many
finite-$\Delta^0_2$-piecewise degrees (where $(\Pi^0_n)_2$ denotes the
difference of two $\Pi^0_n$ sets), whereas the greatest degrees in these three
&quot;finite-$\Gamma$-piecewise&quot; degree structures coincide. Moreover, as for
nonempty $\Pi^0_1$ subsets of Cantor space, we also show that every nonzero
finite-$(\Pi^0_1)_2$-piecewise degree includes infinitely many Medvedev (i.e.,
one-piecewise) degrees, every nonzero countable-$\Delta^0_2$-piecewise degree
includes infinitely many finite-piecewise degrees, every nonzero
finite-$(\Pi^0_2)_2$-countable-$\Delta^0_2$-piecewise degree includes
infinitely many countable-$\Delta^0_2$-piecewise degrees, and every nonzero
Muchnik (i.e., countable-$\Pi^0_2$-piecewise) degree includes infinitely many
finite-$(\Pi^0_2)_2$-countable-$\Delta^0_2$-piecewise degrees. Indeed, we show
that any nonzero Medvedev degree and nonzero countable-$\Delta^0_2$-piecewise
degree of a nonempty $\Pi^0_1$ subset of Cantor space have the strong
anticupping properties. Finally, we obtain an elementary difference between the
Medvedev (Muchnik) degree structure and the finite-$\Gamma$-piecewise degree
structure of all subsets of Baire space by showing that none of the
finite-$\Gamma$-piecewise structures are Brouwerian, where $\Gamma$ is any of
the Wadge classes mentioned above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1939</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1939</id><created>2013-09-08</created><updated>2015-03-15</updated><authors><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author></authors><title>The placement of the head that minimizes online memory: a complex
  systems approach</title><categories>cs.CL nlin.AO physics.data-an physics.soc-ph</categories><comments>Minor changes (language improved; typos in Eqs. 5, 6 and 13
  corrected)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the length of a syntactic dependency determines its
online memory cost. Thus, the problem of the placement of a head and its
dependents (complements or modifiers) that minimizes online memory is
equivalent to the problem of the minimum linear arrangement of a star tree.
However, how that length is translated into cognitive cost is not known. This
study shows that the online memory cost is minimized when the head is placed at
the center, regardless of the function that transforms length into cost,
provided only that this function is strictly monotonically increasing. Online
memory defines a quasi-convex adaptive landscape with a single central minimum
if the number of elements is odd and two central minima if that number is even.
We discuss various aspects of the dynamics of word order of subject (S), verb
(V) and object (O) from a complex systems perspective and suggest that word
orders tend to evolve by swapping adjacent constituents from an initial or
early SOV configuration that is attracted towards a central word order by
online memory minimization. We also suggest that the stability of SVO is due to
at least two factors, the quasi-convex shape of the adaptive landscape in the
online memory dimension and online memory adaptations that avoid regression to
SOV. Although OVS is also optimal for placing the verb at the center, its low
frequency is explained by its long distance to the seminal SOV in the
permutation space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1952</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1952</id><created>2013-09-08</created><updated>2014-07-07</updated><authors><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Netrapalli</keyname><forenames>Praneeth</forenames></author></authors><title>A Clustering Approach to Learn Sparsely-Used Overcomplete Dictionaries</title><categories>stat.ML cs.LG math.OC</categories><comments>Part of this work appears in COLT 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning overcomplete dictionaries in the context
of sparse coding, where each sample selects a sparse subset of dictionary
elements. Our main result is a strategy to approximately recover the unknown
dictionary using an efficient algorithm. Our algorithm is a clustering-style
procedure, where each cluster is used to estimate a dictionary element. The
resulting solution can often be further cleaned up to obtain a high accuracy
estimate, and we provide one simple scenario where $\ell_1$-regularized
regression can be used for such a second stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1960</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1960</id><created>2013-09-08</created><authors><author><keyname>Chudnovsky</keyname><forenames>Maria</forenames></author><author><keyname>Seymour</keyname><forenames>Paul</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>Detecting an induced net subdivision</title><categories>cs.DM math.CO</categories><journal-ref>M. Chudnovsky, P. Seymour and N. Trotignon. Detecting an induced
  net subdivision. Journal of Combinatorial Theory, Series B, 103(5):630-641,
  2013</journal-ref><doi>10.1016/j.jctb.2007.07.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A {\em net} is a graph consisting of a triangle $C$ and three more vertices,
each of degree one and with its neighbour in $C$, and all adjacent to different
vertices of $C$. We give a polynomial-time algorithm to test whether an input
graph has an induced subgraph which is a subdivision of a net. Unlike many
similar questions, this does not seem to be solvable by an application of the
&quot;three-in-a-tree&quot; subroutine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1973</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1973</id><created>2013-09-08</created><authors><author><keyname>Wu</keyname><forenames>Feng</forenames></author><author><keyname>Jennings</keyname><forenames>Nicholas R.</forenames></author></authors><title>Regret-Based Multi-Agent Coordination with Uncertain Task Rewards</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many multi-agent coordination problems can be represented as DCOPs. Motivated
by task allocation in disaster response, we extend standard DCOP models to
consider uncertain task rewards where the outcome of completing a task depends
on its current state, which is randomly drawn from unknown distributions. The
goal of solving this problem is to find a solution for all agents that
minimizes the overall worst-case loss. This is a challenging problem for
centralized algorithms because the search space grows exponentially with the
number of agents and is nontrivial for standard DCOP algorithms we have. To
address this, we propose a novel decentralized algorithm that incorporates
Max-Sum with iterative constraint generation to solve the problem by passing
messages among agents. By so doing, our approach scales well and can solve
instances of the task allocation problem with hundreds of agents and tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1976</identifier>
 <datestamp>2014-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1976</id><created>2013-09-08</created><updated>2014-01-20</updated><authors><author><keyname>Mendlovic</keyname><forenames>Uri</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Source Broadcasting to the Masses: Separation has a Bounded Loss</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work discusses the source broadcasting problem, i.e. transmitting a
source to many receivers via a broadcast channel. The optimal rate-distortion
region for this problem is unknown. The separation approach divides the problem
into two complementary problems: source successive refinement and broadcast
channel transmission. We provide bounds on the loss incorporated by applying
time-sharing and separation in source broadcasting. If the broadcast channel is
degraded, it turns out that separation-based time-sharing achieves at least a
factor of the joint source-channel optimal rate, and this factor has a positive
limit even if the number of receivers increases to infinity. For the AWGN
broadcast channel a better bound is introduced, implying that all achievable
joint source-channel schemes have a rate within one bit of the separation-based
achievable rate region for two receivers, or within $\log_2 T$ bits for $T$
receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1981</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1981</id><created>2013-09-08</created><updated>2013-09-18</updated><authors><author><keyname>Ahmed</keyname><forenames>Pritom</forenames></author><author><keyname>Iliopoulos</keyname><forenames>Costas S.</forenames></author><author><keyname>Islam</keyname><forenames>A. S. M. Sohidull</forenames></author><author><keyname>Rahman</keyname><forenames>M. Sohel</forenames></author></authors><title>The Swap Matching Problem Revisited</title><categories>cs.DS</categories><comments>23 pages, 3 Figures and 17 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we revisit the much studied problem of Pattern Matching with
Swaps (Swap Matching problem, for short). We first present a graph-theoretic
model, which opens a new and so far unexplored avenue to solve the problem.
Then, using the model, we devise two efficient algorithms to solve the swap
matching problem. The resulting algorithms are adaptations of the classic
shift-and algorithm. For patterns having length similar to the word-size of the
target machine, both the algorithms run in linear time considering a fixed
alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.1983</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.1983</id><created>2013-09-08</created><authors><author><keyname>Mawson</keyname><forenames>Mark</forenames></author><author><keyname>Revell</keyname><forenames>Alistair</forenames></author></authors><title>Memory transfer optimization for a lattice Boltzmann solver on Kepler
  architecture nVidia GPUs</title><categories>cs.DC cs.PF</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lattice Boltzmann method (LBM) for solving fluid flow is naturally well
suited to an efficient implementation for massively parallel computing, due to
the prevalence of local operations in the algorithm. This paper presents and
analyses the performance of a 3D lattice Boltzmann solver, optimized for third
generation nVidia GPU hardware, also known as `Kepler'. We provide a review of
previous optimisation strategies and analyse data read/write times for
different memory types. In LBM, the time propagation step (known as streaming),
involves shifting data to adjacent locations and is central to parallel
performance; here we examine three approaches which make use of different
hardware options. Two of which make use of `performance enhancing' features of
the GPU; shared memory and the new shuffle instruction found in Kepler based
GPUs. These are compared to a standard transfer of data which relies instead on
optimised storage to increase coalesced access. It is shown that the more
simple approach is most efficient; since the need for large numbers of
registers per thread in LBM limits the block size and thus the efficiency of
these special features is reduced. Detailed results are obtained for a D3Q19
LBM solver, which is benchmarked on nVidia K5000M and K20C GPUs. In the latter
case the use of a read-only data cache is explored, and peak performance of
over 1036 Million Lattice Updates Per Second (MLUPS) is achieved. The
appearance of a periodic bottleneck in the solver performance is also reported,
believed to be hardware related; spikes in iteration-time occur with a
frequency of around 11Hz for both GPUs, independent of the size of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2002</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2002</id><created>2013-09-08</created><authors><author><keyname>Riverso</keyname><forenames>Stefano</forenames></author><author><keyname>Farina</keyname><forenames>Marcello</forenames></author><author><keyname>Scattolini</keyname><forenames>Riccardo</forenames></author><author><keyname>Ferrari-Trecate</keyname><forenames>Giancarlo</forenames></author></authors><title>Plug-and-play distributed state estimation for linear systems</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a state estimator for large-scale linear systems
described by the interaction of state-coupled subsystems affected by bounded
disturbances. We equip each subsystem with a Local State Estimator (LSE) for
the reconstruction of the subsystem states using pieces of information from
parent subsystems only. Moreover we provide conditions guaranteeing that the
estimation errors are confined into prescribed polyhedral sets and converge to
zero in absence of disturbances. Quite remarkably, the design of an LSE is
recast into an optimization problem that requires data from the corresponding
subsystem and its parents only. This allows one to synthesize LSEs in a
Plug-and-Play (PnP) fashion, i.e. when a subsystem gets added, the update of
the whole estimator requires at most the design of an LSE for the subsystem and
its parents. Theoretical results are backed up by numerical experiments on a
mechanical system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2018</identifier>
 <datestamp>2013-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2018</id><created>2013-09-08</created><authors><author><keyname>Dodson</keyname><forenames>Andrew</forenames></author><author><keyname>McCann</keyname><forenames>Roy</forenames></author></authors><title>A Direct Power Controlled and Series Compensated EHV Transmission Line</title><categories>cs.SY</categories><comments>6 pages, 3 figures</comments><journal-ref>Proceedings of the 2013 Frontiers of Power Conference, Stillwater
  OK</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and analysis of a compensation method with
application to a 345 kV 480 MVA three-phase transmission line. The compensator
system includes a series injected voltage source converter that minimizes the
resonance effects of capacitor line reactance. This creates an ability to
compensate for the effects of subsynchronous resonance and thereby increase
line loadability and control real and reactive power flows. The granularity of
power flow control and simultaneous stabilization is achieved by the method of
direct decoupled power control (DPC). The design process is detailed with
respect to optimal response characteristics considering variations of line
parameters, realistic transformer impedances, and maximum ramp response rates.
Line effects are demonstrated in a PLECS model in MATLAB, and compensation
control system functionality is verified. A case study is provided of a 345 kV
transmission line from an EMTP simulation in PSCAD that accounts for
distributed parameter effects that are encountered in physical EHV transmission
lines. This demonstrates the improvement in stability to power system
transients as well as damping of power system oscillations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2024</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2024</id><created>2013-09-08</created><authors><author><keyname>Rehman</keyname><forenames>Obaid Ur</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>A Robust Continuous Time Fixed Lag Smoother for Nonlinear Uncertain
  Systems</title><categories>cs.SY</categories><comments>8 pages, will be presented in 52nd Conference on Decision and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a robust fixed lag smoother for a class of nonlinear
uncertain systems. A unified scheme, which combines a nonlinear robust
estimator with a stable fixed lag smoother, is presented to improve the error
covariance of the estimation. The robust fixed lag smoother is based on the use
of Integral Quadratic Constraints and minimax LQG control. The state estimator
uses a copy of the system nonlinearity in the estimator and combines an
approximate model of the delayed states to produce a smoothed signal. In order
to see the effectiveness of the method, it is applied to a quantum optical
phase estimation problem. Results show significant improvement in the error
covariance of the estimator using fixed lag smoother in the presence of
nonlinear uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2031</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2031</id><created>2013-09-08</created><authors><author><keyname>Gholami</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Tetruashvili</keyname><forenames>Luba</forenames></author><author><keyname>Str&#xf6;m</keyname><forenames>Erik G.</forenames></author><author><keyname>Censor</keyname><forenames>Yair</forenames></author></authors><title>Cooperative Wireless Sensor Network Positioning via Implicit Convex
  Feasibility</title><categories>cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a distributed positioning algorithm to estimate the unknown
positions of a number of target nodes, given distance measurements between
target nodes and between target nodes and a number of reference nodes at known
positions. Based on a geometric interpretation, we formulate the positioning
problem as an implicit convex feasibility problem in which some of the sets
depend on the unknown target positions, and apply a parallel projection onto
convex sets approach to estimate the unknown target node positions. The
proposed technique is suitable for parallel implementation in which every
target node in parallel can update its position and share the estimate of its
location with other targets. We mathematically prove convergence of the
proposed algorithm. Simulation results reveal enhanced performance for the
proposed approach compared to available techniques based on projections,
especially for sparse networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2038</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2038</id><created>2013-09-08</created><updated>2013-11-15</updated><authors><author><keyname>Chakrabarti</keyname><forenames>Amit</forenames></author><author><keyname>Kale</keyname><forenames>Sagar</forenames></author></authors><title>Submodular Maximization Meets Streaming: Matchings, Matroids, and More</title><categories>cs.DS</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of finding a maximum matching in a graph given by an
input stream listing its edges in some arbitrary order, where the quantity to
be maximized is given by a monotone submodular function on subsets of edges.
This problem, which we call maximum submodular-function matching (MSM), is a
natural generalization of maximum weight matching (MWM), which is in turn a
generalization of maximum cardinality matching (MCM). We give two incomparable
algorithms for this problem with space usage falling in the semi-streaming
range---they store only $O(n)$ edges, using $O(n\log n)$ working memory---that
achieve approximation ratios of $7.75$ in a single pass and $(3+\epsilon)$ in
$O(\epsilon^{-3})$ passes respectively. The operations of these algorithms
mimic those of Zelke's and McGregor's respective algorithms for MWM; the
novelty lies in the analysis for the MSM setting. In fact we identify a general
framework for MWM algorithms that allows this kind of adaptation to the broader
setting of MSM.
  In the sequel, we give generalizations of these results where the
maximization is over &quot;independent sets&quot; in a very general sense. This
generalization captures hypermatchings in hypergraphs as well as independence
in the intersection of multiple matroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2052</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2052</id><created>2013-09-09</created><authors><author><keyname>Palasek</keyname><forenames>Stan</forenames></author></authors><title>On the Strategic Allocation of Social Gratification</title><categories>cs.SI physics.soc-ph</categories><comments>5 pages, 5 figures</comments><msc-class>91</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Members of social networks are given opportunities to bestow positive
recognition upon one another by means of constructs such as &quot;likes&quot; and
&quot;retweets.&quot; Although recipients no doubt experience utility from these actions,
one might question why these constructs with no intrinsic value for the sender
are exchanged at all. Here we formulate a metric for the prestige of a member
of a social network based on his or her place within the network and the rate
at which &quot;likes&quot; are exchanged within his or her social circle. Simulation
reveals that the 1% most strategically-optimized networks exchange likes at an
average rate 23.5% higher than that of their random counterparts. This suggests
that purely strategic agents, even with no concern for altruism or the general
welfare, experience utility from giving social gratification. Further, we show
that prestige-maximization creates a selective pressure for structural features
associated with social networks including clustering and the small-world
property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2055</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2055</id><created>2013-09-09</created><authors><author><keyname>Rutkowski</keyname><forenames>Tomasz M.</forenames></author></authors><title>Beyond visual P300 based brain-computer interfacing paradigms</title><categories>q-bio.NC cs.HC</categories><comments>7 pages, 5 figures, Proceedings of the Third Postgraduate Consortium
  International Workshop on Innovations in Information and Communication
  Science and Technology, (E. Cooper, G. A. Kobzev, A. F. Uvarov, and V. V.
  Kryssanov, eds.), (Tomsk, Russia), pp. 277-283, TUSUR and Ritsumeikan,
  September 2-5, 2013. ISBN 978-5-86889-7</comments><msc-class>92C55, 92C50, 92C30</msc-class><acm-class>D.2.2; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper reviews and summarizes recent developments in spatial auditory and
tactile brain-computer interfacing neurotechology applications. It serves as
the latest developments summary in &quot;non-visual&quot; brain-computer interfacing
solutions presented in a tutorial delivered by the author at the IICST 2013
workshop. The novel concepts of unimodal auditory or tactile, as well as a
bimodal combined paradigms are described and supported with recent research
results from our BCI-lab research group at Life Science Center, University of
Tsukuba, Japan. The newly developed experimental paradigms fit perfectly to
needs of paralyzed or hearing impaired users, in case of tactile stimulus, as
well as for able users who cannot utilize vision in computer or machine
interaction (driving or operation of machinery required not disturbed
eyesight). We present and review the EEG event related potential responses
useful for brain computer interfacing applications beyond state-of-the-art
visual paradigms. In conclusion the recent results are discussed and
suggestions for further applications are drawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2057</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2057</id><created>2013-09-09</created><authors><author><keyname>Naik</keyname><forenames>Sapan</forenames></author><author><keyname>Patel</keyname><forenames>Nikunj</forenames></author></authors><title>Single image super resolution in spatial and wavelet domain</title><categories>cs.CV</categories><comments>10 pages, 5 figures, 1 table, sample code given</comments><journal-ref>The International Journal of Multimedia &amp; Its Applications (IJMA)
  Vol.5, No.4, August 2013</journal-ref><doi>10.5121/ijma.2013.5402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently single image super resolution is very important research area to
generate high resolution image from given low resolution image. Algorithms of
single image resolution are mainly based on wavelet domain and spatial domain.
Filters support to model the regularity of natural images is exploited in
wavelet domain while edges of images get sharp during up sampling in spatial
domain. Here single image super resolution algorithm is presented which based
on both spatial and wavelet domain and take the advantage of both. Algorithm is
iterative and use back projection to minimize reconstruction error. Wavelet
based denoising method is also introduced to remove noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2069</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2069</id><created>2013-09-09</created><updated>2013-09-23</updated><authors><author><keyname>Segoufin</keyname><forenames>Luc</forenames><affiliation>INRIA</affiliation></author><author><keyname>Cate</keyname><forenames>Balder ten</forenames><affiliation>UCSC</affiliation></author></authors><title>Unary negation</title><categories>cs.LO</categories><comments>2 figures</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  24, 2013) lmcs:792</journal-ref><doi>10.2168/LMCS-9(3:25)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study fragments of first-order logic and of least fixed point logic that
allow only unary negation: negation of formulas with at most one free variable.
These logics generalize many interesting known formalisms, including modal
logic and the $\mu$-calculus, as well as conjunctive queries and monadic
Datalog. We show that satisfiability and finite satisfiability are decidable
for both fragments, and we pinpoint the complexity of satisfiability, finite
satisfiability, and model checking. We also show that the unary negation
fragment of first-order logic is model-theoretically very well behaved. In
particular, it enjoys Craig Interpolation and the Projective Beth Property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2074</identifier>
 <datestamp>2014-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2074</id><created>2013-09-09</created><updated>2014-03-09</updated><authors><author><keyname>Qiu</keyname><forenames>Qiang</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Learning Transformations for Clustering and Classification</title><categories>cs.CV cs.LG stat.ML</categories><comments>arXiv admin note: substantial text overlap with arXiv:1308.0273,
  arXiv:1308.0275</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A low-rank transformation learning framework for subspace clustering and
classification is here proposed. Many high-dimensional data, such as face
images and motion sequences, approximately lie in a union of low-dimensional
subspaces. The corresponding subspace clustering problem has been extensively
studied in the literature to partition such high-dimensional data into clusters
corresponding to their underlying low-dimensional subspaces. However,
low-dimensional intrinsic structures are often violated for real-world
observations, as they can be corrupted by errors or deviate from ideal models.
We propose to address this by learning a linear transformation on subspaces
using matrix rank, via its convex surrogate nuclear norm, as the optimization
criteria. The learned linear transformation restores a low-rank structure for
data from the same subspace, and, at the same time, forces a a maximally
separated structure for data from different subspaces. In this way, we reduce
variations within subspaces, and increase separation between subspaces for a
more robust subspace clustering. This proposed learned robust subspace
clustering framework significantly enhances the performance of existing
subspace clustering methods. Basic theoretical results here presented help to
further support the underlying framework. To exploit the low-rank structures of
the transformed subspaces, we further introduce a fast subspace clustering
technique, which efficiently combines robust PCA with sparse modeling. When
class labels are present at the training stage, we show this low-rank
transformation framework also significantly enhances classification
performance. Extensive experiments using public datasets are presented, showing
that the proposed approach significantly outperforms state-of-the-art methods
for subspace clustering and classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2077</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2077</id><created>2013-09-09</created><authors><author><keyname>Mendes</keyname><forenames>Nuno</forenames></author><author><keyname>Neto</keyname><forenames>Pedro</forenames></author><author><keyname>Pires</keyname><forenames>J. Norberto</forenames></author><author><keyname>Loureiro</keyname><forenames>Altino</forenames></author></authors><title>An optimal fuzzy-PI force/motion controller to increase industrial robot
  autonomy</title><categories>cs.RO</categories><journal-ref>The International Journal of Advanced Manufacturing Technology,
  Volume 68, 2013 , pp 435-441</journal-ref><doi>10.1007/s00170-013-4741-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for robot self-recognition and self-adaptation
through the analysis of the contact between the robot end effector and its
surrounding environment. Often, in off-line robot programming, the idealized
robotic environment (the virtual one) does not reflect accurately the real one.
In this situation, we are in the presence of a partially unknown environment
(PUE). Thus, robotic systems must have some degree of autonomy to overcome this
situation, especially when contact exists. The proposed force/motion control
system has an external control loop based on forces and torques exerted on the
robot end effector and an internal control loop based on robot motion. The
external control loop is tested with an optimal proportional integrative (PI)
and a fuzzy-PI controller. The system performance is validated with real-world
experiments involving contact in PUEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2078</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2078</id><created>2013-09-09</created><authors><author><keyname>Neto</keyname><forenames>Pedro</forenames></author><author><keyname>Mendes</keyname><forenames>Nuno</forenames></author></authors><title>Direct off-line robot programming via a common CAD package</title><categories>cs.RO</categories><journal-ref>Robotics and Autonomous Systems, Vol. 61, No. 8, pp. 896-910, 2013</journal-ref><doi>10.1016/j.robot.2013.02.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on intuitive and direct off-line robot programming from a
CAD drawing running on a common 3-D CAD package. It explores the most suitable
way to represent robot motion in a CAD drawing, how to automatically extract
such motion data from the drawing, make the mapping of data from the virtual
(CAD model) to the real environment and the process of automatic generation of
robot paths/programs. In summary, this study aims to present a novel CAD-based
robot programming system accessible to anyone with basic knowledge of CAD and
robotics. Experiments on different manipulation tasks show the effectiveness
and versatility of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="49000" completeListSize="102538">1122234|50001</resumptionToken>
</ListRecords>
</OAI-PMH>
