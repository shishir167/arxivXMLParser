<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:36:41Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|2001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0541</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0541</id><created>2007-12-04</created><updated>2009-01-09</updated><authors><author><keyname>Chen</keyname><forenames>Eric Z.</forenames></author></authors><title>New Construction of A Family of Quasi-Twisted Two-Weight Codes</title><categories>cs.IT math.IT</categories><comments>4 pages, submitted to IEEE Trans. Information Theory</comments><journal-ref>IEEE Trans. Inform. Theory, December 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on cyclic and consta-cyclic simplex codes, a new explicit construction
of a family of two-weight codes is presented. These two-weight codes obtained
are in the form of 2-generator quasi-cyclic, or quasi-twisted structure. Based
on this construction, new optimal binary quasi-cyclic [195, 8, 96], [210, 8,
104] and [240, 8, 120] codes, and good QC ternary [208, 6, 135] and [221, 6,
144] codes are thus obtained. It is also shown that many codes among the family
meet the Griesmer bound and thereful are optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0554</identifier>
 <datestamp>2007-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0554</id><created>2007-12-04</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Carmi</keyname><forenames>Paz</forenames></author><author><keyname>Couture</keyname><forenames>Mathieu</forenames></author><author><keyname>Maheshwari</keyname><forenames>Anil</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author></authors><title>Spanners of Complete $k$-Partite Geometric Graphs</title><categories>cs.CG</categories><abstract>  We address the following problem: Given a complete $k$-partite geometric
graph $K$ whose vertex set is a set of $n$ points in $\mathbb{R}^d$, compute a
spanner of $K$ that has a ``small'' stretch factor and ``few'' edges. We
present two algorithms for this problem. The first algorithm computes a
$(5+\epsilon)$-spanner of $K$ with O(n) edges in $O(n \log n)$ time. The second
algorithm computes a $(3+\epsilon)$-spanner of $K$ with $O(n \log n)$ edges in
$O(n \log n)$ time. The latter result is optimal: We show that for any $2 \leq
k \leq n - \Theta(\sqrt{n \log n})$, spanners with $O(n \log n)$ edges and
stretch factor less than 3 do not exist for all complete $k$-partite geometric
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0616</identifier>
 <datestamp>2008-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0616</id><created>2007-12-04</created><updated>2008-12-05</updated><authors><author><keyname>Zhang</keyname><forenames>Jinshan</forenames></author></authors><title>Upper Bounds for the Number of Hamiltonian Cycles</title><categories>cs.DM</categories><comments>8 pages</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An upper bound for the number of Hamiltonian cycles of symmetric diagraphs is
established first in this paper, which is tighter than the famous Minc's bound
and the Br$\acute{e}$gman's bound. A transformation on graphs is proposed, so
that counting the number of Hamiltonian cycles of an undirected graph can be
done by counting the number of Hamiltonian cycles of its corresponding
symmetric directed graph. In this way, an upper bound for the number of
Hamiltonian cycles of undirected graphs is also obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0653</identifier>
 <datestamp>2009-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0653</id><created>2007-12-05</created><updated>2009-05-11</updated><authors><author><keyname>Watanabe</keyname><forenames>Sumio</forenames></author></authors><title>Equations of States in Singular Statistical Estimation</title><categories>cs.LG</categories><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning machines which have hierarchical structures or hidden variables are
singular statistical models because they are nonidentifiable and their Fisher
information matrices are singular. In singular statistical models, neither the
Bayes a posteriori distribution converges to the normal distribution nor the
maximum likelihood estimator satisfies asymptotic normality. This is the main
reason why it has been difficult to predict their generalization performances
from trained states. In this paper, we study four errors, (1) Bayes
generalization error, (2) Bayes training error, (3) Gibbs generalization error,
and (4) Gibbs training error, and prove that there are mathematical relations
among these errors. The formulas proved in this paper are equations of states
in statistical estimation because they hold for any true distribution, any
parametric model, and any a priori distribution. Also we show that Bayes and
Gibbs generalization errors are estimated by Bayes and Gibbs training errors,
and propose widely applicable information criteria which can be applied to both
regular and singular statistical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0693</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0693</id><created>2007-12-05</created><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Zhang</keyname><forenames>Dan</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author></authors><title>Cryptanalysis of an image encryption scheme based on the Hill cipher</title><categories>cs.CR</categories><comments>10 pages, three figures</comments><doi>10.1631/jzus.A0720102</doi><abstract>  This paper studies the security of an image encryption scheme based on the
Hill cipher and reports its following problems: 1) there is a simple necessary
and sufficient condition that makes a number of secret keys invalid; 2) it is
insensitive to the change of the secret key; 3) it is insensitive to the change
of the plain-image; 4) it can be broken with only one known/chosen-plaintext;
5) it has some other minor defects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0744</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0744</id><created>2007-12-05</created><authors><author><keyname>Ramos</keyname><forenames>Vitorino</forenames></author><author><keyname>Fernandes</keyname><forenames>C. M.</forenames></author><author><keyname>Rosa</keyname><forenames>A. C.</forenames></author><author><keyname>Abraham</keyname><forenames>A.</forenames></author></authors><title>Computational Chemotaxis in Ants and Bacteria over Dynamic Environments</title><categories>cs.MA cs.AI q-bio.PE q-bio.QM</categories><comments>8 pages, 6 figures, in CEC 07 - IEEE Congress on Evolutionary
  Computation, ISBN 1-4244-1340-0, pp. 1009-1017, Sep. 2007</comments><acm-class>I.2; I.2.11; G.1.6</acm-class><abstract>  Chemotaxis can be defined as an innate behavioural response by an organism to
a directional stimulus, in which bacteria, and other single-cell or
multicellular organisms direct their movements according to certain chemicals
in their environment. This is important for bacteria to find food (e.g.,
glucose) by swimming towards the highest concentration of food molecules, or to
flee from poisons. Based on self-organized computational approaches and similar
stigmergic concepts we derive a novel swarm intelligent algorithm. What strikes
from these observations is that both eusocial insects as ant colonies and
bacteria have similar natural mechanisms based on stigmergy in order to emerge
coherent and sophisticated patterns of global collective behaviour. Keeping in
mind the above characteristics we will present a simple model to tackle the
collective adaptation of a social swarm based on real ant colony behaviors (SSA
algorithm) for tracking extrema in dynamic environments and highly multimodal
complex functions described in the well-know De Jong test suite. Later, for the
purpose of comparison, a recent model of artificial bacterial foraging (BFOA
algorithm) based on similar stigmergic features is described and analyzed.
Final results indicate that the SSA collective intelligence is able to cope and
quickly adapt to unforeseen situations even when over the same cooperative
foraging period, the community is requested to deal with two different and
contradictory purposes, while outperforming BFOA in adaptive speed. Results
indicate that the present approach deals well in severe Dynamic Optimization
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0769</identifier>
 <datestamp>2008-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0769</id><created>2007-12-05</created><authors><author><keyname>Baumann</keyname><forenames>Michael</forenames><affiliation>TIMC</affiliation></author><author><keyname>Mozer</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Towards 3D ultrasound image based soft tissue tracking: a transrectal
  ultrasound prostate image alignment system</title><categories>cs.OH physics.med-ph</categories><proxy>ccsd hal-00193084</proxy><journal-ref>Dans Proceedings of MICCAI 2007 - Medical Image Computing and
  Computer Assisted Interventions 2007, Brisbane : Australie (2007)</journal-ref><abstract>  The emergence of real-time 3D ultrasound (US) makes it possible to consider
image-based tracking of subcutaneous soft tissue targets for computer guided
diagnosis and therapy. We propose a 3D transrectal US based tracking system for
precise prostate biopsy sample localisation. The aim is to improve sample
distribution, to enable targeting of unsampled regions for repeated biopsies,
and to make post-interventional quality controls possible. Since the patient is
not immobilized, since the prostate is mobile and due to the fact that probe
movements are only constrained by the rectum during biopsy acquisition, the
tracking system must be able to estimate rigid transformations that are beyond
the capture range of common image similarity measures. We propose a fast and
robust multi-resolution attribute-vector registration approach that combines
global and local optimization methods to solve this problem. Global
optimization is performed on a probe movement model that reduces the
dimensionality of the search space and thus renders optimization efficient. The
method was tested on 237 prostate volumes acquired from 14 different patients
for 3D to 3D and 3D to orthogonal 2D slices registration. The 3D-3D version of
the algorithm converged correctly in 96.7% of all cases in 6.5s with an
accuracy of 1.41mm (r.m.s.) and 3.84mm (max). The 3D to slices method yielded a
success rate of 88.9% in 2.3s with an accuracy of 1.37mm (r.m.s.) and 4.3mm
(max).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0804</identifier>
 <datestamp>2007-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0804</id><created>2007-12-05</created><authors><author><keyname>Gupta</keyname><forenames>A.</forenames></author><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Karimi</keyname><forenames>M.</forenames></author><author><keyname>Kim</keyname><forenames>E. J.</forenames></author><author><keyname>Rafiey</keyname><forenames>A.</forenames></author></authors><title>Minimum Cost Homomorphisms to Locally Semicomplete and Quasi-Transitive
  Digraphs</title><categories>cs.DM</categories><abstract>  For digraphs $G$ and $H$, a homomorphism of $G$ to $H$ is a mapping $f:\
V(G)\dom V(H)$ such that $uv\in A(G)$ implies $f(u)f(v)\in A(H)$. If, moreover,
each vertex $u \in V(G)$ is associated with costs $c_i(u), i \in V(H)$, then
the cost of a homomorphism $f$ is $\sum_{u\in V(G)}c_{f(u)}(u)$. For each fixed
digraph $H$, the minimum cost homomorphism problem for $H$, denoted
MinHOM($H$), can be formulated as follows: Given an input digraph $G$, together
with costs $c_i(u)$, $u\in V(G)$, $i\in V(H)$, decide whether there exists a
homomorphism of $G$ to $H$ and, if one exists, to find one of minimum cost.
Minimum cost homomorphism problems encompass (or are related to) many well
studied optimization problems such as the minimum cost chromatic partition and
repair analysis problems. We focus on the minimum cost homomorphism problem for
locally semicomplete digraphs and quasi-transitive digraphs which are two
well-known generalizations of tournaments. Using graph-theoretic
characterization results for the two digraph classes, we obtain a full
dichotomy classification of the complexity of minimum cost homomorphism
problems for both classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0811</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0811</id><created>2007-12-05</created><updated>2007-12-19</updated><authors><author><keyname>Baca</keyname><forenames>R.</forenames></author><author><keyname>Snasel</keyname><forenames>V.</forenames></author><author><keyname>Platos</keyname><forenames>J.</forenames></author><author><keyname>Kratky</keyname><forenames>M.</forenames></author><author><keyname>El-Qawasmeh</keyname><forenames>E.</forenames></author></authors><title>The Fast Fibonacci Decompression Algorithm</title><categories>cs.PF cs.OH</categories><abstract>  Data compression has been widely applied in many data processing areas.
Compression methods use variable-size codes with the shorter codes assigned to
symbols or groups of symbols that appear in the data frequently. Fibonacci
coding, as a representative of these codes, is used for compressing small
numbers. Time consumption of a decompression algorithm is not usually as
important as the time of a compression algorithm. However, efficiency of the
decompression may be a critical issue in some cases. For example, a real-time
compression of tree data structures follows this issue. Tree's pages are
decompressed during every reading from a secondary storage into the main
memory. In this case, the efficiency of a decompression algorithm is extremely
important. We have developed a Fast Fibonacci decompression for this purpose.
Our approach is up to $3.5\times$ faster than the original implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0836</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0836</id><created>2007-12-05</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author><author><keyname>Collet</keyname><forenames>Pierre</forenames></author><author><keyname>Sapin</keyname><forenames>Emmanuel</forenames></author></authors><title>Evolving localizations in reaction-diffusion cellular automata</title><categories>cs.AI</categories><comments>Accepted for publication in Int. J. Modern Physics C</comments><journal-ref>International Journal of Modern Physics C (IJMPC) Volume: 19,
  Issue: 4 (April 2008) pp. 557-567</journal-ref><doi>10.1142/S0129183108012376</doi><abstract>  We consider hexagonal cellular automata with immediate cell neighbourhood and
three cell-states. Every cell calculates its next state depending on the
integral representation of states in its neighbourhood, i.e. how many
neighbours are in each one state. We employ evolutionary algorithms to breed
local transition functions that support mobile localizations (gliders), and
characterize sets of the functions selected in terms of quasi-chemical systems.
Analysis of the set of functions evolved allows to speculate that mobile
localizations are likely to emerge in the quasi-chemical systems with limited
diffusion of one reagent, a small number of molecules is required for
amplification of travelling localizations, and reactions leading to stationary
localizations involve relatively equal amount of quasi-chemical species.
Techniques developed can be applied in cascading signals in nature-inspired
spatially extended computing devices, and phenomenological studies and
classification of non-linear discrete systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0840</identifier>
 <datestamp>2007-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0840</id><created>2007-12-05</created><authors><author><keyname>Leonid</keyname><affiliation>Aryeh</affiliation></author><author><keyname>Kontorovich</keyname></author></authors><title>A Universal Kernel for Learning Regular Languages</title><categories>cs.LG cs.DM</categories><comments>7 pages</comments><acm-class>F.1.1; D.3.1; F.4.3</acm-class><journal-ref>The 5th International Workshop on Mining and Learning with Graphs,
  2007</journal-ref><abstract>  We give a universal kernel that renders all the regular languages linearly
separable. We are not able to compute this kernel efficiently and conjecture
that it is intractable, but we do have an efficient $\eps$-approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0871</identifier>
 <datestamp>2007-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0871</id><created>2007-12-05</created><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Balancing forward and feedback error correction for erasure channels
  with unreliable feedback</title><categories>cs.IT math.IT</categories><comments>20 pages, 6 pages, submitted to IEEE Transactions on Information
  Theory, an earlier version was presented at ITA '07 in UCSD</comments><abstract>  The traditional information theoretic approach to studying feedback is to
consider ideal instantaneous high-rate feedback of the channel outputs to the
encoder. This was acceptable in classical work because the results were
negative: Shannon pointed out that even perfect feedback often does not improve
capacity and in the context of symmetric DMCs, Dobrushin showed that it does
not improve the fixed block-coding error exponents in the interesting high rate
regime. However, it has recently been shown that perfect feedback does allow
great improvements in the asymptotic tradeoff between end-to-end delay and
probability of error, even for symmetric channels at high rate. Since gains are
claimed with ideal instantaneous feedback, it is natural to wonder whether
these improvements remain if the feedback is unreliable or otherwise limited.
  Here, packet-erasure channels are considered on both the forward and feedback
links. First, the feedback channel is considered as a given and a strategy is
given to balance forward and feedback error correction in the suitable
information-theoretic limit of long end-to-end delays. At high enough rates,
perfect-feedback performance is asymptotically attainable despite having only
unreliable feedback! Second, the results are interpreted in the zero- sum case
of &quot;half-duplex&quot; nodes where the allocation of bandwidth or time to the
feedback channel comes at the direct expense of the forward channel. It turns
out that even here, feedback is worthwhile since dramatically lower asymptotic
delays are possible by appropriately balancing forward and feedback error
correction.
  The results easily generalize to channels with strictly positive
zero-undeclared-error capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0873</identifier>
 <datestamp>2007-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0873</id><created>2007-12-05</created><authors><author><keyname>Chang</keyname><forenames>Cheng</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>The price of ignorance: The impact of side-information on delay for
  lossless source-coding</title><categories>cs.IT math.IT</categories><comments>25 pages, 17 figures. Submitted to the IEEE Transactions on
  Information Theory</comments><abstract>  Inspired by the context of compressing encrypted sources, this paper
considers the general tradeoff between rate, end-to-end delay, and probability
of error for lossless source coding with side-information. The notion of
end-to-end delay is made precise by considering a sequential setting in which
source symbols are revealed in real time and need to be reconstructed at the
decoder within a certain fixed latency requirement. Upper bounds are derived on
the reliability functions with delay when side-information is known only to the
decoder as well as when it is also known at the encoder.
  When the encoder is not ignorant of the side-information (including the
trivial case when there is no side-information), it is possible to have
substantially better tradeoffs between delay and probability of error at all
rates. This shows that there is a fundamental price of ignorance in terms of
end-to-end delay when the encoder is not aware of the side information. This
effect is not visible if only fixed-block-length codes are considered. In this
way, side-information in source-coding plays a role analogous to that of
feedback in channel coding.
  While the theorems in this paper are asymptotic in terms of long delays and
low probabilities of error, an example is used to show that the qualitative
effects described here are significant even at short and moderate delays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0917</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0917</id><created>2007-12-06</created><authors><author><keyname>Bethke</keyname><forenames>Inge</forenames></author><author><keyname>Rodenburg</keyname><forenames>Piet</forenames></author></authors><title>Some properties of finite meadows</title><categories>math.RA cs.SC</categories><comments>8 pages, 1 table</comments><abstract>  The aim of this note is to describe the structure of finite meadows. We will
show that the class of finite meadows is the closure of the class of finite
fields under finite products. As a corollary, we obtain a unique representation
of minimal meadows in terms of prime fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0932</identifier>
 <datestamp>2008-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0932</id><created>2007-12-06</created><authors><author><keyname>Deepthi</keyname><forenames>Dasika Ratna</forenames></author><author><keyname>Kuchibhotla</keyname><forenames>Sujeet</forenames></author><author><keyname>Eswaran</keyname><forenames>K.</forenames></author></authors><title>Dimensionality Reduction and Reconstruction using Mirroring Neural
  Networks and Object Recognition based on Reduced Dimension Characteristic
  Vector</title><categories>cs.CV cs.AI cs.NE</categories><comments>Presented in IEEE International Conference on Advances in Computer
  Vision and Information Technology (ACVIT-07), Nov. 28-30 2007</comments><journal-ref>IEEE International Conference On Advances in Computer Vision and
  Information Tech. (IEEE, ACVIT-07), pp. 348 - 353 (2007)</journal-ref><abstract>  In this paper, we present a Mirroring Neural Network architecture to perform
non-linear dimensionality reduction and Object Recognition using a reduced
lowdimensional characteristic vector. In addition to dimensionality reduction,
the network also reconstructs (mirrors) the original high-dimensional input
vector from the reduced low-dimensional data. The Mirroring Neural Network
architecture has more number of processing elements (adalines) in the outer
layers and the least number of elements in the central layer to form a
converging-diverging shape in its configuration. Since this network is able to
reconstruct the original image from the output of the innermost layer (which
contains all the information about the input pattern), these outputs can be
used as object signature to classify patterns. The network is trained to
minimize the discrepancy between actual output and the input by back
propagating the mean squared error from the output layer to the input layer.
After successfully training the network, it can reduce the dimension of input
vectors and mirror the patterns fed to it. The Mirroring Neural Network
architecture gave very good results on various test patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0938</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0938</id><created>2007-12-06</created><authors><author><keyname>Deepthi</keyname><forenames>Dasika Ratna</forenames></author><author><keyname>Krishna</keyname><forenames>G. R. Aditya</forenames></author><author><keyname>Eswaran</keyname><forenames>K.</forenames></author></authors><title>Automatic Pattern Classification by Unsupervised Learning Using
  Dimensionality Reduction of Data with Mirroring Neural Networks</title><categories>cs.LG cs.AI cs.NE</categories><comments>Presented in IEEE International Conference on Advances in Computer
  Vision and Information Technology (ACVIT-07), Nov. 28-30 2007</comments><journal-ref>IEEE International Conference on Advances in Computer Vision and
  Information Tech. (IEEE, ACVIT-07), pp. 354 - 360 (2007)</journal-ref><abstract>  This paper proposes an unsupervised learning technique by using Multi-layer
Mirroring Neural Network and Forgy's clustering algorithm. Multi-layer
Mirroring Neural Network is a neural network that can be trained with
generalized data inputs (different categories of image patterns) to perform
non-linear dimensionality reduction and the resultant low-dimensional code is
used for unsupervised pattern classification using Forgy's algorithm. By
adapting the non-linear activation function (modified sigmoidal function) and
initializing the weights and bias terms to small random values, mirroring of
the input pattern is initiated. In training, the weights and bias terms are
changed in such a way that the input presented is reproduced at the output by
back propagating the error. The mirroring neural network is capable of reducing
the input vector to a great degree (approximately 1/30th the original size) and
also able to reconstruct the input pattern at the output layer from this
reduced code units. The feature set (output of central hidden layer) extracted
from this network is fed to Forgy's algorithm, which classify input data
patterns into distinguishable classes. In the implementation of Forgy's
algorithm, initial seed points are selected in such a way that they are distant
enough to be perfectly grouped into different categories. Thus a new method of
unsupervised learning is formulated and demonstrated in this paper. This method
gave impressive results when applied to classification of different image
patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0948</identifier>
 <datestamp>2007-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0948</id><created>2007-12-06</created><authors><author><keyname>Woltran</keyname><forenames>Stefan</forenames></author></authors><title>A Common View on Strong, Uniform, and Other Notions of Equivalence in
  Answer-Set Programming</title><categories>cs.AI cs.LO</categories><abstract>  Logic programming under the answer-set semantics nowadays deals with numerous
different notions of program equivalence. This is due to the fact that
equivalence for substitution (known as strong equivalence) and ordinary
equivalence are different concepts. The former holds, given programs P and Q,
iff P can be faithfully replaced by Q within any context R, while the latter
holds iff P and Q provide the same output, that is, they have the same answer
sets. Notions in between strong and ordinary equivalence have been introduced
as theoretical tools to compare incomplete programs and are defined by either
restricting the syntactic structure of the considered context programs R or by
bounding the set A of atoms allowed to occur in R (relativized equivalence).For
the latter approach, different A yield properly different equivalence notions,
in general. For the former approach, however, it turned out that any
``reasonable'' syntactic restriction to R coincides with either ordinary,
strong, or uniform equivalence. In this paper, we propose a parameterization
for equivalence notions which takes care of both such kinds of restrictions
simultaneously by bounding, on the one hand, the atoms which are allowed to
occur in the rule heads of the context and, on the other hand, the atoms which
are allowed to occur in the rule bodies of the context. We introduce a general
semantical characterization which includes known ones as SE-models (for strong
equivalence) or UE-models (for uniform equivalence) as special cases.
Moreover,we provide complexity bounds for the problem in question and sketch a
possible implementation method.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0975</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0975</id><created>2007-12-06</created><authors><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Shor</keyname><forenames>Peter W.</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Random quantum codes from Gaussian ensembles and an uncertainty relation</title><categories>quant-ph cs.IT math.IT</categories><comments>9 pages, two-column style. This paper is a companion to
  quant-ph/0702005 and quant-ph/0702006</comments><journal-ref>Open Syst. Inf. Dyn. 15 (2008) 71-89</journal-ref><doi>10.1142/S1230161208000079</doi><abstract>  Using random Gaussian vectors and an information-uncertainty relation, we
give a proof that the coherent information is an achievable rate for
entanglement transmission through a noisy quantum channel. The codes are random
subspaces selected according to the Haar measure, but distorted as a function
of the sender's input density operator. Using large deviations techniques, we
show that classical data transmitted in either of two Fourier-conjugate bases
for the coding subspace can be decoded with low probability of error. A
recently discovered information-uncertainty relation then implies that the
quantum mutual information for entanglement encoded into the subspace and
transmitted through the channel will be high. The monogamy of quantum
correlations finally implies that the environment of the channel cannot be
significantly coupled to the entanglement, and concluding, which ensures the
existence of a decoding by the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1014</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1014</id><created>2007-12-06</created><authors><author><keyname>Tserunyan</keyname><forenames>A. V.</forenames></author></authors><title>Characterization Of A Class Of Graphs Related To Pairs Of Disjoint
  Matchings</title><categories>cs.DM</categories><comments>33 pages, 10 figures</comments><journal-ref>Discrete Mathematics 309 (2009) 693--713</journal-ref><doi>10.1016/j.disc.2008.01.004</doi><abstract>  For a given graph consider a pair of disjoint matchings the union of which
contains as many edges as possible. Furthermore, consider the relation of the
cardinalities of a maximum matching and the largest matching in those pairs. It
is known that this relation does not exceed 5/4 for any graph. We characterize
the class of graphs for which this relation is precisely 5/4. Our
characterization implies that these graphs contain a spanning subgraph, every
component of which is the minimal graph of this class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1037</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1037</id><created>2007-12-06</created><authors><author><keyname>Dietrich</keyname><forenames>J. P.</forenames></author></authors><title>The Importance of Being First: Position Dependent Citation Rates on
  arXiv:astro-ph</title><categories>astro-ph cs.DL</categories><comments>accepted for publication in PASP</comments><doi>10.1086/527522</doi><abstract>  We study the dependence of citation counts of e-prints published on the
arXiv:astro-ph server on their position in the daily astro-ph listing. Using
the SPIRES literature database we reconstruct the astro-ph listings from July
2002 to December 2005 and determine citation counts for e-prints from their ADS
entry. We use Zipf plots to analyze the citation distributions for each
astro-ph position. We find that e-prints appearing at or near the top of the
astro-ph mailings receive significantly more citations than those further down
the list. This difference is significant at the 7 sigma level and on average
amounts to two times more citations for papers at the top than those further
down the listing. We propose three possible non-exclusive explanations for this
positional citation effect and try to test them. We conclude that
self-promotion by authors plays a role in the observed effect but cannot
exclude that increased visibility at the top of the daily listings contributes
to higher citation counts as well. We can rule out that the positional
dependence of citations is caused by the coincidence of the submission deadline
with the working hours of a geographically constrained set of intrinsically
higher cited authors. We discuss several ways of mitigating the observed
effect, including splitting astro-ph into several subject classes, randomizing
the order of e-prints, and a novel approach to sorting entries by relevance to
individual readers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1097</identifier>
 <datestamp>2007-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1097</id><created>2007-12-07</created><authors><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author><author><keyname>Planes</keyname><forenames>Jordi</forenames></author></authors><title>On Using Unsatisfiability for Solving Maximum Satisfiability</title><categories>cs.AI cs.DS</categories><abstract>  Maximum Satisfiability (MaxSAT) is a well-known optimization pro- blem, with
several practical applications. The most widely known MAXS AT algorithms are
ineffective at solving hard problems instances from practical application
domains. Recent work proposed using efficient Boolean Satisfiability (SAT)
solvers for solving the MaxSAT problem, based on identifying and eliminating
unsatisfiable subformulas. However, these algorithms do not scale in practice.
This paper analyzes existing MaxSAT algorithms based on unsatisfiable
subformula identification. Moreover, the paper proposes a number of key
optimizations to these MaxSAT algorithms and a new alternative algorithm. The
proposed optimizations and the new algorithm provide significant performance
improvements on MaxSAT instances from practical applications. Moreover, the
efficiency of the new generation of unsatisfiability-based MaxSAT solvers
becomes effectively indexed to the ability of modern SAT solvers to proving
unsatisfiability and identifying unsatisfiable subformulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1163</identifier>
 <datestamp>2008-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1163</id><created>2007-12-07</created><updated>2008-05-02</updated><authors><author><keyname>Schuetz</keyname><forenames>Philipp</forenames></author><author><keyname>Caflisch</keyname><forenames>Amedeo</forenames></author></authors><title>Efficient modularity optimization by multistep greedy algorithm and
  vertex mover refinement</title><categories>cs.DS cond-mat.dis-nn cs.DM physics.soc-ph</categories><comments>7 pages, parts of text rewritten, illustrations and pseudocode
  representation of algorithms added</comments><journal-ref>Phys. Rev. E 77,046112 (2008)</journal-ref><doi>10.1103/PhysRevE.77.046112</doi><abstract>  Identifying strongly connected substructures in large networks provides
insight into their coarse-grained organization. Several approaches based on the
optimization of a quality function, e.g., the modularity, have been proposed.
We present here a multistep extension of the greedy algorithm (MSG) that allows
the merging of more than one pair of communities at each iteration step. The
essential idea is to prevent the premature condensation into few large
communities. Upon convergence of the MSG a simple refinement procedure called
&quot;vertex mover&quot; (VM) is used for reassigning vertices to neighboring communities
to improve the final modularity value. With an appropriate choice of the step
width, the combined MSG-VM algorithm is able to find solutions of higher
modularity than those reported previously. The multistep extension does not
alter the scaling of computational cost of the greedy algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1167</identifier>
 <datestamp>2007-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1167</id><created>2007-12-07</created><authors><author><keyname>Marzulo</keyname><forenames>Leandro A. J.</forenames></author><author><keyname>Fran&#xe7;a</keyname><forenames>Felipe M. G.</forenames></author><author><keyname>Costa</keyname><forenames>V&#xed;tor Santos</forenames></author></authors><title>Transactional WaveCache: Towards Speculative and Out-of-Order DataFlow
  Execution of Memory Operations</title><categories>cs.AR cs.DC</categories><comments>Submitted to ACM International Conference on Computing Frontiers
  2008, http://www.computingfrontiers.org/, 20 pages</comments><acm-class>C.1.3</acm-class><abstract>  The WaveScalar is the first DataFlow Architecture that can efficiently
provide the sequential memory semantics required by imperative languages. This
work presents an alternative memory ordering mechanism for this architecture,
the Transaction WaveCache. Our mechanism maintains the execution order of
memory operations within blocks of code, called Waves, but adds the ability to
speculatively execute, out-of-order, operations from different waves. This
ordering mechanism is inspired by progress in supporting Transactional
Memories. Waves are considered as atomic regions and executed as nested
transactions. If a wave has finished the execution of all its memory
operations, as soon as the previous waves are committed, it can be committed.
If a hazard is detected in a speculative Wave, all the following Waves
(children) are aborted and re-executed. We evaluate the WaveCache on a set
artificial benchmarks. If the benchmark does not access memory often, we could
achieve speedups of around 90%. Speedups of 33.1% and 24% were observed on more
memory intensive applications, and slowdowns up to 16% arise if memory
bandwidth is a bottleneck. For an application full of WAW, WAR and RAW hazards,
a speedup of 139.7% was verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1169</identifier>
 <datestamp>2009-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1169</id><created>2007-12-07</created><updated>2009-07-24</updated><authors><author><keyname>Cui</keyname><forenames>Shengshan</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames></author><author><keyname>Somekh</keyname><forenames>Oren</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Opportunistic Relaying in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>17 pages, 8 figures, To appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relay networks having $n$ source-to-destination pairs and $m$ half-duplex
relays, all operating in the same frequency band in the presence of block
fading, are analyzed. This setup has attracted significant attention and
several relaying protocols have been reported in the literature. However, most
of the proposed solutions require either centrally coordinated scheduling or
detailed channel state information (CSI) at the transmitter side. Here, an
opportunistic relaying scheme is proposed, which alleviates these limitations.
The scheme entails a two-hop communication protocol, in which sources
communicate with destinations only through half-duplex relays. The key idea is
to schedule at each hop only a subset of nodes that can benefit from
\emph{multiuser diversity}. To select the source and destination nodes for each
hop, it requires only CSI at receivers (relays for the first hop, and
destination nodes for the second hop) and an integer-value CSI feedback to the
transmitters. For the case when $n$ is large and $m$ is fixed, it is shown that
the proposed scheme achieves a system throughput of $m/2$ bits/s/Hz. In
contrast, the information-theoretic upper bound of $(m/2)\log \log n$ bits/s/Hz
is achievable only with more demanding CSI assumptions and cooperation between
the relays. Furthermore, it is shown that, under the condition that the product
of block duration and system bandwidth scales faster than $\log n$, the
achievable throughput of the proposed scheme scales as $\Theta ({\log n})$.
Notably, this is proven to be the optimal throughput scaling even if
centralized scheduling is allowed, thus proving the optimality of the proposed
scheme in the scaling law sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1182</identifier>
 <datestamp>2007-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1182</id><created>2007-12-07</created><authors><author><keyname>Josang</keyname><forenames>Audun</forenames></author></authors><title>Cumulative and Averaging Fission of Beliefs</title><categories>cs.AI cs.LO</categories><comments>7 pages, 4 figures, working paper</comments><abstract>  Belief fusion is the principle of combining separate beliefs or bodies of
evidence originating from different sources. Depending on the situation to be
modelled, different belief fusion methods can be applied. Cumulative and
averaging belief fusion is defined for fusing opinions in subjective logic, and
for fusing belief functions in general. The principle of fission is the
opposite of fusion, namely to eliminate the contribution of a specific belief
from an already fused belief, with the purpose of deriving the remaining
belief. This paper describes fission of cumulative belief as well as fission of
averaging belief in subjective logic. These operators can for example be
applied to belief revision in Bayesian belief networks, where the belief
contribution of a given evidence source can be determined as a function of a
given fused belief and its other contributing beliefs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1189</identifier>
 <datestamp>2007-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1189</id><created>2007-12-07</created><authors><author><keyname>Zendra</keyname><forenames>Olivier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Jul</keyname><forenames>Eric</forenames><affiliation>DIKU</affiliation></author><author><keyname>Ducournau</keyname><forenames>Roland</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Gagnon</keyname><forenames>Etienne</forenames><affiliation>RACE LAB</affiliation></author><author><keyname>Jones</keyname><forenames>Richard E.</forenames><affiliation>RACE LAB</affiliation></author><author><keyname>Krintz</keyname><forenames>Chandra</forenames><affiliation>RACE LAB</affiliation></author><author><keyname>Mulet</keyname><forenames>Philippe</forenames><affiliation>S3L</affiliation></author><author><keyname>Vitek</keyname><forenames>Jan</forenames><affiliation>S3L</affiliation></author></authors><title>Implementation, Compilation, Optimization of Object-Oriented Languages,
  Programs and Systems - Report on the Workshop ICOOOLPS'2007 at ECOOP'07</title><categories>cs.PL cs.SE</categories><proxy>ccsd inria-00194953</proxy><journal-ref>ECOOP 2007 Workshop Reader Springer (Ed.) (2008)</journal-ref><abstract>  ICOOOLPS'2007 was the second edition of the ECOOP-ICOOOLPS workshop. ICOOOLPS
intends to bring researchers and practitioners both from academia and industry
together, with a spirit of openness, to try and identify and begin to address
the numerous and very varied issues of optimization. After a first successful
edition, this second one put a stronger emphasis on exchanges and discussions
amongst the participants, progressing on the bases set last year in Nantes. The
workshop attendance was a success, since the 30-people limit we had set was
reached about 2 weeks before the workshop itself. Some of the discussions (e.g.
annotations) were so successful that they would required even more time than we
were able to dedicate to them. That's one area we plan to further improve for
the next edition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1205</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1205</id><created>2007-12-07</created><updated>2008-01-09</updated><authors><author><keyname>Jagadeesan</keyname><forenames>Radha</forenames></author><author><keyname>Jeffrey</keyname><forenames>Alan</forenames></author><author><keyname>Pitcher</keyname><forenames>Corin</forenames></author><author><keyname>Riely</keyname><forenames>James</forenames></author></authors><title>Lambda-RBAC: Programming with Role-Based Access Control</title><categories>cs.PL cs.CR</categories><comments>LMCS</comments><acm-class>F.4.1; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 1 (January 9,
  2008) lmcs:1195</journal-ref><doi>10.2168/LMCS-4(1:2)2008</doi><abstract>  We study mechanisms that permit program components to express role
constraints on clients, focusing on programmatic security mechanisms, which
permit access controls to be expressed, in situ, as part of the code realizing
basic functionality. In this setting, two questions immediately arise: (1) The
user of a component faces the issue of safety: is a particular role sufficient
to use the component? (2) The component designer faces the dual issue of
protection: is a particular role demanded in all execution paths of the
component? We provide a formal calculus and static analysis to answer both
questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1224</identifier>
 <datestamp>2008-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1224</id><created>2007-12-07</created><updated>2008-06-27</updated><authors><author><keyname>Lakkaraju</keyname><forenames>Kiran</forenames></author><author><keyname>Slagell</keyname><forenames>Adam</forenames></author></authors><title>Evaluating the Utility of Anonymized Network Traces for Intrusion
  Detection</title><categories>cs.CR</categories><comments>* Updated version. * 17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anonymization is the process of removing or hiding sensitive information in
logs. Anonymization allows organizations to share network logs while not
exposing sensitive information. However, there is an inherent trade off between
the amount of information revealed in the log and the usefulness of the log to
the client (the utility of a log). There are many anonymization techniques, and
there are many ways to anonymize a particular log (that is, which fields to
anonymize and how). Different anonymization policies will result in logs with
varying levels of utility for analysis. In this paper we explore the effect of
different anonymization policies on logs. We provide an empirical analysis of
the effect of varying anonymization policies by looking at the number of alerts
generated by an Intrusion Detection System. This is the first work to
thoroughly evaluate the effect of single field anonymization policies on a data
set. Our main contributions are to determine a set of fields that have a large
impact on the utility of a log.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1279</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1279</id><created>2007-12-08</created><authors><author><keyname>Caporaso</keyname><forenames>Salvatore</forenames></author><author><keyname>Corriero</keyname><forenames>Nicola</forenames></author></authors><title>Kleene, Rogers and Rice Theorems Revisited in C and in Bash</title><categories>cs.LO</categories><comments>10 pages</comments><acm-class>F.4.1</acm-class><abstract>  The recursion theorem in the weak form {e}(z)=x(e,z) (universal function not
needed) and in Rogers form {n}(z)={{x}(n)}(z) and Rice theorem are proved a
first time using programs in C, and a second time with scripts in Bash.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1309</identifier>
 <datestamp>2008-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1309</id><created>2007-12-10</created><updated>2008-02-24</updated><authors><author><keyname>Duda</keyname><forenames>Jarek</forenames></author></authors><title>Complex base numeral systems</title><categories>math.DS cs.DM</categories><comments>19 pages, 7 figures</comments><abstract>  In this paper will be introduced large, probably complete family of complex
base systems, which are 'proper' - for each point of the space there is a
representation which is unique for all but some zero measure set. The condition
defining this family is the periodicity - we get periodic covering of the plane
by fractals in hexagonal-type structure, what can be used for example in image
compression. There will be introduced full methodology of analyzing and using
this approach - both for the integer part: periodic lattice and the fractional:
attractor of some IFS, for which the convex hull or properties like dimension
of the boundary can be found analytically. There will be also shown how to
generalize this approach to higher dimensions and found some proper systems in
dimension 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1310</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1310</id><created>2007-12-08</created><authors><author><keyname>Cherbanski</keyname><forenames>Lev</forenames></author></authors><title>About Algorithm for Transformation of Logic Functions (ATLF)</title><categories>cs.LO cs.AI</categories><comments>25 pages, in English, German and Russian</comments><abstract>  In this article the algorithm for transformation of logic functions which are
given by truth tables is considered. The suggested algorithm allows the
transformation of many-valued logic functions with the required number of
variables and can be looked in this sense as universal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1337</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1337</id><created>2007-12-09</created><updated>2008-12-09</updated><authors><author><keyname>Bloom</keyname><forenames>S. L.</forenames></author><author><keyname>Esik</keyname><forenames>Z.</forenames></author></authors><title>Axiomatizing rational power series</title><categories>cs.LO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iteration semirings are Conway semirings satisfying Conway's group
identities. We show that the semirings $\N^{\rat}\llangle \Sigma^* \rrangle$ of
rational power series with coefficients in the semiring $\N$ of natural numbers
are the free partial iteration semirings. Moreover, we characterize the
semirings $\N_\infty^{\rat}\llangle \Sigma^* \rrangle$ as the free semirings in
the variety of iteration semirings defined by three additional simple
identities, where $\N_\infty$ is the completion of $\N$ obtained by adding a
point of infinity. We also show that this latter variety coincides with the
variety generated by the complete, or continuous semirings. As a consequence of
these results, we obtain that the semirings $\N_\infty^{\rat}\llangle \Sigma^*
\rrangle$, equipped with the sum order, are free in the class of symmetric
inductive $^*$-semirings. This characterization corresponds to Kozen's
axiomatization of regular languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1339</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1339</id><created>2007-12-09</created><authors><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Joint Receiver and Transmitter Optimization for Energy-Efficient CDMA
  Communications</title><categories>cs.IT cs.GT math.IT</categories><comments>To appear in the IEEE Journal on Selected Areas in Communications -
  Special Issue on Multiuser Detection for Advanced Communication Systems and
  Networks</comments><abstract>  This paper focuses on the cross-layer issue of joint multiuser detection and
resource allocation for energy efficiency in wireless CDMA networks. In
particular, assuming that a linear multiuser detector is adopted in the uplink
receiver, the case considered is that in which each terminal is allowed to vary
its transmit power, spreading code, and uplink receiver in order to maximize
its own utility, which is defined as the ratio of data throughput to transmit
power. Resorting to a game-theoretic formulation, a non-cooperative game for
utility maximization is formulated, and it is proved that a unique Nash
equilibrium exists, which, under certain conditions, is also Pareto-optimal.
Theoretical results concerning the relationship between the problems of SINR
maximization and MSE minimization are given, and, resorting to the tools of
large system analysis, a new distributed power control algorithm is
implemented, based on very little prior information about the user of interest.
The utility profile achieved by the active users in a large CDMA system is also
computed, and, moreover, the centralized socially optimum solution is analyzed.
Considerations on the extension of the proposed framework to a multi-cell
scenario are also briefly detailed. Simulation results confirm that the
proposed non-cooperative game largely outperforms competing alternatives, and
that it exhibits a quite small performance loss with respect to the socially
optimum solution, and only in the case in which the users number exceeds the
processing gain. Finally, results also show an excellent agreement between the
theoretical closed-form formulas based on large system analysis and the outcome
of numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1345</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1345</id><created>2007-12-09</created><updated>2008-10-15</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Sequential operators in computability logic</title><categories>cs.LO cs.AI math.LO</categories><comments>To appear in &quot;Information and Computation&quot;</comments><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Information and Computation 206 (2008), pp. 1443-1475</journal-ref><doi>10.1016/j.ic.2008.10.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computability logic (CL) (see http://www.cis.upenn.edu/~giorgi/cl.html) is a
semantical platform and research program for redeveloping logic as a formal
theory of computability, as opposed to the formal theory of truth which it has
more traditionally been. Formulas in CL stand for (interactive) computational
problems, understood as games between a machine and its environment; logical
operators represent operations on such entities; and &quot;truth&quot; is understood as
existence of an effective solution, i.e., of an algorithmic winning strategy.
  The formalism of CL is open-ended, and may undergo series of extensions as
the study of the subject advances. The main groups of operators on which CL has
been focused so far are the parallel, choice, branching, and blind operators.
The present paper introduces a new important group of operators, called
sequential. The latter come in the form of sequential conjunction and
disjunction, sequential quantifiers, and sequential recurrences. As the name
may suggest, the algorithmic intuitions associated with this group are those of
sequential computations, as opposed to the intuitions of parallel computations
associated with the parallel group of operations: playing a sequential
combination of games means playing its components in a sequential fashion, one
after one.
  The main technical result of the present paper is a sound and complete
axiomatization of the propositional fragment of computability logic whose
vocabulary, together with negation, includes all three -- parallel, choice and
sequential -- sorts of conjunction and disjunction. An extension of this result
to the first-order level is also outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1359</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1359</id><created>2007-12-09</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>Borel Ranks and Wadge Degrees of Context Free Omega Languages</title><categories>cs.LO cs.GT math.LO</categories><proxy>ccsd hal-00139169</proxy><journal-ref>Mathematical Structures in Computer Science 16 (5) (2006) 813-840</journal-ref><abstract>  We show that, from a topological point of view, considering the Borel and the
Wadge hierarchies, 1-counter B\&quot;uchi automata have the same accepting power
than Turing machines equipped with a B\&quot;uchi acceptance condition. In
particular, for every non null recursive ordinal alpha, there exist some
Sigma^0_alpha-complete and some Pi^0_alpha-complete omega context free
languages accepted by 1-counter B\&quot;uchi automata, and the supremum of the set
of Borel ranks of context free omega languages is the ordinal gamma^1_2 which
is strictly greater than the first non recursive ordinal. This very surprising
result gives answers to questions of H. Lescow and W. Thomas [Logical
Specifications of Infinite Computations, In:&quot;A Decade of Concurrency&quot;, LNCS
803, Springer, 1994, p. 583-621].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1363</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1363</id><created>2007-12-09</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>Undecidable Problems About Timed Automata</title><categories>cs.LO cs.CC math.LO</categories><proxy>ccsd hal-00121529</proxy><journal-ref>Dans Proceedings of the 4th International Conference on Formal
  Modelling and Analysis of Timed Systems - FORMATS'06, France (2006)</journal-ref><abstract>  We solve some decision problems for timed automata which were recently raised
by S. Tripakis in [ Folk Theorems on the Determinization and Minimization of
Timed Automata, in the Proceedings of the International Workshop FORMATS'2003,
LNCS, Volume 2791, p. 182-188, 2004 ] and by E. Asarin in [ Challenges in Timed
Languages, From Applied Theory to Basic Theory, Bulletin of the EATCS, Volume
83, p. 106-120, 2004 ]. In particular, we show that one cannot decide whether a
given timed automaton is determinizable or whether the complement of a timed
regular language is timed regular. We show that the problem of the minimization
of the number of clocks of a timed automaton is undecidable. It is also
undecidable whether the shuffle of two timed regular languages is timed
regular. We show that in the case of timed B\&quot;uchi automata accepting infinite
timed words some of these problems are Pi^1_1-hard, hence highly undecidable
(located beyond the arithmetical hierarchy).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1365</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1365</id><created>2007-12-09</created><authors><author><keyname>Vazquez</keyname><forenames>Alexei</forenames></author></authors><title>Population stratification using a statistical model on hypergraphs</title><categories>q-bio.PE cs.AI physics.data-an</categories><comments>7 pages, 6 figures</comments><journal-ref>Phys. Rev. E 77, 066106 (2008)</journal-ref><doi>10.1103/PhysRevE.77.066106</doi><abstract>  Population stratification is a problem encountered in several areas of
biology and public health. We tackle this problem by mapping a population and
its elements attributes into a hypergraph, a natural extension of the concept
of graph or network to encode associations among any number of elements. On
this hypergraph, we construct a statistical model reflecting our intuition
about how the elements attributes can emerge from a postulated population
structure. Finally, we introduce the concept of stratification
representativeness as a mean to identify the simplest stratification already
containing most of the information about the population structure. We
demonstrate the power of this framework stratifying an animal and a human
population based on phenotypic and genotypic properties, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1400</identifier>
 <datestamp>2009-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1400</id><created>2007-12-10</created><updated>2007-12-10</updated><authors><author><keyname>Li</keyname><forenames>An-Ping</forenames></author></authors><title>Birthday attack to discrete logarithm</title><categories>cs.CR</categories><comments>4 pages</comments><abstract>  The discrete logarithm in a finite group of large order has been widely
applied in public key cryptosystem. In this paper, we will present a
probabilistic algorithm for discrete logarithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1402</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1402</id><created>2007-12-10</created><updated>2010-03-08</updated><authors><author><keyname>Bresler</keyname><forenames>Guy</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Sly</keyname><forenames>Allan</forenames></author></authors><title>Reconstruction of Markov Random Fields from Samples: Some Easy
  Observations and Algorithms</title><categories>cs.CC cs.LG</categories><comments>14 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov random fields are used to model high dimensional distributions in a
number of applied areas. Much recent interest has been devoted to the
reconstruction of the dependency structure from independent samples from the
Markov random fields. We analyze a simple algorithm for reconstructing the
underlying graph defining a Markov random field on $n$ nodes and maximum degree
$d$ given observations. We show that under mild non-degeneracy conditions it
reconstructs the generating graph with high probability using $\Theta(d
\epsilon^{-2}\delta^{-4} \log n)$ samples where $\epsilon,\delta$ depend on the
local interactions. For most local interaction $\eps,\delta$ are of order
$\exp(-O(d))$.
  Our results are optimal as a function of $n$ up to a multiplicative constant
depending on $d$ and the strength of the local interactions. Our results seem
to be the first results for general models that guarantee that {\em the}
generating model is reconstructed. Furthermore, we provide explicit $O(n^{d+2}
\epsilon^{-2}\delta^{-4} \log n)$ running time bound. In cases where the
measure on the graph has correlation decay, the running time is $O(n^2 \log n)$
for all fixed $d$. We also discuss the effect of observing noisy samples and
show that as long as the noise level is low, our algorithm is effective. On the
other hand, we construct an example where large noise implies
non-identifiability even for generic noise and interactions. Finally, we
briefly show that in some simple cases, models with hidden nodes can also be
recovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1442</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1442</id><created>2007-12-10</created><authors><author><keyname>K&#xf6;rner</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Simonyi</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Sinaimeri</keyname><forenames>Blerina</forenames></author></authors><title>On types of growth for graph-different permutations</title><categories>math.CO cs.IT math.IT</categories><comments>14 pages+title page</comments><msc-class>05D05</msc-class><abstract>  We consider an infinite graph G whose vertex set is the set of natural
numbers and adjacency depends solely on the difference between vertices. We
study the largest cardinality of a set of permutations of [n] any pair of which
differ somewhere in a pair of adjacent vertices of G and determine it
completely in an interesting special case. We give estimates for other cases
and compare the results in case of complementary graphs. We also explore the
close relationship between our problem and the concept of Shannon capacity
&quot;within a given type&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1499</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1499</id><created>2007-12-10</created><authors><author><keyname>Aehlig</keyname><forenames>Klaus</forenames></author><author><keyname>Beckmann</keyname><forenames>Arnold</forenames></author></authors><title>On the computational complexity of cut-reduction</title><categories>cs.LO cs.CC</categories><comments>41 pages, technical report (CS, Swansea University)</comments><report-no>CSR15-2007</report-no><acm-class>F.4.1</acm-class><abstract>  Using appropriate notation systems for proofs, cut-reduction can often be
rendered feasible on these notations, and explicit bounds can be given.
Developing a suitable notation system for Bounded Arithmetic, and applying
these bounds, all the known results on definable functions of certain such
theories can be reobtained in a uniform way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1519</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1519</id><created>2007-12-10</created><authors><author><keyname>Roux</keyname><forenames>St&#xe9;phane Le</forenames><affiliation>LIP</affiliation></author></authors><title>Discrete Nondeterminism and Nash Equilibria for Strategy-Based Games</title><categories>cs.GT</categories><proxy>ccsd inria-00195397</proxy><abstract>  Several notions of game enjoy a Nash-like notion of equilibrium without
guarantee of existence. There are different ways of weakening a definition of
Nash-like equilibrium in order to guarantee the existence of a weakened
equilibrium. Nash's approach to the problem for strategic games is
probabilistic, \textit{i.e.} continuous, and static. CP and BR approaches for
CP and BR games are discrete and dynamic. This paper proposes an approach that
lies between those two different approaches: a discrete and static approach.
multi strategic games are introduced as a formalism that is able to express
both sequential and simultaneous decision-making, which promises a good
modelling power. multi strategic games are a generalisation of strategic games
and sequential graph games that still enjoys a Cartesian product structure,
\textit{i.e.} where agent actually choose their strategies. A pre-fixed point
result allows guaranteeing existence of discrete and non deterministic
equilibria. On the one hand, these equilibria can be computed with polynomial
(low) complexity. On the other hand, they are effective in terms of
recommendation, as shown by a numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1521</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1521</id><created>2007-12-10</created><authors><author><keyname>Roux</keyname><forenames>St&#xe9;phane Le</forenames><affiliation>LIP</affiliation></author></authors><title>Graphs and Path Equilibria</title><categories>cs.GT</categories><proxy>ccsd inria-00195379</proxy><abstract>  The quest for optimal/stable paths in graphs has gained attention in a few
practical or theoretical areas. To take part in this quest this chapter adopts
an equilibrium-oriented approach that is abstract and general: it works with
(quasi-arbitrary) arc-labelled digraphs, and it assumes very little about the
structure of the sought paths and the definition of equilibrium, \textit{i.e.}
optimality/stability. In this setting, this chapter presents a sufficient
condition for equilibrium existence for every graph; it also presents a
necessary condition for equilibrium existence for every graph. The necessary
condition does not imply the sufficient condition a priori. However, the
chapter pinpoints their logical difference and thus identifies what work
remains to be done. Moreover, the necessary and the sufficient conditions
coincide when the definition of optimality relates to a total order, which
provides a full-equivalence property. These results are applied to network
routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1529</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1529</id><created>2007-12-01</created><updated>2007-12-13</updated><authors><author><keyname>Saba</keyname><forenames>Walid S.</forenames></author></authors><title>Ontology and Formal Semantics - Integration Overdue</title><categories>cs.AI cs.CL</categories><abstract>  In this note we suggest that difficulties encountered in natural language
semantics are, for the most part, due to the use of mere symbol manipulation
systems that are devoid of any content. In such systems, where there is hardly
any link with our common-sense view of the world, and it is quite difficult to
envision how one can formally account for the considerable amount of content
that is often implicit, but almost never explicitly stated in our everyday
discourse. The solution, in our opinion, is a compositional semantics grounded
in an ontology that reflects our commonsense view of the world and the way we
talk about it in ordinary language. In the compositional logic we envision
there are ontological (or first-intension) concepts, and logical (or
second-intension) concepts, and where the ontological concepts include not only
Davidsonian events, but other abstract objects as well (e.g., states,
processes, properties, activities, attributes, etc.) It will be demonstrated
here that in such a framework, a number of challenges in the semantics of
natural language (e.g., metonymy, intensionality, metaphor, etc.) can be
properly and uniformly addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1532</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1532</id><created>2007-12-10</created><authors><author><keyname>Jonsson</keyname><forenames>Peter</forenames></author><author><keyname>Krokhin</keyname><forenames>Andrei</forenames></author><author><keyname>Kuivinen</keyname><forenames>Fredrik</forenames></author></authors><title>Hard constraint satisfaction problems have hard gaps at location 1</title><categories>cs.CC</categories><abstract>  An instance of Max CSP is a finite collection of constraints on a set of
variables, and the goal is to assign values to the variables that maximises the
number of satisfied constraints. Max CSP captures many well-known problems
(such as Max k-SAT and Max Cut) and is consequently NP-hard. Thus, it is
natural to study how restrictions on the allowed constraint types (or
constraint languages) affect the complexity and approximability of Max CSP. The
PCP theorem is equivalent to the existence of a constraint language for which
Max CSP has a hard gap at location 1, i.e. it is NP-hard to distinguish between
satisfiable instances and instances where at most some constant fraction of the
constraints are satisfiable. All constraint languages, for which the CSP
problem (i.e., the problem of deciding whether all constraints can be
satisfied) is currently known to be NP-hard, have a certain algebraic property.
We prove that any constraint language with this algebraic property makes Max
CSP have a hard gap at location 1 which, in particular, implies that such
problems cannot have a PTAS unless P = NP. We then apply this result to Max CSP
restricted to a single constraint type; this class of problems contains, for
instance, Max Cut and Max DiCut. Assuming P $\neq$ NP, we show that such
problems do not admit PTAS except in some trivial cases. Our results hold even
if the number of occurrences of each variable is bounded by a constant. We use
these results to partially answer open questions and strengthen results by
Engebretsen et al. [Theor. Comput. Sci., 312 (2004), pp. 17--45], Feder et al.
[Discrete Math., 307 (2007), pp. 386--392], Krokhin and Larose [Proc.
Principles and Practice of Constraint Programming (2005), pp. 388--402], and
Jonsson and Krokhin [J. Comput. System Sci., 73 (2007), pp. 691--702]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1549</identifier>
 <datestamp>2007-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1549</id><created>2007-12-10</created><authors><author><keyname>Veldhuizen</keyname><forenames>Todd L.</forenames></author></authors><title>Dynamic Multilevel Graph Visualization</title><categories>cs.GR cs.DM</categories><comments>21 pages</comments><acm-class>H.5.0; G.2.2</acm-class><abstract>  We adapt multilevel, force-directed graph layout techniques to visualizing
dynamic graphs in which vertices and edges are added and removed in an online
fashion (i.e., unpredictably). We maintain multiple levels of coarseness using
a dynamic, randomized coarsening algorithm. To ensure the vertices follow
smooth trajectories, we employ dynamics simulation techniques, treating the
vertices as point particles. We simulate fine and coarse levels of the graph
simultaneously, coupling the dynamics of adjacent levels. Projection from
coarser to finer levels is adaptive, with the projection determined by an
affine transformation that evolves alongside the graph layouts. The result is a
dynamic graph visualizer that quickly and smoothly adapts to changes in a
graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1609</identifier>
 <datestamp>2009-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1609</id><created>2007-12-10</created><updated>2009-09-28</updated><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Distributed Consensus Algorithms in Sensor Networks: Quantized Data and
  Random Link Failures</title><categories>cs.MA cs.IT math.IT</categories><comments>31 pages, 2 figures. Original version submitted Nov, 2007. Revised on
  Aug, 2008. Re-revised on Sept. 2009. Accepted fpr piblication in the IEEE
  Transactions on Signal Processing with mandatory revisions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the problem of distributed average consensus in sensor
networks with quantized data and random link failures. To achieve consensus,
dither (small noise) is added to the sensor states before quantization. When
the quantizer range is unbounded (countable number of quantizer levels),
stochastic approximation shows that consensus is asymptotically achieved with
probability one and in mean square to a finite random variable. We show that
the meansquared error (m.s.e.) can be made arbitrarily small by tuning the link
weight sequence, at a cost of the convergence rate of the algorithm. To study
dithered consensus with random links when the range of the quantizer is
bounded, we establish uniform boundedness of the sample paths of the unbounded
quantizer. This requires characterization of the statistical properties of the
supremum taken over the sample paths of the state of the quantizer. This is
accomplished by splitting the state vector of the quantizer in two components:
one along the consensus subspace and the other along the subspace orthogonal to
the consensus subspace. The proofs use maximal inequalities for submartingale
and supermartingale sequences. From these, we derive probability bounds on the
excursions of the two subsequences, from which probability bounds on the
excursions of the quantizer state vector follow. The paper shows how to use
these probability bounds to design the quantizer parameters and to explore
tradeoffs among the number of quantizer levels, the size of the quantization
steps, the desired probability of saturation, and the desired level of accuracy
$\epsilon$ away from consensus. Finally, the paper illustrates the quantizer
design with a numerical study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1655</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1655</id><created>2007-12-11</created><authors><author><keyname>Hut</keyname><forenames>Piet</forenames><affiliation>IAS, Princeton</affiliation></author></authors><title>Virtual Laboratories and Virtual Worlds</title><categories>astro-ph cs.HC physics.comp-ph</categories><comments>10 pages, 2 figures, Conference proceedings for IAUS246 'Dynamical
  Evolution of Dense Stellar Systems', ed. E. Vesperini (Chief Editor), M.
  Giersz, A. Sills, Capri, Sept. 2007</comments><doi>10.1017/S1743921308016153</doi><abstract>  Since we cannot put stars in a laboratory, astrophysicists had to wait till
the invention of computers before becoming laboratory scientists. For half a
century now, we have been conducting experiments in our virtual laboratories.
However, we ourselves have remained behind the keyboard, with the screen of the
monitor separating us from the world we are simulating. Recently, 3D on-line
technology, developed first for games but now deployed in virtual worlds like
Second Life, is beginning to make it possible for astrophysicists to enter
their virtual labs themselves, in virtual form as avatars. This has several
advantages, from new possibilities to explore the results of the simulations to
a shared presence in a virtual lab with remote collaborators on different
continents. I will report my experiences with the use of Qwaq Forums, a virtual
world developed by a new company (see http://www.qwaq.com)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1658</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1658</id><created>2007-12-11</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Program algebra with a jump-shift instruction</title><categories>cs.PL</categories><comments>19 pages</comments><report-no>PRG0711</report-no><acm-class>D.3.1; D.3.3; F.1.1; F.3.2; F.3.3</acm-class><journal-ref>Journal of Applied Logic, 6(4):553--563, 2008</journal-ref><doi>10.1016/j.jal.2008.07.001</doi><abstract>  We study sequential programs that are instruction sequences with jump-shift
instructions in the setting of PGA (ProGram Algebra). Jump-shift instructions
preceding a jump instruction increase the position to jump to. The jump-shift
instruction is not found in programming practice. Its merit is that the
expressive power of PGA extended with the jump-shift instruction, is not
reduced if the reach of jump instructions is bounded. This is used to show that
there exists a finite-state execution mechanism that by making use of a counter
can produce each finite-state thread from some program that is a finite or
periodic infinite sequence of instructions from a finite set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1659</identifier>
 <datestamp>2007-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1659</id><created>2007-12-11</created><authors><author><keyname>Shenouda</keyname><forenames>Michael Botros</forenames></author><author><keyname>Davidson</keyname><forenames>Timothy N.</forenames></author></authors><title>Non-linear and Linear Broadcasting with QoS Requirements: Tractable
  Approaches for Bounded Channel Uncertainties</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transaction of Signal Processing</comments><abstract>  We consider the downlink of a cellular system in which the base station
employs multiple transmit antennas, each receiver has a single antenna, and the
users specify. We consider communication schemes in which the users have
certain Quality of Service (QoS) requirements. We study the design of robust
broadcasting schemes that minimize the transmission power necessary to
guarantee that the QoS requirements are satisfied for all channels within
bounded uncertainty regions around the transmitter's estimate of each user's
channel. Each user's QoS requirement is formulated as a constraint on the mean
square error (MSE) in its received signal, and we show that these MSE
constraints imply constraints on the received SINR. Using the MSE constraints,
we present a unified design approach for robust linear and non-linear
transceivers with QoS requirements. The proposed designs overcome the
limitations of existing approaches that provide conservative designs or are
only applicable to the case of linear precoding. Furthermore, we provide
computationally-efficient design formulations for a rather general model of
channel uncertainty that subsumes many natural choices for the uncertainty
region. We also consider the problem of the robust counterpart to precoding
schemes that maximize the fidelity of the weakest user's signal subject to a
power constraint. For this problem, we provide quasi-convex formulations, for
both linear and non-linear transceivers, that can be efficiently solved using a
one-dimensional bisection search. Our numerical results demonstrate that in the
presence of CSI uncertainty, the proposed designs provide guarantees for a
larger range of QoS requirements than the existing approaches, and consume
require less transmission power in providing these guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1662</identifier>
 <datestamp>2007-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1662</id><created>2007-12-11</created><authors><author><keyname>Kumar</keyname><forenames>N. Praneeth</forenames></author><author><keyname>Gore</keyname><forenames>Ashutosh Deepak</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author></authors><title>Link Scheduling in STDMA Wireless Networks: A Line Graph Approach</title><categories>cs.NI</categories><comments>4 pages, 1 figure</comments><abstract>  We consider point to point link scheduling in Spatial Time Division Multiple
Access (STDMA) wireless networks under the physical interference model. We
propose a novel link scheduling algorithm based on a line graph representation
of the network, by embedding the interferences between pairs of nodes into the
edge weights of the line graph. Our algorithm achieves lower schedule length
and lower run time complexity than existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1759</identifier>
 <datestamp>2007-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1759</id><created>2007-12-11</created><authors><author><keyname>May</keyname><forenames>Madeth</forenames><affiliation>LIESP</affiliation></author><author><keyname>George</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIESP</affiliation></author><author><keyname>Pr&#xe9;v&#xf4;t</keyname><forenames>Patrick</forenames><affiliation>LIESP</affiliation></author></authors><title>A Web-based System for Observing and Analyzing Computer Mediated
  Communications</title><categories>cs.HC</categories><proxy>ccsd hal-00195951</proxy><journal-ref>Dans Proceedings of the IEEE/WIC/ACM International Conference on
  Web Intelligence (WI 2006) - IEEE/WIC/ACM International Conference on Web
  Intelligence (WI 2006, Hong Kong : Chine (2006)</journal-ref><abstract>  Tracking data of user's activities resulting from Computer Mediated
Communication (CMC) tools (forum, chat, etc.) is often carried out in an ad-hoc
manner, which either confines the reusability of data in different purposes or
makes data exploitation difficult. Our research works are biased toward
methodological challenges involved in designing and developing a generic system
for tracking user's activities while interacting with asynchronous
communication tools like discussion forums. We present in this paper, an
approach for building a Web-based system for observing and analyzing user
activity on any type of discussion forums.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1765</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1765</id><created>2007-12-11</created><updated>2009-05-25</updated><authors><author><keyname>Gimbert</keyname><forenames>Hugo</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Horn</keyname><forenames>Florian</forenames><affiliation>LIAFA, Cwi</affiliation></author></authors><title>Solving Simple Stochastic Games with Few Random Vertices</title><categories>cs.GT</categories><proxy>ccsd hal-00195914</proxy><acm-class>I.2.1; G.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (May 25,
  2009) lmcs:1119</journal-ref><doi>10.2168/LMCS-5(2:9)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simple stochastic games are two-player zero-sum stochastic games with
turn-based moves, perfect information, and reachability winning conditions. We
present two new algorithms computing the values of simple stochastic games.
Both of them rely on the existence of optimal permutation strategies, a class
of positional strategies derived from permutations of the random vertices. The
&quot;permutation-enumeration&quot; algorithm performs an exhaustive search among these
strategies, while the &quot;permutation-improvement&quot; algorithm is based on
successive improvements, \`a la Hoffman-Karp. Our algorithms improve previously
known algorithms in several aspects. First they run in polynomial time when the
number of random vertices is fixed, so the problem of solving simple stochastic
games is fixed-parameter tractable when the parameter is the number of random
vertices. Furthermore, our algorithms do not require the input game to be
transformed into a stopping game. Finally, the permutation-enumeration
algorithm does not use linear programming, while the permutation-improvement
algorithm may run in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1768</identifier>
 <datestamp>2007-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1768</id><created>2007-12-11</created><authors><author><keyname>George</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIESP</affiliation></author><author><keyname>Derycke</keyname><forenames>Alain</forenames><affiliation>TRIGONE</affiliation></author></authors><title>Conceptions et usages des plates-formes de formation, Revue Sciences et
  Technologies de l'Information et de la Communication pour l'\'Education et la
  Formation</title><categories>cs.HC</categories><proxy>ccsd hal-00195853</proxy><journal-ref>Sciences et Technologies de l'Information et de la Communication
  pour l'Education et la Formation 12 (2006) 51-64</journal-ref><abstract>  Educative platforms are at the heart of the development of online education.
They can not only be reduced to technological aspects. Underlying models impact
teaching and learning from the preparing of lessons to the learning sessions.
Research related to these platforms are numerous and their stakes are
important. For these reasons, we launched a call to a special issue on &quot;Designs
and uses of educative platforms&quot; An educative platform is a computer system
designed to automate various functions relating to the organization of the
course, to the management of their content, to the monitoring of learners and
supervision of persons in charge of various formations (Office de la langue
fran\c{c}aise, 2005). So educative platforms are Learning Management Systems
(LMS) which are specific to education contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1775</identifier>
 <datestamp>2007-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1775</id><created>2007-12-11</created><authors><author><keyname>Agarwal</keyname><forenames>Rachit</forenames></author></authors><title>On Computation of Error Locations and Values in Hermitian Codes</title><categories>cs.IT math.IT</categories><comments>10 pages, Submitted to ITW 2008 (with some minor modifications)</comments><abstract>  We obtain a technique to reduce the computational complexity associated with
decoding of Hermitian codes. In particular, we propose a method to compute the
error locations and values using an uni-variate error locator and an
uni-variate error evaluator polynomial. To achieve this, we introduce the
notion of Semi-Erasure Decoding of Hermitian codes and prove that decoding of
Hermitian codes can always be performed using semi-erasure decoding. The
central results are:
  * Searching for error locations require evaluating an univariate error
locator polynomial over $q^2$ points as in Chien search for Reed-Solomon codes.
  * Forney's formula for error value computation in Reed-Solomon codes can
directly be applied to compute the error values in Hermitian codes.
  The approach develops from the idea that transmitting a modified form of the
information may be more efficient that the information itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1800</identifier>
 <datestamp>2007-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1800</id><created>2007-12-11</created><authors><author><keyname>George</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIESP</affiliation></author><author><keyname>Bothorel</keyname><forenames>C&#xe9;cile</forenames><affiliation>TECH/EASY</affiliation></author></authors><title>Conception d'outils de communication sp\'ecifiques au contexte
  \'educatif</title><categories>cs.HC</categories><proxy>ccsd hal-00195874</proxy><journal-ref>Sciences et Technologies de l'Information et de la Communication
  pour l'Education et la Formation 13 (2007) 317-344</journal-ref><abstract>  In a distance learning context, providing usual communication tools (forum,
chat, ...) is not always enough to create efficient interactions between
learners and to favour collective knowledge building. A solution consists in
setting-up collective activities which encourage learners to communicate. But,
even in that case, tools can sometimes become a barrier to communication. We
present in this paper examples of specific tools that are designed in order to
favour and to guide communications in an educational context, but also to
foster interactions during learning activities that are not inherently
collaborative. We describe synchronous communication tools (semi-structured
chat), asynchronous tools (temporally structured forum, contextual forum) and a
system which promotes mutual aid between learners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1803</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1803</id><created>2007-12-11</created><updated>2007-12-19</updated><authors><author><keyname>Galtier</keyname><forenames>Jerome</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Tournament MAC with Constant Size Congestion Window for WLAN</title><categories>cs.NI</categories><proxy>ccsd inria-00195965</proxy><abstract>  In the context of radio distributed networks, we present a generalized
approach for the Medium Access Control (MAC) with fixed congestion window. Our
protocol is quite simple to analyze and can be used in a lot of different
situations. We give mathematical evidence showing that our performance is
tight, in the sense that no protocol with fixed congestion window can do
better. We also place ourselves in the WiFi/WiMAX framework, and show
experimental results enlightening collision reduction of 14% to 21% compared to
the best known other methods. We show channel capacity improvement, and
fairness considerations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1854</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1854</id><created>2007-12-11</created><authors><author><keyname>Liew</keyname><forenames>S. C.</forenames></author><author><keyname>Kai</keyname><forenames>C.</forenames></author><author><keyname>Leung</keyname><forenames>J.</forenames></author><author><keyname>Wong</keyname><forenames>B.</forenames></author></authors><title>Back-of-the-Envelope Computation of Throughput Distributions in CSMA
  Wireless Networks</title><categories>cs.NI cs.PF</categories><abstract>  This work started out with our accidental discovery of a pattern of
throughput distributions among links in IEEE 802.11 networks from experimental
results. This pattern gives rise to an easy computation method, which we term
back-of-the-envelop (BoE) computation, because for many network configurations,
very accurate results can be obtained within minutes, if not seconds, by simple
hand computation. BoE beats prior methods in terms of both speed and accuracy.
While the computation procedure of BoE is simple, explaining why it works is by
no means trivial. Indeed the majority of our investigative efforts have been
devoted to the construction of a theory to explain BoE. This paper models an
ideal CSMA network as a set of interacting on-off telegraph processes. In
developing the theory, we discovered a number of analytical techniques and
observations that have eluded prior research, such as that the carrier-sensing
interactions among links in an ideal CSMA network result in a system state
evolution that is time-reversible; and that the probability distribution of the
system state is insensitive to the distributions of the &quot;on&quot; and &quot;off&quot;
durations given their means, and is a Markov random field. We believe these
theoretical frameworks are useful not just for explaining BoE, but could also
be a foundation for a fundamental understanding of how links in CSMA networks
interact. Last but not least, because of their basic nature, we surmise that
some of the techniques and results developed in this paper may be applicable to
not just CSMA networks, but also to other physical and engineering systems
consisting of entities interacting with each other in time and space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1863</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1863</id><created>2007-12-11</created><authors><author><keyname>Chang</keyname><forenames>Weng-Long</forenames><affiliation>Shan-Hui</affiliation></author><author><keyname>Michael</keyname><affiliation>Shan-Hui</affiliation></author><author><keyname>Ho</keyname></author><author><keyname>Guo</keyname><forenames>Minyi</forenames></author></authors><title>Constructing Bio-molecular Databases on a DNA-based Computer</title><categories>cs.NE cs.DB q-bio.OT</categories><comments>The article includes 35 pages, several tables and figures</comments><acm-class>H.3.0; H.3.3; D.3.0; D.3.1; D.3.m</acm-class><abstract>  Codd [Codd 1970] wrote the first paper in which the model of a relational
database was proposed. Adleman [Adleman 1994] wrote the first paper in which
DNA strands in a test tube were used to solve an instance of the Hamiltonian
path problem. From [Adleman 1994], it is obviously indicated that for storing
information in molecules of DNA allows for an information density of
approximately 1 bit per cubic nm (nanometer) and a dramatic improvement over
existing storage media such as video tape which store information at a density
of approximately 1 bit per 1012 cubic nanometers. This paper demonstrates that
biological operations can be applied to construct bio-molecular databases where
data records in relational tables are encoded as DNA strands. In order to
achieve the goal, DNA algorithms are proposed to perform eight operations of
relational algebra (calculus) on bio-molecular relational databases, which
include Cartesian product, union, set difference, selection, projection,
intersection, join and division. Furthermore, this work presents clear evidence
of the ability of molecular computing to perform data retrieval operations on
bio-molecular relational databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1869</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1869</id><created>2007-12-12</created><updated>2008-01-21</updated><authors><author><keyname>Gagarin</keyname><forenames>Andrei</forenames><affiliation>Acadia Un. Wolfville N. S. Canada</affiliation></author><author><keyname>Labelle</keyname><forenames>Gilbert</forenames><affiliation>LaCIM UQAM Montreal Qc Canada</affiliation></author><author><keyname>Leroux</keyname><forenames>Pierre</forenames><affiliation>LaCIM UQAM Montreal Qc Canada</affiliation></author><author><keyname>Walsh</keyname><forenames>Timothy</forenames><affiliation>LaCIM UQAM Montreal Qc Canada</affiliation></author></authors><title>Two-connected graphs with prescribed three-connected components</title><categories>math.CO cs.DM</categories><comments>Work presented at the Ottawa-Carleton Discrete Mathematics Workshop,
  May 25-26, 2007 and at the Seminaire Lotharingien de Combinatoire, Bertinoro,
  Italy, September 24-26, 2007. 32 pages. 11 pdf figures. Version 2: Minor
  revisions, one Table added</comments><msc-class>05A15, 05C30, 05C75</msc-class><journal-ref>Adv. in Appl. Math. 43 (2009), no. 1, pp. 46-74</journal-ref><doi>10.1016/j.aam.2009.01.002</doi><abstract>  We adapt the classical 3-decomposition of any 2-connected graph to the case
of simple graphs (no loops or multiple edges). By analogy with the
block-cutpoint tree of a connected graph, we deduce from this decomposition a
bicolored tree tc(g) associated with any 2-connected graph g, whose white
vertices are the 3-components of g (3-connected components or polygons) and
whose black vertices are bonds linking together these 3-components, arising
from separating pairs of vertices of g. Two fundamental relationships on graphs
and networks follow from this construction. The first one is a dissymmetry
theorem which leads to the expression of the class B=B(F) of 2-connected
graphs, all of whose 3-connected components belong to a given class F of
3-connected graphs, in terms of various rootings of B. The second one is a
functional equation which characterizes the corresponding class R=R(F) of
two-pole networks all of whose 3-connected components are in F. All the
rootings of B are then expressed in terms of F and R. There follow
corresponding identities for all the associated series, in particular the edge
index series. Numerous enumerative consequences are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1875</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1875</id><created>2007-12-12</created><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Critique du rapport signal \`a bruit en th\'eorie de l'information -- A
  critical appraisal of the signal to noise ratio in information theory</title><categories>cs.IT math.IT math.LO math.PR math.RA quant-ph</categories><proxy>ccsd inria-00195987</proxy><abstract>  The signal to noise ratio, which plays such an important role in information
theory, is shown to become pointless in digital communications where - symbols
are modulating carriers, which are solutions of linear differential equations
with polynomial coefficients, - demodulations is achieved thanks to new
algebraic estimation techniques. Operational calculus, differential algebra and
nonstandard analysis are the main mathematical tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1878</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1878</id><created>2007-12-12</created><authors><author><keyname>Pruvot</keyname><forenames>Jean Hugues</forenames><affiliation>GREYC</affiliation></author><author><keyname>Brun</keyname><forenames>Luc</forenames><affiliation>GREYC</affiliation></author></authors><title>Hierarchy construction schemes within the Scale set framework</title><categories>cs.CV</categories><proxy>ccsd hal-00195954</proxy><journal-ref>Dans Graph-Based Representations in Pattern Recognition - Graph
  based Representation 2007, Alicante : Espagne (2007)</journal-ref><abstract>  Segmentation algorithms based on an energy minimisation framework often
depend on a scale parameter which balances a fit to data and a regularising
term. Irregular pyramids are defined as a stack of graphs successively reduced.
Within this framework, the scale is often defined implicitly as the height in
the pyramid. However, each level of an irregular pyramid can not usually be
readily associated to the global optimum of an energy or a global criterion on
the base level graph. This last drawback is addressed by the scale set
framework designed by Guigues. The methods designed by this author allow to
build a hierarchy and to design cuts within this hierarchy which globally
minimise an energy. This paper studies the influence of the construction scheme
of the initial hierarchy on the resulting optimal cuts. We propose one
sequential and one parallel method with two variations within both. Our
sequential methods provide partitions near the global optima while parallel
methods require less execution times than the sequential method of Guigues even
on sequential machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1916</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1916</id><created>2007-12-12</created><updated>2008-07-01</updated><authors><author><keyname>Vanclay</keyname><forenames>Jerome K.</forenames></author></authors><title>Ranking forestry journals using the h-index</title><categories>cs.DL</categories><comments>21 pages, 3 figures, 5 tables. New table added in response to
  reviewer comments</comments><journal-ref>Journal of Informetrics 2 (2008) 326-334</journal-ref><doi>10.1016/j.joi.2008.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An expert ranking of forestry journals was compared with journal impact
factors and h-indices computed from the ISI Web of Science and internet-based
data. Citations reported by Google Scholar appear to offer the most efficient
way to rank all journals objectively, in a manner consistent with other
indicators. This h-index exhibited a high correlation with the journal impact
factor (r=0.92), but is not confined to journals selected by any particular
commercial provider. A ranking of 180 forestry journals is presented, on the
basis of this index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1928</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1928</id><created>2007-12-12</created><authors><author><keyname>Fekete</keyname><forenames>Attila</forenames></author><author><keyname>Vattay</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Kocarev</keyname><forenames>Ljupco</forenames></author></authors><title>Distribution of Edge Load in Scale-free Trees</title><categories>cs.NI cond-mat.other</categories><comments>26 pages, 9 figures</comments><acm-class>G.2.2</acm-class><journal-ref>Phys. Rev. E 73, 046102 (2006)</journal-ref><doi>10.1103/PhysRevE.73.046102</doi><abstract>  Node betweenness has been studied recently by a number of authors, but until
now less attention has been paid to edge betweenness. In this paper, we present
an exact analytic study of edge betweenness in evolving scale-free and
non-scale-free trees. We aim at the probability distribution of edge
betweenness under the condition that a local property, the in-degree of the
``younger'' node of a randomly selected edge, is known. En route to the
conditional distribution of edge betweenness the exact joint distribution of
cluster size and in-degree, and its one dimensional marginal distributions have
been presented in the paper as well. From the derived probability distributions
the expectation values of different quantities have been calculated. Our
results provide an exact solution not only for infinite, but for finite
networks as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1959</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1959</id><created>2007-12-12</created><authors><author><keyname>Cheng</keyname><forenames>Siu-Wing</forenames></author><author><keyname>Dey</keyname><forenames>Tamal K.</forenames></author></authors><title>Delaunay Edge Flips in Dense Surface Triangulations</title><categories>cs.CG cs.DS</categories><comments>This paper is prelude to &quot;Maintaining Deforming Surface Meshes&quot; by
  Cheng-Dey in SODA 2008</comments><abstract>  Delaunay flip is an elegant, simple tool to convert a triangulation of a
point set to its Delaunay triangulation. The technique has been researched
extensively for full dimensional triangulations of point sets. However, an
important case of triangulations which are not full dimensional is surface
triangulations in three dimensions. In this paper we address the question of
converting a surface triangulation to a subcomplex of the Delaunay
triangulation with edge flips. We show that the surface triangulations which
closely approximate a smooth surface with uniform density can be transformed to
a Delaunay triangulation with a simple edge flip algorithm. The condition on
uniformity becomes less stringent with increasing density of the triangulation.
If the condition is dropped completely, the flip algorithm still terminates
although the output surface triangulation becomes &quot;almost Delaunay&quot; instead of
exactly Delaunay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1987</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1987</id><created>2007-12-12</created><updated>2007-12-12</updated><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>A New Outer Bound and the Noisy-Interference Sum-Rate Capacity for
  Gaussian Interference Channels</title><categories>cs.IT math.IT</categories><comments>20 pages, 8 figures, submitted to IEEE Trans. Inform. Theory,</comments><abstract>  A new outer bound on the capacity region of Gaussian interference channels is
developed. The bound combines and improves existing genie-aided methods and is
shown to give the sum-rate capacity for noisy interference as defined in this
paper. Specifically, it is shown that if the channel coefficients and power
constraints satisfy a simple condition then single-user detection at each
receiver is sum-rate optimal, i.e., treating the interference as noise incurs
no loss in performance. This is the first concrete (finite signal-to-noise
ratio) capacity result for the Gaussian interference channel with weak to
moderate interference. Furthermore, for certain mixed (weak and strong)
interference scenarios, the new outer bounds give a corner point of the
capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1994</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1994</id><created>2007-12-12</created><authors><author><keyname>Sureephong</keyname><forenames>Pradorn</forenames><affiliation>LIESP, CAMT</affiliation></author><author><keyname>Chakpitak</keyname><forenames>Nopasit</forenames><affiliation>CAMT</affiliation></author><author><keyname>Ouzrout</keyname><forenames>Yacine</forenames><affiliation>LIESP</affiliation></author><author><keyname>Neubert</keyname><forenames>Gilles</forenames><affiliation>LIESP</affiliation></author><author><keyname>Bouras</keyname><forenames>Abdelaziz</forenames><affiliation>LIESP</affiliation></author></authors><title>Knowledge Engineering Technique for Cluster Development</title><categories>cs.OH</categories><proxy>ccsd hal-00196472</proxy><journal-ref>Dans Proceeding of Knowledge Science, Engineering and Management
  (KSEM 07) - Knowledge Science, Engineering and Management (KSEM 07),
  Melbourne : Australie (2007)</journal-ref><abstract>  After the concept of industry cluster was tangibly applied in many countries,
SMEs trended to link to each other to maintain their competitiveness in the
market. The major key success factors of the cluster are knowledge sharing and
collaboration between partners. This knowledge is collected in form of tacit
and explicit knowledge from experts and institutions within the cluster. The
objective of this study is about enhancing the industry cluster with knowledge
management by using knowledge engineering which is one of the most important
method for managing knowledge. This work analyzed three well known knowledge
engineering methods, i.e. MOKA, SPEDE and CommonKADS, and compares the
capability to be implemented in the cluster context. Then, we selected one
method and proposed the adapted methodology. At the end of this paper, we
validated and demonstrated the proposed methodology with some primary result by
using case study of handicraft cluster in Thailand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1996</identifier>
 <datestamp>2007-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1996</id><created>2007-12-12</created><authors><author><keyname>Kuijpers</keyname><forenames>Bart</forenames></author><author><keyname>Othman</keyname><forenames>Walied</forenames></author><author><keyname>Grimson</keyname><forenames>Rafael</forenames></author></authors><title>A case study of the difficulty of quantifier elimination in constraint
  databases: the alibi query in moving object databases</title><categories>cs.LO cs.CC cs.DB</categories><comments>35 pages</comments><abstract>  In the constraint database model, spatial and spatio-temporal data are stored
by boolean combinations of polynomial equalities and inequalities over the real
numbers. The relational calculus augmented with polynomial constraints is the
standard first-order query language for constraint databases. Although the
expressive power of this query language has been studied extensively, the
difficulty of the efficient evaluation of queries, usually involving some form
of quantifier elimination, has received considerably less attention. The
inefficiency of existing quantifier-elimination software and the intrinsic
difficulty of quantifier elimination have proven to be a bottle-neck for for
real-world implementations of constraint database systems. In this paper, we
focus on a particular query, called the \emph{alibi query}, that asks whether
two moving objects whose positions are known at certain moments in time, could
have possibly met, given certain speed constraints. This query can be seen as a
constraint database query and its evaluation relies on the elimination of a
block of three existential quantifiers. Implementations of general purpose
elimination algorithms are in the specific case, for practical purposes, too
slow in answering the alibi query and fail completely in the parametric case.
The main contribution of this paper is an analytical solution to the parametric
alibi query, which can be used to answer this query in the specific case in
constant time. We also give an analytic solution to the alibi query at a fixed
moment in time. The solutions we propose are based on geometric argumentation
and they illustrate the fact that some practical problems require creative
solutions, where at least in theory, existing systems could provide a solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2054</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2054</id><created>2007-12-12</created><authors><author><keyname>Jiang</keyname><forenames>Libin</forenames></author><author><keyname>Walrand</keyname><forenames>Jean</forenames></author></authors><title>Distributed Fair Scheduling Using Variable Transmission Lengths in
  Carrier-Sensing-based Wireless Networks</title><categories>cs.NI</categories><comments>Allerton Conference on Communication, Control, and Computing, 2007</comments><abstract>  The fairness of IEEE 802.11 wireless networks (including Wireless LAN and
Ad-hoc networks) is hard to predict and control because of the randomness and
complexity of the MAC contentions and dynamics. Moreover, asymmetric channel
conditions such as those caused by capture and channel errors often lead to
severe unfairness among stations. In this paper we propose a novel distributed
scheduling algorithm that we call VLS, for ``{\em variable-length
scheduling}'', that provides weighted fairness to all stations despite the
imperfections of the MAC layer and physical channels. Distinct features of VLS
include the use of variable transmission lengths based on distributed
observations, compatibility with 802.11's contention window algorithm,
opportunistic scheduling to achieve high throughput in time-varying wireless
environments, and flexibility and ease of implementation. Also, VLS makes the
throughput of each station more smooth, which is appealing to real-time
applications such as video and voice. Although the paper mostly assumes 802.11
protocol, the idea generally applies to wireless networks based on CSMA
(Carrier Sensing Multiple Access).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2063</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2063</id><created>2007-12-12</created><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>An axiomatic approach to intrinsic dimension of a dataset</title><categories>cs.IR</categories><comments>10 pages, 5 figures, latex 2e with Elsevier macros, final submission
  to Neural Networks with referees' comments taken into account</comments><acm-class>H.1.1; H.2.1; H.3.1; I.5.3</acm-class><journal-ref>Neural Networks 21, 2-3 (2008), 204-213.</journal-ref><abstract>  We perform a deeper analysis of an axiomatic approach to the concept of
intrinsic dimension of a dataset proposed by us in the IJCNN'07 paper
(arXiv:cs/0703125). The main features of our approach are that a high intrinsic
dimension of a dataset reflects the presence of the curse of dimensionality (in
a certain mathematically precise sense), and that dimension of a discrete
i.i.d. sample of a low-dimensional manifold is, with high probability, close to
that of the manifold. At the same time, the intrinsic dimension of a sample is
easily corrupted by moderate high-dimensional noise (of the same amplitude as
the size of the manifold) and suffers from prohibitevely high computational
complexity (computing it is an $NP$-complete problem). We outline a possible
way to overcome these difficulties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2083</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2083</id><created>2007-12-12</created><authors><author><keyname>Chan</keyname><forenames>A.</forenames></author><author><keyname>Liew</keyname><forenames>S. C.</forenames></author></authors><title>VoIP over Multiple IEEE 802.11 Wireless LANs</title><categories>cs.NI</categories><abstract>  Prior work indicates that 802.11 is extremely inefficient for VoIP transport.
Only 12 and 60 VoIP sessions can be supported in an 802.11b and an 802.11g
WLAN, respectively. This paper shows that the bad news does not stop there.
When there are multiple WLANs in the vicinity of each other, the already-low
VoIP capacity can be further eroded in a significant manner. For example, in a
5-by-5, 25-cell multi-WLAN network, the VoIP capacities for 802.11b and 802.11g
are only 1.63 and 10.34 sessions per AP, respectively. This paper investigates
several solutions to improve the VoIP capacity. Based on a conflict graph
model, we propose a clique-analytical call-admission scheme, which increases
the VoIP capacity by 52% and 37% in 802.11b and 802.11g respectively. If all
the three orthogonal frequency channels available in 11b and 11g are used, the
capacity can be nearly tripled by the call-admission scheme. This paper also
proposes for the first time the use of coarse-grained time-division multiple
access (CoTDMA) in conjunction with the basic 802.11 CSMA to eliminate the
performance-degrading exposed-node and hidden-node problems. We find that
CoTDMA can further increase the VoIP capacity in the multi-WLAN scenario by an
additional 35%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2094</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2094</id><created>2007-12-12</created><authors><author><keyname>Abbott</keyname><forenames>Timothy G.</forenames></author><author><keyname>Abel</keyname><forenames>Zachary</forenames></author><author><keyname>Charlton</keyname><forenames>David</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Kominers</keyname><forenames>Scott D.</forenames></author></authors><title>Hinged Dissections Exist</title><categories>cs.CG</categories><comments>22 pages, 14 figures</comments><acm-class>F.2.2</acm-class><journal-ref>Proceedings of the Twenty-fourth Annual Symposium on Computational
  Geometry (2008): 110-119.</journal-ref><doi>10.1145/1377676.1377695</doi><abstract>  We prove that any finite collection of polygons of equal area has a common
hinged dissection. That is, for any such collection of polygons there exists a
chain of polygons hinged at vertices that can be folded in the plane
continuously without self-intersection to form any polygon in the collection.
This result settles the open problem about the existence of hinged dissections
between pairs of polygons that goes back implicitly to 1864 and has been
studied extensively in the past ten years. Our result generalizes and indeed
builds upon the result from 1814 that polygons have common dissections (without
hinges). We also extend our common dissection result to edge-hinged dissections
of solid 3D polyhedra that have a common (unhinged) dissection, as determined
by Dehn's 1900 solution to Hilbert's Third Problem. Our proofs are
constructive, giving explicit algorithms in all cases. For a constant number of
planar polygons, both the number of pieces and running time required by our
construction are pseudopolynomial. This bound is the best possible, even for
unhinged dissections. Hinged dissections have possible applications to
reconfigurable robotics, programmable matter, and nanomanufacturing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2099</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2099</id><created>2007-12-13</created><authors><author><keyname>Daanen</keyname><forenames>V.</forenames><affiliation>TIMC</affiliation></author><author><keyname>Gastaldo</keyname><forenames>J.</forenames><affiliation>TIMC</affiliation></author><author><keyname>Giraud</keyname><forenames>J. Y.</forenames><affiliation>TIMC</affiliation></author><author><keyname>Fourneret</keyname><forenames>P.</forenames><affiliation>TIMC</affiliation></author><author><keyname>Descotes</keyname><forenames>J. L.</forenames><affiliation>TIMC</affiliation></author><author><keyname>Bolla</keyname><forenames>M.</forenames><affiliation>TIMC</affiliation></author><author><keyname>Collomb</keyname><forenames>D.</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>MRI/TRUS data fusion for brachytherapy</title><categories>cs.OH</categories><proxy>ccsd hal-00195006</proxy><journal-ref>International Journal of Medical Robotics and Computer Assisted
  Surgery 2, 3 (2006) 256-61</journal-ref><doi>10.1002/rcs.95</doi><abstract>  BACKGROUND: Prostate brachytherapy consists in placing radioactive seeds for
tumour destruction under transrectal ultrasound imaging (TRUS) control. It
requires prostate delineation from the images for dose planning. Because
ultrasound imaging is patient- and operator-dependent, we have proposed to fuse
MRI data to TRUS data to make image processing more reliable. The technical
accuracy of this approach has already been evaluated. METHODS: We present work
in progress concerning the evaluation of the approach from the dosimetry
viewpoint. The objective is to determine what impact this system may have on
the treatment of the patient. Dose planning is performed from initial TRUS
prostate contours and evaluated on contours modified by data fusion. RESULTS:
For the eight patients included, we demonstrate that TRUS prostate volume is
most often underestimated and that dose is overestimated in a correlated way.
However, dose constraints are still verified for those eight patients.
CONCLUSIONS: This confirms our initial hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2100</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2100</id><created>2007-12-13</created><authors><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author><author><keyname>Baumann</keyname><forenames>Michael</forenames><affiliation>TIMC</affiliation></author><author><keyname>Berkelman</keyname><forenames>Peter</forenames><affiliation>TIMC</affiliation></author><author><keyname>Cinquin</keyname><forenames>Philippe</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Leroy</keyname><forenames>Antoine</forenames><affiliation>TIMC</affiliation></author><author><keyname>Marchal</keyname><forenames>Maud</forenames><affiliation>TIMC</affiliation></author><author><keyname>Payan</keyname><forenames>Yohan</forenames><affiliation>TIMC</affiliation></author><author><keyname>Promayon</keyname><forenames>Emmanuel</forenames><affiliation>TIMC</affiliation></author><author><keyname>Voros</keyname><forenames>Sandrine</forenames><affiliation>TIMC</affiliation></author><author><keyname>Bart</keyname><forenames>St&#xe9;phane</forenames><affiliation>TIMC</affiliation></author><author><keyname>Bolla</keyname><forenames>Michel</forenames><affiliation>TIMC</affiliation></author><author><keyname>Chartier-Kastler</keyname><forenames>Emmanuel</forenames><affiliation>TIMC</affiliation></author><author><keyname>Descotes</keyname><forenames>Jean-Luc</forenames><affiliation>TIMC</affiliation></author><author><keyname>Dusserre</keyname><forenames>Andr&#xe9;e</forenames><affiliation>TIMC</affiliation></author><author><keyname>Giraud</keyname><forenames>Jean-Yves</forenames><affiliation>TIMC</affiliation></author><author><keyname>Long</keyname><forenames>Jean-Alexandre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Moalic</keyname><forenames>Ronan</forenames><affiliation>TIMC</affiliation></author><author><keyname>Mozer</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author></authors><title>Medical image computing and computer-aided medical interventions applied
  to soft tissues. Work in progress in urology</title><categories>cs.OH cs.RO</categories><proxy>ccsd hal-00195036</proxy><journal-ref>Proceedings of the IEEE 94, 9 (2006) 1665-1677</journal-ref><abstract>  Until recently, Computer-Aided Medical Interventions (CAMI) and Medical
Robotics have focused on rigid and non deformable anatomical structures.
Nowadays, special attention is paid to soft tissues, raising complex issues due
to their mobility and deformation. Mini-invasive digestive surgery was probably
one of the first fields where soft tissues were handled through the development
of simulators, tracking of anatomical structures and specific assistance
robots. However, other clinical domains, for instance urology, are concerned.
Indeed, laparoscopic surgery, new tumour destruction techniques (e.g. HIFU,
radiofrequency, or cryoablation), increasingly early detection of cancer, and
use of interventional and diagnostic imaging modalities, recently opened new
challenges to the urologist and scientists involved in CAMI. This resulted in
the last five years in a very significant increase of research and developments
of computer-aided urology systems. In this paper, we propose a description of
the main problems related to computer-aided diagnostic and therapy of soft
tissues and give a survey of the different types of assistance offered to the
urologist: robotization, image fusion, surgical navigation. Both research
projects and operational industrial systems are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2113</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2113</id><created>2007-12-13</created><authors><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Kasper</keyname><forenames>Michael</forenames></author></authors><title>On the deployment of Mobile Trusted Modules</title><categories>cs.CR</categories><comments>To appear in: Proceedings of the Wireless Communications and
  Networking Conference, IEEE WCNC 2008, Las Vegas, USA, 31 March - 2 April
  2008</comments><abstract>  In its recently published TCG Mobile Reference Architecture, the TCG Mobile
Phone Work Group specifies a new concept to enable trust into future mobile
devices. For this purpose, the TCG devises a trusted mobile platform as a set
of trusted engines on behalf of different stakeholders supported by a physical
trust-anchor. In this paper, we present our perception on this emerging
specification. We propose an approach for the practical design and
implementation of this concept and how to deploy it to a trustworthy operating
platform. In particular we propose a method for the take-ownership of a device
by the user and the migration (i.e., portability) of user credentials between
devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2141</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2141</id><created>2007-12-13</created><authors><author><keyname>Chojnacki</keyname><forenames>Eric</forenames><affiliation>IRSN</affiliation></author><author><keyname>Baccou</keyname><forenames>Jean</forenames><affiliation>IRSN</affiliation></author><author><keyname>Destercke</keyname><forenames>S&#xe9;bastien</forenames><affiliation>IRSN, IRIT</affiliation></author></authors><title>Numerical Sensitivity and Efficiency in the Treatment of Epistemic and
  Aleatory Uncertainty</title><categories>cs.AI math.PR</categories><proxy>ccsd irsn-00196663</proxy><journal-ref>Fifth International Conference on Sensitivity Analysis of Model
  Output, Budapest : Hongrie (2007)</journal-ref><abstract>  The treatment of both aleatory and epistemic uncertainty by recent methods
often requires an high computational effort. In this abstract, we propose a
numerical sampling method allowing to lighten the computational burden of
treating the information by means of so-called fuzzy random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2168</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2168</id><created>2007-12-13</created><authors><author><keyname>Bobiller-Chaumon</keyname><forenames>Marc-Eric</forenames><affiliation>GRePS</affiliation></author><author><keyname>Dubois</keyname><forenames>Michel</forenames><affiliation>LIP - PC2S</affiliation></author><author><keyname>Sandoz-Guermond</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>LIESP</affiliation></author></authors><title>Study of conditions of use of E-services accessible to visually disabled
  persons</title><categories>cs.HC</categories><comments>4 pages visible \`a http://ceur-ws.org/Vol-285</comments><proxy>ccsd hal-00196783</proxy><journal-ref>Dans CEUR Workshop Proceedings - DEGAS'07 : Workshop of Design &amp;
  Evaluation of e-Government Applications and services, Rio de Janeiro :
  Br\'esil (2006)</journal-ref><abstract>  The aim of this paper is to determine the expectations that French-speaking
disabled persons have for electronic administrative sites (utility). At the
same time, it is a matter of identifying the difficulties of use that the
manipulation of these E-services poses concretely for blind people (usability)
and of evaluating the psychosocial impacts on the way of life of these people
with specific needs. We show that the lack of numerical accessibility is likely
to accentuate the social exclusion of which these people are victim by
establishing a numerical glass ceiling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2182</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2182</id><created>2007-12-13</created><authors><author><keyname>Hollmann</keyname><forenames>Henk D. L.</forenames></author><author><keyname>Tolhuizen</keyname><forenames>Ludo M. G. M.</forenames></author></authors><title>Optimal codes for correcting a single (wrap-around) burst of errors</title><categories>cs.IT math.IT</categories><comments>10 pages; submitted to IEEE Transactions on Information Theory</comments><abstract>  In 2007, Martinian and Trott presented codes for correcting a burst of
erasures with a minimum decoding delay. Their construction employs [n,k] codes
that can correct any burst of erasures (including wrap-around bursts) of length
n-k. The raised the question if such [n,k] codes exist for all integers k and n
with 1&lt;= k &lt;= n and all fields (in particular, for the binary field). In this
note, we answer this question affirmatively by giving two recursive
constructions and a direct one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2183</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2183</id><created>2007-12-13</created><authors><author><keyname>Bobiller-Chaumon</keyname><forenames>Marc-Eric</forenames><affiliation>GRePS</affiliation></author><author><keyname>Sandoz-Guermond</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>LIESP</affiliation></author></authors><title>Apports des d\'emarches d'inspection et des tests d'usage dans
  l'\'evaluation de l'accessibilit\'e de E-services</title><categories>cs.HC</categories><comments>4 pages</comments><proxy>ccsd hal-00196853</proxy><journal-ref>Dans Actes du congr\`es ERGO IA'2006 - ERGO'IA : L'humain comme
  facteur de performance des syst\`emes complexes, Biarritz : France (2006)</journal-ref><abstract>  This article proposes to describe and compare the contributions of various
techniques of evaluation of the accessibility of E-services carried out
starting from (i) methods of inspection (on the basis of traditional ergonomic
criteria and accessibility) and (ii) of tests of use. It show that these are
the latter which show the best rate of identification of the problems of uses
for the poeple with disabilities
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2223</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2223</id><created>2007-12-13</created><updated>2010-04-02</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Brun</keyname><forenames>Todd A.</forenames></author></authors><title>Entanglement-Assisted Quantum Convolutional Coding</title><categories>quant-ph cs.IT math.IT</categories><comments>Accepted for publication in Physical Review A</comments><report-no>CSI-07-12-01</report-no><journal-ref>Physical Review A 81, 042333 (2010)</journal-ref><doi>10.1103/PhysRevA.81.042333</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to protect a stream of quantum information from decoherence
induced by a noisy quantum communication channel. We exploit preshared
entanglement and a convolutional coding structure to develop a theory of
entanglement-assisted quantum convolutional coding. Our construction produces a
Calderbank-Shor-Steane (CSS) entanglement-assisted quantum convolutional code
from two arbitrary classical binary convolutional codes. The rate and
error-correcting properties of the classical convolutional codes directly
determine the corresponding properties of the resulting entanglement-assisted
quantum convolutional code. We explain how to encode our CSS
entanglement-assisted quantum convolutional codes starting from a stream of
information qubits, ancilla qubits, and shared entangled bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2231</identifier>
 <datestamp>2007-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2231</id><created>2007-12-13</created><authors><author><keyname>Schmidt</keyname><forenames>Andreas U.</forenames></author><author><keyname>Kuntze</keyname><forenames>Nicolai</forenames></author><author><keyname>Abendroth</keyname><forenames>Joerg</forenames></author></authors><title>Trust for Location-based Authorisation</title><categories>cs.CR</categories><comments>To appear in: Proceedings of the Wireless Communications and
  Networking Conference, IEEE WCNC 2008, Las Vegas, USA, 31 March - 2 April
  2008</comments><abstract>  We propose a concept for authorisation using the location of a mobile device
and the enforcement of location-based policies. Mobile devices enhanced by
Trusted Computing capabilities operate an autonomous and secure location
trigger and policy enforcement entity. Location determination is two-tiered,
integrating cell-based triggering at handover with precision location
measurement by the device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2235</identifier>
 <datestamp>2007-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2235</id><created>2007-12-13</created><authors><author><keyname>Das</keyname><forenames>Manik Lal</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author><author><keyname>Gulati</keyname><forenames>Ved P.</forenames></author></authors><title>A Dynamic ID-based Remote User Authentication Scheme</title><categories>cs.CR</categories><comments>Published in IEEE Transactions On Consumer Electronics</comments><journal-ref>IEEE Transactions on Consumer Electronics, Vol. 50, No. 2, 2004,
  pp. 629-631</journal-ref><abstract>  Password-based authentication schemes are the most widely used techniques for
remote user authentication. Many static ID-based remote user authentication
schemes both with and without smart cards have been proposed. Most of the
schemes do not allow the users to choose and change their passwords, and
maintain a verifier table to verify the validity of the user login. In this
paper we present a dynamic ID-based remote user authentication scheme using
smart cards. Our scheme allows the users to choose and change their passwords
freely, and do not maintain any verifier table. The scheme is secure against
ID-theft, and can resist the reply attacks, forgery attacks, guessing attacks,
insider attacks and stolen verifier attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2245</identifier>
 <datestamp>2009-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2245</id><created>2007-12-13</created><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author><author><keyname>Kl&#xf8;ve</keyname><forenames>Torleiv</forenames></author></authors><title>Exact and Approximate Expressions for the Probability of Undetected
  Error of Varshamov-Tenengol'ts Codes</title><categories>cs.IT math.IT</categories><comments>33 pages, 9 figures, 1 table. Submitted to the IEEE Transactions on
  Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, ISSN 0018-9448, Vol. 54,
  No. 11, pp. 5019-5029, Nov. 2008</journal-ref><doi>10.1109/TIT.2008.929912</doi><abstract>  Computation of the undetected error probability for error correcting codes
over the Z-channel is an important issue, explored only in part in previous
literature. In this paper we consider the case of Varshamov-Tenengol'ts codes,
by presenting some analytical, numerical, and heuristic methods for unveiling
this additional feature. Possible comparisons with Hamming codes are also shown
and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2255</identifier>
 <datestamp>2007-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2255</id><created>2007-12-13</created><authors><author><keyname>Foster</keyname><forenames>Ian</forenames></author></authors><title>Human-Machine Symbiosis, 50 Years On</title><categories>cs.DC cs.CE cs.HC</categories><abstract>  Licklider advocated in 1960 the construction of computers capable of working
symbiotically with humans to address problems not easily addressed by humans
working alone. Since that time, many of the advances that he envisioned have
been achieved, yet the time spent by human problem solvers in mundane
activities remains large. I propose here four areas in which improved tools can
further advance the goal of enhancing human intellect: services, provenance,
knowledge communities, and automation of problem-solving protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2262</identifier>
 <datestamp>2007-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2262</id><created>2007-12-13</created><authors><author><keyname>Bernholdt</keyname><forenames>David</forenames></author><author><keyname>Bharathi</keyname><forenames>Shishir</forenames></author><author><keyname>Brown</keyname><forenames>David</forenames></author><author><keyname>Chanchio</keyname><forenames>Kasidit</forenames></author><author><keyname>Chen</keyname><forenames>Meili</forenames></author><author><keyname>Chervenak</keyname><forenames>Ann</forenames></author><author><keyname>Cinquini</keyname><forenames>Luca</forenames></author><author><keyname>Drach</keyname><forenames>Bob</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author><author><keyname>Fox</keyname><forenames>Peter</forenames></author><author><keyname>Garcia</keyname><forenames>Jose</forenames></author><author><keyname>Kesselman</keyname><forenames>Carl</forenames></author><author><keyname>Markel</keyname><forenames>Rob</forenames></author><author><keyname>Middleton</keyname><forenames>Don</forenames></author><author><keyname>Nefedova</keyname><forenames>Veronika</forenames></author><author><keyname>Pouchard</keyname><forenames>Line</forenames></author><author><keyname>Shoshani</keyname><forenames>Arie</forenames></author><author><keyname>Sim</keyname><forenames>Alex</forenames></author><author><keyname>Strand</keyname><forenames>Gary</forenames></author><author><keyname>Williams</keyname><forenames>Dean</forenames></author></authors><title>The Earth System Grid: Supporting the Next Generation of Climate
  Modeling Research</title><categories>cs.CE cs.DC cs.NI</categories><abstract>  Understanding the earth's climate system and how it might be changing is a
preeminent scientific challenge. Global climate models are used to simulate
past, present, and future climates, and experiments are executed continuously
on an array of distributed supercomputers. The resulting data archive, spread
over several sites, currently contains upwards of 100 TB of simulation data and
is growing rapidly. Looking toward mid-decade and beyond, we must anticipate
and prepare for distributed climate research data holdings of many petabytes.
The Earth System Grid (ESG) is a collaborative interdisciplinary project aimed
at addressing the challenge of enabling management, discovery, access, and
analysis of these critically important datasets in a distributed and
heterogeneous computational environment. The problem is fundamentally a Grid
problem. Building upon the Globus toolkit and a variety of other technologies,
ESG is developing an environment that addresses authentication, authorization
for data access, large-scale data transport and management, services and
abstractions for high-performance remote data access, mechanisms for scalable
data replication, cataloging with rich semantic and syntactic information, data
discovery, distributed monitoring, and Web-based portals for using the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2274</identifier>
 <datestamp>2007-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2274</id><created>2007-12-13</created><authors><author><keyname>Chen</keyname><forenames>Da Rui</forenames><affiliation>Angela</affiliation></author><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author></authors><title>Distributed MAC Strategy for Exploiting Multi-user Diversity in
  Multi-rate IEEE 802.11 Wireless LANs</title><categories>cs.NI</categories><abstract>  Fast rate adaptation has been established as an effective way to improve the
PHY-layer raw date rate of wireless networks. However, within the current IEEE
802.11 legacy, MAC-layer throughput is dominated by users with the lowest data
rates, resulting in underutilization of bandwidth. In this paper, we propose
and analyze a novel distributed MAC strategy, referred to as Rate-aware DCF
(R-DCF), to leverage the potential of rate adaptation in IEEE 802.11 WLANs. The
key feature of R-DCF is that by introducing different mini slots according to
the instantaneous channel conditions, only contending stations with the highest
data rate can access the channel. In this way, the R-DCF protocol not only
exploits multi-user diversity in a fully distributed manner but also reduces
the loss of throughput due to collisions. Through analysis, we develop an
analytical model to derive the throughput of R-DCF in general multi-rate WLANs.
Using the analytical model we investigate the performance of R-DCF protocol in
various network settings with different rate adaptation strategies and channel
variations. Based on the analysis, we further derive the maximal throughput
achievable by R-DCF. For practical implementation, an offline adaptive backoff
method is developed to achieve a close-to-optimal performance at low runtime
complexity. The superiority of R-DCF is proven via extensive analyses and
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2302</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2302</id><created>2007-12-14</created><updated>2008-01-28</updated><authors><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Zeiser</keyname><forenames>Thomas</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>Data access optimizations for highly threaded multi-core CPUs with
  multiple memory controllers</title><categories>cs.DC cs.PF</categories><comments>12 pages, 7 figures. Accepted for Workshop on Large-Scale Parallel
  Processing 2008. Revised and extended version</comments><abstract>  Processor and system architectures that feature multiple memory controllers
are prone to show bottlenecks and erratic performance numbers on codes with
regular access patterns. Although such effects are well known in the form of
cache thrashing and aliasing conflicts, they become more severe when memory
access is involved. Using the new Sun UltraSPARC T2 processor as a prototypical
multi-core design, we analyze performance patterns in low-level and application
benchmarks and show ways to circumvent bottlenecks by careful data layout and
padding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2371</identifier>
 <datestamp>2007-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2371</id><created>2007-12-14</created><authors><author><keyname>Karmakar</keyname><forenames>Sanjay</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Maximum-rate, Minimum-Decoding-Complexity STBCs from Clifford Algebras</title><categories>cs.IT math.IT</categories><comments>Under consideration for possible publication in IEEE Transactions on
  Information Theory</comments><abstract>  It is well known that Space-Time Block Codes (STBCs) from orthogonal designs
(ODs) are single-symbol decodable/symbol-by-symbol decodable (SSD) and are
obtainable from unitary matrix representations of Clifford algebras. However,
SSD codes are obtainable from designs that are not orthogonal also. Recently,
two such classes of SSD codes have been studied: (i) Coordinate Interleaved
Orthogonal Designs (CIODs) and (ii) Minimum-Decoding-Complexity (MDC) STBCs
from Quasi-ODs (QODs). Codes from ODs, CIODs and MDC-QODs are mutually
non-intersecting classes of codes. The class of CIODs have {\it non-unitary
weight matrices} when written as a Linear Dispersion Code (LDC) proposed by
Hassibi and Hochwald, whereas several known SSD codes including CODs have {\it
unitary weight matrices}. In this paper, we obtain SSD codes with unitary
weight matrices (that are not CODs) called Clifford Unitary Weight SSDs
(CUW-SSDs) from matrix representations of Clifford algebras. A main result of
this paper is the derivation of an achievable upper bound on the rate of any
unitary weight SSD code as $\frac{a}{2^{a-1}}$ for $2^a$ antennas which is
larger than that of the CODs which is $\frac{a+1}{2^a}$. It is shown that
several known classes of SSD codes are CUW-SSD codes and CUW-SSD codes meet
this upper bound. Also, for the codes of this paper conditions on the signal
sets which ensure full-diversity and expressions for the coding gain are
presented. A large class of SSD codes with non-unitary weight matrices are
obtained which include CIODs as a proper subclass.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2384</identifier>
 <datestamp>2008-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2384</id><created>2007-12-14</created><updated>2008-11-22</updated><authors><author><keyname>Rajan</keyname><forenames>G. Susinder</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Multi-group ML Decodable Collocated and Distributed Space Time Block
  Codes</title><categories>cs.IT cs.DM math.IT math.RA</categories><comments>Revised version. Under consideration for publication in IEEE
  Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, collocated and distributed space-time block codes (DSTBCs)
which admit multi-group maximum likelihood (ML) decoding are studied. First the
collocated case is considered and the problem of constructing space-time block
codes (STBCs) which optimally tradeoff rate and ML decoding complexity is
posed. Recently, sufficient conditions for multi-group ML decodability have
been provided in the literature and codes meeting these sufficient conditions
were called Clifford Unitary Weight (CUW) STBCs. An algebraic framework based
on extended Clifford algebras is proposed to study CUW STBCs and using this
framework, the optimal tradeoff between rate and ML decoding complexity of CUW
STBCs is obtained for few specific cases. Code constructions meeting this
tradeoff optimally are also provided. The paper then focuses on multi-group ML
decodable DSTBCs for application in synchronous wireless relay networks and
three constructions of four-group ML decodable DSTBCs are provided. Finally,
the OFDM based Alamouti space-time coded scheme proposed by Li-Xia for a 2
relay asynchronous relay network is extended to a more general transmission
scheme that can achieve full asynchronous cooperative diversity for arbitrary
number of relays. It is then shown how differential encoding at the source can
be combined with the proposed transmission scheme to arrive at a new
transmission scheme that can achieve full cooperative diversity in asynchronous
wireless relay networks with no channel information and also no timing error
knowledge at the destination node. Four-group decodable DSTBCs applicable in
the proposed OFDM based transmission scheme are also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2389</identifier>
 <datestamp>2008-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2389</id><created>2007-12-14</created><updated>2008-06-11</updated><authors><author><keyname>Mann</keyname><forenames>Martin</forenames></author><author><keyname>Tack</keyname><forenames>Guido</forenames></author><author><keyname>Will</keyname><forenames>Sebastian</forenames></author></authors><title>Decomposition During Search for Propagation-Based Constraint Solvers</title><categories>cs.AI</categories><comments>20 pages, 9 figures, 2 tables; longer, more detailed version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe decomposition during search (DDS), an integration of And/Or tree
search into propagation-based constraint solvers. The presented search
algorithm dynamically decomposes sub-problems of a constraint satisfaction
problem into independent partial problems, avoiding redundant work.
  The paper discusses how DDS interacts with key features that make
propagation-based solvers successful: constraint propagation, especially for
global constraints, and dynamic search heuristics.
  We have implemented DDS for the Gecode constraint programming library. Two
applications, solution counting in graph coloring and protein structure
prediction, exemplify the benefits of DDS in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2430</identifier>
 <datestamp>2008-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2430</id><created>2007-12-14</created><authors><author><keyname>Gyorfi</keyname><forenames>L.</forenames></author><author><keyname>Morvai</keyname><forenames>G.</forenames></author><author><keyname>Yakowitz</keyname><forenames>S.</forenames></author></authors><title>Limits to consistent on-line forecasting for ergodic time series</title><categories>math.PR cs.IT math.IT</categories><journal-ref>IEEE Trans. Inform. Theory 44 (1998), no. 2, 886--892</journal-ref><abstract>  This study concerns problems of time-series forecasting under the weakest of
assumptions. Related results are surveyed and are points of departure for the
developments here, some of which are new and others are new derivations of
previous findings. The contributions in this study are all negative, showing
that various plausible prediction problems are unsolvable, or in other cases,
are not solvable by predictors which are known to be consistent when mixing
conditions hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2449</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2449</id><created>2007-12-14</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Mutschke</keyname><forenames>Peter</forenames></author><author><keyname>Petras</keyname><forenames>Vivien</forenames></author></authors><title>Reducing semantic complexity in distributed Digital Libraries: treatment
  of term vagueness and document re-ranking</title><categories>cs.DL</categories><comments>12 pages, 4 figures</comments><acm-class>H.3.7</acm-class><abstract>  The purpose of the paper is to propose models to reduce the semantic
complexity in heterogeneous DLs. The aim is to introduce value-added services
(treatment of term vagueness and document re-ranking) that gain a certain
quality in DLs if they are combined with heterogeneity components established
in the project &quot;Competence Center Modeling and Treatment of Semantic
Heterogeneity&quot;. Empirical observations show that freely formulated user terms
and terms from controlled vocabularies are often not the same or match just by
coincidence. Therefore, a value-added service will be developed which rephrases
the natural language searcher terms into suggestions from the controlled
vocabulary, the Search Term Recommender (STR). Two methods, which are derived
from scientometrics and network analysis, will be implemented with the
objective to re-rank result sets by the following structural properties: the
ranking of the results by core journals (so-called Bradfordizing) and ranking
by centrality of authors in co-authorship networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2467</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2467</id><created>2007-12-14</created><authors><author><keyname>Andrews</keyname><forenames>Jeff</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author><author><keyname>Berry</keyname><forenames>Randy</forenames></author><author><keyname>Jafar</keyname><forenames>Syed</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Shakkottai</keyname><forenames>Sanjay</forenames></author><author><keyname>Heath</keyname><forenames>Robert</forenames></author><author><keyname>Neely</keyname><forenames>Michael</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Rethinking Information Theory for Mobile Ad Hoc Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Communications Magazine</comments><abstract>  The subject of this paper is the long-standing open problem of developing a
general capacity theory for wireless networks, particularly a theory capable of
describing the fundamental performance limits of mobile ad hoc networks
(MANETs). A MANET is a peer-to-peer network with no pre-existing
infrastructure. MANETs are the most general wireless networks, with single-hop,
relay, interference, mesh, and star networks comprising special cases. The lack
of a MANET capacity theory has stunted the development and commercialization of
many types of wireless networks, including emergency, military, sensor, and
community mesh networks. Information theory, which has been vital for links and
centralized networks, has not been successfully applied to decentralized
wireless networks. Even if this was accomplished, for such a theory to truly
characterize the limits of deployed MANETs it must overcome three key
roadblocks. First, most current capacity results rely on the allowance of
unbounded delay and reliability. Second, spatial and timescale decompositions
have not yet been developed for optimally modeling the spatial and temporal
dynamics of wireless networks. Third, a useful network capacity theory must
integrate rather than ignore the important role of overhead messaging and
feedback. This paper describes some of the shifts in thinking that may be
needed to overcome these roadblocks and develop a more general theory that we
refer to as non-equilibrium information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2469</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2469</id><created>2007-12-14</created><authors><author><keyname>Kong</keyname><forenames>Zhenning</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>Directed Percolation in Wireless Networks with Interference and Noise</title><categories>cs.IT cs.NI math.IT math.PR</categories><abstract>  Previous studies of connectivity in wireless networks have focused on
undirected geometric graphs. More sophisticated models such as
Signal-to-Interference-and-Noise-Ratio (SINR) model, however, usually leads to
directed graphs. In this paper, we study percolation processes in wireless
networks modelled by directed SINR graphs. We first investigate
interference-free networks, where we define four types of phase transitions and
show that they take place at the same time. By coupling the directed SINR graph
with two other undirected SINR graphs, we further obtain analytical upper and
lower bounds on the critical density. Then, we show that with interference,
percolation in directed SINR graphs depends not only on the density but also on
the inverse system processing gain. We also provide bounds on the critical
value of the inverse system processing gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2497</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2497</id><created>2007-12-15</created><authors><author><keyname>Fu</keyname><forenames>Fangwen</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>A New Theoretic Foundation for Cross-Layer Optimization</title><categories>cs.NI cs.LG</categories><comments>39 pages, 10 figures, technical report</comments><abstract>  Cross-layer optimization solutions have been proposed in recent years to
improve the performance of network users operating in a time-varying,
error-prone wireless environment. However, these solutions often rely on ad-hoc
optimization approaches, which ignore the different environmental dynamics
experienced at various layers by a user and violate the layered network
architecture of the protocol stack by requiring layers to provide access to
their internal protocol parameters to other layers. This paper presents a new
theoretic foundation for cross-layer optimization, which allows each layer to
make autonomous decisions individually, while maximizing the utility of the
wireless user by optimally determining what information needs to be exchanged
among layers. Hence, this cross-layer framework does not change the current
layered architecture. Specifically, because the wireless user interacts with
the environment at various layers of the protocol stack, the cross-layer
optimization problem is formulated as a layered Markov decision process (MDP)
in which each layer adapts its own protocol parameters and exchanges
information (messages) with other layers in order to cooperatively maximize the
performance of the wireless user. The message exchange mechanism for
determining the optimal cross-layer transmission strategies has been designed
for both off-line optimization and on-line dynamic adaptation. We also show
that many existing cross-layer optimization algorithms can be formulated as
simplified, sub-optimal, versions of our layered MDP framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2501</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2501</id><created>2007-12-15</created><updated>2008-01-03</updated><authors><author><keyname>Liang</keyname><forenames>Wang</forenames></author><author><keyname>Bing-wen</keyname><forenames>Wang</forenames></author><author><keyname>Yi-Ping</keyname><forenames>Guo</forenames></author></authors><title>Cell mapping description for digital control system with quantization
  effect</title><categories>cs.OH</categories><comments>22 pages,14 figues</comments><acm-class>C.3</acm-class><abstract>  Quantization problem in digital control system have attracted more and more
attention in these years. Normally, a quantized variable is regarded as a
perturbed copy of the unquantized variable in the research of quantization
effect, but this model has shown many obvious disadvantages in control system
analysis and design process. In this paper, we give a new model for
quantization based 'cell mapping' concept. This cell model could clearly
describe the global dynamics of quantized digital system. Then some important
characteristics of control system like controllability are analyzed by this
model. The finite precision control design method based on cell concept is also
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2552</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2552</id><created>2007-12-15</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Ling</keyname><forenames>Alan C. H.</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Shen</keyname><forenames>Hao</forenames></author></authors><title>The PBD-Closure of Constant-Composition Codes</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>8 pages</comments><journal-ref>IEEE Transactions on Information Theory, vol. 53, No. 8, August
  2007, pp. 2685-2692</journal-ref><doi>10.1109/TIT.2007.901175</doi><abstract>  We show an interesting PBD-closure result for the set of lengths of
constant-composition codes whose distance and size meet certain conditions. A
consequence of this PBD-closure result is that the size of optimal
constant-composition codes can be determined for infinite families of parameter
sets from just a single example of an optimal code. As an application, the size
of several infinite families of optimal constant-composition codes are derived.
In particular, the problem of determining the size of optimal
constant-composition codes having distance four and weight three is solved for
all lengths sufficiently large. This problem was previously unresolved for odd
lengths, except for lengths seven and eleven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2553</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2553</id><created>2007-12-15</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Colbourn</keyname><forenames>Charles J.</forenames></author></authors><title>Constructions for Difference Triangle Sets</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>4 pages</comments><acm-class>E.4</acm-class><journal-ref>IEEE Transactions on Information Theory, vol. 43, No. 4, July
  1997, pp. 1346-1349</journal-ref><abstract>  Difference triangle sets are useful in many practical problems of information
transmission. This correspondence studies combinatorial and computational
constructions for difference triangle sets having small scopes. Our algorithms
have been used to produce difference triangle sets whose scopes are the best
currently known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2559</identifier>
 <datestamp>2008-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2559</id><created>2007-12-16</created><updated>2008-03-11</updated><authors><author><keyname>Merlet</keyname><forenames>Glenn</forenames><affiliation>LIAFA</affiliation></author></authors><title>Cycle time of stochastic max-plus linear systems</title><categories>math.PR cs.DM</categories><comments>This article has been published by IMS in Electronic Journal of
  Probability at http://www.math.washington.edu/~ejpecp/viewarticle.php?id=1781</comments><proxy>ccsd hal-00197850</proxy><msc-class>60F15, 90B15, 93C65, 93E15</msc-class><journal-ref>Electronic Journal of Probability 13 (2008) (2008) Paper 12,
  322-340</journal-ref><abstract>  We analyze the asymptotic behavior of sequences of random variables defined
by an initial condition, a stationary and ergodic sequence of random matrices,
and an induction formula involving multiplication is the so-called max-plus
algebra. This type of recursive sequences are frequently used in applied
probability as they model many systems as some queueing networks, train and
computer networks, and production systems. We give a necessary condition for
the recursive sequences to satisfy a strong law of large numbers, which proves
to be sufficient when the matrices are i.i.d. Moreover, we construct a new
example, in which the sequence of matrices is strongly mixing, that condition
is satisfied, but the recursive sequence do not converges almost surely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2567</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2567</id><created>2007-12-17</created><authors><author><keyname>Kamalian</keyname><forenames>Rafael R.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>On Lower Bound for W(K_{2n})</title><categories>cs.DM</categories><comments>3 pages</comments><journal-ref>Mathematical Problems of Computer Science 23, 2004, 127--129</journal-ref><abstract>  The lower bound W(K_{2n})&gt;=3n-2 is proved for the greatest possible number of
colors in an interval edge coloring of the complete graph K_{2n}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2577</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2577</id><created>2007-12-16</created><updated>2007-12-20</updated><authors><author><keyname>Maurice</keyname><forenames>Margenstern</forenames></author></authors><title>Is the injectivity of the global function of a cellular automaton in the
  hyperbolic plane undecidable?</title><categories>cs.DM cs.LO</categories><comments>16 pages, 8 figures. A few words were missing in the initial version</comments><acm-class>F.2.2</acm-class><abstract>  In this paper, we look at the following question. We consider cellular
automata in the hyperbolic plane and we consider the global function defined on
all possible configurations. Is the injectivity of this function undecidable?
The problem was answered positively in the case of the Euclidean plane by
Jarkko Kari, in 1994. In the present paper, we give a partial answer: when the
configurations are restricted to a certain condition, the problem is
undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2579</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2579</id><created>2007-12-16</created><updated>2007-12-19</updated><authors><author><keyname>Yao</keyname><forenames>Hongyi</forenames></author></authors><title>On the Information of the Second Moments Between Random Variables Using
  Mutually Unbiased Bases</title><categories>cs.IT math.IT</categories><comments>20pages, no figures. The paper has been submitted to IEEE
  Transanction on Information Theory</comments><abstract>  The notation of mutually unbiased bases(MUB) was first introduced by Ivanovic
to reconstruct density matrixes\cite{Ivanovic}. The subject about how to use
MUB to analyze, process, and utilize the information of the second moments
between random variables is studied in this paper. In the first part, the
mathematical foundation will be built. It will be shown that the spectra of MUB
have complete information for the correlation matrixes of finite discrete
signals, and the nice properties of them. Roughly speaking, it will be shown
that each spectrum from MUB plays an equal role for finite discrete signals,
and the effect between any two spectra can be treated as a global constant
shift. These properties will be used to find some important and natural
characterizations of random vectors and random discrete operators/filters. For
a technical reason, it will be shown that any MUB spectra can be found as fast
as Fourier spectrum when the length of the signal is a prime number.
  In the second part, some applications will be presented. First of all, a
protocol about how to increase the number of users in a basic digital
communication model will be studied, which has bring some deep insights about
how to encode the information into the second moments between random variables.
Secondly, the application of signal analysis will be studied. It is suggested
that complete &quot;MUB&quot; spectra analysis works well in any case, and people can
just choose the spectra they are interested in to do analysis. For instance,
single Fourier spectra analysis can be also applied in nonstationary case.
Finally, the application of MUB in dimensionality reduction will be considered,
when the prior knowledge of the data isn't reliable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2585</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2585</id><created>2007-12-17</created><updated>2007-12-28</updated><authors><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>Interval Edge Colourings of Complete Graphs and n-cubes</title><categories>cs.DM</categories><comments>4 pages</comments><journal-ref>Mathematical Problems of Computer Science 25, 2006, 5--8</journal-ref><abstract>  For complete graphs and n-cubes bounds are found for the possible number of
colours in an interval edge colourings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2587</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2587</id><created>2007-12-17</created><authors><author><keyname>Wu</keyname><forenames>Chia-Lung</forenames></author><author><keyname>Chen</keyname><forenames>Po-Ning</forenames></author><author><keyname>Han</keyname><forenames>Yunghsiang S.</forenames></author><author><keyname>Kuo</keyname><forenames>Ming-Hsin</forenames></author></authors><title>Maximum-Likelihood Priority-First Search Decodable Codes for Combined
  Channel Estimation and Error Protection</title><categories>cs.IT math.IT</categories><comments>13 figures, 2 tables</comments><abstract>  The code that combines channel estimation and error protection has received
general attention recently, and has been considered a promising methodology to
compensate multi-path fading effect. It has been shown by simulations that such
code design can considerably improve the system performance over the
conventional design with separate channel estimation and error protection
modules under the same code rate. Nevertheless, the major obstacle that
prevents from the practice of the codes is that the existing codes are mostly
searched by computers, and hence exhibit no good structure for efficient
decoding. Hence, the time-consuming exhaustive search becomes the only decoding
choice, and the decoding complexity increases dramatically with the codeword
length. In this paper, by optimizing the signal-tonoise ratio, we found a
systematic construction for the codes for combined channel estimation and error
protection, and confirmed its equivalence in performance to the
computer-searched codes by simulations. Moreover, the structural codes that we
construct by rules can now be maximum-likelihoodly decodable in terms of a
newly derived recursive metric for use of the priority-first search decoding
algorithm. Thus,the decoding complexity reduces significantly when compared
with that of the exhaustive decoder. The extension code design for fast-fading
channels is also presented. Simulations conclude that our constructed extension
code is robust in performance even if the coherent period is shorter than the
codeword length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2591</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2591</id><created>2007-12-16</created><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>A Typical Model Audit Approach: Spreadsheet Audit Methodologies in the
  City of London</title><categories>cs.SE cs.CY</categories><comments>5 Pages</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>IFIP, Integrity and Internal Control in Information Systems, Vol
  124, pp. 213-219, Kluwer, 2003</journal-ref><abstract>  Spreadsheet audit and review procedures are an essential part of almost all
City of London financial transactions. Structured processes are used to
discover errors in large financial spreadsheets underpinning major transactions
of all types. Serious errors are routinely found and are fed back to model
development teams generally under conditions of extreme time urgency. Corrected
models form the essence of the completed transaction and firms undertaking
model audit and review expose themselves to significant financial liability in
the event of any remaining significant error. It is noteworthy that in the
United Kingdom, the management of spreadsheet error is almost unheard of
outside of the City of London despite the commercial ubiquity of the
spreadsheet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2592</identifier>
 <datestamp>2008-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2592</id><created>2007-12-16</created><authors><author><keyname>Yakowitz</keyname><forenames>S.</forenames></author><author><keyname>Gyorfi</keyname><forenames>L.</forenames></author><author><keyname>Kieffer</keyname><forenames>J.</forenames></author><author><keyname>Morvai</keyname><forenames>G.</forenames></author></authors><title>Strongly consistent nonparametric forecasting and regression for
  stationary ergodic sequences</title><categories>math.PR cs.IT math.IT</categories><journal-ref>J. Multivariate Anal. 71 (1999), no. 1, 24--41</journal-ref><abstract>  Let $\{(X_i,Y_i)\}$ be a stationary ergodic time series with $(X,Y)$ values
in the product space $\R^d\bigotimes \R .$ This study offers what is believed
to be the first strongly consistent (with respect to pointwise, least-squares,
and uniform distance) algorithm for inferring $m(x)=E[Y_0|X_0=x]$ under the
presumption that $m(x)$ is uniformly Lipschitz continuous. Auto-regression, or
forecasting, is an important special case, and as such our work extends the
literature of nonparametric, nonlinear forecasting by circumventing customary
mixing assumptions. The work is motivated by a time series model in stochastic
finance and by perspectives of its contribution to the issues of universal time
series estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2594</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2594</id><created>2007-12-16</created><authors><author><keyname>Chadwick</keyname><forenames>David</forenames></author></authors><title>Stop That Subversive Spreadsheet!</title><categories>cs.GL</categories><comments>6 Pages</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>IFIP, Integrity and Internal Control in Information Systems, Vol
  24, pp. 205-211, Kluwer, 2003</journal-ref><abstract>  This paper documents the formation of the European Spreadsheet Risks Interest
Group (EuSpRIG www.eusprig.org) and outlines some of the research undertaken
and reported upon by interested parties in EuSpRIG publications
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2595</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2595</id><created>2007-12-16</created><authors><author><keyname>Rosgen</keyname><forenames>Bill</forenames></author></authors><title>Distinguishing Short Quantum Computations</title><categories>quant-ph cs.CC</categories><comments>12 pages, 4 figures, to be published in the proceedings of STACS 2008</comments><doi>10.4230/LIPIcs.STACS.2008.1322</doi><abstract>  Distinguishing logarithmic depth quantum circuits on mixed states is shown to
be complete for QIP, the class of problems having quantum interactive proof
systems. Circuits in this model can represent arbitrary quantum processes, and
thus this result has implications for the verification of implementations of
quantum algorithms. The distinguishability problem is also complete for QIP on
constant depth circuits containing the unbounded fan-out gate. These results
are shown by reducing a QIP-complete problem to a logarithmic depth version of
itself using a parallelization technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2605</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2605</id><created>2007-12-16</created><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>Some A Priori Torah Decryption Principles</title><categories>cs.CR</categories><comments>11 Pages. Presented at the 2nd conference of the Int. Torah Codes
  Society, Jerusalem, Israel, 5th June 2000</comments><acm-class>E.3</acm-class><journal-ref>Proc. ANPA Cambridge, UK, 2007</journal-ref><abstract>  The author proposes, a priori, a simple set of principles that can be
developed into a range of algorithms by which means the Torah might be decoded.
It is assumed that the Torah is some form of transposition cipher with the
unusual property that the plain text of the Torah may also be the cipher text
of one or more other documents written in Biblical Hebrew. The decryption
principles are based upon the use of Equidistant Letter Sequences (ELS) and the
notions of Message Length, Dimensionality, Euclidean Dimension, Topology, Read
Direction, Skip Distance and offset. The principles can be applied recursively
and define numerous large subsets of the 304,807! theoretically possible
permutations of the characters of the Torah.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2606</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2606</id><created>2007-12-16</created><updated>2010-10-19</updated><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>Algorithmic Permutation of part of the Torah</title><categories>cs.CR</categories><comments>10 Pages. Presented at the Second Conference of the International
  Torah Codes Society, Jerusalem, Israel, 6th June 2000. Minor updates and
  added Appendix B in version 2, October 2010</comments><acm-class>E.3</acm-class><journal-ref>Proc. ANPA 27, Wesley College, Cambridge, UK, September 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A small part of the Torah is arranged into a two dimensional array. The
characters are then permuted using a simple recursive deterministic algorithm.
The various permutations are then passed through three stochastic filters and
one deterministic filter to identify the permutations which most closely
approximate readable Biblical Hebrew. Of the 15 Billion sequences available at
the second level of recursion, 800 pass the a priori thresholds set for each
filter. The resulting &quot;Biblical Hebrew&quot; text is available for inspection and
the generation of further material continues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2619</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2619</id><created>2007-12-16</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author></authors><title>A New Lower Bound for A(17,6,6)</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>3 pages</comments><acm-class>E.4</acm-class><journal-ref>Ars Combinatoria, Vol. 83, pp. 361-363, 2007</journal-ref><abstract>  We construct a record-breaking binary code of length 17, minimal distance 6,
constant weight 6, and containing 113 codewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2629</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2629</id><created>2007-12-16</created><updated>2008-01-04</updated><authors><author><keyname>Hamane</keyname><forenames>Ryoso</forenames></author><author><keyname>Itoh</keyname><forenames>Toshiya</forenames></author><author><keyname>Tomita</keyname><forenames>Kouhei</forenames></author></authors><title>Approximation Algorithms for the Highway Problem under the Coupon Model</title><categories>cs.DS</categories><comments>13 pages, 5 figures</comments><acm-class>F.2.2; G.1.2; G.2.1</acm-class><journal-ref>IEICE Trans. on Fundamentals, E92-A(8), pp.1779-1786, 2009</journal-ref><doi>10.1587/transfun.E92.A.1779</doi><abstract>  When a store sells items to customers, the store wishes to determine the
prices of the items to maximize its profit. Intuitively, if the store sells the
items with low (resp. high) prices, the customers buy more (resp. less) items,
which provides less profit to the store. So it would be hard for the store to
decide the prices of items. Assume that the store has a set V of n items and
there is a set E of m customers who wish to buy those items, and also assume
that each item i \in V has the production cost d_i and each customer e_j \in E
has the valuation v_j on the bundle e_j \subseteq V of items. When the store
sells an item i \in V at the price r_i, the profit for the item i is
p_i=r_i-d_i. The goal of the store is to decide the price of each item to
maximize its total profit. In most of the previous works, the item pricing
problem was considered under the assumption that p_i \geq 0 for each i \in V,
however, Balcan, et al. [In Proc. of WINE, LNCS 4858, 2007] introduced the
notion of loss-leader, and showed that the seller can get more total profit in
the case that p_i &lt; 0 is allowed than in the case that p_i &lt; 0 is not allowed.
In this paper, we consider the line and the cycle highway problem, and show
approximation algorithms for the line and/or cycle highway problem for which
the smallest valuation is s and the largest valuation is \ell or all valuations
are identical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2630</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2630</id><created>2007-12-17</created><authors><author><keyname>Zorzano</keyname><forenames>Nestor</forenames></author><author><keyname>Merino</keyname><forenames>Daniel</forenames></author><author><keyname>Laredo</keyname><forenames>J. L. J.</forenames></author><author><keyname>Sevilla</keyname><forenames>J. P.</forenames></author><author><keyname>Garcia</keyname><forenames>Pablo</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author></authors><title>Evolving XSLT stylesheets</title><categories>cs.NE cs.PL</categories><comments>First draft, preparing for WCCI 2008</comments><abstract>  This paper introduces a procedure based on genetic programming to evolve XSLT
programs (usually called stylesheets or logicsheets). XSLT is a general
purpose, document-oriented functional language, generally used to transform XML
documents (or, in general, solve any problem that can be coded as an XML
document). The proposed solution uses a tree representation for the stylesheets
as well as diverse specific operators in order to obtain, in the studied cases
and a reasonable time, a XSLT stylesheet that performs the transformation.
Several types of representation have been compared, resulting in different
performance and degree of success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2638</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2638</id><created>2007-12-17</created><updated>2007-12-18</updated><authors><author><keyname>Chazal</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Oudot</keyname><forenames>Steve</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Towards Persistence-Based Reconstruction in Euclidean Spaces</title><categories>cs.CG math.AT</categories><proxy>ccsd inria-00197543</proxy><abstract>  Manifold reconstruction has been extensively studied for the last decade or
so, especially in two and three dimensions. Recently, significant improvements
were made in higher dimensions, leading to new methods to reconstruct large
classes of compact subsets of Euclidean space $\R^d$. However, the complexities
of these methods scale up exponentially with d, which makes them impractical in
medium or high dimensions, even for handling low-dimensional submanifolds. In
this paper, we introduce a novel approach that stands in-between classical
reconstruction and topological estimation, and whose complexity scales up with
the intrinsic dimension of the data. Specifically, when the data points are
sufficiently densely sampled from a smooth $m$-submanifold of $\R^d$, our
method retrieves the homology of the submanifold in time at most $c(m)n^5$,
where $n$ is the size of the input and $c(m)$ is a constant depending solely on
$m$. It can also provably well handle a wide range of compact subsets of
$\R^d$, though with worse complexities. Along the way to proving the
correctness of our algorithm, we obtain new results on \v{C}ech, Rips, and
witness complex filtrations in Euclidean spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2640</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2640</id><created>2007-12-17</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Colbourn</keyname><forenames>Charles J.</forenames></author><author><keyname>Ling</keyname><forenames>Alan C. H.</forenames></author></authors><title>Optimal Memoryless Encoding for Low Power Off-Chip Data Buses</title><categories>cs.AR cs.DM cs.IT math.IT</categories><comments>Proceedings of the 2006 IEEE/ACM international Conference on
  Computer-Aided Design (San Jose, California, November 05 - 09, 2006). ICCAD
  '06. ACM, New York, NY, 369-374</comments><acm-class>B.4.3; B.m; E.4</acm-class><doi>10.1145/1233501.1233575</doi><abstract>  Off-chip buses account for a significant portion of the total system power
consumed in embedded systems. Bus encoding schemes have been proposed to
minimize power dissipation, but none has been demonstrated to be optimal with
respect to any measure. In this paper, we give the first provably optimal and
explicit (polynomial-time constructible) families of memoryless codes for
minimizing bit transitions in off-chip buses. Our results imply that having
access to a clock does not make a memoryless encoding scheme that minimizes bit
transitions more powerful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2643</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2643</id><created>2007-12-17</created><authors><author><keyname>Tranouez</keyname><forenames>Pierrick</forenames><affiliation>LITIS</affiliation></author><author><keyname>Bertelle</keyname><forenames>Cyrille</forenames><affiliation>LITIS</affiliation></author><author><keyname>Olivier</keyname><forenames>Damien</forenames><affiliation>LITIS</affiliation></author></authors><title>Changing Levels of Description in a Fluid Flow Simulation</title><categories>physics.flu-dyn cs.CE</categories><proxy>ccsd hal-00198098</proxy><journal-ref>Emergent Properties in Natural and Artificial Dynamical Systems,
  Springer (Ed.) (2006) 87-99</journal-ref><abstract>  We describe here our perception of complex systems, of how we feel the
different layers of description are important part of a correct complex system
simulation. We describe a rough models categorization between rules based and
law based, of how these categories handled the levels of descriptions or
scales. We then describe our fluid flow simulation, which combines different
fineness of grain in a mixed approach of these categories. This simulation is
built keeping in mind an ulterior use inside a more general aquatic ecosystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2644</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2644</id><created>2007-12-17</created><authors><author><keyname>Ghnemat</keyname><forenames>Rawan</forenames><affiliation>LITIS</affiliation></author><author><keyname>Oqeili</keyname><forenames>Saleh</forenames><affiliation>IT</affiliation></author><author><keyname>Bertelle</keyname><forenames>Cyrille</forenames><affiliation>LITIS</affiliation></author><author><keyname>Duchamp</keyname><forenames>G&#xe9;rard Henry Edmond</forenames><affiliation>LIPN</affiliation></author></authors><title>Automata-based Adaptive Behavior for Economical Modelling Using Game
  Theory</title><categories>cs.GT cs.CC</categories><proxy>ccsd hal-00198093</proxy><journal-ref>Emergent Properties in Natural and Artificial Dynamical Systems,
  Springer (Ed.) (2006) 171-183</journal-ref><abstract>  In this chapter, we deal with some specific domains of applications to game
theory. This is one of the major class of models in the new approaches of
modelling in the economic domain. For that, we use genetic automata which allow
to build adaptive strategies for the players. We explain how the automata-based
formalism proposed - matrix representation of automata with multiplicities -
allows to define semi-distance between the strategy behaviors. With that tools,
we are able to generate an automatic processus to compute emergent systems of
entities whose behaviors are represented by these genetic automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2661</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2661</id><created>2007-12-17</created><authors><author><keyname>Balister</keyname><forenames>P.</forenames></author><author><keyname>Gerke</keyname><forenames>S.</forenames></author><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Johnstone</keyname><forenames>A.</forenames></author><author><keyname>Reddington</keyname><forenames>J.</forenames></author><author><keyname>Scott</keyname><forenames>E.</forenames></author><author><keyname>Soleimanfallah</keyname><forenames>A.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>Algorithms for Generating Convex Sets in Acyclic Digraphs</title><categories>cs.DM cs.DS</categories><abstract>  A set $X$ of vertices of an acyclic digraph $D$ is convex if $X\neq
\emptyset$ and there is no directed path between vertices of $X$ which contains
a vertex not in $X$. A set $X$ is connected if $X\neq \emptyset$ and the
underlying undirected graph of the subgraph of $D$ induced by $X$ is connected.
Connected convex sets and convex sets of acyclic digraphs are of interest in
the area of modern embedded processor technology. We construct an algorithm
$\cal A$ for enumeration of all connected convex sets of an acyclic digraph $D$
of order $n$. The time complexity of $\cal A$ is $O(n\cdot cc(D))$, where
$cc(D)$ is the number of connected convex sets in $D$. We also give an optimal
algorithm for enumeration of all (not just connected) convex sets of an acyclic
digraph $D$ of order $n$. In computational experiments we demonstrate that our
algorithms outperform the best algorithms in the literature.
  Using the same approach as for $\cal A$, we design an algorithm for
generating all connected sets of a connected undirected graph $G$. The
complexity of the algorithm is $O(n\cdot c(G)),$ where $n$ is the order of $G$
and $c(G)$ is the number of connected sets of $G.$ The previously reported
algorithm for connected set enumeration is of running time $O(mn\cdot c(G))$,
where $m$ is the number of edges in $G.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2671</identifier>
 <datestamp>2009-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2671</id><created>2007-12-17</created><updated>2009-02-10</updated><authors><author><keyname>Bus&#xe9;</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>On the equations of the moving curve ideal of a rational algebraic plane
  curve</title><categories>math.AG cs.SC math.AC</categories><comments>Journal of Algebra (2009)</comments><proxy>ccsd inria-00198350</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a parametrization of a rational plane algebraic curve C, some explicit
adjoint pencils on C are described in terms of determinants. Moreover, some
generators of the Rees algebra associated to this parametrization are
presented. The main ingredient developed in this paper is a detailed study of
the elimination ideal of two homogeneous polynomials in two homogeneous
variables that form a regular sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2678</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2678</id><created>2007-12-17</created><authors><author><keyname>Balister</keyname><forenames>P.</forenames></author><author><keyname>Gerke</keyname><forenames>S.</forenames></author><author><keyname>Gutin</keyname><forenames>G.</forenames></author></authors><title>Convex sets in acyclic digraphs</title><categories>cs.DM</categories><abstract>  A non-empty set $X$ of vertices of an acyclic digraph is called connected if
the underlying undirected graph induced by $X$ is connected and it is called
convex if no two vertices of $X$ are connected by a directed path in which some
vertices are not in $X$. The set of convex sets (connected convex sets) of an
acyclic digraph $D$ is denoted by $\sco(D)$ ($\scc(D)$) and its size by
$\co(D)$ ($\cc(D)$). Gutin, Johnstone, Reddington, Scott, Soleimanfallah, and
Yeo (Proc. ACiD'07) conjectured that the sum of the sizes of all (connected)
convex sets in $D$ equals $\Theta(n \cdot \co(D))$ ($\Theta(n \cdot \cc(D))$)
where $n$ is the order of $D$.
  In this paper we exhibit a family of connected acyclic digraphs with
$\sum_{C\in \sco(D)}|C| = o(n\cdot \co(D))$ and $\sum_{C\in \scc(D)}|C| =
o(n\cdot \cc(D))$. We also show that the number of connected convex sets of
order $k$ in any connected acyclic digraph of order $n$ is at least $n-k+1$.
This is a strengthening of a theorem by Gutin and Yeo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2682</identifier>
 <datestamp>2008-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2682</id><created>2007-12-17</created><updated>2008-08-22</updated><authors><author><keyname>Puolam&#xe4;ki</keyname><forenames>Kai</forenames></author><author><keyname>Hanhij&#xe4;rvi</keyname><forenames>Sami</forenames></author><author><keyname>Garriga</keyname><forenames>Gemma C.</forenames></author></authors><title>An Approximation Ratio for Biclustering</title><categories>cs.DS stat.ML</categories><comments>9 pages, 2 figures; presentation clarified, replaced to match the
  version to be published in IPL</comments><report-no>Publications in Computer and Information Science E13</report-no><journal-ref>Information Processing Letters 108 (2008) 45-49</journal-ref><doi>10.1016/j.ipl.2008.03.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of biclustering consists of the simultaneous clustering of rows
and columns of a matrix such that each of the submatrices induced by a pair of
row and column clusters is as uniform as possible. In this paper we approximate
the optimal biclustering by applying one-way clustering algorithms
independently on the rows and on the columns of the input matrix. We show that
such a solution yields a worst-case approximation ratio of 1+sqrt(2) under
L1-norm for 0-1 valued matrices, and of 2 under L2-norm for real valued
matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2684</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2684</id><created>2007-12-17</created><authors><author><keyname>Lopez-Ruiz</keyname><forenames>R.</forenames></author><author><keyname>Gonzalez-Estevez</keyname><forenames>J.</forenames></author><author><keyname>Cosenza</keyname><forenames>M. G.</forenames></author><author><keyname>Sanchez</keyname><forenames>J. R.</forenames></author></authors><title>An Economic Model of Coupled Exponential Maps</title><categories>q-fin.GN cs.MA nlin.AO physics.soc-ph</categories><comments>3 pages, 1 figure ; Presented at NOMA'07 Conference, December 2007,
  Toulouse (France)</comments><abstract>  In this work, an ensemble of economic interacting agents is considered. The
agents are arranged in a linear array where only local couplings are allowed.
The deterministic dynamics of each agent is given by a map. This map is
expressed by two factors. The first one is a linear term that models the
expansion of the agent's economy and that is controlled by the {\it growth
capacity parameter}. The second one is an inhibition exponential term that is
regulated by the {\it local environmental pressure}. Depending on the parameter
setting, the system can display Pareto or Boltzmann-Gibbs behavior in the
asymptotic dynamical regime. The regions of parameter space where the system
exhibits one of these two statistical behaviors are delimited. Other properties
of the system, such as the mean wealth, the standard deviation and the Gini
coefficient, are also calculated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2737</identifier>
 <datestamp>2007-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2737</id><created>2007-12-17</created><authors><author><keyname>Henriksen</keyname><forenames>Kim</forenames></author><author><keyname>Banda</keyname><forenames>Gourinath</forenames></author><author><keyname>Gallagher</keyname><forenames>John</forenames></author></authors><title>Experiments with a Convex Polyhedral Analysis Tool for Logic Programs</title><categories>cs.PL cs.SE</categories><comments>Paper presented at the 17th Workshop on Logic-based Methods in
  Programming Environments (WLPE2007)</comments><acm-class>D.2.6; D.1.6</acm-class><abstract>  Convex polyhedral abstractions of logic programs have been found very useful
in deriving numeric relationships between program arguments in order to prove
program properties and in other areas such as termination and complexity
analysis. We present a tool for constructing polyhedral analyses of
(constraint) logic programs. The aim of the tool is to make available, with a
convenient interface, state-of-the-art techniques for polyhedral analysis such
as delayed widening, narrowing, &quot;widening up-to&quot;, and enhanced automatic
selection of widening points. The tool is accessible on the web, permits user
programs to be uploaded and analysed, and is integrated with related program
transformations such as size abstractions and query-answer transformation. We
then report some experiments using the tool, showing how it can be conveniently
used to analyse transition systems arising from models of embedded systems, and
an emulator for a PIC microcontroller which is used for example in wearable
computing systems. We discuss issues including scalability, tradeoffs of
precision and computation time, and other program transformations that can
enhance the results of analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2773</identifier>
 <datestamp>2008-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2773</id><created>2007-12-17</created><updated>2008-11-05</updated><authors><author><keyname>Cecchet</keyname><forenames>Emmanuel</forenames></author><author><keyname>Candea</keyname><forenames>George</forenames></author><author><keyname>Ailamaki</keyname><forenames>Anastasia</forenames></author></authors><title>Middleware-based Database Replication: The Gaps between Theory and
  Practice</title><categories>cs.DB cs.DC cs.PF</categories><comments>14 pages. Appears in Proc. ACM SIGMOD International Conference on
  Management of Data, Vancouver, Canada, June 2008</comments><report-no>EPFL technical report DSLAB-REPORT-2007-001</report-no><acm-class>H.2; C.2.4; C.4; D.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need for high availability and performance in data management systems has
been fueling a long running interest in database replication from both academia
and industry. However, academic groups often attack replication problems in
isolation, overlooking the need for completeness in their solutions, while
commercial teams take a holistic approach that often misses opportunities for
fundamental innovation. This has created over time a gap between academic
research and industrial practice.
  This paper aims to characterize the gap along three axes: performance,
availability, and administration. We build on our own experience developing and
deploying replication systems in commercial and academic settings, as well as
on a large body of prior related work. We sift through representative examples
from the last decade of open-source, academic, and commercial database
replication systems and combine this material with case studies from real
systems deployed at Fortune 500 customers. We propose two agendas, one for
academic research and one for industrial R&amp;D, which we believe can bridge the
gap within 5-10 years. This way, we hope to both motivate and help researchers
in making the theory and practice of middleware-based database replication more
relevant to each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2789</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2789</id><created>2007-12-17</created><updated>2009-11-03</updated><authors><author><keyname>Ingber</keyname><forenames>Lester</forenames></author></authors><title>Trading in Risk Dimensions (TRD)</title><categories>cs.CE cs.NA</categories><comments>This 2005 report has been withdrawn by the author as requested by the
  publisher of &quot;Handbook of Technical Trading Analysis&quot; (Wiley, 2009) in which
  an updated version appears</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work, mostly published, developed two-shell recursive trading
systems. An inner-shell of Canonical Momenta Indicators (CMI) is adaptively fit
to incoming market data. A parameterized trading-rule outer-shell uses the
global optimization code Adaptive Simulated Annealing (ASA) to fit the trading
system to historical data. A simple fitting algorithm, usually not requiring
ASA, is used for the inner-shell fit. An additional risk-management
middle-shell has been added to create a three-shell recursive
optimization/sampling/fitting algorithm. Portfolio-level distributions of
copula-transformed multivariate distributions (with constituent markets
possessing different marginal distributions in returns space) are generated by
Monte Carlo samplings. ASA is used to importance-sample weightings of these
markets.
  The core code, Trading in Risk Dimensions (TRD), processes Training and
Testing trading systems on historical data, and consistently interacts with
RealTime trading platforms at minute resolutions, but this scale can be
modified. This approach transforms constituent probability distributions into a
common space where it makes sense to develop correlations to further develop
probability distributions and risk/uncertainty analyses of the full portfolio.
ASA is used for importance-sampling these distributions and for optimizing
system parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2857</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2857</id><created>2007-12-17</created><authors><author><keyname>Han</keyname><forenames>Junsheng</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Roth</keyname><forenames>Ron M.</forenames></author></authors><title>Single-Exclusion Number and the Stopping Redundancy of MDS Codes</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>12 pages, 1 figure. Submitted to IEEE Transactions on Information
  Theory</comments><acm-class>H.1.1</acm-class><abstract>  For a linear block code C, its stopping redundancy is defined as the smallest
number of check nodes in a Tanner graph for C, such that there exist no
stopping sets of size smaller than the minimum distance of C. Schwartz and
Vardy conjectured that the stopping redundancy of an MDS code should only
depend on its length and minimum distance.
  We define the (n,t)-single-exclusion number, S(n,t) as the smallest number of
t-subsets of an n-set, such that for each i-subset of the n-set, i=1,...,t+1,
there exists a t-subset that contains all but one element of the i-subset. New
upper bounds on the single-exclusion number are obtained via probabilistic
methods, recurrent inequalities, as well as explicit constructions. The new
bounds are used to better understand the stopping redundancy of MDS codes. In
particular, it is shown that for [n,k=n-d+1,d] MDS codes, as n goes to
infinity, the stopping redundancy is asymptotic to S(n,d-2), if d=o(\sqrt{n}),
or if k=o(\sqrt{n}) and k goes to infinity, thus giving partial confirmation of
the Schwartz-Vardy conjecture in the asymptotic sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2869</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2869</id><created>2007-12-17</created><authors><author><keyname>Mahalanabis</keyname><forenames>Satyaki</forenames></author><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author></authors><title>Density estimation in linear time</title><categories>cs.LG</categories><comments>11 pages</comments><abstract>  We consider the problem of choosing a density estimate from a set of
distributions F, minimizing the L1-distance to an unknown distribution
(Devroye, Lugosi 2001). Devroye and Lugosi analyze two algorithms for the
problem: Scheffe tournament winner and minimum distance estimate. The Scheffe
tournament estimate requires fewer computations than the minimum distance
estimate, but has strictly weaker guarantees than the latter.
  We focus on the computational aspect of density estimation. We present two
algorithms, both with the same guarantee as the minimum distance estimate. The
first one, a modification of the minimum distance estimate, uses the same
number (quadratic in |F|) of computations as the Scheffe tournament. The second
one, called ``efficient minimum loss-weight estimate,'' uses only a linear
number of computations, assuming that F is preprocessed.
  We also give examples showing that the guarantees of the algorithms cannot be
improved and explore randomized algorithms for density estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2870</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2870</id><created>2007-12-17</created><authors><author><keyname>Palaiyanur</keyname><forenames>Hari</forenames></author><author><keyname>Chang</keyname><forenames>Cheng</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>The source coding game with a cheating switcher</title><categories>cs.IT cs.CV math.IT</categories><comments>27 pages, 11 figures. Submitted to IT Transactions</comments><report-no>EECS-2007-155</report-no><abstract>  Motivated by the lossy compression of an active-vision video stream, we
consider the problem of finding the rate-distortion function of an arbitrarily
varying source (AVS) composed of a finite number of subsources with known
distributions. Berger's paper `The Source Coding Game', \emph{IEEE Trans.
Inform. Theory}, 1971, solves this problem under the condition that the
adversary is allowed only strictly causal access to the subsource realizations.
We consider the case when the adversary has access to the subsource
realizations non-causally. Using the type-covering lemma, this new
rate-distortion function is determined to be the maximum of the IID
rate-distortion function over a set of source distributions attainable by the
adversary. We then extend the results to allow for partial or noisy
observations of subsource realizations. We further explore the model by
attempting to find the rate-distortion function when the adversary is actually
helpful. 
  Finally, a bound is developed on the uniform continuity of the IID
rate-distortion function for finite-alphabet sources. The bound is used to give
a sufficient number of distributions that need to be sampled to compute the
rate-distortion function of an AVS to within a certain accuracy. The bound is
also used to give a rate of convergence for the estimate of the rate-distortion
function for an unknown IID finite-alphabet source .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2872</identifier>
 <datestamp>2008-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2872</id><created>2007-12-17</created><updated>2008-12-15</updated><authors><author><keyname>Sethuraman</keyname><forenames>Vignesh</forenames></author><author><keyname>Wang</keyname><forenames>Ligong</forenames></author><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>Low SNR Capacity of Noncoherent Fading Channels</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete-time Rayleigh fading single-input single-output (SISO) and
multiple-input multiple-output (MIMO) channels are considered, with no channel
state information at the transmitter or the receiver. The fading is assumed to
be stationary and correlated in time, but independent from antenna to antenna.
Peak-power and average-power constraints are imposed on the transmit antennas.
For MIMO channels, these constraints are either imposed on the sum over
antennas, or on each individual antenna. For SISO channels and MIMO channels
with sum power constraints, the asymptotic capacity as the peak signal-to-noise
ratio tends to zero is identified; for MIMO channels with individual power
constraints, this asymptotic capacity is obtained for a class of channels
called transmit separable channels. The results for MIMO channels with
individual power constraints are carried over to SISO channels with delay
spread (i.e. frequency selective fading).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2923</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2923</id><created>2007-12-18</created><authors><author><keyname>Anguelov</keyname><forenames>Roumen</forenames></author><author><keyname>Plaskitt</keyname><forenames>Inger</forenames></author></authors><title>A Class of LULU Operators on Multi-Dimensional Arrays</title><categories>cs.CV</categories><abstract>  The LULU operators for sequences are extended to multi-dimensional arrays via
the morphological concept of connection in a way which preserves their
essential properties, e.g. they are separators and form a four element fully
ordered semi-group. The power of the operators is demonstrated by deriving a
total variation preserving discrete pulse decomposition of images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2943</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2943</id><created>2007-12-18</created><authors><author><keyname>Diertens</keyname><forenames>Bob</forenames></author></authors><title>Software (Re-)Engineering with PSF</title><categories>cs.SE</categories><report-no>PRG0505</report-no><abstract>  This paper investigates the usefulness of PSF in software engineering and
reengineering. PSF is based on ACP (Algebra of Communicating Processes) and as
some architectural description languages are based on process algebra, we
investigate whether PSF can be used at the software architecture level, but we
also use PSF at lower abstract levels. As a case study we reengineer the
compiler from the Toolkit of PSF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2952</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2952</id><created>2007-12-18</created><authors><author><keyname>Bloom</keyname><forenames>S. L.</forenames></author><author><keyname>Esik</keyname><forenames>Z.</forenames></author><author><keyname>Kuich</keyname><forenames>W.</forenames></author></authors><title>Partial Conway and iteration semirings</title><categories>cs.DM cs.LO</categories><abstract>  A Conway semiring is a semiring $S$ equipped with a unary operation $^*:S \to
S$, always called 'star', satisfying the sum star and product star identities.
It is known that these identities imply a Kleene type theorem. Some
computationally important semirings, such as $N$ or $N^{\rat}\llangle \Sigma^*
\rrangle$ of rational power series of words on $\Sigma$ with coefficients in
$N$, cannot have a total star operation satisfying the Conway identities. We
introduce here partial Conway semirings, which are semirings $S$ which have a
star operation defined only on an ideal of $S$; when the arguments are
appropriate, the operation satisfies the above identities. We develop the
general theory of partial Conway semirings and prove a Kleene theorem for this
generalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2958</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2958</id><created>2007-12-18</created><updated>2008-03-10</updated><authors><author><keyname>N&#xe9;lis</keyname><forenames>Vincent</forenames></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author><author><keyname>Navet</keyname><forenames>Nicolas</forenames></author><author><keyname>Devillers</keyname><forenames>Raymond</forenames></author><author><keyname>Milojevic</keyname><forenames>Dragomir</forenames></author></authors><title>Power-Aware Real-Time Scheduling upon Identical Multiprocessor Platforms</title><categories>cs.OS</categories><comments>The manuscript corresponds to the final version of SUTC 2008
  conference</comments><abstract>  In this paper, we address the power-aware scheduling of sporadic
constrained-deadline hard real-time tasks using dynamic voltage scaling upon
multiprocessor platforms. We propose two distinct algorithms. Our first
algorithm is an off-line speed determination mechanism which provides an
identical speed for each processor. That speed guarantees that all deadlines
are met if the jobs are scheduled using EDF. The second algorithm is an on-line
and adaptive speed adjustment mechanism which reduces the energy consumption
while the system is running.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2959</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2959</id><created>2007-12-18</created><authors><author><keyname>Han</keyname><forenames>Te Sun</forenames></author></authors><title>Joint Source-Channel Coding Revisited: Information-Spectrum Approach</title><categories>cs.IT math.IT</categories><abstract>  Given a general source with countably infinite source alphabet and a general
channel with arbitrary abstract channel input/channel output alphabets, we
study the joint source-channel coding problem from the information-spectrum
point of view. First, we generalize Feinstein's lemma (direct part) and
Verdu-Han's lemma (converse part) so as to be applicable to the general joint
source-channel coding problem. Based on these lemmas, we establish a sufficient
condition as well as a necessary condition for the source to be reliably
transmissible over the channel with asymptotically vanishing probability of
error. It is shown that our sufficient condition is equivalent to the
sufficient condition derived by Vembu, Verdu and Steinberg, whereas our
necessary condition is shown to be stronger than or equivalent to the necessary
condition derived by them. It turns out, as a direct consequence, that
separation principle in a relevantly generalized sense holds for a wide class
of sources and channels, as was shown in a quite dfifferent manner by Vembu,
Verdu and Steinberg. It should also be remarked that a nice duality is found
between our necessary and sufficient conditions, whereas we cannot fully enjoy
such a duality between the necessary condition and the sufficient condition by
Vembu, Verdu and Steinberg. In addition, we demonstrate a sufficient condition
as well as a necessary condition for the epsilon-transmissibility. Finally, the
separation theorem of the traditional standard form is shown to hold for the
class of sources and channels that satisfy the semi-strong converse property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3037</identifier>
 <datestamp>2007-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3037</id><created>2007-12-18</created><authors><author><keyname>Das</keyname><forenames>Manik Lal</forenames></author></authors><title>Comments on &quot;Improved Efficient Remote User Authentication Schemes&quot;</title><categories>cs.CR</categories><journal-ref>International Journal of Network Security, Vol. 6, No. 3, pp.
  282-284, 2008</journal-ref><abstract>  Recently, Tian et al presented an article, in which they discussed some
security weaknesses of Yoon et al's scheme and subsequently proposed two
``improved'' schemes. In this paper, we show that the Tian et al's schemes are
insecure and vulnerable than the Yoon et al's scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3084</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3084</id><created>2007-12-18</created><authors><author><keyname>Das</keyname><forenames>Manik Lal</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author><author><keyname>Phatak</keyname><forenames>Deepak B</forenames></author></authors><title>Proxy Signature Scheme with Effective Revocation Using Bilinear Pairings</title><categories>cs.CR</categories><journal-ref>International Journal of Network Security, Vol. 4, No.3,
  pp.312-317, 2007</journal-ref><abstract>  We present a proxy signature scheme using bilinear pairings that provides
effective proxy revocation. The scheme uses a binding-blinding technique to
avoid secure channel requirements in the key issuance stage. With this
technique, the signer receives a partial private key from a trusted authority
and unblinds it to get his private key, in turn, overcomes the key escrow
problem which is a constraint in most of the pairing-based proxy signature
schemes. The scheme fulfills the necessary security requirements of proxy
signature and resists other possible threats.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3088</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3088</id><created>2007-12-19</created><updated>2012-09-07</updated><authors><author><keyname>Luo</keyname><forenames>Zhaohua</forenames></author></authors><title>Clones and Genoids in Lambda Calculus and First Order Logic</title><categories>cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A genoid is a category of two objects such that one is the product of itself
with the other. A genoid may be viewed as an abstract substitution algebra. It
is a remarkable fact that such a simple concept can be applied to present a
unified algebraic approach to lambda calculus and first order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3113</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3113</id><created>2007-12-19</created><authors><author><keyname>B&#xe9;k&#xe9;s</keyname><forenames>Andr&#xe1;s Gyorgy</forenames></author><author><keyname>Szeredi</keyname><forenames>P&#xe9;ter</forenames></author></authors><title>Optimizing Queries in a Logic-based Information Integration System</title><categories>cs.PL cs.SE</categories><comments>Paper presented at the 17th Workshop on Logic-based Methods in
  Programming Environments (WLPE2007)</comments><acm-class>D.2.6; D.1.6</acm-class><abstract>  The SINTAGMA information integration system is an infrastructure for
accessing several different information sources together. Besides providing a
uniform interface to the information sources (databases, web services, web
sites, RDF resources, XML files), semantic integration is also needed. Semantic
integration is carried out by providing a high-level model and the mappings to
the models of the sources. When executing a query of the high level model, a
query is transformed to a low-level query plan, which is a piece of Prolog code
that answers the high-level query. This transformation is done in two phases.
First, the Query Planner produces a plan as a logic formula expressing the
low-level query. Next, the Query Optimizer transforms this formula to
executable Prolog code and optimizes it according to structural and statistical
information about the information sources.
  This article discusses the main ideas of the optimization algorithm and its
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3115</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3115</id><created>2007-12-19</created><authors><author><keyname>Diertens</keyname><forenames>Bob</forenames></author></authors><title>Software (Re-)Engineering with PSF II: from architecture to
  implementation</title><categories>cs.SE</categories><report-no>prg0609</report-no><abstract>  This paper presents ongoing research on the application of PSF in the field
of software engineering and reengineering. We build a new implementation for
the simulator of the PSF Toolkit starting from the specification in PSF of the
architecture of a simple simulator and extend it with features to obtain the
architecture of a full simulator. We apply refining and constraining techniques
on the specification of the architecture to obtain a specification low enough
to build an implementation from.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3116</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3116</id><created>2007-12-19</created><authors><author><keyname>Hill</keyname><forenames>Patricia</forenames></author><author><keyname>Vanhoof</keyname><forenames>Wim</forenames></author></authors><title>Proceedings of the 17th Workshop on Logic-based methods in Programming
  Environments (WLPE 2007)</title><categories>cs.PL cs.SE</categories><acm-class>D.2.6; D.1.6</acm-class><abstract>  This volume contains the papers presented at WLPE 2007: the 17th Workshop on
Logic-based Methods in Programming Environments on 13th September, 2007 in
Porto, Portugal. It was held as a satellite workshop of ICLP 2007, the 23th
International Conference on Logic Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3128</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3128</id><created>2007-12-19</created><authors><author><keyname>Diertens</keyname><forenames>Bob</forenames></author></authors><title>Software (Re-)Engineering with PSF III: an IDE for PSF</title><categories>cs.SE</categories><report-no>prg0708</report-no><abstract>  We describe the design of an integrated development environment (IDE) for
PSF. In the software engineering process we used process algebra in the form of
PSF for the specification of the architecture of the IDE. This specification is
refined to a PSF specification of the IDE system as a ToolBus application, by
applying vertical and horizontal implementation techniques. We implemented the
various tools as specified and connected them with a ToolBus script extracted
from the system specification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3137</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3137</id><created>2007-12-19</created><authors><author><keyname>Lacasa</keyname><forenames>Lucas</forenames></author><author><keyname>Luque</keyname><forenames>Bartolo</forenames></author><author><keyname>Miramontes</keyname><forenames>Octavio</forenames></author></authors><title>Phase transition and computational complexity in a stochastic prime
  number generator</title><categories>cs.CC physics.comp-ph</categories><comments>Submitted to New Journal of Physics</comments><journal-ref>New Journal of Physics 10 (2008) 023009</journal-ref><doi>10.1088/1367-2630/10/2/023009</doi><abstract>  We introduce a prime number generator in the form of a stochastic algorithm.
The character of such algorithm gives rise to a continuous phase transition
which distinguishes a phase where the algorithm is able to reduce the whole
system of numbers into primes and a phase where the system reaches a frozen
state with low prime density. In this paper we firstly pretend to give a broad
characterization of this phase transition, both in terms of analytical and
numerical analysis. Critical exponents are calculated, and data collapse is
provided. Further on we redefine the model as a search problem, fitting it in
the hallmark of computational complexity theory. We suggest that the system
belongs to the class NP. The computational cost is maximal around the
threshold, as common in many algorithmic phase transitions, revealing the
presence of an easy-hard-easy pattern. We finally relate the nature of the
phase transition to an average-case classification of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3146</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3146</id><created>2007-12-19</created><authors><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author><author><keyname>Puiss&#xe9;gur</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LIP</affiliation></author></authors><title>Dynamic Logic of Common Knowledge in a Proof Assistant</title><categories>cs.GT</categories><comments>15 p</comments><proxy>ccsd ensl-00198782</proxy><abstract>  Common Knowledge Logic is meant to describe situations of the real world
where a group of agents is involved. These agents share knowledge and make
strong statements on the knowledge of the other agents (the so called
\emph{common knowledge}). But as we know, the real world changes and overall
information on what is known about the world changes as well. The changes are
described by dynamic logic. To describe knowledge changes, dynamic logic should
be combined with logic of common knowledge. In this paper we describe
experiments which we have made about the integration in a unique framework of
common knowledge logic and dynamic logic in the proof assistant \Coq. This
results in a set of fully checked proofs for readable statements. We describe
the framework and how a proof can be
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3147</identifier>
 <datestamp>2008-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3147</id><created>2007-12-19</created><updated>2008-01-15</updated><authors><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author></authors><title>Common knowledge logic in a higher order proof assistant?</title><categories>cs.AI cs.LO</categories><comments>11 p</comments><proxy>ccsd ensl-00199368</proxy><abstract>  This paper presents experiments on common knowledge logic, conducted with the
help of the proof assistant Coq. The main feature of common knowledge logic is
the eponymous modality that says that a group of agents shares a knowledge
about a certain proposition in a inductive way. This modality is specified by
using a fixpoint approach. Furthermore, from these experiments, we discuss and
compare the structure of theorems that can be proved in specific theories that
use common knowledge logic. Those structures manifests the interplay between
the theory (as implemented in the proof assistant Coq) and the metatheory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3150</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3150</id><created>2007-12-19</created><authors><author><keyname>Kamalian</keyname><forenames>Rafael R.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>Interval Colourings of Some Regular Graphs</title><categories>cs.DM</categories><comments>4 pages</comments><journal-ref>Mathematical Problems of Computer Science 25, 2006, 53--56</journal-ref><abstract>  A lower bound is obtained for the greatest possible number of colors in an
interval colourings of some regular graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3155</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3155</id><created>2007-12-19</created><updated>2007-12-28</updated><authors><author><keyname>Kamalian</keyname><forenames>Rafael R.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>On Interval Colorings of Complete k-partite Graphs K_{n}^{k}</title><categories>cs.DM</categories><comments>6 pages</comments><journal-ref>Mathematical Problems of Computer Science 26, 2006, 28--32</journal-ref><abstract>  Problems of existence, construction and estimation of parameters of interval
colorings of complete k-partite graphs K_{n}^{k} are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3203</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3203</id><created>2007-12-19</created><updated>2008-06-22</updated><authors><author><keyname>Wan</keyname><forenames>Changlin</forenames></author><author><keyname>Shi</keyname><forenames>Zhongzhi</forenames></author></authors><title>Solving Medium-Density Subset Sum Problems in Expected Polynomial Time:
  An Enumeration Approach</title><categories>cs.DS cs.CC cs.CR</categories><comments>11 pages, 1 figure</comments><acm-class>F.2.2; G.2.1; G.1.6; I.2.8; E.3</acm-class><journal-ref>Changlin Wan, Zhongzhi Shi: Solving Medium-Density Subset Sum
  Problems in Expected Polynomial Time: An Enumeration Approach. FAW 2008:
  300-310</journal-ref><doi>10.1007/978-3-540-69311-6_31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subset sum problem (SSP) can be briefly stated as: given a target integer
$E$ and a set $A$ containing $n$ positive integer $a_j$, find a subset of $A$
summing to $E$. The \textit{density} $d$ of an SSP instance is defined by the
ratio of $n$ to $m$, where $m$ is the logarithm of the largest integer within
$A$. Based on the structural and statistical properties of subset sums, we
present an improved enumeration scheme for SSP, and implement it as a complete
and exact algorithm (EnumPlus). The algorithm always equivalently reduces an
instance to be low-density, and then solve it by enumeration. Through this
approach, we show the possibility to design a sole algorithm that can
efficiently solve arbitrary density instance in a uniform way. Furthermore, our
algorithm has considerable performance advantage over previous algorithms.
Firstly, it extends the density scope, in which SSP can be solved in expected
polynomial time. Specifically, It solves SSP in expected $O(n\log{n})$ time
when density $d \geq c\cdot \sqrt{n}/\log{n}$, while the previously best
density scope is $d \geq c\cdot n/(\log{n})^{2}$. In addition, the overall
expected time and space requirement in the average case are proven to be
$O(n^5\log n)$ and $O(n^5)$ respectively. Secondly, in the worst case, it
slightly improves the previously best time complexity of exact algorithms for
SSP. Specifically, the worst-case time complexity of our algorithm is proved to
be $O((n-6)2^{n/2}+n)$, while the previously best result is $O(n2^{n/2})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3215</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3215</id><created>2007-12-19</created><authors><author><keyname>Sandoz-Guermond</keyname><forenames>Fran&#xe7;oise</forenames><affiliation>LIESP</affiliation></author><author><keyname>Bobiller-Chaumon</keyname><forenames>Marc-Eric</forenames><affiliation>GRePS</affiliation></author></authors><title>L'accessibilit\'e des E-services aux personnes non-voyantes :
  difficult\'es d'usage et recommandations</title><categories>cs.HC</categories><comments>4 pages</comments><proxy>ccsd hal-00196823</proxy><journal-ref>Dans International Conference Proceedings of IHM'2006 - IIHM :
  Interaction Homme Machine, Montr\'eal : Canada (2006)</journal-ref><abstract>  While taking into account handicapped people in the design of technologies
represents a social and political stake that becomes important (in particular
with the recent law on equal rights for all the citizens, March 2004), this
paper aims at evaluating the level of accessibility of two sites of E-services
thanks to tests of use and proposing a set of recommendations in order to
increase usability for the largest amount of people.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3220</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3220</id><created>2007-12-19</created><authors><author><keyname>Gurstein</keyname><forenames>Michael</forenames></author></authors><title>What is Community Informatics (and Why Does It Matter)?</title><categories>cs.CY</categories><comments>109 pages, ISBN 978-88-7699-097-7 (Printed edition), ISBN
  978-88-7699-098-4 (Electronic edition), printed edition available at
  http://www.amazon.com and on http://www.lulu.com</comments><journal-ref>&quot;Publishing studies&quot; book series, edited by Giandomenico Sica,
  ISSN 1973-6061 (Printed edition), ISSN 1973-6053 (Electronic edition)</journal-ref><abstract>  Community Informatics (CI) is the application of information and
communications technologies (ICTs) to enable community processes and the
achievement of community objectives. CI goes beyond the &quot;Digital Divide&quot; to
making ICT access usable and useful to excluded populations and communities for
local economic development, social justice, and political empowerment. CI
approaches ICTs from a &quot;community&quot; perspective and develops strategies and
techniques for managing their use by communities both virtual and physical
including the variety of Community Networking applications. CI assumes that
both communities have characteristics, requirements, and opportunities that
require different strategies for ICT intervention and development from
individual access and use. Also, CI addresses ICT use in Developing Countries
as well as among the poor, the marginalized, the elderly, or those living in
remote locations in Developed Countries. CI is of interest both to ICT
practitioners and academic researchers and addresses the connections between
the policy and pragmatic issues arising from the tens of thousands of Community
Networks, Community Technology Centres, Telecentres, Community Communications
Centres, and Telecottages globally along with the rapidly emerging field of
electronically based virtual &quot;communities&quot;.
  Michael Gurstein, Ph.D. is Executive Director of the Centre for Community
Informatics Research, Development and Training (Vancouver BC), a Director of
The Information Society Institute, Cape Peninsula University of Technology,
Cape Town South Africa; and Research Professor in the School of Computer and
Information Systems at the New Jersey Institute of Technology, Newark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3277</identifier>
 <datestamp>2007-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3277</id><created>2007-12-19</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>On the Capacity and Energy Efficiency of Training-Based Transmissions
  over Fading Channels</title><categories>cs.IT math.IT</categories><abstract>  In this paper, the capacity and energy efficiency of training-based
communication schemes employed for transmission over a-priori unknown Rayleigh
block fading channels are studied. In these schemes, periodically transmitted
training symbols are used at the receiver to obtain the minimum
mean-square-error (MMSE) estimate of the channel fading coefficients.
Initially, the case in which the product of the estimate error and transmitted
signal is assumed to be Gaussian noise is considered. In this case, it is shown
that bit energy requirements grow without bound as the signal-to-noise ratio
(SNR) goes to zero, and the minimum bit energy is achieved at a nonzero SNR
value below which one should not operate. The effect of the block length on
both the minimum bit energy and the SNR value at which the minimum is achieved
is investigated. Flash training and transmission schemes are analyzed and shown
to improve the energy efficiency in the low-SNR regime.
  In the second part of the paper, the capacity and energy efficiency of
training-based schemes are investigated when the channel input is subject to
peak power constraints. The capacity-achieving input structure is characterized
and the magnitude distribution of the optimal input is shown to be discrete
with a finite number of mass points. The capacity, bit energy requirements, and
optimal resource allocation strategies are obtained through numerical analysis.
The bit energy is again shown to grow without bound as SNR decreases to zero
due to the presence of peakedness constraints. The improvements in energy
efficiency when on-off keying with fixed peak power and vanishing duty cycle is
employed are studied. Comparisons of the performances of training-based and
noncoherent transmission schemes are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3286</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3286</id><created>2007-12-19</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Error Rate Analysis for Peaky Signaling over Fading Channels</title><categories>cs.IT math.IT</categories><abstract>  In this paper, the performance of signaling strategies with high
peak-to-average power ratio is analyzed over both coherent and noncoherent
fading channels. Two modulation schemes, namely on-off phase-shift keying
(OOPSK) and on-off frequency-shift keying (OOFSK), are considered. Initially,
uncoded systems are analyzed. For OOPSK and OOFSK, the optimal detector
structures are identified and analytical expressions for the error
probabilities are obtained for arbitrary constellation sizes. Numerical
techniques are employed to compute the error probabilities. It is concluded
that increasing the peakedness of the signals results in reduced error rates
for a given power level and hence equivalently improves the energy efficiency
for fixed error probabilities. The coded performance is also studied by
analyzing the random coding error exponents achieved by OOPSK and OOFSK
signaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3298</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3298</id><created>2007-12-19</created><authors><author><keyname>Radev</keyname><forenames>Dragomir</forenames></author><author><keyname>Hodges</keyname><forenames>Mark</forenames></author><author><keyname>Fader</keyname><forenames>Anthony</forenames></author><author><keyname>Joseph</keyname><forenames>Mark</forenames></author><author><keyname>Gerrish</keyname><forenames>Joshua</forenames></author><author><keyname>Schaller</keyname><forenames>Mark</forenames></author><author><keyname>dePeri</keyname><forenames>Jonathan</forenames></author><author><keyname>Gibson</keyname><forenames>Bryan</forenames></author></authors><title>CLAIRLIB Documentation v1.03</title><categories>cs.IR cs.CL</categories><comments>for download and additional information, please see
  http://www.clairlib.org</comments><report-no>CSE-TR-536-07</report-no><acm-class>H.3.3; I.2.7</acm-class><abstract>  The Clair library is intended to simplify a number of generic tasks in
Natural Language Processing (NLP), Information Retrieval (IR), and Network
Analysis. Its architecture also allows for external software to be plugged in
with very little effort. Functionality native to Clairlib includes
Tokenization, Summarization, LexRank, Biased LexRank, Document Clustering,
Document Indexing, PageRank, Biased PageRank, Web Graph Analysis, Network
Generation, Power Law Distribution Analysis, Network Analysis (clustering
coefficient, degree distribution plotting, average shortest path, diameter,
triangles, shortest path matrices, connected components), Cosine Similarity,
Random Walks on Graphs, Statistics (distributions, tests), Tf, Idf, Community
Finding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3299</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3299</id><created>2007-12-19</created><authors><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Computer- and robot-assisted urological surgery</title><categories>cs.OH cs.RO</categories><proxy>ccsd hal-00195030</proxy><journal-ref>Progr\`es en urologie : journal de l'Association fran\c{c}aise
  d'urologie et de la Soci\'et\'e fran\c{c}aise d'urologie 16, 2 (2006) 112-20</journal-ref><abstract>  The author reviews the computer and robotic tools available to urologists to
help in diagnosis and technical procedures. The first part concerns the
contribution of robotics and presents several systems at various stages of
development (laboratory prototypes, systems under validation or marketed
systems). The second part describes image fusion tools and navigation systems
currently under development or evaluation. Several studies on computerized
simulation of urological procedures are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3327</identifier>
 <datestamp>2008-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3327</id><created>2007-12-19</created><updated>2008-01-09</updated><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>The capacity of a class of 3-receiver broadcast channels with degraded
  message sets</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE transactions on Information Theory</comments><abstract>  Korner and Marton established the capacity region for the 2-receiver
broadcast channel with degraded message sets. Recent results and conjectures
suggest that a straightforward extension of the Korner-Marton region to more
than 2 receivers is optimal. This paper shows that this is not the case. We
establish the capacity region for a class of 3-receiver broadcast channels with
2 degraded message sets and show that it can be strictly larger than the
straightforward extension of the Korner-Marton region. The key new idea is
indirect decoding, whereby a receiver who cannot directly decode a cloud
center, finds it indirectly by decoding satellite codewords. This idea is then
used to establish new inner and outer bounds on the capacity region of the
general 3-receiver broadcast channel with 2 and 3 degraded message sets. We
show that these bounds are tight for some nontrivial cases. The results suggest
that the capacity of the 3-receiver broadcast channel with degraded message
sets is as at least as hard to find as the capacity of the general 2-receiver
broadcast channel with common and private message.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3329</identifier>
 <datestamp>2008-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3329</id><created>2007-12-20</created><authors><author><keyname>Legg</keyname><forenames>Shane</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Universal Intelligence: A Definition of Machine Intelligence</title><categories>cs.AI</categories><comments>50 gentle pages</comments><report-no>IDSIA-10-07</report-no><journal-ref>Minds &amp; Machines, 17:4 (2007) pages 391-444</journal-ref><abstract>  A fundamental problem in artificial intelligence is that nobody really knows
what intelligence is. The problem is especially acute when we need to consider
artificial systems which are significantly different to humans. In this paper
we approach this problem in the following way: We take a number of well known
informal definitions of human intelligence that have been given by experts, and
extract their essential features. These are then mathematically formalised to
produce a general measure of intelligence for arbitrary machines. We believe
that this equation formally captures the concept of machine intelligence in the
broadest reasonable sense. We then show how this formal definition is related
to the theory of universal optimal learning agents. Finally, we survey the many
other tests and definitions of intelligence that have been proposed for
machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3331</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3331</id><created>2007-12-20</created><updated>2007-12-27</updated><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Talwar</keyname><forenames>Kunal</forenames></author></authors><title>How to Complete a Doubling Metric</title><categories>cs.DM cs.CG</categories><comments>An extended abstract will appear in proceedings of LATIN 2008</comments><abstract>  In recent years, considerable advances have been made in the study of
properties of metric spaces in terms of their doubling dimension. This line of
research has not only enhanced our understanding of finite metrics, but has
also resulted in many algorithmic applications. However, we still do not
understand the interaction between various graph-theoretic (topological)
properties of graphs, and the doubling (geometric) properties of the
shortest-path metrics induced by them. For instance, the following natural
question suggests itself: \emph{given a finite doubling metric $(V,d)$, is
there always an \underline{unweighted} graph $(V',E')$ with $V\subseteq V'$
such that the shortest path metric $d'$ on $V'$ is still doubling, and which
agrees with $d$ on $V$.} This is often useful, given that unweighted graphs are
often easier to reason about.
  We show that for any metric space $(V,d)$, there is an \emph{unweighted}
graph $(V',E')$ with shortest-path metric $d':V'\times V' \to \R_{\geq 0}$ such
that
  -- for all $x,y \in V$, the distances $d(x,y) \leq d'(x,y) \leq (1+\eps)
\cdot d(x,y)$, and
  -- the doubling dimension for $d'$ is not much more than that of $d$, where
this change depends only on $\e$ and not on the size of the graph.
  We show a similar result when both $(V,d)$ and $(V',E')$ are restricted to be
trees: this gives a simpler proof that doubling trees embed into constant
dimensional Euclidean space with constant distortion. We also show that our
results are tight in terms of the tradeoff between distortion and dimension
blowup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3333</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3333</id><created>2007-12-20</created><authors><author><keyname>Han</keyname><forenames>Qiaoming</forenames></author><author><keyname>Punnen</keyname><forenames>Abraham P.</forenames></author></authors><title>On the approximability of the vertex cover and related problems</title><categories>cs.DS cs.DM</categories><acm-class>F.2; G.2.2; G.1.6</acm-class><abstract>  In this paper we show that the problem of identifying an edge $(i,j)$ in a
graph $G$ such that there exists an optimal vertex cover $S$ of $G$ containing
exactly one of the nodes $i$ and $j$ is NP-hard. Such an edge is called a weak
edge. We then develop a polynomial time approximation algorithm for the vertex
cover problem with performance guarantee $2-\frac{1}{1+\sigma}$, where $\sigma$
is an upper bound on a measure related to a weak edge of a graph. Further, we
discuss a new relaxation of the vertex cover problem which is used in our
approximation algorithm to obtain smaller values of $\sigma$. We also obtain
linear programming representations of the vertex cover problem for special
graphs. Our results provide new insights into the approximability of the vertex
cover problem - a long standing open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3335</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3335</id><created>2007-12-20</created><authors><author><keyname>Han</keyname><forenames>Qiaoming</forenames></author><author><keyname>Punnen</keyname><forenames>Abraham P.</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>A polynomial time $\frac 3 2$ -approximation algorithm for the vertex
  cover problem on a class of graphs</title><categories>cs.DS cs.DM</categories><acm-class>F.2; G.2.2; G.1.6</acm-class><abstract>  We develop a polynomial time 3/2-approximation algorithm to solve the vertex
cover problem on a class of graphs satisfying a property called ``active edge
hypothesis''. The algorithm also guarantees an optimal solution on specially
structured graphs. Further, we give an extended algorithm which guarantees a
vertex cover $S_1$ on an arbitrary graph such that $|S_1|\leq {3/2} |S^*|+\xi$
where $S^*$ is an optimal vertex cover and $\xi$ is an error bound identified
by the algorithm. We obtained $\xi = 0$ for all the test problems we have
considered which include specially constructed instances that were expected to
be hard. So far we could not construct a graph that gives $\xi \not= 0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3348</identifier>
 <datestamp>2007-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3348</id><created>2007-12-20</created><updated>2007-12-25</updated><authors><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Tian</forenames></author></authors><title>On Exponential Time Lower Bound of Knapsack under Backtracking</title><categories>cs.CC</categories><comments>This paper supersedes the result of arXiv:cs/0606064</comments><abstract>  M.Aleknovich et al. have recently proposed a model of algorithms, called BT
model, which generalizes both the priority model of Borodin, Nielson and
Rackoff, as well as a simple dynamic programming model by Woeginger. BT model
can be further divided into three kinds of fixed, adaptive and fully adaptive
ones. They have proved exponential time lower bounds of exact and approximation
algorithms under adaptive BT model for Knapsack problem. Their exact lower
bound is $\Omega(2^{0.5n}/\sqrt{n})$, in this paper, we slightly improve the
exact lower bound to about $\Omega(2^{0.69n}/\sqrt{n})$, by the same technique,
with related parameters optimized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3360</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3360</id><created>2007-12-20</created><authors><author><keyname>Ferragina</keyname><forenames>Paolo</forenames><affiliation>Dept. of Computer Science, University of Pisa</affiliation></author><author><keyname>Gonzalez</keyname><forenames>Rodrigo</forenames><affiliation>Dept. of Computer Science, University of Chile</affiliation></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames><affiliation>Dept. of Computer Science, University of Chile</affiliation></author><author><keyname>Venturini</keyname><forenames>Rossano</forenames><affiliation>Dept. of Computer Science, University of Chile</affiliation></author></authors><title>Compressed Text Indexes:From Theory to Practice!</title><categories>cs.DS</categories><acm-class>F.2.2; H.2.1; H.3.2; H.3.3</acm-class><abstract>  A compressed full-text self-index represents a text in a compressed form and
still answers queries efficiently. This technology represents a breakthrough
over the text indexing techniques of the previous decade, whose indexes
required several times the size of the text. Although it is relatively new,
this technology has matured up to a point where theoretical research is giving
way to practical developments. Nonetheless this requires significant
programming skills, a deep engineering effort, and a strong algorithmic
background to dig into the research results. To date only isolated
implementations and focused comparisons of compressed indexes have been
reported, and they missed a common API, which prevented their re-use or
deployment within other applications.
  The goal of this paper is to fill this gap. First, we present the existing
implementations of compressed indexes from a practitioner's point of view.
Second, we introduce the Pizza&amp;Chili site, which offers tuned implementations
and a standardized API for the most successful compressed full-text
self-indexes, together with effective testbeds and scripts for their automatic
validation and test. Third, we show the results of our extensive experiments on
these codes with the aim of demonstrating the practical relevance of this novel
and exciting technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3380</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3380</id><created>2007-12-20</created><authors><author><keyname>Brijder</keyname><forenames>Robert</forenames></author><author><keyname>Hoogeboom</keyname><forenames>Hendrik Jan</forenames></author></authors><title>Extending the Overlap Graph for Gene Assembly in Ciliates</title><categories>cs.LO</categories><comments>12 pages, 9 figures</comments><report-no>LIACS Technical Report 2007-05</report-no><abstract>  Gene assembly is an intricate biological process that has been studied
formally and modeled through string and graph rewriting systems. Recently, a
restriction of the general (intramolecular) model, called simple gene assembly,
has been introduced. This restriction has subsequently been defined as a string
rewriting system. We show that by extending the notion of overlap graph it is
possible to define a graph rewriting system for two of the three types of rules
that make up simple gene assembly. It turns out that this graph rewriting
system is less involved than its corresponding string rewriting system.
Finally, we give characterizations of the `power' of both types of graph
rewriting rules. Because of the equivalence of these string and graph rewriting
systems, the given characterizations can be carried over to the string
rewriting system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3389</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3389</id><created>2007-12-20</created><authors><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Stengel</keyname><forenames>Holger</forenames></author><author><keyname>Zeiser</keyname><forenames>Thomas</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>RZBENCH: Performance evaluation of current HPC architectures using
  low-level and application benchmarks</title><categories>cs.DC cs.PF</categories><comments>Contribution to the HLRB/KONWIHR results and review workshop, Dec
  3rd/4th 2007, LRZ Munich, Germany</comments><abstract>  RZBENCH is a benchmark suite that was specifically developed to reflect the
requirements of scientific supercomputer users at the University of
Erlangen-Nuremberg (FAU). It comprises a number of application and low-level
codes under a common build infrastructure that fosters maintainability and
expandability. This paper reviews the structure of the suite and briefly
introduces the most relevant benchmarks. In addition, some widely known
standard benchmark codes are reviewed in order to emphasize the need for a
critical review of often-cited performance results. Benchmark data is presented
for the HLRB-II at LRZ Munich and a local InfiniBand Woodcrest cluster as well
as two uncommon system architectures: A bandwidth-optimized InfiniBand cluster
based on single socket nodes (&quot;Port Townsend&quot;) and an early version of Sun's
highly threaded T2 architecture (&quot;Niagara 2&quot;).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3402</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3402</id><created>2007-12-20</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>WILLOW Project - Inria/Ens</affiliation></author></authors><title>Graph kernels between point clouds</title><categories>cs.LG</categories><proxy>ccsd hal-00200109</proxy><abstract>  Point clouds are sets of points in two or three dimensions. Most kernel
methods for learning on sets of points have not yet dealt with the specific
geometrical invariances and practical constraints associated with point clouds
in computer vision and graphics. In this paper, we present extensions of graph
kernels for point clouds, which allow to use kernel methods for such ob jects
as shapes, line drawings, or any three-dimensional point clouds. In order to
design rich and numerically efficient kernels with as few free parameters as
possible, we use kernels between covariance matrices and their factorizations
on graphical models. We derive polynomial time dynamic programming recursions
and present applications to recognition of handwritten digits and Chinese
characters from few training examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3423</identifier>
 <datestamp>2009-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3423</id><created>2007-12-20</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Ponse</keyname><forenames>A.</forenames></author><author><keyname>van der Zwaag</keyname><forenames>M. B.</forenames></author></authors><title>Tuplix Calculus</title><categories>cs.LO cs.CE</categories><comments>22 pages</comments><report-no>PRG0713</report-no><journal-ref>Scientific Annals of Computer Science, 18:35--61, 2008</journal-ref><abstract>  We introduce a calculus for tuplices, which are expressions that generalize
matrices and vectors. Tuplices have an underlying data type for quantities that
are taken from a zero-totalized field. We start with the core tuplix calculus
CTC for entries and tests, which are combined using conjunctive composition. We
define a standard model and prove that CTC is relatively complete with respect
to it. The core calculus is extended with operators for choice, information
hiding, scalar multiplication, clearing and encapsulation. We provide two
examples of applications; one on incremental financial budgeting, and one on
modular financial budget design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3433</identifier>
 <datestamp>2007-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3433</id><created>2007-12-19</created><authors><author><keyname>Zaliva</keyname><forenames>Vadim</forenames></author></authors><title>AccelKey Selection Method for Mobile Devices</title><categories>cs.HC</categories><comments>15 pages, 12 figures</comments><acm-class>H.5.2</acm-class><abstract>  Portable Electronic Devices usually utilize a small screen with limited
viewing area and a keyboard with a limited number of keys. This makes it
difficult to perform quick searches in data arrays containing more than dozen
items such an address book or song list. In this article we present a new data
selection method which allows the user to quickly select an entry from a list
using 4-way navigation device such as joystick, trackball or 4-way key pad.
This method allows for quick navigation using just one hand, without looking at
the screen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3501</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3501</id><created>2007-12-20</created><updated>2009-06-24</updated><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>The Impact of Hard-Decision Detection on the Energy Efficiency of Phase
  and Frequency Modulation</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The central design challenge in next generation wireless systems is to have
these systems operate at high bandwidths and provide high data rates while
being cognizant of the energy consumption levels especially in mobile
applications. Since communicating at very high data rates prohibits obtaining
high bit resolutions from the analog-to-digital (A/D) converters, analysis of
the energy efficiency under the assumption of hard-decision detection is called
for to accurately predict the performance levels. In this paper, transmission
over the additive white Gaussian noise (AWGN) channel, and coherent and
noncoherent fading channels is considered, and the impact of hard-decision
detection on the energy efficiency of phase and frequency modulations is
investigated. Energy efficiency is analyzed by studying the capacity of these
modulation schemes and the energy required to send one bit of information
reliably in the low signal-to-noise ratio (SNR) regime. The capacity of
hard-decision-detected phase and frequency modulations is characterized at low
SNR levels through closed-form expressions for the first and second derivatives
of the capacity at zero SNR. Subsequently, bit energy requirements in the
low-SNR regime are identified. The increases in the bit energy incurred by
hard-decision detection and channel fading are quantified. Moreover, practical
design guidelines for the selection of the constellation size are drawn from
the analysis of the spectral efficiency--bit energy tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3568</identifier>
 <datestamp>2007-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3568</id><created>2007-12-20</created><authors><author><keyname>Konemann</keyname><forenames>Jochen</forenames></author><author><keyname>Pritchard</keyname><forenames>David</forenames></author><author><keyname>Tan</keyname><forenames>Kunlun</forenames></author></authors><title>A Partition-Based Relaxation For Steiner Trees</title><categories>cs.DS</categories><comments>Submitted to Math. Prog</comments><abstract>  The Steiner tree problem is a classical NP-hard optimization problem with a
wide range of practical applications. In an instance of this problem, we are
given an undirected graph G=(V,E), a set of terminals R, and non-negative costs
c_e for all edges e in E. Any tree that contains all terminals is called a
Steiner tree; the goal is to find a minimum-cost Steiner tree. The nodes V R
are called Steiner nodes.
  The best approximation algorithm known for the Steiner tree problem is due to
Robins and Zelikovsky (SIAM J. Discrete Math, 2005); their greedy algorithm
achieves a performance guarantee of 1+(ln 3)/2 ~ 1.55. The best known linear
(LP)-based algorithm, on the other hand, is due to Goemans and Bertsimas (Math.
Programming, 1993) and achieves an approximation ratio of 2-2/|R|. In this
paper we establish a link between greedy and LP-based approaches by showing
that Robins and Zelikovsky's algorithm has a natural primal-dual interpretation
with respect to a novel partition-based linear programming relaxation. We also
exhibit surprising connections between the new formulation and existing LPs and
we show that the new LP is stronger than the bidirected cut formulation.
  An instance is b-quasi-bipartite if each connected component of G R has at
most b vertices. We show that Robins' and Zelikovsky's algorithm has an
approximation ratio better than 1+(ln 3)/2 for such instances, and we prove
that the integrality gap of our LP is between 8/7 and (2b+1)/(b+1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3576</identifier>
 <datestamp>2007-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3576</id><created>2007-12-21</created><authors><author><keyname>Rost</keyname><forenames>P.</forenames></author><author><keyname>Fettweis</keyname><forenames>G.</forenames></author></authors><title>Protocols For Half-Duplex Multiple Relay Networks</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE ISIT 2008</comments><acm-class>E.4</acm-class><abstract>  In this paper we present several strategies for multiple relay networks which
are constrained by a half-duplex operation, i. e., each node either transmits
or receives on a particular resource. Using the discrete memoryless multiple
relay channel we present achievable rates for a multilevel partial
decode-and-forward approach which generalizes previous results presented by
Kramer and Khojastepour et al.. Furthermore, we derive a compress-and-forward
approach using a regular encoding scheme which simplifies the encoding and
decoding scheme and improves the achievable rates in general. Finally, we give
achievable rates for a mixed strategy used in a four-terminal network with
alternately transmitting relay nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3587</identifier>
 <datestamp>2007-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3587</id><created>2007-12-20</created><authors><author><keyname>Lai</keyname><forenames>Po-Hsiang</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Joseph A.</forenames></author></authors><title>Pattern Recognition System Design with Linear Encoding for Discrete
  Patterns</title><categories>cs.IT cs.CV math.IT</categories><comments>Submitted and accepted to ISIT 2007</comments><abstract>  In this paper, designs and analyses of compressive recognition systems are
discussed, and also a method of establishing a dual connection between designs
of good communication codes and designs of recognition systems is presented.
Pattern recognition systems based on compressed patterns and compressed sensor
measurements can be designed using low-density matrices. We examine truncation
encoding where a subset of the patterns and measurements are stored perfectly
while the rest is discarded. We also examine the use of LDPC parity check
matrices for compressing measurements and patterns. We show how more general
ensembles of good linear codes can be used as the basis for pattern recognition
system design, yielding system design strategies for more general noise models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3617</identifier>
 <datestamp>2008-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3617</id><created>2007-12-20</created><updated>2008-09-20</updated><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Yang</keyname><forenames>Bo</forenames></author></authors><title>A Unified Framework for Pricing Credit and Equity Derivatives</title><categories>cs.CE</categories><comments>Keywords: Credit Default Swap, Defaultable Bond, Defaultable Stock,
  Equity Options, Stochastic Interest Rate, Implied Volatility, Multiscale
  Perturbation Method</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model which can be jointly calibrated to the corporate bond term
structure and equity option volatility surface of the same company. Our purpose
is to obtain explicit bond and equity option pricing formulas that can be
calibrated to find a risk neutral model that matches a set of observed market
prices. This risk neutral model can then be used to price more exotic, illiquid
or over-the-counter derivatives. We observe that the model implied credit
default swap (CDS) spread matches the market CDS spread and that our model
produces a very desirable CDS spread term structure. This is observation is
worth noticing since without calibrating any parameter to the CDS spread data,
it is matched by the CDS spread that our model generates using the available
information from the equity options and corporate bond markets. We also observe
that our model matches the equity option implied volatility surface well since
we properly account for the default risk premium in the implied volatility
surface. We demonstrate the importance of accounting for the default risk and
stochastic interest rate in equity option pricing by comparing our results to
Fouque, Papanicolaou, Sircar and Solna (2003), which only accounts for
stochastic volatility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3641</identifier>
 <datestamp>2007-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3641</id><created>2007-12-21</created><authors><author><keyname>Ding</keyname><forenames>Dawei</forenames></author><author><keyname>Zhu</keyname><forenames>Jie</forenames></author><author><keyname>Luo</keyname><forenames>Xiaoshu</forenames></author><author><keyname>Liu</keyname><forenames>Yuliang</forenames></author></authors><title>Controlling Delay-induced Hopf bifurcation in Internet congestion
  control system</title><categories>cs.NI</categories><comments>20 pages, 8 figures</comments><abstract>  This paper focuses on Hopf bifurcation control in a dual model of Internet
congestion control algorithms which is modeled as a delay differential equation
(DDE). By choosing communication delay as a bifurcation parameter, it has been
demonstrated that the system loses stability and a Hopf bifurcation occurs when
communication delay passes through a critical value. Therefore, a time-delayed
feedback control method is applied to the system for delaying the onset of
undesirable Hopf bifurcation. Theoretical analysis and numerical simulations
confirm that the delayed feedback controller is efficient in controlling Hopf
bifurcation in Internet congestion control system. Moreover, the direction of
the Hopf bifurcation and the stability of the bifurcating periodic solutions
are determinated by applying the center manifold theorem and the normal form
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3654</identifier>
 <datestamp>2007-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3654</id><created>2007-12-21</created><authors><author><keyname>De Lara</keyname><forenames>Alejandro Chinea Manrique</forenames></author><author><keyname>Moreno</keyname><forenames>Juan Manuel</forenames></author><author><keyname>Madrenas</keyname><forenames>Arostegui Jordi</forenames></author><author><keyname>Cabestany</keyname><forenames>Joan</forenames></author></authors><title>Improving the Performance of PieceWise Linear Separation Incremental
  Algorithms for Practical Hardware Implementations</title><categories>cs.NE cs.AI cs.LG</categories><comments>10 pages, 1 figure, 3 tables</comments><journal-ref>Biological and Artificial Computation: From Neuroscience to
  Technology, J.Mira, R.Moreno-Diaz, J.Cabestany (eds.), pp. 607-616,
  Springer-Verlag, 1997</journal-ref><abstract>  In this paper we shall review the common problems associated with Piecewise
Linear Separation incremental algorithms. This kind of neural models yield poor
performances when dealing with some classification problems, due to the
evolving schemes used to construct the resulting networks. So as to avoid this
undesirable behavior we shall propose a modification criterion. It is based
upon the definition of a function which will provide information about the
quality of the network growth process during the learning phase. This function
is evaluated periodically as the network structure evolves, and will permit, as
we shall show through exhaustive benchmarks, to considerably improve the
performance(measured in terms of network complexity and generalization
capabilities) offered by the networks generated by these incremental models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3705</identifier>
 <datestamp>2007-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3705</id><created>2007-12-21</created><authors><author><keyname>Kakkonen</keyname><forenames>Tuomo</forenames></author></authors><title>Framework and Resources for Natural Language Parser Evaluation</title><categories>cs.CL</categories><comments>PhD dissertation. 264 pages</comments><report-no>University of Joensuu, Computer Science Dissertations 19</report-no><acm-class>I.2.7; F.4.2</acm-class><abstract>  Because of the wide variety of contemporary practices used in the automatic
syntactic parsing of natural languages, it has become necessary to analyze and
evaluate the strengths and weaknesses of different approaches. This research is
all the more necessary because there are currently no genre- and
domain-independent parsers that are able to analyze unrestricted text with 100%
preciseness (I use this term to refer to the correctness of analyses assigned
by a parser). All these factors create a need for methods and resources that
can be used to evaluate and compare parsing systems. This research describes:
(1) A theoretical analysis of current achievements in parsing and parser
evaluation. (2) A framework (called FEPa) that can be used to carry out
practical parser evaluations and comparisons. (3) A set of new evaluation
resources: FiEval is a Finnish treebank under construction, and MGTS and RobSet
are parser evaluation resources in English. (4) The results of experiments in
which the developed evaluation framework and the two resources for English were
used for evaluating a set of selected parsers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3757</identifier>
 <datestamp>2007-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3757</id><created>2007-12-21</created><authors><author><keyname>Helleseth</keyname><forenames>Tor</forenames></author><author><keyname>Kholosha</keyname><forenames>Alexander</forenames></author><author><keyname>Johanssen</keyname><forenames>Aina</forenames></author></authors><title>$m$-Sequences of Different Lengths with Four-Valued Cross Correlation</title><categories>cs.DM cs.CR</categories><comments>26 pages</comments><abstract>  {\bf Abstract.} Considered is the distribution of the cross correlation
between $m$-sequences of length $2^m-1$, where $m$ is even, and $m$-sequences
of shorter length $2^{m/2}-1$. The infinite family of pairs of $m$-sequences
with four-valued cross correlation is constructed and the complete correlation
distribution of this family is determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3807</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3807</id><created>2007-12-26</created><updated>2009-10-14</updated><authors><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author><author><keyname>Guo</keyname><forenames>Qiang</forenames></author></authors><title>Improved Collaborative Filtering Algorithm via Information
  Transformation</title><categories>cs.LG cs.CY</categories><comments>5 pages, 4 figures</comments><journal-ref>Int. J. Mod. Phys. C 20(2), 285-293 (2009)</journal-ref><doi>10.1142/S0129183109013613</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a spreading activation approach for collaborative
filtering (SA-CF). By using the opinion spreading process, the similarity
between any users can be obtained. The algorithm has remarkably higher accuracy
than the standard collaborative filtering (CF) using Pearson correlation.
Furthermore, we introduce a free parameter $\beta$ to regulate the
contributions of objects to user-user correlations. The numerical results
indicate that decreasing the influence of popular objects can further improve
the algorithmic accuracy and personality. We argue that a better algorithm
should simultaneously require less computation and generate higher accuracy.
Accordingly, we further propose an algorithm involving only the top-$N$ similar
neighbors for each target user, which has both less computational complexity
and higher algorithmic accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3823</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3823</id><created>2007-12-21</created><updated>2008-07-03</updated><authors><author><keyname>Leverrier</keyname><forenames>Anthony</forenames></author><author><keyname>All&#xe9;aume</keyname><forenames>Romain</forenames></author><author><keyname>Boutros</keyname><forenames>Joseph</forenames></author><author><keyname>Z&#xe9;mor</keyname><forenames>Gilles</forenames></author><author><keyname>Grangier</keyname><forenames>Philippe</forenames></author></authors><title>Multidimensional reconciliation for continuous-variable quantum key
  distribution</title><categories>quant-ph cs.IT math.IT</categories><comments>8 pages, 3 figures</comments><journal-ref>Phys. Rev. A 77, 042325 (2008)</journal-ref><doi>10.1103/PhysRevA.77.042325</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for extracting an errorless secret key in a
continuous-variable quantum key distribution protocol, which is based on
Gaussian modulation of coherent states and homodyne detection. The crucial
feature is an eight-dimensional reconciliation method, based on the algebraic
properties of octonions. Since the protocol does not use any postselection, it
can be proven secure against arbitrary collective attacks, by using
well-established theorems on the optimality of Gaussian attacks. By using this
new coding scheme with an appropriate signal to noise ratio, the distance for
secure continuous-variable quantum key distribution can be significantly
extended.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3825</identifier>
 <datestamp>2008-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3825</id><created>2007-12-21</created><authors><author><keyname>Legg</keyname><forenames>Shane</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Tests of Machine Intelligence</title><categories>cs.AI</categories><comments>12 pages; 1 table. Turing test and derivatives; Compression tests;
  Linguistic complexity; Multiple cognitive abilities; Competitive games;
  Psychometric tests; Smith's test; C-test; Universal intelligence</comments><report-no>IDSIA-11-07</report-no><journal-ref>50 Years of Artificial Intelligence (2007) pages 232-242</journal-ref><abstract>  Although the definition and measurement of intelligence is clearly of
fundamental importance to the field of artificial intelligence, no general
survey of definitions and tests of machine intelligence exists. Indeed few
researchers are even aware of alternatives to the Turing test and its many
derivatives. In this paper we fill this gap by providing a short survey of the
many tests of machine intelligence that have been proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3829</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3829</id><created>2007-12-21</created><updated>2010-01-03</updated><authors><author><keyname>Inui</keyname><forenames>Yoshifumi</forenames></author><author><keyname>Gall</keyname><forenames>Francois Le</forenames></author></authors><title>Quantum Property Testing of Group Solvability</title><categories>quant-ph cs.DS</categories><comments>11 pages; supersedes arXiv:quant-ph/0610013</comments><journal-ref>Algorithmica 59(1): 35-47 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Testing efficiently whether a finite set with a binary operation over it,
given as an oracle, is a group is a well-known open problem in the field of
property testing. Recently, Friedl, Ivanyos and Santha have made a significant
step in the direction of solving this problem by showing that it it possible to
test efficiently whether the input is an Abelian group or is far, with respect
to some distance, from any Abelian group. In this paper, we make a step further
and construct an efficient quantum algorithm that tests whether the input is a
solvable group, or is far from any solvable group. More precisely, the number
of queries used by our algorithm is polylogarithmic in the size of the set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3830</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3830</id><created>2007-12-26</created><authors><author><keyname>Schrijvers</keyname><forenames>Tom</forenames></author><author><keyname>Demoen</keyname><forenames>Bart</forenames></author><author><keyname>Warren</keyname><forenames>David S.</forenames></author></authors><title>TCHR: a framework for tabled CLP</title><categories>cs.PL</categories><comments>Accepted for publication in Theory and Practice of Logic Programming</comments><abstract>  Tabled Constraint Logic Programming is a powerful execution mechanism for
dealing with Constraint Logic Programming without worrying about fixpoint
computation. Various applications, e.g in the fields of program analysis and
model checking, have been proposed. Unfortunately, a high-level system for
developing new applications is lacking, and programmers are forced to resort to
complicated ad hoc solutions.
  This papers presents TCHR, a high-level framework for tabled Constraint Logic
Programming. It integrates in a light-weight manner Constraint Handling Rules
(CHR), a high-level language for constraint solvers, with tabled Logic
Programming. The framework is easily instantiated with new application-specific
constraint domains. Various high-level operations can be instantiated to
control performance. In particular, we propose a novel, generalized technique
for compacting answer sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3831</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3831</id><created>2007-12-22</created><authors><author><keyname>Ding</keyname><forenames>Dawei</forenames></author><author><keyname>Zhu</keyname><forenames>Jie</forenames></author><author><keyname>Luo</keyname><forenames>Xiaoshu</forenames></author><author><keyname>Liu</keyname><forenames>Yuliang</forenames></author></authors><title>Hopf bifurcation analysis in a dual model of Internet congestion control
  algorithm with communication delay</title><categories>cs.NI</categories><comments>18 pages, 6 figures</comments><abstract>  This paper focuses on the delay induced Hopf bifurcation in a dual model of
Internet congestion control algorithms which can be modeled as a time-delay
system described by a one-order delay differential equation (DDE). By choosing
communication delay as the bifurcation parameter, we demonstrate that the
system loses its stability and a Hopf bifurcation occurs when communication
delay passes through a critical value. Moreover, the bifurcating periodic
solution of system is calculated by means of perturbation methods. Discussion
of stability of the periodic solutions involves the computation of Floquet
exponents by considering the corresponding Poincare -Lindstedt series
expansion. Finally, numerical simulations for verify the theoretical analysis
are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3858</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3858</id><created>2007-12-22</created><authors><author><keyname>Punnen</keyname><forenames>Abraham P.</forenames></author><author><keyname>Zhang</keyname><forenames>Ruonan</forenames></author></authors><title>Bottleneck flows in networks</title><categories>cs.DS</categories><abstract>  The bottleneck network flow problem (BNFP) is a generalization of several
well-studied bottleneck problems such as the bottleneck transportation problem
(BTP), bottleneck assignment problem (BAP), bottleneck path problem (BPP), and
so on. In this paper we provide a review of important results on this topic and
its various special cases. We observe that the BNFP can be solved as a sequence
of $O(\log n)$ maximum flow problems. However, special augmenting path based
algorithms for the maximum flow problem can be modified to obtain algorithms
for the BNFP with the property that these variations and the corresponding
maximum flow algorithms have identical worst case time complexity. On unit
capacity network we show that BNFP can be solved in $O(\min \{{m(n\log
n)}^{{2/3}}, m^{{3/2}}\sqrt{\log n}\})$. This improves the best available
algorithm by a factor of $\sqrt{\log n}$. On unit capacity simple graphs, we
show that BNFP can be solved in $O(m \sqrt {n \log n})$ time. As a consequence
we have an $O(m \sqrt {n \log n})$ algorithm for the BTP with unit arc
capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3870</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3870</id><created>2007-12-22</created><updated>2008-05-19</updated><authors><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author></authors><title>Substitute Valuations: Generation and Structure</title><categories>cs.GT cs.PF</categories><comments>Revision includes more background and explanations</comments><acm-class>G.0</acm-class><doi>10.1016/j.peva.2008.07.001</doi><abstract>  Substitute valuations (in some contexts called gross substitute valuations)
are prominent in combinatorial auction theory. An algorithm is given in this
paper for generating a substitute valuation through Monte Carlo simulation. In
addition, the geometry of the set of all substitute valuations for a fixed
number of goods K is investigated. The set consists of a union of polyhedrons,
and the maximal polyhedrons are identified for K=4. It is shown that the
maximum dimension of the maximal polyhedrons increases with K nearly as fast as
two to the power K. Consequently, under broad conditions, if a combinatorial
algorithm can present an arbitrary substitute valuation given a list of input
numbers, the list must grow nearly as fast as two to the power K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3876</identifier>
 <datestamp>2008-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3876</id><created>2007-12-22</created><updated>2008-04-29</updated><authors><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Rothschild</keyname><forenames>Amir</forenames></author></authors><title>Explicit Non-Adaptive Combinatorial Group Testing Schemes</title><categories>cs.DS</categories><comments>15 pages, accepted to ICALP 2008</comments><abstract>  Group testing is a long studied problem in combinatorics: A small set of $r$
ill people should be identified out of the whole ($n$ people) by using only
queries (tests) of the form &quot;Does set X contain an ill human?&quot;. In this paper
we provide an explicit construction of a testing scheme which is better
(smaller) than any known explicit construction. This scheme has $\bigT{\min[r^2
\ln n,n]}$ tests which is as many as the best non-explicit schemes have. In our
construction we use a fact that may have a value by its own right: Linear
error-correction codes with parameters $[m,k,\delta m]_q$ meeting the
Gilbert-Varshamov bound may be constructed quite efficiently, in $\bigT{q^km}$
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3896</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3896</id><created>2007-12-23</created><authors><author><keyname>Wang</keyname><forenames>Jiangping</forenames></author></authors><title>Tighter and Stable Bounds for Marcum Q-Function</title><categories>cs.IT math.IT</categories><comments>7 pages. Submitted to IEEE Transactions on Information Theory</comments><abstract>  This paper proposes new bounds for Marcum Q-function, which prove extremely
tight and outperform all the bounds previously proposed in the literature. What
is more, the proposed bounds are good and stable both for large values and
small values of the parameters of the Marcum Q-function, where the previously
introduced bounds are bad and even useless under some conditions. The new
bounds are derived by refined approximations for the 0th order modified Bessel
function in the integration region of the Marcum Q-function. They should be
useful since they are always tight no matter the parameters are large or small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3916</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3916</id><created>2007-12-23</created><authors><author><keyname>Enge</keyname><forenames>Andreas</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Discrete logarithms in curves over finite fields</title><categories>cs.CR cs.DM math.AG</categories><proxy>ccsd inria-00201090</proxy><abstract>  A survey on algorithms for computing discrete logarithms in Jacobians of
curves over finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3925</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3925</id><created>2007-12-23</created><authors><author><keyname>Heus</keyname><forenames>Pascal</forenames></author><author><keyname>Gomez</keyname><forenames>Richard</forenames></author></authors><title>QIS-XML: A metadata specification for Quantum Information Science</title><categories>cs.SE cs.DB quant-ph</categories><comments>26 pages, 22 figures</comments><abstract>  While Quantum Information Science (QIS) is still in its infancy, the ability
for quantum based hardware or computers to communicate and integrate with their
classical counterparts will be a major requirement towards their success.
Little attention however has been paid to this aspect of QIS. To manage and
exchange information between systems, today's classic Information Technology
(IT) commonly uses the eXtensible Markup Language (XML) and its related tools.
XML is composed of numerous specifications related to various fields of
expertise. No such global specification however has been defined for quantum
computers. QIS-XML is a proposed XML metadata specification for the description
of fundamental components of QIS (gates &amp; circuits) and a platform for the
development of a hardware independent low level pseudo-code for quantum
algorithms. This paper lays out the general characteristics of the QIS-XML
specification and outlines practical applications through prototype use cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3936</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3936</id><created>2007-12-23</created><authors><author><keyname>Mestre</keyname><forenames>Juli&#xe1;n</forenames></author></authors><title>Lagrangian Relaxation and Partial Cover</title><categories>cs.DS cs.DM</categories><comments>20 pages, extended abstract appeared in STACS 2008</comments><acm-class>G.2.1</acm-class><abstract>  Lagrangian relaxation has been used extensively in the design of
approximation algorithms. This paper studies its strengths and limitations when
applied to Partial Cover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3964</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3964</id><created>2007-12-23</created><updated>2007-12-31</updated><authors><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author><author><keyname>Halang</keyname><forenames>Wolfgang A.</forenames></author></authors><title>Cryptanalysis of an Image Encryption Scheme Based on a Compound Chaotic
  Sequence</title><categories>cs.CR cs.MM</categories><comments>11 pages, 2 figures</comments><doi>10.1016/j.imavis.2008.09.004</doi><abstract>  Recently, an image encryption scheme based on a compound chaotic sequence was
proposed. In this paper, the security of the scheme is studied and the
following problems are found: (1) a differential chosen-plaintext attack can
break the scheme with only three chosen plain-images; (2) there is a number of
weak keys and some equivalent keys for encryption; (3) the scheme is not
sensitive to the changes of plain-images; and (4) the compound chaotic sequence
does not work as a good random number resource.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3973</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3973</id><created>2007-12-24</created><authors><author><keyname>Collet</keyname><forenames>Pierre</forenames><affiliation>LIL</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>GUIDE: Unifying Evolutionary Engines through a Graphical User Interface</title><categories>cs.NE</categories><proxy>ccsd inria-00201074</proxy><journal-ref>Dans Evolution Artificielle 2936 (2003) 203-215</journal-ref><abstract>  Many kinds of Evolutionary Algorithms (EAs) have been described in the
literature since the last 30 years. However, though most of them share a common
structure, no existing software package allows the user to actually shift from
one model to another by simply changing a few parameters, e.g. in a single
window of a Graphical User Interface. This paper presents GUIDE, a Graphical
User Interface for DREAM Experiments that, among other user-friendly features,
unifies all kinds of EAs into a single panel, as far as evolution parameters
are concerned. Such a window can be used either to ask for one of the well
known ready-to-use algorithms, or to very easily explore new combinations that
have not yet been studied. Another advantage of grouping all necessary elements
to describe virtually all kinds of EAs is that it creates a fantastic pedagogic
tool to teach EAs to students and newcomers to the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3980</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3980</id><created>2007-12-26</created><authors><author><keyname>Fernandez</keyname><forenames>Antonio</forenames><affiliation>LADyR</affiliation></author><author><keyname>Gramoli</keyname><forenames>Vincent</forenames><affiliation>INRIA Futurs, IRISA</affiliation></author><author><keyname>Jimenez</keyname><forenames>Ernesto</forenames><affiliation>EUI</affiliation></author><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames><affiliation>IRISA</affiliation></author><author><keyname>Raynal</keyname><forenames>Michel</forenames><affiliation>IRISA</affiliation></author></authors><title>Distributed Slicing in Dynamic Systems</title><categories>cs.DC</categories><proxy>ccsd inria-00201165</proxy><report-no>ICDCS07</report-no><journal-ref>Dans The 27th International Conference on Distributed Computing
  Systems (ICDCS'07) (2007) 66</journal-ref><abstract>  Peer to peer (P2P) systems are moving from application specific architectures
to a generic service oriented design philosophy. This raises interesting
problems in connection with providing useful P2P middleware services capable of
dealing with resource assignment and management in a large-scale, heterogeneous
and unreliable environment. The slicing service, has been proposed to allow for
an automatic partitioning of P2P networks into groups (slices) that represent a
controllable amount of some resource and that are also relatively homogeneous
with respect to that resource. In this paper we propose two gossip-based
algorithms to solve the distributed slicing problem. The first algorithm speeds
up an existing algorithm sorting a set of uniform random numbers. The second
algorithm statistically approximates the rank of nodes in the ordering. The
scalability, efficiency and resilience to dynamics of both algorithms rely on
their gossip-based models. These algorithms are proved viable theoretically and
experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4011</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4011</id><created>2007-12-24</created><authors><author><keyname>Taricco</keyname><forenames>Giorgio</forenames></author></authors><title>Asymptotic Mutual Information Statistics of Separately-Correlated Rician
  Fading MIMO Channels</title><categories>cs.IT math.IT</categories><comments>- submitted to the IEEE Transactions on Information Theory on Nov.
  19, 2006 - revised and submitted to the IEEE Transactions on Information
  Theory on Dec. 19, 2007</comments><abstract>  Precise characterization of the mutual information of MIMO systems is
required to assess the throughput of wireless communication channels in the
presence of Rician fading and spatial correlation. Here, we present an
asymptotic approach allowing to approximate the distribution of the mutual
information as a Gaussian distribution in order to provide both the average
achievable rate and the outage probability. More precisely, the mean and
variance of the mutual information of the separatelycorrelated Rician fading
MIMO channel are derived when the number of transmit and receive antennas grows
asymptotically large and their ratio approaches a finite constant. The
derivation is based on the replica method, an asymptotic technique widely used
in theoretical physics and, more recently, in the performance analysis of
communication (CDMA and MIMO) systems. The replica method allows to analyze
very difficult system cases in a comparatively simple way though some authors
pointed out that its assumptions are not always rigorous. Being aware of this,
we underline the key assumptions made in this setting, quite similar to the
assumptions made in the technical literature using the replica method in their
asymptotic analyses. As far as concerns the convergence of the mutual
information to the Gaussian distribution, it is shown that it holds under some
mild technical conditions, which are tantamount to assuming that the spatial
correlation structure has no asymptotically dominant eigenmodes. The accuracy
of the asymptotic approach is assessed by providing a sizeable number of
numerical results. It is shown that the approximation is very accurate in a
wide variety of system settings even when the number of transmit and receive
antennas is as small as a few units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4015</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4015</id><created>2007-12-24</created><authors><author><keyname>Goparaju</keyname><forenames>Sreechakra</forenames></author><author><keyname>Acharya</keyname><forenames>Jayadev</forenames></author><author><keyname>Ray</keyname><forenames>Ajoy K.</forenames></author><author><keyname>Goswami</keyname><forenames>Jaideva C.</forenames></author></authors><title>A Fast Hierarchical Multilevel Image Segmentation Method using Unbiased
  Estimators</title><categories>cs.CV</categories><comments>10 pages, 5 figures, submitted to &quot;IEEE Transactions on Pattern
  Analysis and Machine Intelligence&quot;</comments><abstract>  This paper proposes a novel method for segmentation of images by hierarchical
multilevel thresholding. The method is global, agglomerative in nature and
disregards pixel locations. It involves the optimization of the ratio of the
unbiased estimators of within class to between class variances. We obtain a
recursive relation at each step for the variances which expedites the process.
The efficacy of the method is shown in a comparison with some well-known
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4027</identifier>
 <datestamp>2008-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4027</id><created>2007-12-24</created><authors><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Dumitriu</keyname><forenames>Ioana</forenames></author><author><keyname>Holtz</keyname><forenames>Olga</forenames></author><author><keyname>Koev</keyname><forenames>Plamen</forenames></author></authors><title>Accurate and Efficient Expression Evaluation and Linear Algebra</title><categories>math.NA cs.CC cs.DS math.RA</categories><comments>49 pages, 6 figures, 1 table</comments><msc-class>65Y20, 68Q05, 68Q25, 65F30, 68W40, 68W25</msc-class><journal-ref>Acta Numerica, Volume 17, May 2008, pp 87-145</journal-ref><doi>10.1017/S0962492906350015</doi><abstract>  We survey and unify recent results on the existence of accurate algorithms
for evaluating multivariate polynomials, and more generally for accurate
numerical linear algebra with structured matrices. By &quot;accurate&quot; we mean that
the computed answer has relative error less than 1, i.e., has some correct
leading digits. We also address efficiency, by which we mean algorithms that
run in polynomial time in the size of the input. Our results will depend
strongly on the model of arithmetic: Most of our results will use the so-called
Traditional Model (TM). We give a set of necessary and sufficient conditions to
decide whether a high accuracy algorithm exists in the TM, and describe
progress toward a decision procedure that will take any problem and provide
either a high accuracy algorithm or a proof that none exists. When no accurate
algorithm exists in the TM, it is natural to extend the set of available
accurate operations by a library of additional operations, such as $x+y+z$, dot
products, or indeed any enumerable set which could then be used to build
further accurate algorithms. We show how our accurate algorithms and decision
procedure for finding them extend to this case. Finally, we address other
models of arithmetic, and the relationship between (im)possibility in the TM
and (in)efficient algorithms operating on numbers represented as bit strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4046</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4046</id><created>2007-12-24</created><authors><author><keyname>Harvey</keyname><forenames>David</forenames></author></authors><title>Faster polynomial multiplication via multipoint Kronecker substitution</title><categories>cs.SC cs.DS</categories><comments>14 pages, 4 figures</comments><abstract>  We give several new algorithms for dense polynomial multiplication based on
the Kronecker substitution method. For moderately sized input polynomials, the
new algorithms improve on the performance of the standard Kronecker
substitution by a sizeable constant, both in theory and in empirical tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4057</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4057</id><created>2007-12-25</created><updated>2008-02-19</updated><authors><author><keyname>Chan</keyname><forenames>Aldar C-F.</forenames></author></authors><title>On Compression of Cryptographic Keys</title><categories>cs.CR cs.NI</categories><acm-class>D.4.6; K.6.5</acm-class><abstract>  Any secured system can be modeled as a capability-based access control system
in which each user is given a set of secret keys of the resources he is granted
access to. In some large systems with resource-constrained devices, such as
sensor networks and RFID systems, the design is sensitive to memory or key
storage cost. With a goal to minimize the maximum users' key storage, key
compression based on key linking, that is, deriving one key from another
without compromising security, is studied. A lower bound on key storage needed
for a general access structure with key derivation is derived. This bound
demonstrates the theoretic limit of any systems which do not trade off security
and can be treated as a negative result to provide ground for designs with
security tradeoff. A concrete, provably secure key linking scheme based on
pseudorandom functions is given. Using the key linking framework, a number of
key pre-distribution schemes in the literature are analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4059</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4059</id><created>2007-12-25</created><authors><author><keyname>Kanoria</keyname><forenames>Y.</forenames></author><author><keyname>Manjunath</keyname><forenames>D.</forenames></author></authors><title>On Distributed Computation in Noisy Random Planar Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures</comments><journal-ref>Proceedings of IEEE International Symposium on Information Theory,
  2007</journal-ref><abstract>  We consider distributed computation of functions of distributed data in
random planar networks with noisy wireless links. We present a new algorithm
for computation of the maximum value which is order optimal in the number of
transmissions and computation time.We also adapt the histogram computation
algorithm of Ying et al to make the histogram computation time optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4075</identifier>
 <datestamp>2008-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4075</id><created>2007-12-25</created><updated>2008-04-17</updated><authors><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author><author><keyname>Byrne</keyname><forenames>Eimear</forenames></author><author><keyname>Greferath</keyname><forenames>Marcus</forenames></author></authors><title>Polytope Representations for Linear-Programming Decoding of Non-Binary
  Linear Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in 2008 IEEE International Symposium on
  Information Theory</comments><abstract>  In previous work, we demonstrated how decoding of a non-binary linear code
could be formulated as a linear-programming problem. In this paper, we study
different polytopes for use with linear-programming decoding, and show that for
many classes of codes these polytopes yield a complexity advantage for
decoding. These representations lead to polynomial-time decoders for a wide
variety of classical non-binary linear codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4096</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4096</id><created>2007-12-26</created><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Yaakobi</keyname><forenames>Eitan</forenames></author></authors><title>Error-Correction of Multidimensional Bursts</title><categories>cs.IT math.IT</categories><comments>15 pages</comments><abstract>  In this paper we present several constructions to generate codes for
correcting a multidimensional cluster-error. The goal is to correct a
cluster-error whose shape can be a box-error, a Lee sphere error, or an error
with an arbitrary shape. Our codes have very low redundancy, close to optimal,
and large range of parameters of arrays and clusters. Our main results are
summarized as follows: 1) A construction of two-dimensional codes capable to
correct a rectangular-error with considerably more flexible parameters from
previously known constructions. Another advantage of this construction is that
it is easily generalized for D dimensions. 2) A novel method based on D
colorings of the D-dimensional space for constructing D-dimensional codes
correcting D-dimensional cluster-error of various shapes. This method is
applied efficiently to correct a D-dimensional cluster error of parameters not
covered efficiently by previous onstructions. 3) A transformation of the
D-dimensional space into another D-dimensional space such that a D-dimensional
Lee sphere is transformed into a shape located in a D-dimensional box of a
relatively small size. We use the previous constructions to correct a
D-dimensional error whose shape is a D-dimensional Lee sphere. 4) Applying the
coloring method to correct more efficiently a two-dimensional error whose shape
is a Lee sphere. The D-dimensional case is also discussed. 5) A construction of
one-dimensional codes capable to correct a burst-error of length b in which the
number of erroneous positions is relatively small compared to b. This
construction is generalized for D-dimensional codes. 6) Applying the
constructions correcting a Lee sphere error and a cluster-error with small
number of erroneous positions, to correct an arbitrary cluster-error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4099</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4099</id><created>2007-12-25</created><updated>2009-09-20</updated><authors><author><keyname>Briscoe</keyname><forenames>G.</forenames></author><author><keyname>De Wilde</keyname><forenames>P.</forenames></author></authors><title>Digital Ecosystems: Optimisation by a Distributed Intelligence</title><categories>cs.NE</categories><comments>12 pages, 14 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can intelligence optimise Digital Ecosystems? How could a distributed
intelligence interact with the ecosystem dynamics? Can the software components
that are part of genetic selection be intelligent in themselves, as in an
adaptive technology? We consider the effect of a distributed intelligence
mechanism on the evolutionary and ecological dynamics of our Digital Ecosystem,
which is the digital counterpart of a biological ecosystem for evolving
software services in a distributed network. We investigate Neural Networks and
Support Vector Machine for the learning based pattern recognition functionality
of our distributed intelligence. Simulation results imply that the Digital
Ecosystem performs better with the application of a distributed intelligence,
marginally more effectively when powered by Support Vector Machine than Neural
Networks, and suggest that it can contribute to optimising the operation of our
Digital Ecosystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4101</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4101</id><created>2007-12-25</created><updated>2009-10-04</updated><authors><author><keyname>De Wilde</keyname><forenames>P.</forenames></author><author><keyname>Briscoe</keyname><forenames>G.</forenames></author></authors><title>Digital Ecosystems: Stability of Evolving Agent Populations</title><categories>cs.NE</categories><comments>8 pages, 6 figures, ACM Management of Emergent Digital EcoSystems
  (MEDES) 2009</comments><acm-class>C.2.4; D.2.11; H.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stability is perhaps one of the most desirable features of any engineered
system, given the importance of being able to predict its response to various
environmental conditions prior to actual deployment. Engineered systems are
becoming ever more complex, approaching the same levels of biological
ecosystems, and so their stability becomes ever more important, but taking on
more and more differential dynamics can make stability an ever more elusive
property. The Chli-DeWilde definition of stability views a Multi-Agent System
as a discrete time Markov chain with potentially unknown transition
probabilities. With a Multi-Agent System being considered stable when its
state, a stochastic process, has converged to an equilibrium distribution,
because stability of a system can be understood intuitively as exhibiting
bounded behaviour. We investigate an extension to include Multi-Agent Systems
with evolutionary dynamics, focusing on the evolving agent populations of our
Digital Ecosystem. We then built upon this to construct an entropy-based
definition for the degree of instability (entropy of the limit probabilities),
which was later used to perform a stability analysis. The Digital Ecosystem is
considered to investigate the stability of an evolving agent population through
simulations, for which the results were consistent with the original
Chli-DeWilde definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4102</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4102</id><created>2007-12-26</created><updated>2009-10-04</updated><authors><author><keyname>Briscoe</keyname><forenames>G.</forenames></author><author><keyname>De Wilde</keyname><forenames>P.</forenames></author></authors><title>Digital Ecosystems: Evolving Service-Oriented Architectures</title><categories>cs.NE</categories><comments>7 pages, 4 figures, conference</comments><journal-ref>In IEEE First International Conference on Bio Inspired mOdels of
  NETwork, Information and Computing Systems (BIONETICS) (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We view Digital Ecosystems to be the digital counterparts of biological
ecosystems, exploiting the self-organising properties of biological ecosystems,
which are considered to be robust, self-organising and scalable architectures
that can automatically solve complex, dynamic problems. Digital Ecosystems are
a novel optimisation technique where the optimisation works at two levels: a
first optimisation, migration of agents (representing services) which are
distributed in a decentralised peer-to-peer network, operating continuously in
time; this process feeds a second optimisation based on evolutionary computing
that operates locally on single peers and is aimed at finding solutions to
satisfy locally relevant constraints. We created an Ecosystem-Oriented
Architecture of Digital Ecosystems by extending Service-Oriented Architectures
with distributed evolutionary computing, allowing services to recombine and
evolve over time, constantly seeking to improve their effectiveness for the
user base. Individuals within our Digital Ecosystem will be applications
(groups of services), created in response to user requests by using
evolutionary optimisation to aggregate the services. These individuals will
migrate through the Digital Ecosystem and adapt to find niches where they are
useful in fulfilling other user requests for applications. Simulation results
imply that the Digital Ecosystem performs better at large scales than a
comparable Service-Oriented Architecture, suggesting that incorporating ideas
from theoretical ecology can contribute to useful self-organising properties in
digital ecosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4103</identifier>
 <datestamp>2010-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4103</id><created>2007-12-26</created><updated>2010-01-23</updated><authors><author><keyname>Kapinas</keyname><forenames>Vasilios M.</forenames></author><author><keyname>Mihos</keyname><forenames>Sotirios K.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>On the Monotonicity of the Generalized Marcum and Nuttall Q-Functions</title><categories>cs.IT math.IT</categories><comments>Published in IEEE Transactions on Information Theory, August 2009.
  Only slight formatting modifications</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 55, no. 8, pp. 3701-3710, Aug. 2009</journal-ref><doi>10.1109/TIT.2009.2023710</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monotonicity criteria are established for the generalized Marcum Q-function,
$\emph{Q}_{M}$, the standard Nuttall Q-function, $\emph{Q}_{M,N}$, and the
normalized Nuttall Q-function, $\mathcal{Q}_{M,N}$, with respect to their real
order indices M,N. Besides, closed-form expressions are derived for the
computation of the standard and normalized Nuttall Q-functions for the case
when M,N are odd multiples of 0.5 and $M\geq N$. By exploiting these results,
novel upper and lower bounds for $\emph{Q}_{M,N}$ and $\mathcal{Q}_{M,N}$ are
proposed. Furthermore, specific tight upper and lower bounds for
$\emph{Q}_{M}$, previously reported in the literature, are extended for real
values of M. The offered theoretical results can be efficiently applied in the
study of digital communications over fading channels, in the
information-theoretic analysis of multiple-input multiple-output systems and in
the description of stochastic processes in probability theory, among others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4115</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4115</id><created>2007-12-26</created><updated>2009-11-11</updated><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author></authors><title>A Class of Quantum LDPC Codes Constructed From Finite Geometries</title><categories>quant-ph cs.IT math.IT</categories><comments>5pages, 2 figures</comments><journal-ref>Proc. of IEEE Globecom 08, New Orleans, LA 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-density parity check (LDPC) codes are a significant class of classical
codes with many applications. Several good LDPC codes have been constructed
using random, algebraic, and finite geometries approaches, with containing
cycles of length at least six in their Tanner graphs. However, it is impossible
to design a self-orthogonal parity check matrix of an LDPC code without
introducing cycles of length four.
  In this paper, a new class of quantum LDPC codes based on lines and points of
finite geometries is constructed. The parity check matrices of these codes are
adapted to be self-orthogonal with containing only one cycle of length four.
Also, the column and row weights, and bounds on the minimum distance of these
codes are given. As a consequence, the encoding and decoding algorithms of
these codes as well as their performance over various quantum depolarizing
channels will be investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4124</identifier>
 <datestamp>2008-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4124</id><created>2007-12-25</created><updated>2008-01-09</updated><authors><author><keyname>Singer</keyname><forenames>Michael F.</forenames></author></authors><title>Introduction to the Galois Theory of Linear Differential Equations</title><categories>math.CA cs.SC</categories><comments>82 pages; some typos corrected</comments><msc-class>12H05 (Primary) 34M50, 12H20 (Secondary)</msc-class><abstract>  This is an expanded version of the 10 lectures given as the 2006 London
Mathematical Society Invited Lecture Series at the Heriot-Watt University 31
July - 4 August 2006.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4126</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4126</id><created>2007-12-24</created><authors><author><keyname>Reddy</keyname><forenames>Chandan K.</forenames></author></authors><title>TRUST-TECH based Methods for Optimization and Learning</title><categories>cs.AI cs.CE cs.MS cs.NA cs.NE</categories><comments>PHD Thesis</comments><acm-class>G.1.6; I.5.3; I.5.1</acm-class><journal-ref>Chandan K. Reddy, TRUST-TECH based Methods for Optimization and
  Learning, PHD Thesis, Cornell University, February 2007</journal-ref><abstract>  Many problems that arise in machine learning domain deal with nonlinearity
and quite often demand users to obtain global optimal solutions rather than
local optimal ones. Optimization problems are inherent in machine learning
algorithms and hence many methods in machine learning were inherited from the
optimization literature. Popularly known as the initialization problem, the
ideal set of parameters required will significantly depend on the given
initialization values. The recently developed TRUST-TECH (TRansformation Under
STability-reTaining Equilibria CHaracterization) methodology systematically
explores the subspace of the parameters to obtain a complete set of local
optimal solutions. In this thesis work, we propose TRUST-TECH based methods for
solving several optimization and machine learning problems. Two stages namely,
the local stage and the neighborhood-search stage, are repeated alternatively
in the solution space to achieve improvements in the quality of the solutions.
Our methods were tested on both synthetic and real datasets and the advantages
of using this novel framework are clearly manifested. This framework not only
reduces the sensitivity to initialization, but also allows the flexibility for
the practitioners to use various global and local methods that work well for a
particular problem of interest. Other hierarchical stochastic algorithms like
evolutionary algorithms and smoothing algorithms are also studied and
frameworks for combining these methods with TRUST-TECH have been proposed and
evaluated on several test systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4135</identifier>
 <datestamp>2007-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4135</id><created>2007-12-26</created><authors><author><keyname>Tang</keyname><forenames>Xiaojun</forenames></author><author><keyname>Liu</keyname><forenames>Ruoheng</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On the Throughput of Secure Hybrid-ARQ Protocols for Gaussian
  Block-Fading Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><abstract>  The focus of this paper is an information-theoretic study of retransmission
protocols for reliable packet communication under a secrecy constraint. The
hybrid automatic retransmission request (HARQ) protocol is revisited for a
block-fading wire-tap channel, in which two legitimate users communicate over a
block-fading channel in the presence of a passive eavesdropper who intercepts
the transmissions through an independent block-fading channel. In this model,
the transmitter obtains a 1-bit ACK/NACK feedback from the legitimate receiver
via an error-free public channel. Both reliability and confidentiality of
secure HARQ protocols are studied by the joint consideration of channel coding,
secrecy coding, and retransmission protocols. In particular, the error and
secrecy performance of repetition time diversity (RTD) and incremental
redundancy (INR) protocols are investigated based on good Wyner code sequences,
which ensure that the confidential message is decoded successfully by the
legitimate receiver and is kept in total ignorance by the eavesdropper for a
given set of channel realizations. This paper first illustrates that there
exists a good rate-compatible Wyner code family which ensures a secure INR
protocol. Next, two types of outage probabilities, connection outage and
secrecy outage probabilities are defined in order to characterize the tradeoff
between the reliability of the legitimate communication link and the
confidentiality with respect to the eavesdropper's link. For a given
connection/secrecy outage probability pair, an achievable throughput of secure
HARQ protocols is derived for block-fading channels. Finally, both asymptotic
analysis and numerical computations demonstrate the benefits of HARQ protocols
to throughput and secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4148</identifier>
 <datestamp>2007-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4148</id><created>2007-12-26</created><updated>2007-12-30</updated><authors><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author><author><keyname>Karapetyan</keyname><forenames>Gagik H.</forenames></author></authors><title>Lower bounds for the greatest possible number of colors in interval edge
  colorings of bipartite cylinders and bipartite tori</title><categories>cs.DM</categories><comments>3 pages</comments><journal-ref>Proceedings of the CSIT Conference, Yerevan, 2007, 86-88</journal-ref><abstract>  An interval edge t-coloring of a graph G is a proper edge coloring of G with
colors 1,2...,t such that at least one edge of G is colored by color
i,i=1,2...,t, and the edges incident with each vertex v are colored by d_{G}(v)
consecutive colors, where d_{G}(v) is the degree of the vertex v in G. In this
paper interval edge colorings of bipartite cylinders and bipartite tori are
investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4153</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4153</id><created>2007-12-26</created><updated>2008-10-28</updated><authors><author><keyname>Briscoe</keyname><forenames>G.</forenames></author><author><keyname>Sadedin</keyname><forenames>S.</forenames></author><author><keyname>Paperin</keyname><forenames>G.</forenames></author></authors><title>Biology of Applied Digital Ecosystems</title><categories>cs.NE cs.MA</categories><comments>9 pages, 4 figure, conference</comments><journal-ref>In IEEE First International Conference on Digital Ecosystems and
  Technologies, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A primary motivation for our research in Digital Ecosystems is the desire to
exploit the self-organising properties of biological ecosystems. Ecosystems are
thought to be robust, scalable architectures that can automatically solve
complex, dynamic problems. However, the biological processes that contribute to
these properties have not been made explicit in Digital Ecosystems research.
Here, we discuss how biological properties contribute to the self-organising
features of biological ecosystems, including population dynamics, evolution, a
complex dynamic environment, and spatial distributions for generating local
interactions. The potential for exploiting these properties in artificial
systems is then considered. We suggest that several key features of biological
ecosystems have not been fully explored in existing digital ecosystems, and
discuss how mimicking these features may assist in developing robust, scalable
self-organising architectures. An example architecture, the Digital Ecosystem,
is considered in detail. The Digital Ecosystem is then measured experimentally
through simulations, with measures originating from theoretical ecology, to
confirm its likeness to a biological ecosystem. Including the responsiveness to
requests for applications from the user base, as a measure of the 'ecological
succession' (development).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4159</identifier>
 <datestamp>2012-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4159</id><created>2007-12-26</created><updated>2012-11-27</updated><authors><author><keyname>Briscoe</keyname><forenames>G</forenames></author></authors><title>Creating a Digital Ecosystem: Service-Oriented Architectures with
  Distributed Evolutionary Computing</title><categories>cs.NE</categories><comments>This has been withdrawn by the author due to an error in using
  presentation notes in submission</comments><journal-ref>In JavaOne Conference, 2006, BOF-0759</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We start with a discussion of the relevant literature, including Nature
Inspired Computing as a framework in which to understand this work, and the
process of biomimicry to be used in mimicking the necessary biological
processes to create Digital Ecosystems. We then consider the relevant
theoretical ecology in creating the digital counterpart of a biological
ecosystem, including the topological structure of ecosystems, and evolutionary
processes within distributed environments. This leads to a discussion of the
relevant fields from computer science for the creation of Digital Ecosystems,
including evolutionary computing, Multi-Agent Systems, and Service-Oriented
Architectures. We then define Ecosystem-Oriented Architectures for the creation
of Digital Ecosystems, imbibed with the properties of self-organisation and
scalability from biological ecosystems, including a novel form of distributed
evolutionary computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4168</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4168</id><created>2007-12-26</created><authors><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Islam</keyname><forenames>Humayun Kadir</forenames></author><author><keyname>Sayeed</keyname><forenames>Sabit Anjum</forenames></author><author><keyname>Ahmed</keyname><forenames>Farruk</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>A Framework for Providing E-Services to the Rural Areas using Wireless
  Ad Hoc and Sensor Networks</title><categories>cs.OH cs.NI</categories><comments>5 pages</comments><journal-ref>Proceedings of IEEE ICNEWS 2006, January 2-4, Dhaka, Bangladesh,
  2006, pp. 282-286</journal-ref><abstract>  In recent years, the proliferation of mobile computing devices has driven a
revolutionary change in the computing world. The nature of ubiquitous devices
makes wireless networks the easiest solution for their interconnection. This
has led to the rapid growth of several wireless systems like wireless ad hoc
networks, wireless sensor networks etc. In this paper we have proposed a
framework for rural development by providing various e-services to the rural
areas with the help of wireless ad hoc and sensor networks. We have discussed
how timely and accurate information could be collected from the rural areas
using wireless technologies. In addition to this, we have also mentioned the
technical and operational challenges that could hinder the implementation of
such a framework in the rural areas in the developing countries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4169</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4169</id><created>2007-12-26</created><authors><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Lee</keyname><forenames>Hyung-Woo</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>Security in Wireless Sensor Networks: Issues and Challenges</title><categories>cs.NI</categories><comments>6 pages</comments><journal-ref>Proceedings of 8th IEEE ICACT 2006, Volume II, February 20-22,
  Phoenix Park, Korea, 2006, pp. 1043-1048</journal-ref><abstract>  Wireless Sensor Network (WSN) is an emerging technology that shows great
promise for various futuristic applications both for mass public and military.
The sensing technology combined with processing power and wireless
communication makes it lucrative for being exploited in abundance in future.
The inclusion of wireless communication technology also incurs various types of
security threats. The intent of this paper is to investigate the security
related issues and challenges in wireless sensor networks. We identify the
security threats, review proposed security mechanisms for wireless sensor
networks. We also discuss the holistic view of security for ensuring layered
and robust security in wireless sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4170</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4170</id><created>2007-12-26</created><authors><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author><author><keyname>Lee</keyname><forenames>Hyung-Woo</forenames></author></authors><title>Smartening the Environment using Wireless Sensor Networks in a
  Developing Country</title><categories>cs.NI</categories><comments>5 pages</comments><journal-ref>Proceedings of 8th IEEE ICACT 2006, Volume I, February 20-22,
  Phoenix Park, Korea, 2006, pp. 705-709</journal-ref><abstract>  The miniaturization process of various sensing devices has become a reality
by enormous research and advancements accomplished in Micro Electro-Mechanical
Systems (MEMS) and Very Large Scale Integration (VLSI) lithography. Regardless
of such extensive efforts in optimizing the hardware, algorithm, and protocols
for networking, there still remains a lot of scope to explore how these
innovations can all be tied together to design Wireless Sensor Networks (WSN)
for smartening the surrounding environment for some practical purposes. In this
paper we explore the prospects of wireless sensor networks and propose a design
level framework for developing a smart environment using WSNs, which could be
beneficial for a developing country like Bangladesh. In connection to this, we
also discuss the major aspects of wireless sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4172</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4172</id><created>2007-12-26</created><authors><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>Developing an Efficient DMCIS with Next-Generation Wireless Networks</title><categories>cs.NI</categories><comments>6 pages</comments><journal-ref>IEEE Military Communications Conference (IEEE MILCOM 2006),
  October 23-25, Washington, DC, USA</journal-ref><abstract>  The impact of extreme events across the globe is extraordinary which
continues to handicap the advancement of the struggling developing societies
and threatens most of the industrialized countries in the globe. Various fields
of Information and Communication Technology have widely been used for efficient
disaster management; but only to a limited extent though, there is a tremendous
potential for increasing efficiency and effectiveness in coping with disasters
with the utilization of emerging wireless network technologies. Early warning,
response to the particular situation and proper recovery are among the main
focuses of an efficient disaster management system today. Considering these
aspects, in this paper we propose a framework for developing an efficient
Disaster Management Communications and Information System (DMCIS) which is
basically benefited by the exploitation of the emerging wireless network
technologies combined with other networking and data processing technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4173</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4173</id><created>2007-12-26</created><authors><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>Secure Clustering in DSN with Key Predistribution and WCDS</title><categories>cs.NI</categories><comments>6 pages</comments><journal-ref>IEEE Military Communications Conference (IEEE MILCOM 2006),
  October 23-25, Washington, DC, USA</journal-ref><abstract>  This paper proposes an efficient approach of secure clustering in distributed
sensor networks. The clusters or groups in the network are formed based on
offline rank assignment and predistribution of secret keys. Our approach uses
the concept of weakly connected dominating set (WCDS) to reduce the number of
cluster-heads in the network. The formation of clusters in the network is
secured as the secret keys are distributed and used in an efficient way to
resist the inclusion of any hostile entity in the clusters. Along with the
description of our approach, we present an analysis and comparison of our
approach with other schemes. We also mention the limitations of our approach
considering the practical implementation of the sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4174</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4174</id><created>2007-12-26</created><authors><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author><author><keyname>Suda</keyname><forenames>Tatsuya</forenames></author></authors><title>A Novel and Efficient Bilateral Remote User Authentication Scheme Using
  Smart Cards</title><categories>cs.CR cs.NI</categories><comments>2 pages</comments><journal-ref>Proceedings of the 2007 IEEE International Conference on Consumer
  Electronics (IEEE ICCE 2007), January 10-14, Las Vegas, USA, pp. 1-2</journal-ref><abstract>  This paper proposes a novel remote user authentication scheme using smart
cards which allows both the authentication server (AS) and the user to verify
authenticity of each other. Our scheme is efficient enough to resist the known
attacks that could be launched against remote user authentication process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4176</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4176</id><created>2007-12-26</created><authors><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>An Improved Timestamp-Based Password Authentication Scheme Using Smart
  Cards</title><categories>cs.CR cs.NI</categories><comments>6 pages</comments><journal-ref>Proceedings of the 9th IEEE ICACT 2007, Volume I, February 12-14,
  2007, Phoenix Park, Korea, pp. 804-809</journal-ref><doi>10.1093/ietisy/e90-d.11.1885</doi><abstract>  With the recent proliferation of distributed systems and networking, remote
authentication has become a crucial task in many networking applications.
Various schemes have been proposed so far for the two-party remote
authentication; however, some of them have been proved to be insecure. In this
paper, we propose an efficient timestamp-based password authentication scheme
using smart cards. We show various types of forgery attacks against a
previously proposed timestamp-based password authentication scheme and improve
that scheme to ensure robust security for the remote authentication process,
keeping all the advantages that were present in that scheme. Our scheme
successfully defends the attacks that could be launched against other related
previous schemes. We present a detailed cryptanalysis of previously proposed
Shen et. al scheme and an analysis of the improved scheme to show its
improvements and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4177</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4177</id><created>2007-12-26</created><authors><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Heo</keyname><forenames>Gihyuk</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>A Secure Lightweight Approach of Node Membership Verification in Dense
  HDSN</title><categories>cs.NI cs.CR</categories><comments>6 pages</comments><journal-ref>IEEE Military Communications Conference (IEEE MILCOM 2007),
  October 29-31, Orlando, Florida, USA</journal-ref><abstract>  In this paper, we consider a particular type of deployment scenario of a
distributed sensor network (DSN), where sensors of different types and
categories are densely deployed in the same target area. In this network, the
sensors are associated with different groups, based on their functional types
and after deployment they collaborate with one another in the same group for
doing any assigned task for that particular group. We term this sort of DSN as
a heterogeneous distributed sensor network (HDSN). Considering this scenario,
we propose a secure membership verification mechanism using one-way accumulator
(OWA) which ensures that, before collaborating for a particular task, any pair
of nodes in the same deployment group can verify each other-s legitimacy of
membership. Our scheme also supports addition and deletion of members (nodes)
in a particular group in the HDSN. Our analysis shows that, the proposed scheme
could work well in conjunction with other security mechanisms for sensor
networks and is very effective to resist any adversary-s attempt to be included
in a legitimate group in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4178</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4178</id><created>2007-12-26</created><authors><author><keyname>Haque</keyname><forenames>Md. Mokammel</forenames></author><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Choi</keyname><forenames>Byung Goo</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>An Efficient PKC-Based Security Architecture for Wireless Sensor
  Networks</title><categories>cs.CR cs.NI</categories><comments>7 pages</comments><journal-ref>IEEE Military Communications Conference (IEEE MILCOM 2007),
  October 29-31, Orlando, Florida, USA</journal-ref><abstract>  In spite of previous widely held belief of the incompatibility of public key
cryptography (PKC) schemes for wireless sensor networks (WSNs), some recent
works have shown that, PKC based schemes could be implemented for such networks
in some ways. The major challenge of employing a PKC scheme in wireless sensor
network is posed by the limitations of resources of the tiny sensors.
Considering this feature of the sensors, in this paper, we propose an efficient
PKC based security architecture with relatively less resource requirements than
those of the other previously proposed PKC schemes for WSN. Our security
architecture comprises basically of two parts; a key handshaking scheme based
on simple linear operations and the derivation of decryption key by a receiver
node. Our architecture allows both base-station-to-node or node-to-base-station
secure communications, and node-to-node secure communications. Analysis and
simulation results show that, our proposed architecture ensures a good level of
security for communications in the network and could effectively be implemented
using the limited computation, memory and energy budgets of the current
generation sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4183</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4183</id><created>2007-12-26</created><authors><author><keyname>Wang</keyname><forenames>Dao-Shun</forenames></author><author><keyname>Yi</keyname><forenames>Feng</forenames></author><author><keyname>Li</keyname><forenames>Xiaobo</forenames></author></authors><title>Probabilistic Visual Secret Sharing Schemes for Gray-scale images and
  Color images</title><categories>cs.CR cs.CV</categories><abstract>  Visual secrete sharing (VSS) is an encryption technique that utilizes human
visual system in the recovering of the secret image and it does not require any
complex calculation. Pixel expansion has been a major issue of VSS schemes. A
number of probabilistic VSS schemes with minimum pixel expansion have been
proposed for binary secret images. This paper presents a general probabilistic
(k, n)-VSS scheme for gray-scale images and another scheme for color images.
With our schemes, the pixel expansion can be set to a user-defined value. When
this value is 1, there is no pixel expansion at all. The quality of
reconstructed secret images, measured by Average Relative Difference, is
equivalent to Relative Difference of existing deterministic schemes. Previous
probabilistic VSS schemes for black-and-white images with respect to pixel
expansion can be viewed as special cases of the schemes proposed here
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4209</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4209</id><created>2007-12-27</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>The Generalized Random Energy Model and its Application to the
  Statistical Physics of Ensembles of Hierarchical Codes</title><categories>cs.IT math.IT</categories><comments>43 pages, 1 figure, submitted to the IEEE Transactions on Information
  Theory</comments><abstract>  In an earlier work, the statistical physics associated with
finite--temperature decoding of code ensembles, along with the relation to
their random coding error exponents, were explored in a framework that is
analogous to Derrida's random energy model (REM) of spin glasses, according to
which the energy levels of the various spin configurations are independent
random variables. The generalized REM (GREM) extends the REM in that it
introduces correlations between energy levels in an hierarchical structure. In
this paper, we explore some analogies between the behavior of the GREM and that
of code ensembles which have parallel hierarchical structures. In particular,
in analogy to the fact that the GREM may have different types of phase
transition effects, depending on the parameters of the model, then the
above--mentioned hierarchical code ensembles behave substantially differently
in the various domains of the design parameters of these codes. We make an
attempt to explore the insights that can be imported from the statistical
mechanics of the GREM and be harnessed to serve for code design considerations
and guidelines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4213</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4213</id><created>2007-12-27</created><authors><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Matsumoto</keyname><forenames>Keiji</forenames></author></authors><title>Exact Quantum Algorithms for the Leader Election Problem</title><categories>quant-ph cs.DC cs.DS</categories><comments>47 pages, preliminary version in Proceedings of STACS 2005</comments><journal-ref>ACM TOCT 4 (2012): Article 1; IEEE TPDS 23 (2012): 255 - 262</journal-ref><abstract>  This paper gives the first separation of quantum and classical pure (i.e.,
non-cryptographic) computing abilities with no restriction on the amount of
available computing resources, by considering the exact solvability of a
celebrated unsolvable problem in classical distributed computing, the ``leader
election problem'' on anonymous networks. The goal of the leader election
problem is to elect a unique leader from among distributed parties. The paper
considers this problem for anonymous networks, in which each party has the same
identifier. It is well-known that no classical algorithm can solve exactly
(i.e., in bounded time without error) the leader election problem in anonymous
networks, even if it is given the number of parties. This paper gives two
quantum algorithms that, given the number of parties, can exactly solve the
problem for any network topology in polynomial rounds and polynomial
communication/time complexity with respect to the number of parties, when the
parties are connected by quantum communication links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4215</identifier>
 <datestamp>2007-12-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4215</id><created>2007-12-27</created><authors><author><keyname>Raggad</keyname><forenames>Bel G.</forenames><affiliation>PU - Seidenberg School of CS &amp; IS</affiliation></author><author><keyname>Sidhom</keyname><forenames>Sahbi</forenames><affiliation>LORIA</affiliation></author></authors><title>Cyberspace security: How to develop a security strategy</title><categories>cs.OH</categories><proxy>ccsd inria-00201212</proxy><journal-ref>Dans V. International conference Cyberspace 2007 (2007)</journal-ref><abstract>  Despite all visible dividers, the Internet is getting us closer and closer,
but with a great price. Our security is the price. The international community
is fully aware of the urgent need to secure the cyberspace as you see the
multiplication of security standards and national schemes interpreting them
beyond borders: ISO 15408, ISO 17799, and ISO 27001. Even though some
countries, including the Security Big Six (SB6), are equipped with their
security books and may feel relatively safe; this remains a wrong sense of
security as long as they share their networks with entities of less security.
The standards impose security best practices and system specifications for the
development of information security management systems. Partners beyond borders
have to be secure as this is only possible if all entities connected to the
partnership remain secure. Unfortunately, there is no way to verify the
continuous security of partners without periodic security auditing and
certification, and members who do not comply should be barred from the
partnership. This concept also applies to the cyber space or the electronic
society. In order to clean our society from cyber crimes and cyber terrorism we
need to impose strict security policies and enforce them in a cooperative
manner. The paper discusses a country's effort in the development of a national
security strategy given its security economic intelligence position, its
security readiness, and its adverse exposure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4222</identifier>
 <datestamp>2008-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4222</id><created>2007-12-27</created><updated>2008-03-31</updated><authors><author><keyname>Roversi</keyname><forenames>Luca</forenames></author></authors><title>Weak Affine Light Typing: Polytime intensional expressivity, soundness
  and completeness</title><categories>cs.LO</categories><comments>Updating: *) pag.29, line 527: index j --&gt; index k. *) pag.29, line
  544: point 6 canged. *) pag.30, line 547: p=max{m_1... --&gt; p=max{m,m_1... *)
  pag.30, line 548: the definition of the mapping of the linear composition of
  QlSRN has been updated. *) pag.30, line 544: arguments of the iterator
  changed. *) pag.30,31 occurences of wg: every occurrence of rho erased</comments><abstract>  Weak affine light typing (WALT) assigns light affine linear formulae as types
to a subset of lambda-terms in System F. WALT is poly-time sound: if a
lambda-term M has type in WALT, M can be evaluated with a polynomial cost in
the dimension of the derivation that gives it a type. In particular, the
evaluation can proceed under any strategy of a rewriting relation, obtained as
a mix of both call-by-name/call-by-value beta-reductions. WALT is poly-time
complete since it can represent any poly-time Turing machine. WALT weakens,
namely generalizes, the notion of stratification of deductions common to some
Light Systems -- we call as such those logical systems, derived from Linear
logic, to characterize FP, the set of Polynomial functions -- . A weaker
stratification allows to define a compositional embedding of the Quasi-linear
fragment QlSRN of Safe recursion on notation (SRN) into WALT. QlSRN is SRN,
which is a recursive-theoretical system characterizing FP, where only the
composition scheme is restricted to linear safe variables. So, the expressivity
of WALT is stronger, as compared to the known Light Systems. In particular,
using the types, the embedding puts in evidence the stratification of normal
and safe arguments hidden in QlSRN: the less an argument is impredicative, the
deeper, in a formal, proof-theoretical sense, gets its representation in WALT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4248</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4248</id><created>2007-12-27</created><updated>2008-12-18</updated><authors><author><keyname>Laubenbacher</keyname><forenames>Reinhard</forenames></author><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author></authors><title>Computer algebra in systems biology</title><categories>cs.SC q-bio.MN q-bio.QM</categories><comments>to appear in American Mathematical Monthly</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Systems biology focuses on the study of entire biological systems rather than
on their individual components. With the emergence of high-throughput data
generation technologies for molecular biology and the development of advanced
mathematical modeling techniques, this field promises to provide important new
insights. At the same time, with the availability of increasingly powerful
computers, computer algebra has developed into a useful tool for many
applications. This article illustrates the use of computer algebra in systems
biology by way of a well-known gene regulatory network, the Lac Operon in the
bacterium E. coli.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4273</identifier>
 <datestamp>2011-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4273</id><created>2007-12-27</created><updated>2011-12-02</updated><authors><author><keyname>Capp&#xe9;</keyname><forenames>Olivier</forenames><affiliation>LTCI</affiliation></author><author><keyname>Moulines</keyname><forenames>Eric</forenames><affiliation>LTCI</affiliation></author></authors><title>Online EM Algorithm for Latent Data Models</title><categories>stat.CO cs.LG</categories><comments>Version that includes the corrigendum published in volume 73, part 5
  (2011), of the Journal of the Royal Statistical Society, Series B</comments><proxy>ccsd</proxy><journal-ref>Journal of the Royal Statistical Society Series B (Statistical
  Methodology) 71, 3 (2009) 593-613</journal-ref><doi>10.1111/j.1467-9868.2009.00698.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, we propose a generic online (also sometimes called
adaptive or recursive) version of the Expectation-Maximisation (EM) algorithm
applicable to latent variable models of independent observations. Compared to
the algorithm of Titterington (1984), this approach is more directly connected
to the usual EM algorithm and does not rely on integration with respect to the
complete data distribution. The resulting algorithm is usually simpler and is
shown to achieve convergence to the stationary points of the Kullback-Leibler
divergence between the marginal distribution of the observation and the model
distribution at the optimal rate, i.e., that of the maximum likelihood
estimator. In addition, the proposed approach is also suitable for conditional
(or regression) models, as illustrated in the case of the mixture of linear
regressions model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4279</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4279</id><created>2007-12-27</created><updated>2009-06-09</updated><authors><author><keyname>Lee</keyname><forenames>Troy</forenames></author><author><keyname>Shraibman</keyname><forenames>Adi</forenames></author></authors><title>Disjointness is hard in the multi-party number on the forehead model</title><categories>cs.CC</categories><comments>23 pages. Added background to method and references to more recent
  work. Journal version to appear in Computational Complexity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that disjointness requires randomized communication
Omega(n^{1/(k+1)}/2^{2^k}) in the general k-party number-on-the-forehead model
of complexity. The previous best lower bound for k &gt;= 3 was log(n)/(k-1). Our
results give a separation between nondeterministic and randomized multiparty
number-on-the-forehead communication complexity for up to k=log log n - O(log
log log n) many players. Also by a reduction of Beame, Pitassi, and Segerlind,
these results imply subexponential lower bounds on the size of proofs needed to
refute certain unsatisfiable CNFs in a broad class of proof systems, including
tree-like Lovasz-Schrijver proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4318</identifier>
 <datestamp>2007-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4318</id><created>2007-12-28</created><authors><author><keyname>de Blanc</keyname><forenames>Peter</forenames></author></authors><title>Convergence of Expected Utilities with Algorithmic Probability
  Distributions</title><categories>cs.AI</categories><comments>2 pages + title page, references</comments><abstract>  We consider an agent interacting with an unknown environment. The environment
is a function which maps natural numbers to natural numbers; the agent's set of
hypotheses about the environment contains all such functions which are
computable and compatible with a finite set of known input-output pairs, and
the agent assigns a positive probability to each such hypothesis. We do not
require that this probability distribution be computable, but it must be
bounded below by a positive computable function. The agent has a utility
function on outputs from the environment. We show that if this utility function
is bounded below in absolute value by an unbounded computable function, then
the expected utility of any input is undefined. This implies that a computable
utility function will have convergent expected utilities iff that function is
bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4321</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4321</id><created>2007-12-28</created><updated>2008-01-08</updated><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Klappenecker</keyname><forenames>Andreas</forenames></author></authors><title>Subsystem Code Constructions</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, trading dimensions of subsystem codes, MDS subsystem codes,
  and propagation rules. All stabilizer codes are converted to subsystem codes.
  A talk given at QEC07, and submitted to IEEE ISIT 2008</comments><journal-ref>Proc. of IEEE ISIT 08, Toronto, CA, 2008</journal-ref><abstract>  Subsystem codes are the most versatile class of quantum error-correcting
codes known to date that combine the best features of all known passive and
active error-control schemes. The subsystem code is a subspace of the quantum
state space that is decomposed into a tensor product of two vector spaces: the
subsystem and the co-subsystem. A generic method to derive subsystem codes from
existing subsystem codes is given that allows one to trade the dimensions of
subsystem and co-subsystem while maintaining or improving the minimum distance.
As a consequence, it is shown that all pure MDS subsystem codes are derived
from MDS stabilizer codes. The existence of numerous families of MDS subsystem
codes is established. Propagation rules are derived that allow one to obtain
longer and shorter subsystem codes from given subsystem codes. Furthermore,
propagation rules are derived that allow one to construct a new subsystem code
by combining two given subsystem codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4341</identifier>
 <datestamp>2007-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4341</id><created>2007-12-28</created><authors><author><keyname>Li</keyname><forenames>Yongming</forenames></author></authors><title>Finite Automata Based on Quantum Logic and Their Determinization</title><categories>cs.LO</categories><abstract>  We give the quantum subset construction of orthomodular lattice-valued finite
automata, then we show the equivalence between orthomodular lattice-valued
finite automata, orthomodular lattice-valued deterministic finite automata and
orthomodular lattice-valued finite automata with empty string-moves. Based on
these equivalences, we study the algebraic operations on orthomodular
lattice-valued regular languages, then we establish Kleene theorem in the frame
of quantum logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4402</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4402</id><created>2007-12-28</created><updated>2008-01-18</updated><authors><author><keyname>O'Flanagan</keyname><forenames>Ruadhan</forenames></author></authors><title>Judgment</title><categories>math.PR cs.AI math.LO</categories><comments>20 pages; minor changes; references added; submitted</comments><msc-class>60A05 (Primary) 03B42, 03B48 (Secondary)</msc-class><abstract>  The concept of a judgment as a logical action which introduces new
information into a deductive system is examined. This leads to a way of
mathematically representing implication which is distinct from the familiar
material implication, according to which &quot;If A then B&quot; is considered to be
equivalent to &quot;B or not-A&quot;. This leads, in turn, to a resolution of the paradox
of the raven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0061</identifier>
 <datestamp>2008-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0061</id><created>2007-12-29</created><updated>2008-05-01</updated><authors><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Security for Wiretap Networks via Rank-Metric Codes</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, to be published at the 2008 IEEE International Symposium on
  Information Theory</comments><abstract>  The problem of securing a network coding communication system against a
wiretapper adversary is considered. The network implements linear network
coding to deliver $n$ packets from source to each receiver, and the wiretapper
can eavesdrop on $\mu$ arbitrarily chosen links. A coding scheme is proposed
that can achieve the maximum possible rate of $k=n-\mu$ packets that are
information-theoretically secure from the adversary. A distinctive feature of
our scheme is that it is universal: it can be applied on top of any
communication network without requiring knowledge of or any modifications on
the underlying network code. In fact, even a randomized network code can be
used. Our approach is based on Rouayheb-Soljanin's formulation of a wiretap
network as a generalization of the Ozarow-Wyner wiretap channel of type II.
Essentially, the linear MDS code in Ozarow-Wyner's coset coding scheme is
replaced by a maximum-rank-distance code over an extension of the field in
which linear network coding operations are performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0092</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0092</id><created>2007-12-29</created><updated>2008-01-03</updated><authors><author><keyname>Soileau</keyname><forenames>Kerry Michael</forenames></author></authors><title>Nash bargaining with a nondeterministic threat</title><categories>cs.GT</categories><comments>Added solution algorithm</comments><abstract>  We consider bargaining problems which involve two participants, with a
nonempty closed, bounded convex bargaining set of points in the real plane
representing all realizable bargains. We also assume that there is no definite
threat or disagreement point which will provide the default bargain if the
players cannot agree on some point in the bargaining set. However, there is a
nondeterministic threat: if the players fail to agree on a bargain, one of them
will be chosen at random with equal probability, and that chosen player will
select any realizable bargain as the solution, subject to a reasonable
restriction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0102</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0102</id><created>2007-12-29</created><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Reserved-Length Prefix Coding</title><categories>cs.IT cs.DS math.IT</categories><comments>5 pages, submitted to ISIT 2008</comments><acm-class>G.2.2; F.2; E.4; H.1.1</acm-class><abstract>  Huffman coding finds an optimal prefix code for a given probability mass
function. Consider situations in which one wishes to find an optimal code with
the restriction that all codewords have lengths that lie in a user-specified
set of lengths (or, equivalently, no codewords have lengths that lie in a
complementary set). This paper introduces a polynomial-time dynamic programming
algorithm that finds optimal codes for this reserved-length prefix coding
problem. This has applications to quickly encoding and decoding lossless codes.
In addition, one modification of the approach solves any quasiarithmetic prefix
coding problem, while another finds optimal codes restricted to the set of
codes with g codeword lengths for user-specified g (e.g., g=2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0131</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0131</id><created>2007-12-30</created><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Two-Level Concept-Oriented Data Model</title><categories>cs.DB</categories><report-no>Technical Report RT0006</report-no><journal-ref>Institute of Mathematics and Computer Science, Academy of Sciences
  of Moldova, Technical Report RT0006, 2007</journal-ref><abstract>  In this paper we describe a new approach to data modelling called the
concept-oriented model (CoM). This model is based on the formalism of nested
ordered sets which uses inclusion relation to produce hierarchical structure of
sets and ordering relation to produce multi-dimensional structure among its
elements. Nested ordered set is defined as an ordered set where an each element
can be itself an ordered set. Ordering relation in CoM is used to define data
semantics and operations with data such as projection and de-projection. This
data model can be applied to very different problems and the paper describes
some its uses such grouping with aggregation and multi-dimensional analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0133</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0133</id><created>2007-12-30</created><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>An Approach to Programming Based on Concepts</title><categories>cs.PL</categories><comments>49 pages. Related papers: http://conceptoriented.com</comments><report-no>Technical Report RT0005</report-no><journal-ref>Institute of Mathematics and Computer Science, Academy of Sciences
  of Moldova, Technical Report RT0005, 2007</journal-ref><abstract>  In this paper we describe a new approach to programming which generalizes
object-oriented programming. It is based on using a new programming construct,
called concept, which generalizes classes. Concept is defined as a pair of two
classes: one reference class and one object class. Each concept has a parent
concept which is specified using inclusion relation generalizing inheritance.
We describe several important mechanisms such as reference resolution, context
stack, dual methods and life-cycle management, inheritance and polymorphism.
This approach to programming is positioned as a new programming paradigm and
therefore we formulate its main principles and rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0135</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0135</id><created>2007-12-30</created><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Concepts and their Use for Modelling Objects and References in
  Programming Languages</title><categories>cs.PL</categories><comments>43 pages. Related papers: http://conceptoriented.com/</comments><report-no>Technical Report RT0004</report-no><journal-ref>Institute of Mathematics and Computer Science, Academy of Sciences
  of Moldova, Technical Report RT0004, 2007</journal-ref><abstract>  In the paper a new programming construct, called concept, is introduced.
Concept is pair of two classes: a reference class and an object class.
Instances of the reference classes are passed-by-value and are intended to
represent objects. Instances of the object class are passed-by-reference. An
approach to programming where concepts are used instead of classes is called
concept-oriented programming (CoP). In CoP objects are represented and accessed
indirectly by means of references. The structure of concepts describes a
hierarchical space with a virtual address system. The paper describes this new
approach to programming including such mechanisms as reference resolution,
complex references, method interception, dual methods, life-cycle management
inheritance and polymorphism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0136</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0136</id><created>2007-12-30</created><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Indirect Object Representation and Access by Means of Concepts</title><categories>cs.PL</categories><comments>8 pages. Related papers: http://conceptoriented.com/</comments><journal-ref>Institute of Mathematics and Computer Science, Academy of Sciences
  of Moldova, Technical Report, 2006</journal-ref><abstract>  The paper describes a mechanism for indirect object representation and access
(ORA) in programming languages. The mechanism is based on using a new
programming construct which is referred to as concept. Concept consists of one
object class and one reference class both having their fields and methods. The
object class is the conventional class as defined in OOP with instances passed
by reference. Instances of the reference class are passed by value and are
intended to represent objects. The reference classes are used to describe how
objects have to be represented and accessed by providing custom format for
their identifiers and custom access procedures. Such an approach to programming
where concepts are used instead of classes is referred to as concept-oriented
programming. It generalizes OOP and its main advantage is that it allows the
programmer to describe not only the functionality of target objects but also
intermediate functions which are executed behind the scenes as an object is
being accessed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0139</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0139</id><created>2007-12-30</created><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Principles of the Concept-Oriented Data Model</title><categories>cs.DB</categories><comments>54 pages. Related papers: http://conceptoriented.com/</comments><journal-ref>Institute of Mathematics and Computer Science, Academy of Sciences
  of Moldova, Technical Report, 2004</journal-ref><abstract>  In the paper a new approach to data representation and manipulation is
described, which is called the concept-oriented data model (CODM). It is
supposed that items represent data units, which are stored in concepts. A
concept is a combination of superconcepts, which determine the concept's
dimensionality or properties. An item is a combination of superitems taken by
one from all the superconcepts. An item stores a combination of references to
its superitems. The references implement inclusion relation or attribute-value
relation among items. A concept-oriented database is defined by its concept
structure called syntax or schema and its item structure called semantics. The
model defines formal transformations of syntax and semantics including the
canonical semantics where all concepts are merged and the data semantics is
represented by one set of items. The concept-oriented data model treats
relations as subconcepts where items are instances of the relations.
Multi-valued attributes are defined via subconcepts as a view on the database
semantics rather than as a built-in mechanism. The model includes
concept-oriented query language, which is based on collection manipulations. It
also has such mechanisms as aggregation and inference based on semantics
propagation through the database schema.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0159</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0159</id><created>2007-12-31</created><authors><author><keyname>Petrosyan</keyname><forenames>P. A.</forenames></author></authors><title>Interval Edge Colorings of Mobius Ladders</title><categories>cs.DM</categories><comments>5 pages (in Russian)</comments><journal-ref>Proceedings of the CSIT Conference, Yerevan, 2005, 146-149</journal-ref><abstract>  An interval edge t-coloring of a graph G is a proper edge coloring of G with
colors 1,2...,t such that at least one edge of G is colored by color
i,i=1,2...,t, and the edges incident with each vertex x are colored by d_{G}(x)
consecutive colors, where d_{G}(x) is the degree of the vertex x in G. For
Mobius ladders the existence of this coloring is proved and all possible
numbers of colors in such colorings are found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0184</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0184</id><created>2007-12-30</created><authors><author><keyname>Hutchinson</keyname><forenames>Ryan</forenames></author></authors><title>The Existence of Strongly-MDS Convolutional Codes</title><categories>math.OC cs.IT math.IT</categories><comments>17 pages</comments><msc-class>94B10</msc-class><abstract>  It is known that maximum distance separable and maximum distance profile
convolutional codes exist over large enough finite fields of any characteristic
for all parameters $(n,k,\delta)$. It has been conjectured that the same is
true for convolutional codes that are strongly maximum distance separable.
Using methods from linear systems theory, we resolve this conjecture by showing
that, over a large enough finite field of any characteristic, codes which are
simultaneously maximum distance profile and strongly maximum distance separable
exist for all parameters $(n,k,\delta)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0209</identifier>
 <datestamp>2008-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0209</id><created>2007-12-31</created><updated>2008-04-29</updated><authors><author><keyname>Galatolo</keyname><forenames>Stefano</forenames></author><author><keyname>Hoyrup</keyname><forenames>Mathieu</forenames></author><author><keyname>Rojas</keyname><forenames>Cristobal</forenames></author></authors><title>Effective symbolic dynamics, random points, statistical behavior,
  complexity and entropy</title><categories>math.DS cs.IT math.IT math.PR</categories><msc-class>03D99, 37A05, 37A35, 60A99</msc-class><abstract>  We consider the dynamical behavior of Martin-L\&quot;of random points in dynamical
systems over metric spaces with a computable dynamics and a computable
invariant measure. We use computable partitions to define a sort of effective
symbolic model for the dynamics. Through this construction we prove that such
points have typical statistical behavior (the behavior which is typical in the
Birkhoff ergodic theorem) and are recurrent. We introduce and compare some
notions of complexity for orbits in dynamical systems and prove: (i) that the
complexity of the orbits of random points equals the Kolmogorov-Sina\&quot;i entropy
of the system, (ii) that the supremum of the complexity of orbits equals the
topological entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0232</identifier>
 <datestamp>2008-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0232</id><created>2007-12-31</created><updated>2008-03-18</updated><authors><author><keyname>Frosini</keyname><forenames>Patrizio</forenames></author></authors><title>Does intelligence imply contradiction?</title><categories>cs.AI cs.LO</categories><comments>39 pages, 6 figures; added Remark 9 (page 19) and Remark 12 (page
  25); changed some comments after Definition 13 and in Section 5; some minor
  changes</comments><abstract>  Contradiction is often seen as a defect of intelligent systems and a
dangerous limitation on efficiency. In this paper we raise the question of
whether, on the contrary, it could be considered a key tool in increasing
intelligence in biological structures. A possible way of answering this
question in a mathematical context is shown, formulating a proposition that
suggests a link between intelligence and contradiction.
  A concrete approach is presented in the well-defined setting of cellular
automata. Here we define the models of ``observer'', ``entity'',
``environment'', ``intelligence'' and ``contradiction''. These definitions,
which roughly correspond to the common meaning of these words, allow us to
deduce a simple but strong result about these concepts in an unbiased,
mathematical manner. Evidence for a real-world counterpart to the demonstrated
formal link between intelligence and contradiction is provided by three
computational experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0249</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0249</id><created>2007-12-31</created><authors><author><keyname>Laubenbacher</keyname><forenames>Reinhard</forenames></author><author><keyname>Jarrah</keyname><forenames>Abdul S.</forenames></author><author><keyname>Mortveit</keyname><forenames>Henning</forenames></author><author><keyname>Ravi</keyname><forenames>S. S.</forenames></author></authors><title>A mathematical formalism for agent-based modeling</title><categories>cs.MA cs.DM math.CO</categories><comments>Prepared for the Encyclopedia of Complexity and System Science,
  Springer Verlag, 2008</comments><abstract>  Many complex systems can be modeled as multiagent systems in which the
constituent entities (agents) interact with each other. The global dynamics of
such a system is determined by the nature of the local interactions among the
agents. Since it is difficult to formally analyze complex multiagent systems,
they are often studied through computer simulations. While computer simulations
can be very useful, results obtained through simulations do not formally
validate the observed behavior. Thus, there is a need for a mathematical
framework which one can use to represent multiagent systems and formally
establish their properties. This work contains a brief exposition of some known
mathematical frameworks that can model multiagent systems. The focus is on one
such framework, namely that of finite dynamical systems. Both, deterministic
and stochastic versions of this framework are discussed. The paper contains a
sampling of the mathematical results from the literature to show how finite
dynamical systems can be used to carry out a rigorous study of the properties
of multiagent systems and it is shown how the framework can also serve as a
universal model for computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0253</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0253</id><created>2007-12-31</created><authors><author><keyname>Stephens</keyname><forenames>Greg J.</forenames></author><author><keyname>Bialek</keyname><forenames>William</forenames></author></authors><title>Toward a statistical mechanics of four letter words</title><categories>q-bio.NC cs.CL physics.data-an physics.soc-ph</categories><doi>10.1103/PhysRevE.81.066119</doi><abstract>  We consider words as a network of interacting letters, and approximate the
probability distribution of states taken on by this network. Despite the
intuition that the rules of English spelling are highly combinatorial (and
arbitrary), we find that maximum entropy models consistent with pairwise
correlations among letters provide a surprisingly good approximation to the
full statistics of four letter words, capturing ~92% of the multi-information
among letters and even &quot;discovering&quot; real words that were not represented in
the data from which the pairwise correlations were estimated. The maximum
entropy model defines an energy landscape on the space of possible words, and
local minima in this landscape account for nearly two-thirds of words used in
written English.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0258</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0258</id><created>2007-12-31</created><updated>2010-06-02</updated><authors><author><keyname>Benbernou</keyname><forenames>Nadia</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>On the Maximum Span of Fixed-Angle Chains</title><categories>cs.CG</categories><comments>28 pages, 21 figures. Preliminary version appeared in Proc. 18th
  Canad. Conf. Comput. Geom., pages 93-96, 2006. This paper has been withdrawn
  by the authors. Lemma 15 as stated is incorrect, and although we believe the
  main theorems following (Thms. 17 &amp; 18) are true, the proofs relying on
  Lem.15 are not valid</comments><report-no>Smith Computer Science 088</report-no><acm-class>F.2.2</acm-class><abstract>  Soss proved that it is NP-hard to find the maximum 2D span of a fixed-angle
polygonal chain: the largest distance achievable between the endpoints in a
planar embedding. These fixed-angle chains can serve as models of protein
backbones. The corresponding problem in 3D is open. We show that three special
cases of particular relevance to the protein model are solvable in polynomial
time. When all link lengths and all angles are equal, the maximum 3D span is
achieved in a flat configuration and can be computed in constant time. When all
angles are equal and the chain is simple (non-self-crossing), the maximum flat
span can be found in linear time. In 3D, when all angles are equal to 90 deg
(but the link lengths arbitrary), the maximum 3D span is in general nonplanar
but can be found in quadratic time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0275</identifier>
 <datestamp>2009-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0275</id><created>2008-01-01</created><updated>2008-01-02</updated><authors><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K.</forenames></author></authors><title>Estimating Signals with Finite Rate of Innovation from Noisy Samples: A
  Stochastic Algorithm</title><categories>stat.AP cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><journal-ref>IEEE Trans. on Signal Processing, vol. 56, no. 10, pp. 5135-5146,
  October 2008</journal-ref><doi>10.1109/TSP.2008.928510</doi><abstract>  As an example of the recently-introduced concept of rate of innovation,
signals that are linear combinations of a finite number of Diracs per unit time
can be acquired by linear filtering followed by uniform sampling. However, in
reality, samples are rarely noiseless. In this paper, we introduce a novel
stochastic algorithm to reconstruct a signal with finite rate of innovation
from its noisy samples. Even though variants of this problem has been
approached previously, satisfactory solutions are only available for certain
classes of sampling kernels, for example kernels which satisfy the Strang-Fix
condition. In this paper, we consider the infinite-support Gaussian kernel,
which does not satisfy the Strang-Fix condition. Other classes of kernels can
be employed. Our algorithm is based on Gibbs sampling, a Markov chain Monte
Carlo (MCMC) method. Extensive numerical simulations demonstrate the accuracy
and robustness of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0289</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0289</id><created>2008-01-01</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Grigorieff</keyname><forenames>Serge</forenames><affiliation>LIAFA</affiliation></author></authors><title>Is Randomness &quot;Native&quot; to Computer Science?</title><categories>math.LO cs.CC</categories><comments>43 pages</comments><proxy>ccsd hal-00201576</proxy><journal-ref>Current Trends in Theoretical Computer Science. Vol2, World
  Scientific (Ed.) (2004) 141-180</journal-ref><abstract>  We survey the Kolmogorov's approach to the notion of randomness through the
Kolmogorov complexity theory. The original motivation of Kolmogorov was to give
up a quantitative definition of information. In this theory, an object is
randomness in the sense that it has a large information content. Afterwards, we
present parts of the work of Martin-Lof, Schnorr, Chaitin and Levin which
supply a mathematical notion of randomness throughout diverse theories from the
the 60' up to recently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0337</identifier>
 <datestamp>2008-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0337</id><created>2008-01-02</created><updated>2008-01-05</updated><authors><author><keyname>Whitworth</keyname><forenames>Brian</forenames></author></authors><title>The Physical World as a Virtual Reality</title><categories>cs.OH</categories><comments>The argument that virtual reality information simulations may be
  relevant to modern physics theory is a little outside the mainstream, but
  even people in Physics now consider this possibility, e.g. Svozil</comments><report-no>CDMTCS0316</report-no><abstract>  This paper explores the idea that the universe is a virtual reality created
by information processing, and relates this strange idea to the findings of
modern physics about the physical world. The virtual reality concept is
familiar to us from online worlds, but our world as a virtual reality is
usually a subject for science fiction rather than science. Yet logically the
world could be an information simulation running on a multi-dimensional
space-time screen. Indeed, if the essence of the universe is information,
matter, charge, energy and movement could be aspects of information, and the
many conservation laws could be a single law of information conservation. If
the universe were a virtual reality, its creation at the big bang would no
longer be paradoxical, as every virtual system must be booted up. It is
suggested that whether the world is an objective reality or a virtual reality
is a matter for science to resolve. Modern information science can suggest how
core physical properties like space, time, light, matter and movement could
derive from information processing. Such an approach could reconcile relativity
and quantum theories, with the former being how information processing creates
space-time, and the latter how it creates energy and matter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0340</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0340</id><created>2008-01-02</created><authors><author><keyname>Tenenbaum</keyname><forenames>Adam J.</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author></authors><title>Sum Rate Maximization using Linear Precoding and Decoding in the
  Multiuser MIMO Downlink</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures, uses ieeetran.cls</comments><abstract>  We propose an algorithm to maximize the instantaneous sum data rate
transmitted by a base station in the downlink of a multiuser multiple-input,
multiple-output system. The transmitter and the receivers may each be equipped
with multiple antennas and each user may receive more than one data stream. We
show that maximizing the sum rate is closely linked to minimizing the product
of mean squared errors (PMSE). The algorithm employs an uplink/downlink duality
to iteratively design transmit-receive linear precoders, decoders, and power
allocations that minimize the PMSE for all data streams under a sum power
constraint. Numerical simulations illustrate the effectiveness of the algorithm
and support the use of the PMSE criterion in maximizing the overall
instantaneous data rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0341</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0341</id><created>2008-01-02</created><updated>2008-09-02</updated><authors><author><keyname>Chertkov</keyname><forenames>Michael</forenames><affiliation>Los Alamos</affiliation></author></authors><title>Exactness of Belief Propagation for Some Graphical Models with Loops</title><categories>cond-mat.stat-mech cond-mat.other cs.AI cs.IT math.IT</categories><comments>12 pages, 1 figure, submitted to JSTAT</comments><report-no>LANL LA-UR-07-8441</report-no><journal-ref>J. Stat. Mech. (2008) P10016</journal-ref><doi>10.1088/1742-5468/2008/10/P10016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that an arbitrary graphical model of statistical inference
defined on a tree, i.e. on a graph without loops, is solved exactly and
efficiently by an iterative Belief Propagation (BP) algorithm convergent to
unique minimum of the so-called Bethe free energy functional. For a general
graphical model on a loopy graph the functional may show multiple minima, the
iterative BP algorithm may converge to one of the minima or may not converge at
all, and the global minimum of the Bethe free energy functional is not
guaranteed to correspond to the optimal Maximum-Likelihood (ML) solution in the
zero-temperature limit. However, there are exceptions to this general rule,
discussed in \cite{05KW} and \cite{08BSS} in two different contexts, where
zero-temperature version of the BP algorithm finds ML solution for special
models on graphs with loops. These two models share a key feature: their ML
solutions can be found by an efficient Linear Programming (LP) algorithm with a
Totally-Uni-Modular (TUM) matrix of constraints. Generalizing the two models we
consider a class of graphical models reducible in the zero temperature limit to
LP with TUM constraints. Assuming that a gedanken algorithm, g-BP, funding the
global minimum of the Bethe free energy is available we show that in the limit
of zero temperature g-BP outputs the ML solution. Our consideration is based on
equivalence established between gapless Linear Programming (LP) relaxation of
the graphical model in the $T\to 0$ limit and respective LP version of the
Bethe-Free energy minimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0349</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0349</id><created>2008-01-02</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Grigorieff</keyname><forenames>Serge</forenames><affiliation>LIAFA</affiliation></author></authors><title>Church, Cardinal and Ordinal Representations of Integers and Kolmogorov
  complexity</title><categories>math.LO cs.CC cs.LO</categories><comments>16 pages</comments><proxy>ccsd hal-00201627</proxy><journal-ref>Dans Denis Richard's 60th Biirthday Conference - Denis Richard's
  60th Biirthday Conference, France (2002)</journal-ref><abstract>  We consider classical representations of integers: Church's function
iterators, cardinal equivalence classes of sets, ordinal equivalence classes of
totally ordered sets. Since programs do not work on abstract entities and
require formal representations of objects, we effectivize these abstract
notions in order to allow them to be computed by programs. To any such
effectivized representation is then associated a notion of Kolmogorov
complexity. We prove that these Kolmogorov complexities form a strict hierarchy
which coincides with that obtained by relativization to jump oracles and/or
allowance of infinite computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0350</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0350</id><created>2008-01-02</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Grigorieff</keyname><forenames>Serge</forenames><affiliation>LIAFA</affiliation></author></authors><title>Refinment of the &quot;up to a constant&quot; ordering using contructive
  co-immunity and alike. Application to the Min/Max hierarchy of Kolmogorov
  complexities</title><categories>math.LO cs.CC</categories><comments>41 pages</comments><proxy>ccsd hal-00201625</proxy><abstract>  We introduce orderings between total functions f,g: N -&gt; N which refine the
pointwise &quot;up to a constant&quot; ordering &lt;=cte and also insure that f(x) is often
much less thang(x). With such orderings, we prove a strong hierarchy theorem
for Kolmogorov complexities obtained with jump oracles and/or Max or Min of
partial recursive functions. We introduce a notion of second order conditional
Kolmogorov complexity which yields a uniform bound for the &quot;up to a constant&quot;
comparisons involved in the hierarchy theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0351</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0351</id><created>2008-01-02</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Grigorieff</keyname><forenames>Serge</forenames><affiliation>LIAFA</affiliation></author></authors><title>Kolmogorov complexities Kmax, Kmin on computable partially ordered sets</title><categories>math.LO cs.LO</categories><comments>35 pages</comments><proxy>ccsd hal-00201621</proxy><journal-ref>Theoretical Computer Science 352 (2006) 159-180</journal-ref><abstract>  We introduce a machine free mathematical framework to get a natural
formalization of some general notions of infinite computation in the context of
Kolmogorov complexity. Namely, the classes Max^{X\to D}_{PR} and Max^{X\to
D}_{Rec} of functions X \to D which are pointwise maximum of partial or total
computable sequences of functions where D = (D,&lt;) is some computable partially
ordered set. The enumeration theorem and the invariance theorem always hold for
Max^{X\to D}_{PR}, leading to a variant KD;max of Kolmogorov complexity. We
characterize the orders D such that the enumeration theorem (resp. the
invariance theorem) also holds for Max^{X\to D}_{Rec} . It turns out that
Max^{X\to D}_{Rec} may satisfy the invariance theorem but not the enumeration
theorem. Also, when Max^{X\to D}_{Rec} satisfies the invariance theorem then
the Kolmogorov complexities associated to Max^{X\to D}_{Rec} and Max^{X\to
D}_{PR} are equal (up to a constant).
  Letting K^D_{min} = K^{D^{rev}}_{max}, where D^{rev} is the reverse order, we
prove that either K^D_{min} =_{ct} K^D_{max} =_{ct} K^D (=_{ct} is equality up
to a constant) or K^D_{min}, K^D_{max} are &lt;=_{ct} incomparable and &lt;_{ct} K^D
and &gt;_{ct} K^{0',D}. We characterize the orders leading to each case. We also
show that K^D_{min}, K^D_{max} cannot be both much smaller than K^D at any
point.
  These results are proved in a more general setting with two orders on D, one
extending the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0352</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0352</id><created>2008-01-02</created><authors><author><keyname>Sahai</keyname><forenames>Anant</forenames></author><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author></authors><title>The price of certainty: &quot;waterslide curves&quot; and the gap to capacity</title><categories>cs.IT math.IT</categories><comments>37 pages, 13 figures. Submitted to IEEE Transactions on Information
  Theory. This version corrects a subtle bug in the proofs of the original
  submission and improves the bounds significantly</comments><report-no>UCB/EECS-2008-1</report-no><abstract>  The classical problem of reliable point-to-point digital communication is to
achieve a low probability of error while keeping the rate high and the total
power consumption small. Traditional information-theoretic analysis uses
`waterfall' curves to convey the revolutionary idea that unboundedly low
probabilities of bit-error are attainable using only finite transmit power.
However, practitioners have long observed that the decoder complexity, and
hence the total power consumption, goes up when attempting to use sophisticated
codes that operate close to the waterfall curve.
  This paper gives an explicit model for power consumption at an idealized
decoder that allows for extreme parallelism in implementation. The decoder
architecture is in the spirit of message passing and iterative decoding for
sparse-graph codes. Generalized sphere-packing arguments are used to derive
lower bounds on the decoding power needed for any possible code given only the
gap from the Shannon limit and the desired probability of error. As the gap
goes to zero, the energy per bit spent in decoding is shown to go to infinity.
This suggests that to optimize total power, the transmitter should operate at a
power that is strictly above the minimum demanded by the Shannon capacity.
  The lower bound is plotted to show an unavoidable tradeoff between the
average bit-error probability and the total power used in transmission and
decoding. In the spirit of conventional waterfall curves, we call these
`waterslide' curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0353</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0353</id><created>2008-01-02</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Grigorieff</keyname><forenames>Serge</forenames><affiliation>LIAFA</affiliation></author></authors><title>Set theoretical Representations of Integers, I</title><categories>math.LO cs.CC</categories><comments>56 pages</comments><proxy>ccsd hal-00201608</proxy><journal-ref>Mathematical Logic Quaterly 52, Number 4 (2006) 375-403</journal-ref><doi>10.1002/malq.200510040</doi><abstract>  We reconsider some classical natural semantics of integers (namely iterators
of functions, cardinals of sets, index of equivalence relations), in the
perspective of Kolmogorov complexity. To each such semantics one can attach a
simple representation of integers that we suitably effectivize in order to
develop an associated Kolmogorov theory. Such effectivizations are particular
instances of a general notion of &quot;self-enumerated system&quot; that we introduce in
this paper. Our main result asserts that, with such effectivizations,
Kolmogorov theory allows to quantitatively distinguish the underlying
semantics. We characterize the families obtained by such effectivizations and
prove that the associated Kolmogorov complexities constitute a hierarchy which
coincides with that of Kolmogorov complexities defined via jump oracles and/or
infinite computations. This contrasts with the well-known fact that usual
Kolmogorov complexity does not depend (up to a constant) on the chosen
arithmetic representation of integers, let it be in any base unary, binary et
so on. Also, in a conceptual point of view, our result can be seen as a mean to
measure the degree of abstraction of these diverse semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0354</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0354</id><created>2008-01-02</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Grigorieff</keyname><forenames>Serge</forenames><affiliation>LIAFA</affiliation></author></authors><title>Kolmogorov complexity in perspective</title><categories>math.LO cs.CC cs.IT math.IT</categories><comments>37 pages</comments><proxy>ccsd hal-00201578</proxy><abstract>  We survey the diverse approaches to the notion of information content: from
Shannon entropy to Kolmogorov complexity. The main applications of Kolmogorov
complexity are presented namely, the mathematical notion of randomness (which
goes back to the 60's with the work of Martin-Lof, Schnorr, Chaitin, Levin),
and classification, which is a recent idea with provocative implementation by
Vitanyi and Cilibrasi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0386</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0386</id><created>2008-01-02</created><authors><author><keyname>Katsaros</keyname><forenames>Dimitrios</forenames></author><author><keyname>Akritidis</keyname><forenames>Leonidas</forenames></author><author><keyname>Bozanis</keyname><forenames>Panayiotis</forenames></author></authors><title>Spam: It's Not Just for Inboxes and Search Engines! Making Hirsch
  h-index Robust to Scientospam</title><categories>cs.DL cs.IR</categories><comments>2 figures, 3 tables</comments><abstract>  What is the 'level of excellence' of a scientist and the real impact of
his/her work upon the scientific thinking and practising? How can we design a
fair, an unbiased metric -- and most importantly -- a metric robust to
manipulation?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0390</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0390</id><created>2008-01-02</created><authors><author><keyname>Nock</keyname><forenames>Richard</forenames></author><author><keyname>Sanz</keyname><forenames>Nicolas</forenames></author><author><keyname>Celimene</keyname><forenames>Fred</forenames></author><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author></authors><title>Staring at Economic Aggregators through Information Lenses</title><categories>cs.IT cs.LG math.IT math.OC</categories><comments>18 pages, 2 tables, 3 figures</comments><abstract>  It is hard to exaggerate the role of economic aggregators -- functions that
summarize numerous and / or heterogeneous data -- in economic models since the
early XX$^{th}$ century. In many cases, as witnessed by the pioneering works of
Cobb and Douglas, these functions were information quantities tailored to
economic theories, i.e. they were built to fit economic phenomena. In this
paper, we look at these functions from the complementary side: information. We
use a recent toolbox built on top of a vast class of distortions coined by
Bregman, whose application field rivals metrics' in various subfields of
mathematics. This toolbox makes it possible to find the quality of an
aggregator (for consumptions, prices, labor, capital, wages, etc.), from the
standpoint of the information it carries. We prove a rather striking result.
  From the informational standpoint, well-known economic aggregators do belong
to the \textit{optimal} set. As common economic assumptions enter the analysis,
this large set shrinks, and it essentially ends up \textit{exactly fitting}
either CES, or Cobb-Douglas, or both. To summarize, in the relevant economic
contexts, one could not have crafted better some aggregator from the
information standpoint. We also discuss global economic behaviors of optimal
information aggregators in general, and present a brief panorama of the links
between economic and information aggregators.
  Keywords: Economic Aggregators, CES, Cobb-Douglas, Bregman divergences
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0398</identifier>
 <datestamp>2008-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0398</id><created>2008-01-02</created><updated>2008-01-10</updated><authors><author><keyname>Friedland</keyname><forenames>Shmuel</forenames></author></authors><title>On the graph isomorphism problem</title><categories>cs.CC cs.DM</categories><comments>12 pages</comments><acm-class>G.2.2; F.2.2</acm-class><abstract>  We relate the graph isomorphism problem to the solvability of certain systems
of linear equations with nonnegative variables. This version replaces the two
previous versions of this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0426</identifier>
 <datestamp>2008-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0426</id><created>2008-01-02</created><authors><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>Stojanovic</keyname><forenames>Milica</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>On the Relationship between Transmission Power and Capacity of an
  Underwater Acoustic Communication Channel</title><categories>cs.IT math.IT</categories><comments>6 pages, 9 Figures, Awaiting acceptance to IEEE Oceans 08
  (Conference), Kobe, Japan</comments><abstract>  The underwater acoustic channel is characterized by a path loss that depends
not only on the transmission distance, but also on the signal frequency. As a
consequence, transmission bandwidth depends on the transmission distance, a
feature that distinguishes an underwater acoustic system from a terrestrial
radio system. The exact relationship between power, transmission band, distance
and capacity for the Gaussian noise scenario is a complicated one. This work
provides a closed-form approximate model for 1) power consumption, 2) band-edge
frequency and 3) bandwidth as functions of distance and capacity required for a
data link. This approximate model is obtained by numerical evaluation of
analytical results which takes into account physical models of acoustic
propagation loss and ambient noise. The closed-form approximations may become
useful tools in the design and analysis of underwater acoustic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0452</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0452</id><created>2008-01-02</created><authors><author><keyname>Annapureddy</keyname><forenames>V. Sreekanth</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Sum Capacity of the Gaussian Interference Channel in the Low
  Interference Regime</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures, Proceedings of ITA Workshop, San Diego, CA,
  Jan-Feb, 2008</comments><abstract>  New upper bounds on the sum capacity of the two-user Gaussian interference
channel are derived. Using these bounds, it is shown that treating interference
as noise achieves the sum capacity if the interference levels are below certain
thresholds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0455</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0455</id><created>2008-01-02</created><authors><author><keyname>Liebeherr</keyname><forenames>Jorg</forenames></author><author><keyname>Fidler</keyname><forenames>Markus</forenames></author><author><keyname>Valaee</keyname><forenames>Shahrokh</forenames></author></authors><title>A System Theoretic Approach to Bandwidth Estimation</title><categories>cs.NI cs.PF</categories><comments>23 pages</comments><acm-class>C.4</acm-class><abstract>  It is shown that bandwidth estimation in packet networks can be viewed in
terms of min-plus linear system theory. The available bandwidth of a link or
complete path is expressed in terms of a {\em service curve}, which is a
function that appears in the network calculus to express the service available
to a traffic flow. The service curve is estimated based on measurements of a
sequence of probing packets or passive measurements of a sample path of
arrivals. It is shown that existing bandwidth estimation methods can be derived
in the min-plus algebra of the network calculus, thus providing further
mathematical justification for these methods. Principal difficulties of
estimating available bandwidth from measurement of network probes are related
to potential non-linearities of the underlying network. When networks are
viewed as systems that operate either in a linear or in a non-linear regime, it
is argued that probing schemes extract the most information at a point when the
network crosses from a linear to a non-linear regime. Experiments on the Emulab
testbed at the University of Utah evaluate the robustness of the system
theoretic interpretation of networks in practice. Multi-node experiments
evaluate how well the convolution operation of the min-plus algebra provides
estimates for the available bandwidth of a path from estimates of individual
links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0474</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0474</id><created>2008-01-02</created><authors><author><keyname>Clingerman</keyname><forenames>Christopher</forenames></author><author><keyname>Hemphill</keyname><forenames>Jeremiah</forenames></author><author><keyname>Proscia</keyname><forenames>Corey</forenames></author></authors><title>Analysis and Counterexamples Regarding Yatsenko's Polynomial-Time
  Algorithm for Solving the Traveling Salesman Problem</title><categories>cs.CC</categories><comments>10 pages, 8 figures, references arXiv:cs/0702133</comments><acm-class>F.2.1; G.1.6; I.2.8</acm-class><abstract>  Yatsenko gives a polynomial-time algorithm for solving the traveling salesman
problem. We examine the correctness of the algorithm and its construction. We
also comment on Yatsenko's evaluation of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0514</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0514</id><created>2008-01-03</created><authors><author><keyname>Arvind</keyname><forenames>V.</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Partha</forenames></author><author><keyname>Srinivasan</keyname><forenames>Srikanth</forenames></author></authors><title>New results on Noncommutative and Commutative Polynomial Identity
  Testing</title><categories>cs.CC</categories><comments>23 pages, no figure</comments><abstract>  Using ideas from automata theory we design a new efficient (deterministic)
identity test for the \emph{noncommutative} polynomial identity testing problem
(first introduced and studied in \cite{RS05,BW05}). We also apply this idea to
the reconstruction of black-box noncommuting algebraic branching programs.
Assuming the black-box model allows us to query the ABP for the output at any
given gate, we can reconstruct an (equivalent) ABP in deterministic polynomial
time. Finally, we explore commutative identity testing when the coefficients of
the input polynomial come from an arbitrary finite commutative ring with unity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0523</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0523</id><created>2008-01-03</created><authors><author><keyname>De Dinechin</keyname><forenames>Florent</forenames><affiliation>LIP</affiliation></author><author><keyname>Lauter</keyname><forenames>Christoph Quirin</forenames><affiliation>LIP</affiliation></author><author><keyname>Melquiond</keyname><forenames>Guillaume</forenames><affiliation>LIP</affiliation></author></authors><title>Certifying floating-point implementations using Gappa</title><categories>cs.NA cs.MS</categories><proxy>ccsd ensl-00200830</proxy><abstract>  High confidence in floating-point programs requires proving numerical
properties of final and intermediate values. One may need to guarantee that a
value stays within some range, or that the error relative to some ideal value
is well bounded. Such work may require several lines of proof for each line of
code, and will usually be broken by the smallest change to the code (e.g. for
maintenance or optimization purpose). Certifying these programs by hand is
therefore very tedious and error-prone. This article discusses the use of the
Gappa proof assistant in this context. Gappa has two main advantages over
previous approaches: Its input format is very close to the actual C code to
validate, and it automates error evaluation and propagation using interval
arithmetic. Besides, it can be used to incrementally prove complex mathematical
properties pertaining to the C code. Yet it does not require any specific
knowledge about automatic theorem proving, and thus is accessible to a wide
community. Moreover, Gappa may generate a formal proof of the results that can
be checked independently by a lower-level proof assistant like Coq, hence
providing an even higher confidence in the certification of the numerical code.
The article demonstrates the use of this tool on a real-size example, an
elementary function with correctly rounded output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0533</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0533</id><created>2008-01-03</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author><author><keyname>Simonnet</keyname><forenames>Pierre</forenames><affiliation>SPE</affiliation></author></authors><title>Topology and Ambiguity in Omega Context Free Languages</title><categories>cs.LO math.LO</categories><proxy>ccsd hal-00109923</proxy><journal-ref>Bulletin of the Belgian Mathematical Society 10 (5) (2003) 707-722</journal-ref><abstract>  We study the links between the topological complexity of an omega context
free language and its degree of ambiguity. In particular, using known facts
from classical descriptive set theory, we prove that non Borel omega context
free languages which are recognized by B\&quot;uchi pushdown automata have a maximum
degree of ambiguity. This result implies that degrees of ambiguity are really
not preserved by the operation of taking the omega power of a finitary context
free language. We prove also that taking the adherence or the delta-limit of a
finitary language preserves neither unambiguity nor inherent ambiguity. On the
other side we show that methods used in the study of omega context free
languages can also be applied to study the notion of ambiguity in infinitary
rational relations accepted by B\&quot;uchi 2-tape automata and we get first results
in that direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0534</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0534</id><created>2008-01-03</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>On the Length of the Wadge Hierarchy of Omega Context Free Languages</title><categories>cs.LO cs.CC cs.GT math.LO</categories><proxy>ccsd hal-00122154</proxy><journal-ref>Journal of Automata, Languages and Combinatorics 10 (4) (2005)
  439-464</journal-ref><abstract>  We prove in this paper that the length of the Wadge hierarchy of omega
context free languages is greater than the Cantor ordinal epsilon_omega, which
is the omega-th fixed point of the ordinal exponentiation of base omega. The
same result holds for the conciliating Wadge hierarchy, defined by J. Duparc,
of infinitary context free languages, studied by D. Beauquier. We show also
that there exist some omega context free languages which are
Sigma^0_omega-complete Borel sets, improving previous results on omega context
free languages and the Borel hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0535</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0535</id><created>2008-01-03</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>An omega-Power of a Finitary Language Which is a Borel Set of Infinite
  Rank</title><categories>cs.LO math.LO</categories><proxy>ccsd hal-00108219</proxy><journal-ref>Fundamenta Informaticae 62 (3-4) (2004) 333-342</journal-ref><abstract>  Omega-powers of finitary languages are omega languages in the form V^omega,
where V is a finitary language over a finite alphabet X. Since the set of
infinite words over X can be equipped with the usual Cantor topology, the
question of the topological complexity of omega-powers naturally arises and has
been raised by Niwinski, by Simonnet, and by Staiger. It has been recently
proved that for each integer n &gt; 0, there exist some omega-powers of context
free languages which are Pi^0_n-complete Borel sets, and that there exists a
context free language L such that L^omega is analytic but not Borel. But the
question was still open whether there exists a finitary language V such that
V^omega is a Borel set of infinite rank. We answer this question in this paper,
giving an example of a finitary language whose omega-power is Borel of infinite
rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0537</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0537</id><created>2008-01-03</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author><author><keyname>Ressayre</keyname><forenames>Jean-Pierre</forenames><affiliation>ELM</affiliation></author><author><keyname>Simonnet</keyname><forenames>Pierre</forenames><affiliation>SPE</affiliation></author></authors><title>On Infinite Real Trace Rational Languages of Maximum Topological
  Complexity</title><categories>cs.LO math.LO</categories><proxy>ccsd hal-00109918</proxy><journal-ref>Zapiski Nauchnyh Seminarov POMI 316 (2004) 205-223</journal-ref><abstract>  We consider the set of infinite real traces, over a dependence alphabet
(Gamma, D) with no isolated letter, equipped with the topology induced by the
prefix metric. We then prove that all rational languages of infinite real
traces are analytic sets and that there exist some rational languages of
infinite real traces which are analytic but non Borel sets, and even
Sigma^1_1-complete, hence of maximum possible topological complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0540</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0540</id><created>2008-01-03</created><authors><author><keyname>Farkas</keyname><forenames>L&#xf3;r&#xe1;nt</forenames></author></authors><title>Blind decoding of Linear Gaussian channels with ISI, capacity, error
  exponent, universality</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure</comments><abstract>  A new straightforward universal blind detection algorithm for linear Gaussian
channel with ISI is given. A new error exponent is derived, which is better
than Gallager's random coding error exponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0575</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0575</id><created>2008-01-03</created><authors><author><keyname>Das</keyname><forenames>Manik Lal</forenames></author></authors><title>A Flexible and Secure Remote Systems Authentication Scheme Using Smart
  Cards</title><categories>cs.CR</categories><journal-ref>Published in the Transactions on Electronics, Computer and
  Communication, 1(2):78-82, 2006</journal-ref><abstract>  The paper presents an authentication scheme for remote systems using smart
card. The scheme prevents the scenario of many logged in users with the same
login identity, and does not require password/verifier table to validate the
users' login request. The scheme provides a user-friendly password change
option, and withstands the replay, impersonation, stolen-verifier, guessing,
and denial-of-service attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0581</identifier>
 <datestamp>2008-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0581</id><created>2008-01-03</created><authors><author><keyname>Rezki</keyname><forenames>Z.</forenames></author><author><keyname>Haccoun</keyname><forenames>David</forenames></author><author><keyname>Gagnon</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Capacity of The Discrete-Time Non-Coherent Memoryless Rayleigh Fading
  Channels at Low SNR</title><categories>cs.IT math.IT</categories><comments>26 pages, 5 figues, submitted to IEEE Trans. on Information Theory,
  Septembre 2007</comments><abstract>  The capacity of a discrete-time memoryless channel, in which successive
symbols fade independently, and where the channel state information (CSI) is
neither available at the transmitter nor at the receiver, is considered at low
SNR. We derive a closed form expression of the optimal capacity-achieving input
distribution at low signal-to-noise ratio (SNR) and give the exact capacity of
a non-coherent channel at low SNR. The derived relations allow to better
understanding the capacity of non-coherent channels at low SNR and bring an
analytical answer to the peculiar behavior of the optimal input distribution
observed in a previous work by Abou Faycal, Trott and Shamai. Then, we compute
the non-coherence penalty and give a more precise characterization of the
sub-linear term in SNR. Finally, in order to better understand how the optimal
input varies with SNR, upper and lower bounds on the capacity-achieving input
are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0586</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0586</id><created>2008-01-03</created><updated>2008-12-18</updated><authors><author><keyname>Jeronimo</keyname><forenames>Gabriela</forenames></author><author><keyname>Perrucci</keyname><forenames>Daniel</forenames></author><author><keyname>Sabia</keyname><forenames>Juan</forenames></author></authors><title>On sign conditions over real multivariate polynomials</title><categories>math.AG cs.CG cs.SC</categories><comments>extended version</comments><msc-class>14P10; 14Q20; 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new probabilistic algorithm to find a finite set of points
intersecting the closure of each connected component of the realization of
every sign condition over a family of real polynomials defining regular
hypersurfaces that intersect transversally. This enables us to show a
probabilistic procedure to list all feasible sign conditions over the
polynomials. In addition, we extend these results to the case of closed sign
conditions over an arbitrary family of real multivariate polynomials. The
complexity bounds for these procedures improve the known ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0590</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0590</id><created>2008-01-03</created><updated>2008-01-09</updated><authors><author><keyname>Kettani</keyname><forenames>Omar</forenames></author></authors><title>An algorithm for finding the Independence Number of a graph</title><categories>cs.DM cs.DS</categories><comments>15 pages; a corrected proof for the second method is added</comments><acm-class>F.2.2</acm-class><abstract>  In this paper, we prove that for every connected graph G, there exists a
split graph H with the same independence number and the same order. Then we
propose a first algorithm for finding this graph, given the degree sequence of
the input graph G. Further, we propose a second algorithm for finding the
independence number of G, given the adjacency matrix of G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0597</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0597</id><created>2008-01-03</created><authors><author><keyname>Chen</keyname><forenames>Min</forenames></author><author><keyname>Serbetli</keyname><forenames>Semih</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Distributed Power Allocation Strategies for Parallel Relay Networks</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Wireless Communications, accepted for
  publication. 10 pages, 7 figures</comments><abstract>  We consider a source-destination pair assisted by parallel regenerative
decode-and-forward relays operating in orthogonal channels. We investigate
distributed power allocation strategies for this system with limited channel
state information at the source and the relay nodes. We first propose a
distributed decision mechanism for each relay to individually make its decision
on whether to forward the source data. The decision mechanism calls for each
relay that is able to decode the information from the source to compare its
relay-to-destination channel gain with a given threshold. We identify the
optimum distributed power allocation strategy that minimizes the total transmit
power while providing a target signal-to-noise ratio at the destination with a
target outage probability. The strategy dictates the optimum choices for the
source power as well as the threshold value at the relays. Next, we consider
two simpler distributed power allocation strategies, namely the passive source
model where the source power and the relay threshold are fixed, and the single
relay model where only one relay is allowed to forward the source data. These
models are motivated by limitations on the available channel state information
as well as ease of implementation as compared to the optimum distributed
strategy. Simulation results are presented to demonstrate the performance of
the proposed distributed power allocation schemes. Specifically, we observe
significant power savings with proposed methods as compared to random relay
selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0609</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0609</id><created>2008-01-03</created><authors><author><keyname>Butler</keyname><forenames>Raymond J.</forenames></author></authors><title>Applying the CobiT Control Framework to Spreadsheet Developments</title><categories>cs.SE cs.CY</categories><comments>6 Pages</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2001 7-13 ISBN:1 86166
  179 7</journal-ref><abstract>  One of the problems reported by researchers and auditors in the field of
spreadsheet risks is that of getting and keeping managements attention to the
problem. Since 1996, the Information Systems Audit &amp; Control Foundation and the
IT Governance Institute have published CobiT which brings mainstream IT control
issues into the corporate governance arena. This paper illustrates how
spreadsheet risk and control issues can be mapped onto the CobiT framework and
thus brought to managers attention in a familiar format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0625</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0625</id><created>2008-01-03</created><authors><author><keyname>Lian</keyname><forenames>Shiguo</forenames></author></authors><title>On the Robustness of the Delay-Based Fingerprint Embedding Scheme</title><categories>cs.MM cs.SD</categories><comments>9 pages,6 figures</comments><acm-class>D.2.11; H.5.1; H.5.5</acm-class><abstract>  The delay-based fingerprint embedding was recently proposed to support more
users in secure media distribution scenario. In this embedding scheme, some
users are assigned the same fingerprint code with only different embedding
delay. The algorithm's robustness against collusion attacks is investigated.
However, its robustness against common desynchronization attacks, e.g.,
cropping and time shifting, is not considered. In this paper, desynchronization
attacks are used to break the delay-based fingerprint embedding algorithm. To
improve the robustness, two means are proposed to keep the embedded fingerprint
codes synchronized, i.e., adding a synchronization fingerprint and adopting the
relative delay to detect users. Analyses and experiments are given to show the
improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0649</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0649</id><created>2008-01-04</created><authors><author><keyname>Prost</keyname><forenames>F.</forenames></author><author><keyname>Zerrari</keyname><forenames>C.</forenames></author></authors><title>A logical analysis of entanglement and separability in quantum
  higher-order functions</title><categories>cs.LO</categories><comments>19 pages</comments><acm-class>F.3.1; D.2.1; D.2.4; D.3.1</acm-class><doi>10.1007/978-3-642-03745-0_25</doi><abstract>  We present a logical separability analysis for a functional quantum
computation language. This logic is inspired by previous works on logical
analysis of aliasing for imperative functional programs. Both analyses share
similarities notably because they are highly non-compositional. Quantum setting
is harder to deal with since it introduces non determinism and thus
considerably modifies semantics and validity of logical assertions. This logic
is the first proposal of entanglement/separability analysis dealing with a
functional quantum programming language with higher-order functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0665</identifier>
 <datestamp>2008-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0665</id><created>2008-01-04</created><authors><author><keyname>Durand</keyname><forenames>Fabien</forenames><affiliation>LAMFA</affiliation></author></authors><title>A theorem of Cobham for non-primitive substitutions</title><categories>math.CO cs.DM</categories><proxy>ccsd hal-00202073</proxy><msc-class>68R15</msc-class><journal-ref>Acta Arithmetica 104, 3 (2002) 225-241</journal-ref><abstract>  In this article we generalize Cobham theorem to a large class of
substitutions including non primitive and non constant length substitutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0672</identifier>
 <datestamp>2008-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0672</id><created>2008-01-04</created><updated>2008-05-01</updated><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author></authors><title>On Multipath Fading Channels at High SNR</title><categories>cs.IT math.IT</categories><comments>To be presented at the 2008 IEEE Symposium on Information Theory
  (ISIT), Toronto, Canada; replaced with version that appears in the
  proceedings</comments><abstract>  This paper studies the capacity of discrete-time multipath fading channels.
It is assumed that the number of paths is finite, i.e., that the channel output
is influenced by the present and by the L previous channel inputs. A
noncoherent channel model is considered where neither transmitter nor receiver
are cognizant of the fading's realization, but both are aware of its statistic.
The focus is on capacity at high signal-to-noise ratios (SNR). In particular,
the capacity pre-loglog - defined as the limiting ratio of the capacity to
loglog SNR as SNR tends to infinity - is studied. It is shown that,
irrespective of the number paths L, the capacity pre-loglog is 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0677</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0677</id><created>2008-01-04</created><authors><author><keyname>Attie</keyname><forenames>Paul C.</forenames></author></authors><title>Finite-state concurrent programs can be expressed pairwise</title><categories>cs.LO</categories><comments>14 pages</comments><abstract>  We present a \emph{pairwise normal form} for finite-state shared memory
concurrent programs: all variables are shared between exactly two processes,
and the guards on transitions are conjunctions of conditions over this pairwise
shared state. This representation has been used to efficiently (in polynomial
time) synthesize and model-check correctness properties of concurrent programs.
Our main result is that any finite state concurrent program can be transformed
into pairwise normal form. Specifically, if $Q$ is an arbitrary finite-state
shared memory concurrent program, then there exists a finite-state shared
memory concurrent program $P$ expressed in pairwise normal form such that $P$
is strongly bisimilar to $Q$. Our result is constructive: we give an algorithm
for producing $P$, given $Q$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0678</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0678</id><created>2008-01-04</created><authors><author><keyname>Marli&#xe8;re</keyname><forenames>Sylvain</forenames><affiliation>ICA</affiliation></author><author><keyname>Florens</keyname><forenames>Jean Loup</forenames><affiliation>ICA</affiliation></author><author><keyname>Marchi</keyname><forenames>Florence</forenames><affiliation>ESRF, NEEL</affiliation></author><author><keyname>Luciani</keyname><forenames>Annie</forenames><affiliation>ICA</affiliation></author><author><keyname>Chevrier</keyname><forenames>Joel</forenames><affiliation>ESRF, NEEL</affiliation></author></authors><title>Implementation of perception and action at nanoscale</title><categories>cs.RO cs.HC</categories><comments>Proceedings of ENACTIVE/07 4th International Conference on Enactive
  Interfaces Grenoble, France, November 19th-22nd, 2007</comments><proxy>ccsd hal-00202063</proxy><abstract>  Real time combination of nanosensors and nanoactuators with virtual reality
environment and multisensorial interfaces enable us to efficiently act and
perceive at nanoscale. Advanced manipulation of nanoobjects and new strategies
for scientific education are the key motivations. We have no existing intuitive
representation of the nanoworld ruled by laws foreign to our experience. A
central challenge is then the construction of nanoworld simulacrum that we can
start to visit and to explore. In this nanoworld simulacrum, object
identifications will be based on probed entity physical and chemical intrinsic
properties, on their interactions with sensors and on the final choices made in
building a multisensorial interface so that these objects become coherent
elements of the human sphere of action and perception. Here we describe a 1D
virtual nanomanipulator, part of the Cit\'e des Sciences EXPO NANO in Paris,
that is the first realization based on this program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0701</identifier>
 <datestamp>2008-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0701</id><created>2008-01-04</created><updated>2008-02-06</updated><authors><author><keyname>Nutman</keyname><forenames>Leah</forenames></author><author><keyname>Langberg</keyname><forenames>Michael</forenames></author></authors><title>Adversarial Models and Resilient Schemes for Network Coding</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>Second version includes minor editing</comments><abstract>  In a recent paper, Jaggi et al. (INFOCOM 2007), presented a distributed
polynomial-time rate-optimal network-coding scheme that works in the presence
of Byzantine faults. We revisit their adversarial models and augment them with
three, arguably realistic, models. In each of the models, we present a
distributed scheme that demonstrates the usefulness of the model. In
particular, all of the schemes obtain optimal rate $C-z$, where $C$ is the
network capacity and $z$ is a bound on the number of links controlled by the
adversary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0714</identifier>
 <datestamp>2008-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0714</id><created>2008-01-04</created><authors><author><keyname>Cheney</keyname><forenames>James</forenames></author></authors><title>Regular Expression Subtyping for XML Query and Update Languages</title><categories>cs.PL cs.DB</categories><comments>ESOP 2008. Companion technical report with proofs</comments><abstract>  XML database query languages such as XQuery employ regular expression types
with structural subtyping. Subtyping systems typically have two presentations,
which should be equivalent: a declarative version in which the subsumption rule
may be used anywhere, and an algorithmic version in which the use of
subsumption is limited in order to make typechecking syntax-directed and
decidable. However, the XQuery standard type system circumvents this issue by
using imprecise typing rules for iteration constructs and defining only
algorithmic typechecking, and another extant proposal provides more precise
types for iteration constructs but ignores subtyping. In this paper, we
consider a core XQuery-like language with a subsumption rule and prove the
completeness of algorithmic typechecking; this is straightforward for XQuery
proper but requires some care in the presence of more precise iteration typing
disciplines. We extend this result to an XML update language we have introduced
in earlier work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0715</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0715</id><created>2008-01-04</created><authors><author><keyname>Powell</keyname><forenames>Stephen G.</forenames></author><author><keyname>Lawson</keyname><forenames>Barry</forenames></author><author><keyname>Baker</keyname><forenames>Kenneth R.</forenames></author></authors><title>Impact of Errors in Operational Spreadsheets</title><categories>cs.CY</categories><comments>12 pages including references</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2007 57-68 ISBN
  978-905617-58-6</journal-ref><abstract>  All users of spreadsheets struggle with the problem of errors. Errors are
thought to be prevalent in spreadsheets, and in some instances they have cost
organizations millions of dollars. In a previous study of 50 operational
spreadsheets we found errors in 0.8% to 1.8% of all formula cells, depending on
how errors are defined. In the current study we estimate the quantitative
impacts of errors in 25 operational spreadsheets from five different
organizations. We find that many errors have no quantitative impact on the
spreadsheet. Those that have an impact often affect unimportant portions of the
spreadsheet. The remaining errors do sometimes have substantial impacts on key
aspects of the spreadsheet. This paper provides the first fully-documented
evidence on the quantitative impact of errors in operational spreadsheets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0756</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0756</id><created>2008-01-04</created><updated>2008-11-12</updated><authors><author><keyname>Ma</keyname><forenames>Nan</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>Distributed Source Coding for Interactive Function Computation</title><categories>cs.IT math.IT</categories><comments>30 pages, 6 figures. This work has been submitted to the IEEE for
  possible publication. Parts of this work were presented at 2008 IEEE
  International Symposium on Information Theory (ISIT'08)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-terminal interactive distributed source coding problem with alternating
messages for function computation at both locations is studied. For any number
of messages, a computable characterization of the rate region is provided in
terms of single-letter information measures. While interaction is useless in
terms of the minimum sum-rate for lossless source reproduction at one or both
locations, the gains can be arbitrarily large for function computation even
when the sources are independent. For a class of sources and functions,
interaction is shown to be useless, even with infinite messages, when a
function has to be computed at only one location, but is shown to be useful, if
functions have to be computed at both locations. For computing the Boolean AND
function of two independent Bernoulli sources at both locations, an achievable
infinite-message sum-rate with infinitesimal-rate messages is derived in terms
of a two-dimensional definite integral and a rate-allocation curve. A general
framework for multiterminal interactive function computation based on an
information exchange protocol which successively switches among different
distributed source coding configurations is developed. For networks with a star
topology, multiple rounds of interactive coding is shown to decrease the
scaling law of the total network rate by an order of magnitude as the network
grows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0813</identifier>
 <datestamp>2008-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0813</id><created>2008-01-05</created><authors><author><keyname>Selinger</keyname><forenames>Peter</forenames><affiliation>Dalhousie University</affiliation></author><author><keyname>Valiron</keyname><forenames>Beno&#xee;t</forenames><affiliation>University of Ottawa</affiliation></author></authors><title>A linear-non-linear model for a computational call-by-value lambda
  calculus (extended abstract)</title><categories>cs.LO</categories><comments>15 pages. Preprint, to appear in the proceedings of FOSSACS'08</comments><acm-class>D.3.1; F.4.1</acm-class><abstract>  We give a categorical semantics for a call-by-value linear lambda calculus.
Such a lambda calculus was used by Selinger and Valiron as the backbone of a
functional programming language for quantum computation. One feature of this
lambda calculus is its linear type system, which includes a duplicability
operator &quot;!&quot; as in linear logic. Another main feature is its call-by-value
reduction strategy, together with a side-effect to model probabilistic
measurements. The &quot;!&quot; operator gives rise to a comonad, as in the linear logic
models of Seely, Bierman, and Benton. The side-effects give rise to a monad, as
in Moggi's computational lambda calculus. It is this combination of a monad and
a comonad that makes the present paper interesting. We show that our
categorical semantics is sound and complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0815</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0815</id><created>2008-01-05</created><updated>2008-12-17</updated><authors><author><keyname>Kochman</keyname><forenames>Yuval</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author></authors><title>Joint Wyner-Ziv/Dirty Paper coding by modulo-lattice modulation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. Presented in
  part in ISIT-2006, Seattle. New version after review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The combination of source coding with decoder side-information (Wyner-Ziv
problem) and channel coding with encoder side-information (Gel'fand-Pinsker
problem) can be optimally solved using the separation principle. In this work
we show an alternative scheme for the quadratic-Gaussian case, which merges
source and channel coding. This scheme achieves the optimal performance by a
applying modulo-lattice modulation to the analog source. Thus it saves the
complexity of quantization and channel decoding, and remains with the task of
&quot;shaping&quot; only. Furthermore, for high signal-to-noise ratio (SNR), the scheme
approaches the optimal performance using an SNR-independent encoder, thus it is
robust to unknown SNR at the encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0821</identifier>
 <datestamp>2008-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0821</id><created>2008-01-06</created><updated>2008-04-29</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Brun</keyname><forenames>Todd A.</forenames></author></authors><title>Unified Quantum Convolutional Coding</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 1 figure, Accepted for publication in the Proceedings of the
  2008 IEEE International Symposium on Information Theory (ISIT 2008)</comments><report-no>CSI-08-01-01</report-no><journal-ref>Proceedings of the 2008 International Symposium on Information
  Theory, pp. 359-363, Toronto, Ontario, Canada, July 2008.</journal-ref><doi>10.1109/ISIT.2008.4595008</doi><abstract>  We outline a quantum convolutional coding technique for protecting a stream
of classical bits and qubits. Our goal is to provide a framework for designing
codes that approach the ``grandfather'' capacity of an entanglement-assisted
quantum channel for sending classical and quantum information simultaneously.
Our method incorporates several resources for quantum redundancy: fresh ancilla
qubits, entangled bits, and gauge qubits. The use of these diverse resources
gives our technique the benefits of both active and passive quantum error
correction. We can encode a classical-quantum bit stream with periodic quantum
gates because our codes possess a convolutional structure. We end with an
example of a ``grandfather'' quantum convolutional code that protects one qubit
and one classical bit per frame by encoding them with one fresh ancilla qubit,
one entangled bit, and one gauge qubit per frame. We explicitly provide the
encoding and decoding circuits for this example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0830</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0830</id><created>2008-01-05</created><updated>2012-03-28</updated><authors><author><keyname>Baydin</keyname><forenames>Atilim Gunes</forenames></author></authors><title>Evolution of central pattern generators for the control of a five-link
  bipedal walking mechanism</title><categories>cs.NE cs.RO</categories><comments>11 pages, 9 figures; substantial revision of content, organization,
  and quantitative results</comments><msc-class>92B20, 92B25, 70E60, 68T05, 68U20</msc-class><acm-class>I.2.2; I.2.9</acm-class><journal-ref>Paladyn. Journal of Behavioral Robotics 3(1), 45-53 (2012)</journal-ref><doi>10.2478/s13230-012-0019-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Central pattern generators (CPGs), with a basis is neurophysiological
studies, are a type of neural network for the generation of rhythmic motion.
While CPGs are being increasingly used in robot control, most applications are
hand-tuned for a specific task and it is acknowledged in the field that generic
methods and design principles for creating individual networks for a given task
are lacking. This study presents an approach where the connectivity and
oscillatory parameters of a CPG network are determined by an evolutionary
algorithm with fitness evaluations in a realistic simulation with accurate
physics. We apply this technique to a five-link planar walking mechanism to
demonstrate its feasibility and performance. In addition, to see whether
results from simulation can be acceptably transferred to real robot hardware,
the best evolved CPG network is also tested on a real mechanism. Our results
also confirm that the biologically inspired CPG model is well suited for legged
locomotion, since a diverse manifestation of networks have been observed to
succeed in fitness simulations during evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0841</identifier>
 <datestamp>2008-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0841</id><created>2008-01-06</created><authors><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Shapiro</keyname><forenames>Jeffrey H.</forenames></author><author><keyname>Erkmen</keyname><forenames>Baris I.</forenames></author></authors><title>Capacity of the Bosonic Wiretap Channel and the Entropy Photon-Number
  Inequality</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 1 figure, submitted to ISIT 2008</comments><abstract>  Determining the ultimate classical information carrying capacity of
electromagnetic waves requires quantum-mechanical analysis to properly account
for the bosonic nature of these waves. Recent work has established capacity
theorems for bosonic single-user and broadcast channels, under the presumption
of two minimum output entropy conjectures. Despite considerable accumulated
evidence that supports the validity of these conjectures, they have yet to be
proven. In this paper, it is shown that the second conjecture suffices to prove
the classical capacity of the bosonic wiretap channel, which in turn would also
prove the quantum capacity of the lossy bosonic channel. The preceding minimum
output entropy conjectures are then shown to be simple consequences of an
Entropy Photon-Number Inequality (EPnI), which is a conjectured
quantum-mechanical analog of the Entropy Power Inequality (EPI) form classical
information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0857</identifier>
 <datestamp>2008-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0857</id><created>2008-01-06</created><authors><author><keyname>Hu</keyname><forenames>Lei</forenames></author><author><keyname>Zeng</keyname><forenames>Xiangyong</forenames></author><author><keyname>Li</keyname><forenames>Nian</forenames></author><author><keyname>Jiang</keyname><forenames>Wenfeng</forenames></author></authors><title>Period-Different $m$-Sequences With At Most A Four-Valued Cross
  Correlation</title><categories>cs.IT cs.DM math.IT</categories><comments>9 pages</comments><abstract>  In this paper, we follow the recent work of Helleseth, Kholosha, Johanssen
and Ness to study the cross correlation between an $m$-sequence of period
$2^m-1$ and the $d$-decimation of an $m$-sequence of shorter period $2^{n}-1$
for an even number $m=2n$. Assuming that $d$ satisfies $d(2^l+1)=2^i({\rm mod}
2^n-1)$ for some $l$ and $i$, we prove the cross correlation takes exactly
either three or four values, depending on ${\rm gcd}(l,n)$ is equal to or
larger than 1. The distribution of the correlation values is also completely
determined. Our result confirms the numerical phenomenon Helleseth et al found.
It is conjectured that there are no more other cases of $d$ that give at most a
four-valued cross correlation apart from the ones proved here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0882</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0882</id><created>2008-01-06</created><updated>2008-03-17</updated><authors><author><keyname>Jones</keyname><forenames>Neil D.</forenames></author><author><keyname>Bohr</keyname><forenames>Nina</forenames></author></authors><title>Call-by-value Termination in the Untyped lambda-calculus</title><categories>cs.PL</categories><acm-class>F.3.2; D.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 1 (March 17,
  2008) lmcs:915</journal-ref><doi>10.2168/LMCS-4(1:3)2008</doi><abstract>  A fully-automated algorithm is developed able to show that evaluation of a
given untyped lambda-expression will terminate under CBV (call-by-value). The
``size-change principle'' from first-order programs is extended to arbitrary
untyped lambda-expressions in two steps. The first step suffices to show CBV
termination of a single, stand-alone lambda;-expression. The second suffices to
show CBV termination of any member of a regular set of lambda-expressions,
defined by a tree grammar. (A simple example is a minimum function, when
applied to arbitrary Church numerals.) The algorithm is sound and proven so in
this paper. The Halting Problem's undecidability implies that any sound
algorithm is necessarily incomplete: some lambda-expressions may in fact
terminate under CBV evaluation, but not be recognised as terminating.
  The intensional power of the termination algorithm is reasonably high. It
certifies as terminating many interesting and useful general recursive
algorithms including programs with mutual recursion and parameter exchanges,
and Colson's ``minimum'' algorithm. Further, our type-free approach allows use
of the Y combinator, and so can identify as terminating a substantial subset of
PCF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0931</identifier>
 <datestamp>2008-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0931</id><created>2008-01-07</created><updated>2008-01-23</updated><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Shibuya</keyname><forenames>Tomoharu</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>The Asymptotic Bit Error Probability of LDPC Codes for the Binary
  Erasure Channel with Finite Iteration Number</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, correcting errors in Theorem 1 and poor English</comments><abstract>  We consider communication over the binary erasure channel (BEC) using
low-density parity-check (LDPC) code and belief propagation (BP) decoding. The
bit error probability for infinite block length is known by density evolution
and it is well known that a difference between the bit error probability at
finite iteration number for finite block length $n$ and for infinite block
length is asymptotically $\alpha/n$, where $\alpha$ is a specific constant
depending on the degree distribution, the iteration number and the erasure
probability. Our main result is to derive an efficient algorithm for
calculating $\alpha$ for regular ensembles. The approximation using $\alpha$ is
accurate for $(2,r)$-regular ensembles even in small block length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0938</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0938</id><created>2008-01-07</created><updated>2009-07-16</updated><authors><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Cognitive Networks Achieve Throughput Scaling of a Homogeneous Network</title><categories>cs.IT math.IT</categories><comments>28 pages, 12 figures, submitted to IEEE Trans. on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 8, pp.
  5103-5115, Aug. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two distinct, but overlapping, networks that operate at the same
time, space, and frequency. The first network consists of $n$ randomly
distributed \emph{primary users}, which form either an ad hoc network, or an
infrastructure-supported ad hoc network with $l$ additional base stations. The
second network consists of $m$ randomly distributed, ad hoc secondary users or
cognitive users. The primary users have priority access to the spectrum and do
not need to change their communication protocol in the presence of secondary
users. The secondary users, however, need to adjust their protocol based on
knowledge about the locations of the primary nodes to bring little loss to the
primary network's throughput. By introducing preservation regions around
primary receivers and avoidance regions around primary base stations, we
propose two modified multihop routing protocols for the cognitive users. Base
on percolation theory, we show that when the secondary network is denser than
the primary network, both networks can simultaneously achieve the same
throughput scaling law as a stand-alone network. Furthermore, the primary
network throughput is subject to only a vanishingly fractional loss.
Specifically, for the ad hoc and the infrastructure-supported primary models,
the primary network achieves sum throughputs of order $n^{1/2}$ and
$\max\{n^{1/2},l\}$, respectively. For both primary network models, for any
$\delta&gt;0$, the secondary network can achieve sum throughput of order
$m^{1/2-\delta}$ with an arbitrarily small fraction of outage. Thus, almost all
secondary source-destination pairs can communicate at a rate of order
$m^{-1/2-\delta}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0949</identifier>
 <datestamp>2008-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0949</id><created>2008-01-07</created><authors><author><keyname>Attie</keyname><forenames>Paul C.</forenames></author></authors><title>On the Refinement of Liveness Properties of Distributed Systems</title><categories>cs.LO</categories><comments>54 pages, 12 figures</comments><abstract>  We present a new approach for reasoning about liveness properties of
distributed systems, represented as automata. Our approach is based on
simulation relations, and requires reasoning only over finite execution
fragments. Current simulation-relation based methods for reasoning about
liveness properties of automata require reasoning over entire executions, since
they involve a proof obligation of the form: if a concrete and abstract
execution ``correspond'' via the simulation, and the concrete execution is
live, then so is the abstract execution.
  Our contribution consists of (1) a formalism for defining liveness
properties, (2) a proof method for liveness properties based on that formalism,
and (3) two expressive completeness results: firstly, our formalism can express
any liveness property which satisfies a natural ``robustness'' condition, and
secondly, our formalism can express any liveness property at all, provided that
history variables can be used
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0969</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0969</id><created>2008-01-07</created><authors><author><keyname>Gonzalez-Estevez</keyname><forenames>J.</forenames></author><author><keyname>Cosenza</keyname><forenames>M. G.</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>R.</forenames></author><author><keyname>Sanchez</keyname><forenames>J. R.</forenames></author></authors><title>Pareto and Boltzmann-Gibbs behaviors in a deterministic multi-agent
  system</title><categories>q-fin.GN cond-mat.stat-mech cs.MA nlin.AO nlin.CD physics.comp-ph physics.soc-ph</categories><comments>9 pages, 9 color .eps figures, submitted to Physica A</comments><doi>10.1016/j.physa.2008.03.013</doi><abstract>  A deterministic system of interacting agents is considered as a model for
economic dynamics. The dynamics of the system is described by a coupled map
lattice with near neighbor interactions. The evolution of each agent results
from the competition between two factors: the agent's own tendency to grow and
the environmental influence that moderates this growth. Depending on the values
of the parameters that control these factors, the system can display Pareto or
Boltzmann-Gibbs statistical behaviors in its asymptotic dynamical regime. The
regions where these behaviors appear are calculated on the space of parameters
of the system. Other statistical properties, such as the mean wealth, the
standard deviation, and the Gini coefficient characterizing the degree of
equity in the wealth distribution are also calculated on the space of
parameters of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1002</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1002</id><created>2008-01-07</created><updated>2008-01-29</updated><authors><author><keyname>Schuster</keyname><forenames>Ulrich G.</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Capacity Bounds for Peak-Constrained Multiantenna Wideband Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Communications</comments><abstract>  We derive bounds on the noncoherent capacity of a very general class of
multiple-input multiple-output channels that allow for selectivity in time and
frequency as well as for spatial correlation. The bounds apply to
peak-constrained inputs; they are explicit in the channel's scattering
function, are useful for a large range of bandwidth, and allow to coarsely
identify the capacity-optimal combination of bandwidth and number of transmit
antennas. Furthermore, we obtain a closed-form expression for the first-order
Taylor series expansion of capacity in the limit of infinite bandwidth. From
this expression, we conclude that in the wideband regime: (i) it is optimal to
use only one transmit antenna when the channel is spatially uncorrelated; (ii)
rank-one statistical beamforming is optimal if the channel is spatially
correlated; and (iii) spatial correlation, be it at the transmitter, the
receiver, or both, is beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1033</identifier>
 <datestamp>2008-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1033</id><created>2008-01-07</created><authors><author><keyname>Tsibidis</keyname><forenames>George</forenames></author><author><keyname>Arvanitis</keyname><forenames>Theodoros N.</forenames></author><author><keyname>Baber</keyname><forenames>Chris</forenames></author></authors><title>The What, Who, Where, When, Why and How of Context-Awareness</title><categories>cs.HC</categories><comments>Accepted manuscript at the CHI 2000, April 3-2000, The Hague, The
  Netherlands</comments><abstract>  The understanding of context and context-awareness is very important for the
areas of handheld and ubiquitous computing. Unfortunately, at present, there
has not been a satisfactory definition of these two concepts that would lead to
a more effective communication in humancomputer interaction. As a result, on
the one hand, application designers are not able to choose what context to use
in their applications and on the other, they cannot determine the type of
context-awareness behaviours their applications should exhibit. In this work,
we aim to provide answers to some fundamental questions that could enlighten us
on the definition of context and its functionality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1060</identifier>
 <datestamp>2008-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1060</id><created>2008-01-07</created><updated>2008-04-30</updated><authors><author><keyname>Manada</keyname><forenames>Akiko</forenames></author><author><keyname>Kashyap</keyname><forenames>Navin</forenames></author></authors><title>On the Period of a Periodic-Finite-Type Shift</title><categories>cs.IT math.IT</categories><comments>revised version; 5 pages; to appear in the Proceedings of the 2008
  IEEE International Symposium on Information Theory (ISIT'08), Toronto, Canada</comments><abstract>  Periodic-finite-type shifts (PFT's) form a class of sofic shifts that
strictly contains the class of shifts of finite type (SFT's). In this paper, we
investigate how the notion of &quot;period&quot; inherent in the definition of a PFT
causes it to differ from an SFT, and how the period influences the properties
of a PFT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1063</identifier>
 <datestamp>2008-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1063</id><created>2008-01-07</created><authors><author><keyname>Titov</keyname><forenames>Ivan</forenames></author><author><keyname>McDonald</keyname><forenames>Ryan</forenames></author></authors><title>Modeling Online Reviews with Multi-grain Topic Models</title><categories>cs.IR cs.DB</categories><acm-class>H.2.8; H.3.1; H.4</acm-class><abstract>  In this paper we present a novel framework for extracting the ratable aspects
of objects from online user reviews. Extracting such aspects is an important
challenge in automatically mining product opinions from the web and in
generating opinion-based summaries of user reviews. Our models are based on
extensions to standard topic modeling methods such as LDA and PLSA to induce
multi-grain topics. We argue that multi-grain models are more appropriate for
our task since standard models tend to produce topics that correspond to global
properties of objects (e.g., the brand of a product type) rather than the
aspects of an object that tend to be rated by a user. The models we present not
only extract ratable aspects, but also cluster them into coherent topics, e.g.,
`waitress' and `bartender' are part of the same topic `staff' for restaurants.
This differentiates it from much of the previous work which extracts aspects
through term frequency analysis with minimal clustering. We evaluate the
multi-grain models both qualitatively and quantitatively to show that they
improve significantly upon standard topic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1067</identifier>
 <datestamp>2009-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1067</id><created>2008-01-07</created><updated>2009-03-20</updated><authors><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author><author><keyname>Hehn</keyname><forenames>Thorsten</forenames></author></authors><title>The lowest-possible BER and FER for any discrete memoryless channel with
  given capacity</title><categories>cs.IT math.IT</categories><comments>Accepted as a Transactions on Communications Letter,9 Pages, 4
  Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate properties of a channel coding scheme leading to the
minimum-possible frame error ratio when transmitting over a memoryless channel
with rate R&gt;C. The results are compared to the well-known properties of a
channel coding scheme leading to minimum bit error ratio. It is concluded that
these two optimization requests are contradicting. A valuable application of
the derived results is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1126</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1126</id><created>2008-01-07</created><updated>2009-06-12</updated><authors><author><keyname>Tal</keyname><forenames>Ido</forenames></author><author><keyname>Roth</keyname><forenames>Ron M.</forenames></author></authors><title>Concave Programming Upper Bounds on the Capacity of 2-D Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of 1-D constraints is given by the entropy of a corresponding
stationary maxentropic Markov chain. Namely, the entropy is maximized over a
set of probability distributions, which is defined by some linear requirements.
In this paper, certain aspects of this characterization are extended to 2-D
constraints. The result is a method for calculating an upper bound on the
capacity of 2-D constraints.
  The key steps are: The maxentropic stationary probability distribution on
square configurations is considered. A set of linear equalities and
inequalities is derived from this stationarity. The result is a concave
program, which can be easily solved numerically. Our method improves upon
previous upper bounds for the capacity of the 2-D ``no independent bits''
constraint, as well as certain 2-D RLL constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1136</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1136</id><created>2008-01-07</created><authors><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author><author><keyname>Vedantam</keyname><forenames>Satish</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>A Constrained Channel Coding Approach to Joint Communication and Channel
  Estimation</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2008</comments><abstract>  A joint communication and channel state estimation problem is investigated,
in which reliable information transmission over a noisy channel, and
high-fidelity estimation of the channel state, are simultaneously sought. The
tradeoff between the achievable information rate and the estimation distortion
is quantified by formulating the problem as a constrained channel coding
problem, and the resulting capacity-distortion function characterizes the
fundamental limit of the joint communication and channel estimation problem.
The analytical results are illustrated through case studies, and further issues
such as multiple cost constraints, channel uncertainty, and capacity per unit
distortion are also briefly discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1138</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1138</id><created>2008-01-07</created><authors><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author></authors><title>An Addendum to &quot;How Good is PSK for Peak-Limited Fading Channels in the
  Low-SNR Regime?&quot;</title><categories>cs.IT math.IT</categories><comments>Submitted as an addendum to the paper appearing in the title</comments><abstract>  A proof is provided of the operational achievability of $R_\mathrm{rt}$ by
the recursive training scheme in \cite{zhang07:it}, for general wide-sense
stationary and ergodic Rayleigh fading processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1141</identifier>
 <datestamp>2008-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1141</id><created>2008-01-08</created><updated>2008-05-02</updated><authors><author><keyname>Lutz</keyname><forenames>Tobias</forenames></author><author><keyname>Hausl</keyname><forenames>Christoph</forenames></author><author><keyname>K&#xf6;tter</keyname><forenames>Ralf</forenames></author></authors><title>Coding Strategies for Noise-Free Relay Cascades with Half-Duplex
  Constraint</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Symposium on Information
  Theory, Toronto, ON, Canada, July 6 - 11, 2008</comments><abstract>  Two types of noise-free relay cascades are investigated. Networks where a
source communicates with a distant receiver via a cascade of half-duplex
constrained relays, and networks where not only the source but also a single
relay node intends to transmit information to the same destination. We
introduce two relay channel models, capturing the half-duplex constraint, and
within the framework of these models capacity is determined for the first
network type. It turns out that capacity is significantly higher than the rates
which are achievable with a straightforward time-sharing approach. A capacity
achieving coding strategy is presented based on allocating the transmit and
receive time slots of a node in dependence of the node's previously received
data. For the networks of the second type, an upper bound to the rate region is
derived from the cut-set bound. Further, achievability of the cut-set bound in
the single relay case is shown given that the source rate exceeds a certain
minimum value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1179</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1179</id><created>2008-01-08</created><updated>2015-06-19</updated><authors><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames><affiliation>ISC, UMR 7044, GERIICO</affiliation></author><author><keyname>Ploux</keyname><forenames>Sabine</forenames><affiliation>ISC</affiliation></author></authors><title>Corpus sp{\'e}cialis{\'e} et ressource de sp{\'e}cialit{\'e}</title><categories>cs.IR cs.CL</categories><comments>16 pages, in French</comments><proxy>ccsd</proxy><journal-ref>Appears in Fran\c{c}ois Maniez; Pascaline Dury; Nathalie Arlin;
  Claire Rougemont. Corpus et dictionnaires de langues de sp{\'e}cialit{\'e},
  Presses Universitaires de Granoble, pp.197-212, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;Semantic Atlas&quot; is a mathematic and statistic model to visualise word senses
according to relations between words. The model, that has been applied to
proximity relations from a corpus, has shown its ability to distinguish word
senses as the corpus' contributors comprehend them. We propose to use the model
and a specialised corpus in order to create automatically a specialised
dictionary relative to the corpus' domain. A morpho-syntactic analysis
performed on the corpus makes it possible to create the dictionary from
syntactic relations between lexical units. The semantic resource can be used to
navigate semantically - and not only lexically - through the corpus, to create
classical dictionaries or for diachronic studies of the language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1185</identifier>
 <datestamp>2008-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1185</id><created>2008-01-08</created><updated>2008-05-15</updated><authors><author><keyname>Singh</keyname><forenames>Jaspreet</forenames></author><author><keyname>Dabeer</keyname><forenames>Onkar</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author></authors><title>Capacity of the Discrete-Time AWGN Channel Under Output Quantization</title><categories>cs.IT math.IT</categories><comments>To appear at ISIT 2008. (Some changes in the content (in Section IV)
  compared to the first version uploaded on Jan 08, 2008.)</comments><abstract>  We investigate the limits of communication over the discrete-time Additive
White Gaussian Noise (AWGN) channel, when the channel output is quantized using
a small number of bits. We first provide a proof of our recent conjecture on
the optimality of a discrete input distribution in this scenario. Specifically,
we show that for any given output quantizer choice with K quantization bins
(i.e., a precision of log2 K bits), the input distribution, under an average
power constraint, need not have any more than K + 1 mass points to achieve the
channel capacity. The cutting-plane algorithm is employed to compute this
capacity and to generate optimum input distributions. Numerical optimization
over the choice of the quantizer is then performed (for 2-bit and 3-bit
symmetric quantization), and the results we obtain show that the loss due to
low-precision output quantization, which is small at low signal-to-noise ratio
(SNR) as expected, can be quite acceptable even for moderate to high SNR
values. For example, at SNRs up to 20 dB, 2-3 bit quantization achieves 80-90%
of the capacity achievable using infinite-precision quantization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1208</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1208</id><created>2008-01-08</created><updated>2009-07-02</updated><authors><author><keyname>Li</keyname><forenames>Guangwen</forenames></author><author><keyname>Li</keyname><forenames>Dashe</forenames></author><author><keyname>Wang</keyname><forenames>Yuling</forenames></author><author><keyname>Sun</keyname><forenames>Wenyan</forenames></author></authors><title>Hybrid Decoding of Finite Geometry LDPC Codes</title><categories>cs.IT math.IT</categories><comments>19 pages, 5 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For finite geometry low-density parity-check codes, heavy row and column
weights in their parity check matrix make the decoding with even Min-Sum (MS)
variants computationally expensive. To alleviate it, we present a class of
hybrid schemes by concatenating a parallel bit flipping (BF) variant with an
Min-Sum (MS) variant. In most SNR region of interest, without compromising
performance or convergence rate, simulation results show that the proposed
hybrid schemes can save substantial computational complexity with respect to MS
variant decoding alone. Specifically, the BF variant, with much less
computational complexity, bears most decoding load before resorting to MS
variant. Computational and hardware complexity is also elaborated to justify
the feasibility of the hybrid schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1210</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1210</id><created>2008-01-08</created><authors><author><keyname>Gonzalez</keyname><forenames>Daniel Lombrana</forenames></author><author><keyname>de Vega</keyname><forenames>Francisco Fernandez</forenames></author><author><keyname>Trujillo</keyname><forenames>L.</forenames></author><author><keyname>Olague</keyname><forenames>G.</forenames></author><author><keyname>de la O</keyname><forenames>F. Chavez</forenames></author><author><keyname>Cardenas</keyname><forenames>M.</forenames></author><author><keyname>Araujo</keyname><forenames>L.</forenames></author><author><keyname>Castillo</keyname><forenames>P.</forenames></author><author><keyname>Sharman</keyname><forenames>K.</forenames></author></authors><title>Increasing GP Computing Power via Volunteer Computing</title><categories>cs.DC</categories><comments>First draft, preparing for PPSN 2008</comments><abstract>  This paper describes how it is possible to increase GP Computing Power via
Volunteer Computing (VC) using the BOINC framework. Two experiments using
well-known GP tools -Lil-gp &amp; ECJ- are performed in order to demonstrate the
benefit of using VC in terms of computing power and speed up. Finally we
present an extension of the model where any GP tool or framework can be used
inside BOINC regardless of its programming language, complexity or required
operating system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1219</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1219</id><created>2008-01-08</created><authors><author><keyname>Breslav</keyname><forenames>Andrey</forenames></author></authors><title>DSL development based on target meta-models. Using AST transformations
  for automating semantic analysis in a textual DSL framework</title><categories>cs.PL</categories><comments>15 pages, 3 figures</comments><acm-class>D.3.4</acm-class><abstract>  This paper describes an approach to creating textual syntax for Do-
main-Specific Languages (DSL). We consider target meta-model to be the main
artifact and hence to be developed first. The key idea is to represent analysis
of textual syntax as a sequence of transformations. This is made by explicit
opera- tions on abstract syntax trees (ATS), for which a simple language is
proposed. Text-to-model transformation is divided into two parts: text-to-AST
(developed by openArchitectureWare [1]) and AST-to-model (proposed by this
paper). Our approach simplifies semantic analysis and helps to generate as much
as possi- ble.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1245</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1245</id><created>2008-01-08</created><updated>2009-11-17</updated><authors><author><keyname>Velasco</keyname><forenames>Pedro Pablo Perez</forenames></author></authors><title>Matrix Graph Grammars</title><categories>cs.DM</categories><comments>321 pages, 75 figures. This book has is publisehd by VDM verlag, ISBN
  978-3639212556</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This book objective is to develop an algebraization of graph grammars.
Equivalently, we study graph dynamics. From the point of view of a computer
scientist, graph grammars are a natural generalization of Chomsky grammars for
which a purely algebraic approach does not exist up to now. A Chomsky (or
string) grammar is, roughly speaking, a precise description of a formal
language (which in essence is a set of strings). On a more discrete
mathematical style, it can be said that graph grammars -- Matrix Graph Grammars
in particular -- study dynamics of graphs. Ideally, this algebraization would
enforce our understanding of grammars in general, providing new analysis
techniques and generalizations of concepts, problems and results known so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1251</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1251</id><created>2008-01-08</created><updated>2008-03-18</updated><authors><author><keyname>Pitts</keyname><forenames>Andrew M.</forenames></author><author><keyname>Shinwell</keyname><forenames>Mark R.</forenames></author></authors><title>Generative Unbinding of Names</title><categories>cs.PL cs.LO</categories><acm-class>D.3.1; D.3.3; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 1 (March 18,
  2008) lmcs:916</journal-ref><doi>10.2168/LMCS-4(1:4)2008</doi><abstract>  This paper is concerned with the form of typed name binding used by the
FreshML family of languages. Its characteristic feature is that a name binding
is represented by an abstract (name,value)-pair that may only be deconstructed
via the generation of fresh bound names. The paper proves a new result about
what operations on names can co-exist with this construct. In FreshML the only
observation one can make of names is to test whether or not they are equal.
This restricted amount of observation was thought necessary to ensure that
there is no observable difference between alpha-equivalent name binders. Yet
from an algorithmic point of view it would be desirable to allow other
operations and relations on names, such as a total ordering. This paper shows
that, contrary to expectations, one may add not just ordering, but almost any
relation or numerical function on names without disturbing the fundamental
correctness result about this form of typed name binding (that object-level
alpha-equivalence precisely corresponds to contextual equivalence at the
programming meta-level), so long as one takes the state of dynamically created
names into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1253</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1253</id><created>2008-01-08</created><updated>2009-07-26</updated><authors><author><keyname>Baillot</keyname><forenames>Patrick</forenames></author><author><keyname>Mazza</keyname><forenames>Damiano</forenames></author></authors><title>Linear Logic by Levels and Bounded Time Complexity</title><categories>cs.LO cs.CC</categories><comments>63 pages. To appear in Theoretical Computer Science. This version
  corrects minor fonts problems from v2</comments><journal-ref>Theoretical Computer Science 411 (2010) 470-503</journal-ref><doi>10.1016/j.tcs.2009.09.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new characterization of elementary and deterministic polynomial
time computation in linear logic through the proofs-as-programs correspondence.
Girard's seminal results, concerning elementary and light linear logic, achieve
this characterization by enforcing a stratification principle on proofs, using
the notion of depth in proof nets. Here, we propose a more general form of
stratification, based on inducing levels in proof nets by means of indexes,
which allows us to extend Girard's systems while keeping the same complexity
properties. In particular, it turns out that Girard's systems can be recovered
by forcing depth and level to coincide. A consequence of the higher flexibility
of levels with respect to depth is the absence of boxes for handling the
paragraph modality. We use this fact to propose a variant of our polytime
system in which the paragraph modality is only allowed on atoms, and which may
thus serve as a basis for developing lambda-calculus type assignment systems
with more efficient typing algorithms than existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1275</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1275</id><created>2008-01-08</created><authors><author><keyname>Roche</keyname><forenames>Christophe</forenames><affiliation>LISTIC</affiliation></author></authors><title>Le terme et le concept : fondements d'une ontoterminologie</title><categories>cs.AI</categories><comments>22 pages</comments><proxy>ccsd hal-00202645</proxy><journal-ref>Dans TOTh 2007 : Terminologie et Ontologie : Th\'eories et
  Applications - TOTh 2007 : Terminologie et Ontologie : Th\'eories et
  Applications, Annecy : France (2007)</journal-ref><abstract>  Most definitions of ontology, viewed as a &quot;specification of a
conceptualization&quot;, agree on the fact that if an ontology can take different
forms, it necessarily includes a vocabulary of terms and some specification of
their meaning in relation to the domain's conceptualization. And as domain
knowledge is mainly conveyed through scientific and technical texts, we can
hope to extract some useful information from them for building ontology. But is
it as simple as this? In this article we shall see that the lexical structure,
i.e. the network of words linked by linguistic relationships, does not
necessarily match the domain conceptualization. We have to bear in mind that
writing documents is the concern of textual linguistics, of which one of the
principles is the incompleteness of text, whereas building ontology - viewed as
task-independent knowledge - is concerned with conceptualization based on
formal and not natural languages. Nevertheless, the famous Sapir and Whorf
hypothesis, concerning the interdependence of thought and language, is also
applicable to formal languages. This means that the way an ontology is built
and a concept is defined depends directly on the formal language which is used;
and the results will not be the same. The introduction of the notion of
ontoterminology allows to take into account epistemological principles for
formal ontology building.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1276</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1276</id><created>2008-01-08</created><authors><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Nguyen</keyname><forenames>Dung Viet</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Marcellin</keyname><forenames>Michael</forenames></author></authors><title>On the guaranteed error correction capability of LDPC codes</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to IEEE International Symposium on Information
  Theory (ISIT), 2008</comments><abstract>  We investigate the relation between the girth and the guaranteed error
correction capability of $\gamma$-left regular LDPC codes when decoded using
the bit flipping (serial and parallel) algorithms. A lower bound on the number
of variable nodes which expand by a factor of at least $3 \gamma/4$ is found
based on the Moore bound. An upper bound on the guaranteed correction
capability is established by studying the sizes of smallest possible trapping
sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1282</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1282</id><created>2008-01-08</created><authors><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Krishnan</keyname><forenames>Anantha Raman</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author></authors><title>LDPC Codes Which Can Correct Three Errors Under Iterative Decoding</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to IEEE Information Theory Workshop
  (ITW), 2008</comments><abstract>  In this paper, we provide necessary and sufficient conditions for a
column-weight-three LDPC code to correct three errors when decoded using
Gallager A algorithm. We then provide a construction technique which results in
a code satisfying the above conditions. We also provide numerical assessment of
code performance via simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1300</identifier>
 <datestamp>2008-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1300</id><created>2008-01-08</created><updated>2008-04-18</updated><authors><author><keyname>Razgon</keyname><forenames>Igor</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Barry</forenames></author></authors><title>Almost 2-SAT is Fixed-Parameter Tractable</title><categories>cs.DS cs.CG cs.LO</categories><comments>This new version fixes the bug found by Somnath Sikdar in the proof
  of Claim 8. In the repaired version the modification of the Almost 2-SAT
  problem called 2-SLASAT is no longer needed and only the modification called
  2-ASLASAT remains relevant. Hence the whole manuscript is updated so that the
  2-SLASAT problem is not mentioned there anymore</comments><abstract>  We consider the following problem. Given a 2-CNF formula, is it possible to
remove at most $k$ clauses so that the resulting 2-CNF formula is satisfiable?
This problem is known to different research communities in Theoretical Computer
Science under the names 'Almost 2-SAT', 'All-but-$k$ 2-SAT', '2-CNF deletion',
'2-SAT deletion'. The status of fixed-parameter tractability of this problem is
a long-standing open question in the area of Parameterized Complexity. We
resolve this open question by proposing an algorithm which solves this problem
in $O(15^k*k*m^3)$ and thus we show that this problem is fixed-parameter
tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1306</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1306</id><created>2008-01-08</created><authors><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Capacity Bounds for the Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>35 pages, 14 figures, submitted to IEEE Trans. on Inf. Theory</comments><abstract>  The capacity region of the two-user Gaussian Interference Channel (IC) is
studied. Three classes of channels are considered: weak, one-sided, and mixed
Gaussian IC. For the weak Gaussian IC, a new outer bound on the capacity region
is obtained that outperforms previously known outer bounds. The sum capacity
for a certain range of channel parameters is derived. For this range, it is
proved that using Gaussian codebooks and treating interference as noise is
optimal. It is shown that when Gaussian codebooks are used, the full
Han-Kobayashi achievable rate region can be obtained by using the naive
Han-Kobayashi achievable scheme over three frequency bands (equivalently, three
subspaces). For the one-sided Gaussian IC, an alternative proof for the Sato's
outer bound is presented. We derive the full Han-Kobayashi achievable rate
region when Gaussian codebooks are utilized. For the mixed Gaussian IC, a new
outer bound is obtained that outperforms previously known outer bounds. For
this case, the sum capacity for the entire range of channel parameters is
derived. It is proved that the full Han-Kobayashi achievable rate region using
Gaussian codebooks is equivalent to that of the one-sided Gaussian IC for a
particular range of channel parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1307</identifier>
 <datestamp>2008-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1307</id><created>2008-01-08</created><authors><author><keyname>Pollett</keyname><forenames>Chris</forenames></author><author><keyname>Miles</keyname><forenames>Eric</forenames></author></authors><title>Alternating Hierarchies for Time-Space Tradeoffs</title><categories>cs.CC cs.LO</categories><comments>14 pages</comments><acm-class>F.1.3</acm-class><abstract>  Nepomnjascii's Theorem states that for all 0 &lt;= \epsilon &lt; 1 and k &gt; 0 the
class of languages recognized in nondeterministic time n^k and space
n^\epsilon, NTISP[n^k, n^\epsilon ], is contained in the linear time hierarchy.
By considering restrictions on the size of the universal quantifiers in the
linear time hierarchy, this paper refines Nepomnjascii's result to give a sub-
hierarchy, Eu-LinH, of the linear time hierarchy that is contained in NP and
which contains NTISP[n^k, n^\epsilon ]. Hence, Eu-LinH contains NL and SC. This
paper investigates basic structural properties of Eu-LinH. Then the
relationships between Eu-LinH and the classes NL, SC, and NP are considered to
see if they can shed light on the NL = NP or SC = NP questions. Finally, a new
hierarchy, zeta -LinH, is defined to reduce the space requirements needed for
the upper bound on Eu-LinH.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1336</identifier>
 <datestamp>2008-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1336</id><created>2008-01-09</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Stream Computing</title><categories>cs.AI</categories><comments>7 pages, 4 figures</comments><abstract>  Stream computing is the use of multiple autonomic and parallel modules
together with integrative processors at a higher level of abstraction to embody
&quot;intelligent&quot; processing. The biological basis of this computing is sketched
and the matter of learning is examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1341</identifier>
 <datestamp>2008-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1341</id><created>2008-01-08</created><authors><author><keyname>Tsarev</keyname><forenames>S. P.</forenames></author></authors><title>Factorization in categories of systems of linear partial differential
  equations</title><categories>cs.SC</categories><comments>LaTeX, 23 pages</comments><abstract>  We start with elementary algebraic theory of factorization of linear ordinary
differential equations developed in the period 1880-1930. After exposing these
classical results we sketch more sophisticated algorithmic approaches developed
in the last 20 years.
  The main part of this paper is devoted to modern generalizations of the
notion of factorization to the case of systems of linear partial differential
equations and their relation with explicit solvability of nonlinear partial
differential equations based on some constructions from the theory of abelian
categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1362</identifier>
 <datestamp>2008-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1362</id><created>2008-01-09</created><updated>2008-01-20</updated><authors><author><keyname>Li</keyname><forenames>An-Ping</forenames></author></authors><title>A new key exchange cryptosystem</title><categories>cs.CR</categories><comments>A revision</comments><abstract>  In this paper, we will present a new key exchange cryptosystem based on
linear algebra, which take less operations but weaker in security than
Diffie-Hellman's one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1364</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1364</id><created>2008-01-09</created><updated>2008-09-29</updated><authors><author><keyname>McKilliam</keyname><forenames>Robby G.</forenames></author><author><keyname>Clarkson</keyname><forenames>I. Vaughan L.</forenames></author><author><keyname>Quinn</keyname><forenames>Barry G.</forenames></author></authors><title>An Algorithm to Compute the Nearest Point in the Lattice $A_{n}^*$</title><categories>cs.IT math.IT</categories><comments>3 pages</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 54, No. 9, pp
  4378-4381, Sept. 2008</journal-ref><doi>10.1109/TIT.2008.928280</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lattice $A_n^*$ is an important lattice because of its covering
properties in low dimensions. Clarkson \cite{Clarkson1999:Anstar} described an
algorithm to compute the nearest lattice point in $A_n^*$ that requires
$O(n\log{n})$ arithmetic operations. In this paper, we describe a new
algorithm. While the complexity is still $O(n\log{n})$, it is significantly
simpler to describe and verify. In practice, we find that the new algorithm
also runs faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1410</identifier>
 <datestamp>2009-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1410</id><created>2008-01-09</created><updated>2008-01-12</updated><authors><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author></authors><title>Two graph isomorphism polytopes</title><categories>cs.CC cs.DM math.CO math.OC</categories><journal-ref>Discrete Mathematics, 309:2934--2936, 2009</journal-ref><abstract>  The convex hull $\psi_{n,n}$ of certain $(n!)^2$ tensors was considered
recently in connection with graph isomorphism. We consider the convex hull
$\psi_n$ of the $n!$ diagonals among these tensors. We show: 1. The polytope
$\psi_n$ is a face of $\psi_{n,n}$. 2. Deciding if a graph $G$ has a subgraph
isomorphic to $H$ reduces to optimization over $\psi_n$. 3. Optimization over
$\psi_n$ reduces to optimization over $\psi_{n,n}$. In particular, this implies
that the subgraph isomorphism problem reduces to optimization over
$\psi_{n,n}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1415</identifier>
 <datestamp>2008-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1415</id><created>2008-01-09</created><authors><author><keyname>Wichmann</keyname><forenames>S.</forenames></author></authors><title>The emerging field of language dynamics</title><categories>cs.CL physics.soc-ph</categories><abstract>  A simple review by a linguist, citing many articles by physicists:
Quantitative methods, agent-based computer simulations, language dynamics,
language typology, historical linguistics
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1416</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1416</id><created>2008-01-09</created><updated>2008-09-19</updated><authors><author><keyname>De</keyname><forenames>Anindya</forenames></author><author><keyname>Kurur</keyname><forenames>Piyush P</forenames></author><author><keyname>Saha</keyname><forenames>Chandan</forenames></author><author><keyname>Saptharishi</keyname><forenames>Ramprasad</forenames></author></authors><title>Fast Integer Multiplication using Modular Arithmetic</title><categories>cs.SC cs.DS</categories><comments>fixed some typos and references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an $O(N\cdot \log N\cdot 2^{O(\log^*N)})$ algorithm for multiplying
two $N$-bit integers that improves the $O(N\cdot \log N\cdot \log\log N)$
algorithm by Sch\&quot;{o}nhage-Strassen. Both these algorithms use modular
arithmetic. Recently, F\&quot;{u}rer gave an $O(N\cdot \log N\cdot 2^{O(\log^*N)})$
algorithm which however uses arithmetic over complex numbers as opposed to
modular arithmetic. In this paper, we use multivariate polynomial
multiplication along with ideas from F\&quot;{u}rer's algorithm to achieve this
improvement in the modular setting. Our algorithm can also be viewed as a
$p$-adic version of F\&quot;{u}rer's algorithm. Thus, we show that the two seemingly
different approaches to integer multiplication, modular and complex arithmetic,
are similar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1419</identifier>
 <datestamp>2008-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1419</id><created>2008-01-09</created><authors><author><keyname>Gramoli</keyname><forenames>Vincent</forenames><affiliation>IRISA</affiliation></author><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames><affiliation>IRISA</affiliation></author><author><keyname>Mostefaoui</keyname><forenames>Achour</forenames><affiliation>IRISA</affiliation></author><author><keyname>Raynal</keyname><forenames>Michel</forenames><affiliation>IRISA</affiliation></author><author><keyname>Sericola</keyname><forenames>Bruno</forenames><affiliation>IRISA</affiliation></author></authors><title>Core Persistence in Peer-to-Peer Systems: Relating Size to Lifetime</title><categories>cs.DC</categories><proxy>ccsd inria-00201164</proxy><journal-ref>Dans Proceedings of the Workshop on Reliability in Decentralized
  Distributed Systems 4278 (2006) 1470--1479</journal-ref><abstract>  Distributed systems are now both very large and highly dynamic. Peer to peer
overlay networks have been proved efficient to cope with this new deal that
traditional approaches can no longer accommodate. While the challenge of
organizing peers in an overlay network has generated a lot of interest leading
to a large number of solutions, maintaining critical data in such a network
remains an open issue. In this paper, we are interested in defining the portion
of nodes and frequency one has to probe, given the churn observed in the
system, in order to achieve a given probability of maintaining the persistence
of some critical data. More specifically, we provide a clear result relating
the size and the frequency of the probing set along with its proof as well as
an analysis of the way of leveraging such an information in a large scale
dynamic distributed system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1500</identifier>
 <datestamp>2008-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1500</id><created>2008-01-09</created><authors><author><keyname>McGuigan</keyname><forenames>Michael</forenames></author></authors><title>Toward the Graphics Turing Scale on a Blue Gene Supercomputer</title><categories>cs.GR</categories><comments>9 pages, 4 figures, 6 tables</comments><abstract>  We investigate raytracing performance that can be achieved on a class of Blue
Gene supercomputers. We measure a 822 times speedup over a Pentium IV on a 6144
processor Blue Gene/L. We measure the computational performance as a function
of number of processors and problem size to determine the scaling performance
of the raytracing calculation on the Blue Gene. We find nontrivial scaling
behavior at large number of processors. We discuss applications of this
technology to scientific visualization with advanced lighting and high
resolution. We utilize three racks of a Blue Gene/L in our calculations which
is less than three percent of the the capacity of the worlds largest Blue Gene
computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1514</identifier>
 <datestamp>2008-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1514</id><created>2008-01-09</created><authors><author><keyname>Chadwick</keyname><forenames>David</forenames></author><author><keyname>Sue</keyname><forenames>Rodney E.</forenames></author></authors><title>Teaching spreadsheet development using peer audit and self-audit methods
  for reducing error</title><categories>cs.CY</categories><comments>9 Pages, includes references</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1; K.3</acm-class><journal-ref>European Spreadsheet Risks Int. Grp. 2001 95-105 ISBN:1 86166 179
  7</journal-ref><abstract>  Recent research has highlighted the high incidence of errors in spreadsheet
models used in industry. In an attempt to reduce the incidence of such errors,
a teaching approach has been devised which aids students to reduce their
likelihood of making common errors during development. The approach comprises
of spreadsheet checking methods based on the commonly accepted educational
paradigms of peer assessment and self-assessment. However, these paradigms are
here based upon practical techniques commonly used by the internal audit
function such as peer audit and control and risk self-assessment. The result of
this symbiosis between educational assessment and professional audit is a
method that educates students in a set of structured, transferable skills for
spreadsheet error-checking which are useful for increasing error-awareness in
the classroom and for reducing business risk in the workplace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1516</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1516</id><created>2008-01-09</created><authors><author><keyname>Rajalingham</keyname><forenames>Kamalasen</forenames></author><author><keyname>Chadwick</keyname><forenames>David</forenames></author><author><keyname>Knight</keyname><forenames>Brian</forenames></author></authors><title>An Evaluation of a Structured Spreadsheet Development Methodology</title><categories>cs.CY</categories><comments>17 pages including references</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1; K.3; K.6.3</acm-class><journal-ref>European Spreadsheet Risks Int. Grp. 2001 39-59 ISBN:1 86166 179</journal-ref><abstract>  This paper presents the results of an empirical evaluation of the quality of
a structured methodology for the development of spreadsheet models, proposed in
numerous previous papers by Rajalingham K, Knight B and Chadwick D et al. This
paper also describes an improved version of their methodology, supported by
appropriate examples. The principal objective of a structured and disciplined
methodology for the construction of spreadsheet models is to reduce the
occurrence of user-generated errors in the models. The evaluation of the
effectiveness of the methodology has been carried out based on a number of
real-life experiments. The results of these experiments demonstrate the
methodology's potential for improved integrity control and enhanced
comprehensibility of spreadsheet models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1573</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1573</id><created>2008-01-10</created><updated>2010-12-13</updated><authors><author><keyname>Matzke</keyname><forenames>Christina</forenames></author><author><keyname>Challet</keyname><forenames>Damien</forenames></author></authors><title>Taking a shower in Youth Hostels: risks and delights of heterogeneity</title><categories>physics.soc-ph cs.GT</categories><comments>13 pages, 7 figures</comments><doi>10.1103/PhysRevE.84.016107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tuning one's shower in some hotels may turn into a challenging coordination
game with imperfect information. The temperature sensitivity increases with the
number of agents, making the problem possibly unlearnable. Because there is in
practice a finite number of possible tap positions, identical agents are
unlikely to reach even approximately their favorite water temperature. We show
that a population of agents with homogeneous strategies is evolutionary
unstable, which gives insights into the emergence of heterogeneity, the latter
being tempting but risky.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1630</identifier>
 <datestamp>2008-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1630</id><created>2008-01-10</created><updated>2008-04-08</updated><authors><author><keyname>Bentrem</keyname><forenames>Frank W.</forenames><affiliation>Naval Research Laboratory</affiliation></author><author><keyname>Sample</keyname><forenames>John T.</forenames><affiliation>Naval Research Laboratory</affiliation></author><author><keyname>Harris</keyname><forenames>Michael M.</forenames><affiliation>Naval Research Laboratory</affiliation></author></authors><title>Computational Solutions for Today's Navy</title><categories>cs.MA cs.GL</categories><comments>This is a work of the U.S. Government</comments><acm-class>I.2.11; J.2</acm-class><journal-ref>Scientific Computing, vol. 25, no. 2, pp. 30-32 (March 2008)</journal-ref><abstract>  New methods are being employed to meet the Navy's changing
software-development environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1655</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1655</id><created>2008-01-10</created><updated>2008-09-17</updated><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Justin</keyname><forenames>Jacques</forenames></author></authors><title>Episturmian words: a survey</title><categories>math.CO cs.DM</categories><comments>36 pages; major revision: improvements + new material + more
  references</comments><msc-class>68R15</msc-class><journal-ref>RAIRO - Theoretical Informatics and Applications 43 (2009) 402-433</journal-ref><doi>10.1051/ita/2009003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we survey the rich theory of infinite episturmian words which
generalize to any finite alphabet, in a rather resembling way, the well-known
family of Sturmian words on two letters. After recalling definitions and basic
properties, we consider episturmian morphisms that allow for a deeper study of
these words. Some properties of factors are described, including factor
complexity, palindromes, fractional powers, frequencies, and return words. We
also consider lexicographical properties of episturmian words, as well as their
connection to the balance property, and related notions such as finite
episturmian words, Arnoux-Rauzy sequences, and &quot;episkew words&quot; that generalize
the skew words of Morse and Hedlund.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1656</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1656</id><created>2008-01-10</created><updated>2008-04-11</updated><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Justin</keyname><forenames>Jacques</forenames></author><author><keyname>Widmer</keyname><forenames>Steve</forenames></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames></author></authors><title>Palindromic Richness</title><categories>math.CO cs.DM</categories><comments>26 pages; merged with work of Steve Widmer and Luca Q. Zamboni on
  weakly rich words; accepted by the European Journal of Combinatorics</comments><msc-class>68R15</msc-class><journal-ref>European Journal of Combinatorics 30 (2009) 510-531</journal-ref><doi>10.1016/j.ejc.2008.04.006</doi><abstract>  In this paper, we study combinatorial and structural properties of a new
class of finite and infinite words that are 'rich' in palindromes in the utmost
sense. A characteristic property of so-called &quot;rich words&quot; is that all complete
returns to any palindromic factor are themselves palindromes. These words
encompass the well-known episturmian words, originally introduced by the second
author together with X. Droubay and G. Pirillo in 2001. Other examples of rich
words have appeared in many different contexts. Here we present the first
unified approach to the study of this intriguing family of words.
  Amongst our main results, we give an explicit description of the periodic
rich infinite words and show that the recurrent balanced rich infinite words
coincide with the balanced episturmian words. We also consider two wider
classes of infinite words, namely &quot;weakly rich words&quot; and almost rich words
(both strictly contain all rich words, but neither one is contained in the
other). In particular, we classify all recurrent balanced weakly rich words. As
a consequence, we show that any such word on at least three letters is
necessarily episturmian; hence weakly rich words obey Fraenkel's conjecture.
Likewise, we prove that a certain class of almost rich words obeys Fraenkel's
conjecture by showing that the recurrent balanced ones are episturmian or
contain at least two distinct letters with the same frequency.
  Lastly, we study the action of morphisms on (almost) rich words with
particular interest in morphisms that preserve (almost) richness. Such
morphisms belong to the class of &quot;P-morphisms&quot; that was introduced by A. Hof,
O. Knill, and B. Simon in 1995.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1658</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1658</id><created>2008-01-10</created><updated>2010-08-21</updated><authors><author><keyname>Lipowski</keyname><forenames>Adam</forenames></author><author><keyname>Lipowska</keyname><forenames>Dorota</forenames></author></authors><title>Computational approach to the emergence and evolution of language -
  evolutionary naming game model</title><categories>physics.soc-ph cs.CL cs.MA</categories><comments>paper withdrawn, much revised version is under preparation</comments><abstract>  Computational modelling with multi-agent systems is becoming an important
technique of studying language evolution. We present a brief introduction into
this rapidly developing field, as well as our own contributions that include an
analysis of the evolutionary naming-game model. In this model communicating
agents, that try to establish a common vocabulary, are equipped with an
evolutionarily selected learning ability. Such a coupling of biological and
linguistic ingredients results in an abrupt transition: upon a small change of
the model control parameter a poorly communicating group of linguistically
unskilled agents transforms into almost perfectly communicating group with
large learning abilities. Genetic imprinting of the learning abilities proceeds
via Baldwin effect: initially unskilled communicating agents learn a language
and that creates a niche in which there is an evolutionary pressure for the
increase of learning ability. Under the assumption that communication intensity
increases continuously with finite speed, the transition is split into several
transition-like changes. It shows that the speed of cultural changes, that sets
an additional characteristic timescale, might be yet another factor affecting
the evolution of language. In our opinion, this model shows that linguistic and
biological processes have a strong influence on each other and this effect
certainly has contributed to an explosive development of our species.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1676</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1676</id><created>2008-01-10</created><updated>2008-09-02</updated><authors><author><keyname>Alcazar</keyname><forenames>Juan Gerardo</forenames></author></authors><title>Analyzing the Topology Types arising in a Family of Algebraic Curves
  Depending On Two Parameters</title><categories>cs.SC</categories><comments>8 pages, 4 figures</comments><acm-class>I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the implicit equation $F(x,y,t,s)$ of a family of algebraic plane
curves depending on the parameters $t,s$, we provide an algorithm for studying
the topology types arising in the family. For this purpose, the algorithm
computes a finite partition of the parameter space so that the topology type of
the family stays invariant over each element of the partition. The ideas
contained in the paper can be seen as a generalization of the ideas in
\cite{JGRS}, where the problem is solved for families of algebraic curves
depending on one parameter, to the two-parameters case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1687</identifier>
 <datestamp>2008-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1687</id><created>2008-01-10</created><authors><author><keyname>Attie</keyname><forenames>Paul C.</forenames></author></authors><title>Synthesis of Large Dynamic Concurrent Programs from Dynamic
  Specifications</title><categories>cs.LO</categories><comments>46 pages</comments><abstract>  We present a tractable method for synthesizing arbitrarily large concurrent
programs, for a shared memory model with common hardware-available primitives
such as atomic registers, compare-and-swap, load-linked/store conditional, etc.
The programs we synthesize are dynamic: new processes can be created and added
at run-time, and so our programs are not finite-state, in general.
Nevertheless, we successfully exploit automatic synthesis and model-checking
methods based on propositional temporal logic. Our method is algorithmically
efficient, with complexity polynomial in the number of component processes (of
the program) that are ``alive'' at any time. Our method does not explicitly
construct the automata-theoretic product of all processes that are alive,
thereby avoiding \intr{state explosion}. Instead, for each pair of processes
which interact, our method constructs an automata-theoretic product
(\intr{pair-machine}) which embodies all the possible interactions of these two
processes. From each pair-machine, we can synthesize a correct
\intr{pair-program} which coordinates the two involved processes as needed. We
allow such pair-programs to be added dynamically at run-time. They are then
``composed conjunctively'' with the currently alive pair-programs to
re-synthesize the program as it results after addition of the new pair-program.
We are thus able to add new behaviors, which result in new properties being
satisfied, at run-time. We establish a ``large model'' theorem which shows that
the synthesized large program inherits correctness properties from the
pair-programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1703</identifier>
 <datestamp>2008-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1703</id><created>2008-01-10</created><authors><author><keyname>Derpich</keyname><forenames>Milan S.</forenames></author><author><keyname>Ostergaard</keyname><forenames>Jan</forenames></author><author><keyname>Goodwin</keyname><forenames>Graham C.</forenames></author></authors><title>The Quadratic Gaussian Rate-Distortion Function for Source Uncorrelated
  Distortions</title><categories>cs.IT math.IT</categories><comments>Revised version, to be presented at the Data Compression Conference
  2008</comments><abstract>  We characterize the rate-distortion function for zero-mean stationary
Gaussian sources under the MSE fidelity criterion and subject to the additional
constraint that the distortion is uncorrelated to the input. The solution is
given by two equations coupled through a single scalar parameter. This has a
structure similar to the well known water-filling solution obtained without the
uncorrelated distortion restriction. Our results fully characterize the unique
statistics of the optimal distortion. We also show that, for all positive
distortions, the minimum achievable rate subject to the uncorrelation
constraint is strictly larger than that given by the un-constrained
rate-distortion function. This gap increases with the distortion and tends to
infinity and zero, respectively, as the distortion tends to zero and infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1715</identifier>
 <datestamp>2008-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1715</id><created>2008-01-10</created><updated>2008-02-08</updated><authors><author><keyname>Ganta</keyname><forenames>Srivatsava Ranjit</forenames></author><author><keyname>Acharya</keyname><forenames>Raj</forenames></author></authors><title>On Breaching Enterprise Data Privacy Through Adversarial Information
  Fusion</title><categories>cs.DB cs.CR cs.OH</categories><abstract>  Data privacy is one of the key challenges faced by enterprises today.
Anonymization techniques address this problem by sanitizing sensitive data such
that individual privacy is preserved while allowing enterprises to maintain and
share sensitive data. However, existing work on this problem make inherent
assumptions about the data that are impractical in day-to-day enterprise data
management scenarios. Further, application of existing anonymization schemes on
enterprise data could lead to adversarial attacks in which an intruder could
use information fusion techniques to inflict a privacy breach. In this paper,
we shed light on the shortcomings of current anonymization schemes in the
context of enterprise data. We define and experimentally demonstrate Web-based
Information- Fusion Attack on anonymized enterprise data. We formulate the
problem of Fusion Resilient Enterprise Data Anonymization and propose a
prototype solution to address this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1718</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1718</id><created>2008-01-10</created><updated>2008-07-24</updated><authors><author><keyname>Derpich</keyname><forenames>Milan S.</forenames></author><author><keyname>Ostergaard</keyname><forenames>Jan</forenames></author><author><keyname>Quevedo</keyname><forenames>Daniel E.</forenames></author></authors><title>Achieving the Quadratic Gaussian Rate-Distortion Function for Source
  Uncorrelated Distortions</title><categories>cs.IT math.IT</categories><comments>Technical report, January 2008. Other papers available from
  http://msderpich.no-ip.org</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove achievability of the recently characterized quadratic Gaussian
rate-distortion function (RDF) subject to the constraint that the distortion is
uncorrelated to the source. This result is based on shaped dithered lattice
quantization in the limit as the lattice dimension tends to infinity and holds
for all positive distortions. It turns out that this uncorrelated distortion
RDF can be realized causally. This feature, which stands in contrast to
Shannon's RDF, is illustrated by causal transform coding. Moreover, we prove
that by using feedback noise shaping the uncorrelated distortion RDF can be
achieved causally and with memoryless entropy coding. Whilst achievability
relies upon infinite dimensional quantizers, we prove that the rate loss
incurred in the finite dimensional case can be upper-bounded by the space
filling loss of the quantizer and, thus, is at most 0.254 bit/dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1736</identifier>
 <datestamp>2008-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1736</id><created>2008-01-11</created><authors><author><keyname>Kammoun</keyname><forenames>Abla</forenames></author><author><keyname>Kharouf</keyname><forenames>Malika</forenames></author><author><keyname>Hachem</keyname><forenames>Walid</forenames></author><author><keyname>Najim</keyname><forenames>Jamal</forenames></author></authors><title>A Central Limit Theorem for the SNR at the Wiener Filter Output for
  Large Dimensional Signals</title><categories>cs.IT math.IT</categories><abstract>  Consider the quadratic form $\beta = {\bf y}^* ({\bf YY}^* + \rho {\bf
I})^{-1} {\bf y}$ where $\rho$ is a positive number, where ${\bf y}$ is a
random vector and ${\bf Y}$ is a $N \times K$ random matrix both having
independent elements with different variances, and where ${\bf y}$ and ${\bf
Y}$ are independent. Such quadratic forms represent the Signal to Noise Ratio
at the output of the linear Wiener receiver for multi dimensional signals
frequently encountered in wireless communications and in array processing.
Using well known results of Random Matrix Theory, the quadratic form $\beta$
can be approximated with a known deterministic real number $\bar\beta_K$ in the
asymptotic regime where $K\to\infty$ and $K/N \to \alpha &gt; 0$. This paper
addresses the problem of convergence of $\beta$. More specifically, it is shown
here that $\sqrt{K}(\beta - \bar\beta_K)$ behaves for large $K$ like a Gaussian
random variable which variance is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1737</identifier>
 <datestamp>2008-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1737</id><created>2008-01-11</created><authors><author><keyname>Zenklusen</keyname><forenames>Rico</forenames></author></authors><title>Extensions to Network Flow Interdiction on Planar Graphs</title><categories>cs.DM</categories><comments>16 pages, 3 figures</comments><abstract>  Network flow interdiction analysis studies by how much the value of a maximum
flow in a network can be diminished by removing components of the network
constrained to some budget. Although this problem is strongly NP-complete on
general networks, pseudo-polynomial algorithms were found for planar networks
with a single source and a single sink and without the possibility to remove
vertices. In this work we introduce pseudo-polynomial algorithms which overcome
some of the restrictions of previous methods. We propose a planarity-preserving
transformation that allows to incorporate vertex removals and vertex capacities
in pseudo-polynomial interdiction algorithms for planar graphs. Additionally, a
pseudo-polynomial algorithm is introduced for the problem of determining the
minimal interdiction budget which is at least needed to make it impossible to
satisfy the demand of all sink nodes, on planar networks with multiple sources
and sinks satisfying that the sum of the supplies at the source nodes equals
the sum of the demands at the sink nodes. Furthermore we show that the
k-densest subgraph problem on planar graphs can be reduced to a network flow
interdiction problem on a planar graph with multiple sources and sinks and
polynomially bounded input numbers. However it is still not known if either of
these problems can be solved in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1766</identifier>
 <datestamp>2008-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1766</id><created>2008-01-11</created><updated>2008-01-12</updated><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author><author><keyname>Xia</keyname><forenames>Mingji</forenames></author></authors><title>A Family of Counter Examples to an Approach to Graph Isomorphism</title><categories>cs.CC cs.DM</categories><abstract>  We give a family of counter examples showing that the two sequences of
polytopes $\Phi_{n,n}$ and $\Psi_{n,n}$ are different. These polytopes were
defined recently by S. Friedland in an attempt at a polynomial time algorithm
for graph isomorphism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1772</identifier>
 <datestamp>2008-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1772</id><created>2008-01-11</created><authors><author><keyname>Benoit</keyname><forenames>Anne</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Kosch</keyname><forenames>Harald</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Rehn-Sonigo</keyname><forenames>Veronika</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author><author><keyname>Robert</keyname><forenames>Yves</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes, LIP</affiliation></author></authors><title>Bi-criteria Pipeline Mappings for Parallel Image Processing</title><categories>cs.DC</categories><proxy>ccsd inria-00203889</proxy><abstract>  Mapping workflow applications onto parallel platforms is a challenging
problem, even for simple application patterns such as pipeline graphs. Several
antagonistic criteria should be optimized, such as throughput and latency (or a
combination). Typical applications include digital image processing, where
images are processed in steady-state mode. In this paper, we study the mapping
of a particular image processing application, the JPEG encoding. Mapping
pipelined JPEG encoding onto parallel platforms is useful for instance for
encoding Motion JPEG images. As the bi-criteria mapping problem is NP-complete,
we concentrate on the evaluation and performance of polynomial heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1783</identifier>
 <datestamp>2008-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1783</id><created>2008-01-11</created><authors><author><keyname>Duparc</keyname><forenames>Jacques</forenames><affiliation>UNIL</affiliation></author><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>LIP</affiliation></author></authors><title>An omega-power of a context-free language which is Borel above
  Delta^0_omega</title><categories>cs.CC cs.GT cs.LO math.LO</categories><comments>To appear in the Proceedings of the International Conference
  Foundations of the Formal Sciences V : Infinite Games, November 26th to 29th,
  2004, Bonn, Germany, Stefan Bold, Benedikt L\&quot;owe, Thoralf R\&quot;asch, Johan van
  Benthem (eds.), College Publications at King's College (Studies in Logic),
  2007</comments><proxy>ccsd ensl-00147245</proxy><journal-ref>Dans Proceedings of the International Conference on Foundations of
  the Formal Sciences V : Infinite Games - Foundations of the Formal Sciences V
  : Infinite Games, November 26-29, 2004, Bonn : Allemagne</journal-ref><abstract>  We use erasers-like basic operations on words to construct a set that is both
Borel and above Delta^0_omega, built as a set V^\omega where V is a language of
finite words accepted by a pushdown automaton. In particular, this gives a
first example of an omega-power of a context free language which is a Borel set
of infinite rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1784</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1784</id><created>2008-01-11</created><updated>2008-01-14</updated><authors><author><keyname>Vyshenski</keyname><forenames>S. V.</forenames></author><author><keyname>Grigoriev</keyname><forenames>P. V.</forenames></author><author><keyname>Dubenskaya</keyname><forenames>Yu. Yu.</forenames></author></authors><title>Ideal synchronizer for marked pairs in fork-join network</title><categories>cs.DM</categories><comments>18 pages, 3 figures, in Russian, typos fixed</comments><acm-class>G.3</acm-class><abstract>  We introduce a new functional element (synchronizer for marked pairs) meant
to join results of parallel processing in two-branch fork-join queueing
network. Approximations for distribution of sojourn time at the synchronizer
are derived along with a validity domain. Calculations are performed assuming
that: arrivals to the network form a Poisson process, each branch operates like
an M/M/N queueing system. It is shown that mean sojourn time at a real
synchronizer node is bounded below by the value, defined by parameters of the
network (which contains the synchronizer) and does not depend upon performance
and particular properties of the synchronizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1856</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1856</id><created>2008-01-11</created><authors><author><keyname>Banks</keyname><forenames>David A.</forenames></author><author><keyname>Monday</keyname><forenames>Ann</forenames></author></authors><title>Interpretation as a factor in understanding flawed spreadsheets</title><categories>cs.CY cs.HC</categories><comments>9 pages incuding references</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1; K.3</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2002 13 21 ISBN 1 86166
  182 7</journal-ref><abstract>  The spreadsheet has been used by the business community for many years and
yet still raises a number of significant concerns. As educators our concern is
to try to develop the students skills in both the development of spreadsheets
and in taking a critical view of their potential defects. In this paper we
consider both the problems of mechanical production and the problems of
translation of problem to spreadsheet representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1883</identifier>
 <datestamp>2008-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1883</id><created>2008-01-12</created><authors><author><keyname>Poczos</keyname><forenames>Barnabas</forenames></author><author><keyname>Lorincz</keyname><forenames>Andras</forenames></author></authors><title>D-optimal Bayesian Interrogation for Parameter and Noise Identification
  of Recurrent Neural Networks</title><categories>cs.NE cs.IT math.IT</categories><abstract>  We introduce a novel online Bayesian method for the identification of a
family of noisy recurrent neural networks (RNNs). We develop Bayesian active
learning technique in order to optimize the interrogating stimuli given past
experiences. In particular, we consider the unknown parameters as stochastic
variables and use the D-optimality principle, also known as `\emph{infomax
method}', to choose optimal stimuli. We apply a greedy technique to maximize
the information gain concerning network parameters at each time step. We also
derive the D-optimal estimation of the additive noise that perturbs the
dynamical system of the RNN. Our analytical results are approximation-free. The
analytic derivation gives rise to attractive quadratic update rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1925</identifier>
 <datestamp>2008-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1925</id><created>2008-01-12</created><authors><author><keyname>Luk</keyname><forenames>Rowena</forenames></author><author><keyname>Ho</keyname><forenames>Melissa</forenames></author><author><keyname>Aoki</keyname><forenames>Paul M.</forenames></author></authors><title>A Framework for Designing Teleconsultation Systems in Africa</title><categories>cs.HC</categories><comments>5 pages</comments><acm-class>H.5.3</acm-class><journal-ref>Proc. Int'l Conf. on Health Informatics in Africa (HELINA),
  Bamako, Mali, Jan. 2007, 28(1-5)</journal-ref><abstract>  All of the countries within Africa experience a serious shortage of medical
professionals, particularly specialists, a problem that is only exacerbated by
high emigration of doctors with better prospects overseas. As a result, those
that remain in Africa, particularly those practicing in rural regions,
experience a shortage of specialists and other colleagues with whom to exchange
ideas. Telemedicine and teleconsultation are key areas that attempt to address
this problem by leveraging remote expertise for local problems. This paper
presents an overview of teleconsultation in the developing world, with a
particular focus on how lessons learned apply to Africa. By teleconsultation,
we are addressing non-real-time communication between health care professionals
for the purposes of providing expertise and informal recommendations, without
the real-time, interactive requirements typical of diagnosis and patient care,
which is impractical for the vast majority of existing medical practices. From
these previous experiences, we draw a set of guidelines and examine their
relevance to Ghana in particular. Based on 6 weeks of needs assessment, we
identify key variables that guide our framework, and then illustrate how our
framework is used to inform the iterative design of a prototype system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1927</identifier>
 <datestamp>2008-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1927</id><created>2008-01-12</created><authors><author><keyname>Luk</keyname><forenames>Rowena</forenames></author><author><keyname>Ho</keyname><forenames>Melissa</forenames></author><author><keyname>Aoki</keyname><forenames>Paul M.</forenames></author></authors><title>Asynchronous Remote Medical Consultation for Ghana</title><categories>cs.HC</categories><comments>10 pages</comments><acm-class>H.5.m</acm-class><journal-ref>Proc. ACM SIGCHI Conf. on Human Factors in Computing Systems,
  Florence, Italy, Apr. 2008, 743-752. ACM Press.</journal-ref><doi>10.1145/1357054.1357173</doi><abstract>  Computer-mediated communication systems can be used to bridge the gap between
doctors in underserved regions with local shortages of medical expertise and
medical specialists worldwide. To this end, we describe the design of a
prototype remote consultation system intended to provide the social,
institutional and infrastructural context for sustained, self-organizing growth
of a globally-distributed Ghanaian medical community. The design is grounded in
an iterative design process that included two rounds of extended design
fieldwork throughout Ghana and draws on three key design principles (social
networks as a framework on which to build incentives within a self-organizing
network; optional and incremental integration with existing referral
mechanisms; and a weakly-connected, distributed architecture that allows for a
highly interactive, responsive system despite failures in connectivity). We
discuss initial experiences from an ongoing trial deployment in southern Ghana.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1979</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1979</id><created>2008-01-13</created><updated>2008-10-14</updated><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Razgon</keyname><forenames>I.</forenames></author><author><keyname>Kim</keyname><forenames>E. J.</forenames></author></authors><title>Minimum Leaf Out-branching and Related Problems</title><categories>cs.DS cs.DM</categories><comments>The main change is a quadratic kernel derivation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a digraph $D$, the Minimum Leaf Out-Branching problem (MinLOB) is the
problem of finding in $D$ an out-branching with the minimum possible number of
leaves, i.e., vertices of out-degree 0. We prove that MinLOB is polynomial-time
solvable for acyclic digraphs. In general, MinLOB is NP-hard and we consider
three parameterizations of MinLOB. We prove that two of them are NP-complete
for every value of the parameter, but the third one is fixed-parameter
tractable (FPT). The FPT parametrization is as follows: given a digraph $D$ of
order $n$ and a positive integral parameter $k$, check whether $D$ contains an
out-branching with at most $n-k$ leaves (and find such an out-branching if it
exists). We find a problem kernel of order $O(k^2)$ and construct an algorithm
of running time $O(2^{O(k\log k)}+n^6),$ which is an `additive' FPT algorithm.
We also consider transformations from two related problems, the minimum path
covering and the maximum internal out-tree problems into MinLOB, which imply
that some parameterizations of the two problems are FPT as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1987</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1987</id><created>2008-01-13</created><updated>2013-03-13</updated><authors><author><keyname>Koufogiannakis</keyname><forenames>Christos</forenames></author><author><keyname>Young</keyname><forenames>Neal E.</forenames></author></authors><title>A Nearly Linear-Time PTAS for Explicit Fractional Packing and Covering
  Linear Programs</title><categories>cs.DS</categories><comments>corrected version of FOCS 2007 paper: 10.1109/FOCS.2007.62. Accepted
  to Algorithmica, 2013</comments><msc-class>68W25</msc-class><acm-class>G.1.6</acm-class><journal-ref>Algorithmica 70(4):648-674(2014)</journal-ref><doi>10.1007/s00453-013-9771-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an approximation algorithm for packing and covering linear programs
(linear programs with non-negative coefficients). Given a constraint matrix
with n non-zeros, r rows, and c columns, the algorithm computes feasible primal
and dual solutions whose costs are within a factor of 1+eps of the optimal cost
in time O((r+c)log(n)/eps^2 + n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1988</identifier>
 <datestamp>2008-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1988</id><created>2008-01-14</created><authors><author><keyname>Szita</keyname><forenames>Istvan</forenames></author><author><keyname>Lorincz</keyname><forenames>Andras</forenames></author></authors><title>Online variants of the cross-entropy method</title><categories>cs.LG</categories><comments>8 pages</comments><abstract>  The cross-entropy method is a simple but efficient method for global
optimization. In this paper we provide two online variants of the basic CEM,
together with a proof of convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2034</identifier>
 <datestamp>2008-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2034</id><created>2008-01-14</created><authors><author><keyname>Sommerfeld</keyname><forenames>Jochen</forenames></author><author><keyname>Bjelakovic</keyname><forenames>Igor</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author></authors><title>On the Boundedness of the Support of Optimal Input Measures for Rayleigh
  Fading Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2008</comments><abstract>  We consider transmission over a wireless multiple antenna communication
system operating in a Rayleigh flat fading environment with no channel state
information at the receiver and the transmitter with coherence time T=1. We
show that, subject to the average power constraint, the support of the capacity
achieving input distribution is bounded. Moreover, we show by a simple example
concerning the identity theorem (or uniqueness theorem) from the complex
analysis in several variables that some of the existing results in the field
are not rigorous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2069</identifier>
 <datestamp>2008-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2069</id><created>2008-01-14</created><updated>2008-08-13</updated><authors><author><keyname>Szita</keyname><forenames>Istvan</forenames></author><author><keyname>Lorincz</keyname><forenames>Andras</forenames></author></authors><title>Factored Value Iteration Converges</title><categories>cs.AI cs.LG</categories><comments>17 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel algorithm, factored value iteration (FVI),
for the approximate solution of factored Markov decision processes (fMDPs). The
traditional approximate value iteration algorithm is modified in two ways. For
one, the least-squares projection operator is modified so that it does not
increase max-norm, and thus preserves convergence. The other modification is
that we uniformly sample polynomially many samples from the (exponentially
large) state space. This way, the complexity of our algorithm becomes
polynomial in the size of the fMDP description length. We prove that the
algorithm is convergent. We also derive an upper bound on the difference
between our approximate solution and the optimal one, and also on the error
introduced by sampling. We analyze various projection operators with respect to
their computation complexity and their convergence when combined with
approximate value iteration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2088</identifier>
 <datestamp>2008-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2088</id><created>2008-01-14</created><authors><author><keyname>Bressaud</keyname><forenames>Xavier</forenames></author><author><keyname>Hubert</keyname><forenames>Pascal</forenames></author><author><keyname>Maass</keyname><forenames>Alejandro</forenames></author></authors><title>Persistence of Wandering Intervals in Self-Similar Affine Interval
  Exchange Transformations</title><categories>math.DS cs.IT math.IT</categories><msc-class>37C15</msc-class><abstract>  In this article we prove that given a self-similar interval exchange
transformation T, whose associated matrix verifies a quite general algebraic
condition, there exists an affine interval exchange transformation with
wandering intervals that is semi-conjugated to it. That is, in this context the
existence of Denjoy counterexamples occurs very often, generalizing the result
of M. Cobo in [C].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2092</identifier>
 <datestamp>2008-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2092</id><created>2008-01-14</created><authors><author><keyname>Vyshenski</keyname><forenames>S. V.</forenames></author><author><keyname>Grigoriev</keyname><forenames>P. V.</forenames></author><author><keyname>Dubenskaya</keyname><forenames>Yu. Yu.</forenames></author></authors><title>Model for synchronizer of marked pairs in fork-join network</title><categories>cs.DM</categories><comments>15 pages, 3 figures, in Russian</comments><acm-class>G.3</acm-class><abstract>  We introduce a model for synchronizer of marked pairs, which is a node for
joining results of parallel processing in two-branch fork-join queueing
network. A distribution for number of jobs in the synchronizer is obtained.
Calculations are performed assuming that: arrivals to the network form a
Poisson process, each branch operates like an M/M/N queueing system. It is
shown that a mean quantity of jobs in the synchronizer is bounded below by the
value, defined by parameters of the network (which contains the synchronizer)
and does not depend upon performance and particular properties of the
synchronizer. A domain of network parameters is found, where the flow of jobs
departing from the synchronizer does not manifest a statistically significant
difference from the Poisson type, despite the correlation between job flows
from both branches of the fork-join network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2144</identifier>
 <datestamp>2009-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2144</id><created>2008-01-14</created><authors><author><keyname>Grassl</keyname><forenames>Markus</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>Non-Additive Quantum Codes from Goethals and Preparata Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>submitted to the 2008 IEEE Information Theory Workshop (ITW 2008)</comments><journal-ref>Proceedings IEEE Information Theory Workshop 2008 (ITW 2008),
  Porto, Portugal, May 2008, pp. 396-400</journal-ref><doi>10.1109/ITW.2008.4578694</doi><abstract>  We extend the stabilizer formalism to a class of non-additive quantum codes
which are constructed from non-linear classical codes. As an example, we
present infinite families of non-additive codes which are derived from Goethals
and Preparata codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2150</identifier>
 <datestamp>2009-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2150</id><created>2008-01-14</created><authors><author><keyname>Grassl</keyname><forenames>Markus</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>Quantum Goethals-Preparata Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>Submitted to the 2008 IEEE International Symposium on Information
  Theory</comments><journal-ref>Proceedings 2008 IEEE International Symposium on Information
  Theory (ISIT 2008), Toronto, Canada, July 2008, pp. 300-304</journal-ref><doi>10.1109/ISIT.2008.4594996</doi><abstract>  We present a family of non-additive quantum codes based on Goethals and
Preparata codes with parameters ((2^m,2^{2^m-5m+1},8)). The dimension of these
codes is eight times higher than the dimension of the best known additive
quantum codes of equal length and minimum distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2175</identifier>
 <datestamp>2008-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2175</id><created>2008-01-15</created><authors><author><keyname>Gro&#xdf;e</keyname><forenames>Johannes</forenames></author></authors><title>MathPSfrag 2: Convenient LaTeX Labels in Mathematica</title><categories>cs.GR</categories><comments>9 pages, package can be found at
  http://wwwth.mppmu.mpg.de/members/jgrosse/mathpsfrag/</comments><acm-class>I.3.4</acm-class><abstract>  This article introduces the next version of MathPSfrag. MathPSfrag is a
Mathematica package that during export automatically replaces all expressions
in a plot by corresponding LaTeX commands. The new version can also produce
LaTeX independent images; e.g., PDF files for inclusion in pdfLaTeX. Moreover
from these files a preview is generated and shown within Mathematica.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2185</identifier>
 <datestamp>2008-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2185</id><created>2008-01-14</created><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>New Outer Bounds on the Capacity Region of Gaussian Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to ISIT 2008</comments><abstract>  Recent outer bounds on the capacity region of Gaussian interference channels
are generalized to $m$-user channels with $m&gt;2$ and asymmetric powers and
crosstalk coefficients. The bounds are again shown to give the sum-rate
capacity for Gaussian interference channels with low powers and crosstalk
coefficients. The capacity is achieved by using single-user detection at each
receiver, i.e., treating the interference as noise incurs no loss in
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2187</identifier>
 <datestamp>2008-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2187</id><created>2008-01-14</created><authors><author><keyname>Feig</keyname><forenames>Ephraim</forenames></author><author><keyname>Feig</keyname><forenames>Vivian</forenames></author></authors><title>A One-Way Function Based On The Extended Euclidean Algorithm</title><categories>cs.CR</categories><comments>2-page correspondence</comments><abstract>  A problem based on the Extended Euclidean Algorithm applied to a class of
polynomials with many factors is presented and believed to be hard. If so, it
is a one-way function well suited for applications in digital signicatures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2201</identifier>
 <datestamp>2008-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2201</id><created>2008-01-15</created><authors><author><keyname>Harcourt</keyname><forenames>Ed</forenames></author></authors><title>Policies of System Level Pipeline Modeling</title><categories>cs.AR cs.PL</categories><abstract>  Pipelining is a well understood and often used implementation technique for
increasing the performance of a hardware system. We develop several SystemC/C++
modeling techniques that allow us to quickly model, simulate, and evaluate
pipelines. We employ a small domain specific language (DSL) based on resource
usage patterns that automates the drudgery of boilerplate code needed to
configure connectivity in simulation models. The DSL is embedded directly in
the host modeling language SystemC/C++. Additionally we develop several
techniques for parameterizing a pipeline's behavior based on policies of
function, communication, and timing (performance modeling).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2226</identifier>
 <datestamp>2008-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2226</id><created>2008-01-15</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Programming an interpreter using molecular dynamics</title><categories>cs.PL</categories><comments>27 pages</comments><report-no>PRG0801</report-no><acm-class>D.1.4; D.3.1; D.3.4; F.1.1; F.3.2</acm-class><journal-ref>Scientific Annals of Computer Science, 17:47--81, 2007.
  http://www.infoiasi.ro/bin/download/Annals/XVII/XVII_2.pdf</journal-ref><abstract>  PGA (ProGram Algebra) is an algebra of programs which concerns programs in
their simplest form: sequences of instructions. Molecular dynamics is a simple
model of computation developed in the setting of PGA, which bears on the use of
dynamic data structures in programming. We consider the programming of an
interpreter for a program notation that is close to existing assembly languages
using PGA with the primitives of molecular dynamics as basic instructions. It
happens that, although primarily meant for explaining programming language
features relating to the use of dynamic data structures, the collection of
primitives of molecular dynamics in itself is suited to our programming wants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2233</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2233</id><created>2008-01-15</created><authors><author><keyname>Sassatelli</keyname><forenames>Lucile</forenames></author><author><keyname>Declercq</keyname><forenames>David</forenames></author></authors><title>Analysis of Non-binary Hybrid LDPC Codes</title><categories>cs.IT math.IT</categories><comments>in the proceedings of IEEE International Symposium on Information
  Theory, June 2007, Nice, France</comments><abstract>  In this paper, we analyse asymptotically a new class of LDPC codes called
Non-binary Hybrid LDPC codes, which has been recently introduced. We use
density evolution techniques to derive a stability condition for hybrid LDPC
codes, and prove their threshold behavior. We study this stability condition to
conclude on asymptotic advantages of hybrid LDPC codes compared to their
non-hybrid counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2242</identifier>
 <datestamp>2010-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2242</id><created>2008-01-15</created><updated>2008-08-22</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Information Spectrum Approach to Second-Order Coding Rate in Channel
  Coding</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory Volume 55, Issue 11, 4947
  - 4966 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Second-order coding rate of channel coding is discussed for general sequence
of channels. The optimum second-order transmission rate with a constant error
constraint $\epsilon$ is obtained by using the information spectrum method. We
apply this result to the discrete memoryless case, the discrete memoryless case
with a cost constraint, the additive Markovian case, and the Gaussian channel
case with an energy constraint. We also clarify that the Gallager bound does
not give the optimum evaluation in the second-order coding rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2284</identifier>
 <datestamp>2008-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2284</id><created>2008-01-15</created><updated>2008-01-19</updated><authors><author><keyname>Kettani</keyname><forenames>Omar</forenames></author></authors><title>Le probleme de l'isomorphisme de graphes est dans P</title><categories>cs.DM cs.DS</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn by the author, due to possible
counter-examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2323</identifier>
 <datestamp>2008-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2323</id><created>2008-01-15</created><updated>2008-04-29</updated><authors><author><keyname>Cui</keyname><forenames>Shengshan</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames></author><author><keyname>Somekh</keyname><forenames>Oren</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Decentralized Two-Hop Opportunistic Relaying With Limited Channel State
  Information</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Symposium on Information
  Theory, Toronto, ON, Canada, July 6 - 11, 2008</comments><abstract>  A network consisting of $n$ source-destination pairs and $m$ relays is
considered. Focusing on the large system limit (large $n$), the throughput
scaling laws of two-hop relaying protocols are studied for Rayleigh fading
channels. It is shown that, under the practical constraints of single-user
encoding-decoding scheme, and partial channel state information (CSI) at the
transmitters (via integer-value feedback from the receivers), the maximal
throughput scales as $\log n$ even if full relay cooperation is allowed.
Furthermore, a novel decentralized opportunistic relaying scheme with receiver
CSI, partial transmitter CSI, and no relay cooperation, is shown to achieve the
optimal throughput scaling law of $\log n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2345</identifier>
 <datestamp>2008-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2345</id><created>2008-01-15</created><updated>2008-07-18</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author></authors><title>On the relationship between the structural and socioacademic communities
  of a coauthorship network</title><categories>cs.DL cs.GL physics.soc-ph</categories><report-no>LA-UR-07-8339</report-no><acm-class>H.3.7; G.2.2</acm-class><journal-ref>Journal of Informetrics, volume 2, issue 3, pages 195-201, ISSN:
  1751-1577, Elsevier, July 2008</journal-ref><doi>10.1016/j.joi.2008.04.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a study that compares detected structural communities
in a coauthorship network to the socioacademic characteristics of the scholars
that compose the network. The coauthorship network was created from the
bibliographic record of a multi-institution, interdisciplinary research group
focused on the study of sensor networks and wireless communication. Four
different community detection algorithms were employed to assign a structural
community to each scholar in the network: leading eigenvector, walktrap, edge
betweenness and spinglass. Socioacademic characteristics were gathered from the
scholars and include such information as their academic department, academic
affiliation, country of origin, and academic position. A Pearson's $\chi^2$
test, with a simulated Monte Carlo, revealed that structural communities best
represent groupings of individuals working in the same academic department and
at the same institution. A generalization of this result suggests that, even in
interdisciplinary, multi-institutional research groups, coauthorship is
primarily driven by departmental and institutional affiliation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2347</identifier>
 <datestamp>2008-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2347</id><created>2008-01-15</created><authors><author><keyname>Buslov</keyname><forenames>V. A.</forenames></author><author><keyname>Khudobakhshov</keyname><forenames>V. A.</forenames></author></authors><title>On the Minimum Spanning Tree for Directed Graphs with Potential Weights</title><categories>cs.DM</categories><comments>3 pages</comments><abstract>  In general the problem of finding a miminum spanning tree for a weighted
directed graph is difficult but solvable. There are a lot of differences
between problems for directed and undirected graphs, therefore the algorithms
for undirected graphs cannot usually be applied to the directed case. In this
paper we examine the kind of weights such that the problems are equivalent and
a minimum spanning tree of a directed graph may be found by a simple algorithm
for an undirected graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2378</identifier>
 <datestamp>2008-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2378</id><created>2008-01-15</created><authors><author><keyname>Ferragina</keyname><forenames>Paolo</forenames></author></authors><title>String algorithms and data structures</title><categories>cs.DS cs.IR</categories><abstract>  The string-matching field has grown at a such complicated stage that various
issues come into play when studying it: data structure and algorithmic design,
database principles, compression techniques, architectural features, cache and
prefetching policies. The expertise nowadays required to design good string
data structures and algorithms is therefore transversal to many computer
science fields and much more study on the orchestration of known, or novel,
techniques is needed to make progress in this fascinating topic. This survey is
aimed at illustrating the key ideas which should constitute, in our opinion,
the current background of every index designer. We also discuss the positive
features and drawback of known indexing schemes and algorithms, and devote much
attention to detail research issues and open problems both on the theoretical
and the experimental side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2398</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2398</id><created>2008-01-15</created><updated>2008-01-18</updated><authors><author><keyname>Hou</keyname><forenames>Thomas Y.</forenames></author><author><keyname>Shi</keyname><forenames>Zuoqiang</forenames></author></authors><title>Removing the Stiffness of Elastic Force from the Immersed Boundary
  Method for the 2D Stokes Equations</title><categories>cs.CE cs.NA math.NA</categories><comments>40 pages with 8 figures</comments><doi>10.1016/j.jcp.2008.03.002</doi><abstract>  The Immersed Boundary method has evolved into one of the most useful
computational methods in studying fluid structure interaction. On the other
hand, the Immersed Boundary method is also known to suffer from a severe
timestep stability restriction when using an explicit time discretization. In
this paper, we propose several efficient semi-implicit schemes to remove this
stiffness from the Immersed Boundary method for the two-dimensional Stokes
flow. First, we obtain a novel unconditionally stable semi-implicit
discretization for the immersed boundary problem. Using this unconditionally
stable discretization as a building block, we derive several efficient
semi-implicit schemes for the immersed boundary problem by applying the Small
Scale Decomposition to this unconditionally stable discretization. Our
stability analysis and extensive numerical experiments show that our
semi-implicit schemes offer much better stability property than the explicit
scheme. Unlike other implicit or semi-implicit schemes proposed in the
literature, our semi-implicit schemes can be solved explicitly in the spectral
space. Thus the computational cost of our semi-implicit schemes is comparable
to that of an explicit scheme, but with a much better stability property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2405</identifier>
 <datestamp>2009-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2405</id><created>2008-01-15</created><updated>2009-02-25</updated><authors><author><keyname>Haroz</keyname><forenames>Steve</forenames></author><author><keyname>Ma</keyname><forenames>Kwan-Liu</forenames></author><author><keyname>Heitmann</keyname><forenames>Katrin</forenames></author></authors><title>Multiple Uncertainties in Time-Variant Cosmological Particle Data</title><categories>astro-ph cs.GR cs.HC</categories><comments>8 pages, 8 figures, published in Pacific Vis 2008, project website at
  http://steveharoz.com/research/cosmology/</comments><report-no>LAUR-08-0052</report-no><journal-ref>Haroz, S; Ma, K-L; Heitmann, K, &quot;Multiple Uncertainties in
  Time-Variant Cosmological Particle Data&quot; IEEE PacificVIS '08, pp.207-214, 5-7
  March 2008</journal-ref><doi>10.1109/PACIFICVIS.2008.4475478</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Though the mediums for visualization are limited, the potential dimensions of
a dataset are not. In many areas of scientific study, understanding the
correlations between those dimensions and their uncertainties is pivotal to
mining useful information from a dataset. Obtaining this insight can
necessitate visualizing the many relationships among temporal, spatial, and
other dimensionalities of data and its uncertainties. We utilize multiple views
for interactive dataset exploration and selection of important features, and we
apply those techniques to the unique challenges of cosmological particle
datasets. We show how interactivity and incorporation of multiple visualization
techniques help overcome the problem of limited visualization dimensions and
allow many types of uncertainty to be seen in correlation with other variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2423</identifier>
 <datestamp>2008-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2423</id><created>2008-01-15</created><authors><author><keyname>Wang</keyname><forenames>Qingchuan</forenames></author><author><keyname>He</keyname><forenames>Chen</forenames></author></authors><title>Design and Analysis of LDGM-Based Codes for MSE Quantization</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><acm-class>E.4</acm-class><abstract>  Approaching the 1.5329-dB shaping (granular) gain limit in mean-squared error
(MSE) quantization of R^n is important in a number of problems, notably
dirty-paper coding. For this purpose, we start with a binary low-density
generator-matrix (LDGM) code, and construct the quantization codebook by
periodically repeating its set of binary codewords, or them mapped to m-ary
ones with Gray mapping. The quantization algorithm is based on belief
propagation, and it uses a decimation procedure to do the guessing necessary
for convergence. Using the results of a true typical decimator (TTD) as
reference, it is shown that the asymptotic performance of the proposed
quantizer can be characterized by certain monotonicity conditions on the code's
fixed point properties, which can be analyzed with density evolution, and
degree distribution optimization can be carried out accordingly. When the
number of iterations is finite, the resulting loss is made amenable to analysis
through the introduction of a recovery algorithm from ``bad'' guesses, and the
results of such analysis enable further optimization of the pace of decimation
and the degree distribution. Simulation results show that the proposed
LDGM-based quantizer can achieve a shaping gain of 1.4906 dB, or 0.0423 dB from
the limit, and significantly outperforms trellis-coded quantization (TCQ) at a
similar computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2480</identifier>
 <datestamp>2008-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2480</id><created>2008-01-16</created><authors><author><keyname>Scutari</keyname><forenames>Gesualdo</forenames></author><author><keyname>Palomar</keyname><forenames>Daniel P.</forenames></author><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author></authors><title>Asynchronous Iterative Waterfilling for Gaussian Frequency-Selective
  Interference Channels</title><categories>cs.IT cs.GT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, August 22,
  2006. Revised September 25, 2007. Accepted January 14, 2008. To appear on
  IEEE Transactions on Information Theory, 2008</comments><abstract>  This paper considers the maximization of information rates for the Gaussian
frequency-selective interference channel, subject to power and spectral mask
constraints on each link. To derive decentralized solutions that do not require
any cooperation among the users, the optimization problem is formulated as a
static noncooperative game of complete information. To achieve the so-called
Nash equilibria of the game, we propose a new distributed algorithm called
asynchronous iterative waterfilling algorithm. In this algorithm, the users
update their power spectral density in a completely distributed and
asynchronous way: some users may update their power allocation more frequently
than others and they may even use outdated measurements of the received
interference. The proposed algorithm represents a unified framework that
encompasses and generalizes all known iterative waterfilling algorithms, e.g.,
sequential and simultaneous versions. The main result of the paper consists of
a unified set of conditions that guarantee the global converge of the proposed
algorithm to the (unique) Nash equilibrium of the game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2498</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2498</id><created>2008-01-16</created><updated>2008-03-25</updated><authors><author><keyname>B&#xe8;s</keyname><forenames>Alexis</forenames></author></authors><title>An Application of the Feferman-Vaught Theorem to Automata and Logics
  for&lt;br&gt; Words over an Infinite Alphabet</title><categories>cs.LO</categories><comments>24 pages</comments><acm-class>F.1.1; F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 1 (March 25,
  2008) lmcs:1202</journal-ref><doi>10.2168/LMCS-4(1:8)2008</doi><abstract>  We show that a special case of the Feferman-Vaught composition theorem gives
rise to a natural notion of automata for finite words over an infinite
alphabet, with good closure and decidability properties, as well as several
logical characterizations. We also consider a slight extension of the
Feferman-Vaught formalism which allows to express more relations between
component values (such as equality), and prove related decidability results.
  From this result we get new classes of decidable logics for words over an
infinite alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2510</identifier>
 <datestamp>2008-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2510</id><created>2008-01-16</created><authors><author><keyname>Gillet</keyname><forenames>J.</forenames></author><author><keyname>Ausloos</keyname><forenames>M.</forenames></author></authors><title>A Comparison of natural (english) and artificial (esperanto) languages.
  A Multifractal method based analysis</title><categories>cs.CL physics.data-an</categories><comments>7 pages, 4 double figures, 45 references</comments><abstract>  We present a comparison of two english texts, written by Lewis Carroll, one
(Alice in wonderland) and the other (Through a looking glass), the former
translated into esperanto, in order to observe whether natural and artificial
languages significantly differ from each other. We construct one dimensional
time series like signals using either word lengths or word frequencies. We use
the multifractal ideas for sorting out correlations in the writings. In order
to check the robustness of the methods we also write the corresponding shuffled
texts. We compare characteristic functions and e.g. observe marked differences
in the (far from parabolic) f(alpha) curves, differences which we attribute to
Tsallis non extensive statistical features in the ''frequency time series'' and
''length time series''. The esperanto text has more extreme vallues. A very
rough approximation consists in modeling the texts as a random Cantor set if
resulting from a binomial cascade of long and short words (or words and
blanks). This leads to parameters characterizing the text style, and most
likely in fine the author writings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2588</identifier>
 <datestamp>2008-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2588</id><created>2008-01-16</created><authors><author><keyname>Kumar</keyname><forenames>K. Raj</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Coding and Decoding for the Dynamic Decode and Forward Relay Protocol</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><abstract>  We study the Dynamic Decode and Forward (DDF) protocol for a single
half-duplex relay, single-antenna channel with quasi-static fading. The DDF
protocol is well-known and has been analyzed in terms of the
Diversity-Multiplexing Tradeoff (DMT) in the infinite block length limit. We
characterize the finite block length DMT and give new explicit code
constructions. The finite block length analysis illuminates a few key aspects
that have been neglected in the previous literature: 1) we show that one
dominating cause of degradation with respect to the infinite block length
regime is the event of decoding error at the relay; 2) we explicitly take into
account the fact that the destination does not generally know a priori the
relay decision time at which the relay switches from listening to transmit
mode. Both the above problems can be tackled by a careful design of the
decoding algorithm. In particular, we introduce a decision rejection criterion
at the relay based on Forney's decision rule (a variant of the Neyman-Pearson
rule), such that the relay triggers transmission only when its decision is
reliable. Also, we show that a receiver based on the Generalized Likelihood
Ratio Test rule that jointly decodes the relay decision time and the
information message achieves the optimal DMT. Our results show that no cyclic
redundancy check (CRC) for error detection or additional protocol overhead to
communicate the decision time are needed for DDF. Finally, we investigate the
use of minimum mean squared error generalized decision feedback equalizer
(MMSE-GDFE) lattice decoding at both the relay and the destination, and show
that it provides near optimal performance at moderate complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2618</identifier>
 <datestamp>2008-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2618</id><created>2008-01-17</created><authors><author><keyname>Doyle</keyname><forenames>Barry</forenames><affiliation>University of California, Irvine</affiliation></author><author><keyname>Lopes</keyname><forenames>Cristina Videira</forenames><affiliation>University of California, Irvine</affiliation></author></authors><title>Survey of Technologies for Web Application Development</title><categories>cs.SE cs.IR cs.NI</categories><comments>43 pages</comments><acm-class>A.1; D.1.0; D.1.1; D.2.11; H.3.5; H.5.4</acm-class><abstract>  Web-based application developers face a dizzying array of platforms,
languages, frameworks and technical artifacts to choose from. We survey,
classify, and compare technologies supporting Web application development. The
classification is based on (1) foundational technologies; (2)integration with
other information sources; and (3) dynamic content generation. We further
survey and classify software engineering techniques and tools that have been
adopted from traditional programming into Web programming. We conclude that,
although the infrastructure problems of the Web have largely been solved, the
cacophony of technologies for Web-based applications reflects the lack of a
solid model tailored for this domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2666</identifier>
 <datestamp>2008-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2666</id><created>2008-01-17</created><authors><author><keyname>Reynier</keyname><forenames>Christophe</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author><author><keyname>Fourneret</keyname><forenames>Philippe</forenames><affiliation>TIMC</affiliation></author><author><keyname>Dusserre</keyname><forenames>Andr&#xe9;</forenames><affiliation>CHU-Grenoble radio</affiliation></author><author><keyname>Gay-Jeune</keyname><forenames>C&#xe9;cile</forenames><affiliation>CHU-Grenoble radio</affiliation></author><author><keyname>Descotes</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Bolla</keyname><forenames>Michel</forenames></author><author><keyname>Giraud</keyname><forenames>Jean-Yves</forenames></author></authors><title>MRI/TRUS data fusion for prostate brachytherapy. Preliminary results</title><categories>cs.OH</categories><proxy>ccsd hal-00206282</proxy><journal-ref>Medical Physics 31, 6 (2004) 1568-75</journal-ref><abstract>  Prostate brachytherapy involves implanting radioactive seeds (I125 for
instance) permanently in the gland for the treatment of localized prostate
cancers, e.g., cT1c-T2a N0 M0 with good prognostic factors. Treatment planning
and seed implanting are most often based on the intensive use of transrectal
ultrasound (TRUS) imaging. This is not easy because prostate visualization is
difficult in this imaging modality particularly as regards the apex of the
gland and from an intra- and interobserver variability standpoint. Radioactive
seeds are implanted inside open interventional MR machines in some centers.
Since MRI was shown to be sensitive and specific for prostate imaging whilst
open MR is prohibitive for most centers and makes surgical procedures very
complex, this work suggests bringing the MR virtually in the operating room
with MRI/TRUS data fusion. This involves providing the physician with
bi-modality images (TRUS plus MRI) intended to improve treatment planning from
the data registration stage. The paper describes the method developed and
implemented in the PROCUR system. Results are reported for a phantom and first
series of patients. Phantom experiments helped characterize the accuracy of the
process. Patient experiments have shown that using MRI data linked with TRUS
data improves TRUS image segmentation especially regarding the apex and base of
the prostate. This may significantly modify prostate volume definition and have
an impact on treatment planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2793</identifier>
 <datestamp>2008-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2793</id><created>2008-01-17</created><updated>2008-05-09</updated><authors><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author></authors><title>Algorithms for eps-approximations of Terrains</title><categories>cs.CG</categories><comments>24 pages. Long version to supplement conference version to appear in
  ICALP in May 2008</comments><abstract>  Consider a point set D with a measure function w : D -&gt; R. Let A be the set
of subsets of D induced by containment in a shape from some geometric family
(e.g. axis-aligned rectangles, half planes, balls, k-oriented polygons). We say
a range space (D, A) has an eps-approximation P if max {R \in A} | w(R \cap
P)/w(P) - w(R \cap D)/w(D) | &lt;= eps. We describe algorithms for
deterministically constructing discrete eps-approximations for continuous point
sets such as distributions or terrains. Furthermore, for certain families of
subsets A, such as those described by axis-aligned rectangles, we reduce the
size of the eps-approximations by almost a square root from O(1/eps^2 log
1/eps) to O(1/eps polylog 1/eps). This is often the first step in transforming
a continuous problem into a discrete one for which combinatorial techniques can
be applied. We describe applications of this result in geo-spatial analysis,
biosurveillance, and sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2823</identifier>
 <datestamp>2008-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2823</id><created>2008-01-18</created><authors><author><keyname>Schers</keyname><forenames>Jonathan</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Fouard</keyname><forenames>C&#xe9;line</forenames><affiliation>TIMC</affiliation></author><author><keyname>Plaskos</keyname><forenames>Christopher</forenames></author><author><keyname>Kilian</keyname><forenames>Pascal</forenames></author></authors><title>3D/4D ultrasound registration of bone</title><categories>cs.OH physics.med-ph</categories><proxy>ccsd hal-00207587</proxy><journal-ref>Dans IEEE International Ultrasonic Symposium, 2007 - IEEE
  International Ultrasonic Symposium, 2007, New-York : \'Etats-Unis
  d'Am\'erique (2007)</journal-ref><doi>10.1109/ULTSYM.2007.634</doi><abstract>  This paper presents a method to reduce the invasiveness of Computer Assisted
Orthopaedic Surgery (CAOS) using ultrasound. In this goal, we need to develop a
method for 3D/4D ultrasound registration. The premilinary results of this study
suggest that the development of a robust and ``realtime'' 3D/4D ultrasound
registration is feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2838</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2838</id><created>2008-01-18</created><updated>2010-11-23</updated><authors><author><keyname>Trahtman</keyname><forenames>A. N.</forenames></author></authors><title>An Algorithm for Road Coloring</title><categories>cs.DM</categories><comments>10 pages</comments><acm-class>G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A coloring of edges of a finite directed graph turns the graph into
finite-state automaton. The synchronizing word of a deterministic automaton is
a word in the alphabet of colors (considered as letters) of its edges that maps
the automaton to a single state. A coloring of edges of a directed graph of
uniform outdegree (constant outdegree of any vertex) is synchronizing if the
coloring turns the graph into a deterministic finite automaton possessing a
synchronizing word. The road coloring problem is the problem of synchronizing
coloring of a directed finite strongly connected graph of uniform outdegree if
the greatest common divisor of the lengths of all its cycles is one. The
problem posed in 1970 had evoked a noticeable interest among the specialists in
the theory of graphs, automata, codes, symbolic dynamics as well as among the
wide mathematical community. A polynomial time algorithm of $O(n^3)$ complexity
in the most worst case and quadratic in majority of studied cases for the road
coloring of the considered graph is presented below. The work is based on
recent positive solution of the road coloring problem. The algorithm was
implemented in the package TESTAS
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2858</identifier>
 <datestamp>2008-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2858</id><created>2008-01-18</created><authors><author><keyname>Altarelli</keyname><forenames>Fabrizio</forenames></author></authors><title>Theoretical analysis of optimization problems - Some properties of
  random k-SAT and k-XORSAT</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC</categories><comments>Ph.D. thesis, 132 pages</comments><abstract>  This thesis is divided in two parts. The first presents an overview of known
results in statistical mechanics of disordered systems and its approach to
random combinatorial optimization problems. The second part is a discussion of
two original results.
  The first result concerns DPLL heuristics for random k-XORSAT, which is
equivalent to the diluted Ising p-spin model. It is well known that DPLL is
unable to find the ground states in the clustered phase of the problem, i.e.
that it leads to contradictions with probability 1. However, no solid argument
supports this is general. A class of heuristics, which includes the well known
UC and GUC, is introduced and studied. It is shown that any heuristic in this
class must fail if the clause to variable ratio is larger than some constant,
which depends on the heuristic but is always smaller than the clustering
threshold.
  The second result concerns the properties of random k-SAT at large clause to
variable ratios. In this regime, it is well known that the uniform distribution
of random instances is dominated by unsatisfiable instances. A general
technique (based on the Replica method) to restrict the distribution to
satisfiable instances with uniform weight is introduced, and is used to
characterize their solutions. It is found that in the limit of large clause to
variable ratios, the uniform distribution of satisfiable random k-SAT formulas
is asymptotically equal to the much studied Planted distribution.
  Both results are already published and available as arXiv:0709.0367 and
arXiv:cs/0609101 . A more detailed and self-contained derivation is presented
here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2890</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2890</id><created>2008-01-18</created><authors><author><keyname>Dall'Asta</keyname><forenames>L.</forenames></author><author><keyname>Ramezanpour</keyname><forenames>A.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Entropy landscape and non-Gibbs solutions in constraint satisfaction
  problems</title><categories>cond-mat.stat-mech cs.CC</categories><comments>38 pages, 10 figures</comments><journal-ref>Phys. Rev. E 77, 031118 (2008)</journal-ref><doi>10.1103/PhysRevE.77.031118</doi><abstract>  We study the entropy landscape of solutions for the bicoloring problem in
random graphs, a representative difficult constraint satisfaction problem. Our
goal is to classify which type of clusters of solutions are addressed by
different algorithms. In the first part of the study we use the cavity method
to obtain the number of clusters with a given internal entropy and determine
the phase diagram of the problem, e.g. dynamical, rigidity and SAT-UNSAT
transitions. In the second part of the paper we analyze different algorithms
and locate their behavior in the entropy landscape of the problem. For instance
we show that a smoothed version of a decimation strategy based on Belief
Propagation is able to find solutions belonging to sub-dominant clusters even
beyond the so called rigidity transition where the thermodynamically relevant
clusters become frozen. These non-equilibrium solutions belong to the most
probable unfrozen clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2931</identifier>
 <datestamp>2008-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2931</id><created>2008-01-18</created><authors><author><keyname>Feldman</keyname><forenames>Jon</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Nikolova</keyname><forenames>Evdokia</forenames></author><author><keyname>Pal</keyname><forenames>Martin</forenames></author></authors><title>A Truthful Mechanism for Offline Ad Slot Scheduling</title><categories>cs.GT cs.DS</categories><abstract>  We consider the &quot;Offline Ad Slot Scheduling&quot; problem, where advertisers must
be scheduled to &quot;sponsored search&quot; slots during a given period of time.
Advertisers specify a budget constraint, as well as a maximum cost per click,
and may not be assigned to more than one slot for a particular search.
  We give a truthful mechanism under the utility model where bidders try to
maximize their clicks, subject to their personal constraints. In addition, we
show that the revenue-maximizing mechanism is not truthful, but has a Nash
equilibrium whose outcome is identical to our mechanism. As far as we can tell,
this is the first treatment of sponsored search that directly incorporates both
multiple slots and budget constraints into an analysis of incentives.
  Our mechanism employs a descending-price auction that maintains a solution to
a certain machine scheduling problem whose job lengths depend on the price, and
hence is variable over the auction. The price stops when the set of bidders
that can afford that price pack exactly into a block of ad slots, at which
point the mechanism allocates that block and continues on the remaining slots.
To prove our result on the equilibrium of the revenue-maximizing mechanism, we
first show that a greedy algorithm suffices to solve the revenue-maximizing
linear program; we then use this insight to prove that bidders allocated in the
same block of our mechanism have no incentive to deviate from bidding the fixed
price of that block.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3024</identifier>
 <datestamp>2008-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3024</id><created>2008-01-19</created><authors><author><keyname>Pujol</keyname><forenames>J.</forenames></author><author><keyname>Rif&#xe1;</keyname><forenames>J.</forenames></author><author><keyname>Solov'eva</keyname><forenames>F. I.</forenames></author></authors><title>Construction of Z4-linear Reed-Muller codes</title><categories>cs.IT math.IT</categories><comments>Paper submitted to IEEE Transactions on Information Theory</comments><msc-class>68P30, 94A29</msc-class><abstract>  New quaternary Plotkin constructions are given and are used to obtain new
families of quaternary codes. The parameters of the obtained codes, such as the
length, the dimension and the minimum distance are studied. Using these
constructions new families of quaternary Reed-Muller codes are built with the
peculiarity that after using the Gray map the obtained Z4-linear codes have the
same parameters and fundamental properties as the codes in the usual binary
linear Reed-Muller family. To make more evident the duality relationships in
the constructed families the concept of Kronecker inner product is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3042</identifier>
 <datestamp>2008-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3042</id><created>2008-01-19</created><authors><author><keyname>Dong</keyname><forenames>Lun</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Performance Analysis of a Cross-layer Collaborative Beamforming Approach
  in the Presence of Channel and Phase Errors</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures, To appear in the Proceedings of the 2008 IEEE
  International Conference on Acoustics, Speech and Signal Processing, Las
  Vegas, NV, March 30 - April 4, 2008</comments><abstract>  Collaborative beamforming enables nodes in a wireless network to transmit a
common message over long distances in an energy efficient fashion. However, the
process of making available the same message to all collaborating nodes
introduces delays. The authors recently proposed a MAC-PHY cross-layer scheme
that enables collaborative beamforming with significantly reduced collaboration
overhead. The method requires knowledge of node locations and internode channel
coefficients. In this paper, the performance of that approach is studied
analytically in terms of average beampattern and symbol error probability (SEP)
under realistic conditions, i.e., when imperfect channel estimates are used and
when there are phase errors in the contributions of the collaborating nodes at
the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3046</identifier>
 <datestamp>2009-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3046</id><created>2008-01-19</created><updated>2009-01-01</updated><authors><author><keyname>Chapwanya</keyname><forenames>Michael</forenames></author><author><keyname>Liu</keyname><forenames>Wentao</forenames></author><author><keyname>Stockie</keyname><forenames>John M.</forenames></author></authors><title>A model for reactive porous transport during re-wetting of hardened
  concrete</title><categories>cs.CE physics.flu-dyn</categories><comments>30 pages</comments><journal-ref>Journal of Engineering Mathematics, 65(1):53-73, 2009</journal-ref><doi>10.1007/s10665-009-9268-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mathematical model is developed that captures the transport of liquid water
in hardened concrete, as well as the chemical reactions that occur between the
imbibed water and the residual calcium silicate compounds residing in the
porous concrete matrix. The main hypothesis in this model is that the reaction
product -- calcium silicate hydrate gel -- clogs the pores within the concrete
thereby hindering water transport. Numerical simulations are employed to
determine the sensitivity of the model solution to changes in various physical
parameters, and compare to experimental results available in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3048</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3048</id><created>2008-01-19</created><authors><author><keyname>Bagnoli</keyname><forenames>Franco</forenames></author><author><keyname>Guazzini</keyname><forenames>Andrea</forenames></author><author><keyname>Lio'</keyname><forenames>Pietro</forenames></author></authors><title>Human Heuristics for Autonomous Agents</title><categories>cs.MA cs.HC cs.NI</categories><comments>12 pages</comments><journal-ref>P. Li\'o et al. editors, BIOWIRE 2007, LNCS 5151, pages 340-351,
  Springer--Verlag Berlin Heidelberg 2008</journal-ref><doi>10.1007/978-3-540-92191-2_30</doi><abstract>  We investigate the problem of autonomous agents processing pieces of
information that may be corrupted (tainted). Agents have the option of
contacting a central database for a reliable check of the status of the
message, but this procedure is costly and therefore should be used with
parsimony. Agents have to evaluate the risk of being infected, and decide if
and when communicating partners are affordable. Trustability is implemented as
a personal (one-to-one) record of past contacts among agents, and as a
mean-field monitoring of the level of message corruption. Moreover, this
information is slowly forgotten in time, so that at the end everybody is
checked against the database. We explore the behavior of a homogeneous system
in the case of a fixed pool of spreaders of corrupted messages, and in the case
of spontaneous appearance of corrupted messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3049</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3049</id><created>2008-01-19</created><authors><author><keyname>Quan</keyname><forenames>Zhi</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author><author><keyname>Sayed</keyname><forenames>Ali. H.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Spatial-Spectral Joint Detection for Wideband Spectrum Sensing in
  Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the 2008 IEEE International
  Conference on Acoustics, Speech and Signal Processing, Las Vegas, NV, March
  30-April 4, 2008</comments><doi>10.1109/TSP.2008.2008540</doi><abstract>  Spectrum sensing is an essential functionality that enables cognitive radios
to detect spectral holes and opportunistically use under-utilized frequency
bands without causing harmful interference to primary networks. Since
individual cognitive radios might not be able to reliably detect weak primary
signals due to channel fading/shadowing, this paper proposes a cooperative
wideband spectrum sensing scheme, referred to as spatial-spectral joint
detection, which is based on a linear combination of the local statistics from
spatially distributed multiple cognitive radios. The cooperative sensing
problem is formulated into an optimization problem, for which suboptimal but
efficient solutions can be obtained through mathematical transformation under
practical conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3065</identifier>
 <datestamp>2008-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3065</id><created>2008-01-20</created><authors><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author></authors><title>Cut Elimination for a Logic with Generic Judgments and Induction</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><abstract>  This paper presents a cut-elimination proof for the logic $LG^\omega$, which
is an extension of a proof system for encoding generic judgments, the logic
$\FOLDNb$ of Miller and Tiu, with an induction principle. The logic
$LG^\omega$, just as $\FOLDNb$, features extensions of first-order
intuitionistic logic with fixed points and a ``generic quantifier'', $\nabla$,
which is used to reason about the dynamics of bindings in object systems
encoded in the logic. A previous attempt to extend $\FOLDNb$ with an induction
principle has been unsuccessful in modeling some behaviours of bindings in
inductive specifications. It turns out that this problem can be solved by
relaxing some restrictions on $\nabla$, in particular by adding the axiom $B
\equiv \nabla x. B$, where $x$ is not free in $B$. We show that by adopting the
equivariance principle, the presentation of the extended logic can be much
simplified. This paper contains the technical proofs for the results stated in
\cite{tiu07entcs}; readers are encouraged to consult \cite{tiu07entcs} for
motivations and examples for $LG^\omega.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3073</identifier>
 <datestamp>2008-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3073</id><created>2008-01-20</created><authors><author><keyname>Sung</keyname><forenames>Youngchul</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Yu</keyname><forenames>Heejung</forenames></author></authors><title>Large Deviations Analysis for the Detection of 2D Hidden Gauss-Markov
  Random Fields Using Sensor Networks</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the 2008 IEEE International
  Conference on Acoustics, Speech and Signal Processing, Las Vegas, NV, March
  30 - April 4, 2008</comments><acm-class>E.4; H.1.1</acm-class><abstract>  The detection of hidden two-dimensional Gauss-Markov random fields using
sensor networks is considered. Under a conditional autoregressive model, the
error exponent for the Neyman-Pearson detector satisfying a fixed level
constraint is obtained using the large deviations principle. For a symmetric
first order autoregressive model, the error exponent is given explicitly in
terms of the SNR and an edge dependence factor (field correlation). The
behavior of the error exponent as a function of correlation strength is seen to
divide into two regions depending on the value of the SNR. At high SNR,
uncorrelated observations maximize the error exponent for a given SNR, whereas
there is non-zero optimal correlation at low SNR. Based on the error exponent,
the energy efficiency (defined as the ratio of the total information gathered
to the total energy required) of ad hoc sensor network for detection is
examined for two sensor deployment models: an infinite area model and and
infinite density model. For a fixed sensor density, the energy efficiency
diminishes to zero at rate O(area^{-1/2}) as the area is increased. On the
other hand, non-zero efficiency is possible for increasing density depending on
the behavior of the physical correlation as a function of the link length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3097</identifier>
 <datestamp>2008-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3097</id><created>2008-01-20</created><authors><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Auction-based Resource Allocation for Multi-relay Asynchronous
  Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the 2008 IEEE International
  Conference on Acoustics, Speech and Signal Processing, Las Vegas, NV, March
  30 to April 4, 2008</comments><abstract>  Resource allocation is considered for cooperative transmissions in
multiple-relay wireless networks. Two auction mechanisms, SNR auctions and
power auctions, are proposed to distributively coordinate the allocation of
power among multiple relays. In the SNR auction, a user chooses the relay with
the lowest weighted price. In the power auction, a user may choose to use
multiple relays simultaneously, depending on the network topology and the
relays' prices. Sufficient conditions for the existence (in both auctions) and
uniqueness (in the SNR auction) of the Nash equilibrium are given. The fairness
of the SNR auction and efficiency of the power auction are further discussed.
It is also proven that users can achieve the unique Nash equilibrium
distributively via best response updates in a completely asynchronous manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3102</identifier>
 <datestamp>2008-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3102</id><created>2008-01-20</created><authors><author><keyname>Wenstrom</keyname><forenames>Mark</forenames><affiliation>Pennsylvania State University</affiliation></author><author><keyname>Bentivegna</keyname><forenames>Eloisa</forenames><affiliation>Pennsylvania State University</affiliation></author><author><keyname>Hurson</keyname><forenames>Ali</forenames><affiliation>Pennsylvania State University</affiliation></author></authors><title>Balancing transparency, efficiency and security in pervasive systems</title><categories>cs.HC cs.IR</categories><comments>52 pages, to be published in Advances in Computers</comments><acm-class>H.m</acm-class><abstract>  This chapter will survey pervasive computing with a look at how its
constraint for transparency affects issues of resource management and security.
The goal of pervasive computing is to render computing transparent, such that
computing resources are ubiquitously offered to the user and services are
proactively performed for a user without his or her intervention. The task of
integrating computing infrastructure into everyday life without making it
excessively invasive brings about tradeoffs between flexibility and robustness,
efficiency and effectiveness, as well as autonomy and reliability. As the
feasibility of ubiquitous computing and its real potential for mass
applications are still a matter of controversy, this chapter will look into the
underlying issues of resource management and authentication to discover how
these can be handled in a least invasive fashion. The discussion will be closed
by an overview of the solutions proposed by current pervasive computing
efforts, both in the area of generic platforms and for dedicated applications
such as pervasive education and healthcare.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3111</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3111</id><created>2008-01-20</created><authors><author><keyname>Pelikan</keyname><forenames>Martin</forenames></author></authors><title>Analysis of Estimation of Distribution Algorithms and Genetic Algorithms
  on NK Landscapes</title><categories>cs.NE cs.AI</categories><comments>Also available at the MEDAL web site, http://medal.cs.umsl.edu/</comments><report-no>MEDAL Report No. 2008001</report-no><acm-class>I.2.6; I.2.8; G.1.6</acm-class><journal-ref>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO-2008), ACM Press, 1033-1040</journal-ref><abstract>  This study analyzes performance of several genetic and evolutionary
algorithms on randomly generated NK fitness landscapes with various values of n
and k. A large number of NK problem instances are first generated for each n
and k, and the global optimum of each instance is obtained using the
branch-and-bound algorithm. Next, the hierarchical Bayesian optimization
algorithm (hBOA), the univariate marginal distribution algorithm (UMDA), and
the simple genetic algorithm (GA) with uniform and two-point crossover
operators are applied to all generated instances. Performance of all algorithms
is then analyzed and compared, and the results are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3112</identifier>
 <datestamp>2008-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3112</id><created>2008-01-20</created><updated>2008-04-30</updated><authors><author><keyname>Raja</keyname><forenames>Adnan</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>The Two User Gaussian Compound Interference Channel</title><categories>cs.IT math.IT</categories><abstract>  We introduce the two user finite state compound Gaussian interference channel
and characterize its capacity region to within one bit. The main contributions
involve both novel inner and outer bounds. The inner bound is multilevel
superposition coding, but the decoding of the levels is opportunistic,
depending on the channel state. The genie aided outer bound is motivated by the
typical error events of the achievable scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3113</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3113</id><created>2008-01-20</created><authors><author><keyname>Pelikan</keyname><forenames>Martin</forenames></author><author><keyname>Sastry</keyname><forenames>Kumara</forenames></author><author><keyname>Goldberg</keyname><forenames>David E.</forenames></author></authors><title>iBOA: The Incremental Bayesian Optimization Algorithm</title><categories>cs.NE cs.AI</categories><comments>Also available at the MEDAL web site, http://medal.cs.umsl.edu/</comments><report-no>MEDAL Report No. 2008002</report-no><acm-class>I.2.6; I.2.8; G.1.6</acm-class><journal-ref>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO-2008), ACM Press, 455-462</journal-ref><abstract>  This paper proposes the incremental Bayesian optimization algorithm (iBOA),
which modifies standard BOA by removing the population of solutions and using
incremental updates of the Bayesian network. iBOA is shown to be able to learn
and exploit unrestricted Bayesian networks using incremental techniques for
updating both the structure as well as the parameters of the probabilistic
model. This represents an important step toward the design of competent
incremental estimation of distribution algorithms that can solve difficult
nearly decomposable problems scalably and reliably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3114</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3114</id><created>2008-01-20</created><authors><author><keyname>Panko</keyname><forenames>Raymond R.</forenames></author></authors><title>Thinking is Bad: Implications of Human Error Research for Spreadsheet
  Research and Practice</title><categories>cs.HC</categories><comments>12 pages including references</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1; K.3; K.6.3</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2007 69-80 ISBN
  978-905617-58-6</journal-ref><abstract>  In the spreadsheet error community, both academics and practitioners
generally have ignored the rich findings produced by a century of human error
research. These findings can suggest ways to reduce errors; we can then test
these suggestions empirically. In addition, research on human error seems to
suggest that several common prescriptions and expectations for reducing errors
are likely to be incorrect. Among the key conclusions from human error research
are that thinking is bad, that spreadsheets are not the cause of spreadsheet
errors, and that reducing errors is extremely difficult.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3116</identifier>
 <datestamp>2008-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3116</id><created>2008-01-20</created><authors><author><keyname>Baxter</keyname><forenames>Ralph</forenames></author></authors><title>Enterprise Spreadsheet Management: A Necessary Good</title><categories>cs.CY</categories><comments>8 pages, includes references</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2007 7-13 ISBN
  978-905617-58-6</journal-ref><abstract>  This paper presents the arguments and supporting business metrics for
Enterprise Spreadsheet Management to be seen as a necessary good. These
arguments are divided into a summary of external business drivers that make it
necessary and the good that may be delivered to business spreadsheet users
involved in repetitive manual processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3117</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3117</id><created>2008-01-20</created><authors><author><keyname>Cao</keyname><forenames>Yongzhi</forenames></author></authors><title>A hierarchy of behavioral equivalences in the $\pi$-calculus with noisy
  channels</title><categories>cs.LO</categories><comments>30 pages, 2 figures</comments><journal-ref>Comput. J., vol. 53, no. 1, pp. 3-20, 2010</journal-ref><abstract>  The $\pi$-calculus is a process algebra where agents interact by sending
communication links to each other via noiseless communication channels. Taking
into account the reality of noisy channels, an extension of the $\pi$-calculus,
called the $\pi_N$-calculus, has been introduced recently. In this paper, we
present an early transitional semantics of the $\pi_N$-calculus, which is not a
directly translated version of the late semantics of $\pi_N$, and then extend
six kinds of behavioral equivalences consisting of reduction bisimilarity,
barbed bisimilarity, barbed equivalence, barbed congruence, bisimilarity, and
full bisimilarity into the $\pi_N$-calculus. Such behavioral equivalences are
cast in a hierarchy, which is helpful to verify behavioral equivalence of two
agents. In particular, we show that due to the noisy nature of channels, the
coincidence of bisimilarity and barbed equivalence, as well as the coincidence
of full bisimilarity and barbed congruence, in the $\pi$-calculus does not hold
in $\pi_N$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3118</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3118</id><created>2008-01-20</created><authors><author><keyname>Murphy</keyname><forenames>Simon</forenames></author></authors><title>Spreadsheet Hell</title><categories>cs.CY</categories><comments>6 pages</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2007 15-20 ISBN
  978-905617-58-6</journal-ref><abstract>  This management paper looks at the real world issues faced by practitioners
managing spreadsheets through the production phase of their life cycle. It
draws on the commercial experience of several developers working with large
corporations, either as employees or consultants or contractors. It provides
commercial examples of some of the practicalities involved with spreadsheet use
around the enterprise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3119</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3119</id><created>2008-01-20</created><authors><author><keyname>Madahar</keyname><forenames>Mukul</forenames></author><author><keyname>Cleary</keyname><forenames>Pat</forenames></author><author><keyname>Ball</keyname><forenames>David</forenames></author></authors><title>Categorisation of Spreadsheet Use within Organisations, Incorporating
  Risk: A Progress Report</title><categories>cs.CY cs.HC</categories><comments>10 pages</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2007 37-45 ISBN
  978-905617-58-6</journal-ref><abstract>  There has been a significant amount of research into spreadsheets over the
last two decades. Errors in spreadsheets are well documented. Once used mainly
for simple functions such as logging, tracking and totalling information,
spreadsheets with enhanced formulas are being used for complex calculative
models. There are many software packages and tools which assist in detecting
errors within spreadsheets. There has been very little evidence of
investigation into the spreadsheet risks associated with the main stream
operations within an organisation. This study is a part of the investigation
into the means of mitigating risks associated with spreadsheet use within
organisations. In this paper the authors present and analyse three proposed
models for categorisation of spreadsheet use and the level of risks involved.
The models are analysed in the light of current knowledge and the general risks
associated with organisations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3147</identifier>
 <datestamp>2008-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3147</id><created>2008-01-21</created><authors><author><keyname>Li</keyname><forenames>Liang</forenames></author><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Tian</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>From k-SAT to k-CSP: Two Generalized Algorithms</title><categories>cs.DS cs.AI cs.CC</categories><acm-class>F.2.2</acm-class><abstract>  Constraint satisfaction problems (CSPs) models many important intractable
NP-hard problems such as propositional satisfiability problem (SAT). Algorithms
with non-trivial upper bounds on running time for restricted SAT with bounded
clause length k (k-SAT) can be classified into three styles: DPLL-like,
PPSZ-like and Local Search, with local search algorithms having already been
generalized to CSP with bounded constraint arity k (k-CSP). We generalize a
DPLL-like algorithm in its simplest form and a PPSZ-like algorithm from k-SAT
to k-CSP. As far as we know, this is the first attempt to use PPSZ-like
strategy to solve k-CSP, and before little work has been focused on the
DPLL-like or PPSZ-like strategies for k-CSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3199</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3199</id><created>2008-01-21</created><updated>2009-08-24</updated><authors><author><keyname>Ho</keyname><forenames>Ngoc-Diep</forenames><affiliation>Universit&#xe9; catholique de Louvain, Belgium</affiliation></author><author><keyname>Van Dooren</keyname><forenames>Paul</forenames><affiliation>Universit&#xe9; catholique de Louvain, Belgium</affiliation></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames><affiliation>Universit&#xe9; catholique de Louvain, Belgium</affiliation></author></authors><title>Descent methods for Nonnegative Matrix Factorization</title><categories>cs.NA cs.IR math.OC</categories><comments>47 pages. New convergence proof using damped version of RRI. To
  appear in Numerical Linear Algebra in Signals, Systems and Control. Accepted.
  Illustrating Matlab code is included in the source bundle</comments><report-no>2007.057</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present several descent methods that can be applied to
nonnegative matrix factorization and we analyze a recently developped fast
block coordinate method called Rank-one Residue Iteration (RRI). We also give a
comparison of these different methods and show that the new block coordinate
method has better properties in terms of approximation error and complexity. By
interpreting this method as a rank-one approximation of the residue matrix, we
prove that it \emph{converges} and also extend it to the nonnegative tensor
factorization and introduce some variants of the method by imposing some
additional controllable constraints such as: sparsity, discreteness and
smoothness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3209</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3209</id><created>2008-01-21</created><updated>2008-03-03</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A Pyramidal Evolutionary Algorithm with Different Inter-Agent Partnering
  Strategies for Scheduling Problems</title><categories>cs.NE cs.CE</categories><journal-ref>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO 2001), late-breaking papers volume, pp 1-8, San Francisco, USA</journal-ref><abstract>  This paper combines the idea of a hierarchical distributed genetic algorithm
with different inter-agent partnering strategies. Cascading clusters of
sub-populations are built from bottom up, with higher-level sub-populations
optimising larger parts of the problem. Hence higher-level sub-populations
search a larger search space with a lower resolution whilst lower-level
sub-populations search a smaller search space with a higher resolution. The
effects of different partner selection schemes amongst the agents on solution
quality are examined for two multiple-choice optimisation problems. It is shown
that partnering strategies that exploit problem-specific knowledge are superior
and can counter inappropriate (sub-) fitness measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3239</identifier>
 <datestamp>2014-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3239</id><created>2008-01-21</created><authors><author><keyname>Buk</keyname><forenames>Solomiya</forenames></author><author><keyname>Rovenchak</keyname><forenames>Andrij</forenames></author></authors><title>Online-concordance &quot;Perekhresni stezhky&quot; (&quot;The Cross-Paths&quot;), a novel by
  Ivan Franko</title><categories>cs.CL cs.DL</categories><comments>in Ukrainian</comments><journal-ref>Ivan Franko: Spirit, Science, Thought, Will (Proceedings of the
  International Scientific Congress dedicated to the 150th anniversary (Lviv,
  27 September -- 1 October 2006, Lviv University Press, Vol. 2, pp. 203-211,
  2010)</journal-ref><abstract>  In the article, theoretical principles and practical realization for the
compilation of the concordance to &quot;Perekhresni stezhky&quot; (&quot;The Cross-Paths&quot;), a
novel by Ivan Franko, are described. Two forms for the context presentation are
proposed. The electronic version of this lexicographic work is available
online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3249</identifier>
 <datestamp>2008-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3249</id><created>2008-01-21</created><authors><author><keyname>Kuehn</keyname><forenames>Christian</forenames></author></authors><title>Complex Eigenvalues for Binary Subdivision Schemes</title><categories>cs.GR cs.NA</categories><comments>7 pages, 2 figures</comments><acm-class>I.3.5</acm-class><abstract>  Convergence properties of binary stationary subdivision schemes for curves
have been analyzed using the techniques of z-transforms and eigenanalysis.
Eigenanalysis provides a way to determine derivative continuity at specific
points based on the eigenvalues of a finite matrix. None of the well-known
subdivision schemes for curves have complex eigenvalues. We prove when a
convergent scheme with palindromic mask can have complex eigenvalues and that a
lower limit for the size of the mask exists in this case. We find a scheme with
complex eigenvalues achieving this lower bound. Furthermore we investigate this
scheme numerically and explain from a geometric viewpoint why such a scheme has
not yet been used in computer-aided geometric design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3272</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3272</id><created>2008-01-21</created><authors><author><keyname>Peters</keyname><forenames>Steven W.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Nonregenerative MIMO Relaying with Optimal Transmit Antenna Selection</title><categories>cs.IT math.IT</categories><doi>10.1109/LSP.2008.921466</doi><abstract>  We derive optimal SNR-based transmit antenna selection rules at the source
and relay for the nonregenerative half duplex MIMO relay channel. While antenna
selection is a suboptimal form of beamforming, it has the advantage that the
optimization is tractable and can be implemented with only a few bits of
feedback from the destination to the source and relay. We compare the bit error
rate of optimal antenna selection at both the source and relay to other
proposed beamforming techniques and propose methods for performing the
necessary limited feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3289</identifier>
 <datestamp>2008-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3289</id><created>2008-01-21</created><authors><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Jiang</keyname><forenames>Hai</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Optimal Medium Access Control in Cognitive Radios: A Sequential Design
  Approach</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear in the Proceedings of the 2008 IEEE International
  Conference on Acoustics, Speech and Signal Processing, Las Vegas, NV, March
  30- April 4, 2008</comments><abstract>  The design of medium access control protocols for a cognitive user wishing to
opportunistically exploit frequency bands within parts of the radio spectrum
having multiple bands is considered. In the scenario under consideration, the
availability probability of each channel is unknown a priori to the cognitive
user. Hence efficient medium access strategies must strike a balance between
exploring the availability of channels and exploiting the opportunities
identified thus far. Using a sequential design approach, an optimal medium
access strategy is derived. To avoid the prohibitive computational complexity
of this optimal strategy, a low complexity asymptotically optimal strategy is
also developed. The proposed strategy does not require any prior statistical
knowledge about the traffic pattern on the different channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3331</identifier>
 <datestamp>2008-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3331</id><created>2008-01-22</created><updated>2008-01-24</updated><authors><author><keyname>Hanrot</keyname><forenames>Guillaume</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Stehl&#xe9;</keyname><forenames>Damien</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Worst-Case Hermite-Korkine-Zolotarev Reduced Lattice Bases</title><categories>math.NT cs.CC cs.CR</categories><proxy>ccsd inria-00211875</proxy><abstract>  The Hermite-Korkine-Zolotarev reduction plays a central role in strong
lattice reduction algorithms. By building upon a technique introduced by Ajtai,
we show the existence of Hermite-Korkine-Zolotarev reduced bases that are
arguably least reduced. We prove that for such bases, Kannan's algorithm
solving the shortest lattice vector problem requires
$d^{\frac{d}{2\e}(1+o(1))}$ bit operations in dimension $d$. This matches the
best complexity upper bound known for this algorithm. These bases also provide
lower bounds on Schnorr's constants $\alpha_d$ and $\beta_d$ that are
essentially equal to the best upper bounds. Finally, we also show the existence
of particularly bad bases for Schnorr's hierarchy of reductions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3408</identifier>
 <datestamp>2008-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3408</id><created>2008-01-22</created><authors><author><keyname>Flarup</keyname><forenames>Uffe</forenames><affiliation>IMADA</affiliation></author><author><keyname>Lyaudet</keyname><forenames>Laurent</forenames><affiliation>LIP</affiliation></author></authors><title>On the expressive power of permanents and perfect matchings of matrices
  of bounded pathwidth/cliquewidth</title><categories>cs.DM</categories><comments>21 pages</comments><proxy>ccsd ensl-00212158</proxy><abstract>  Some 25 years ago Valiant introduced an algebraic model of computation in
order to study the complexity of evaluating families of polynomials. The theory
was introduced along with the complexity classes VP and VNP which are analogues
of the classical classes P and NP. Families of polynomials that are difficult
to evaluate (that is, VNP-complete) includes the permanent and hamiltonian
polynomials. In a previous paper the authors together with P. Koiran studied
the expressive power of permanent and hamiltonian polynomials of matrices of
bounded treewidth, as well as the expressive power of perfect matchings of
planar graphs. It was established that the permanent and hamiltonian
polynomials of matrices of bounded treewidth are equivalent to arithmetic
formulas. Also, the sum of weights of perfect matchings of planar graphs was
shown to be equivalent to (weakly) skew circuits. In this paper we continue the
research in the direction described above, and study the expressive power of
permanents, hamiltonians and perfect matchings of matrices that have bounded
pathwidth or bounded cliquewidth. In particular, we prove that permanents,
hamiltonians and perfect matchings of matrices that have bounded pathwidth
express exactly arithmetic formulas. This is an improvement of our previous
result for matrices of bounded treewidth. Also, for matrices of bounded
weighted cliquewidth we show membership in VP for these polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3511</identifier>
 <datestamp>2008-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3511</id><created>2008-01-23</created><authors><author><keyname>Saeedi</keyname><forenames>Hamid</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>Deterministic Design of Low-Density Parity-Check Codes for Binary
  Erasure Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications, Sept. 2007</comments><abstract>  We propose a deterministic method to design irregular Low-Density
Parity-Check (LDPC) codes for binary erasure channels (BEC). Compared to the
existing methods, which are based on the application of asymptomatic analysis
tools such as density evolution or Extrinsic Information Transfer (EXIT) charts
in an optimization process, the proposed method is much simpler and faster.
Through a number of examples, we demonstrate that the codes designed by the
proposed method perform very closely to the best codes designed by
optimization. An important property of the proposed designs is the flexibility
to select the number of constituent variable node degrees P. The proposed
designs include existing deterministic designs as a special case with P = N-1,
where N is the maximum variable node degree. Compared to the existing
deterministic designs, for a given rate and a given d &gt; 0, the designed
ensembles can have a threshold in d-neighborhood of the capacity upper bound
with smaller values of P and N. They can also achieve the capacity of the BEC
as N, and correspondingly P and the maximum check node degree tend to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3521</identifier>
 <datestamp>2008-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3521</id><created>2008-01-23</created><authors><author><keyname>Hariharan</keyname><forenames>Gautham</forenames></author><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Sayeed</keyname><forenames>Akbar M.</forenames></author></authors><title>Capacity of Sparse Wideband Channels with Partial Channel Feedback</title><categories>cs.IT math.IT</categories><comments>32 pages, 4 figures, Accepted for publication in European
  Transactions on Telecommunication, New Directions in Information Theory</comments><abstract>  This paper studies the ergodic capacity of wideband multipath channels with
limited feedback. Our work builds on recent results that have established the
possibility of significant capacity gains in the wideband/low-SNR regime when
there is perfect channel state information (CSI) at the transmitter.
Furthermore, the perfect CSI benchmark gain can be obtained with the feedback
of just one bit per channel coefficient. However, the input signals used in
these methods are peaky, that is, they have a large peak-to-average power
ratios. Signal peakiness is related to channel coherence and many recent
measurement campaigns show that, in contrast to previous assumptions, wideband
channels exhibit a sparse multipath structure that naturally leads to coherence
in time and frequency. In this work, we first show that even an instantaneous
power constraint is sufficient to achieve the benchmark gain when perfect CSI
is available at the receiver. In the more realistic non-coherent setting, we
study the performance of a training-based signaling scheme. We show that
multipath sparsity can be leveraged to achieve the benchmark gain under both
average as well as instantaneous power constraints as long as the channel
coherence scales at a sufficiently fast rate with signal space dimensions. We
also present rules of thumb on choosing signaling parameters as a function of
the channel parameters so that the full benefits of sparsity can be realized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3526</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3526</id><created>2008-01-23</created><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venu</forenames></author><author><keyname>Sayeed</keyname><forenames>Akbar</forenames></author></authors><title>Quantized Multimode Precoding in Spatially Correlated Multi-Antenna
  Channels</title><categories>cs.IT math.IT</categories><comments>30 pages, 4 figures, Preprint to be submitted to IEEE Transactions on
  Signal Processing</comments><doi>10.1109/TSP.2008.2005748</doi><abstract>  Multimode precoding, where the number of independent data-streams is adapted
optimally, can be used to maximize the achievable throughput in multi-antenna
communication systems. Motivated by standardization efforts embraced by the
industry, the focus of this work is on systematic precoder design with
realistic assumptions on the spatial correlation, channel state information
(CSI) at the transmitter and the receiver, and implementation complexity. For
spatial correlation of the channel matrix, we assume a general channel model,
based on physical principles, that has been verified by many recent measurement
campaigns. We also assume a coherent receiver and knowledge of the spatial
statistics at the transmitter along with the presence of an ideal, low-rate
feedback link from the receiver to the transmitter. The reverse link is used
for codebook-index feedback and the goal of this work is to construct precoder
codebooks, adaptable in response to the statistical information, such that the
achievable throughput is significantly enhanced over that of a fixed,
non-adaptive, i.i.d. codebook design. We illustrate how a codebook of
semiunitary precoder matrices localized around some fixed center on the
Grassmann manifold can be skewed in response to the spatial correlation via
low-complexity maps that can rotate and scale submanifolds on the Grassmann
manifold. The skewed codebook in combination with a lowcomplexity statistical
power allocation scheme is then shown to bridge the gap in performance between
a perfect CSI benchmark and an i.i.d. codebook design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3539</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3539</id><created>2008-01-23</created><updated>2008-05-16</updated><authors><author><keyname>Cayzer</keyname><forenames>Steve</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>On the Effects of Idiotypic Interactions for Recommendation Communities
  in Artificial Immune Systems</title><categories>cs.NE cs.AI</categories><journal-ref>Proceedings of the 1st International Conference on Artificial
  Immune Systems (ICARIS 2002), pp 154-160, Canterbury, UK, 2001</journal-ref><abstract>  It has previously been shown that a recommender based on immune system
idiotypic principles can out perform one based on correlation alone. This paper
reports the results of work in progress, where we undertake some investigations
into the nature of this beneficial effect. The initial findings are that the
immune system recommender tends to produce different neighbourhoods, and that
the superior performance of this recommender is due partly to the different
neighbourhoods, and partly to the way that the idiotypic effect is used to
weight each neighbours recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3547</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3547</id><created>2008-01-23</created><updated>2008-03-03</updated><authors><author><keyname>Cazyer</keyname><forenames>Steve</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A Recommender System based on the Immune Network</title><categories>cs.NE cs.AI</categories><journal-ref>Proceedings of the IEEE Congress on Evolutionary Computation (CEC
  2002), pp 807-813, Honolulu, USA, 2002</journal-ref><abstract>  The immune system is a complex biological system with a highly distributed,
adaptive and self-organising nature. This paper presents an artificial immune
system (AIS) that exploits some of these characteristics and is applied to the
task of film recommendation by collaborative filtering (CF). Natural evolution
and in particular the immune system have not been designed for classical
optimisation. However, for this problem, we are not interested in finding a
single optimum. Rather we intend to identify a sub-set of good matches on which
recommendations can be based. It is our hypothesis that an AIS built on two
central aspects of the biological immune system will be an ideal candidate to
achieve this: Antigen - antibody interaction for matching and antibody -
antibody interaction for diversity. Computational results are presented in
support of this conjecture and compared to those found by other CF techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3549</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3549</id><created>2008-01-23</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Cayzer</keyname><forenames>Steve</forenames></author></authors><title>The Danger Theory and Its Application to Artificial Immune Systems</title><categories>cs.NE cs.AI cs.CR</categories><journal-ref>Proceedings of the 1st International Conference on Artificial
  Immune Systems (ICARIS 2002), pp 141-148, Canterbury, Uk, 2002</journal-ref><abstract>  Over the last decade, a new idea challenging the classical self-non-self
viewpoint has become popular amongst immunologists. It is called the Danger
Theory. In this conceptual paper, we look at this theory from the perspective
of Artificial Immune System practitioners. An overview of the Danger Theory is
presented with particular emphasis on analogies in the Artificial Immune
Systems world. A number of potential application areas are then used to provide
a framing for a critical assessment of the concept, and its relevance for
Artificial Immune Systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3550</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3550</id><created>2008-01-23</created><updated>2008-03-03</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>Partnering Strategies for Fitness Evaluation in a Pyramidal Evolutionary
  Algorithm</title><categories>cs.NE cs.AI</categories><journal-ref>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO 2002), pp 263-270, New York, USA, 2002</journal-ref><abstract>  This paper combines the idea of a hierarchical distributed genetic algorithm
with different inter-agent partnering strategies. Cascading clusters of
sub-populations are built from bottom up, with higher-level sub-populations
optimising larger parts of the problem. Hence higher-level sub-populations
search a larger search space with a lower resolution whilst lower-level
sub-populations search a smaller search space with a higher resolution. The
effects of different partner selection schemes for (sub-)fitness evaluation
purposes are examined for two multiple-choice optimisation problems. It is
shown that random partnering strategies perform best by providing better
sampling and more diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3581</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3581</id><created>2008-01-23</created><authors><author><keyname>Dinitz</keyname><forenames>Yefim</forenames></author><author><keyname>Elkin</keyname><forenames>Michael</forenames></author><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>Shallow, Low, and Light Trees, and Tight Lower Bounds for Euclidean
  Spanners</title><categories>cs.CG cs.DS</categories><comments>41 pages, 11 figures</comments><acm-class>F.2.2; F.2.3; G.2.2</acm-class><abstract>  We show that for every $n$-point metric space $M$ there exists a spanning
tree $T$ with unweighted diameter $O(\log n)$ and weight $\omega(T) = O(\log n)
\cdot \omega(MST(M))$. Moreover, there is a designated point $rt$ such that for
every point $v$, $dist_T(rt,v) \le (1+\epsilon) \cdot dist_M(rt,v)$, for an
arbitrarily small constant $\epsilon &gt; 0$. We extend this result, and provide a
tradeoff between unweighted diameter and weight, and prove that this tradeoff
is \emph{tight up to constant factors} in the entire range of parameters. These
results enable us to settle a long-standing open question in Computational
Geometry. In STOC'95 Arya et al. devised a construction of Euclidean Spanners
with unweighted diameter $O(\log n)$ and weight $O(\log n) \cdot
\omega(MST(M))$. Ten years later in SODA'05 Agarwal et al. showed that this
result is tight up to a factor of $O(\log \log n)$. We close this gap and show
that the result of Arya et al. is tight up to constant factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3624</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3624</id><created>2008-01-23</created><updated>2008-02-20</updated><authors><author><keyname>Chattopadhyay</keyname><forenames>Arkadev</forenames></author><author><keyname>Ada</keyname><forenames>Anil</forenames></author></authors><title>Multiparty Communication Complexity of Disjointness</title><categories>cs.CC</categories><comments>15 pages, 2 figures</comments><abstract>  We obtain a lower bound of n^Omega(1) on the k-party randomized communication
complexity of the Disjointness function in the `Number on the Forehead' model
of multiparty communication when k is a constant. For k=o(loglog n), the bounds
remain super-polylogarithmic i.e. (log n)^omega(1). The previous best lower
bound for three players until recently was Omega(log n).
  Our bound separates the communication complexity classes NP^{CC}_k and
BPP^{CC}_k for k=o(loglog n). Furthermore, by the results of Beame, Pitassi and
Segerlind \cite{BPS07}, our bound implies proof size lower bounds for
tree-like, degree k-1 threshold systems and superpolynomial size lower bounds
for Lovasz-Schrijver proofs.
  Sherstov \cite{She07b} recently developed a novel technique to obtain lower
bounds on two-party communication using the approximate polynomial degree of
boolean functions. We obtain our results by extending his technique to the
multi-party setting using ideas from Chattopadhyay \cite{Cha07}.
  A similar bound for Disjointness has been recently and independently obtained
by Lee and Shraibman.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3640</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3640</id><created>2008-01-23</created><authors><author><keyname>Betz</keyname><forenames>Sharon</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Energy Efficiency in Multi-Hop CDMA Networks: a Game Theoretic Analysis
  Considering Operating Costs</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the 2008 IEEE International
  Conference on Acoustics, Speech and Signal Processing, Las Vegas, NV, March
  30 -- April 4, 2008</comments><doi>10.1109/TSP.2008.929118</doi><abstract>  A game-theoretic analysis is used to study the effects of receiver choice and
transmit power on the energy efficiency of multi-hop networks in which the
nodes communicate using Direct-Sequence Code Division Multiple Access
(DS-CDMA). A Nash equilibrium of the game in which the network nodes can choose
their receivers as well as their transmit powers to maximize the total number
of bits they transmit per unit of energy spent (including both transmit and
operating energy) is derived. The energy efficiencies resulting from the use of
different linear multiuser receivers in this context are compared for the
non-cooperative game. Significant gains in energy efficiency are observed when
multiuser receivers, particularly the linear minimum mean-square error (MMSE)
receiver, are used instead of conventional matched filter receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3642</identifier>
 <datestamp>2008-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3642</id><created>2008-01-23</created><authors><author><keyname>Metcalf-Burton</keyname><forenames>Jessica Ruth</forenames></author></authors><title>Information Rates of Minimal Non-Matroid-Related Access Structures</title><categories>cs.CR math.CO</categories><comments>8 pages</comments><abstract>  In a secret sharing scheme, shares of a secret are distributed to
participants in such a way that only certain predetermined sets of participants
are qualified to reconstruct the secret. An access structure on a set of
participants specifies which sets are to be qualified. The information rate of
an access structure is a bound on how efficient a secret sharing scheme for
that access structure can be. Marti-Farre and Padro showed that all access
structures with information rate greater than two-thirds are matroid-related,
and Stinson showed that four of the minor-minimal, non-matroid-related access
structures have information rate exactly two-thirds. By a result of Seymour,
there are infinitely many remaining minor-minimal, non-matroid-related access
structures. In this paper we find the exact information rates for all such
structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3654</identifier>
 <datestamp>2008-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3654</id><created>2008-01-23</created><updated>2008-10-27</updated><authors><author><keyname>Zaslavskiy</keyname><forenames>Mikhail</forenames></author><author><keyname>Bach</keyname><forenames>Francis</forenames></author><author><keyname>Vert</keyname><forenames>Jean-Philippe</forenames></author></authors><title>A path following algorithm for the graph matching problem</title><categories>cs.CV cs.DM</categories><comments>23 pages, 13 figures,typo correction, new results in sections 4,5,6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a convex-concave programming approach for the labeled weighted
graph matching problem. The convex-concave programming formulation is obtained
by rewriting the weighted graph matching problem as a least-square problem on
the set of permutation matrices and relaxing it to two different optimization
problems: a quadratic convex and a quadratic concave optimization problem on
the set of doubly stochastic matrices. The concave relaxation has the same
global minimum as the initial graph matching problem, but the search for its
global minimum is also a hard combinatorial problem. We therefore construct an
approximation of the concave problem solution by following a solution path of a
convex-concave problem obtained by linear interpolation of the convex and
concave formulations, starting from the convex relaxation. This method allows
to easily integrate the information on graph label similarities into the
optimization problem, and therefore to perform labeled weighted graph matching.
The algorithm is compared with some of the best performing graph matching
methods on four datasets: simulated graphs, QAPLib, retina vessel images and
handwritten chinese characters. In all cases, the results are competitive with
the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3669</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3669</id><created>2008-01-23</created><updated>2008-07-10</updated><authors><author><keyname>Barak</keyname><forenames>Boaz</forenames></author><author><keyname>Mahmoody-Ghidary</keyname><forenames>Mohammad</forenames></author></authors><title>Merkle Puzzles are Optimal</title><categories>cs.CC</categories><comments>This version fixes a bug in the proof of the previous version of this
  paper, see &quot;Correction of Error&quot; paragraph and Appendix A</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that every key exchange protocol in the random oracle model in which
the honest users make at most n queries to the oracle can be broken by an
adversary making O(n^2) queries to the oracle. This improves on the previous
Omega(n^6) query attack given by Impagliazzo and Rudich (STOC '89). Our bound
is optimal up to a constant factor since Merkle (CACM '78) gave an n query key
exchange protocol in this model that cannot be broken by an adversary making
o(n^2) queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3678</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3678</id><created>2008-01-23</created><authors><author><keyname>Baxter</keyname><forenames>Ralph</forenames></author></authors><title>Regulation and the Integrity of Spreadsheets in the Information Supply
  Chain</title><categories>cs.CY cs.CR</categories><comments>7 Pages including references and diagrams in colour</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2005 95-101
  ISBN:1-902724-16-X</journal-ref><abstract>  Spreadsheets provide many of the key links between information systems,
closing the gap between business needs and the capability of central systems.
Recent regulations have brought these vulnerable parts of information supply
chains into focus. The risk they present to the organisation depends on the
role that they fulfil, with generic differences between their use as modeling
tools and as operational applications. Four sections of the Sarbanes-Oxley Act
(SOX) are particularly relevant to the use of spreadsheets. Compliance with
each of these sections is dependent on maintaining the integrity of those
spreadsheets acting as operational applications. This can be achieved manually
but at high cost. There are a range of commercially available off-the-shelf
solutions that can reduce this cost. These may be divided into those that
assist in the debugging of logic and more recently the arrival of solutions
that monitor the change and user activity taking place in business-critical
spreadsheets. ClusterSeven provides one of these monitoring solutions,
highlighting areas of operational risk whilst also establishing a database of
information to deliver new business intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3680</identifier>
 <datestamp>2008-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3680</id><created>2008-01-23</created><updated>2008-01-24</updated><authors><author><keyname>Barak</keyname><forenames>Boaz</forenames></author><author><keyname>Mahmoody-Ghidary</keyname><forenames>Mohammad</forenames></author></authors><title>Lower Bounds on Signatures from Symmetric Primitives</title><categories>cs.CC cs.CR</categories><abstract>  We show that every construction of one-time signature schemes from a random
oracle achieves black-box security at most 2^{(1+o(1))q}, where q is the total
number of oracle queries asked by the key generation, signing, and verification
algorithms. That is, any such scheme can be broken with probability close to 1
by a (computationally unbounded) adversary making 2^{(1+o(1))q} queries to the
oracle. This is tight up to a constant factor in the number of queries, since a
simple modification of Lamport's one-time signatures (Lamport '79) achieves
2^{(0.812-o(1))q} black-box security using q queries to the oracle.
  Our result extends (with a loss of a constant factor in the number of
queries) also to the random permutation and ideal-cipher oracles. Since the
symmetric primitives (e.g. block ciphers, hash functions, and message
authentication codes) can be constructed by a constant number of queries to the
mentioned oracles, as corollary we get lower bounds on the efficiency of
signature schemes from symmetric primitives when the construction is black-box.
This can be taken as evidence of an inherent efficiency gap between signature
schemes and symmetric primitives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3690</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3690</id><created>2008-01-23</created><authors><author><keyname>Paine</keyname><forenames>Jocelyn</forenames></author></authors><title>Ensuring Spreadsheet Integrity with Model Master</title><categories>cs.PL cs.HC</categories><comments>15 pages; substantive references; code examples</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2001 17-38 ISBN:1 86166
  179 7</journal-ref><abstract>  We have developed the Model Master (MM) language for describing spreadsheets,
and tools for converting MM programs to and from spreadsheets. The MM
decompiler translates a spreadsheet into an MM program which gives a concise
summary of its calculations, layout, and styling. This is valuable when trying
to understand spreadsheets one has not seen before, and when checking for
errors. The MM compiler goes the other way, translating an MM program into a
spreadsheet. This makes possible a new style of development, in which
spreadsheets are generated from textual specifications. This can reduce error
rates compared to working directly with the raw spreadsheet, and gives
important facilities for code reuse. MM programs also offer advantages over
Excel files for the interchange of spreadsheets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3697</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3697</id><created>2008-01-24</created><updated>2013-12-15</updated><authors><author><keyname>Bell</keyname><forenames>George I.</forenames></author></authors><title>The mathematics of Septoku</title><categories>math.CO cs.DM math.GM</categories><comments>11 pages, 9 figures; many minor changes</comments><msc-class>00A08, 97A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Septoku is a Sudoku variant invented by Bruce Oberg, played on a hexagonal
grid of 37 cells. We show that up to rotations, reflections, and symbol
permutations, there are only six valid Septoku boards. In order to have a
unique solution, we show that the minimum number of given values is six. We
generalize the puzzle to other board shapes, and devise a puzzle on a
star-shaped board with 73 cells with six givens which has a unique solution. We
show how this puzzle relates to the unsolved Hadwiger-Nelson problem in
combinatorial geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3702</identifier>
 <datestamp>2008-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3702</id><created>2008-01-23</created><authors><author><keyname>Holliday</keyname><forenames>Tim</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Joint source and channel coding for MIMO systems: Is it better to be
  robust or quick?</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Information Theory, Vol. 54,
  No. 4, April 2008</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 54, No. 4, April
  2008</journal-ref><doi>10.1109/TIT.2008.917725</doi><abstract>  We develop a framework to optimize the tradeoff between diversity,
multiplexing, and delay in MIMO systems to minimize end-to-end distortion. We
first focus on the diversity-multiplexing tradeoff in MIMO systems, and develop
analytical results to minimize distortion of a vector quantizer concatenated
with a space-time MIMO channel code. In the high SNR regime we obtain a
closed-form expression for the end-to-end distortion as a function of the
optimal point on the diversity-multiplexing tradeoff curve. For large but
finite SNR we find this optimal point via convex optimization. We then consider
MIMO systems using ARQ retransmission to provide additional diversity at the
expense of delay. For sources without a delay constraint, distortion is
minimized by maximizing the ARQ window size. This results in an ARQ-enhanced
multiplexing-diversity tradeoff region, with distortion minimized over this
region in the same manner as without ARQ. Under a source delay constraint the
problem formulation changes to account for delay distortion associated with
random message arrival and random ARQ completion times. We use a dynamic
programming formulation to capture the channel diversity-multiplexing tradeoff
at finite SNR as well as the random arrival and retransmission dynamics; we
solve for the optimal multiplexing-diversity-delay tradeoff to minimize
end-to-end distortion associated with the source encoder, channel, and ARQ
retransmissions. Our results show that a delay-sensitive system should adapt
its operating point on the diversity-multiplexing-delay tradeoff region to the
system dynamics. We provide numerical results that demonstrate significant
performance gains of this adaptive policy over a static allocation of
diversity/multiplexing in the channel code and a static ARQ window size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3703</identifier>
 <datestamp>2010-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3703</id><created>2008-01-24</created><updated>2009-04-14</updated><authors><author><keyname>Kuijper</keyname><forenames>Margreta</forenames></author><author><keyname>Pinto</keyname><forenames>Raquel</forenames></author></authors><title>On minimality of convolutional ring encoders</title><categories>cs.IT math.IT</categories><comments>13 pages in v1, submitted; 8 pages in revision v2</comments><journal-ref>IEEE Trans. Information Theory, Vol. 55, No. 11, pp. 4890-4897,
  November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional codes are considered with code sequences modelled as
semi-infinite Laurent series. It is wellknown that a convolutional code C over
a finite group G has a minimal trellis representation that can be derived from
code sequences. It is also wellknown that, for the case that G is a finite
field, any polynomial encoder of C can be algebraically manipulated to yield a
minimal polynomial encoder whose controller canonical realization is a minimal
trellis. In this paper we seek to extend this result to the finite ring case G
= Z_{p^r} by introducing a socalled &quot;p-encoder&quot;. We show how to manipulate a
polynomial encoding of a noncatastrophic convolutional code over Z_{p^r} to
produce a particular type of p-encoder (&quot;minimal p-encoder&quot;) whose controller
canonical realization is a minimal trellis with nonlinear features. The minimum
number of trellis states is then expressed as p^gamma, where gamma is the sum
of the row degrees of the minimal p-encoder. In particular, we show that any
convolutional code over Z_{p^r} admits a delay-free p-encoder which implies the
novel result that delay-freeness is not a property of the code but of the
encoder, just as in the field case. We conjecture that a similar result holds
with respect to catastrophicity, i.e., any catastrophic convolutional code over
Z_{p^r} admits a noncatastrophic p-encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3710</identifier>
 <datestamp>2008-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3710</id><created>2008-01-24</created><authors><author><keyname>Saia</keyname><forenames>Jared</forenames></author><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>Picking up the Pieces: Self-Healing in Reconfigurable Networks</title><categories>cs.DS cs.DC cs.NI</categories><comments>To be presented at IPDPS (IEEE International Parallel &amp; Distributed
  Processing Symposium) 2008</comments><acm-class>C.2.1; C.2.3; C.2.4; C.4; H.3.4</acm-class><abstract>  We consider the problem of self-healing in networks that are reconfigurable
in the sense that they can change their topology during an attack. Our goal is
to maintain connectivity in these networks, even in the presence of repeated
adversarial node deletion, by carefully adding edges after each attack. We
present a new algorithm, DASH, that provably ensures that: 1) the network stays
connected even if an adversary deletes up to all nodes in the network; and 2)
no node ever increases its degree by more than 2 log n, where n is the number
of nodes initially in the network. DASH is fully distributed; adds new edges
only among neighbors of deleted nodes; and has average latency and bandwidth
costs that are at most logarithmic in n. DASH has these properties irrespective
of the topology of the initial network, and is thus orthogonal and
complementary to traditional topology-based approaches to defending against
attack.
  We also prove lower-bounds showing that DASH is asymptotically optimal in
terms of minimizing maximum degree increase over multiple attacks. Finally, we
present empirical results on power-law graphs that show that DASH performs well
in practice, and that it significantly outperforms naive algorithms in reducing
maximum degree increase. We also present empirical results on performance of
our algorithms and a new heuristic with regard to stretch (increase in shortest
path lengths).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3711</identifier>
 <datestamp>2008-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3711</id><created>2008-01-24</created><authors><author><keyname>Baumann</keyname><forenames>Michael</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Leroy</keyname><forenames>Antoine</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>3D-Ultrasound probe calibration for computer-guided diagnosis and
  therapy</title><categories>cs.OH</categories><proxy>ccsd hal-00214270</proxy><journal-ref>Dans Proceedings of CVAMIA'06 - 2nd International workshop on
  Computer Vision Approaches to Medical Image Analysis - CVAMIA'06, Graz :
  Autriche (2006)</journal-ref><abstract>  With the emergence of swept-volume ultrasound (US) probes, precise and almost
real-time US volume imaging has become available. This offers many new
opportunities for computer guided diagnosis and therapy, 3-D images containing
significantly more information than 2-D slices. However, computer guidance
often requires knowledge about the exact position of US voxels relative to a
tracking reference, which can only be achieved through probe calibration. In
this paper we present a 3-D US probe calibration system based on a membrane
phantom. The calibration matrix is retrieved by detection of a membrane plane
in a dozen of US acquisitions of the phantom. Plane detection is robustly
performed with the 2-D Hough transformation. The feature extraction process is
fully automated, calibration requires about 20 minutes and the calibration
system can be used in a clinical context. The precision of the system was
evaluated to a root mean square (RMS) distance error of 1.15mm and to an RMS
angular error of 0.61 degrees. The point reconstruction accuracy was evaluated
to 0.9mm and the angular reconstruction accuracy to 1.79 degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3714</identifier>
 <datestamp>2008-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3714</id><created>2008-01-24</created><authors><author><keyname>DeVos</keyname><forenames>Matt</forenames></author><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Samvel S.</forenames></author></authors><title>5-cycles and the Petersen graph</title><categories>cs.DM</categories><comments>6 pages</comments><abstract>  We show that if G is a connected bridgeless cubic graph whose every 2-factor
is comprised of cycles of length five then G is the Petersen graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3715</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3715</id><created>2008-01-24</created><authors><author><keyname>Ressouche</keyname><forenames>Annie</forenames><affiliation>LEAT</affiliation></author><author><keyname>Gaff&#xe9;</keyname><forenames>Daniel</forenames><affiliation>LEAT</affiliation></author><author><keyname>Roy</keyname><forenames>Val&#xe9;rie</forenames></author></authors><title>Modular Compilation of a Synchronous Language</title><categories>cs.PL cs.LO</categories><proxy>ccsd inria-00213472</proxy><abstract>  Synchronous languages rely on formal methods to ease the development of
applications in an efficient and reusable way. Formal methods have been
advocated as a means of increasing the reliability of systems, especially those
which are safety or business critical. It is still difficult to develop
automatic specification and verification tools due to limitations like state
explosion, undecidability, etc... In this work, we design a new specification
model based on a reactive synchronous approach. Then, we benefit from a formal
framework well suited to perform compilation and formal validation of systems.
In practice, we design and implement a special purpose language (LE) and its
two semantics: the ehavioral semantics helps us to define a program by the set
of its behaviors and avoid ambiguousness in programs' interpretation; the
execution equational semantics allows the modular compilation of programs into
software and hardware targets (c code, vhdl code, fpga synthesis, observers).
Our approach is pertinent considering the two main requirements of critical
realistic applications: the modular compilation allows us to deal with large
systems, the model-based approach provides us with formal validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3773</identifier>
 <datestamp>2009-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3773</id><created>2008-01-24</created><updated>2009-10-03</updated><authors><author><keyname>Danielsen</keyname><forenames>Lars Eirik</forenames></author></authors><title>Graph-Based Classification of Self-Dual Additive Codes over Finite
  Fields</title><categories>cs.IT math.CO math.IT quant-ph</categories><comments>20 pages, 13 figures</comments><journal-ref>Adv. Math. Commun. 3(4), pp. 329-348, 2009</journal-ref><doi>10.3934/amc.2009.3.329</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum stabilizer states over GF(m) can be represented as self-dual additive
codes over GF(m^2). These codes can be represented as weighted graphs, and
orbits of graphs under the generalized local complementation operation
correspond to equivalence classes of codes. We have previously used this fact
to classify self-dual additive codes over GF(4). In this paper we classify
self-dual additive codes over GF(9), GF(16), and GF(25). Assuming that the
classical MDS conjecture holds, we are able to classify all self-dual additive
MDS codes over GF(9) by using an extension technique. We prove that the minimum
distance of a self-dual additive code is related to the minimum vertex degree
in the associated graph orbit. Circulant graph codes are introduced, and a
computer search reveals that this set contains many strong codes. We show that
some of these codes have highly regular graph representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3790</identifier>
 <datestamp>2008-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3790</id><created>2008-01-24</created><updated>2008-04-28</updated><authors><author><keyname>Boros</keyname><forenames>Endre</forenames></author><author><keyname>Elbassioni</keyname><forenames>Khaled</forenames></author><author><keyname>Gurvich</keyname><forenames>Vladimir</forenames></author><author><keyname>Tiwary</keyname><forenames>Hans Raj</forenames></author></authors><title>Characterization of the Vertices and Extreme Directions of the Negative
  Cycles Polyhedron and Hardness of Generating Vertices of 0/1-Polyhedra</title><categories>cs.CC cs.DM</categories><comments>Title typo fixed</comments><acm-class>F.2.2</acm-class><abstract>  Given a graph $G=(V,E)$ and a weight function on the edges $w:E\mapsto\RR$,
we consider the polyhedron $P(G,w)$ of negative-weight flows on $G$, and get a
complete characterization of the vertices and extreme directions of $P(G,w)$.
As a corollary, we show that, unless $P=NP$, there is no output polynomial-time
algorithm to generate all the vertices of a 0/1-polyhedron. This strengthens
the NP-hardness result of Khachiyan et al. (2006) for non 0/1-polyhedra, and
comes in contrast with the polynomiality of vertex enumeration for
0/1-polytopes \cite{BL98} [Bussieck and L\&quot;ubbecke (1998)].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3802</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3802</id><created>2008-01-24</created><updated>2008-12-01</updated><authors><author><keyname>Kosub</keyname><forenames>Sven</forenames></author></authors><title>Dichotomy Results for Fixed-Point Existence Problems for Boolean
  Dynamical Systems</title><categories>cs.CC cond-mat.dis-nn cs.DM nlin.AO nlin.CG</categories><comments>17 pages; this version corrects an error/typo in the 2008/01/24
  version</comments><report-no>TUM-I0701, Institut fuer Informatik, Technische Universitaet
  Muenchen</report-no><acm-class>F.2.2; F.1.1; F.1.3</acm-class><journal-ref>Mathematics in Computer Science, 1(3):487-505, 2008, special issue
  on Modeling and Analysis of Complex Systems</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complete classification of the computational complexity of the fixed-point
existence problem for boolean dynamical systems, i.e., finite discrete
dynamical systems over the domain {0, 1}, is presented. For function classes F
and graph classes G, an (F, G)-system is a boolean dynamical system such that
all local transition functions lie in F and the underlying graph lies in G. Let
F be a class of boolean functions which is closed under composition and let G
be a class of graphs which is closed under taking minors. The following
dichotomy theorems are shown: (1) If F contains the self-dual functions and G
contains the planar graphs then the fixed-point existence problem for (F,
G)-systems with local transition function given by truth-tables is NP-complete;
otherwise, it is decidable in polynomial time. (2) If F contains the self-dual
functions and G contains the graphs having vertex covers of size one then the
fixed-point existence problem for (F, G)-systems with local transition function
given by formulas or circuits is NP-complete; otherwise, it is decidable in
polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3817</identifier>
 <datestamp>2008-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3817</id><created>2008-01-24</created><authors><author><keyname>Kakkonen</keyname><forenames>Tuomo</forenames></author></authors><title>Robustness Evaluation of Two CCG, a PCFG and a Link Grammar Parsers</title><categories>cs.CL</categories><journal-ref>Proceedings of the 3rd Language &amp; Technology Conference: Human
  Language Technologies as a Challenge for Computer Science and Linguistics.
  Poznan, Poland, 2007</journal-ref><abstract>  Robustness in a parser refers to an ability to deal with exceptional
phenomena. A parser is robust if it deals with phenomena outside its normal
range of inputs. This paper reports on a series of robustness evaluations of
state-of-the-art parsers in which we concentrated on one aspect of robustness:
its ability to parse sentences containing misspelled words. We propose two
measures for robustness evaluation based on a comparison of a parser's output
for grammatical input sentences and their noisy counterparts. In this paper, we
use these measures to compare the overall robustness of the four evaluated
parsers, and we present an analysis of the decline in parser performance with
increasing error levels. Our results indicate that performance typically
declines tens of percentage units when parsers are presented with texts
containing misspellings. When it was tested on our purpose-built test set of
443 sentences, the best parser in the experiment (C&amp;C parser) was able to
return exactly the same parse tree for the grammatical and ungrammatical
sentences for 60.8%, 34.0% and 14.9% of the sentences with one, two or three
misspelled words respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3837</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3837</id><created>2008-01-24</created><updated>2011-05-24</updated><authors><author><keyname>Moulin</keyname><forenames>Pierre</forenames></author></authors><title>Universal Fingerprinting: Capacity and Random-Coding Exponents</title><categories>cs.IT math.IT</categories><comments>69 pages, revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies fingerprinting (traitor tracing) games in which the number
of colluders and the collusion channel are unknown. The fingerprints are
embedded into host sequences representing signals to be protected and provide
the receiver with the capability to trace back pirated copies to the colluders.
The colluders and the fingerprint embedder are subject to signal fidelity
constraints. Our problem setup unifies the signal-distortion and Boneh-Shaw
formulations of fingerprinting. The fundamental tradeoffs between fingerprint
codelength, number of users, number of colluders, fidelity constraints, and
decoding reliability are then determined. Several bounds on fingerprinting
capacity have been presented in recent literature. This paper derives exact
capacity formulas and presents a new randomized fingerprinting scheme with the
following properties: (1) the encoder and receiver assume a nominal coalition
size but do not need to know the actual coalition size and the collusion
channel; (2) a tunable parameter $\Delta$ trades off false-positive and
false-negative error exponents; (3) the receiver provides a reliability metric
for its decision; and (4) the scheme is capacity-achieving when the
false-positive exponent $\Delta$ tends to zero and the nominal coalition size
coincides with the actual coalition size.
  A fundamental component of the new scheme is the use of a &quot;time-sharing&quot;
randomized sequence. The decoder is a maximum penalized mutual information
decoder, where the significance of each candidate coalition is assessed
relative to a threshold, and the penalty is proportional to the coalition size.
A much simpler {\em threshold decoder} that satisfies properties (1)---(3)
above but not (4) is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3841</identifier>
 <datestamp>2008-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3841</id><created>2008-01-24</created><authors><author><keyname>Gangasani</keyname><forenames>Sumanth Kumar Reddy</forenames></author></authors><title>Analysis of Prime Reciprocal Sequences in Base 10</title><categories>cs.CR</categories><comments>12 pages, 1 figure</comments><abstract>  Prime reciprocals have applications in coding and cryptography and for
generation of random sequences. This paper investigates the structural
redundancy of prime reciprocals in base 10 in a manner that parallels an
earlier study for binary prime reciprocals. Several different kinds of
structural relationships amongst the digits in reciprocal sequences are
classified with respect to the digit in the least significant place of the
prime. It is also shown that the frequency of digit 0 exceeds that of every
other digit when the entire set of prime reciprocal sequences is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3853</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3853</id><created>2008-01-24</created><authors><author><keyname>Murphy</keyname><forenames>Simon</forenames></author></authors><title>Comparison of Spreadsheets with other Development Tools (limitations,
  solutions, workarounds and alternatives)</title><categories>cs.SE cs.CY</categories><comments>9 pages including references, colour diagrams and comparison tables</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2005 201208
  ISBN:1-902724-16-X</journal-ref><abstract>  The spreadsheet paradigm has some unique risks and challenges that are not
present in more traditional development technologies. Many of the recent
advances in other branches of software development have bypassed spreadsheets
and spreadsheet developers. This paper compares spreadsheets and spreadsheet
development to more traditional platforms such as databases and procedural
languages. It also considers the fundamental danger introduced in the
transition from paper spreadsheets to electronic. Suggestions are made to
manage the risks and work around the limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3864</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3864</id><created>2008-01-24</created><authors><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author></authors><title>Between conjecture and memento: shaping a collective emotional
  perception of the future</title><categories>cs.CL cs.GL</categories><comments>6 pages. AAAI Spring Symposium on Emotion, Personality, and Social
  Behavior</comments><abstract>  Large scale surveys of public mood are costly and often impractical to
perform. However, the web is awash with material indicative of public mood such
as blogs, emails, and web queries. Inexpensive content analysis on such
extensive corpora can be used to assess public mood fluctuations. The work
presented here is concerned with the analysis of the public mood towards the
future. Using an extension of the Profile of Mood States questionnaire, we have
extracted mood indicators from 10,741 emails submitted in 2006 to futureme.org,
a web service that allows its users to send themselves emails to be delivered
at a later date. Our results indicate long-term optimism toward the future, but
medium-term apprehension and confusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3871</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3871</id><created>2008-01-24</created><authors><author><keyname>Zhao</keyname><forenames>Chunyan</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Zheng</keyname><forenames>Zhiming</forenames></author></authors><title>On the Scaling Window of Model RB</title><categories>cs.CC cond-mat.stat-mech cs.AI</categories><abstract>  This paper analyzes the scaling window of a random CSP model (i.e. model RB)
for which we can identify the threshold points exactly, denoted by $r_{cr}$ or
$p_{cr}$. For this model, we establish the scaling window
$W(n,\delta)=(r_{-}(n,\delta), r_{+}(n,\delta))$ such that the probability of a
random instance being satisfiable is greater than $1-\delta$ for
$r&lt;r_{-}(n,\delta)$ and is less than $\delta$ for $r&gt;r_{+}(n,\delta)$.
Specifically, we obtain the following result
$$W(n,\delta)=(r_{cr}-\Theta(\frac{1}{n^{1-\epsilon}\ln n}), \
r_{cr}+\Theta(\frac{1}{n\ln n})),$$ where $0\leq\epsilon&lt;1$ is a constant. A
similar result with respect to the other parameter $p$ is also obtained. Since
the instances generated by model RB have been shown to be hard at the
threshold, this is the first attempt, as far as we know, to analyze the scaling
window of such a model with hard instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3875</identifier>
 <datestamp>2015-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3875</id><created>2008-01-24</created><updated>2008-01-26</updated><authors><author><keyname>Mandel</keyname><forenames>Jan</forenames></author><author><keyname>Beezley</keyname><forenames>Jonathan D.</forenames></author><author><keyname>Chakraborty</keyname><forenames>Soham</forenames></author><author><keyname>Coen</keyname><forenames>Janice L.</forenames></author><author><keyname>Douglas</keyname><forenames>Craig C.</forenames></author><author><keyname>Vodacek</keyname><forenames>Anthony</forenames></author><author><keyname>Wang</keyname><forenames>Zhen</forenames></author></authors><title>Towards a Real-Time Data Driven Wildland Fire Model</title><categories>physics.ao-ph cs.CE</categories><comments>5 pages, 4 figures</comments><report-no>UCD CCM Report 265</report-no><journal-ref>IEEE International Symposium on Parallel and Distributed
  Processing, 2008 (IPDPS 2008), pp. 1-5</journal-ref><doi>10.1109/IPDPS.2008.4536414</doi><abstract>  A wildland fire model based on semi-empirical relations for the spread rate
of a surface fire and post-frontal heat release is coupled with the Weather
Research and Forecasting atmospheric model (WRF). The propagation of the fire
front is implemented by a level set method. Data is assimilated by a morphing
ensemble Kalman filter, which provides amplitude as well as position
corrections. Thermal images of a fire will provide the observations and will be
compared to a synthetic image from the model state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3878</identifier>
 <datestamp>2013-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3878</id><created>2008-01-25</created><updated>2009-03-19</updated><authors><author><keyname>Muramatsu</keyname><forenames>Jun</forenames></author><author><keyname>Miyake</keyname><forenames>Shigeki</forenames></author></authors><title>Hash Property and Coding Theorems for Sparse Matrices and
  Maximum-Likelihood Coding</title><categories>cs.IT math.IT</categories><comments>This manuscript has been submitted to IEEE Transactions on
  Information Theory and a part of this manuscript has been submitted to IEEE
  International Symposium on Information Theory (ISIT2008,ISIT2009). 55 pages
  v2: major changes</comments><journal-ref>IEEE Transactions on Information Theory, vol 56, no. 5,
  pp.2143-2167, May 2010; Corrections: IEEE Transactions on Information Theory,
  vol. 56, no.9, p. 4762, Sep. 2010. Corrections: vol.56, no.9, p.4762, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove the achievability of several coding
problems by using sparse matrices (the maximum column weight grows
logarithmically in the block length) and maximal-likelihood (ML) coding. These
problems are the Slepian-Wolf problem, the Gel'fand-Pinsker problem, the
Wyner-Ziv problem, and the One-helps-one problem (source coding with partial
side information at the decoder). To this end, the notion of a hash property
for an ensemble of functions is introduced and it is proved that an ensemble of
$q$-ary sparse matrices satisfies the hash property. Based on this property, it
is proved that the rate of codes using sparse matrices and maximal-likelihood
(ML) coding can achieve the optimal rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3880</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3880</id><created>2008-01-25</created><authors><author><keyname>Sun</keyname><forenames>Yi</forenames></author></authors><title>Spectral efficiency and optimal medium access control of random access
  systems over large random spreading CDMA</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Trans. on Communications</comments><abstract>  This paper analyzes the spectral efficiency as a function of medium access
control (MAC) for large random spreading CDMA random access systems that employ
a linear receiver. It is shown that located at higher than the physical layer,
MAC along with spreading and power allocation can effectively perform spectral
efficiency maximization and near-far mitigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3908</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3908</id><created>2008-01-25</created><authors><author><keyname>Voss</keyname><forenames>Jakob</forenames></author></authors><title>Encoding changing country codes for the Semantic Web with ISO 3166 and
  SKOS</title><categories>cs.IR</categories><comments>Accepted to appear in the proceedings of the 2nd International Con-
  ference on Metadata and Semantics Research (MTSR 2007)</comments><acm-class>H.3.1</acm-class><abstract>  This paper shows how authority files can be encoded for the Semantic Web with
the Simple Knowledge Organisation System (SKOS). In particular the application
of SKOS for encoding the structure, management, and utilization of country
codes as defined in ISO 3166 is demonstrated. The proposed encoding gives a use
case for SKOS that includes features that have only been discussed little so
far, such as multiple notations, nested concept schemes, changes by versioning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3912</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3912</id><created>2008-01-25</created><authors><author><keyname>Carton</keyname><forenames>Olivier</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>LIP</affiliation></author><author><keyname>Simonnet</keyname><forenames>Pierre</forenames><affiliation>SPE</affiliation></author></authors><title>On the Continuity Set of an omega Rational Function</title><categories>cs.CC cs.LO</categories><comments>Dedicated to Serge Grigorieff on the occasion of his 60th Birthday</comments><proxy>ccsd ensl-00216624</proxy><journal-ref>Theoretical Informatics and Applications (1), 42 (2008) 183-196</journal-ref><abstract>  In this paper, we study the continuity of rational functions realized by
B\&quot;uchi finite state transducers. It has been shown by Prieur that it can be
decided whether such a function is continuous. We prove here that surprisingly,
it cannot be decided whether such a function F has at least one point of
continuity and that its continuity set C(F) cannot be computed. In the case of
a synchronous rational function, we show that its continuity set is rational
and that it can be computed. Furthermore we prove that any rational
Pi^0_2-subset of X^omega for some alphabet X is the continuity set C(F) of an
omega-rational synchronous function F defined on X^omega.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3924</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3924</id><created>2008-01-25</created><authors><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author><author><keyname>Jacobs</keyname><forenames>Bart</forenames></author></authors><title>Increased security through open source</title><categories>cs.CR cs.CY cs.GL cs.SE</categories><journal-ref>Communications of the ACM, 50(1):79-83, 2007</journal-ref><abstract>  In this paper we discuss the impact of open source on both the security and
transparency of a software system. We focus on the more technical aspects of
this issue, combining and extending arguments developed over the years. We
stress that our discussion of the problem only applies to software for general
purpose computing systems. For embedded systems, where the software usually
cannot easily be patched or upgraded, different considerations may apply.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3926</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3926</id><created>2008-01-25</created><authors><author><keyname>Tjhai</keyname><forenames>C.</forenames></author><author><keyname>Tomlinson</keyname><forenames>M.</forenames></author><author><keyname>Ambroze</keyname><forenames>M.</forenames></author><author><keyname>Ahmed</keyname><forenames>M.</forenames></author></authors><title>On the Weight Distribution of the Extended Quadratic Residue Code of
  Prime 137</title><categories>cs.IT cs.DM math.IT</categories><comments>Post-print of 7th International ITG Conference on Source and Channel
  Coding, Ulm, 14--16 January 2008</comments><abstract>  The Hamming weight enumerator function of the formally self-dual even, binary
extended quadratic residue code of prime p = 8m + 1 is given by Gleason's
theorem for singly-even code. Using this theorem, the Hamming weight
distribution of the extended quadratic residue is completely determined once
the number of codewords of Hamming weight j A_j, for 0 &lt;= j &lt;= 2m, are known.
The smallest prime for which the Hamming weight distribution of the
corresponding extended quadratic residue code is unknown is 137. It is shown in
this paper that, for p=137 A_2m = A_34 may be obtained with out the need of
exhaustive codeword enumeration. After the remainder of A_j required by
Gleason's theorem are computed and independently verified using their
congruences, the Hamming weight distributions of the binary augmented and
extended quadratic residue codes of prime 137 are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3930</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3930</id><created>2008-01-25</created><authors><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author><author><keyname>Hubbers</keyname><forenames>Engelbert</forenames></author><author><keyname>Jacobs</keyname><forenames>Bart</forenames></author><author><keyname>Oostdijk</keyname><forenames>Martijn</forenames></author><author><keyname>Schreur</keyname><forenames>Ronny Wichers</forenames></author></authors><title>Crossing Borders: Security and Privacy Issues of the European e-Passport</title><categories>cs.CR cs.CY</categories><journal-ref>1st Int. Workshop on Security, LNCS 4266, pages 152-167, Kyoto,
  Japan, October 23-24 2006</journal-ref><abstract>  The first generation of European e-passports will be issued in 2006. We
discuss how borders are crossed regarding the security and privacy erosion of
the proposed schemes, and show which borders need to be crossed to improve the
security and the privacy protection of the next generation of e-passports. In
particular we discuss attacks on Basic Access Control due to the low entropy of
the data from which the access keys are derived, we sketch the European
proposals for Extended Access Control and the weaknesses in that scheme, and
show how fundamentally different design decisions can make e-passports more
secure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3965</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3965</id><created>2008-01-25</created><authors><author><keyname>Mozer</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Baumann</keyname><forenames>Michael</forenames><affiliation>TIMC</affiliation></author><author><keyname>Chevreau</keyname><forenames>G.</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Moreau-Gaudry</keyname><forenames>Alexandre</forenames><affiliation>TIMC, CHU-Grenoble CIC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Framework for 3D TransRectal Ultrasound</title><categories>cs.OH</categories><proxy>ccsd hal-00216330</proxy><journal-ref>Johns Hopkins University &quot;Prostate Day&quot;, Baltimore : \'Etats-Unis
  d'Am\'erique (2008)</journal-ref><abstract>  Prostate biopsies are mainly performed under 2D TransRectal UltraSound (TRUS)
control by sampling the prostate according to a predefined pattern. In case of
first biopsies, this pattern follows a random systematic plan. Sometimes,
repeat biopsies can be needed to target regions unsampled by previous biopsies
or resample critical regions (for example in case of cancer expectant
management or previous prostatic intraepithelial neoplasia findings). From a
clinical point of view, it could be useful to control the 3D spatial
distribution of theses biopsies inside the prostate. Modern 3D-TRUS probes
allow acquiring high-quality volumes of the prostate in few seconds. We
developed a framework to track the prostate in 3D TRUS images. It means that if
one acquires a reference volume at the beginning of the session and another
during each biopsy, it is possible to determine the relationship between the
prostate in the reference and the others volumes by aligning images. We used
this tool to evaluate the ability of a single operator (a young urologist
assistant professor) to perform a pattern of 12 biopsies under 2D TRUS
guidance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3971</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3971</id><created>2008-01-25</created><updated>2008-05-16</updated><authors><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A Bayesian Optimisation Algorithm for the Nurse Scheduling Problem</title><categories>cs.NE cs.CE</categories><journal-ref>Proceedings of the IEEE Congress on Evolutionary Computation (CEC
  2003), pp 2149-2156, Canberra, Australia, 2003</journal-ref><abstract>  A Bayesian optimization algorithm for the nurse scheduling problem is
presented, which involves choosing a suitable scheduling rule from a set for
each nurses assignment. Unlike our previous work that used Gas to implement
implicit learning, the learning in the proposed algorithm is explicit, ie.
Eventually, we will be able to identify and mix building blocks directly. The
Bayesian optimization algorithm is applied to implement such explicit learning
by building a Bayesian network of the joint distribution of solutions. The
conditional probability of each variable in the network is computed according
to an initial set of promising solutions. Subsequently, each new instance for
each variable is generated, ie in our case, a new rule string has been
obtained. Another set of rule strings will be generated in this way, some of
which will replace previous strings based on fitness selection. If stopping
conditions are not met, the conditional probabilities for all nodes in the
Bayesian network are updated again using the current set of promising rule
strings. Computational results from 52 real data instances demonstrate the
success of this approach. It is also suggested that the learning mechanism in
the proposed approach might be suitable for other scheduling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3982</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3982</id><created>2008-01-25</created><authors><author><keyname>Pellicer-Lostao</keyname><forenames>C.</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>R.</forenames></author></authors><title>Pseudo-Random Bit Generation based on 2D chaotic maps of logistic type
  and its Applications in Chaotic Cryptography</title><categories>nlin.CD cs.CR physics.comp-ph</categories><comments>13 pages, 5 figures, 3 tables</comments><abstract>  Pseudo-Random Bit Generation (PRBG) is required in many aspects of
cryptography as well as in other applications of modern security engineering.
In this work, PRBG based on 2D symmetrical chaotic mappings of logistic type is
considered. The sequences generated with a chaotic PRBG of this type, are
statistically tested and the computational effectiveness of the generators is
estimated. Considering this PRBG valid for cryptography, the size of the
available key space is also calculated. Different cryptographic applications
can be suitable to this PRBG, being a stream cipher probably the most immediate
of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3983</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3983</id><created>2008-01-25</created><authors><author><keyname>Yang</keyname><forenames>Lizhen</forenames></author><author><keyname>Dong</keyname><forenames>Ling</forenames></author><author><keyname>Chen</keyname><forenames>Kefei</forenames></author></authors><title>New Upper Bounds on Sizes of Permutation Arrays</title><categories>cs.IT math.IT</categories><abstract>  A permutation array(or code) of length $n$ and distance $d$, denoted by
$(n,d)$ PA, is a set of permutations $C$ from some fixed set of $n$ elements
such that the Hamming distance between distinct members
$\mathbf{x},\mathbf{y}\in C$ is at least $d$. Let $P(n,d)$ denote the maximum
size of an $(n,d)$ PA. New upper bounds on $P(n,d)$ are given. For constant
$\alpha,\beta$ satisfying certain conditions, whenever $d=\beta n^{\alpha}$,
the new upper bounds are asymptotically better than the previous ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3985</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3985</id><created>2008-01-25</created><updated>2011-01-08</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. Krzysztof</forenames></author><author><keyname>Dziemianczuk</keyname><forenames>M.</forenames></author></authors><title>Cobweb posets - Recent Results</title><categories>math.CO cs.DM</categories><comments>27 pages, 15 figures</comments><msc-class>06A07, 05C70, 05C75, 11B39,</msc-class><journal-ref>Adv. Stud. Contemp. Math. volume 16 (2), 2008 (April) pp. 197-218</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cobweb posets uniquely represented by directed acyclic graphs are such a
generalization of the Fibonacci tree that allows joint combinatorial
interpretation for all of them under admissibility condition. This
interpretation was derived in the source papers ([6,7] and references therein
to the first author).[7,6,8] include natural enquires to be reported on here.
The purpose of this presentation is to report on the progress in solving
computational problems which are quite easily formulated for the new class of
directed acyclic graphs interpreted as Hasse diagrams. The problems posed there
and not yet all solved completely are of crucial importance for the vast class
of new partially ordered sets with joint combinatorial interpretation. These so
called cobweb posets - are relatives of Fibonacci tree and are labeled by
specific number sequences - natural numbers sequence and Fibonacci sequence
included. The cobweb posets might be identified with a chain of di-bicliques
i.e. by definition - a chain of complete bipartite one direction digraphs [6].
Any chain of relations is therefore obtainable from the cobweb poset chain of
complete relations via deleting arcs in di-bicliques of the complete relations
chain. In particular we response to one of those problems [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3986</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3986</id><created>2008-01-25</created><authors><author><keyname>Yang</keyname><forenames>Lizhen</forenames></author><author><keyname>Chen</keyname><forenames>Kefei</forenames></author><author><keyname>Yuan</keyname><forenames>Luo</forenames></author></authors><title>New Lower Bounds on Sizes of Permutation Arrays</title><categories>cs.IT math.IT</categories><abstract>  A permutation array(or code) of length $n$ and distance $d$, denoted by
$(n,d)$ PA, is a set of permutations $C$ from some fixed set of $n$ elements
such that the Hamming distance between distinct members
$\mathbf{x},\mathbf{y}\in C$ is at least $d$. Let $P(n,d)$ denote the maximum
size of an $(n,d)$ PA. This correspondence focuses on the lower bound on
$P(n,d)$. First we give three improvements over the Gilbert-Varshamov lower
bounds on $P(n,d)$ by applying the graph theorem framework presented by Jiang
and Vardy. Next we show another two new improved bounds by considering the
covered balls intersections. Finally some new lower bounds for certain values
of $n$ and $d$ are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3987</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3987</id><created>2008-01-25</created><authors><author><keyname>Yang</keyname><forenames>Lizhen</forenames></author><author><keyname>Chen</keyname><forenames>Kefei</forenames></author><author><keyname>Yuan</keyname><forenames>Luo</forenames></author></authors><title>New Constructions of Permutation Arrays</title><categories>cs.IT math.IT</categories><abstract>  A permutation array(permutation code, PA) of length $n$ and distance $d$,
denoted by $(n,d)$ PA, is a set of permutations $C$ from some fixed set of $n$
elements such that the Hamming distance between distinct members
$\mathbf{x},\mathbf{y}\in C$ is at least $d$. In this correspondence, we
present two constructions of PA from fractional polynomials over finite field,
and a construction of $(n,d)$ PA from permutation group with degree $n$ and
minimal degree $d$. All these new constructions produces some new lower bounds
for PA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4013</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4013</id><created>2008-01-25</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Carmi</keyname><forenames>Paz</forenames></author><author><keyname>Couture</keyname><forenames>Mathieu</forenames></author></authors><title>Spanners of Additively Weighted Point Sets</title><categories>cs.CG</categories><abstract>  We study the problem of computing geometric spanners for (additively)
weighted point sets. A weighted point set is a set of pairs $(p,r)$ where $p$
is a point in the plane and $r$ is a real number. The distance between two
points $(p_i,r_i)$ and $(p_j,r_j)$ is defined as $|p_ip_j|-r_i-r_j$. We show
that in the case where all $r_i$ are positive numbers and $|p_ip_j|\geq
r_i+r_j$ for all $i,j$ (in which case the points can be seen as
non-intersecting disks in the plane), a variant of the Yao graph is a
$(1+\epsilon)$-spanner that has a linear number of edges. We also show that the
Additively Weighted Delaunay graph (the face-dual of the Additively Weighted
Voronoi diagram) has constant spanning ratio. The straight line embedding of
the Additively Weighted Delaunay graph may not be a plane graph. We show how to
compute a plane embedding that also has a constant spanning ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4019</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4019</id><created>2008-01-25</created><authors><author><keyname>Benton</keyname><forenames>Alex</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>A Class of Convex Polyhedra with Few Edge Unfoldings</title><categories>cs.CG</categories><comments>12 pages, 9 figures</comments><report-no>Smith Computer Science 088</report-no><acm-class>F.2.2</acm-class><abstract>  We construct a sequence of convex polyhedra on n vertices with the property
that, as n -&gt; infinity, the fraction of its edge unfoldings that avoid overlap
approaches 0, and so the fraction that overlap approaches 1. Nevertheless, each
does have (several) nonoverlapping edge unfoldings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4024</identifier>
 <datestamp>2008-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4024</id><created>2008-01-25</created><authors><author><keyname>Galas</keyname><forenames>David J.</forenames></author><author><keyname>Nykter</keyname><forenames>Matti</forenames></author><author><keyname>Carter</keyname><forenames>Gregory W.</forenames></author><author><keyname>Price</keyname><forenames>Nathan D.</forenames></author><author><keyname>Shmulevich</keyname><forenames>Ilya</forenames></author></authors><title>Set-based complexity and biological information</title><categories>cs.IT cs.CC math.IT q-bio.QM</categories><abstract>  It is not obvious what fraction of all the potential information residing in
the molecules and structures of living systems is significant or meaningful to
the system. Sets of random sequences or identically repeated sequences, for
example, would be expected to contribute little or no useful information to a
cell. This issue of quantitation of information is important since the ebb and
flow of biologically significant information is essential to our quantitative
understanding of biological function and evolution. Motivated specifically by
these problems of biological information, we propose here a class of measures
to quantify the contextual nature of the information in sets of objects, based
on Kolmogorov's intrinsic complexity. Such measures discount both random and
redundant information and are inherent in that they do not require a defined
state space to quantify the information. The maximization of this new measure,
which can be formulated in terms of the universal information distance, appears
to have several useful and interesting properties, some of which we illustrate
with examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4048</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4048</id><created>2008-01-25</created><authors><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>High Performance Cooperative Transmission Protocols Based on Multiuser
  Detection and Network Coding</title><categories>cs.IT math.IT</categories><comments>to appear IEEE Transactions on Wireless Communications</comments><abstract>  Cooperative transmission is an emerging communication technique that takes
advantage of the broadcast nature of wireless channels. However, due to low
spectral efficiency and the requirement of orthogonal channels, its potential
for use in future wireless networks is limited. In this paper, by making use of
multiuser detection (MUD) and network coding, cooperative transmission
protocols with high spectral efficiency, diversity order, and coding gain are
developed. Compared with the traditional cooperative transmission protocols
with single-user detection, in which the diversity gain is only for one source
user, the proposed MUD cooperative transmission protocols have the merit that
the improvement of one user's link can also benefit the other users. In
addition, using MUD at the relay provides an environment in which network
coding can be employed. The coding gain and high diversity order can be
obtained by fully utilizing the link between the relay and the destination.
  From the analysis and simulation results, it is seen that the proposed
protocols achieve higher diversity gain, better asymptotic efficiency, and
lower bit error rate, compared to traditional MUD schemes and to existing
cooperative transmission protocols. From the simulation results, the
performance of the proposed scheme is near optimal as the performance gap is
0.12dB for average bit error rate (BER) 10^{-6} and 1.04dB for average BER
10^(-3), compared to two performance upper bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4054</identifier>
 <datestamp>2008-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4054</id><created>2008-01-25</created><updated>2008-07-14</updated><authors><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author><author><keyname>Chen</keyname><forenames>Da Rui</forenames></author></authors><title>Bounded Mean-Delay Throughput and Non-Starvation Conditions in Aloha
  Network</title><categories>cs.NI</categories><comments>We are replacing the old version (submitted in Jan 2008) with this
  new version. The presentation and organization of the new version, we
  believe, is easire to read. In addition, new simulation results have been
  added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the requirements to ensure bounded mean queuing delay
and non-starvation in a slotted Aloha network operating the exponential backoff
protocol. It is well-known that the maximum possible throughput of a slotted
Aloha system with a large number of nodes is 1/e = 0.3679. Indeed, a saturation
throughput of 1/e can be achieved with an exponential backoff factor of r =
e/(e-1)=1.5820. The binary backoff factor of r = 2 is assumed in the majority
of prior work, and in many practical multiple-access networks such as the
Ethernet and WiFi. For slotted Aloha, the saturation throughput 0.3466 for r =
2 is reasonably close to the maximum of 1/e, and one could hardly raise
objection to adopting r = 2 in the system. However, this paper shows that if
mean queuing delay is to be bounded, then the sustainable throughput when r = 2
is only 0.2158, a drastic 41% drop from 1/e . Fortunately, the optimal setting
of r = 1.3757 under the bounded mean-delay requirement allows us to achieve
sustainable throughput of 0.3545, a penalty of only less than 4% relative to
1/e. A general conclusion is that the value of r may significantly affect the
queuing delay performance. Besides analyzing mean queuing delay, this paper
also delves into the phenomenon of starvation, wherein some nodes are deprived
of service for an extended period of time while other nodes hog the system.
Specifically, we propose a quantitative definition for starvation and show that
the conditions to guarantee bounded mean delay and non-starved operation are
one of the same, thus uniting these two notions. Finally, we show that when
mean delay is large and starvation occurs, the performance results obtained
from simulation experiments may not converge. A quantitative discussion of this
issue is provided in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4061</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4061</id><created>2008-01-26</created><authors><author><keyname>Vert</keyname><forenames>Jean-Philippe</forenames><affiliation>CB</affiliation></author></authors><title>The optimal assignment kernel is not positive definite</title><categories>cs.LG</categories><proxy>ccsd hal-00218278</proxy><abstract>  We prove that the optimal assignment kernel, proposed recently as an attempt
to embed labeled graphs and more generally tuples of basic data to a Hilbert
space, is in fact not always positive definite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4079</identifier>
 <datestamp>2008-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4079</id><created>2008-01-28</created><updated>2008-01-30</updated><authors><author><keyname>Dubrova</keyname><forenames>Elena</forenames><affiliation>Royal Institute of Technology</affiliation></author></authors><title>An equivalence preserving transformation from the Fibonacci to the
  Galois NLFSRs</title><categories>cs.CR</categories><comments>14 pages, 4 figures, one reference added, example 4 corrected</comments><abstract>  Conventional Non-Linear Feedback Shift Registers (NLFSRs) use the Fibonacci
configuration in which the value of the first bit is updated according to some
non-linear feedback function of previous values of other bits, and each
remaining bit repeats the value of its previous bit. We show how to transform
the feedback function of a Fibonacci NLFSR into several smaller feedback
functions of individual bits. Such a transformation reduces the propagation
time, thus increasing the speed of pseudo-random sequence generation. The
practical significance of the presented technique is that is makes possible
increasing the keystream generation speed of any Fibonacci NLFSR-based stream
cipher with no penalty in area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4082</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4082</id><created>2008-01-26</created><authors><author><keyname>Caleffi</keyname><forenames>Marcello</forenames></author><author><keyname>Ferraiuolo</keyname><forenames>Giancarlo</forenames></author><author><keyname>Paura</keyname><forenames>Luigi</forenames></author></authors><title>On Reliability of Dynamic Addressing Routing Protocols in Mobile Ad Hoc
  Networks</title><categories>cs.NI cs.DC</categories><comments>Proc. of WRECOM '07: Wireless Rural and Emergency Communications
  Conference, Roma (Italy), October 2007</comments><abstract>  In this paper, a reliability analysis is carried out to state a performance
comparison between two recently proposed proactive routing algorithms. These
protocols are able to scale in ad hoc and sensor networks by resorting to
dynamic addressing, to face with the topology variability, which is typical of
ad hoc, and sensor networks. Numerical simulations are also carried out to
corroborate the results of the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4105</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4105</id><created>2008-01-27</created><authors><author><keyname>Perron</keyname><forenames>Steven</forenames><affiliation>University of Toronto</affiliation></author></authors><title>Quantified Propositional Logspace Reasoning</title><categories>cs.LO cs.CC</categories><comments>28 pages</comments><abstract>  In this paper, we develop a quantified propositional proof systems that
corresponds to logarithmic-space reasoning. We begin by defining a class
SigmaCNF(2) of quantified formulas that can be evaluated in log space. Then our
new proof system GL^* is defined as G_1^* with cuts restricted to SigmaCNF(2)
formulas and no cut formula that is not quantifier free contains a free
variable that does not appear in the final formula.
  To show that GL^* is strong enough to capture log space reasoning, we
translate theorems of VL into a family of tautologies that have polynomial-size
GL^* proofs. VL is a theory of bounded arithmetic that is known to correspond
to logarithmic-space reasoning. To do the translation, we find an appropriate
axiomatization of VL, and put VL proofs into a new normal form.
  To show that GL^* is not too strong, we prove the soundness of GL^* in such a
way that it can be formalized in VL. This is done by giving a logarithmic-space
algorithm that witnesses GL^* proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4119</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4119</id><created>2008-01-28</created><updated>2008-05-16</updated><authors><author><keyname>Tedesco</keyname><forenames>Gianni</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Strategic Alert Throttling for Intrusion Detection Systems</title><categories>cs.NE cs.CR</categories><journal-ref>4th WSEAS International Conference on Information Security (WSEAS
  2005), Tenerife, Spain, 2005</journal-ref><abstract>  Network intrusion detection systems are themselves becoming targets of
attackers. Alert flood attacks may be used to conceal malicious activity by
hiding it among a deluge of false alerts sent by the attacker. Although these
types of attacks are very hard to stop completely, our aim is to present
techniques that improve alert throughput and capacity to such an extent that
the resources required to successfully mount the attack become prohibitive. The
key idea presented is to combine a token bucket filter with a realtime
correlation algorithm. The proposed algorithm throttles alert output from the
IDS when an attack is detected. The attack graph used in the correlation
algorithm is used to make sure that alerts crucial to forming strategies are
not discarded by throttling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4129</identifier>
 <datestamp>2009-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4129</id><created>2008-01-27</created><updated>2009-12-07</updated><authors><author><keyname>Sanderovich</keyname><forenames>Amichai</forenames></author><author><keyname>Peleg</keyname><forenames>Michael</forenames></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames></author></authors><title>Scaling Laws and Techniques in Decentralized Processing of Interfered
  Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to European Transactions on Telecommunication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The scaling laws of the achievable communication rates and the corresponding
upper bounds of distributed reception in the presence of an interfering signal
are investigated. The scheme includes one transmitter communicating to a remote
destination via two relays, which forward messages to the remote destination
through reliable links with finite capacities. The relays receive the
transmission along with some unknown interference. We focus on three common
settings for distributed reception, wherein the scaling laws of the capacity
(the pre-log as the power of the transmitter and the interference are taken to
infinity) are completely characterized. It is shown in most cases that in order
to overcome the interference, a definite amount of information about the
interference needs to be forwarded along with the desired message, to the
destination. It is exemplified in one scenario that the cut-set upper bound is
strictly loose. The results are derived using the cut-set along with a new
bounding technique, which relies on multi letter expressions. Furthermore,
lattices are found to be a useful communication technique in this setting, and
are used to characterize the scaling laws of achievable rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4130</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4130</id><created>2008-01-27</created><authors><author><keyname>Andersson</keyname><forenames>Daniel</forenames></author></authors><title>Solving Min-Max Problems with Applications to Games</title><categories>cs.GT cs.DS</categories><abstract>  We refine existing general network optimization techniques, give new
characterizations for the class of problems to which they can be applied, and
show that they can also be used to solve various two-player games in almost
linear time. Among these is a new variant of the network interdiction problem,
where the interdictor wants to destroy high-capacity paths from the source to
the destination using a vertex-wise limited budget of arc removals. We also
show that replacing the limit average in mean payoff games by the maximum
weight results in a class of games amenable to these techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4150</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4150</id><created>2008-01-27</created><authors><author><keyname>Diaz</keyname><forenames>G.</forenames></author><author><keyname>Florez-Lopez</keyname><forenames>J.</forenames></author><author><keyname>Hamar</keyname><forenames>V.</forenames></author><author><keyname>Hoeger</keyname><forenames>H.</forenames></author><author><keyname>Mendoza</keyname><forenames>C.</forenames></author><author><keyname>Mendez</keyname><forenames>Z.</forenames></author><author><keyname>Nunez</keyname><forenames>L. A.</forenames></author><author><keyname>Ruiz</keyname><forenames>N.</forenames></author><author><keyname>Torrens</keyname><forenames>R.</forenames></author><author><keyname>Uzcategui</keyname><forenames>M.</forenames></author></authors><title>e-Science perspectives in Venezuela</title><categories>cs.DC</categories><comments>Presented at the Third Conference of the EELA Project in Catania,
  Italy, Dec 2007</comments><journal-ref>Proceedings of the Third EELA Conference, R. Gavela, B. Marechal,
  R. Barbera, L.N. Ciuffo, R. Mayo. (Editors), CIEMAT, Madrid, Spain (2007), pp
  131-139</journal-ref><abstract>  We describe the e-Science strategy in Venezuela, in particular initiatives by
the Centro Nacional de Calculo Cientifico Universidad de Los Andes (CECALCULA),
Merida, the Universidad de Los Andes (ULA), Merida, and the Instituto
Venezolano de Investigaciones Cientificas (IVIC), Caracas. We present the plans
for the Venezuelan Academic Grid and the current status of Grid ULA supported
by Internet2. We show different web-based scientific applications that are
being developed in quantum chemistry, atomic physics, structural damage
analysis, biomedicine and bioclimate within the framework of the
E-Infrastructure shared between Europe and Latin America (EELA)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4158</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4158</id><created>2008-01-27</created><authors><author><keyname>Simon</keyname><forenames>Gabor</forenames></author><author><keyname>Steger</keyname><forenames>Jozsef</forenames></author><author><keyname>Csabai</keyname><forenames>Peter Haga Istvan</forenames></author><author><keyname>Vattay</keyname><forenames>Gabor</forenames></author></authors><title>Measuring the Dynamical State of the Internet: Large Scale Network
  Tomography via the ETOMIC Infrastructure</title><categories>physics.data-an cs.NI</categories><abstract>  In this paper we show how to go beyond the study of the topological
properties of the Internet, by measuring its dynamical state using special
active probing techniques and the methods of network tomography. We demonstrate
this approach by measuring the key state parameters of Internet paths, the
characteristics of queueing delay, in a part of the European Internet. In the
paper we describe in detail the ETOMIC measurement platform that was used to
conduct the experiments, and the applied method of queueing delay tomography.
The main results of the paper are maps showing various spatial structure in the
characteristics of queueing delay corresponding to the resolved part of the
European Internet. These maps reveal that the average queueing delay of network
segments spans more than two orders of magnitude, and that the distribution of
this quantity is very well fitted by the log-normal distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4190</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4190</id><created>2008-01-28</created><updated>2009-07-27</updated><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Phylogenies without Branch Bounds: Contracting the Short, Pruning the
  Deep</title><categories>q-bio.PE cs.CE cs.DS math.PR math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new phylogenetic reconstruction algorithm which, unlike most
previous rigorous inference techniques, does not rely on assumptions regarding
the branch lengths or the depth of the tree. The algorithm returns a forest
which is guaranteed to contain all edges that are: 1) sufficiently long and 2)
sufficiently close to the leaves. How much of the true tree is recovered
depends on the sequence length provided. The algorithm is distance-based and
runs in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4194</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4194</id><created>2008-01-28</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>A statistical mechanical interpretation of algorithmic information
  theory</title><categories>cs.IT cs.CC math.IT math.PR quant-ph</categories><comments>31 pages, LaTeX2e, no figures</comments><abstract>  We develop a statistical mechanical interpretation of algorithmic information
theory by introducing the notion of thermodynamic quantities, such as free
energy, energy, statistical mechanical entropy, and specific heat, into
algorithmic information theory. We investigate the properties of these
quantities by means of program-size complexity from the point of view of
algorithmic randomness. It is then discovered that, in the interpretation, the
temperature plays a role as the compression rate of the values of all these
thermodynamic quantities, which include the temperature itself. Reflecting this
self-referential nature of the compression rate of the temperature, we obtain
fixed point theorems on compression rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4198</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4198</id><created>2008-01-28</created><authors><author><keyname>Nakamura</keyname><forenames>Kazutaka</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author></authors><title>Microscopic Analysis for Decoupling Principle of Linear Vector Channel</title><categories>cs.IT math.IT</categories><abstract>  This paper studies the decoupling principle of a linear vector channel, which
is an extension of CDMA and MIMO channels. We show that the scalar-channel
characterization obtained via the decoupling principle is valid not only for
collections of a large number of elements of input vector, as discussed in
previous studies, but also for individual elements of input vector, i.e. the
linear vector channel for individual elements of channel input vector is
decomposed into a bank of independent scalar Gaussian channels in the
large-system limit, where dimensions of channel input and output are both sent
to infinity while their ratio fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4230</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4230</id><created>2008-01-28</created><authors><author><keyname>Perdrix</keyname><forenames>Simon</forenames></author></authors><title>Quantum entanglement analysis based on abstract interpretation</title><categories>cs.LO cs.PL quant-ph</categories><comments>13 pages</comments><journal-ref>Proc. of 15th International Static Analysis Symposium (SAS 2008).
  LNCS 5079, pp 270-282</journal-ref><doi>10.1007/978-3-540-69166-2_18</doi><abstract>  Entanglement is a non local property of quantum states which has no classical
counterpart and plays a decisive role in quantum information theory. Several
protocols, like the teleportation, are based on quantum entangled states.
Moreover, any quantum algorithm which does not create entanglement can be
efficiently simulated on a classical computer. The exact role of the
entanglement is nevertheless not well understood. Since an exact analysis of
entanglement evolution induces an exponential slowdown, we consider
approximative analysis based on the framework of abstract interpretation. In
this paper, a concrete quantum semantics based on superoperators is associated
with a simple quantum programming language. The representation of entanglement,
i.e. the design of the abstract domain is a key issue. A representation of
entanglement as a partition of the memory is chosen. An abstract semantics is
introduced, and the soundness of the approximation is proven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4238</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4238</id><created>2008-01-28</created><authors><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Hurand</keyname><forenames>Mathilde</forenames></author><author><keyname>Robert</keyname><forenames>Julien</forenames></author></authors><title>Algorithms for Temperature-Aware Task Scheduling in Microprocessor
  Systems</title><categories>cs.DS</categories><abstract>  We study scheduling problems motivated by recently developed techniques for
microprocessor thermal management at the operating systems level. The general
scenario can be described as follows. The microprocessor's temperature is
controlled by the hardware thermal management system that continuously monitors
the chip temperature and automatically reduces the processor's speed as soon as
the thermal threshold is exceeded. Some tasks are more CPU-intensive than other
and thus generate more heat during execution. The cooling system operates
non-stop, reducing (at an exponential rate) the deviation of the processor's
temperature from the ambient temperature. As a result, the processor's
temperature, and thus the performance as well, depends on the order of the task
execution. Given a variety of possible underlying architectures, models for
cooling and for hardware thermal management, as well as types of tasks, this
scenario gives rise to a plethora of interesting and never studied scheduling
problems.
  We focus on scheduling real-time jobs in a simplified model for cooling and
thermal management. A collection of unit-length jobs is given, each job
specified by its release time, deadline and heat contribution. If, at some time
step, the temperature of the system is t and the processor executes a job with
heat contribution h, then the temperature at the next step is (t+h)/2. The
temperature cannot exceed the given thermal threshold T. The objective is to
maximize the throughput, that is, the number of tasks that meet their
deadlines. We prove that, in the offline case, computing the optimum schedule
is NP-hard, even if all jobs are released at the same time. In the online case,
we show a 2-competitive deterministic algorithm and a matching lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4268</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4268</id><created>2008-01-28</created><authors><author><keyname>Mittermeir</keyname><forenames>Roland T.</forenames></author><author><keyname>Clermont</keyname><forenames>Markus</forenames></author><author><keyname>Hodnigg</keyname><forenames>Karin</forenames></author></authors><title>Protecting Spreadsheets Against Fraud</title><categories>cs.CY cs.CR</categories><comments>16 Pages including extensive references</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1; K.6.5; K.4.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2005 69-80
  ISBN:1-902724-16-X</journal-ref><abstract>  Previous research on spreadsheet risks has predominantly focussed on errors
inadvertently introduced by spreadsheet writers i.e. it focussed on the
end-user aspects of spreadsheet development. When analyzing a faulty
spreadsheet, one might not be able to determine whether a particular error
(fault) has been made by mistake or with fraudulent intentions. However, the
fences protecting against fraudulent errors have to be different from those
shielding against inadvertent mistakes. Faults resulting from errors committed
inadvertently can be prevented ab initio by tools that notify the spreadsheet
writer about potential problems whereas faults that are introduced on purpose
have to be discovered by auditors without the cooperation of their originators.
Even worse, some spreadsheet writers will do their best to conceal fraudulent
parts of their spreadsheets from auditors. In this paper we survey the
available means for fraud protection by contrasting approaches suitable for
spreadsheets with those known from fraud protection for conventional software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4274</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4274</id><created>2008-01-28</created><authors><author><keyname>Hodnigg</keyname><forenames>Karin</forenames></author><author><keyname>Clermont</keyname><forenames>Markus</forenames></author><author><keyname>Mittermeir</keyname><forenames>Roland T.</forenames></author></authors><title>Computational Models of Spreadsheet Development: Basis for Educational
  Approaches</title><categories>cs.HC cs.SE</categories><comments>16 Pages, 4 figures, includes references</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2004 153-168 ISBN 1
  902724 94 1</journal-ref><abstract>  Among the multiple causes of high error rates in spreadsheets, lack of proper
training and of deep understanding of the computational model upon which
spreadsheet computations rest might not be the least issue. The paper addresses
this problem by presenting a didactical model focussing on cell interaction,
thus exceeding the atomicity of cell computations. The approach is motivated by
an investigation how different spreadsheet systems handle certain computational
issues implied from moving cells, copy-paste operations, or recursion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4280</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4280</id><created>2008-01-28</created><authors><author><keyname>Ayalew</keyname><forenames>Yirsaw</forenames></author><author><keyname>Mittermeir</keyname><forenames>Roland</forenames></author></authors><title>Spreadsheet Debugging</title><categories>cs.SE cs.PL</categories><comments>13 Pages, 4 figues</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2003 67-79 ISBN 1 86166
  199 1</journal-ref><abstract>  Spreadsheet programs, artifacts developed by non-programmers, are used for a
variety of important tasks and decisions. Yet a significant proportion of them
have severe quality problems. To address this issue, our previous work
presented an interval-based testing methodology for spreadsheets.
Interval-based testing rests on the observation that spreadsheets are mainly
used for numerical computations. It also incorporates ideas from symbolic
testing and interval analysis. This paper addresses the issue of efficiently
debugging spreadsheets. Based on the interval-based testing methodology, this
paper presents a technique for tracing faults in spreadsheet programs. The
fault tracing technique proposed uses the dataflow information and cell marks
to identify the most influential faulty cell(s) for a given formula cell
containing a propagated fault.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4287</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4287</id><created>2008-01-28</created><updated>2008-03-03</updated><authors><author><keyname>Chen</keyname><forenames>Qi</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Movie Recommendation Systems Using An Artificial Immune System</title><categories>cs.NE cs.AI</categories><journal-ref>6th International Conference in Adaptive Computing in Design and
  Manufacture (ACDM 2004), Bristol, UK, 2004</journal-ref><abstract>  We apply the Artificial Immune System (AIS) technology to the Collaborative
Filtering (CF) technology when we build the movie recommendation system. Two
different affinity measure algorithms of AIS, Kendall tau and Weighted Kappa,
are used to calculate the correlation coefficients for this movie
recommendation system. From the testing we think that Weighted Kappa is more
suitable than Kendall tau for movie problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4292</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4292</id><created>2008-01-28</created><authors><author><keyname>Cucu</keyname><forenames>Liliana</forenames></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author></authors><title>Exact Feasibility Tests for Real-Time Scheduling of Periodic Tasks upon
  Multiprocessor Platforms</title><categories>cs.OS</categories><abstract>  In this paper we study the global scheduling of periodic task systems upon
multiprocessor platforms. We first show two very general properties which are
well-known for uniprocessor platforms and which remain for multiprocessor
platforms: (i) under few and not so restrictive assumptions, we show that
feasible schedules of periodic task systems are periodic from some point with a
period equal to the least common multiple of task periods and (ii) for the
specific case of synchronous periodic task systems, we show that feasible
schedules repeat from the origin. We then present our main result: we
characterize, for task-level fixed-priority schedulers and for asynchronous
constrained or arbitrary deadline periodic task models, upper bounds of the
first time instant where the schedule repeats. We show that job-level
fixed-priority schedulers are predictable upon unrelated multiprocessor
platforms. For task-level fixed-priority schedulers, based on the upper bounds
and the predictability property, we provide for asynchronous constrained or
arbitrary deadline periodic task sets, exact feasibility tests. Finally, for
the job-level fixed-priority EDF scheduler, for which such an upper bound
remains unknown, we provide an exact feasibility test as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4305</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4305</id><created>2008-01-28</created><updated>2008-09-07</updated><authors><author><keyname>Barrientos</keyname><forenames>J. Emeterio Navarro</forenames></author><author><keyname>Walter</keyname><forenames>Frank E.</forenames></author><author><keyname>Schweitzer</keyname><forenames>Frank</forenames></author></authors><title>Risk-Seeking versus Risk-Avoiding Investments in Noisy Periodic
  Environments</title><categories>q-fin.PM cs.CE physics.soc-ph</categories><comments>27 pp. v2 with minor corrections. See http://www.sg.ethz.ch for more
  info</comments><journal-ref>International Journal of Modern Physics C vol. 19, no. 6 (2008)
  971-994</journal-ref><doi>10.1142/S0129183108012662</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance of various agent strategies in an artificial
investment scenario. Agents are equipped with a budget, $x(t)$, and at each
time step invest a particular fraction, $q(t)$, of their budget. The return on
investment (RoI), $r(t)$, is characterized by a periodic function with
different types and levels of noise. Risk-avoiding agents choose their fraction
$q(t)$ proportional to the expected positive RoI, while risk-seeking agents
always choose a maximum value $q_{max}$ if they predict the RoI to be positive
(&quot;everything on red&quot;). In addition to these different strategies, agents have
different capabilities to predict the future $r(t)$, dependent on their
internal complexity. Here, we compare 'zero-intelligent' agents using technical
analysis (such as moving least squares) with agents using reinforcement
learning or genetic algorithms to predict $r(t)$. The performance of agents is
measured by their average budget growth after a certain number of time steps.
We present results of extensive computer simulations, which show that, for our
given artificial environment, (i) the risk-seeking strategy outperforms the
risk-avoiding one, and (ii) the genetic algorithm was able to find this optimal
strategy itself, and thus outperforms other prediction approaches considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4307</identifier>
 <datestamp>2008-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4307</id><created>2008-01-28</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Chen</keyname><forenames>Qi</forenames></author></authors><title>On Affinity Measures for Artificial Immune System Movie Recommenders</title><categories>cs.NE cs.AI cs.CY</categories><journal-ref>Proceedings of the 5th International Conference on Recent Advances
  in Soft Computing (RASC 2004), Nottingham, UK</journal-ref><abstract>  We combine Artificial Immune Systems 'AIS', technology with Collaborative
Filtering 'CF' and use it to build a movie recommendation system. We already
know that Artificial Immune Systems work well as movie recommenders from
previous work by Cayzer and Aickelin 3, 4, 5. Here our aim is to investigate
the effect of different affinity measure algorithms for the AIS. Two different
affinity measures, Kendalls Tau and Weighted Kappa, are used to calculate the
correlation coefficients for the movie recommender. We compare the results with
those published previously and show that Weighted Kappa is more suitable than
others for movie problems. We also show that AIS are generally robust movie
recommenders and that, as long as a suitable affinity measure is chosen,
results are good.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4312</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4312</id><created>2008-01-28</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Burke</keyname><forenames>Edmund</forenames></author><author><keyname>Din</keyname><forenames>Aniza</forenames></author></authors><title>Investigating Artificial Immune Systems For Job Shop Rescheduling In
  Changing Environments</title><categories>cs.NE cs.CE</categories><journal-ref>6th International Conference in Adaptive Computing in Design and
  Manufacture (ACDM 2004), Bristol, UK, 2004</journal-ref><abstract>  Artificial immune system can be used to generate schedules in changing
environments and it has been proven to be more robust than schedules developed
using a genetic algorithm. Good schedules can be produced especially when the
number of the antigens is increased. However, an increase in the range of the
antigens had somehow affected the fitness of the immune system. In this
research, we are trying to improve the result of the system by rescheduling the
same problem using the same method while at the same time maintaining the
robustness of the schedules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4314</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4314</id><created>2008-01-28</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Artificial Immune Systems (AIS) - A New Paradigm for Heuristic Decision
  Making</title><categories>cs.NE cs.AI</categories><journal-ref>Invited Keynote Talk, Annual Operational Research Conference 46,
  York, UK, 2004</journal-ref><abstract>  Over the last few years, more and more heuristic decision making techniques
have been inspired by nature, e.g. evolutionary algorithms, ant colony
optimisation and simulated annealing. More recently, a novel computational
intelligence technique inspired by immunology has emerged, called Artificial
Immune Systems (AIS). This immune system inspired technique has already been
useful in solving some computational problems. In this keynote, we will very
briefly describe the immune system metaphors that are relevant to AIS. We will
then give some illustrative real-world problems suitable for AIS use and show a
step-by-step algorithm walkthrough. A comparison of AIS to other well-known
algorithms and areas for future work will round this keynote off. It should be
noted that as AIS is still a young and evolving field, there is not yet a fixed
algorithm template and hence actual implementations might differ somewhat from
the examples given here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4355</identifier>
 <datestamp>2008-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4355</id><created>2008-01-28</created><authors><author><keyname>Banihachemi</keyname><forenames>Jean-Jacques</forenames><affiliation>TIMC</affiliation></author><author><keyname>Boidard</keyname><forenames>Eric</forenames><affiliation>TIMC</affiliation></author><author><keyname>Bosson</keyname><forenames>Jean-Luc</forenames><affiliation>TIMC, CHU-Grenoble CIC</affiliation></author><author><keyname>Bressollette</keyname><forenames>Luc</forenames><affiliation>TIMC, CHU-Grenoble radio</affiliation></author><author><keyname>Bricault</keyname><forenames>Ivan</forenames><affiliation>TIMC, CHU-Grenoble radio</affiliation></author><author><keyname>Cinquin</keyname><forenames>Philippe</forenames><affiliation>TIMC</affiliation></author><author><keyname>Ferretti</keyname><forenames>Gilbert</forenames><affiliation>CHU-Grenoble radio</affiliation></author><author><keyname>Marchal</keyname><forenames>Maud</forenames><affiliation>TIMC</affiliation></author><author><keyname>Martinelli</keyname><forenames>Thomas</forenames><affiliation>CHU-Grenoble radio</affiliation></author><author><keyname>Moreau-Gaudry</keyname><forenames>Alexandre</forenames><affiliation>CHU-Grenoble CIC</affiliation></author><author><keyname>Pelissier</keyname><forenames>Franck</forenames><affiliation>TIMC</affiliation></author><author><keyname>Roux</keyname><forenames>Christian</forenames><affiliation>TIMC</affiliation></author><author><keyname>Saragaglia</keyname><forenames>Dominique</forenames><affiliation>TIMC</affiliation></author><author><keyname>Thorel</keyname><forenames>Pierre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author><author><keyname>Vilchis</keyname><forenames>Adriana</forenames><affiliation>TIMC</affiliation></author></authors><title>TER: A Robot for Remote Ultrasonic Examination: Experimental Evaluations</title><categories>cs.OH cs.RO</categories><proxy>ccsd hal-00221454</proxy><journal-ref>Telesurgery, Springer Verlag (Ed.) (2008) 91-99</journal-ref><abstract>  This chapter:
  o Motivates the clinical use of robotic tele-echography
  o Introduces the TER system
  o Describes technical and clinical evaluations performed with TER
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4405</identifier>
 <datestamp>2008-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4405</id><created>2008-01-28</created><authors><author><keyname>Charlton</keyname><forenames>David</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Price</keyname><forenames>Gregory</forenames></author><author><keyname>Tu</keyname><forenames>Yaa-Lirng</forenames></author></authors><title>A Locked Orthogonal Tree</title><categories>cs.CG</categories><abstract>  We give a counterexample to a conjecture of Poon [Poo06] that any orthogonal
tree in two dimensions can always be flattened by a continuous motion that
preserves edge lengths and avoids self-intersection. We show our example is
locked by extending results on strongly locked self-touching linkages due to
Connelly, Demaine and Rote [CDR02] to allow zero-length edges as defined in
[ADG07], which may be of independent interest. Our results also yield a locked
tree with only eleven edges, which is the smallest known example of a locked
tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4417</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4417</id><created>2008-01-28</created><authors><author><keyname>Wei</keyname><forenames>L. F.</forenames></author><author><keyname>Johansson</keyname><forenames>J. R.</forenames></author><author><keyname>Cen</keyname><forenames>L. X.</forenames></author><author><keyname>Ashhab</keyname><forenames>S.</forenames></author><author><keyname>Nori</keyname><forenames>Franco</forenames></author></authors><title>Controllable coherent population transfers in superconducting qubits for
  quantum computing</title><categories>quant-ph cond-mat.mes-hall cond-mat.supr-con cs.GT</categories><comments>4 pages, 6 figures. to appear in Physical Review Letters</comments><journal-ref>Phys. Rev. Lett. 100, 113601 (2008)</journal-ref><doi>10.1103/PhysRevLett.100.113601</doi><abstract>  We propose an approach to coherently transfer populations between selected
quantum states in one- and two-qubit systems by using controllable
Stark-chirped rapid adiabatic passages (SCRAPs). These {\it evolution-time
insensitive} transfers, assisted by easily implementable single-qubit
phase-shift operations, could serve as elementary logic gates for quantum
computing. Specifically, this proposal could be conveniently demonstrated with
existing Josephson phase qubits. Our proposal can find an immediate application
in the readout of these qubits. Indeed, the broken parity symmetries of the
bound states in these artificial &quot;atoms&quot; provide an efficient approach to
design the required adiabatic pulses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4423</identifier>
 <datestamp>2008-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4423</id><created>2008-01-28</created><authors><author><keyname>Tungare</keyname><forenames>Manas</forenames></author><author><keyname>Perez-Quinones</keyname><forenames>Manuel</forenames></author></authors><title>It's Not What You Have, But How You Use It: Compromises in Mobile Device
  Use</title><categories>cs.HC</categories><abstract>  As users begin to use many more devices for personal information management
(PIM) than just the traditional desktop computer, it is essential for HCI
researchers to understand how these devices are being used in the wild and
their roles in users' information environments. We conducted a study of 220
knowledge workers about their devices, the activities they performed on each,
and the groups of devices used together. Our findings indicate that several
devices are often used in groups; integrated multi-function portable devices
have begun to replace single-function devices for communication (e.g. email and
IM). Users use certain features opportunistically because they happen to be
carrying a multi-function device with them. The use of multiple devices and
multi-function devices is fraught with compromises as users must choose and
make trade-offs among various factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4480</identifier>
 <datestamp>2008-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4480</id><created>2008-01-29</created><authors><author><keyname>Okunoye</keyname><forenames>Babatunde O.</forenames></author></authors><title>Abstractions for biomolecular computations</title><categories>cs.OH</categories><comments>9 pages, 2 figures</comments><abstract>  Deoxyribonucleic acid is increasingly being understood to be an informational
molecule, capable of information processing.It has found application in the
determination of non-deterministic algorithms and in the design of molecular
computing devices. This is a theoretical analysis of the mathematical
properties and relations of the molecules which constituting DNA, which
explains in part why DNA is a successful computing molecule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4483</identifier>
 <datestamp>2008-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4483</id><created>2008-01-29</created><authors><author><keyname>Long</keyname><forenames>Jean-Alexandre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Moreau-Gaudry</keyname><forenames>Alexandre</forenames><affiliation>TIMC, CHU-Grenoble CIC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author><author><keyname>Rambeaud</keyname><forenames>Jean-Jacques</forenames></author><author><keyname>Descotes</keyname><forenames>Jean-Luc</forenames></author></authors><title>Biopsies prostatiques sous guidage \'echographique 3D et temps r\'eel
  (4D) sur fant\^ome. Etude comparative versus guidage 2D</title><categories>cs.OH</categories><proxy>ccsd hal-00221557</proxy><journal-ref>Progr\`es en Urologie 17, 7 (2007) 1137-1143</journal-ref><abstract>  This paper analyzes the impact of using 2D or 3D ultrasound on the efficiency
of prostate biopsies. The evaluation is performed on home-made phantoms. The
study shows that the accuracy is significantly improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4544</identifier>
 <datestamp>2008-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4544</id><created>2008-01-29</created><authors><author><keyname>Moulin</keyname><forenames>Pierre</forenames></author></authors><title>A Neyman-Pearson Approach to Universal Erasure and List Decoding</title><categories>cs.IT math.IT</categories><comments>31 pages, submitted to IEEE Transactions on Information Theory</comments><abstract>  When information is to be transmitted over an unknown, possibly unreliable
channel, an erasure option at the decoder is desirable. Using
constant-composition random codes, we propose a generalization of Csiszar and
Korner's Maximum Mutual Information decoder with erasure option for discrete
memoryless channels. The new decoder is parameterized by a weighting function
that is designed to optimize the fundamental tradeoff between undetected-error
and erasure exponents for a compound class of channels. The class of weighting
functions may be further enlarged to optimize a similar tradeoff for list
decoders -- in that case, undetected-error probability is replaced with average
number of incorrect messages in the list. Explicit solutions are identified.
  The optimal exponents admit simple expressions in terms of the sphere-packing
exponent, at all rates below capacity. For small erasure exponents, these
expressions coincide with those derived by Forney (1968) for symmetric
channels, using Maximum a Posteriori decoding. Thus for those channels at
least, ignorance of the channel law is inconsequential. Conditions for
optimality of the Csiszar-Korner rule and of the simpler
empirical-mutual-information thresholding rule are identified. The error
exponents are evaluated numerically for the binary symmetric channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4571</identifier>
 <datestamp>2008-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4571</id><created>2008-01-29</created><authors><author><keyname>Tu</keyname><forenames>Ronghui</forenames></author><author><keyname>Mao</keyname><forenames>Yongyi</forenames></author><author><keyname>Zhao</keyname><forenames>Jiying</forenames></author></authors><title>Is SP BP?</title><categories>cs.IT math.IT</categories><comments>77 page double-spaced single-column submitted version to IEEE
  Transactions on Information Theory</comments><abstract>  The Survey Propagation (SP) algorithm for solving $k$-SAT problems has been
shown recently as an instance of the Belief Propagation (BP) algorithm. In this
paper, we show that for general constraint-satisfaction problems, SP may not be
reducible from BP. We also establish the conditions under which such a
reduction is possible. Along our development, we present a unification of the
existing SP algorithms in terms of a probabilistically interpretable iterative
procedure -- weighted Probabilistic Token Passing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4585</identifier>
 <datestamp>2008-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4585</id><created>2008-01-29</created><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>The Complexity of Power-Index Comparison</title><categories>cs.CC cs.GT</categories><comments>12 pages</comments><report-no>URCS TR-2008-929</report-no><acm-class>I.2.11; F.2.2; F.1.3</acm-class><abstract>  We study the complexity of the following problem: Given two weighted voting
games G' and G'' that each contain a player p, in which of these games is p's
power index value higher? We study this problem with respect to both the
Shapley-Shubik power index [SS54] and the Banzhaf power index [Ban65,DS79]. Our
main result is that for both of these power indices the problem is complete for
probabilistic polynomial time (i.e., is PP-complete). We apply our results to
partially resolve some recently proposed problems regarding the complexity of
weighted voting games. We also study the complexity of the raw Shapley-Shubik
power index. Deng and Papadimitriou [DP94] showed that the raw Shapley-Shubik
power index is #P-metric-complete. We strengthen this by showing that the raw
Shapley-Shubik power index is many-one complete for #P. And our strengthening
cannot possibly be further improved to parsimonious completeness, since we
observe that, in contrast with the raw Banzhaf power index, the raw
Shapley-Shubik power index is not #P-parsimonious-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4592</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4592</id><created>2008-01-29</created><updated>2008-09-25</updated><authors><author><keyname>Wang</keyname><forenames>Yue</forenames></author><author><keyname>Lui</keyname><forenames>John C. S.</forenames></author><author><keyname>Chiu</keyname><forenames>Dah-Ming</forenames></author></authors><title>Understanding the Paradoxical Effects of Power Control on the Capacity
  of Wireless Networks</title><categories>cs.NI cs.PF</categories><comments>I refined the previous version in many places, including the title.
  to appear in IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent works show conflicting results: network capacity may increase or
decrease with higher transmission power under different scenarios. In this
work, we want to understand this paradox. Specifically, we address the
following questions: (1)Theoretically, should we increase or decrease
transmission power to maximize network capacity? (2) Theoretically, how much
network capacity gain can we achieve by power control? (3) Under realistic
situations, how do power control, link scheduling and routing interact with
each other? Under which scenarios can we expect a large capacity gain by using
higher transmission power? To answer these questions, firstly, we prove that
the optimal network capacity is a non-decreasing function of transmission
power. Secondly, we prove that the optimal network capacity can be increased
unlimitedly by higher transmission power in some network configurations.
However, when nodes are distributed uniformly, the gain of optimal network
capacity by higher transmission power is upper-bounded by a positive constant.
Thirdly, we discuss why network capacity in practice may increase or decrease
with higher transmission power under different scenarios using carrier sensing
and the minimum hop-count routing. Extensive simulations are carried out to
verify our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4664</identifier>
 <datestamp>2008-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4664</id><created>2008-01-30</created><authors><author><keyname>Babatunde</keyname><forenames>O. Okunoye</forenames></author></authors><title>A Molecular Model for Communication through a Secrecy System</title><categories>cs.CR</categories><comments>8 pages,7 figures</comments><abstract>  Codes have been used for centuries to convey secret information.To a
cryptanalyst, the interception of a code is only the first step in recovering a
secret message.Deoxyribonucleic acid (DNA) is a biological and molecular
code.Through the work of Marshall Nirenberg and others, DNA is now understood
to specify for amino acids in triplet codes of bases.The possibilty of DNA
encoding secret information in a natural language is explored, since a code is
expected to have a distinct mathematical solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4699</identifier>
 <datestamp>2009-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4699</id><created>2008-01-30</created><authors><author><keyname>Dziemia&#x144;czuk</keyname><forenames>M.</forenames></author></authors><title>On Cobweb Admissible Sequences - The Production Theorem</title><categories>math.CO cs.DM</categories><comments>6 pages</comments><msc-class>06A07, 05C70,05C75, 11B39</msc-class><journal-ref>Proceedings of FCS'08, Interesting results, new models, and
  methodologies, pp.163-165, July 14-17, 2008, Las Vegas, USA</journal-ref><abstract>  In this note further clue decisive observations on cobweb admissible
sequences are shared with the audience. In particular an announced proof of the
Theorem 1 (by Dziemia\'nczuk) from [1] announced in India -Kolkata- December
2007 is delivered here. Namely here and there we claim that any cobweb
admissible sequence F is at the point product of primary cobweb admissible
sequences taking values one and/or certain power of an appropriate primary
number p.
  Here also an algorithm to produce the family of all cobweb-admissible
sequences i.e. the Problem 1 from [1] i.e. one of several problems posed in
source papers [2,3] is solved using the idea and methods implicitly present
already in [4]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4706</identifier>
 <datestamp>2008-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4706</id><created>2008-01-30</created><updated>2008-10-18</updated><authors><author><keyname>Pad</keyname><forenames>P.</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author><author><keyname>Alishahi</keyname><forenames>K.</forenames></author><author><keyname>Akbari</keyname><forenames>S.</forenames></author></authors><title>A Class of Errorless Codes for Over-loaded Synchronous Wireless and
  Optical CDMA Systems</title><categories>cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a new class of codes for over-loaded synchronous
wireless and optical CDMA systems which increases the number of users for fixed
number of chips without introducing any errors. Equivalently, the chip rate can
be reduced for a given number of users, which implies bandwidth reduction for
downlink wireless systems. An upper bound for the maximum number of users for a
given number of chips is derived. Also, lower and upper bounds for the sum
channel capacity of a binary over-loaded CDMA are derived that can predict the
existence of such over-loaded codes. We also propose a simplified maximum
likelihood method for decoding these types of over-loaded codes. Although a
high percentage of the over-loading factor degrades the system performance in
noisy channels, simulation results show that this degradation is not
significant. More importantly, for moderate values of Eb/N0 (in the range of
6-10 dB) or higher, the proposed codes perform much better than the binary
Welch bound equality sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4709</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4709</id><created>2008-01-30</created><authors><author><keyname>Stepanenko</keyname><forenames>A. S.</forenames></author><author><keyname>Constantinou</keyname><forenames>C. C.</forenames></author><author><keyname>Yurkevich</keyname><forenames>I. V.</forenames></author><author><keyname>Lerner</keyname><forenames>I. V.</forenames></author></authors><title>Temporal Correlations of Local Network Losses</title><categories>cs.NI cond-mat.stat-mech</categories><journal-ref>Phys. Rev. E 77, 046115 (2008)</journal-ref><doi>10.1103/PhysRevE.77.046115</doi><abstract>  We introduce a continuum model describing data losses in a single node of a
packet-switched network (like the Internet) which preserves the discrete nature
of the data loss process. {\em By construction}, the model has critical
behavior with a sharp transition from exponentially small to finite losses with
increasing data arrival rate. We show that such a model exhibits strong
fluctuations in the loss rate at the critical point and non-Markovian power-law
correlations in time, in spite of the Markovian character of the data arrival
process. The continuum model allows for rather general incoming data packet
distributions and can be naturally generalized to consider the buffer server
idleness statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4714</identifier>
 <datestamp>2009-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4714</id><created>2008-01-30</created><updated>2009-03-24</updated><authors><author><keyname>Sotakova</keyname><forenames>Miroslava</forenames></author></authors><title>Breaking One-Round Key-Agreement Protocols in the Random Oracle Model</title><categories>cs.CC cs.CR</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study one-round key-agreement protocols analogous to
Merkle's puzzles in the random oracle model. The players Alice and Bob are
allowed to query a random permutation oracle $n$ times and upon their queries
and communication, they both output the same key with high probability. We
prove that Eve can always break such a protocol by querying the oracle $O(n^2)$
times. The long-time unproven optimality of the quadratic bound in the fully
general, multi-round scenario has been shown recently by Barak and
Mahmoody-Ghidary. The results in this paper have been found independently of
their work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4716</identifier>
 <datestamp>2008-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4716</id><created>2008-01-30</created><authors><author><keyname>Wandmacher</keyname><forenames>Tonio</forenames></author><author><keyname>Antoine</keyname><forenames>Jean-Yves</forenames></author></authors><title>Methods to integrate a language model with semantic information for a
  word prediction component</title><categories>cs.CL</categories><comments>10 pages ; EMNLP'2007 Conference (Prague)</comments><acm-class>K.4.2; I.2.7; H.5.2; I.2.1</acm-class><abstract>  Most current word prediction systems make use of n-gram language models (LM)
to estimate the probability of the following word in a phrase. In the past
years there have been many attempts to enrich such language models with further
syntactic or semantic information. We want to explore the predictive powers of
Latent Semantic Analysis (LSA), a method that has been shown to provide
reliable information on long-distance semantic dependencies between words in a
context. We present and evaluate here several methods that integrate LSA-based
information with a standard language model: a semantic cache, partial
reranking, and different forms of interpolation. We found that all methods show
significant improvements, compared to the 4-gram baseline, and most of them to
a simple cache model as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4746</identifier>
 <datestamp>2008-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4746</id><created>2008-01-30</created><updated>2008-02-10</updated><authors><author><keyname>Saba</keyname><forenames>Walid S.</forenames></author></authors><title>Concerning Olga, the Beautiful Little Street Dancer (Adjectives as
  Higher-Order Polymorphic Functions)</title><categories>cs.CL cs.LO</categories><comments>6 pages</comments><abstract>  In this paper we suggest a typed compositional seman-tics for nominal
compounds of the form [Adj Noun] that models adjectives as higher-order
polymorphic functions, and where types are assumed to represent concepts in an
ontology that reflects our commonsense view of the world and the way we talk
about it in or-dinary language. In addition to [Adj Noun] compounds our
proposal seems also to suggest a plausible explana-tion for well known
adjective ordering restrictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4750</identifier>
 <datestamp>2008-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4750</id><created>2008-01-30</created><authors><author><keyname>Gariel</keyname><forenames>Maxime</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Graceful Degradation of Air Traffic Operations</title><categories>cs.OH</categories><abstract>  The introduction of new technologies and concepts of operation in the air
transportation system is not possible, unless they can be proven not to
adversely affect the system operation under not only nominal, but also degraded
conditions. In extreme scenarios, degraded operations due to partial or
complete technological failures should never endanger system safety. Many past
system evolutions, whether ground-based or airborne, have been based on
trial-and-error, and system safety was addressed only after a specific event
yielded dramatic or near- dramatic consequences. Future system evolutions,
however, must leverage available computation, prior knowledge and abstract
reasoning to anticipate all possible system degradations and prove that such
degradations are graceful and safe. This paper is concerned with the graceful
degradation of high-density, structured arrival traffic against partial or
complete surveillance failures. It is shown that for equal performance
requirements, some traffic configurations might be easier to handle than
others, thereby offering a quantitative perspective on these traffic
configurations. ability to &quot;gracefully degrade&quot;. To support our work, we also
introduce a new conflict resolution algorithm, aimed at solving conflicts
involving many aircraft when aircraft position information is in the process of
degrading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4774</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4774</id><created>2008-01-30</created><authors><author><keyname>Grossman</keyname><forenames>Thomas A.</forenames></author></authors><title>Source Code Protection for Applications Written in Microsoft Excel and
  Google Spreadsheet</title><categories>cs.SE</categories><comments>11 pages</comments><acm-class>D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2007 81-91 ISBN
  978-905617-58-6</journal-ref><abstract>  Spreadsheets are used to develop application software that is distributed to
users. Unfortunately, the users often have the ability to change the
programming statements (&quot;source code&quot;) of the spreadsheet application. This
causes a host of problems. By critically examining the suitability of
spreadsheet computer programming languages for application development, six
&quot;application development features&quot; are identified, with source code protection
being the most important. We investigate the status of these features and
discuss how they might be implemented in the dominant Microsoft Excel
spreadsheet and in the new Google Spreadsheet. Although Google Spreadsheet
currently provides no source code control, its web-centric delivery model
offers technical advantages for future provision of a rich set of features.
Excel has a number of tools that can be combined to provide &quot;pretty good
protection&quot; of source code, but weak passwords reduce its robustness. User
access to Excel source code must be considered a programmer choice rather than
an attribute of the spreadsheet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4775</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4775</id><created>2008-01-30</created><authors><author><keyname>Ettema</keyname><forenames>Harmen</forenames></author><author><keyname>Janssen</keyname><forenames>Paul</forenames></author><author><keyname>de Swart</keyname><forenames>Jacques</forenames></author></authors><title>Spreadsheet Assurance by &quot;Control Around&quot; is a Viable Alternative to the
  Traditional Approach</title><categories>cs.SE</categories><comments>9 pages, one colour diagram and a client case study</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2001 107-116 ISBN:1
  86166 179 7</journal-ref><abstract>  The traditional approach to spreadsheet auditing generally consists of
auditing every distinct formula within a spreadsheet. Although tools are
developed to support auditors during this process, the approach is still very
time consuming and therefore relatively expensive. As an alternative to the
traditional &quot;control through&quot; approach, this paper discusses a &quot;control around&quot;
approach. Within the proposed approach not all distinct formulas are audited
separately, but the relationship between input data and output data of a
spreadsheet is audited through comparison with a shadow model developed in a
modelling language. Differences between the two models then imply possible
errors in the spreadsheet. This paper describes relevant issues regarding the
&quot;control around&quot; approach and the circumstances in which this approach is
preferred above a traditional spreadsheet audit approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4777</identifier>
 <datestamp>2008-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4777</id><created>2008-01-30</created><authors><author><keyname>Ada</keyname><forenames>Anil</forenames></author></authors><title>Non-Deterministic Communication Complexity of Regular Languages</title><categories>cs.CC</categories><comments>Master's thesis, 93 pages</comments><abstract>  In this thesis, we study the place of regular languages within the
communication complexity setting. In particular, we are interested in the
non-deterministic communication complexity of regular languages.
  We show that a regular language has either O(1) or Omega(log n)
non-deterministic complexity. We obtain several linear lower bound results
which cover a wide range of regular languages having linear non-deterministic
complexity. These lower bound results also imply a result in semigroup theory:
we obtain sufficient conditions for not being in the positive variety Pol(Com).
  To obtain our results, we use algebraic techniques. In the study of regular
languages, the algebraic point of view pioneered by Eilenberg (\cite{Eil74})
has led to many interesting results. Viewing a semigroup as a computational
device that recognizes languages has proven to be prolific from both semigroup
theory and formal languages perspectives. In this thesis, we provide further
instances of such mutualism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4790</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4790</id><created>2008-01-30</created><updated>2008-07-01</updated><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>Information Width</title><categories>cs.DM cs.IT cs.LG math.IT</categories><comments>Typo error in eq. (13)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kolmogorov argued that the concept of information exists also in problems
with no underlying stochastic model (as Shannon's information representation)
for instance, the information contained in an algorithm or in the genome. He
introduced a combinatorial notion of entropy and information $I(x:\sy)$
conveyed by a binary string $x$ about the unknown value of a variable $\sy$.
The current paper poses the following questions: what is the relationship
between the information conveyed by $x$ about $\sy$ to the description
complexity of $x$ ? is there a notion of cost of information ? are there limits
on how efficient $x$ conveys information ?
  To answer these questions Kolmogorov's definition is extended and a new
concept termed {\em information width} which is similar to $n$-widths in
approximation theory is introduced. Information of any input source, e.g.,
sample-based, general side-information or a hybrid of both can be evaluated by
a single common formula. An application to the space of binary functions is
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4794</identifier>
 <datestamp>2008-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4794</id><created>2008-01-30</created><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>On the Complexity of Binary Samples</title><categories>cs.DM cs.AI cs.LG</categories><abstract>  Consider a class $\mH$ of binary functions $h: X\to\{-1, +1\}$ on a finite
interval $X=[0, B]\subset \Real$. Define the {\em sample width} of $h$ on a
finite subset (a sample) $S\subset X$ as $\w_S(h) \equiv \min_{x\in S}
|\w_h(x)|$, where $\w_h(x) = h(x) \max\{a\geq 0: h(z)=h(x), x-a\leq z\leq
x+a\}$. Let $\mathbb{S}_\ell$ be the space of all samples in $X$ of cardinality
$\ell$ and consider sets of wide samples, i.e., {\em hypersets} which are
defined as $A_{\beta, h} = \{S\in \mathbb{S}_\ell: \w_{S}(h) \geq \beta\}$.
Through an application of the Sauer-Shelah result on the density of sets an
upper estimate is obtained on the growth function (or trace) of the class
$\{A_{\beta, h}: h\in\mH\}$, $\beta&gt;0$, i.e., on the number of possible
dichotomies obtained by intersecting all hypersets with a fixed collection of
samples $S\in\mathbb{S}_\ell$ of cardinality $m$. The estimate is
$2\sum_{i=0}^{2\lfloor B/(2\beta)\rfloor}{m-\ell\choose i}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4802</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4802</id><created>2008-01-30</created><authors><author><keyname>Rust</keyname><forenames>Alan</forenames></author><author><keyname>Bishop</keyname><forenames>Brian</forenames></author><author><keyname>McDaid</keyname><forenames>Kevin</forenames></author></authors><title>Investigating the Potential of Test-Driven Development for Spreadsheet
  Engineering</title><categories>cs.SE</categories><comments>11 pages, 5 colour figures, 2 case studies</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. 2006 95-105
  ISBN:1-905617-08-9</journal-ref><abstract>  It is widely documented that the absence of a structured approach to
spreadsheet engineering is a key factor in the high level of spreadsheet
errors. In this paper we propose and investigate the application of Test-Driven
Development to the creation of spreadsheets. Test-Driven Development is an
emerging development technique in software engineering that has been shown to
result in better quality software code. It has also been shown that this code
requires less testing and is easier to maintain. Through a pair of case studies
we demonstrate that Test-Driven Development can be applied to the development
of spreadsheets. We present the detail of these studies preceded by a clear
explanation of the technique and its application to spreadsheet engineering. A
supporting tool under development by the authors is also documented along with
proposed research to determine the effectiveness of the methodology and the
associated tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4807</identifier>
 <datestamp>2008-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4807</id><created>2008-01-30</created><authors><author><keyname>Jafri</keyname><forenames>Syed Ali Raza</forenames></author><author><keyname>Boutin</keyname><forenames>Mireille</forenames></author><author><keyname>Delp</keyname><forenames>Edward J.</forenames></author></authors><title>Automatic Text Area Segmentation in Natural Images</title><categories>cs.CV</categories><abstract>  We present a hierarchical method for segmenting text areas in natural images.
The method assumes that the text is written with a contrasting color on a more
or less uniform background. But no assumption is made regarding the language or
character set used to write the text. In particular, the text can contain
simple graphics or symbols. The key feature of our approach is that we first
concentrate on finding the background of the text, before testing whether there
is actually text on the background. Since uniform areas are easy to find in
natural images, and since text backgrounds define areas which contain &quot;holes&quot;
(where the text is written) we thus look for uniform areas containing &quot;holes&quot;
and label them as text backgrounds candidates. Each candidate area is then
further tested for the presence of text within its convex hull. We tested our
method on a database of 65 images including English and Urdu text. The method
correctly segmented all the text areas in 63 of these images, and in only 4 of
these were areas that do not contain text also segmented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4817</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4817</id><created>2008-01-30</created><updated>2014-11-01</updated><authors><author><keyname>Su</keyname><forenames>Shenghui</forenames></author><author><keyname>Lv</keyname><forenames>Shuwang</forenames></author></authors><title>The REESSE2+ Public-key Encryption Scheme</title><categories>cs.CR cs.CC</categories><comments>11 pages, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives the definitions of an anomalous super-increasing sequence
and an anomalous subset sum separately, proves the two properties of an
anomalous super-increasing sequence, and proposes the REESSE2+ public-key
encryption scheme which includes the three algorithms for key generation,
encryption and decryption. The paper discusses the necessity and sufficiency of
the lever function for preventing the Shamir extremum attack, analyzes the
security of REESSE2+ against extracting a private key from a public key through
the exhaustive search, recovering a plaintext from a ciphertext plus a knapsack
of high density through the L3 lattice basis reduction method, and
heuristically obtaining a plaintext through the meet-in-the-middle attack or
the adaptive-chosen-ciphertext attack. The authors evaluate the time complexity
of REESSE2+ encryption and decryption algorithms, compare REESSE2+ with ECC and
NTRU, and find that the encryption speed of REESSE2+ is ten thousand times
faster than ECC and NTRU bearing the equivalent security, and the decryption
speed of REESSE2+ is roughly equivalent to ECC and NTRU respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4845</identifier>
 <datestamp>2008-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4845</id><created>2008-01-31</created><authors><author><keyname>Brito</keyname><forenames>Carlos</forenames></author><author><keyname>Vaya</keyname><forenames>Shailesh</forenames></author></authors><title>Improved lower bound for deterministic broadcasting in radio networks</title><categories>cs.DM cs.DC</categories><comments>13 pages</comments><abstract>  We consider the problem of deterministic broadcasting in radio networks when
the nodes have limited knowledge about the topology of the network. We show
that for every deterministic broadcasting protocol there exists a network, of
radius 2, for which the protocol takes at least $\Omega(\sqrt{n}) rounds for
completing the broadcast. Our argument can be extended to prove a lower bound
of Omega(\sqrt{nD}) rounds for broadcasting in radio networks of radius D. This
resolves one of the open problems posed in [29], where in the authors proved a
lower bound of $\Omega(n^{1/4}) rounds for broadcasting in constant diameter
networks.
  We prove the new lower $\Omega(\sqrt{n})$ bound for a special family of
radius 2 networks. Each network of this family consists of O(\sqrt{n})
components which are connected to each other via only the source node. At the
heart of the proof is a novel simulation argument, which essentially says that
any arbitrarily complicated strategy of the source node can be simulated by the
nodes of the networks, if the source node just transmits partial topological
knowledge about some component instead of arbitrary complicated messages. To
the best of our knowledge this type of simulation argument is novel and may be
useful in further improving the lower bound or may find use in other
applications.
  Keywords: radio networks, deterministic broadcast, lower bound, advice
string, simulation, selective families, limited topological knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4851</identifier>
 <datestamp>2008-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4851</id><created>2008-01-31</created><authors><author><keyname>Busch</keyname><forenames>Costas</forenames></author><author><keyname>Kannan</keyname><forenames>Rajgopal</forenames></author></authors><title>Bicretieria Optimization in Routing Games</title><categories>cs.GT cs.DS</categories><comments>15 pages, submitted to SPAA</comments><abstract>  Two important metrics for measuring the quality of routing paths are the
maximum edge congestion $C$ and maximum path length $D$. Here, we study
bicriteria in routing games where each player $i$ selfishly selects a path that
simultaneously minimizes its maximum edge congestion $C_i$ and path length
$D_i$. We study the stability and price of anarchy of two bicriteria games:
  - {\em Max games}, where the social cost is $\max(C,D)$ and the player cost
is $\max(C_i, D_i)$. We prove that max games are stable and convergent under
best-response dynamics, and that the price of anarchy is bounded above by the
maximum path length in the players' strategy sets. We also show that this bound
is tight in worst-case scenarios.
  - {\em Sum games}, where the social cost is $C+D$ and the player cost is
$C_i+D_i$. For sum games, we first show the negative result that there are game
instances that have no Nash-equilibria. Therefore, we examine an approximate
game called the {\em sum-bucket game} that is always convergent (and therefore
stable). We show that the price of anarchy in sum-bucket games is bounded above
by $C^* \cdot D^* / (C^* + D^*)$ (with a poly-log factor), where $C^*$ and
$D^*$ are the optimal coordinated congestion and path length. Thus, the
sum-bucket game has typically superior price of anarchy bounds than the max
game. In fact, when either $C^*$ or $D^*$ is small (e.g. constant) the social
cost of the Nash-equilibria is very close to the coordinated optimal $C^* +
D^*$ (within a poly-log factor). We also show that the price of anarchy bound
is tight for cases where both $C^*$ and $D^*$ are large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4911</identifier>
 <datestamp>2008-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4911</id><created>2008-01-31</created><authors><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>On the Double Coset Membership Problem for Permutation Groups</title><categories>cs.CC</categories><comments>14 pages</comments><journal-ref>Algebraic structures and their applications, pp. 351--363 (2002)</journal-ref><abstract>  We show that the Double Coset Membership problem for permutation groups
possesses perfect zero-knowledge proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4917</identifier>
 <datestamp>2008-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4917</id><created>2008-01-31</created><authors><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>Zero-Knowledge Proofs of the Conjugacy for Permutation Groups</title><categories>cs.CC</categories><comments>12 pages</comments><journal-ref>Bulletin of the Lviv University, Series in Mechanics and
  Mathematics. Vol. 61, pp. 195--205 (2003)</journal-ref><abstract>  We design a perfect zero-knowledge proof system for recognition if two
permutation groups are conjugate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0003</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0003</id><created>2008-02-01</created><authors><author><keyname>Vasil'ev</keyname><forenames>Yuriy</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author><author><keyname>Avgustinovich</keyname><forenames>Sergey</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author><author><keyname>Krotov</keyname><forenames>Denis</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author></authors><title>On mobile sets in the binary hypercube</title><categories>math.CO cs.IT math.IT</categories><comments>9p., in Russian (English version will be finished later)</comments><msc-class>05B99; 94B25</msc-class><journal-ref>Diskretn. Anal. Issled. Oper. 15(3) 2008, 11-21 (in Russian)</journal-ref><abstract>  If two distance-3 codes have the same neighborhood, then each of them is
called a mobile set. In the (4k+3)-dimensional binary hypercube, there exists a
mobile set of cardinality 2*6^k that cannot be split into mobile sets of
smaller cardinalities or represented as a natural extension of a mobile set in
a hypercube of smaller dimension. Keywords: mobile set; 1-perfect code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0006</identifier>
 <datestamp>2008-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0006</id><created>2008-01-31</created><updated>2008-02-03</updated><authors><author><keyname>Effros</keyname><forenames>Edward G.</forenames></author></authors><title>New Perspectives and some Celebrated Quantum Inequalities</title><categories>math-ph cs.IT math.IT math.MP</categories><msc-class>81P68</msc-class><abstract>  Some of the important inequalities associated with quantum entropy are
immediate algebraic consequences of the Hansen-Pedersen-Jensen inequality. A
general argument is given in terms of the matrix perspective of an operator
convex function. A matrix analogue of Mar\'{e}chal's extended perspectives
provides additional inequalities, including a $p+q\leq 1$ result of Lieb.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0017</identifier>
 <datestamp>2008-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0017</id><created>2008-01-31</created><authors><author><keyname>Amir</keyname><forenames>Amihood</forenames></author><author><keyname>Efremenko</keyname><forenames>Klim</forenames></author><author><keyname>Kapah</keyname><forenames>Oren</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Rothschild</keyname><forenames>Amir</forenames></author></authors><title>Improved Deterministic Length Reduction</title><categories>cs.DS</categories><comments>7 pages</comments><abstract>  This paper presents a new technique for deterministic length reduction. This
technique improves the running time of the algorithm presented in \cite{LR07}
for performing fast convolution in sparse data. While the regular fast
convolution of vectors $V_1,V_2$ whose sizes are $N_1,N_2$ respectively, takes
$O(N_1 \log N_2)$ using FFT, using the new technique for length reduction, the
algorithm proposed in \cite{LR07} performs the convolution in $O(n_1 \log^3
n_1)$, where $n_1$ is the number of non-zero values in $V_1$. The algorithm
assumes that $V_1$ is given in advance, and $V_2$ is given in running time. The
novel technique presented in this paper improves the convolution time to $O(n_1
\log^2 n_1)$ {\sl deterministically}, which equals the best running time given
achieved by a {\sl randomized} algorithm.
  The preprocessing time of the new technique remains the same as the
preprocessing time of \cite{LR07}, which is $O(n_1^2)$. This assumes and deals
the case where $N_1$ is polynomial in $n_1$. In the case where $N_1$ is
exponential in $n_1$, a reduction to a polynomial case can be used. In this
paper we also improve the preprocessing time of this reduction from $O(n_1^4)$
to $O(n_1^3{\rm polylog}(n_1))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0024</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0024</id><created>2008-02-01</created><updated>2008-07-10</updated><authors><author><keyname>Guillemot</keyname><forenames>Sylvain</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author></authors><title>Solving the Maximum Agreement SubTree and the Maximum Compatible Tree
  problems on many bounded degree trees</title><categories>cs.CC cs.DM</categories><comments>Revised version of our paper from CPM'06. 14 pages. 3 figures</comments><journal-ref>Proceedings of the 17th Annual Symposium on Combinatorial Pattern
  Matching (CPM'06), volume 4009 of Lecture Notes in Computer Science, pages
  165--176. Springer-Verlag, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of leaf-labeled trees with identical leaf sets, the well-known
&quot;Maximum Agreement SubTree&quot; problem (MAST) consists of finding a subtree
homeomorphically included in all input trees and with the largest number of
leaves. Its variant called &quot;Maximum Compatible Tree&quot; (MCT) is less stringent,
as it allows the input trees to be refined. Both problems are of particular
interest in computational biology, where trees encountered have often small
degrees.
  In this paper, we study the parameterized complexity of MAST and MCT with
respect to the maximum degree, denoted by D, of the input trees. It is known
that MAST is polynomial for bounded D. As a counterpart, we show that the
problem is W[1]-hard with respect to parameter D. Moreover, relying on recent
advances in parameterized complexity we obtain a tight lower bound: while MAST
can be solved in O(N^{O(D)}) time where N denotes the input length, we show
that an O(N^{o(D)}) bound is not achievable, unless SNP is contained in SE. We
also show that MCT is W[1]-hard with respect to D, and that MCT cannot be
solved in O(N^{o(2^{D/2})}) time, SNP is contained in SE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0030</identifier>
 <datestamp>2008-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0030</id><created>2008-01-31</created><authors><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author></authors><title>Mission impossible: Computing the network coding capacity region</title><categories>cs.IT math.IT</categories><abstract>  One of the main theoretical motivations for the emerging area of network
coding is the achievability of the max-flow/min-cut rate for single source
multicast. This can exceed the rate achievable with routing alone, and is
achievable with linear network codes. The multi-source problem is more
complicated. Computation of its capacity region is equivalent to determination
of the set of all entropy functions $\Gamma^*$, which is non-polyhedral. The
aim of this paper is to demonstrate that this difficulty can arise even in
single source problems. In particular, for single source networks with
hierarchical sink requirements, and for single source networks with secrecy
constraints. In both cases, we exhibit networks whose capacity regions involve
$\Gamma^*$. As in the multi-source case, linear codes are insufficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0116</identifier>
 <datestamp>2008-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0116</id><created>2008-02-01</created><updated>2008-04-03</updated><authors><author><keyname>Schr&#xf6;der</keyname><forenames>Lutz</forenames></author><author><keyname>Patinson</keyname><forenames>Dirk</forenames></author></authors><title>Shallow Models for Non-Iterative Modal Logics</title><categories>cs.LO cs.AI cs.CC cs.MA</categories><report-no>Imperial College TR Computing 2008/3</report-no><acm-class>F.4.1; F.2.2</acm-class><abstract>  The methods used to establish PSPACE-bounds for modal logics can roughly be
grouped into two classes: syntax driven methods establish that exhaustive proof
search can be performed in polynomial space whereas semantic approaches
directly construct shallow models. In this paper, we follow the latter approach
and establish generic PSPACE-bounds for a large and heterogeneous class of
modal logics in a coalgebraic framework. In particular, no complete
axiomatisation of the logic under scrutiny is needed. This does not only
complement our earlier, syntactic, approach conceptually, but also covers a
wide variety of new examples which are difficult to harness by purely syntactic
means. Apart from re-proving known complexity bounds for a large variety of
structurally different logics, we apply our method to obtain previously unknown
PSPACE-bounds for Elgesem's logic of agency and for graded modal logic over
reflexive frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0130</identifier>
 <datestamp>2008-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0130</id><created>2008-02-01</created><authors><author><keyname>Ezri</keyname><forenames>D.</forenames></author><author><keyname>Bobrovsky</keyname><forenames>B. Z.</forenames></author><author><keyname>Schuss</keyname><forenames>Z.</forenames></author></authors><title>About the true type of smoothers</title><categories>math.OC cs.IT math.IT</categories><comments>Non-causal estimation</comments><msc-class>60G35; 93E10; 94A05</msc-class><abstract>  We employ the variational formulation and the Euler-Lagrange equations to
study the steady-state error in linear non-causal estimators (smoothers). We
give a complete description of the steady-state error for inputs that are
polynomial in time. We show that the steady-state error regime in a smoother is
similar to that in a filter of double the type. This means that the
steady-state error in the optimal smoother is significantly smaller than that
in the Kalman filter. The results reveal a significant advantage of smoothing
over filtering with respect to robustness to model uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0137</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0137</id><created>2008-02-01</created><updated>2009-03-31</updated><authors><author><keyname>Sutra</keyname><forenames>Pierre</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Shapiro</keyname><forenames>Marc</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Fault-Tolerant Partial Replication in Large-Scale Database Systems</title><categories>cs.DB</categories><proxy>ccsd inria-00232662</proxy><report-no>RR-6440</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a decentralised approach to committing transactions in a
replicated database, under partial replication. Previous protocols either
re-execute transactions entirely and/or compute a total order of transactions.
In contrast, ours applies update values, and orders only conflicting
transactions. It results that transactions execute faster, and distributed
databases commit in small committees. Both effects contribute to preserve
scalability as the number of databases and transactions increase. Our algorithm
ensures serializability, and is live and safe in spite of faults.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0179</identifier>
 <datestamp>2008-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0179</id><created>2008-02-01</created><updated>2008-05-12</updated><authors><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author><author><keyname>Sprintson</keyname><forenames>Alex</forenames></author><author><keyname>Georghiades</keyname><forenames>Costas</forenames></author></authors><title>On the Relation Between the Index Coding and the Network Coding Problems</title><categories>cs.IT math.IT</categories><abstract>  In this paper we show that the Index Coding problem captures several
important properties of the more general Network Coding problem. An instance of
the Index Coding problem includes a server that holds a set of information
messages $X=\{x_1,...,x_k\}$ and a set of receivers $R$. Each receiver has some
side information, known to the server, represented by a subset of $X$ and
demands another subset of $X$. The server uses a noiseless communication
channel to broadcast encodings of messages in $X$ to satisfy the receivers'
demands. The goal of the server is to find an encoding scheme that requires the
minimum number of transmissions.
  We show that any instance of the Network Coding problem can be efficiently
reduced to an instance of the Index Coding problem. Our reduction shows that
several important properties of the Network Coding problem carry over to the
Index Coding problem. In particular, we prove that both scalar linear and
vector linear codes are insufficient for achieving the minimal number of
transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0188</identifier>
 <datestamp>2008-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0188</id><created>2008-02-01</created><authors><author><keyname>Feret</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author></authors><title>Partitioning the Threads of a Mobile System</title><categories>cs.OH</categories><abstract>  In this paper, we show how thread partitioning helps in proving properties of
mobile systems. Thread partitioning consists in gathering the threads of a
mobile system into several classes. The partitioning criterion is left as a
parameter of both the mobility model and the properties we are interested in.
Then, we design a polynomial time abstract interpretation-based static analysis
that counts the number of threads inside each partition class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0212</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0212</id><created>2008-02-01</created><authors><author><keyname>Alves</keyname><forenames>Miriam C. B.</forenames><affiliation>Institute of Aeronautics and Space - IAE/CTA, Brazil</affiliation></author><author><keyname>Dantas</keyname><forenames>Christine C.</forenames><affiliation>Institute of Aeronautics and Space - IAE/CTA, Brazil</affiliation></author><author><keyname>Arai</keyname><forenames>Nanci N.</forenames><affiliation>Institute of Aeronautics and Space - IAE/CTA, Brazil</affiliation></author><author><keyname>da Silva</keyname><forenames>Rovedy B.</forenames><affiliation>Institute of Aeronautics and Space - IAE/CTA, Brazil</affiliation></author></authors><title>A topological formal treatment for scenario-based software specification
  of concurrent real-time systems</title><categories>cs.SE cs.LO</categories><comments>20th International Conference on Software and Systems Engineering and
  their Applications, Conservatoire des Arts &amp; Metiers, Paris, France, 4-6
  December 2007</comments><abstract>  Real-time systems are computing systems in which the meeting of their
requirements is vital for their correctness. Consequently, if the real-time
requirements of these systems are poorly understood and verified, the results
can be disastrous and lead to irremediable project failures at the early phases
of development. The present work addresses the problem of detecting deadlock
situations early in the requirements specification phase of a concurrent real
time system, proposing a simple proof-of-concepts prototype that joins
scenario-based requirements specifications and techniques based on topology.
The efforts are concentrated in the integration of the formal representation of
Message Sequence Chart scenarios into the deadlock detection algorithm of
Fajstrup et al., based on geometric and algebraic topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0249</identifier>
 <datestamp>2008-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0249</id><created>2008-02-02</created><authors><author><keyname>Duchamp</keyname><forenames>G. H. E.</forenames><affiliation>LIPN</affiliation></author><author><keyname>Blasiak</keyname><forenames>P.</forenames><affiliation>IFJ-Pan</affiliation></author><author><keyname>Horzela</keyname><forenames>A.</forenames><affiliation>IFJ-Pan</affiliation></author><author><keyname>Penson</keyname><forenames>K. A.</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Solomon</keyname><forenames>A. I.</forenames></author></authors><title>Hopf Algebras in General and in Combinatorial Physics: a practical
  introduction</title><categories>quant-ph cs.SC math.CO</categories><proxy>ccsd hal-00232877</proxy><abstract>  This tutorial is intended to give an accessible introduction to Hopf
algebras. The mathematical context is that of representation theory, and we
also illustrate the structures with examples taken from combinatorics and
quantum physics, showing that in this latter case the axioms of Hopf algebra
arise naturally. The text contains many exercises, some taken from physics,
aimed at expanding and exemplifying the concepts introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0251</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0251</id><created>2008-02-02</created><authors><author><keyname>Rossi</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis, CEREMADE</affiliation></author><author><keyname>Conan-Guez</keyname><forenames>Brieuc</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis, LITA</affiliation></author></authors><title>Multi-Layer Perceptrons and Symbolic Data</title><categories>cs.NE</categories><proxy>ccsd inria-00232878</proxy><journal-ref>Symbolic Data Analysis and the SODAS Software Wiley (Ed.) (2008)
  373-391</journal-ref><abstract>  In some real world situations, linear models are not sufficient to represent
accurately complex relations between input variables and output variables of a
studied system. Multilayer Perceptrons are one of the most successful
non-linear regression tool but they are unfortunately restricted to inputs and
outputs that belong to a normed vector space. In this chapter, we propose a
general recoding method that allows to use symbolic data both as inputs and
outputs to Multilayer Perceptrons. The recoding is quite simple to implement
and yet provides a flexible framework that allows to deal with almost all
practical cases. The proposed method is illustrated on a real world data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0252</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0252</id><created>2008-02-02</created><authors><author><keyname>Conan-Guez</keyname><forenames>Brieuc</forenames><affiliation>LITA</affiliation></author><author><keyname>Rossi</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author></authors><title>Acc\'el\'eration des cartes auto-organisatrices sur tableau de
  dissimilarit\'es par s\'eparation et \'evaluation</title><categories>cs.NE</categories><comments>A para\^itre</comments><proxy>ccsd inria-00232866</proxy><journal-ref>REVUE DES NOUVELLES TECHNOLOGIES DE L'INFORMATION (2008)</journal-ref><abstract>  In this paper, a new implementation of the adaptation of Kohonen
self-organising maps (SOM) to dissimilarity matrices is proposed. This
implementation relies on the branch and bound principle to reduce the algorithm
running time. An important property of this new approach is that the obtained
algorithm produces exactly the same results as the standard algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0260</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0260</id><created>2008-02-02</created><authors><author><keyname>Jeganathan</keyname><forenames>L.</forenames></author><author><keyname>Rama</keyname><forenames>R.</forenames></author><author><keyname>Sengupta</keyname><forenames>Ritabrata</forenames></author></authors><title>A proposal to a generalised splicing with a self assembly approach</title><categories>cs.DM</categories><comments>8 pages, 3 figures</comments><abstract>  Theory of splicing is an abstract model of the recombinant behaviour of DNAs.
In a splicing system, two strings to be spliced are taken from the same set and
the splicing rule is from another set. Here we propose a generalised splicing
(GS) model with three components, two strings from two languages and a splicing
rule from third component. We propose a generalised self assembly (GSA) of
strings. Two strings $u_1xv_1$ and $u_2xv_2$ self assemble over $x$ and
generate $u_1xv_2$ and $u_2xv_1$. We study the relationship between GS and GSA.
We study some classes of generalised splicing languages with the help of
generalised self assembly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0287</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0287</id><created>2008-02-03</created><authors><author><keyname>Krier</keyname><forenames>Catherine</forenames><affiliation>DICE</affiliation></author><author><keyname>Rossi</keyname><forenames>Fabrice</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author><author><keyname>Fran&#xe7;ois</keyname><forenames>Damien</forenames><affiliation>CESAME</affiliation></author><author><keyname>Verleysen</keyname><forenames>Michel</forenames><affiliation>DICE - MLG</affiliation></author></authors><title>A data-driven functional projection approach for the selection of
  feature ranges in spectra with ICA or cluster analysis</title><categories>cs.NE</categories><comments>A paraitre</comments><proxy>ccsd inria-00232874</proxy><journal-ref>Chemometrics and Intelligent Laboratory Systems (2008)</journal-ref><doi>10.1016/j.chemolab.2007.09.004</doi><abstract>  Prediction problems from spectra are largely encountered in chemometry. In
addition to accurate predictions, it is often needed to extract information
about which wavelengths in the spectra contribute in an effective way to the
quality of the prediction. This implies to select wavelengths (or wavelength
intervals), a problem associated to variable selection. In this paper, it is
shown how this problem may be tackled in the specific case of smooth (for
example infrared) spectra. The functional character of the spectra (their
smoothness) is taken into account through a functional variable projection
procedure. Contrarily to standard approaches, the projection is performed on a
basis that is driven by the spectra themselves, in order to best fit their
characteristics. The methodology is illustrated by two examples of functional
projection, using Independent Component Analysis and functional variable
clustering, respectively. The performances on two standard infrared spectra
benchmarks are illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0314</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0314</id><created>2008-02-03</created><updated>2010-09-01</updated><authors><author><keyname>Michael</keyname><forenames>Morris</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author><author><keyname>Ukkonen</keyname><forenames>Esko</forenames></author></authors><title>On the complexity of finding gapped motifs</title><categories>cs.CC cs.DM</categories><comments>Published in Journal of Discrete Algorithms</comments><doi>10.1016/j.jda.2009.12.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the corresponding author because the newest
version is now published in Journal of Discrete Algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0342</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0342</id><created>2008-02-04</created><authors><author><keyname>Nazer</keyname><forenames>Bobak</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>The Case for Structured Random Codes in Network Capacity Theorems</title><categories>cs.IT math.IT</categories><comments>23 pages, 7 figures, To appear in European Transactions on
  Telecommunication: Special Issue on New Directions in Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random coding arguments are the backbone of most channel capacity
achievability proofs. In this paper, we show that in their standard form, such
arguments are insufficient for proving some network capacity theorems:
structured coding arguments, such as random linear or lattice codes, attain
higher rates. Historically, structured codes have been studied as a stepping
stone to practical constructions. However, K\&quot;{o}rner and Marton demonstrated
their usefulness for capacity theorems through the derivation of the optimal
rate region of a distributed functional source coding problem. Here, we use
multicasting over finite field and Gaussian multiple-access networks as
canonical examples to demonstrate that even if we want to send bits over a
network, structured codes succeed where simple random codes fail. Beyond
network coding, we also consider distributed computation over noisy channels
and a special relay-type problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0351</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0351</id><created>2008-02-04</created><updated>2012-01-22</updated><authors><author><keyname>Srinivasa</keyname><forenames>Sunil</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Path Loss Exponent Estimation in a Large Field of Interferers</title><categories>cs.IT math.IT</categories><comments>Work underway</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless channels, the path loss exponent (PLE) has a strong impact on the
quality of links, and hence, it needs to be accurately estimated for the
efficient design and operation of wireless networks. In this paper, we address
the problem of PLE estimation in large wireless networks, which is relevant to
several important issues in networked communications such as localization,
energy-efficient routing, and channel access. We consider a large ad hoc
network where nodes are distributed as a homogeneous Poisson point process on
the plane and the channels are subject to Nakagami-m fading. We propose and
discuss three distributed algorithms for estimating the PLE under these
settings which explicitly take into account the interference in the network. In
addition, we provide simulation results to demonstrate the performance of the
algorithms and quantify the estimation errors. We also describe how to estimate
the PLE accurately even in networks with spatially varying PLEs and more
general node distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0414</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0414</id><created>2008-02-04</created><authors><author><keyname>Ezri</keyname><forenames>Doron</forenames></author><author><keyname>Bobrovsky</keyname><forenames>Ben-Tzion</forenames></author><author><keyname>Schuss</keyname><forenames>Zeev</forenames></author></authors><title>The exit problem in optimal non-causal extimation</title><categories>math.OC cs.IT math.IT</categories><comments>Loss of lock in nonlinear smoothers</comments><msc-class>60G35; 62M09; 93E10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the phenomenon of loss of lock in the optimal non-causal phase
estimation problem, a benchmark problem in nonlinear estimation. Our method is
based on the computation of the asymptotic distribution of the optimal
estimation error in case the number of trajectories in the optimization problem
is finite. The computation is based directly on the minimum noise energy
optimality criterion rather than on state equations of the error, as is the
usual case in the literature. The results include an asymptotic computation of
the mean time to lose lock (MTLL) in the optimal smoother. We show that the
MTLL in the first and second order smoothers is significantly longer than that
in the causal extended Kalman filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0423</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0423</id><created>2008-02-04</created><authors><author><keyname>F&#xe4;rnqvist</keyname><forenames>Tommy</forenames></author><author><keyname>Jonsson</keyname><forenames>Peter</forenames></author><author><keyname>Thapper</keyname><forenames>Johan</forenames></author></authors><title>Approximability Distance in the Space of H-Colourability Problems</title><categories>cs.CC</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph homomorphism is a vertex map which carries edges from a source graph
to edges in a target graph. We study the approximability properties of the
Weighted Maximum H-Colourable Subgraph problem (MAX H-COL). The instances of
this problem are edge-weighted graphs G and the objective is to find a subgraph
of G that has maximal total edge weight, under the condition that the subgraph
has a homomorphism to H; note that for H=K_k this problem is equivalent to MAX
k-CUT. To this end, we introduce a metric structure on the space of graphs
which allows us to extend previously known approximability results to larger
classes of graphs. Specifically, the approximation algorithms for MAX CUT by
Goemans and Williamson and MAX k-CUT by Frieze and Jerrum can be used to yield
non-trivial approximation results for MAX H-COL. For a variety of graphs, we
show near-optimality results under the Unique Games Conjecture. We also use our
method for comparing the performance of Frieze &amp; Jerrum's algorithm with
Hastad's approximation algorithm for general MAX 2-CSP. This comparison is, in
most cases, favourable to Frieze &amp; Jerrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0483</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0483</id><created>2008-02-04</created><authors><author><keyname>Wu</keyname><forenames>Fang</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Popularity, Novelty and Attention</title><categories>cs.CY</categories><acm-class>H.1.2; H.5.2; K.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the role that popularity and novelty play in attracting the
attention of users to dynamic websites. We do so by determining the performance
of three different strategies that can be utilized to maximize attention. The
first one prioritizes novelty while the second emphasizes popularity. A third
strategy looks myopically into the future and prioritizes stories that are
expected to generate the most clicks within the next few minutes. We show that
the first two strategies should be selected on the basis of the rate of novelty
decay, while the third strategy performs sub-optimally in most cases. We also
demonstrate that the relative performance of the first two strategies as a
function of the rate of novelty decay changes abruptly around a critical value,
resembling a phase transition in the physical world. 1
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0487</identifier>
 <datestamp>2008-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0487</id><created>2008-02-04</created><authors><author><keyname>Calude</keyname><forenames>Cristian</forenames></author><author><keyname>Zimand</keyname><forenames>Marius</forenames></author></authors><title>Algorithmically independent sequences</title><categories>cs.IT cs.SE math.AG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two objects are independent if they do not affect each other. Independence is
well-understood in classical information theory, but less in algorithmic
information theory. Working in the framework of algorithmic information theory,
the paper proposes two types of independence for arbitrary infinite binary
sequences and studies their properties. Our two proposed notions of
independence have some of the intuitive properties that one naturally expects.
For example, for every sequence $x$, the set of sequences that are independent
(in the weaker of the two senses) with $x$ has measure one. For both notions of
independence we investigate to what extent pairs of independent sequences, can
be effectively constructed via Turing reductions (from one or more input
sequences). In this respect, we prove several impossibility results. For
example, it is shown that there is no effective way of producing from an
arbitrary sequence with positive constructive Hausdorff dimension two sequences
that are independent (even in the weaker type of independence) and have
super-logarithmic complexity. Finally, a few conjectures and open questions are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0534</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0534</id><created>2008-02-04</created><authors><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Capacity of Wireless Networks within o(log(SNR)) - the Impact of Relays,
  Feedback, Cooperation and Full-Duplex Operation</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, Vol. 55, No. 5, May 2009,
  Pages: 2334-2344</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has characterized the sum capacity of
time-varying/frequency-selective wireless interference networks and $X$
networks within $o(\log({SNR}))$, i.e., with an accuracy approaching 100% at
high SNR (signal to noise power ratio). In this paper, we seek similar capacity
characterizations for wireless networks with relays, feedback, full duplex
operation, and transmitter/receiver cooperation through noisy channels. First,
we consider a network with $S$ source nodes, $R$ relay nodes and $D$
destination nodes with random time-varying/frequency-selective channel
coefficients and global channel knowledge at all nodes. We allow full-duplex
operation at all nodes, as well as causal noise-free feedback of all received
signals to all source and relay nodes. The sum capacity of this network is
characterized as $\frac{SD}{S+D-1}\log({SNR})+o(\log({SNR}))$. The implication
of the result is that the capacity benefits of relays, causal feedback,
transmitter/receiver cooperation through physical channels and full duplex
operation become a negligible fraction of the network capacity at high SNR.
Some exceptions to this result are also pointed out in the paper. Second, we
consider a network with $K$ full duplex nodes with an independent message from
every node to every other node in the network. We find that the sum capacity of
this network is bounded below by $\frac{K(K-1)}{2K-2}+o(\log({SNR}))$ and
bounded above by $\frac{K(K-1)}{2K-3}+o(\log({SNR}))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0543</identifier>
 <datestamp>2008-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0543</id><created>2008-02-04</created><authors><author><keyname>Jahanbakhsh</keyname><forenames>Kazem</forenames></author><author><keyname>Hajhosseini</keyname><forenames>Marzieh</forenames></author></authors><title>Improving Performance of Cluster Based Routing Protocol using
  Cross-Layer Design</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main goal of routing protocol is to efficiency delivers data from source
to destination. All routing protocols are the same in this goal, but the way
they adopt to achieve it is different, so routing strategy has an egregious
role on the performance of an ad hoc network. Most of routing protocols
proposed for ad hoc networks have a flat structure. These protocols expand the
control overhead packets to discover or maintain a route. On the other hand a
number of hierarchical-based routing protocols have been developed, mostly are
based on layered design. These protocols improve network performances
especially when the network size grows up since details about remote portion of
network can be handled in an aggregate manner. Although, there is another
approach to design a protocol called cross-layer design. Using this approach
information can exchange between different layer of protocol stack, result in
optimizing network performances.
  In this paper, we intend to exert cross-layer design to optimize Cluster
Based Routing Protocol (Cross-CBRP). Using NS-2 network simulator we evaluate
rate of cluster head changes, throughput and packet delivery ratio. Comparisons
denote that Cross-CBRP has better performances with respect to the original
CBRP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0550</identifier>
 <datestamp>2008-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0550</id><created>2008-02-05</created><authors><author><keyname>Merrer</keyname><forenames>Erwan Le</forenames><affiliation>IRISA, FT R&amp;D</affiliation></author><author><keyname>Gramoli</keyname><forenames>Vincent</forenames><affiliation>IRISA</affiliation></author><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames><affiliation>IRISA</affiliation></author><author><keyname>Viana</keyname><forenames>Aline</forenames><affiliation>IRISA</affiliation></author><author><keyname>Bertier</keyname><forenames>Marin</forenames><affiliation>IRISA</affiliation></author></authors><title>Energy Aware Self-Organizing Density Management in Wireless Sensor
  Networks</title><categories>cs.DC</categories><proxy>ccsd inria-00238567</proxy><journal-ref>Dans International Workshop on Decentralized Resource Sharing in
  Mobile Computing and Networking (2006) 23--29</journal-ref><abstract>  Energy consumption is the most important factor that determines sensor node
lifetime. The optimization of wireless sensor network lifetime targets not only
the reduction of energy consumption of a single sensor node but also the
extension of the entire network lifetime. We propose a simple and adaptive
energy-conserving topology management scheme, called SAND (Self-Organizing
Active Node Density). SAND is fully decentralized and relies on a distributed
probing approach and on the redundancy resolution of sensors for energy
optimizations, while preserving the data forwarding and sensing capabilities of
the network. We present the SAND's algorithm, its analysis of convergence, and
simulation results. Simulation results show that, though slightly increasing
path lengths from sensor to sink nodes, the proposed scheme improves
significantly the network lifetime for different neighborhood densities
degrees, while preserving both sensing and routing fidelity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0552</identifier>
 <datestamp>2008-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0552</id><created>2008-02-05</created><authors><author><keyname>Gramoli</keyname><forenames>Vincent</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Raynal</keyname><forenames>Michel</forenames><affiliation>IRISA</affiliation></author></authors><title>Timed Quorum System for Large-Scale and Dynamic Environments</title><categories>cs.DC cs.NI</categories><proxy>ccsd inria-00238563</proxy><journal-ref>Dans 11th International Conference On Principles Of Distributed
  Systems 4878 (2007) 429--442</journal-ref><abstract>  This paper presents Timed Quorum System (TQS), a new quorum system especially
suited for large-scale and dynamic systems. TQS requires that two quorums
intersect with high probability if they are used in the same small period of
time. It proposed an algorithm that implements TQS and that verifies
probabilistic atomicity: a consistency criterion that requires each operation
to respect atomicity with high probability. This TQS implementation has quorum
of size O(\sqrt{nD}) and expected access time of O(log \sqrt{nD}) message
delays, where n measures the size of the system and D is a required parameter
to handle dynamism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0554</identifier>
 <datestamp>2008-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0554</id><created>2008-02-05</created><authors><author><keyname>Kurkoski</keyname><forenames>Brian M.</forenames></author><author><keyname>Dauwels</keyname><forenames>Justin</forenames></author></authors><title>Message-Passing Decoding of Lattices Using Gaussian Mixtures</title><categories>cs.IT math.IT</categories><comments>Cite this paper as: Brian Kurkoski and Justin Dauwels,
  &quot;Message-passing decoding of lattices using Gaussian mixtures,&quot; in
  Proceedings of the 30th Symposium on Information Theory and its Applications
  (SITA 2007), pp. 877-882, November 27-30, 2007, Shima, Mie, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lattice decoder which represents messages explicitly as a mixture of
Gaussians functions is given. In order to prevent the number of functions in a
mixture from growing as the decoder iterations progress, a method for replacing
N Gaussian functions with M Gaussian functions, with M &lt; N, is given. A squared
distance metric is used to select functions for combining. A pair of selected
Gaussians is replaced by a single Gaussian with the same first and second
moments. The metric can be computed efficiently, and at the same time, the
proposed algorithm empirically gives good results, for example, a dimension 100
lattice has a loss of 0.2 dB in signal-to-noise ratio at a probability of
symbol error of 10^{-5}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0580</identifier>
 <datestamp>2008-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0580</id><created>2008-02-05</created><authors><author><keyname>Willems</keyname><forenames>Frans M. J.</forenames></author></authors><title>Rotated and Scaled Alamouti Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Repetition-based retransmission is used in Alamouti-modulation [1998] for
$2\times 2$ MIMO systems. We propose to use instead of ordinary repetition
so-called &quot;scaled repetition&quot; together with rotation. It is shown that the
rotated and scaled Alamouti code has a hard-decision performance which is only
slightly worse than that of the Golden code [2005], the best known $2\times 2$
space-time code. Decoding the Golden code requires an exhaustive search over
all codewords, while our rotated and scaled Alamouti code can be decoded with
an acceptable complexity however.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0603</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0603</id><created>2008-02-05</created><authors><author><keyname>Bringer</keyname><forenames>Julien</forenames></author><author><keyname>Chabanne</keyname><forenames>Herve</forenames></author></authors><title>Trusted-HB: a low-cost version of HB+ secure against Man-in-The-Middle
  attacks</title><categories>cs.CR</categories><comments>submitted to IEEE Transactions on Information Theory</comments><journal-ref>IEEE Trans. IT. 54:9 (2008) 4339-4342</journal-ref><doi>10.1109/TIT.2008.928290</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the introduction at Crypto'05 by Juels and Weis of the protocol HB+, a
lightweight protocol secure against active attacks but only in a detection
based-model, many works have tried to enhance its security. We propose here a
new approach to achieve resistance against Man-in-The-Middle attacks. Our
requirements - in terms of extra communications and hardware - are surprisingly
low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0726</identifier>
 <datestamp>2008-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0726</id><created>2008-02-05</created><updated>2008-11-12</updated><authors><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author></authors><title>(Generalized) Post Correspondence Problem and semi-Thue systems</title><categories>cs.DM</categories><comments>Lecture notes. 14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let PCP(k) denote the Post Correspondence Problem for k input pairs of
strings. Let ACCESSIBILITY(k) denote the the word problem for k-rule semi-Thue
systems. In 1980, Claus showed that if ACCESSIBILITY(k) is undecidable then
PCP(k + 4) is also undecidable. The aim of the paper is to present a clean,
detailed proof of the statement.
  We proceed in two steps, using the Generalized Post Correspondence Problem as
an auxiliary. First, we prove that if ACCESSIBILITY(k) is undecidable then
GPCP(k + 2) is also undecidable. Then, we prove that if GPCP(k) is undecidable
then PCP(k + 2) is also undecidable. (The latter result has also been shown by
Harju and Karhumaki.) To date, the sharpest undecidability bounds for both PCP
and GPCP have been deduced from Claus's result: since Matiyasevich and
Senizergues showed that ACCESSIBILITY(3) is undecidable, GPCP(5) and PCP(7) are
undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0738</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0738</id><created>2008-02-05</created><updated>2009-10-08</updated><authors><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author><author><keyname>Shin</keyname><forenames>Hyundong</forenames></author></authors><title>MIMO Networks: the Effects of Interference</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Info. Theory</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 56, no. 1, pp. 336-349, Jan. 2010</journal-ref><doi>10.1109/TIT.2009.2034810</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-input/multiple-output (MIMO) systems promise enormous capacity
increase and are being considered as one of the key technologies for future
wireless networks. However, the decrease in capacity due to the presence of
interferers in MIMO networks is not well understood. In this paper, we develop
an analytical framework to characterize the capacity of MIMO communication
systems in the presence of multiple MIMO co-channel interferers and noise. We
consider the situation in which transmitters have no information about the
channel and all links undergo Rayleigh fading. We first generalize the known
determinant representation of hypergeometric functions with matrix arguments to
the case when the argument matrices have eigenvalues of arbitrary multiplicity.
This enables the derivation of the distribution of the eigenvalues of Gaussian
quadratic forms and Wishart matrices with arbitrary correlation, with
application to both single user and multiuser MIMO systems. In particular, we
derive the ergodic mutual information for MIMO systems in the presence of
multiple MIMO interferers. Our analysis is valid for any number of interferers,
each with arbitrary number of antennas having possibly unequal power levels.
This framework, therefore, accommodates the study of distributed MIMO systems
and accounts for different positions of the MIMO interferers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0745</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0745</id><created>2008-02-06</created><authors><author><keyname>Spek</keyname><forenames>Sander</forenames></author></authors><title>Knowledge management by wikis</title><categories>cs.DL</categories><comments>Position paper, not submitted elsewhere</comments><acm-class>J.0</acm-class><abstract>  Wikis provide a new way of collaboration and knowledge sharing. Wikis are
software that allows users to work collectively on a web-based knowledge base.
Wikis are characterised by a sense of anarchism, collaboration, connectivity,
organic development and self-healing, and they rely on trust. We list several
concerns about applying wikis in professional organisation. After these
concerns are met, wikis can provide a progessive, new knowledge sharing and
collaboration tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0766</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0766</id><created>2008-02-06</created><authors><author><keyname>Daneshgaran</keyname><forenames>F.</forenames></author><author><keyname>Laddomada</keyname><forenames>M.</forenames></author><author><keyname>Mesiti</keyname><forenames>F.</forenames></author><author><keyname>Mondin</keyname><forenames>M.</forenames></author></authors><title>Modelling and Analysis of the Distributed Coordination Function of IEEE
  802.11 with Multirate Capability</title><categories>cs.NI</categories><comments>Accepted at IEEE WCNC 2008, Las Vegas</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is twofold. On one hand, it presents a
multi-dimensional Markovian state transition model characterizing the behavior
at the Medium Access Control (MAC) layer by including transmission states that
account for packet transmission failures due to errors caused by propagation
through the channel, along with a state characterizing the system when there
are no packets to be transmitted in the queue of a station (to model
non-saturated traffic conditions). On the other hand, it provides a throughput
analysis of the IEEE 802.11 protocol at the data link layer in both saturated
and non-saturated traffic conditions taking into account the impact of both
transmission channel and multirate transmission in Rayleigh fading environment.
Simulation results closely match the theoretical derivations confirming the
effectiveness of the proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0776</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0776</id><created>2008-02-06</created><authors><author><keyname>del Coso</keyname><forenames>Aitor</forenames></author><author><keyname>Simoens</keyname><forenames>Sebastien</forenames></author></authors><title>Distributed Compression for the Uplink of a Backhaul-Constrained
  Coordinated Cellular Network</title><categories>cs.IT math.IT</categories><comments>30 pages, 6 figures, Submitted to IEEE Trans on signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a backhaul-constrained coordinated cellular network. That is, a
single-frequency network with $N+1$ multi-antenna base stations (BSs) that
cooperate in order to decode the users' data, and that are linked by means of a
common lossless backhaul, of limited capacity $\mathrm{R}$. To implement
receive cooperation, we propose distributed compression: $N$ BSs, upon
receiving their signals, compress them using a multi-source lossy compression
code. Then, they send the compressed vectors to a central BS, which performs
users' decoding. Distributed Wyner-Ziv coding is proposed to be used, and is
optimally designed in this work. The first part of the paper is devoted to a
network with a unique multi-antenna user, that transmits a predefined Gaussian
space-time codeword. For such a scenario, the compression codebooks at the BSs
are optimized, considering the user's achievable rate as the performance
metric. In particular, for $N = 1$ the optimum codebook distribution is derived
in closed form, while for $N&gt;1$ an iterative algorithm is devised. The second
part of the contribution focusses on the multi-user scenario. For it, the
achievable rate region is obtained by means of the optimum compression
codebooks for sum-rate and weighted sum-rate, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0797</identifier>
 <datestamp>2009-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0797</id><created>2008-02-06</created><updated>2009-04-17</updated><authors><author><keyname>Atto</keyname><forenames>Abdourrahmane</forenames><affiliation>TAMCIC</affiliation></author><author><keyname>Pastor</keyname><forenames>Dominique</forenames><affiliation>TAMCIC</affiliation></author></authors><title>Central Limit Theorems for Wavelet Packet Decompositions of Stationary
  Random Processes</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Signal Processing, October 2008</comments><proxy>ccsd hal-00241849</proxy><journal-ref>IEEE Transactions on Signal Processing (2008) 1-12</journal-ref><doi>10.1109/TSP.2009.2031726</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides central limit theorems for the wavelet packet
decomposition of stationary band-limited random processes. The asymptotic
analysis is performed for the sequences of the wavelet packet coefficients
returned at the nodes of any given path of the $M$-band wavelet packet
decomposition tree. It is shown that if the input process is centred and
strictly stationary, these sequences converge in distribution to white Gaussian
processes when the resolution level increases, provided that the decomposition
filters satisfy a suitable property of regularity. For any given path, the
variance of the limit white Gaussian process directly relates to the value of
the input process power spectral density at a specific frequency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0799</identifier>
 <datestamp>2008-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0799</id><created>2008-02-06</created><updated>2008-02-13</updated><authors><author><keyname>Val</keyname><forenames>Thierry</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Bossche</keyname><forenames>Adrien Van Den</forenames><affiliation>LATTIS</affiliation></author></authors><title>D\'eveloppement et analyse multi outils d'un protocole MAC
  d\'eterministe pour un r\'eseau de capteurs sans fil</title><categories>cs.NI</categories><proxy>ccsd hal-00239472</proxy><journal-ref>Colloque Francophone sur l'Ing\'enierie des Protocoles (CFIP), Les
  Arcs : France (2008)</journal-ref><abstract>  In this article, we present a multi-tool method for the development and the
analysis of a new medium access method. IEEE 802.15.4 / ZigBee technology has
been used as a basis for this new determinist MAC layer which enables a high
level of QoS. This WPAN can be typically used for wireless sensor networks
which require strong temporal constraints. To validate the proposed protocol,
three complementary and adequate tools are used: Petri Nets for the formal
validation of the algorithm, a dedicated simulator for the temporal aspects,
and some measures on a real prototype based on a couple of ZigBee FREESCALE
components for the hardware characterization of layers #1 and #2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0802</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0802</id><created>2008-02-06</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>On Approximating Frequency Moments of Data Streams with Skewed
  Projections</title><categories>cs.DS cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose skewed stable random projections for approximating the pth
frequency moments of dynamic data streams (0&lt;p&lt;=2), which has been frequently
studied in theoretical computer science and database communities. Our method
significantly (or even infinitely when p-&gt;1) improves previous methods based on
(symmetric) stable random projections.
  Our proposed method is applicable to data streams that are (a) insertion only
(the cash-register model); or (b) always non-negative (the strict Turnstile
model), or (c) eventually non-negative at check points. This is only a minor
restriction for practical applications.
  Our method works particularly well when p = 1+/- \Delta and \Delta is small,
which is a practically important scenario. For example, \Delta may be the decay
rate or interest rate, which are usually small. Of course, when \Delta = 0, one
can compute the 1th frequent moment (i.e., the sum) essentially error-free
using a simple couter. Our method may be viewed as a ``genearlized counter'' in
that it can count the total value in the future, taking in account of the
effect of decaying or interest accruement.
  In a summary, our contributions are two-fold. (A) This is the first propsal
of skewed stable random projections. (B) Based on first principle, we develop
various statistical estimators for skewed stable distributions, including their
variances and error (tail) probability bounds, and consequently the sample
complexity bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0808</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0808</id><created>2008-02-06</created><authors><author><keyname>Guerrero</keyname><forenames>Fabio G.</forenames></author><author><keyname>Sacanamboy</keyname><forenames>Maribell</forenames></author></authors><title>Turbo Interleaving inside the cdma2000 and W-CDMA Mobile Communication
  Systems: A Tutorial</title><categories>cs.IT math.IT</categories><abstract>  In this paper a discussion of the detailed operation of the interleavers used
by the turbo codes defined on the telecommunications standards cdma2000 (3GPP2
C.S0024-B V2.0) and W-CDMA (3GPP TS 25.212 V7.4.0) is presented. Differences in
the approach used by each turbo interleaver as well as dispersion analysis and
frequency analysis are also discussed. Two examples are presented to illustrate
the complete interleaving process defined by each standard. These two
interleaving approaches are also representative for other communications
standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0820</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0820</id><created>2008-02-06</created><updated>2008-03-19</updated><authors><author><keyname>Hayman</keyname><forenames>Jonathan</forenames></author><author><keyname>Winskel</keyname><forenames>Glynn</forenames></author></authors><title>Independence and concurrent separation logic</title><categories>cs.LO cs.PL</categories><acm-class>F.3.2; F.3.1; D.3.1; F.1.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 1 (March 19,
  2008) lmcs:1100</journal-ref><doi>10.2168/LMCS-4(1:6)2008</doi><abstract>  A compositional Petri net-based semantics is given to a simple language
allowing pointer manipulation and parallelism. The model is then applied to
give a notion of validity to the judgements made by concurrent separation logic
that emphasizes the process-environment duality inherent in such rely-guarantee
reasoning. Soundness of the rules of concurrent separation logic with respect
to this definition of validity is shown. The independence information retained
by the Petri net model is then exploited to characterize the independence of
parallel processes enforced by the logic. This is shown to permit a refinement
operation capable of changing the granularity of atomic actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0823</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0823</id><created>2008-02-06</created><authors><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Fossorier</keyname><forenames>Marc</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>Doubly-Generalized LDPC Codes: Stability Bound over the BEC</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Inform. Theory</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 55, no. 3, pp. 1027-1046, March
  2009</journal-ref><doi>10.1109/TIT.2008.2011446</doi><abstract>  The iterative decoding threshold of low-density parity-check (LDPC) codes
over the binary erasure channel (BEC) fulfills an upper bound depending only on
the variable and check nodes with minimum distance 2. This bound is a
consequence of the stability condition, and is here referred to as stability
bound. In this paper, a stability bound over the BEC is developed for
doubly-generalized LDPC codes, where the variable and the check nodes can be
generic linear block codes, assuming maximum a posteriori erasure correction at
each node. It is proved that in this generalized context as well the bound
depends only on the variable and check component codes with minimum distance 2.
A condition is also developed, namely the derivative matching condition, under
which the bound is achieved with equality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0832</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0832</id><created>2008-02-06</created><authors><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author></authors><title>Distributed Double Spending Prevention</title><categories>cs.CR</categories><comments>15th Int. Workshop on Security Protocols, 2007 (to appear)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of preventing double spending in electronic payment
schemes in a distributed fashion. This problem occurs, for instance, when the
spending of electronic coins needs to be controlled by a large collection of
nodes (eg. in a peer-to-peer (P2P) system) instead of one central bank.
Contrary to the commonly held belief that this is fundamentally impossible, we
propose several solutions that do achieve a reasonable level of double spending
prevention, and analyse their efficiency under varying assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0834</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0834</id><created>2008-02-06</created><authors><author><keyname>Hoepman</keyname><forenames>Jaap-Henk</forenames></author></authors><title>The Ephemeral Pairing Problem</title><categories>cs.CR</categories><journal-ref>In 8th Int. Conf. Financial Cryptography, LNCS 3110, pages
  212-226, Key West, FL, USA, February 9-12 2004. Springer</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless ad-hoc broadcast networks the pairing problem consists of
establishing a (long-term) connection between two specific physical nodes in
the network that do not yet know each other. We focus on the ephemeral
version of this problem. Ephemeral pairings occur, for example, when electronic
business cards are exchanged between two people that meet, or when one pays at
a check-out using a wireless wallet.
  This problem can, in more abstract terms, be phrased as an ephemeral key
exchange problem: given a low bandwidth authentic (or private) communication
channel between two nodes, and a high bandwidth broadcast channel, can we
establish a high-entropy shared secret session key between the two nodes
without relying on any a priori shared secret information.
  Apart from introducing this new problem, we present several ephemeral key
exchange protocols, both for the case of authentic channels as well as for the
case of private channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0835</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0835</id><created>2008-02-06</created><authors><author><keyname>Ferragina</keyname><forenames>Paolo</forenames></author><author><keyname>Nitto</keyname><forenames>Igor</forenames></author><author><keyname>Venturini</keyname><forenames>Rossano</forenames></author></authors><title>Bit-Optimal Lempel-Ziv compression</title><categories>cs.DS cs.IT math.IT</categories><abstract>  One of the most famous and investigated lossless data-compression scheme is
the one introduced by Lempel and Ziv about 40 years ago. This compression
scheme is known as &quot;dictionary-based compression&quot; and consists of squeezing an
input string by replacing some of its substrings with (shorter) codewords which
are actually pointers to a dictionary of phrases built as the string is
processed. Surprisingly enough, although many fundamental results are nowadays
known about upper bounds on the speed and effectiveness of this compression
process and references therein), ``we are not aware of any parsing scheme that
achieves optimality when the LZ77-dictionary is in use under any constraint on
the codewords other than being of equal length'' [N. Rajpoot and C. Sahinalp.
Handbook of Lossless Data Compression, chapter Dictionary-based data
compression. Academic Press, 2002. pag. 159]. Here optimality means to achieve
the minimum number of bits in compressing each individual input string, without
any assumption on its generating source. In this paper we provide the first
LZ-based compressor which computes the bit-optimal parsing of any input string
in efficient time and optimal space, for a general class of variable-length
codeword encodings which encompasses most of the ones typically used in data
compression and in the design of search engines and compressed indexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0861</identifier>
 <datestamp>2008-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0861</id><created>2008-02-06</created><authors><author><keyname>Gazis</keyname><forenames>Paul R.</forenames></author><author><keyname>Scargle</keyname><forenames>Jeffrey D.</forenames></author></authors><title>Using Bayesian Blocks to Partition Self-Organizing Maps</title><categories>cs.NE</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self organizing maps (SOMs) are widely-used for unsupervised classification.
For this application, they must be combined with some partitioning scheme that
can identify boundaries between distinct regions in the maps they produce. We
discuss a novel partitioning scheme for SOMs based on the Bayesian Blocks
segmentation algorithm of Scargle [1998]. This algorithm minimizes a cost
function to identify contiguous regions over which the values of the attributes
can be represented as approximately constant. Because this cost function is
well-defined and largely independent of assumptions regarding the number and
structure of clusters in the original sample space, this partitioning scheme
offers significant advantages over many conventional methods. Sample code is
available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0865</identifier>
 <datestamp>2008-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0865</id><created>2008-02-06</created><updated>2008-04-14</updated><authors><author><keyname>Gacek</keyname><forenames>Andrew</forenames></author><author><keyname>Miller</keyname><forenames>Dale</forenames></author><author><keyname>Nadathur</keyname><forenames>Gopalan</forenames></author></authors><title>Combining generic judgments with recursive definitions</title><categories>cs.LO</categories><comments>To appear in LICS 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many semantical aspects of programming languages, such as their operational
semantics and their type assignment calculi, are specified by describing
appropriate proof systems. Recent research has identified two proof-theoretic
features that allow direct, logic-based reasoning about such descriptions: the
treatment of atomic judgments as fixed points (recursive definitions) and an
encoding of binding constructs via generic judgments. However, the logics
encompassing these two features have thus far treated them orthogonally: that
is, they do not provide the ability to define object-logic properties that
themselves depend on an intrinsic treatment of binding. We propose a new and
simple integration of these features within an intuitionistic logic enhanced
with induction over natural numbers and we show that the resulting logic is
consistent. The pivotal benefit of the integration is that it allows recursive
definitions to not just encode simple, traditional forms of atomic judgments
but also to capture generic properties pertaining to such judgments. The
usefulness of this logic is illustrated by showing how it can provide elegant
treatments of object-logic contexts that appear in proofs involving typing
calculi and of arbitrarily cascading substitutions that play a role in
reducibility arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1002</identifier>
 <datestamp>2008-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1002</id><created>2008-02-07</created><authors><author><keyname>Bry</keyname><forenames>Xavier</forenames><affiliation>I3M</affiliation></author></authors><title>New Estimation Procedures for PLS Path Modelling</title><categories>cs.LG</categories><proxy>ccsd hal-00243151</proxy><abstract>  Given R groups of numerical variables X1, ... XR, we assume that each group
is the result of one underlying latent variable, and that all latent variables
are bound together through a linear equation system. Moreover, we assume that
some explanatory latent variables may interact pairwise in one or more
equations. We basically consider PLS Path Modelling's algorithm to estimate
both latent variables and the model's coefficients. New &quot;external&quot; estimation
schemes are proposed that draw latent variables towards strong group structures
in a more flexible way. New &quot;internal&quot; estimation schemes are proposed to
enable PLSPM to make good use of variable group complementarity and to deal
with interactions. Application examples are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1015</identifier>
 <datestamp>2008-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1015</id><created>2008-02-07</created><authors><author><keyname>Marciniak</keyname><forenames>Pawel</forenames><affiliation>UCLA</affiliation></author><author><keyname>Liogkas</keyname><forenames>Nikitas</forenames><affiliation>UCLA</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Kohler</keyname><forenames>Eddie</forenames><affiliation>UCLA</affiliation></author></authors><title>Small Is Not Always Beautiful</title><categories>cs.NI</categories><proxy>ccsd inria-00246564</proxy><journal-ref>Dans IPTPS'2008 (2008)</journal-ref><abstract>  Peer-to-peer content distribution systems have been enjoying great
popularity, and are now gaining momentum as a means of disseminating video
streams over the Internet. In many of these protocols, including the popular
BitTorrent, content is split into mostly fixed-size pieces, allowing a client
to download data from many peers simultaneously. This makes piece size
potentially critical for performance. However, previous research efforts have
largely overlooked this parameter, opting to focus on others instead. This
paper presents the results of real experiments with varying piece sizes on a
controlled BitTorrent testbed. We demonstrate that this parameter is indeed
critical, as it determines the degree of parallelism in the system, and we
investigate optimal piece sizes for distributing small and large content. We
also pinpoint a related design trade-off, and explain how BitTorrent's choice
of dividing pieces into subpieces attempts to address it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1026</identifier>
 <datestamp>2008-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1026</id><created>2008-02-07</created><authors><author><keyname>Sach</keyname><forenames>Benjamin</forenames></author><author><keyname>Clifford</keyname><forenames>Rapha&#xeb;l</forenames></author></authors><title>An Empirical Study of Cache-Oblivious Priority Queues and their
  Application to the Shortest Path Problem</title><categories>cs.DS cs.SE</categories><abstract>  In recent years the Cache-Oblivious model of external memory computation has
provided an attractive theoretical basis for the analysis of algorithms on
massive datasets. Much progress has been made in discovering algorithms that
are asymptotically optimal or near optimal. However, to date there are still
relatively few successful experimental studies. In this paper we compare two
different Cache-Oblivious priority queues based on the Funnel and Bucket Heap
and apply them to the single source shortest path problem on graphs with
positive edge weights. Our results show that when RAM is limited and data is
swapping to external storage, the Cache-Oblivious priority queues achieve
orders of magnitude speedups over standard internal memory techniques. However,
for the single source shortest path problem both on simulated and real world
graph data, these speedups are markedly lower due to the time required to
access the graph adjacency list itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1059</identifier>
 <datestamp>2008-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1059</id><created>2008-02-07</created><authors><author><keyname>Ajwani</keyname><forenames>Deepak</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author></authors><title>Average-Case Analysis of Online Topological Ordering</title><categories>cs.DS</categories><comments>22 pages, long version of ISAAC'07 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many applications like pointer analysis and incremental compilation require
maintaining a topological ordering of the nodes of a directed acyclic graph
(DAG) under dynamic updates. All known algorithms for this problem are either
only analyzed for worst-case insertion sequences or only evaluated
experimentally on random DAGs. We present the first average-case analysis of
online topological ordering algorithms. We prove an expected runtime of O(n^2
polylog(n)) under insertion of the edges of a complete DAG in a random order
for the algorithms of Alpern et al. (SODA, 1990), Katriel and Bodlaender (TALG,
2006), and Pearce and Kelly (JEA, 2006). This is much less than the best known
worst-case bound O(n^{2.75}) for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1076</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1076</id><created>2008-02-07</created><authors><author><keyname>Vergnaud</keyname><forenames>Damien</forenames></author></authors><title>New Extensions of Pairing-based Signatures into Universal (Multi)
  Designated Verifier Signatures</title><categories>cs.CR</categories><comments>23 pages</comments><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of universal designated verifier signatures was introduced by
Steinfeld, Bull, Wang and Pieprzyk at Asiacrypt 2003. These signatures can be
used as standard publicly verifiable digital signatures but have an additional
functionality which allows any holder of a signature to designate the signature
to any desired verifier. This designated verifier can check that the message
was indeed signed, but is unable to convince anyone else of this fact. We
propose new efficient constructions for pairing-based short signatures. Our
first scheme is based on Boneh-Boyen signatures and its security can be
analyzed in the standard security model. We prove its resistance to forgery
assuming the hardness of the so-called strong Diffie-Hellman problem, under the
knowledge-of-exponent assumption. The second scheme is compatible with the
Boneh-Lynn-Shacham signatures and is proven unforgeable, in the random oracle
model, under the assumption that the computational bilinear Diffie-Hellman
problem is untractable. Both schemes are designed for devices with constrained
computation capabilities since the signing and the designation procedure are
pairing-free. Finally, we present extensions of these schemes in the multi-user
setting proposed by Desmedt in 2003.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1113</identifier>
 <datestamp>2008-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1113</id><created>2008-02-08</created><authors><author><keyname>Libert</keyname><forenames>Beno&#xee;t</forenames></author><author><keyname>Vergnaud</keyname><forenames>Damien</forenames></author></authors><title>Multi-Use Unidirectional Proxy Re-Signatures</title><categories>cs.CR</categories><comments>16 pages</comments><acm-class>D.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1998, Blaze, Bleumer, and Strauss suggested a cryptographic primitive
named proxy re-signatures where a proxy turns a signature computed under
Alice's secret key into one from Bob on the same message. The semi-trusted
proxy does not learn either party's signing key and cannot sign arbitrary
messages on behalf of Alice or Bob. At CCS 2005, Ateniese and Hohenberger
revisited the primitive by providing appropriate security definitions and
efficient constructions in the random oracle model. Nonetheless, they left open
the problem of designing a multi-use unidirectional scheme where the proxy is
able to translate in only one direction and signatures can be re-translated
several times.
  This paper solves this problem, suggested for the first time 10 years ago,
and shows the first multi-hop unidirectional proxy re-signature schemes. We
describe a random-oracle-using system that is secure in the
Ateniese-Hohenberger model. The same technique also yields a similar
construction in the standard model (i.e. without relying on random oracles).
Both schemes are efficient and require newly defined -- but falsifiable --
Diffie-Hellman-like assumptions in bilinear groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1123</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1123</id><created>2008-02-08</created><updated>2008-02-11</updated><authors><author><keyname>Dela&#xeb;t</keyname><forenames>Sylvie</forenames><affiliation>LRI</affiliation></author><author><keyname>Devismes</keyname><forenames>St&#xe9;phane</forenames><affiliation>LRI</affiliation></author><author><keyname>Nesterenko</keyname><forenames>Mikhail</forenames><affiliation>INRIA Futurs, LIP6</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Futurs, LIP6</affiliation></author></authors><title>Snap-Stabilization in Message-Passing Systems</title><categories>cs.DC cs.NI cs.PF</categories><proxy>ccsd inria-00248465</proxy><abstract>  In this paper, we tackle the open problem of snap-stabilization in
message-passing systems. Snap-stabilization is a nice approach to design
protocols that withstand transient faults. Compared to the well-known
self-stabilizing approach, snap-stabilization guarantees that the effect of
faults is contained immediately after faults cease to occur. Our contribution
is twofold: we show that (1) snap-stabilization is impossible for a wide class
of problems if we consider networks with finite yet unbounded channel capacity;
(2) snap-stabilization becomes possible in the same setting if we assume
bounded-capacity channels. We propose three snap-stabilizing protocols working
in fully-connected networks. Our work opens exciting new research perspectives,
as it enables the snap-stabilizing paradigm to be implemented in actual
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1162</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1162</id><created>2008-02-08</created><authors><author><keyname>Cheballah</keyname><forenames>H.</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchamp</keyname><forenames>G. H. E.</forenames><affiliation>LIPN</affiliation></author><author><keyname>Penson</keyname><forenames>K. A.</forenames><affiliation>LPTMC</affiliation></author></authors><title>Approximate substitutions and the normal ordering problem</title><categories>quant-ph cs.SC math.CO</categories><proxy>ccsd hal-00249977</proxy><doi>10.1088/1742-6596/104/1/012031</doi><abstract>  In this paper, we show that the infinite generalised Stirling matrices
associated with boson strings with one annihilation operator are projective
limits of approximate substitutions, the latter being characterised by a finite
set of algebraic equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1176</identifier>
 <datestamp>2008-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1176</id><created>2008-02-08</created><updated>2008-03-14</updated><authors><author><keyname>Begin</keyname><forenames>Thomas</forenames><affiliation>LIP6</affiliation></author><author><keyname>Brandwajn</keyname><forenames>Alexandre</forenames><affiliation>UCSC</affiliation></author></authors><title>Note sur les temps de service r\'esiduels dans les syst\`emes type M/G/c</title><categories>cs.NI cs.PF</categories><proxy>ccsd hal-00250025</proxy><journal-ref>Colloque Francophone sur l'Ing\'enierie des Protocoles (CFIP), Les
  Arcs : France (2008)</journal-ref><abstract>  Approximations for the mean performance indices for the M/G/c queue rely on
the approximate computation of the probability that an arriving request has to
wait for service and of the minimum of residual service times if all servers
are found busy. Using numerical examples, we investigate properties of these
two quantities. In particular, we show that the minimum of residual service
times depends on higher order properties, beyond the first two moments, of the
service time distribution. Improved knowledge of the properties of the two
quantities studied in this paper provides insight into avenues for improving
the accuracy of approximations for the M/G/c queue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1220</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1220</id><created>2008-02-08</created><authors><author><keyname>Cheng</keyname><forenames>Qi</forenames></author><author><keyname>Wan</keyname><forenames>Daqing</forenames></author></authors><title>Complexity of Decoding Positive-Rate Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><msc-class>94B05; 11T71</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of maximal likelihood decoding of the Reed-Solomon codes
$[q-1, k]_q$ is a well known open problem. The only known result in this
direction states that it is at least as hard as the discrete logarithm in some
cases where the information rate unfortunately goes to zero. In this paper, we
remove the rate restriction and prove that the same complexity result holds for
any positive information rate. In particular, this resolves an open problem
left in [4], and rules out the possibility of a polynomial time algorithm for
maximal likelihood decoding problem of Reed-Solomon codes of any rate under a
well known cryptographical hardness assumption. As a side result, we give an
explicit construction of Hamming balls of radius bounded away from the minimum
distance, which contain exponentially many codewords for Reed-Solomon code of
any positive rate less than one. The previous constructions only apply to
Reed-Solomon codes of diminishing rates. We also give an explicit construction
of Hamming balls of relative radius less than 1 which contain subexponentially
many codewords for Reed-Solomon code of rate approaching one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1226</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1226</id><created>2008-02-08</created><updated>2008-10-22</updated><authors><author><keyname>Yan</keyname><forenames>Qiqi</forenames></author></authors><title>Lower Bounds for Complementation of omega-Automata Via the Full Automata
  Technique</title><categories>cs.LO</categories><acm-class>F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 1 (March 19,
  2008) lmcs:992</journal-ref><doi>10.2168/LMCS-4(1:5)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first introduce a lower bound technique for the state
complexity of transformations of automata. Namely we suggest first considering
the class of full automata in lower bound analysis, and later reducing the size
of the large alphabet via alphabet substitutions. Then we apply such technique
to the complementation of nondeterministic \omega-automata, and obtain several
lower bound results. Particularly, we prove an \omega((0.76n)^n) lower bound
for B\&quot;uchi complementation, which also holds for almost every complementation
or determinization transformation of nondeterministic omega-automata, and prove
an optimal (\omega(nk))^n lower bound for the complementation of generalized
B\&quot;uchi automata, which holds for Streett automata as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1237</identifier>
 <datestamp>2008-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1237</id><created>2008-02-08</created><updated>2008-09-22</updated><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author></authors><title>Minimum Entropy Orientations</title><categories>cs.DS cs.DM</categories><comments>Referees' comments incorporated</comments><journal-ref>Operations Research Letters 36 (2008), pp. 680-683</journal-ref><doi>10.1016/j.orl.2008.06.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study graph orientations that minimize the entropy of the in-degree
sequence. The problem of finding such an orientation is an interesting special
case of the minimum entropy set cover problem previously studied by Halperin
and Karp [Theoret. Comput. Sci., 2005] and by the current authors
[Algorithmica, to appear]. We prove that the minimum entropy orientation
problem is NP-hard even if the graph is planar, and that there exists a simple
linear-time algorithm that returns an approximate solution with an additive
error guarantee of 1 bit. This improves on the only previously known algorithm
which has an additive error guarantee of log_2 e bits (approx. 1.4427 bits).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1244</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1244</id><created>2008-02-10</created><authors><author><keyname>Zhou</keyname><forenames>Shuheng</forenames></author></authors><title>Learning Balanced Mixtures of Discrete Distributions with Small Sample</title><categories>cs.LG stat.ML</categories><comments>24 Pages, 5 figures</comments><abstract>  We study the problem of partitioning a small sample of $n$ individuals from a
mixture of $k$ product distributions over a Boolean cube $\{0, 1\}^K$ according
to their distributions. Each distribution is described by a vector of allele
frequencies in $\R^K$. Given two distributions, we use $\gamma$ to denote the
average $\ell_2^2$ distance in frequencies across $K$ dimensions, which
measures the statistical divergence between them. We study the case assuming
that bits are independently distributed across $K$ dimensions. This work
demonstrates that, for a balanced input instance for $k = 2$, a certain
graph-based optimization function returns the correct partition with high
probability, where a weighted graph $G$ is formed over $n$ individuals, whose
pairwise hamming distances between their corresponding bit vectors define the
edge weights, so long as $K = \Omega(\ln n/\gamma)$ and $Kn = \tilde\Omega(\ln
n/\gamma^2)$. The function computes a maximum-weight balanced cut of $G$, where
the weight of a cut is the sum of the weights across all edges in the cut. This
result demonstrates a nice property in the high-dimensional feature space: one
can trade off the number of features that are required with the size of the
sample to accomplish certain tasks like clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1258</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1258</id><created>2008-02-09</created><authors><author><keyname>Lian</keyname><forenames>Heng</forenames></author></authors><title>Bayesian Nonlinear Principal Component Analysis Using Random Fields</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel model for nonlinear dimension reduction motivated by the
probabilistic formulation of principal component analysis. Nonlinearity is
achieved by specifying different transformation matrices at different locations
of the latent space and smoothing the transformation using a Markov random
field type prior. The computation is made feasible by the recent advances in
sampling from von Mises-Fisher distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1274</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1274</id><created>2008-02-11</created><authors><author><keyname>Martin-Garcia</keyname><forenames>Jose M.</forenames></author><author><keyname>Yllanes</keyname><forenames>David</forenames></author><author><keyname>Portugal</keyname><forenames>Renato</forenames></author></authors><title>The Invar tensor package: Differential invariants of Riemann</title><categories>cs.SC gr-qc hep-th</categories><comments>12 pages, 1 figure, 3 tables. Package can be downloaded from
  http://metric.iem.csic.es/Martin-Garcia/xAct/Invar/ (Mathematica version) or
  http://www.lncc.br/~portugal/Invar.html (Maple version)</comments><journal-ref>Comp.Phys.Commun.179:586-590,2008</journal-ref><doi>10.1016/j.cpc.2008.04.018</doi><abstract>  The long standing problem of the relations among the scalar invariants of the
Riemann tensor is computationally solved for all 6x10^23 objects with up to 12
derivatives of the metric. This covers cases ranging from products of up to 6
undifferentiated Riemann tensors to cases with up to 10 covariant derivatives
of a single Riemann. We extend our computer algebra system Invar to produce
within seconds a canonical form for any of those objects in terms of a basis.
The process is as follows: (1) an invariant is converted in real time into a
canonical form with respect to the permutation symmetries of the Riemann
tensor; (2) Invar reads a database of more than 6x10^5 relations and applies
those coming from the cyclic symmetry of the Riemann tensor; (3) then applies
the relations coming from the Bianchi identity, (4) the relations coming from
commutations of covariant derivatives, (5) the dimensionally-dependent
identities for dimension 4, and finally (6) simplifies invariants that can be
expressed as product of dual invariants. Invar runs on top of the tensor
computer algebra systems xTensor (for Mathematica) and Canon (for Maple).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1296</identifier>
 <datestamp>2009-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1296</id><created>2008-02-09</created><updated>2008-05-13</updated><authors><author><keyname>Pavlovic</keyname><forenames>Dusko</forenames></author></authors><title>On quantum statistics in data analysis</title><categories>cs.IR math.CT quant-ph</categories><comments>7 pages, Quantum Interaction 2008 (Oxford, April 2008) v3: added two
  diagrams, changed some wordings</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Originally, quantum probability theory was developed to analyze statistical
phenomena in quantum systems, where classical probability theory does not
apply, because the lattice of measurable sets is not necessarily distributive.
On the other hand, it is well known that the lattices of concepts, that arise
in data analysis, are in general also non-distributive, albeit for completely
different reasons. In his recent book, van Rijsbergen argues that many of the
logical tools developed for quantum systems are also suitable for applications
in information retrieval. I explore the mathematical support for this idea on
an abstract vector space model, covering several forms of data analysis
(information retrieval, data mining, collaborative filtering, formal concept
analysis...), and roughly based on an idea from categorical quantum mechanics.
It turns out that quantum (i.e., noncommutative) probability distributions
arise already in this rudimentary mathematical framework. We show that a
Bell-type inequality must be satisfied by the standard similarity measures, if
they are used for preference predictions. The fact that already a very general,
abstract version of the vector space model yields simple counterexamples for
such inequalities seems to be an indicator of a genuine need for quantum
statistics in data analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1303</identifier>
 <datestamp>2008-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1303</id><created>2008-02-10</created><authors><author><keyname>Dziemia&#x144;czuk</keyname><forenames>M.</forenames></author><author><keyname>Bajguz</keyname><forenames>W.</forenames></author></authors><title>On GCD-morphic sequences</title><categories>math.CO cs.DM</categories><msc-class>06A07, 05A10, 11A41, 05C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note is a response to one of the problems posed by Kwa\'sniewski in
[1,2], see also [3] i.e. GCD-morphic Problem III. We show that any GCD-morphic
sequence $F$ is at the point product of primary GCD-morphic sequences and any
GCD-morphic sequence is encoded by natural number valued sequence satisfying
condition (C1). The problem of general importance - for example in number
theory was formulated in [1,2] while investigating a new class of DAG's and
their correspondent p.o. sets encoded uniquely by sequences with
combinatorially interpretable properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1306</identifier>
 <datestamp>2009-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1306</id><created>2008-02-10</created><authors><author><keyname>Pavlovic</keyname><forenames>Dusko</forenames></author></authors><title>Network as a computer: ranking paths to find flows</title><categories>cs.IR cs.AI math.CT</categories><comments>12 pages, CSR 2008</comments><acm-class>H.3.3; I.2.4; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore a simple mathematical model of network computation, based on
Markov chains. Similar models apply to a broad range of computational
phenomena, arising in networks of computers, as well as in genetic, and neural
nets, in social networks, and so on. The main problem of interaction with such
spontaneously evolving computational systems is that the data are not uniformly
structured. An interesting approach is to try to extract the semantical content
of the data from their distribution among the nodes. A concept is then
identified by finding the community of nodes that share it. The task of data
structuring is thus reduced to the task of finding the network communities, as
groups of nodes that together perform some non-local data processing. Towards
this goal, we extend the ranking methods from nodes to paths. This allows us to
extract some information about the likely flow biases from the available static
information about the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1312</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1312</id><created>2008-02-10</created><updated>2008-06-25</updated><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author></authors><title>Untangling polygons and graphs</title><categories>cs.CG cs.DM</categories><comments>11 pages, 3 figures</comments><journal-ref>Discrete and Computational Geometry 43(2): 402-411 (2010)</journal-ref><doi>10.1007/s00454-009-9150-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Untangling is a process in which some vertices of a planar graph are moved to
obtain a straight-line plane drawing. The aim is to move as few vertices as
possible. We present an algorithm that untangles the cycle graph C_n while
keeping at least \Omega(n^{2/3}) vertices fixed. For any graph G, we also
present an upper bound on the number of fixed vertices in the worst case. The
bound is a function of the number of vertices, maximum degree and diameter of
G. One of its consequences is the upper bound O((n log n)^{2/3}) for all
3-vertex-connected planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1327</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1327</id><created>2008-02-10</created><authors><author><keyname>Korada</keyname><forenames>Satish Babu</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>Exchange of Limits: Why Iterative Decoding Works</title><categories>cs.IT math.IT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider communication over binary-input memoryless output-symmetric
channels using low-density parity-check codes and message-passing decoding. The
asymptotic (in the length) performance of such a combination for a fixed number
of iterations is given by density evolution. Letting the number of iterations
tend to infinity we get the density evolution threshold, the largest channel
parameter so that the bit error probability tends to zero as a function of the
iterations.
  In practice we often work with short codes and perform a large number of
iterations. It is therefore interesting to consider what happens if in the
standard analysis we exchange the order in which the blocklength and the number
of iterations diverge to infinity. In particular, we can ask whether both
limits give the same threshold.
  Although empirical observations strongly suggest that the exchange of limits
is valid for all channel parameters, we limit our discussion to channel
parameters below the density evolution threshold. Specifically, we show that
under some suitable technical conditions the bit error probability vanishes
below the density evolution threshold regardless of how the limit is taken.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1332</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1332</id><created>2008-02-10</created><updated>2008-04-11</updated><authors><author><keyname>Bucci</keyname><forenames>Michelangelo</forenames></author><author><keyname>De Luca</keyname><forenames>Alessandro</forenames></author><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames></author></authors><title>A connection between palindromic and factor complexity using return
  words</title><categories>math.CO cs.DM</categories><comments>17 pages; minor adjustment to the main theorem and other minor
  changes (particularly in Sections 3 and 4); accepted by &quot;Advances in Applied
  Mathematics&quot;</comments><msc-class>68R15</msc-class><journal-ref>Advances In Applied Mathematics 42 (2009) 60--74</journal-ref><doi>10.1016/j.aam.2008.03.005</doi><abstract>  In this paper we prove that for any infinite word W whose set of factors is
closed under reversal, the following conditions are equivalent:
  (I) all complete returns to palindromes are palindromes;
  (II) P(n) + P(n+1) = C(n+1) - C(n) + 2 for all n, where P (resp. C) denotes
the palindromic complexity (resp. factor complexity) function of W, which
counts the number of distinct palindromic factors (resp. factors) of each
length in W.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1338</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1338</id><created>2008-02-10</created><authors><author><keyname>Gutner</keyname><forenames>Shai</forenames></author><author><keyname>Tarsi</keyname><forenames>Michael</forenames></author></authors><title>Some results on (a:b)-choosability</title><categories>cs.DM cs.CC cs.DS</categories><abstract>  A solution to a problem of Erd\H{o}s, Rubin and Taylor is obtained by showing
that if a graph $G$ is $(a:b)$-choosable, and $c/d &gt; a/b$, then $G$ is not
necessarily $(c:d)$-choosable. Applying probabilistic methods, an upper bound
for the $k^{th}$ choice number of a graph is given. We also prove that a
directed graph with maximum outdegree $d$ and no odd directed cycle is
$(k(d+1):k)$-choosable for every $k \geq 1$. Other results presented in this
article are related to the strong choice number of graphs (a generalization of
the strong chromatic number). We conclude with complexity analysis of some
decision problems related to graph choosability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1348</identifier>
 <datestamp>2008-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1348</id><created>2008-02-11</created><updated>2008-06-04</updated><authors><author><keyname>Khilko</keyname><forenames>Andrey</forenames></author></authors><title>Fourier-Based Spectral Analysis with Adaptive Resolution</title><categories>physics.data-an cs.NA math.GM</categories><comments>31 pages including 10 figures. Fixed problem with computational
  complexity, so section 10 is rewritten and 3 more figures are added. Also, a
  way of optimal computation is suggested. Corrected a couple of typos in
  formulas. Several language and style corrections. Two additional references
  are added</comments><abstract>  Despite being the most popular methods of data analysis, Fourier-based
techniques suffer from the problem of static resolution that is currently
believed to be a fundamental limitation of the Fourier Transform. Although
alternative solutions overcome this limitation, none provide the simplicity,
versatility, and convenience of the Fourier analysis. The lack of convenience
often prevents these alternatives from replacing classical spectral methods -
even in applications that suffer from the limitation of static resolution.
  This work demonstrates that, contrary to the generally accepted belief, the
Fourier Transform can be generalized to the case of adaptive resolution. The
generalized transform provides backward compatibility with classical spectral
techniques and introduces minimal computational overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1361</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1361</id><created>2008-02-10</created><updated>2010-04-20</updated><authors><author><keyname>Karavelas</keyname><forenames>Menelaos I.</forenames></author></authors><title>Guarding curvilinear art galleries with edge or mobile guards via
  2-dominance of triangulation graphs</title><categories>cs.CG</categories><comments>45 pages, 33 figures, short version has appeared in [M. I. Karavelas.
  Guarding curvilinear art galleries with edge or mobile guards. 2008 ACM
  Symposium on Solid and Physical Modeling (SPM08), 339-345, 2008.]; v2: new
  lower bound for the edge 2-dominance problem which now matches the upper
  bound</comments><acm-class>F.2.2; I.3.5</acm-class><journal-ref>Comput. Geom. Theory Appl. 44(1):20-51, 2011</journal-ref><doi>10.1016/j.comgeo.2010.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of monitoring an art gallery modeled as a polygon,
the edges of which are arcs of curves, with edge or mobile guards. Our focus is
on piecewise-convex polygons, i.e., polygons that are locally convex, except
possibly at the vertices, and their edges are convex arcs. We transform the
problem of monitoring a piecewise-convex polygon to the problem of 2-dominating
a properly defined triangulation graph with edges or diagonals, where
2-dominance requires that every triangle in the triangulation graph has at
least two of its vertices in its 2-dominating set. We show that
$\lfloor\frac{n+1}{3}\rfloor$ diagonal guards or $\lfloor\frac{2n+1}{5}\rfloor$
edge guards are always sufficient and sometimes necessary, in order to
2-dominate a triangulation graph. Furthermore, we show how to compute: a
diagonal 2-dominating set of size $\lfloor\frac{n+1}{3}\rfloor$ in linear time,
an edge 2-dominating set of size $\lfloor\frac{2n+1}{5}\rfloor$ in $O(n^2)$
time, and an edge 2-dominating set of size $\lfloor\frac{3n}{7}\rfloor$ in O(n)
time. Based on the above-mentioned results, we prove that, for piecewise-convex
polygons, we can compute: a mobile guard set of size
$\lfloor\frac{n+1}{3}\rfloor$ in $O(n\log{}n)$ time, an edge guard set of size
$\lfloor\frac{2n+1}{5}\rfloor$ in $O(n^2)$ time, and an edge guard set of size
$\lfloor\frac{3n}{7}\rfloor$ in $O(n\log{}n)$ time. Finally, we show that
$\lfloor\frac{n}{3}\rfloor$ mobile or $\lceil\frac{n}{3}\rceil$ edge guards are
sometimes necessary. When restricting our attention to monotone
piecewise-convex polygons, the bounds mentioned above drop:
$\lceil\frac{n+1}{4}\rceil$ edge or mobile guards are always sufficient and
sometimes necessary; such an edge or mobile guard set, of size at most
$\lceil\frac{n+1}{4}\rceil$, can be computed in O(n) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1362</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1362</id><created>2008-02-10</created><authors><author><keyname>Chen</keyname><forenames>Yiling</forenames></author><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Lambert</keyname><forenames>Nicolas</forenames></author><author><keyname>Pennock</keyname><forenames>David M.</forenames></author><author><keyname>Wortman</keyname><forenames>Jennifer</forenames></author></authors><title>Complexity of Combinatorial Market Makers</title><categories>cs.GT</categories><acm-class>J.4</acm-class><abstract>  We analyze the computational complexity of market maker pricing algorithms
for combinatorial prediction markets. We focus on Hanson's popular logarithmic
market scoring rule market maker (LMSR). Our goal is to implicitly maintain
correct LMSR prices across an exponentially large outcome space. We examine
both permutation combinatorics, where outcomes are permutations of objects, and
Boolean combinatorics, where outcomes are combinations of binary events. We
look at three restrictive languages that limit what traders can bet on. Even
with severely limited languages, we find that LMSR pricing is $\SP$-hard, even
when the same language admits polynomial-time matching without the market
maker. We then propose an approximation technique for pricing permutation
markets based on a recent algorithm for online permutation learning. The
connections we draw between LMSR pricing and the vast literature on online
learning with expert advice may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1369</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1369</id><created>2008-02-10</created><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Interior-Point Algorithms for Linear-Programming Decoding</title><categories>cs.IT math.IT</categories><comments>Essentially the paper that appeared in Proc. 2008 Information Theory
  and Applications Workshop, UC San Diego, CA, USA, January 27 -- February 1,
  2008</comments><abstract>  Interior-point algorithms constitute a very interesting class of algorithms
for solving linear-programming problems. In this paper we study efficient
implementations of such algorithms for solving the linear program that appears
in the linear-programming decoder formulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1372</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1372</id><created>2008-02-10</created><updated>2008-02-20</updated><authors><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>An integral formula for large random rectangular matrices and its
  application to analysis of linear vector channels</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>Submitted to PHYSCOMNET08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A statistical mechanical framework for analyzing random linear vector
channels is presented in a large system limit. The framework is based on the
assumptions that the left and right singular value bases of the rectangular
channel matrix $\bH$ are generated independently from uniform distributions
over Haar measures and the eigenvalues of $\bH^{\rm T}\bH$ asymptotically
follow a certain specific distribution. These assumptions make it possible to
characterize the communication performance of the channel utilizing an integral
formula with respect to $\bH$, which is analogous to the one introduced by
Marinari {\em et. al.} in {\em J. Phys. A} {\bf 27}, 7647 (1994) for large
random square (symmetric) matrices. A computationally feasible algorithm for
approximately decoding received signals based on the integral formula is also
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1379</identifier>
 <datestamp>2008-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1379</id><created>2008-02-11</created><updated>2008-11-12</updated><authors><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author></authors><title>Structure and Optimality of Myopic Policy in Opportunistic Access with
  Noisy Observations</title><categories>cs.NI</categories><comments>Submitted to IEEE Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A restless multi-armed bandit problem that arises in multichannel
opportunistic communications is considered, where channels are modeled as
independent and identical Gilbert-Elliot channels and channel state
observations are subject to errors. A simple structure of the myopic policy is
established under a certain condition on the false alarm probability of the
channel state detector. It is shown that the myopic policy has a semi-universal
structure that reduces channel selection to a simple round-robin procedure and
obviates the need to know the underlying Markov transition probabilities. The
optimality of the myopic policy is proved for the case of two channels and
conjectured for the general case based on numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1380</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1380</id><created>2008-02-11</created><authors><author><keyname>Permuter</keyname><forenames>Haim H.</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author><author><keyname>Chen</keyname><forenames>Jun</forenames></author></authors><title>New Bounds for the Capacity Region of the Finite-State Multiple Access
  Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity region of the Finite-State Multiple Access Channel (FS-MAC) with
feedback that may be an arbitrary time-invariant function of the channel output
samples is considered. We provided a sequence of inner and outer bounds for
this region. These bounds are shown to coincide, and hence yield the capacity
region, of FS-MACs where the state process is stationary and ergodic and not
affected by the inputs, and for indecomposable FS-MAC when feedback is not
allowed.
  Though the capacity region is `multi-letter' in general, our results yield
explicit conclusions when applied to specific scenarios of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1381</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1381</id><created>2008-02-11</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>Comments on combinatorial interpretation of fibonomial coefficients - an
  email style letter</title><categories>math.CO cs.DM math-ph math.MP</categories><comments>2 pages</comments><msc-class>05C20, 11C08</msc-class><journal-ref>Bulletin of the ICA vol. 42 September (2004) 10-11</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Up to our knowledge -since about 126 years we were lacking of classical type
combinatorial interpretation of Fibonomial coefficients as it was Lukas
\cite{1} - to our knowledge -who was the first who had defined Finonomial
coefficients and derived a recurrence for them (see Historical Note in
\cite{2,3}). Here we inform that a join combinatorial interpretation was found
\cite{4} for all binomial-type coefficient - Fibonomial coefficients included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1382</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1382</id><created>2008-02-11</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>New type Stirling like numbers - an email style letter</title><categories>math.CO cs.DM</categories><comments>3 pages</comments><msc-class>05C20, 11C08, 17B56</msc-class><journal-ref>Bulletin of the ICA Vol. 49 (2007), pp. 99-102</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of the Fibonacci cobweb poset from [1] has been naturally extended
to any admissible sequence $F$ in [2] where it was also recognized that the
celebrated prefab notion of Bender and Goldman [3] - (see also [4,5]) - admits
such an extension so as to encompass the new type combinatorial objects from
[2] as leading examples. Recently the present author had introduced also [6]
two natural partial orders in there: one $\leq$ in grading-natural subsets of
cobweb`s prefabs sets [2] and in the second proposal one endows the set sums of
the so called &quot;prefabiants&quot; with such another partial order that one arrives at
Bell-like numbers including Fibonacci triad sequences introduced by the present
author in [7]. Here we quote the basic observations concerning the new type
Stirling like numbers as they appear in [6]. For more on notation, Stirling
like numbers of the first kind and for proofs - see [6].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1383</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1383</id><created>2008-02-11</created><authors><author><keyname>Permuter</keyname><forenames>Haim H.</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>On Directed Information and Gambling</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of gambling in horse races with causal side information
and show that Massey's directed information characterizes the increment in the
maximum achievable capital growth rate due to the availability of side
information. This result gives a natural interpretation of directed information
$I(Y^n \to X^n)$ as the amount of information that $Y^n$ \emph{causally}
provides about $X^n$. Extensions to stock market portfolio strategies and data
compression with causal side information are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1387</identifier>
 <datestamp>2008-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1387</id><created>2008-02-11</created><updated>2008-02-25</updated><authors><author><keyname>Mitton</keyname><forenames>Nathalie</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Paroux</keyname><forenames>Katy</forenames><affiliation>LM-Besan&#xe7;on</affiliation></author><author><keyname>Sericola</keyname><forenames>Bruno</forenames><affiliation>IRISA</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>Ascending runs in dependent uniformly distributed random variables:
  Application to wireless networks</title><categories>cs.DM cs.NI math.CO math.PR</categories><proxy>ccsd inria-00239348</proxy><abstract>  We analyze in this paper the longest increasing contiguous sequence or
maximal ascending run of random variables with common uniform distribution but
not independent. Their dependence is characterized by the fact that two
successive random variables cannot take the same value. Using a Markov chain
approach, we study the distribution of the maximal ascending run and we develop
an algorithm to compute it. This problem comes from the analysis of several
self-organizing protocols designed for large-scale wireless sensor networks,
and we show how our results apply to this domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1389</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1389</id><created>2008-02-11</created><authors><author><keyname>Janson</keyname><forenames>Svante</forenames></author><author><keyname>Lavault</keyname><forenames>Christian</forenames></author><author><keyname>Louchard</keyname><forenames>Guy</forenames></author></authors><title>Convergence of some leader election algorithms</title><categories>cs.DC math.PR</categories><comments>27 pages, 13 figures, 5 tables</comments><abstract>  We start with a set of n players. With some probability P(n,k), we kill n-k
players; the other ones stay alive, and we repeat with them. What is the
distribution of the number X_n of phases (or rounds) before getting only one
player? We present a probabilistic analysis of this algorithm under some
conditions on the probability distributions P(n,k), including stochastic
monotonicity and the assumption that roughly a fixed proportion alpha of the
players survive in each round.
  We prove a kind of convergence in distribution for X_n-log_a n, where the
basis a=1/alpha; as in many other similar problems there are oscillations and
no true limit distribution, but suitable subsequences converge, and there is an
absolutely continuous random variable Z such that the distribution of X_n can
be approximated by Z+log_a n rounded to the nearest larger integer.
  Applications of the general result include the leader election algorithm
where players are eliminated by independent coin tosses and a variation of the
leader election algorithm proposed by W.R. Franklin. We study the latter
algorithm further, including numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1393</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1393</id><created>2008-02-11</created><authors><author><keyname>Jonquet</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Cerri</keyname><forenames>Stefano A.</forenames><affiliation>LIRMM</affiliation></author></authors><title>Les Agents comme des interpr\'eteurs Scheme : Sp\'ecification dynamique
  par la communication</title><categories>cs.MA cs.AI</categories><proxy>ccsd hal-00250149</proxy><journal-ref>Dans 14\`eme Congr\`es Francophone AFRIF-AFIA de Reconnaissance
  des Formes et Intelligence Artificielle - RFIA'04, Toulouse : France (2004)</journal-ref><abstract>  We proposed in previous papers an extension and an implementation of the
STROBE model, which regards the Agents as Scheme interpreters. These Agents are
able to interpret messages in a dedicated environment including an interpreter
that learns from the current conversation therefore representing evolving
meta-level Agent's knowledge. When the Agent's interpreter is a
nondeterministic one, the dialogues may consist of subsequent refinements of
specifications in the form of constraint sets. The paper presents a worked out
example of dynamic service generation - such as necessary on Grids - by
exploiting STROBE Agents equipped with a nondeterministic interpreter. It shows
how enabling dynamic specification of a problem. Then it illustrates how these
principles could be effective for other applications. Details of the
implementation are not provided here, but are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1412</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1412</id><created>2008-02-11</created><authors><author><keyname>Pal</keyname><forenames>Mahesh</forenames></author></authors><title>Extreme Learning Machine for land cover classification</title><categories>cs.NE cs.CV</categories><comments>6 pages, mapindia 2008 conference</comments><doi>10.1080/01431160902788636</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the potential of extreme learning machine based
supervised classification algorithm for land cover classification. In
comparison to a backpropagation neural network, which requires setting of
several user-defined parameters and may produce local minima, extreme learning
machine require setting of one parameter and produce a unique solution. ETM+
multispectral data set (England) was used to judge the suitability of extreme
learning machine for remote sensing classifications. A back propagation neural
network was used to compare its performance in term of classification accuracy
and computational cost. Results suggest that the extreme learning machine
perform equally well to back propagation neural network in term of
classification accuracy with this data set. The computational cost using
extreme learning machine is very small in comparison to back propagation neural
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1427</identifier>
 <datestamp>2008-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1427</id><created>2008-02-11</created><authors><author><keyname>Efremenko</keyname><forenames>Klim</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author></authors><title>Approximating General Metric Distances Between a Pattern and a Text</title><categories>cs.DS</categories><comments>This is updated version of paper appered in SODA 2008</comments><journal-ref>SODA 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $T=t_0 ... t_{n-1}$ be a text and $P = p_0 ... p_{m-1}$ a pattern taken
from some finite alphabet set $\Sigma$, and let $\dist$ be a metric on
$\Sigma$. We consider the problem of calculating the sum of distances between
the symbols of $P$ and the symbols of substrings of $T$ of length $m$ for all
possible offsets. We present an $\epsilon$-approximation algorithm for this
problem which runs in time $O(\frac{1}{\epsilon^2}n\cdot
\mathrm{polylog}(n,\abs{\Sigma}))$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1430</identifier>
 <datestamp>2008-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1430</id><created>2008-02-11</created><updated>2008-12-19</updated><authors><author><keyname>Abernethy</keyname><forenames>Jacob</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Evgeniou</keyname><forenames>Theodoros</forenames><affiliation>CB</affiliation></author><author><keyname>Vert</keyname><forenames>Jean-Philippe</forenames><affiliation>CB</affiliation></author></authors><title>A New Approach to Collaborative Filtering: Operator Estimation with
  Spectral Regularization</title><categories>cs.LG</categories><proxy>ccsd hal-00250231</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general approach for collaborative filtering (CF) using spectral
regularization to learn linear operators from &quot;users&quot; to the &quot;objects&quot; they
rate. Recent low-rank type matrix completion approaches to CF are shown to be
special cases. However, unlike existing regularization based CF methods, our
approach can be used to also incorporate information such as attributes of the
users or the objects -- a limitation of existing regularization based CF
methods. We then provide novel representer theorems that we use to develop new
estimation methods. We provide learning algorithms based on low-rank
decompositions, and test them on a standard CF dataset. The experiments
indicate the advantages of generalizing the existing regularization based CF
methods to incorporate related information about users and objects. Finally, we
show that certain multi-task learning methods can be also seen as special cases
of our proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1465</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1465</id><created>2008-02-11</created><updated>2008-02-22</updated><authors><author><keyname>Allauzen</keyname><forenames>Cyril</forenames></author><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author></authors><title>3-Way Composition of Weighted Finite-State Transducers</title><categories>cs.CC</categories><comments>Added missing acknowledgments</comments><abstract>  Composition of weighted transducers is a fundamental algorithm used in many
applications, including for computing complex edit-distances between automata,
or string kernels in machine learning, or to combine different components of a
speech recognition, speech synthesis, or information extraction system. We
present a generalization of the composition of weighted transducers, 3-way
composition, which is dramatically faster in practice than the standard
composition algorithm when combining more than two transducers. The worst-case
complexity of our algorithm for composing three transducers $T_1$, $T_2$, and
$T_3$ resulting in $T$, \ignore{depending on the strategy used, is $O(|T|_Q
d(T_1) d(T_3) + |T|_E)$ or $(|T|_Q d(T_2) + |T|_E)$,} is $O(|T|_Q \min(d(T_1)
d(T_3), d(T_2)) + |T|_E)$, where $|\cdot|_Q$ denotes the number of states,
$|\cdot|_E$ the number of transitions, and $d(\cdot)$ the maximum out-degree.
As in regular composition, the use of perfect hashing requires a pre-processing
step with linear-time expected complexity in the size of the input transducers.
In many cases, this approach significantly improves on the complexity of
standard composition. Our algorithm also leads to a dramatically faster
composition in practice. Furthermore, standard composition can be obtained as a
special case of our algorithm. We report the results of several experiments
demonstrating this improvement. These theoretical and empirical improvements
significantly enhance performance in the applications already mentioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1471</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1471</id><created>2008-02-11</created><updated>2008-12-01</updated><authors><author><keyname>de Wolf</keyname><forenames>Ronald</forenames><affiliation>CWI Amsterdam</affiliation></author></authors><title>Error-Correcting Data Structures</title><categories>cs.DS</categories><comments>15 pages LaTeX; an abridged version will appear in the Proceedings of
  the STACS 2009 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study data structures in the presence of adversarial noise. We want to
encode a given object in a succinct data structure that enables us to
efficiently answer specific queries about the object, even if the data
structure has been corrupted by a constant fraction of errors. This new model
is the common generalization of (static) data structures and locally decodable
error-correcting codes. The main issue is the tradeoff between the space used
by the data structure and the time (number of probes) needed to answer a query
about the encoded object. We prove a number of upper and lower bounds on
various natural error-correcting data structure problems. In particular, we
show that the optimal length of error-correcting data structures for the
Membership problem (where we want to store subsets of size s from a universe of
size n) is closely related to the optimal length of locally decodable codes for
s-bit strings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1514</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1514</id><created>2008-02-11</created><updated>2008-02-15</updated><authors><author><keyname>Kobylkin</keyname><forenames>K. S.</forenames></author></authors><title>Minimal Committee Problem for Inconsistent Systems of Linear
  Inequalities on the Plane</title><categories>cs.DM cs.CG</categories><comments>29 pages, 2 figures</comments><doi>10.1134/S1054661806040201</doi><abstract>  A representation of an arbitrary system of strict linear inequalities in R^n
as a system of points is proposed. The representation is obtained by using a
so-called polarity. Based on this representation an algorithm for constructing
a committee solution of an inconsistent plane system of linear inequalities is
given. A solution of two problems on minimal committee of a plane system is
proposed. The obtained solutions to these problems can be found by means of the
proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1555</identifier>
 <datestamp>2008-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1555</id><created>2008-02-11</created><updated>2008-08-27</updated><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Honold</keyname><forenames>Thomas</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>Constructing Linear Codes with Good Joint Spectra</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure, to appear in Proc. ChinaCom 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of finding good linear codes for joint source-channel coding
(JSCC) is investigated in this paper. By the code-spectrum approach, it has
been proved in the authors' previous paper that a good linear code for the
authors' JSCC scheme is a code with a good joint spectrum, so the main task in
this paper is to construct linear codes with good joint spectra. First, the
code-spectrum approach is developed further to facilitate the calculation of
spectra. Second, some general principles for constructing good linear codes are
presented. Finally, we propose an explicit construction of linear codes with
good joint spectra based on low density parity check (LDPC) codes and low
density generator matrix (LDGM) codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1567</identifier>
 <datestamp>2008-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1567</id><created>2008-02-12</created><authors><author><keyname>Kuzuoka</keyname><forenames>Shigeaki</forenames></author><author><keyname>Kimura</keyname><forenames>Akisato</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author></authors><title>Universal Coding for Lossless and Lossy Complementary Delivery Problems</title><categories>cs.IT math.IT</categories><comments>20 pages, one column, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with a coding problem called complementary delivery, where
messages from two correlated sources are jointly encoded and each decoder
reproduces one of two messages using the other message as the side information.
Both lossless and lossy universal complementary delivery coding schemes are
investigated. In the lossless case, it is demonstrated that a universal
complementary delivery code can be constructed by only combining two
Slepian-Wolf codes. Especially, it is shown that a universal lossless
complementary delivery code, for which error probability is exponentially
tight, can be constructed from two linear Slepian-Wolf codes. In the lossy
case, a universal complementary delivery coding scheme based on Wyner-Ziv codes
is proposed. While the proposed scheme cannot attain the optimal
rate-distortion trade-off in general, the rate-loss is upper bounded by a
universal constant under some mild conditions. The proposed schemes allows us
to apply any Slepian-Wolf and Wyner-Ziv codes to complementary delivery coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1578</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1578</id><created>2008-02-12</created><updated>2009-07-28</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Thread extraction for polyadic instruction sequences</title><categories>cs.PL</categories><comments>21 pages; error corrected; presentation improved</comments><report-no>PRG0803</report-no><acm-class>D.3.1; D.3.3; F.1.1; F.3.2; F.3.3</acm-class><journal-ref>Scientific Annals of Computer Science, 21(2):283--310, 2011.
  http://www.infoiasi.ro/bin/download/Annals/XXI2/XXI2_4.pdf</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the phenomenon that instruction sequences are split
into fragments which somehow produce a joint behaviour. In order to bring this
phenomenon better into the picture, we formalize a simple mechanism by which
several instruction sequence fragments can produce a joint behaviour. We also
show that, even in the case of this simple mechanism, it is a non-trivial
matter to explain by means of a translation into a single instruction sequence
what takes place on execution of a collection of instruction sequence
fragments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1586</identifier>
 <datestamp>2008-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1586</id><created>2008-02-12</created><authors><author><keyname>Aredo</keyname><forenames>Demissies</forenames></author><author><keyname>Burgess</keyname><forenames>Mark</forenames></author><author><keyname>Hagen</keyname><forenames>Simen</forenames></author></authors><title>Program Promises</title><categories>cs.SE</categories><abstract>  The framework of promise theory offers an alternative way of understanding
programming models, especially in distributed systems. We show that promise
theory can express some familiar constructs and resolve some problems in
program interface design, using fewer and simpler concepts than the Unified
Modelling Language (UML).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1604</identifier>
 <datestamp>2008-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1604</id><created>2008-02-12</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Schoenebeck</keyname><forenames>Grant</forenames></author><author><keyname>Valiant</keyname><forenames>Gregory</forenames></author><author><keyname>Valiant</keyname><forenames>Paul</forenames></author></authors><title>On the Complexity of Nash Equilibria of Action-Graph Games</title><categories>cs.GT cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing Nash Equilibria of action-graph games
(AGGs). AGGs, introduced by Bhat and Leyton-Brown, is a succinct representation
of games that encapsulates both &quot;local&quot; dependencies as in graphical games, and
partial indifference to other agents' identities as in anonymous games, which
occur in many natural settings. This is achieved by specifying a graph on the
set of actions, so that the payoff of an agent for selecting a strategy depends
only on the number of agents playing each of the neighboring strategies in the
action graph. We present a Polynomial Time Approximation Scheme for computing
mixed Nash equilibria of AGGs with constant treewidth and a constant number of
agent types (and an arbitrary number of strategies), together with hardness
results for the cases when either the treewidth or the number of agent types is
unconstrained. In particular, we show that even if the action graph is a tree,
but the number of agent-types is unconstrained, it is NP-complete to decide the
existence of a pure-strategy Nash equilibrium and PPAD-complete to compute a
mixed Nash equilibrium (even an approximate one); similarly for symmetric AGGs
(all agents belong to a single type), if we allow arbitrary treewidth. These
hardness results suggest that, in some sense, our PTAS is as strong of a
positive result as one can expect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1617</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1617</id><created>2008-02-12</created><authors><author><keyname>Mercat</keyname><forenames>Christian</forenames><affiliation>I3M</affiliation></author></authors><title>Discrete Complex Structure on Surfel Surfaces</title><categories>cs.CG cs.GR math.CV</categories><proxy>ccsd hal-00250975</proxy><journal-ref>Dans 14th IAPR International Conference on Discrete Geometry for
  Computer Imagery - 14th IAPR International Conference on Discrete Geometry
  for Computer Imagery, Lyon : France (2008)</journal-ref><abstract>  This paper defines a theory of conformal parametrization of digital surfaces
made of surfels equipped with a normal vector. The main idea is to locally
project each surfel to the tangent plane, therefore deforming its aspect-ratio.
It is a generalization of the theory known for polyhedral surfaces. The main
difference is that the conformal ratios that appear are no longer real in
general. It yields a generalization of the standard Laplacian on weighted
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1661</identifier>
 <datestamp>2008-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1661</id><created>2008-02-12</created><authors><author><keyname>Grigoriev</keyname><forenames>Dima</forenames><affiliation>IRMAR</affiliation></author><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author></authors><title>Zero-knowledge authentication schemes from actions on graphs, groups, or
  rings</title><categories>cs.CR</categories><proxy>ccsd hal-00252139</proxy><report-no>08-09</report-no><msc-class>94A62, 68P25</msc-class><abstract>  We propose a general way of constructing zero-knowledge authentication
schemes from actions of a semigroup on a set, without exploiting any specific
algebraic properties of the set acted upon. Then we give several concrete
realizations of this general idea, and in particular, we describe several
zero-knowledge authentication schemes where forgery (a.k.a. impersonation) is
NP-hard. Computationally hard problems that can be employed in these
realizations include (Sub)graph Isomorphism, Graph Colorability, Diophantine
Problem, and many others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1685</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1685</id><created>2008-02-12</created><updated>2008-02-16</updated><authors><author><keyname>Bienkowski</keyname><forenames>Marcin</forenames></author><author><keyname>Chrobak</keyname><forenames>Marek</forenames></author><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Hurand</keyname><forenames>Mathilde</forenames></author><author><keyname>Jez</keyname><forenames>Artur</forenames></author><author><keyname>Jez</keyname><forenames>Lukasz</forenames></author><author><keyname>Lopuszanski</keyname><forenames>Jakub</forenames></author><author><keyname>Stachowiak</keyname><forenames>Grzegorz</forenames></author></authors><title>Generalized Whac-a-Mole</title><categories>cs.DS</categories><abstract>  We consider online competitive algorithms for the problem of collecting
weighted items from a dynamic set S, when items are added to or deleted from S
over time. The objective is to maximize the total weight of collected items. We
study the general version, as well as variants with various restrictions,
including the following: the uniform case, when all items have the same
weight, the decremental sets, when all items are present at the beginning and
only deletion operations are allowed, and dynamic queues, where the dynamic
set is ordered and only its prefixes can be deleted (with no restriction on
insertions). The dynamic queue case is a generalization of bounded-delay packet
scheduling (also referred to as buffer management). We present several upper
and lower bounds on the competitive ratio for these variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1690</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1690</id><created>2008-02-12</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. Krzysztof</forenames></author></authors><title>More on the Bernoulli and Taylor Formula for Extended Umbral Calculus</title><categories>math.CO cs.DM</categories><comments>11 pages</comments><msc-class>05A40, 81S05, 01A45, 01A50, 01A61</msc-class><journal-ref>Advances in Applied Clifford Algebras Volume 16, Number 1,(2006)
  29-39</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One delivers here the extended Bernoulli and Taylor formula of a new sort
with the rest term of the Cauchy type recently derived by the author in the
case of the so called $\psi$-difference calculus which constitutes the
representative for the purpose case of extended umbral calculus. The central
importance of such a type formulas is beyond any doubt. Recent publications do
confirm this historically established experience. Its links via umbrality to
combinatorics are known at least since Rota and Mullin source papers then up to
recently extended by many authors to be indicated in the sequel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1696</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1696</id><created>2008-02-12</created><authors><author><keyname>Kwa&#x15b;niewski</keyname><forenames>A. Krzysztof</forenames></author></authors><title>First Observations on Prefab Posets Whitney Numbers</title><categories>math.CO cs.DM</categories><comments>14 pages</comments><msc-class>05C20 - 11C08 - 06A07</msc-class><journal-ref>Advances in Applied Clifford Algebras Volume 18, Number 1 /
  February, 2008, 57-73</journal-ref><doi>10.1007/s00006-007-0054-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a natural partial order in structurally natural finite subsets
of the cobweb prefabs sets recently constructed by the present author. Whitney
numbers of the second kind of the corresponding subposet which constitute
Stirling like numbers triangular array are then calculated and the explicit
formula for them is provided. Next, in the second construction we endow the set
sums of prefabiants with such an another partial order that their Bell like
numbers include Fibonacci triad sequences introduced recently by the present
author in order to extend famous relation between binomial Newton coefficients
and Fibonacci numbers onto the infinity of their relatives among whom there are
also the Fibonacci triad sequences and binomial like coefficients (incidence
coefficients included). The first partial order is F sequence independent while
the second partial order is F sequence dependent where F is the so called
admissible sequence determining cobweb poset by construction. An F determined
cobweb posets Hasse diagram becomes Fibonacci tree sheathed with specific
cobweb if the sequence F is chosen to be just the Fibonacci sequence. From the
stand-point of linear algebra of formal series these are generating functions
which stay for the so called extended coherent states of quantum physics. This
information is delivered in the last section.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1699</identifier>
 <datestamp>2008-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1699</id><created>2008-02-12</created><authors><author><keyname>Limaye</keyname><forenames>Nutan</forenames></author><author><keyname>Mahajan</keyname><forenames>Meena</forenames></author><author><keyname>Nimbhorkar</keyname><forenames>Prajakta</forenames></author></authors><title>Longest paths in Planar DAGs in Unambiguous Logspace</title><categories>cs.CC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We show via two different algorithms that finding the length of the longest
path in planar directed acyclic graph (DAG) is in unambiguous logspace UL, and
also in the complement class co-UL. The result extends to toroidal DAGs as
well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1722</identifier>
 <datestamp>2008-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1722</id><created>2008-02-12</created><authors><author><keyname>Amini</keyname><forenames>Omid</forenames></author><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Parameterized Algorithms for Partial Cover Problems</title><categories>cs.DS</categories><comments>20 page, 1 Figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Covering problems are fundamental classical problems in optimization,
computer science and complexity theory. Typically an input to these problems is
a family of sets over a finite universe and the goal is to cover the elements
of the universe with as few sets of the family as possible.
  The variations of covering problems include well known problems like Set
Cover, Vertex Cover, Dominating Set and Facility Location to name a few.
Recently there has been a lot of study on partial covering problems, a natural
generalization of covering problems. Here, the goal is not to cover all the
elements but to cover the specified number of elements with the minimum number
of sets.
  In this paper we study partial covering problems in graphs in the realm of
parameterized complexity. Classical (non-partial) version of all these problems
have been intensively studied in planar graphs and in graphs excluding a fixed
graph $H$ as a minor. However, the techniques developed for parameterized
version of non-partial covering problems cannot be applied directly to their
partial counterparts. The approach we use, to show that various partial
covering problems are fixed parameter tractable on planar graphs, graphs of
bounded local treewidth and graph excluding some graph as a minor, is quite
different from previously known techniques. The main idea behind our approach
is the concept of implicit branching. We find implicit branching technique to
be interesting on its own and believe that it can be used for some other
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1738</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1738</id><created>2008-02-12</created><updated>2008-02-18</updated><authors><author><keyname>Huertas-Rosero</keyname><forenames>&#xc1;lvaro Francisco</forenames></author><author><keyname>Azzopardi</keyname><forenames>Leif</forenames></author><author><keyname>van Rijsbergen</keyname><forenames>C. J.</forenames></author></authors><title>Characterising through Erasing: A Theoretical Framework for Representing
  Documents Inspired by Quantum Theory</title><categories>cs.IR quant-ph</categories><comments>4 pages, 3 figures, Quantum Interaction Symposium 2008</comments><acm-class>H.3.1</acm-class><journal-ref>Proceedings of Quantum Interaction Symposium 2008</journal-ref><abstract>  The problem of representing text documents within an Information Retrieval
system is formulated as an analogy to the problem of representing the quantum
states of a physical system. Lexical measurements of text are proposed as a way
of representing documents which are akin to physical measurements on quantum
states. Consequently, the representation of the text is only known after
measurements have been made, and because the process of measuring may destroy
parts of the text, the document is characterised through erasure. The
mathematical foundations of such a quantum representation of text are provided
in this position paper as a starting point for indexing and retrieval within a
``quantum like'' Information Retrieval system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1754</identifier>
 <datestamp>2008-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1754</id><created>2008-02-12</created><authors><author><keyname>Sundararajan</keyname><forenames>Jay Kumar</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>ARQ for Network Coding</title><categories>cs.IT cs.NI math.IT</categories><comments>Submitted to the 2008 IEEE International Symposium on Information
  Theory (ISIT 2008)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new coding and queue management algorithm is proposed for communication
networks that employ linear network coding. The algorithm has the feature that
the encoding process is truly online, as opposed to a block-by-block approach.
The setup assumes a packet erasure broadcast channel with stochastic arrivals
and full feedback, but the proposed scheme is potentially applicable to more
general lossy networks with link-by-link feedback. The algorithm guarantees
that the physical queue size at the sender tracks the backlog in degrees of
freedom (also called the virtual queue size). The new notion of a node &quot;seeing&quot;
a packet is introduced. In terms of this idea, our algorithm may be viewed as a
natural extension of ARQ schemes to coded networks. Our approach, known as the
drop-when-seen algorithm, is compared with a baseline queuing approach called
drop-when-decoded. It is shown that the expected queue size for our approach is
$O(\frac1{1-\rho})$ as opposed to $\Omega(\frac1{(1-\rho)^2})$ for the baseline
approach, where $\rho$ is the load factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1785</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1785</id><created>2008-02-13</created><authors><author><keyname>Okawado</keyname><forenames>Atsushi</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author></authors><title>Near ML detection using Dijkstra's algorithm with bounded list size over
  MIMO channels</title><categories>cs.IT math.IT</categories><comments>8 pages, two column, 14 figures, LaTeX2e</comments><journal-ref>Proceedings of 2008 IEEE International Symposium on Information
  Theory, pp. 2022-2025, 2008</journal-ref><doi>10.1109/ISIT.2008.4595344</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose Dijkstra's algorithm with bounded list size after QR decomposition
for decreasing the computational complexity of near maximum-likelihood (ML)
detection of signals over multiple-input-multiple-output (MIMO) channels. After
that, we compare the performances of proposed algorithm, QR decomposition
M-algorithm (QRD-MLD), and its improvement. When the list size is set to
achieve the almost same symbol error rate (SER) as the QRD-MLD, the proposed
algorithm has smaller average computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1790</identifier>
 <datestamp>2008-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1790</id><created>2008-02-13</created><authors><author><keyname>Di Zenzo</keyname><forenames>Silvano</forenames></author></authors><title>SAT Has No Wizards</title><categories>cs.CC</categories><comments>19 pages</comments><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An (encoded) decision problem is a pair (E, F) where E=words that encode
instances of the problem, F=words to be accepted. We use &quot;strings&quot; in a
technical sense. With an NP problem (E, F) we associate the &quot;logogram&quot; of F
relative to E, which conveys structural information on E, F, and how F is
embedded in E. The kernel Ker(P) of a program P that solves (E, F) consists of
those strings in the logogram that are used by P. There are relations between
Ker(P) and the complexity of P. We develop an application to SAT that relies
upon a property of internal independence of SAT. We show that SAT cannot have
in its logogram strings serving as collective certificates. As consequence, all
programs that solve SAT have same kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1815</identifier>
 <datestamp>2008-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1815</id><created>2008-02-13</created><authors><author><keyname>Ding</keyname><forenames>Yang</forenames></author></authors><title>A Construction for Constant-Composition Codes</title><categories>cs.IT math.IT</categories><comments>4 pages, submitted to IEEE Infromation Theory</comments><abstract>  By employing the residue polynomials, a construction of constant-composition
codes is given. This construction generalizes the one proposed by Xing[16]. It
turns out that when d=3 this construction gives a lower bound of
constant-composition codes improving the one in [10]. Moreover, for d&gt;3, we
give a lower bound on maximal size of constant-composition codes. In
particular, our bound for d=5 gives the best possible size of
constant-composition codes up to magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1829</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1829</id><created>2008-02-13</created><authors><author><keyname>Altarelli</keyname><forenames>Fabrizio</forenames></author><author><keyname>Monasson</keyname><forenames>Remi</forenames></author><author><keyname>Semerjian</keyname><forenames>Guilhem</forenames></author><author><keyname>Zamponi</keyname><forenames>Francesco</forenames></author></authors><title>A review of the Statistical Mechanics approach to Random Optimization
  Problems</title><categories>cs.CC</categories><comments>26 pages, 8 figures. Contribution to the book &quot;Handbook of
  Satisfiability&quot; to be published in 2008 by IOS press</comments><journal-ref>In &quot;Handbook of Satisfiability&quot;, published by IOS press (2009),
  Volume 185 of the Series &quot;Frontiers in Artificial Intelligence and
  Applications&quot;</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the connection between statistical mechanics and the analysis of
random optimization problems, with particular emphasis on the random k-SAT
problem. We discuss and characterize the different phase transitions that are
met in these problems, starting from basic concepts. We also discuss how
statistical mechanics methods can be used to investigate the behavior of local
search and decimation based algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1884</identifier>
 <datestamp>2008-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1884</id><created>2008-02-13</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Schnoor</keyname><forenames>Henning</forenames></author></authors><title>On the Complexity of Elementary Modal Logics</title><categories>cs.CC cs.LO</categories><comments>Full version of STACS 2008 paper</comments><abstract>  Modal logics are widely used in computer science. The complexity of modal
satisfiability problems has been investigated since the 1970s, usually proving
results on a case-by-case basis. We prove a very general classification for a
wide class of relevant logics: Many important subclasses of modal logics can be
obtained by restricting the allowed models with first-order Horn formulas. We
show that the satisfiability problem for each of these logics is either
NP-complete or PSPACE-hard, and exhibit a simple classification criterion.
Further, we prove matching PSPACE upper bounds for many of the PSPACE-hard
logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1888</identifier>
 <datestamp>2008-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1888</id><created>2008-02-13</created><authors><author><keyname>Sreeram</keyname><forenames>K.</forenames></author><author><keyname>Birenjith</keyname><forenames>S.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Multi-hop Cooperative Wireless Networks: Diversity Multiplexing Tradeoff
  and Optimal Code Design</title><categories>cs.IT math.IT</categories><abstract>  We consider single-source single-sink (ss-ss) multi-hop networks, with
slow-fading links and single-antenna half-duplex relays. We identify two
families of networks that are multi-hop generalizations of the well-studied
two-hop network: K-Parallel-Path (KPP) networks and layered networks. KPP
networks can be viewed as the union of K node-disjoint parallel relaying paths,
each of length greater than one. KPP networks are then generalized to KPP(I)
networks, which permit interference between paths and to KPP(D) networks, which
possess a direct link from source to sink. We characterize the DMT of these
families of networks completely for K &gt; 3. Layered networks are networks
comprising of relaying layers with edges existing only within the same layer or
between adjacent layers. We prove that a linear DMT between the maximum
diversity d_{max} and the maximum multiplexing gain of 1 is achievable for
fully-connected layered networks. This is shown to be equal to the optimal DMT
if the number of layers is less than 4. For multi-antenna KPP and layered
networks, we provide an achievable DMT region.
  For arbitrary ss-ss single-antenna directed-acyclic full-duplex networks, we
prove that a linear tradeoff between maximum diversity and maximum multiplexing
gain is achievable. All protocols in this paper are explicit and use only
amplify and forward (AF) relaying. We also construct codes with short
block-lengths based on cyclic division algebras that achieve the optimal DMT
for all the proposed schemes. Two key implications of the results in the paper
are that the half-duplex constraint does not entail any rate loss for a large
class of networks and that simple AF protocols are often sufficient to attain
the optimal DMT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1893</identifier>
 <datestamp>2008-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1893</id><created>2008-02-13</created><authors><author><keyname>Sreeram</keyname><forenames>K.</forenames></author><author><keyname>Birenjith</keyname><forenames>S.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Diversity and Degrees of Freedom of Cooperative Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to International Symposium on Information Theory (ISIT),
  2008</comments><abstract>  Wireless fading networks with multiple antennas are typically studied
information-theoretically from two different perspectives - the outage
characterization and the ergodic capacity characterization. A key parameter in
the outage characterization of a network is the diversity, whereas a
first-order indicator for the ergodic capacity is the degrees of freedom (DOF),
which is the pre-log coefficient in the capacity expression. In this paper, we
present max-flow min-cut type theorems for computing both the diversity and the
degrees of freedom of arbitrary single-source single-sink multi-antenna
networks. We also show that an amplify-and-forward protocol is sufficient to
achieve this. The degrees of freedom characterization is obtained using a
conversion to a deterministic wireless network for which the capacity was
recently found. We show that the diversity result easily extends to
multi-source multi-sink networks and evaluate the DOF for multi-casting in
single-source multi-sink networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1957</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1957</id><created>2008-02-13</created><updated>2008-07-21</updated><authors><author><keyname>Singh</keyname><forenames>Sudhir Kumar</forenames></author><author><keyname>Roychowdhury</keyname><forenames>Vwani P.</forenames></author></authors><title>To Broad-Match or Not to Broad-Match : An Auctioneer's Dilemma ?</title><categories>cs.GT cs.CC cs.DS</categories><comments>33 pages, 10 figures, new results added, substantially revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of an interesting aspect of sponsored search
advertising, namely the consequences of broad match-a feature where an ad of an
advertiser can be mapped to a broader range of relevant queries, and not
necessarily to the particular keyword(s) that ad is associated with. Starting
with a very natural setting for strategies available to the advertisers, and
via a careful look through the algorithmic lens, we first propose solution
concepts for the game originating from the strategic behavior of advertisers as
they try to optimize their budget allocation across various keywords. Next, we
consider two broad match scenarios based on factors such as information
asymmetry between advertisers and the auctioneer, and the extent of
auctioneer's control on the budget splitting. In the first scenario, the
advertisers have the full information about broad match and relevant
parameters, and can reapportion their own budgets to utilize the extra
information; in particular, the auctioneer has no direct control over budget
splitting. We show that, the same broad match may lead to different equilibria,
one leading to a revenue improvement, whereas another to a revenue loss. This
leaves the auctioneer in a dilemma - whether to broad-match or not. This
motivates us to consider another broad match scenario, where the advertisers
have information only about the current scenario, and the allocation of the
budgets unspent in the current scenario is in the control of the auctioneer. We
observe that the auctioneer can always improve his revenue by judiciously using
broad match. Thus, information seems to be a double-edged sword for the
auctioneer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2001</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2001</id><created>2008-02-14</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Dowsland</keyname><forenames>Kathryn</forenames></author></authors><title>Exploiting problem structure in a genetic algorithm approach to a nurse
  rostering problem</title><categories>cs.NE cs.CE</categories><journal-ref>Journal of Scheduling, 3(3), pp 139-153, 2000</journal-ref><doi>10.1002/(SICI)1099-1425(200005/06)3:3&lt;139::AID-JOS41&gt;3.0.CO;2-2</doi><abstract>  There is considerable interest in the use of genetic algorithms to solve
problems arising in the areas of scheduling and timetabling. However, the
classical genetic algorithm paradigm is not well equipped to handle the
conflict between objectives and constraints that typically occurs in such
problems. In order to overcome this, successful implementations frequently make
use of problem specific knowledge. This paper is concerned with the development
of a GA for a nurse rostering problem at a major UK hospital. The structure of
the constraints is used as the basis for a co-evolutionary strategy using
co-operating sub-populations. Problem specific knowledge is also used to define
a system of incentives and disincentives, and a complementary mutation
operator. Empirical results based on 52 weeks of live data show how these
features are able to improve an unsuccessful canonical GA to the point where it
is able to provide a practical solution to the problem
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2013</identifier>
 <datestamp>2009-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2013</id><created>2008-02-14</created><updated>2009-09-15</updated><authors><author><keyname>Ozgur</keyname><forenames>Ayfer</forenames></author><author><keyname>Leveque</keyname><forenames>Olivier</forenames></author></authors><title>Throughput-Delay Trade-off for Hierarchical Cooperation in Ad Hoc
  Wireless Networks</title><categories>cs.IT math.IT</categories><comments>9 pages, 6 figures, to appear in IEEE Transactions on Information
  Theory, submitted Dec 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hierarchical cooperation has recently been shown to achieve better throughput
scaling than classical multihop schemes under certain assumptions on the
channel model in static wireless networks. However, the end-to-end delay of
this scheme turns out to be significantly larger than those of multihop
schemes. A modification of the scheme is proposed here that achieves a
throughput-delay trade-off $D(n)=(\log n)^2 T(n)$ for T(n) between
$\Theta(\sqrt{n}/\log n)$ and $\Theta(n/\log n)$, where D(n) and T(n) are
respectively the average delay per bit and the aggregate throughput in a
network of n nodes. This trade-off complements the previous results of El Gamal
et al., which show that the throughput-delay trade-off for multihop schemes is
given by D(n)=T(n) where T(n) lies between $\Theta(1)$ and $\Theta(\sqrt{n})$.
  Meanwhile, the present paper considers the network multiple-access problem,
which may be of interest in its own right.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2015</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2015</id><created>2008-02-14</created><updated>2008-02-15</updated><authors><author><keyname>Koolen</keyname><forenames>Wouter</forenames></author><author><keyname>de Rooij</keyname><forenames>Steven</forenames></author></authors><title>Combining Expert Advice Efficiently</title><categories>cs.LG cs.DS cs.IT math.IT</categories><comments>50 pages</comments><acm-class>G.3</acm-class><abstract>  We show how models for prediction with expert advice can be defined concisely
and clearly using hidden Markov models (HMMs); standard HMM algorithms can then
be used to efficiently calculate, among other things, how the expert
predictions should be weighted according to the model. We cast many existing
models as HMMs and recover the best known running times in each case. We also
describe two new models: the switch distribution, which was recently developed
to improve Bayesian/Minimum Description Length model selection, and a new
generalisation of the fixed share algorithm based on run-length coding. We give
loss bounds for all models and shed new light on their relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2027</identifier>
 <datestamp>2008-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2027</id><created>2008-02-14</created><updated>2008-03-28</updated><authors><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author><author><keyname>Koolen</keyname><forenames>Wouter M.</forenames></author></authors><title>Kolmogorov Complexity Theory over the Reals</title><categories>cs.CC cs.SC</categories><acm-class>F.4.1; F.1.1; E.4; I.1.2; I.1.3</acm-class><abstract>  Kolmogorov Complexity constitutes an integral part of computability theory,
information theory, and computational complexity theory -- in the discrete
setting of bits and Turing machines. Over real numbers, on the other hand, the
BSS-machine (aka real-RAM) has been established as a major model of
computation. This real realm has turned out to exhibit natural counterparts to
many notions and results in classical complexity and recursion theory; although
usually with considerably different proofs. The present work investigates
similarities and differences between discrete and real Kolmogorov Complexity as
introduced by Montana and Pardo (1998).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2045</identifier>
 <datestamp>2008-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2045</id><created>2008-02-14</created><authors><author><keyname>Settepanella</keyname><forenames>Simona</forenames></author></authors><title>Blocking Sets in the complement of hyperplane arrangements in projective
  space</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well know that the theory of minimal blocking sets is studied by
several author. Another theory which is also studied by a large number of
researchers is the theory of hyperplane arrangements. We can remark that the
affine space $AG(n,q)$ is the complement of the line at infinity in $PG(n,q)$.
Then $AG(n,q)$ can be regarded as the complement of an hyperplane arrangement
in $PG(n,q)$! Therefore the study of blocking sets in the affine space
$AG(n,q)$ is simply the study of blocking sets in the complement of a finite
arrangement in $PG(n,q)$. In this paper the author generalizes this remark
starting to study the problem of existence of blocking sets in the complement
of a given hyperplane arrangement in $PG(n,q)$. As an example she solves the
problem for the case of braid arrangement. Moreover she poses significant
questions on this new and interesting problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2108</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2108</id><created>2008-02-14</created><updated>2009-08-18</updated><authors><author><keyname>VanderZee</keyname><forenames>Evan</forenames></author><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Guoy</keyname><forenames>Damrong</forenames></author><author><keyname>Ramos</keyname><forenames>Edgar</forenames></author></authors><title>Well-Centered Triangulation</title><categories>cs.CG cs.NA</categories><comments>Content has been added to experimental results section. Significant
  edits in introduction and in summary of current and previous results. Minor
  edits elsewhere</comments><report-no>UIUCDCS-R-2008-2936</report-no><acm-class>I.3.5</acm-class><journal-ref>SIAM J. Sci. Comput. 31, 6 (2010) 4497-4523</journal-ref><doi>10.1137/090748214</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meshes composed of well-centered simplices have nice orthogonal dual meshes
(the dual Voronoi diagram). This is useful for certain numerical algorithms
that prefer such primal-dual mesh pairs. We prove that well-centered meshes
also have optimality properties and relationships to Delaunay and minmax angle
triangulations. We present an iterative algorithm that seeks to transform a
given triangulation in two or three dimensions into a well-centered one by
minimizing a cost function and moving the interior vertices while keeping the
mesh connectivity and boundary vertices fixed. The cost function is a direct
result of a new characterization of well-centeredness in arbitrary dimensions
that we present. Ours is the first optimization-based heuristic for
well-centeredness, and the first one that applies in both two and three
dimensions. We show the results of applying our algorithm to small and large
two-dimensional meshes, some with a complex boundary, and obtain a
well-centered tetrahedralization of the cube. We also show numerical evidence
that our algorithm preserves gradation and that it improves the maximum and
minimum angles of acute triangulations created by the best known previous
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2112</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2112</id><created>2008-02-14</created><authors><author><keyname>Das</keyname><forenames>Manik Lal</forenames></author></authors><title>On the Security of ``an efficient and complete remote user
  authentication scheme''</title><categories>cs.CR</categories><abstract>  Recently, Liaw et al. proposed a remote user authentication scheme using
smart cards. Their scheme has claimed a number of features e.g. mutual
authentication, no clock synchronization, no verifier table, flexible user
password change, etc. We show that Liaw et al.'s scheme is completely insecure.
By intercepting a valid login message in Liaw et al.'s scheme, any unregistered
user or adversary can easily login to the remote system and establish a session
key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2125</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2125</id><created>2008-02-14</created><authors><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Multiple Access Outerbounds and the Inseparability of Parallel
  Interference Channels</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, Vol. 55, No. 9, Sep.
  2009,Pages: 3983-3990</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that the capacity of parallel (multi-carrier) Gaussian
point-to-point, multiple access and broadcast channels can be achieved by
separate encoding for each subchannel (carrier) subject to a power allocation
across carriers. In this paper we show that such a separation does not apply to
parallel Gaussian interference channels in general. A counter-example is
provided in the form of a 3 user interference channel where separate encoding
can only achieve a sum capacity of $\log({SNR})+o(\log({SNR}))$ per carrier
while the actual capacity, achieved only by joint-encoding across carriers, is
$3/2\log({SNR}))+o(\log({SNR}))$ per carrier. As a byproduct of our analysis,
we propose a class of multiple-access-outerbounds on the capacity of the 3 user
interference channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2127</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2127</id><created>2008-02-14</created><authors><author><keyname>Riazanov</keyname><forenames>Alexandre</forenames></author></authors><title>New Implementation Framework for Saturation-Based Reasoning</title><categories>cs.AI cs.LO</categories><comments>17 pages</comments><abstract>  The saturation-based reasoning methods are among the most theoretically
developed ones and are used by most of the state-of-the-art first-order logic
reasoners. In the last decade there was a sharp increase in performance of such
systems, which I attribute to the use of advanced calculi and the intensified
research in implementation techniques. However, nowadays we are witnessing a
slowdown in performance progress, which may be considered as a sign that the
saturation-based technology is reaching its inherent limits. The position I am
trying to put forward in this paper is that such scepticism is premature and a
sharp improvement in performance may potentially be reached by adopting new
architectural principles for saturation. The top-level algorithms and
corresponding designs used in the state-of-the-art saturation-based theorem
provers have (at least) two inherent drawbacks: the insufficient flexibility of
the used inference selection mechanisms and the lack of means for intelligent
prioritising of search directions. In this position paper I analyse these
drawbacks and present two ideas on how they could be overcome. In particular, I
propose a flexible low-cost high-precision mechanism for inference selection,
intended to overcome problems associated with the currently used instances of
clause selection-based procedures. I also outline a method for intelligent
prioritising of search directions, based on probing the search space by
exploring generalised search directions. I discuss some technical issues
related to implementation of the proposed architectural principles and outline
possible solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2130</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2130</id><created>2008-02-14</created><authors><author><keyname>Aazami</keyname><forenames>Ashkan</forenames></author></authors><title>Domination in graphs with bounded propagation: algorithms, formulations
  and hardness results</title><categories>cs.DS cs.CC</categories><comments>24 pages</comments><abstract>  We introduce a hierarchy of problems between the \textsc{Dominating Set}
problem and the \textsc{Power Dominating Set} (PDS) problem called the
$\ell$-round power dominating set ($\ell$-round PDS, for short) problem. For
$\ell=1$, this is the \textsc{Dominating Set} problem, and for $\ell\geq n-1$,
this is the PDS problem; here $n$ denotes the number of nodes in the input
graph. In PDS the goal is to find a minimum size set of nodes $S$ that power
dominates all the nodes, where a node $v$ is power dominated if (1) $v$ is in
$S$ or it has a neighbor in $S$, or (2) $v$ has a neighbor $u$ such that $u$
and all of its neighbors except $v$ are power dominated. Note that rule (1) is
the same as for the \textsc{Dominating Set} problem, and that rule (2) is a
type of propagation rule that applies iteratively. The $\ell$-round PDS problem
has the same set of rules as PDS, except we apply rule (2) in ``parallel'' in
at most $\ell-1$ rounds. We prove that $\ell$-round PDS cannot be approximated
better than $2^{\log^{1-\epsilon}{n}}$ even for $\ell=4$ in general graphs. We
provide a dynamic programming algorithm to solve $\ell$-round PDS optimally in
polynomial time on graphs of bounded tree-width. We present a PTAS (polynomial
time approximation scheme) for $\ell$-round PDS on planar graphs for
$\ell=O(\tfrac{\log{n}}{\log{\log{n}}})$. Finally, we give integer programming
formulations for $\ell$-round PDS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2134</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2134</id><created>2008-02-14</created><updated>2011-10-09</updated><authors><author><keyname>Buchin</keyname><forenames>Kevin</forenames></author></authors><title>Minimizing the Maximum Interference is Hard</title><categories>cs.NI cs.CG</categories><comments>4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following interference model for wireless sensor and ad hoc
networks: the receiver interference of a node is the number of transmission
ranges it lies in. We model transmission ranges as disks. For this case we show
that choosing transmission radii which minimize the maximum interference while
maintaining a connected symmetric communication graph is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2138</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2138</id><created>2008-02-14</created><authors><author><keyname>Pal</keyname><forenames>Mahesh</forenames></author><author><keyname>Mather</keyname><forenames>Paul M.</forenames></author></authors><title>Support Vector classifiers for Land Cover Classification</title><categories>cs.NE cs.CV</categories><comments>11 pages, 1 figure, Published in MapIndia Conference 2003</comments><doi>10.1080/01431160802007624</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Support vector machines represent a promising development in machine learning
research that is not widely used within the remote sensing community. This
paper reports the results of Multispectral(Landsat-7 ETM+) and Hyperspectral
DAIS)data in which multi-class SVMs are compared with maximum likelihood and
artificial neural network methods in terms of classification accuracy. Our
results show that the SVM achieves a higher level of classification accuracy
than either the maximum likelihood or the neural classifier, and that the
support vector machine can be used with small training datasets and
high-dimensional data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2157</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2157</id><created>2008-02-15</created><authors><author><keyname>Gutner</keyname><forenames>Shai</forenames></author></authors><title>Choice numbers of graphs</title><categories>cs.DM cs.CC cs.DS</categories><abstract>  A solution to a problem of Erd\H{o}s, Rubin and Taylor is obtained by showing
that if a graph $G$ is $(a:b)$-choosable, and $c/d &gt; a/b$, then $G$ is not
necessarily $(c:d)$-choosable. The simplest case of another problem, stated by
the same authors, is settled, proving that every 2-choosable graph is also
$(4:2)$-choosable. Applying probabilistic methods, an upper bound for the
$k^{th}$ choice number of a graph is given. We also prove that a directed graph
with maximum outdegree $d$ and no odd directed cycle is $(k(d+1):k)$-choosable
for every $k \geq 1$. Other results presented in this article are related to
the strong choice number of graphs (a generalization of the strong chromatic
number). We conclude with complexity analysis of some decision problems related
to graph choosability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2158</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2158</id><created>2008-02-15</created><authors><author><keyname>Franco</keyname><forenames>Jessica</forenames><affiliation>LMA-PAU</affiliation></author><author><keyname>Carraro</keyname><forenames>Laurent</forenames><affiliation>LMA-PAU</affiliation></author><author><keyname>Roustant</keyname><forenames>Olivier</forenames><affiliation>LMA-PAU</affiliation></author><author><keyname>Jourdan</keyname><forenames>Astrid</forenames><affiliation>LMA-PAU</affiliation></author></authors><title>A Radar-Shaped Statistic for Testing and Visualizing Uniformity
  Properties in Computer Experiments</title><categories>cs.LG math.ST stat.TH</categories><proxy>ccsd hal-00256176</proxy><abstract>  In the study of computer codes, filling space as uniformly as possible is
important to describe the complexity of the investigated phenomenon. However,
this property is not conserved by reducing the dimension. Some numeric
experiment designs are conceived in this sense as Latin hypercubes or
orthogonal arrays, but they consider only the projections onto the axes or the
coordinate planes. In this article we introduce a statistic which allows
studying the good distribution of points according to all 1-dimensional
projections. By angularly scanning the domain, we obtain a radar type
representation, allowing the uniformity defects of a design to be identified
with respect to its projections onto straight lines. The advantages of this new
tool are demonstrated on usual examples of space-filling designs (SFD) and a
global statistic independent of the angle of rotation is studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2159</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2159</id><created>2008-02-15</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Hj\orungnes</keyname><forenames>Are</forenames></author></authors><title>A Distributed Merge and Split Algorithm for Fair Cooperation in Wireless
  Networks</title><categories>cs.IT cs.GT math.IT</categories><comments>This paper is accepted for publication at the IEEE ICC Workshop on
  Cooperative Communications and Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel concept from coalitional game theory which
allows the dynamic formation of coalitions among wireless nodes. A simple and
distributed merge and split algorithm for coalition formation is constructed.
This algorithm is applied to study the gains resulting from the cooperation
among single antenna transmitters for virtual MIMO formation. The aim is to
find an ultimate transmitters coalition structure that allows cooperating users
to maximize their utilities while accounting for the cost of coalition
formation. Through this novel game theoretical framework, the wireless network
transmitters are able to self-organize and form a structured network composed
of disjoint stable coalitions. Simulation results show that the proposed
algorithm can improve the average individual user utility by 26.4% as well as
cope with the mobility of the distributed users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2175</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2175</id><created>2008-02-15</created><authors><author><keyname>Bras-Amoros</keyname><forenames>Maria</forenames></author></authors><title>Bounds on the Number of Numerical Semigroups of a Given Genus</title><categories>math.CO cs.DM</categories><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combinatorics on multisets is used to deduce new upper and lower bounds on
the number of numerical semigroups of each given genus, significantly improving
existing ones. In particular, it is proved that the number $n_g$ of numerical
semigroups of genus $g$ satisfies $2F_{g}\leq n_g\leq 1+3\cdot 2^{g-3}$, where
$F_g$ denotes the $g$th Fibonacci number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2184</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2184</id><created>2008-02-15</created><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Dumeunier</keyname><forenames>Christophe</forenames></author></authors><title>Set Covering Problems with General Objective Functions</title><categories>cs.DS</categories><comments>14 pages, 1 figure</comments><acm-class>F.2.2</acm-class><abstract>  We introduce a parameterized version of set cover that generalizes several
previously studied problems. Given a ground set V and a collection of subsets
S_i of V, a feasible solution is a partition of V such that each subset of the
partition is included in one of the S_i. The problem involves maximizing the
mean subset size of the partition, where the mean is the generalized mean of
parameter p, taken over the elements. For p=-1, the problem is equivalent to
the classical minimum set cover problem. For p=0, it is equivalent to the
minimum entropy set cover problem, introduced by Halperin and Karp. For p=1,
the problem includes the maximum-edge clique partition problem as a special
case. We prove that the greedy algorithm simultaneously approximates the
problem within a factor of (p+1)^1/p for any p in R^+, and that this is the
best possible unless P=NP. These results both generalize and simplify previous
results for special cases. We also consider the corresponding graph coloring
problem, and prove several tractability and inapproximability results. Finally,
we consider a further generalization of the set cover problem in which we aim
at minimizing the sum of some concave function of the part sizes. As an
application, we derive an approximation ratio for a Rent-or-Buy set cover
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2201</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2201</id><created>2008-02-15</created><updated>2008-03-13</updated><authors><author><keyname>Baptista</keyname><forenames>M. S.</forenames></author><author><keyname>Bohn</keyname><forenames>C.</forenames></author><author><keyname>Kliegl</keyname><forenames>R.</forenames></author><author><keyname>Engbert</keyname><forenames>R.</forenames></author><author><keyname>Kurths</keyname><forenames>J.</forenames></author></authors><title>Reconstruction of eye movements during blinks</title><categories>cs.SC</categories><journal-ref>Chaos (2008)</journal-ref><doi>10.1063/1.2890843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In eye movement research in reading, the amount of data plays a crucial role
for the validation of results. A methodological problem for the analysis of the
eye movement in reading are blinks, when readers close their eyes. Blinking
rate increases with increasing reading time, resulting in high data losses,
especially for older adults or reading impaired subjects. We present a method,
based on the symbolic sequence dynamics of the eye movements, that reconstructs
the horizontal position of the eyes while the reader blinks. The method makes
use of an observed fact that the movements of the eyes before closing or after
opening contain information about the eyes movements during blinks. Test
results indicate that our reconstruction method is superior to methods that use
simpler interpolation approaches. In addition, analyses of the reconstructed
data show no significant deviation from the usual behavior observed in readers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2228</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2228</id><created>2008-02-15</created><authors><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author><author><keyname>Ordyniak</keyname><forenames>Sebastian</forenames></author></authors><title>Digraph Decompositions and Monotonicity in Digraph Searching</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider monotonicity problems for graph searching games. Variants of
these games - defined by the type of moves allowed for the players - have been
found to be closely connected to graph decompositions and associated width
measures such as path- or tree-width. Of particular interest is the question
whether these games are monotone, i.e. whether the cops can catch a robber
without ever allowing the robber to reach positions that have been cleared
before. The monotonicity problem for graph searching games has intensely been
studied in the literature, but for two types of games the problem was left
unresolved. These are the games on digraphs where the robber is invisible and
lazy or visible and fast. In this paper, we solve the problems by giving
examples showing that both types of games are non-monotone. Graph searching
games on digraphs are closely related to recent proposals for digraph
decompositions generalising tree-width to directed graphs. These proposals have
partly been motivated by attempts to develop a structure theory for digraphs
similar to the graph minor theory developed by Robertson and Seymour for
undirected graphs, and partly by the immense number of algorithmic results
using tree-width of undirected graphs and the hope that part of this success
might be reproducible on digraphs using a directed tree-width. Unfortunately
the number of applications for the digraphs measures introduced so far is still
small. We therefore explore the limits of the algorithmic applicability of
digraph decompositions. In particular, we show that various natural candidates
for problems that might benefit from digraphs having small directed tree-width
remain NP-complete even on almost acyclic graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2234</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2234</id><created>2008-02-15</created><authors><author><keyname>Schommer</keyname><forenames>Christoph</forenames></author><author><keyname>Uhde</keyname><forenames>Conny</forenames></author></authors><title>Textual Fingerprinting with Texts from Parkin, Bassewitz, and Leander</title><categories>cs.CL cs.CR</categories><comments>11 pages, 4 Figures</comments><acm-class>I.7.5; I.5.4; K.6.5</acm-class><abstract>  Current research in author profiling to discover a legal author's fingerprint
does not only follow examinations based on statistical parameters only but
include more and more dynamic methods that can learn and that react adaptable
to the specific behavior of an author. But the question on how to appropriately
represent a text is still one of the fundamental tasks, and the problem of
which attribute should be used to fingerprint the author's style is still not
exactly defined. In this work, we focus on linguistic selection of attributes
to fingerprint the style of the authors Parkin, Bassewitz and Leander. We use
texts of the genre Fairy Tale as it has a clear style and texts of a shorter
size with a straightforward story-line and a simple language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2258</identifier>
 <datestamp>2008-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2258</id><created>2008-02-15</created><authors><author><keyname>Simons</keyname><forenames>Anthony J. H.</forenames></author><author><keyname>Fernandez-y-Fernandez</keyname><forenames>Carlos Alberto</forenames></author></authors><title>Using Alloy to model-check visual design notations</title><categories>cs.SE cs.SC</categories><comments>8 pages</comments><acm-class>I.6.4; D.3.1; I.3.5</acm-class><journal-ref>Simons, A.J.H. and Fernandez-y-Fernandez, C.A., Using Alloy to
  model-check visual design notations. In Sixth Mexican Int. Conf. on C S,
  (Mexico, 2005), IEEE, 121-128</journal-ref><doi>10.1109/ENC.2005.52</doi><abstract>  This paper explores the process of validation for the abstract syntax of a
graphical notation. We define an unified specification for five of the UML
diagrams used by the Discovery Method and, in this document, we illustrate how
diagrams can be represented in Alloy and checked against our specification in
order to know if these are valid under the Discovery notation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2300</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2300</id><created>2008-02-15</created><authors><author><keyname>Austrin</keyname><forenames>Per</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author></authors><title>Approximation Resistant Predicates From Pairwise Independence</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the approximability of predicates on $k$ variables from a domain
$[q]$, and give a new sufficient condition for such predicates to be
approximation resistant under the Unique Games Conjecture. Specifically, we
show that a predicate $P$ is approximation resistant if there exists a balanced
pairwise independent distribution over $[q]^k$ whose support is contained in
the set of satisfying assignments to $P$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2305</identifier>
 <datestamp>2008-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2305</id><created>2008-02-17</created><updated>2008-02-24</updated><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>Compressed Counting</title><categories>cs.IT cs.CC cs.DM cs.DS cs.LG math.IT</categories><abstract>  Counting is among the most fundamental operations in computing. For example,
counting the pth frequency moment has been a very active area of research, in
theoretical computer science, databases, and data mining. When p=1, the task
(i.e., counting the sum) can be accomplished using a simple counter.
  Compressed Counting (CC) is proposed for efficiently computing the pth
frequency moment of a data stream signal A_t, where 0&lt;p&lt;=2. CC is applicable if
the streaming data follow the Turnstile model, with the restriction that at the
time t for the evaluation, A_t[i]&gt;= 0, which includes the strict Turnstile
model as a special case. For natural data streams encountered in practice, this
restriction is minor.
  The underly technique for CC is what we call skewed stable random
projections, which captures the intuition that, when p=1 a simple counter
suffices, and when p = 1+/\Delta with small \Delta, the sample complexity of a
counter system should be low (continuously as a function of \Delta). We show at
small \Delta the sample complexity (number of projections) k = O(1/\epsilon)
instead of O(1/\epsilon^2).
  Compressed Counting can serve a basic building block for other tasks in
statistics and computing, for example, estimation entropies of data streams,
parameter estimations using the method of moments and maximum likelihood.
  Finally, another contribution is an algorithm for approximating the
logarithmic norm, \sum_{i=1}^D\log A_t[i], and logarithmic distance. The
logarithmic distance is useful in machine learning practice with heavy-tailed
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2306</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2306</id><created>2008-02-15</created><authors><author><keyname>Baxter</keyname><forenames>G. J.</forenames></author><author><keyname>Frean</keyname><forenames>M. R.</forenames></author></authors><title>Software graphs and programmer awareness</title><categories>cs.SE cs.PL</categories><comments>9 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dependencies between types in object-oriented software can be viewed as
directed graphs, with types as nodes and dependencies as edges. The in-degree
and out-degree distributions of such graphs have quite different forms, with
the former resembling a power-law distribution and the latter an exponential
distribution. This effect appears to be independent of application or type
relationship. A simple generative model is proposed to explore the proposition
that the difference arises because the programmer is aware of the out-degree of
a type but not of its in-degree. The model reproduces the two distributions,
and compares reasonably well to those observed in 14 different type
relationships across 12 different Java applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2317</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2317</id><created>2008-02-16</created><authors><author><keyname>Prieur</keyname><forenames>Christophe</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Cardon</keyname><forenames>Dominique</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Beuscart</keyname><forenames>Jean-Samuel</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Pissard</keyname><forenames>Nicolas</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Pons</keyname><forenames>Pascal</forenames><affiliation>LIAFA</affiliation></author></authors><title>The Stength of Weak cooperation: A Case Study on Flickr</title><categories>cs.CY</categories><proxy>ccsd hal-00256649</proxy><abstract>  Web 2.0 works with the principle of weak cooperation, where a huge amount of
individual contributions build solid and structured sources of data. In this
paper, we detail the main properties of this weak cooperation by illustrating
them on the photo publication website Flickr, showing the variety of uses
producing a rich content and the various procedures devised by Flickr users
themselves to select quality. We underlined the interaction between small and
heavy users as a specific form of collective production in large social
networks communities. We also give the main statistics on the (5M-users,
150M-photos) data basis we worked on for this study, collected from Flickr
website using the public API.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2345</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2345</id><created>2008-02-16</created><authors><author><keyname>Chatzigeorgiou</keyname><forenames>Ioannis</forenames></author><author><keyname>Wassell</keyname><forenames>Ian J.</forenames></author><author><keyname>Carrasco</keyname><forenames>Rolando</forenames></author></authors><title>On the Frame Error Rate of Transmission Schemes on Quasi-Static Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, Proceedings of the 42nd Conference on Information
  Sciences and Systems, Princeton, USA, March 19-21, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that the frame error rate of turbo codes on quasi-static fading
channels can be accurately approximated using the convergence threshold of the
corresponding iterative decoder. This paper considers quasi-static fading
channels and demonstrates that non-iterative schemes can also be characterized
by a similar threshold based on which their frame error rate can be readily
estimated. In particular, we show that this threshold is a function of the
probability of successful frame detection in additive white Gaussian noise,
normalized by the squared instantaneous signal-to-noise ratio. We apply our
approach to uncoded binary phase shift keying, convolutional coding and turbo
coding and demonstrate that the approximated frame error rate is within 0.4 dB
of the simulation results. Finally, we introduce performance evaluation plots
to explore the impact of the frame size on the performance of the schemes under
investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2349</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2349</id><created>2008-02-16</created><authors><author><keyname>Little</keyname><forenames>John B.</forenames></author></authors><title>Algebraic geometry codes from higher dimensional varieties</title><categories>cs.IT math.IT</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a general survey of literature on Goppa-type codes from higher
dimensional algebraic varieties. The construction and several techniques for
estimating the minimum distance are described first. Codes from various classes
of varieties, including Hermitian hypersurfaces, Grassmannians, flag varieties,
ruled surfaces over curves, and Deligne-Lusztig varieties are considered.
Connections with the theories of toric codes and order domains are also briefly
indicated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2360</identifier>
 <datestamp>2009-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2360</id><created>2008-02-16</created><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Bennatan</keyname><forenames>Amir</forenames></author><author><keyname>Calderbank</keyname><forenames>A. Robert</forenames></author></authors><title>On Maximizing Coverage in Gaussian Relay Networks</title><categories>cs.IT math.IT</categories><comments>17 pages,8 figures, Submitted to IEEE Trans. Inf. Th, Oct. 2007</comments><journal-ref>final version can be seen at V. Aggarwal, A. Bennatan and A. R.
  Calderbank, &quot;On Maximizing Coverage in Gaussian Relay Channels,&quot; IEEE Trans.
  on Inf. Th., vol.55, no.6, pp.2518-2536, June 2009.</journal-ref><doi>10.1109/TIT.2009.2018337</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Results for Gaussian relay channels typically focus on maximizing
transmission rates for given locations of the source, relay and destination. We
introduce an alternative perspective, where the objective is maximizing
coverage for a given rate. The new objective captures the problem of how to
deploy relays to provide a given level of service to a particular geographic
area, where the relay locations become a design parameter that can be
optimized. We evaluate the decode and forward (DF) and compress and forward
(CF) strategies for the relay channel with respect to the new objective of
maximizing coverage. When the objective is maximizing rate, different locations
of the destination favor different strategies. When the objective is coverage
for a given rate, and the relay is able to decode, DF is uniformly superior in
that it provides coverage at any point served by CF. When the channel model is
modified to include random fading, we show that the monotone ordering of
coverage regions is not always maintained. While the coverage provided by DF is
sensitive to changes in the location of the relay and the path loss exponent,
CF exhibits a more graceful degradation with respect to such changes. The
techniques used to approximate coverage regions are new and may be of
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2371</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2371</id><created>2008-02-17</created><authors><author><keyname>Comon</keyname><forenames>P.</forenames></author><author><keyname>Berge</keyname><forenames>J. ten</forenames></author></authors><title>Generic and Typical Ranks of Three-Way Arrays</title><categories>cs.OH cs.MS</categories><report-no>I3S report ISRN I3S/RR-2006-29-FR</report-no><acm-class>F.1.3; G.0; G.3; I.1; J.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The concept of tensor rank, introduced in the twenties, has been popularized
at the beginning of the seventies. This has allowed to carry out Factor
Analysis on arrays with more than two indices. The generic rank may be seen as
an upper bound to the number of factors that can be extracted from a given
tensor. We explain in this short paper how to obtain numerically the generic
rank of tensors of arbitrary dimensions, and compare it with the rare algebraic
results already known at order three. In particular, we examine the cases of
symmetric tensors, tensors with symmetric matrix slices, or tensors with free
entries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2385</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2385</id><created>2008-02-17</created><updated>2010-01-19</updated><authors><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author></authors><title>Essential variables and positions in terms</title><categories>math.GM cs.IT math.IT</categories><comments>17 pages, 2 figures</comments><msc-class>08B05; 03C05; 08A02</msc-class><journal-ref>J. Algebra Universalis, Vol. 61, No 3-4, (2009), pp. 381-397</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The paper deals with $\Sigma-$composition of terms, which allows us to extend
the derivation rules in formal deduction of identities.
  The concept of essential variables and essential positions of terms with
respect to a set of identities is a key step in the simplification of the
process of formal deduction. $\Sigma-$composition of terms is defined as
replacement between $\Sigma$-equal terms. This composition induces $\Sigma
R-$deductively closed sets of identities. In analogy to balanced identities we
introduce and investigate $\Sigma-$balanced identities for a given set of
identities $\Sigma$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2411</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2411</id><created>2008-02-17</created><authors><author><keyname>Pal</keyname><forenames>Mahesh</forenames></author></authors><title>Multiclass Approaches for Support Vector Machine Based Land Cover
  Classification</title><categories>cs.NE cs.CV</categories><comments>16 pages, MapIndia 2005 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SVMs were initially developed to perform binary classification; though,
applications of binary classification are very limited. Most of the practical
applications involve multiclass classification, especially in remote sensing
land cover classification. A number of methods have been proposed to implement
SVMs to produce multiclass classification. A number of methods to generate
multiclass SVMs from binary SVMs have been proposed by researchers and is still
a continuing research topic. This paper compares the performance of six
multi-class approaches to solve classification problem with remote sensing data
in term of classification accuracy and computational cost. One vs. one, one vs.
rest, Directed Acyclic Graph (DAG), and Error Corrected Output Coding (ECOC)
based multiclass approaches creates many binary classifiers and combines their
results to determine the class label of a test pixel. Another catogery of multi
class approach modify the binary class objective function and allows
simultaneous computation of multiclass classification by solving a single
optimisation problem. Results from this study conclude the usefulness of One
vs. One multi class approach in term of accuracy and computational cost over
other multi class approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2418</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2418</id><created>2008-02-18</created><updated>2008-02-18</updated><authors><author><keyname>Crutchfield</keyname><forenames>Christopher</forenames></author><author><keyname>Dzunic</keyname><forenames>Zoran</forenames></author><author><keyname>Fineman</keyname><forenames>Jeremy T.</forenames></author><author><keyname>Karger</keyname><forenames>David R.</forenames></author><author><keyname>Scott</keyname><forenames>Jacob</forenames></author></authors><title>Improved Approximations for Multiprocessor Scheduling Under Uncertainty</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents improved approximation algorithms for the problem of
multiprocessor scheduling under uncertainty, or SUU, in which the execution of
each job may fail probabilistically. This problem is motivated by the
increasing use of distributed computing to handle large, computationally
intensive tasks. In the SUU problem we are given n unit-length jobs and m
machines, a directed acyclic graph G of precedence constraints among jobs, and
unrelated failure probabilities q_{ij} for each job j when executed on machine
i for a single timestep. Our goal is to find a schedule that minimizes the
expected makespan, which is the expected time at which all jobs complete.
  Lin and Rajaraman gave the first approximations for this NP-hard problem for
the special cases of independent jobs, precedence constraints forming disjoint
chains, and precedence constraints forming trees. In this paper, we present
asymptotically better approximation algorithms. In particular, we give an
O(loglog min(m,n))-approximation for independent jobs (improving on the
previously best O(log n)-approximation). We also give an O(log(n+m) loglog
min(m,n))-approximation algorithm for precedence constraints that form disjoint
chains (improving on the previously best
O(log(n)log(m)log(n+m)/loglog(n+m))-approximation by a (log n/loglog n)^2
factor when n = poly(m). Our algorithm for precedence constraints forming
chains can also be used as a component for precedence constraints forming
trees, yielding a similar improvement over the previously best algorithms for
trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2428</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2428</id><created>2008-02-18</created><authors><author><keyname>Aran</keyname><forenames>Oya</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Ari</keyname><forenames>Ismail</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Benoit</keyname><forenames>Alexandre</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Carrillo</keyname><forenames>Ana Huerta</forenames><affiliation>TELE</affiliation></author><author><keyname>Fanard</keyname><forenames>Fran&#xe7;ois-Xavier</forenames><affiliation>TELE</affiliation></author><author><keyname>Campr</keyname><forenames>Pavel</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Akarun</keyname><forenames>Lale</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Caplier</keyname><forenames>Alice</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Rombaut</keyname><forenames>Michele</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Sankur</keyname><forenames>Bulent</forenames></author></authors><title>Sign Language Tutoring Tool</title><categories>cs.LG cs.HC</categories><comments>eNTERFACE'06. Summer Workshop. on Multimodal Interfaces, Dubrovnik :
  Croatie (2007)</comments><proxy>ccsd hal-00256661</proxy><abstract>  In this project, we have developed a sign language tutor that lets users
learn isolated signs by watching recorded videos and by trying the same signs.
The system records the user's video and analyses it. If the sign is recognized,
both verbal and animated feedback is given to the user. The system is able to
recognize complex signs that involve both hand gestures and head movements and
expressions. Our performance tests yield a 99% recognition rate on signs
involving only manual gestures and 85% recognition rate on signs that involve
both manual and non manual components, such as head movement and facial
expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2429</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2429</id><created>2008-02-18</created><authors><author><keyname>Simoncini</keyname><forenames>David</forenames><affiliation>I3S</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>I3S</affiliation></author><author><keyname>Collard</keyname><forenames>Philippe</forenames><affiliation>I3S</affiliation></author><author><keyname>Clergue</keyname><forenames>Manuel</forenames><affiliation>I3S</affiliation></author></authors><title>Anisotropic selection in cellular genetic algorithms</title><categories>cs.AI</categories><proxy>ccsd hal-00164697</proxy><journal-ref>Dans Proceedings of the 8th annual conference on Genetic and
  evolutionary computation - Genetic And Evolutionary Computation Conference,
  Seatle : \'Etats-Unis d'Am\'erique (2006)</journal-ref><doi>10.1145/1143997.1144098</doi><abstract>  In this paper we introduce a new selection scheme in cellular genetic
algorithms (cGAs). Anisotropic Selection (AS) promotes diversity and allows
accurate control of the selective pressure. First we compare this new scheme
with the classical rectangular grid shapes solution according to the selective
pressure: we can obtain the same takeover time with the two techniques although
the spreading of the best individual is different. We then give experimental
results that show to what extent AS promotes the emergence of niches that
support low coupling and high cohesion. Finally, using a cGA with anisotropic
selection on a Quadratic Assignment Problem we show the existence of an
anisotropic optimal value for which the best average performance is observed.
Further work will focus on the selective pressure self-adjustment ability
provided by this new selection scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2432</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2432</id><created>2008-02-18</created><updated>2010-01-27</updated><authors><author><keyname>Durand</keyname><forenames>Bruno</forenames><affiliation>LIF</affiliation></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames><affiliation>LIP</affiliation></author><author><keyname>Shen</keyname><forenames>Alexander</forenames><affiliation>LIF</affiliation></author></authors><title>Fixed Point and Aperiodic Tilings</title><categories>cs.CC cs.DM</categories><comments>v5: technical revision (positions of figures are shifted)</comments><proxy>ccsd hal-00256364</proxy><journal-ref>12th International Conference on Developments in Language Theory,
  Kyoto : Japan (2008)</journal-ref><doi>10.1007/978-3-540-85780-8_22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An aperiodic tile set was first constructed by R.Berger while proving the
undecidability of the domino problem. It turned out that aperiodic tile sets
appear in many topics ranging from logic (the Entscheidungsproblem) to physics
(quasicrystals) We present a new construction of an aperiodic tile set that is
based on Kleene's fixed-point construction instead of geometric arguments. This
construction is similar to J. von Neumann self-reproducing automata; similar
ideas were also used by P. Gacs in the context of error-correcting
computations. The flexibility of this construction allows us to construct a
&quot;robust&quot; aperiodic tile set that does not have periodic (or close to periodic)
tilings even if we allow some (sparse enough) tiling errors. This property was
not known for any of the existing aperiodic tile sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2451</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2451</id><created>2008-02-18</created><updated>2010-06-10</updated><authors><author><keyname>Bocherer</keyname><forenames>Georg</forenames></author><author><keyname>Junior</keyname><forenames>Valdemar Cardoso da Rocha</forenames></author><author><keyname>Pimentel</keyname><forenames>Cecilio</forenames></author></authors><title>Capacity of General Discrete Noiseless Channels</title><categories>cs.IT math.IT</categories><comments>4 pages. Essentially the paper that appeared in Proc. ISCTA '07,
  2007. From v1 to v2, one error was corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the capacity of the discrete noiseless channel introduced
by Shannon. A sufficient condition is given for the capacity to be
well-defined. For a general discrete noiseless channel allowing non-integer
valued symbol weights, it is shown that the capacity--if well-defined--can be
determined from the radius of convergence of its generating function, from the
smallest positive pole of its generating function, or from the rightmost real
singularity of its complex generating function. A generalisation is given for
Pringsheim's Theorem and for the Exponential Growth Formula to generating
functions of combinatorial structures with non-integer valued symbol weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2476</identifier>
 <datestamp>2008-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2476</id><created>2008-02-18</created><updated>2008-08-07</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Bielefeld</keyname><forenames>Daniel</forenames></author></authors><title>Theoretical Analysis of the Energy Capture in Strictly Bandlimited
  Ultra-Wideband Channels</title><categories>cs.IT math.IT</categories><comments>5 pages. Changes from 2nd version: minor corrections. Essentially the
  paper to be presented at ISWCS 2008 in Reykjavik</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The frequency selectivity of wireless communication channels can be
characterized by the delay spread Ds of the channel impulse response. If the
delay spread is small compared to the bandwidth W of the input signal, that is,
Ds*W approximately equal to 1, the channel appears to be flat fading. For Ds*W
&gt;&gt; 1, the channel appears to be frequency selective, which is usually the case
for wideband signals. In the first case, small scale synchronization with a
precision much higher than the sampling time T = 1/W is crucial. In this paper,
it is shown by analytical means that this is different in the wideband regime.
Here synchronization with a precision of T is sufficient and small scale
synchronization cannot further increase the captured energy at the receiver.
Simulation results show that this effect already occurs for W &gt; 50MHz for the
IEEE 802.15.4a channel model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2528</identifier>
 <datestamp>2008-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2528</id><created>2008-02-18</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Korula</keyname><forenames>Nitish</forenames></author></authors><title>Min-Cost 2-Connected Subgraphs With k Terminals</title><categories>cs.DS</categories><comments>18 pages, 3 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the k-2VC problem, we are given an undirected graph G with edge costs and
an integer k; the goal is to find a minimum-cost 2-vertex-connected subgraph of
G containing at least k vertices. A slightly more general version is obtained
if the input also specifies a subset S \subseteq V of terminals and the goal is
to find a subgraph containing at least k terminals. Closely related to the
k-2VC problem, and in fact a special case of it, is the k-2EC problem, in which
the goal is to find a minimum-cost 2-edge-connected subgraph containing k
vertices. The k-2EC problem was introduced by Lau et al., who also gave a
poly-logarithmic approximation for it. No previous approximation algorithm was
known for the more general k-2VC problem. We describe an O(\log n \log k)
approximation for the k-2VC problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2543</identifier>
 <datestamp>2009-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2543</id><created>2008-02-18</created><updated>2009-01-29</updated><authors><author><keyname>Bartolini</keyname><forenames>Novella</forenames><affiliation>Department of Computer Science University of Rome Sapienza, Italy</affiliation></author><author><keyname>Bongiovanni</keyname><forenames>Giancarlo</forenames><affiliation>Department of Computer Science University of Rome Sapienza, Italy</affiliation></author><author><keyname>Silvestri</keyname><forenames>Simone</forenames><affiliation>Department of Computer Science University of Rome Sapienza, Italy</affiliation></author></authors><title>Self-* overload control for distributed web systems</title><categories>cs.NI cs.PF</categories><comments>The full version of this paper, titled &quot;Self-* through self-learning:
  overload control for distributed web systems&quot;, has been published on Computer
  Networks, Elsevier. The simulator used for the evaluation of the proposed
  algorithm is available for download at the address:
  http://www.dsi.uniroma1.it/~novella/qos_web/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unexpected increases in demand and most of all flash crowds are considered
the bane of every web application as they may cause intolerable delays or even
service unavailability. Proper quality of service policies must guarantee rapid
reactivity and responsiveness even in such critical situations. Previous
solutions fail to meet common performance requirements when the system has to
face sudden and unpredictable surges of traffic. Indeed they often rely on a
proper setting of key parameters which requires laborious manual tuning,
preventing a fast adaptation of the control policies. We contribute an original
Self-* Overload Control (SOC) policy. This allows the system to self-configure
a dynamic constraint on the rate of admitted sessions in order to respect
service level agreements and maximize the resource utilization at the same
time. Our policy does not require any prior information on the incoming traffic
or manual configuration of key parameters. We ran extensive simulations under a
wide range of operating conditions, showing that SOC rapidly adapts to time
varying traffic and self-optimizes the resource utilization. It admits as many
new sessions as possible in observance of the agreements, even under intense
workload variations. We compared our algorithm to previously proposed
approaches highlighting a more stable behavior and a better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2574</identifier>
 <datestamp>2008-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2574</id><created>2008-02-18</created><authors><author><keyname>Guille</keyname><forenames>Laurent</forenames></author><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author></authors><title>The minimal set of Ingleton inequalities</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Ingleton-LP bound is an outer bound for the multicast capacity region,
assuming the use of linear network codes. Computation of the bound is performed
on a polyhedral cone obtained by taking the intersection of half-spaces induced
by the basic (Shannon-type) inequalities and Ingleton inequalities. This paper
simplifies the characterization of this cone, by obtaining the unique minimal
set of Ingleton inequalities. As a result, the effort required for computation
of the Ingleton-LP bound can be greatly reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2587</identifier>
 <datestamp>2008-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2587</id><created>2008-02-18</created><authors><author><keyname>Benezit</keyname><forenames>F.</forenames></author><author><keyname>Dimakis</keyname><forenames>A. G.</forenames></author><author><keyname>Thiran</keyname><forenames>P.</forenames></author><author><keyname>Vetterli</keyname><forenames>M.</forenames></author></authors><title>Order-Optimal Consensus through Randomized Path Averaging</title><categories>cs.IT cs.NI math.IT math.PR</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gossip algorithms have recently received significant attention, mainly
because they constitute simple and robust message-passing schemes for
distributed information processing over networks. However for many topologies
that are realistic for wireless ad-hoc and sensor networks (like grids and
random geometric graphs), the standard nearest-neighbor gossip converges as
slowly as flooding ($O(n^2)$ messages).
  A recently proposed algorithm called geographic gossip improves gossip
efficiency by a $\sqrt{n}$ factor, by exploiting geographic information to
enable multi-hop long distance communications. In this paper we prove that a
variation of geographic gossip that averages along routed paths, improves
efficiency by an additional $\sqrt{n}$ factor and is order optimal ($O(n)$
messages) for grids and random geometric graphs.
  We develop a general technique (travel agency method) based on Markov chain
mixing time inequalities, which can give bounds on the performance of
randomized message-passing algorithms operating over various graph topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2594</identifier>
 <datestamp>2009-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2594</id><created>2008-02-19</created><authors><author><keyname>Karavelas</keyname><forenames>Menelaos I.</forenames></author><author><keyname>Tsigaridas</keyname><forenames>Elias P.</forenames></author></authors><title>Guarding curvilinear art galleries with vertex or point guards</title><categories>cs.CG</categories><comments>35 pages, 24 figures</comments><acm-class>F.2.2; I.3.5</acm-class><journal-ref>Comput. Geom. Theory Appl. 42(6-7):522-535, 2009</journal-ref><doi>10.1016/j.comgeo.2008.11.002</doi><abstract>  One of the earliest and most well known problems in computational geometry is
the so-called art gallery problem. The goal is to compute the minimum possible
number guards placed on the vertices of a simple polygon in such a way that
they cover the interior of the polygon.
  In this paper we consider the problem of guarding an art gallery which is
modeled as a polygon with curvilinear walls. Our main focus is on polygons the
edges of which are convex arcs pointing towards the exterior or interior of the
polygon (but not both), named piecewise-convex and piecewise-concave polygons.
We prove that, in the case of piecewise-convex polygons, if we only allow
vertex guards, $\lfloor\frac{4n}{7}\rfloor-1$ guards are sometimes necessary,
and $\lfloor\frac{2n}{3}\rfloor$ guards are always sufficient. Moreover, an
$O(n\log{}n)$ time and O(n) space algorithm is described that produces a vertex
guarding set of size at most $\lfloor\frac{2n}{3}\rfloor$. When we allow point
guards the afore-mentioned lower bound drops down to
$\lfloor\frac{n}{2}\rfloor$. In the special case of monotone piecewise-convex
polygons we can show that $\lfloor\frac{n}{2}\rfloor$ vertex guards are always
sufficient and sometimes necessary; these bounds remain valid even if we allow
point guards.
  In the case of piecewise-concave polygons, we show that $2n-4$ point guards
are always sufficient and sometimes necessary, whereas it might not be possible
to guard such polygons by vertex guards. We conclude with bounds for other
types of curvilinear polygons and future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2612</identifier>
 <datestamp>2008-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2612</id><created>2008-02-19</created><updated>2008-08-14</updated><authors><author><keyname>Gubin</keyname><forenames>Sergey</forenames></author></authors><title>On Subgraph Isomorphism</title><categories>cs.DM cs.CC cs.DS math.CO</categories><comments>Simplified, 6 pages</comments><acm-class>F.2.0; G.2.1; G.2.2</acm-class><journal-ref>Polynomial size asymmetric linear model for Subgraph Isomorphism,
  Proceedings WCECS 2008, ISBN: 978-988-98671-0-2, pp.241-246</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Article explicitly expresses Subgraph Isomorphism by a polynomial size
asymmetric linear system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2655</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2655</id><created>2008-02-19</created><updated>2010-06-09</updated><authors><author><keyname>Bubeck</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Munos</keyname><forenames>R&#xe9;mi</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Stoltz</keyname><forenames>Gilles</forenames><affiliation>DMA, GREGH</affiliation></author></authors><title>Pure Exploration for Multi-Armed Bandit Problems</title><categories>math.ST cs.LG stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the framework of stochastic multi-armed bandit problems and study
the possibilities and limitations of forecasters that perform an on-line
exploration of the arms. These forecasters are assessed in terms of their
simple regret, a regret notion that captures the fact that exploration is only
constrained by the number of available rounds (not necessarily known in
advance), in contrast to the case when the cumulative regret is considered and
when exploitation needs to be performed at the same time. We believe that this
performance criterion is suited to situations when the cost of pulling an arm
is expressed in terms of resources rather than rewards. We discuss the links
between the simple and the cumulative regret. One of the main results in the
case of a finite number of arms is a general lower bound on the simple regret
of a forecaster in terms of its cumulative regret: the smaller the latter, the
larger the former. Keeping this result in mind, we then exhibit upper bounds on
the simple regret of some forecasters. The paper ends with a study devoted to
continuous-armed bandit problems; we show that the simple regret can be
minimized with respect to a family of probability distributions if and only if
the cumulative regret can be minimized for it. Based on this equivalence, we
are able to prove that the separable metric spaces are exactly the metric
spaces on which these regrets can be minimized with respect to the family of
all probability distributions with continuous mean-payoff functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2666</identifier>
 <datestamp>2008-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2666</id><created>2008-02-19</created><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author></authors><title>Distributed Joint Source-Channel Coding for arbitrary memoryless
  correlated sources and Source coding for Markov correlated sources using LDPC
  codes</title><categories>cs.IT math.IT</categories><comments>7 pages, 10 figures, Results have been taken from the Course Project
  Report for ELE 539B (Instructor: Prof. Robert Calderbank), May 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we give a distributed joint source channel coding scheme for
arbitrary correlated sources for arbitrary point in the Slepian-Wolf rate
region, and arbitrary link capacities using LDPC codes. We consider the
Slepian-Wolf setting of two sources and one destination, with one of the
sources derived from the other source by some correlation model known at the
decoder. Distributed encoding and separate decoding is used for the two
sources. We also give a distributed source coding scheme when the source
correlation has memory to achieve any point in the Slepian-Wolf rate achievable
region. In this setting, we perform separate encoding but joint decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2668</identifier>
 <datestamp>2008-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2668</id><created>2008-02-19</created><authors><author><keyname>Gutner</keyname><forenames>Shai</forenames></author></authors><title>The complexity of planar graph choosability</title><categories>cs.DM cs.CC cs.DS</categories><journal-ref>Discrete Math. 159 (1996), 119-130</journal-ref><abstract>  A graph $G$ is {\em $k$-choosable} if for every assignment of a set $S(v)$ of
$k$ colors to every vertex $v$ of $G$, there is a proper coloring of $G$ that
assigns to each vertex $v$ a color from $S(v)$. We consider the complexity of
deciding whether a given graph is $k$-choosable for some constant $k$. In
particular, it is shown that deciding whether a given planar graph is
4-choosable is NP-hard, and so is the problem of deciding whether a given
planar triangle-free graph is 3-choosable. We also obtain simple constructions
of a planar graph which is not 4-choosable and a planar triangle-free graph
which is not 3-choosable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2684</identifier>
 <datestamp>2008-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2684</id><created>2008-02-19</created><authors><author><keyname>Fan</keyname><forenames>Yijia</forenames></author><author><keyname>Adinoyi</keyname><forenames>Abdulkareem</forenames></author><author><keyname>Thompson</keyname><forenames>John S</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>A Simple Distributed Antenna Processing Scheme for Cooperative Diversity</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Communications</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this letter the performance of multiple relay channels is analyzed for the
situation in which multiple antennas are deployed only at the relays. The
simple repetition-coded decodeand- forward protocol with two different antenna
processing techniques at the relays is investigated. The antenna combining
techniques are maximum ratio combining (MRC) for reception and transmit
beamforming (TB) for transmission. It is shown that these distributed antenna
combining techniques can exploit the full spatial diversity of the relay
channels regardless of the number of relays and antennas at each relay, and
offer significant power gain over distributed space-time coding techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2685</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2685</id><created>2008-02-19</created><authors><author><keyname>Rhodes</keyname><forenames>C. J.</forenames></author><author><keyname>Nekovee</keyname><forenames>M.</forenames></author></authors><title>The Opportunistic Transmission of Wireless Worms between Mobile Devices</title><categories>cs.NI cond-mat.stat-mech cs.CR</categories><comments>Submitted for publication</comments><doi>10.1016/j.physa.2008.09.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ubiquity of portable wireless-enabled computing and communications
devices has stimulated the emergence of malicious codes (wireless worms) that
are capable of spreading between spatially proximal devices. The potential
exists for worms to be opportunistically transmitted between devices as they
move around, so human mobility patterns will have an impact on epidemic spread.
The scenario we address in this paper is proximity attacks from fleetingly
in-contact wireless devices with short-range communication range, such as
Bluetooth-enabled smart phones. An individual-based model of mobile devices is
introduced and the effect of population characteristics and device behaviour on
the outbreak dynamics is investigated. We show through extensive simulations
that in the above scenario the resulting mass-action epidemic models remain
applicable provided the contact rate is derived consistently from the
underlying mobility model. The model gives useful analytical expressions
against which more refined simulations of worm spread can be developed and
tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2696</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2696</id><created>2008-02-19</created><authors><author><keyname>Krot-Sieniawska</keyname><forenames>Ewa</forenames></author></authors><title>On Characteristic Polynomials of the Family of Cobweb Posets</title><categories>math.CO cs.DM</categories><comments>7 pages, 1 figure</comments><msc-class>06A06, 06A07, 06A11, 11C08, 11B37</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note is a response to one of problems posed by A.K. Kwasniewski in one
of his recent papers. Namely for the sequence of finite cobweb subposets, the
looked for explicit formulas for corresponding sequence of characteristic
polynomials are discovered and delivered here. The recurrence relation defining
arbitrary family of charactristic polynomials of finite cobweb posets is also
derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2701</identifier>
 <datestamp>2008-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2701</id><created>2008-02-19</created><authors><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Authentication over Noisy Channels</title><categories>cs.IT cs.CR math.IT</categories><comments>Appeared in the Proceedings of the 45th Annual Allerton Conference on
  Communication, Control and Computing, Monticello, IL, September 26 - 28, 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, message authentication over noisy channels is studied. The
model developed in this paper is the authentication theory counterpart of
Wyner's wiretap channel model. Two types of opponent attacks, namely
impersonation attacks and substitution attacks, are investigated for both
single message and multiple message authentication scenarios. For each
scenario, information theoretic lower and upper bounds on the opponent's
success probability are derived. Remarkably, in both scenarios, lower and upper
bounds are shown to match, and hence the fundamental limit of message
authentication over noisy channels is fully characterized. The opponent's
success probability is further shown to be smaller than that derived in the
classic authentication model in which the channel is assumed to be noiseless.
These results rely on a proposed novel authentication scheme in which key
information is used to provide simultaneous protection again both types of
attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2703</identifier>
 <datestamp>2008-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2703</id><created>2008-02-19</created><authors><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author><author><keyname>Jiang</keyname><forenames>Hai</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Optimal Medium Access Protocols for Cognitive Radio Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear in the Proceedings of the 6th International Symposium on
  Modeling and Optimization in Mobile, Ad Hoc and Wireless Networks (WiOpt08),
  Berlin, Germany, March 31-April 4, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the design of medium access control protocols for
cognitive radio networks. The scenario in which a single cognitive user wishes
to opportunistically exploit the availability of empty frequency bands within
parts of the radio spectrum having multiple bands is first considered. In this
scenario, the availability probability of each channel is unknown a priori to
the cognitive user. Hence efficient medium access strategies must strike a
balance between exploring (learning) the availability probability of the
channels and exploiting the knowledge of the availability probability
identified thus far. For this scenario, an optimal medium access strategy is
derived and its underlying recursive structure is illustrated via examples. To
avoid the prohibitive computational complexity of this optimal strategy, a low
complexity asymptotically optimal strategy is developed. Next, the
multi-cognitive user scenario is considered and low complexity medium access
protocols, which strike an optimal balance between exploration and exploitation
in such competitive environments, are developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2723</identifier>
 <datestamp>2008-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2723</id><created>2008-02-19</created><updated>2008-10-05</updated><authors><author><keyname>Mackenthun</keyname><forenames>Kenneth M.</forenames><suffix>Jr</suffix></author></authors><title>On strongly controllable group codes and mixing group shifts: solvable
  groups, translation nets, and algorithms</title><categories>cs.IT math.IT</categories><comments>Improved algorithm included and paper rewritten; 26 pages</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The branch group of a strongly controllable group code is a shift group. We
show that a shift group can be characterized in a very simple way. In addition
it is shown that if a strongly controllable group code is labeled with Latin
squares, a strongly controllable Latin group code, then the shift group is
solvable. Moreover the mathematical structure of a Latin square (as a
translation net) and the shift group of a strongly controllable Latin group
code are closely related. Thus a strongly controllable Latin group code can be
viewed as a natural extension of a Latin square to a sequence space. Lastly we
construct shift groups. We show that it is sufficient to construct a simpler
group, the state group of a shift group. We give an algorithm to find the state
group, and from this it is easy to construct a stronlgy controllable Latin
group code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2736</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2736</id><created>2008-02-20</created><updated>2010-09-01</updated><authors><author><keyname>Guillemot</keyname><forenames>Sylvain</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author><author><keyname>Berry</keyname><forenames>Vincent</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author></authors><title>On the approximability of the Maximum Agreement SubTree and Maximum
  Compatible Tree problems</title><categories>cs.CC cs.DM</categories><comments>Published in Discrete Applied Mathematics</comments><doi>10.1016/j.dam.2008.06.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the corresponding author because the newest
version is now published in Discrete Applied Mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2755</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2755</id><created>2008-02-20</created><authors><author><keyname>Kamiyama</keyname><forenames>Naoyuki</forenames></author><author><keyname>Katoh</keyname><forenames>Naoki</forenames></author></authors><title>Covering Directed Graphs by In-trees</title><categories>cs.DM</categories><comments>15 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a directed graph $D=(V,A)$ with a set of $d$ specified vertices
$S=\{s_1,...,s_d\}\subseteq V$ and a function $f\colon S \to \mathbb{Z}_+$
where $\mathbb{Z}_+$ denotes the set of non-negative integers, we consider the
problem which asks whether there exist $\sum_{i=1}^d f(s_i)$ in-trees denoted
by $T_{i,1},T_{i,2},..., T_{i,f(s_i)}$ for every $i=1,...,d$ such that
$T_{i,1},...,T_{i,f(s_i)}$ are rooted at $s_i$, each $T_{i,j}$ spans vertices
from which $s_i$ is reachable and the union of all arc sets of $T_{i,j}$ for
$i=1,...,d$ and $j=1,...,f(s_i)$ covers $A$. In this paper, we prove that such
set of in-trees covering $A$ can be found by using an algorithm for the
weighted matroid intersection problem in time bounded by a polynomial in
$\sum_{i=1}^df(s_i)$ and the size of $D$. Furthermore, for the case where $D$
is acyclic, we present another characterization of the existence of in-trees
covering $A$, and then we prove that in-trees covering $A$ can be computed more
efficiently than the general case by finding maximum matchings in a series of
bipartite graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2773</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2773</id><created>2008-02-20</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Stiffness Analysis of 3-d.o.f. Overconstrained Translational Parallel
  Manipulators</title><categories>cs.RO physics.class-ph</categories><proxy>ccsd hal-00257728</proxy><journal-ref>Dans IEEE Int. Conference on Robotics and Automation - ICRA IEEE
  Int. Conference on Robotics and Automation, Pasadena : \'Etats-Unis
  d'Am\'erique (2008)</journal-ref><abstract>  The paper presents a new stiffness modelling method for overconstrained
parallel manipulators, which is applied to 3-d.o.f. translational mechanisms.
It is based on a multidimensional lumped-parameter model that replaces the link
flexibility by localized 6-d.o.f. virtual springs. In contrast to other works,
the method includes a FEA-based link stiffness evaluation and employs a new
solution strategy of the kinetostatic equations, which allows computing the
stiffness matrix for the overconstrained architectures and for the singular
manipulator postures. The advantages of the developed technique are confirmed
by application examples, which deal with comparative stiffness analysis of two
translational parallel manipulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2823</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2823</id><created>2008-02-20</created><authors><author><keyname>Sakarovitch</keyname><forenames>Jacques</forenames><affiliation>LTCI</affiliation></author><author><keyname>De Souza</keyname><forenames>Rodrigo</forenames><affiliation>LTCI</affiliation></author></authors><title>On the decomposition of k-valued rational relations</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00256231</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We give a new, and hopefully more easily understandable, structural proof of
the decomposition of a $k$-valued transducer into $k$ unambiguous functional
ones, a result established by A. Weber in 1996. Our construction is based on a
lexicographic ordering of computations of automata and on two coverings that
can be build by means of this ordering. The complexity of the construction,
measured as the number of states of the transducers involved in the
decomposition, improves the original one by one exponential. Moreover, this
method allows further generalisation that solves the problem of decomposition
of rational relations with bounded length-degree, which was left open in
Weber's paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2825</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2825</id><created>2008-02-20</created><authors><author><keyname>Thierauf</keyname><forenames>Thomas</forenames></author><author><keyname>Wagner</keyname><forenames>Fabian</forenames></author></authors><title>The Isomorphism Problem for Planar 3-Connected Graphs is in Unambiguous
  Logspace</title><categories>cs.DS cs.CC</categories><proxy>ccsd hal-00255966</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  The isomorphism problem for planar graphs is known to be efficiently
solvable. For planar 3-connected graphs, the isomorphism problem can be solved
by efficient parallel algorithms, it is in the class $AC^1$. In this paper we
improve the upper bound for planar 3-connected graphs to unambiguous logspace,
in fact to $UL \cap coUL$. As a consequence of our method we get that the
isomorphism problem for oriented graphs is in $NL$. We also show that the
problems are hard for $L$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2826</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2826</id><created>2008-02-20</created><authors><author><keyname>Valmari</keyname><forenames>Antti</forenames></author><author><keyname>Lehtinen</keyname><forenames>Petri</forenames></author></authors><title>Efficient Minimization of DFAs with Partial Transition Functions</title><categories>cs.IT cs.DS math.IT</categories><proxy>ccsd hal-00255954</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  Let PT-DFA mean a deterministic finite automaton whose transition relation is
a partial function. We present an algorithm for minimizing a PT-DFA in $O(m \lg
n)$ time and $O(m+n+\alpha)$ memory, where $n$ is the number of states, $m$ is
the number of defined transitions, and $\alpha$ is the size of the alphabet.
Time consumption does not depend on $\alpha$, because the $\alpha$ term arises
from an array that is accessed at random and never initialized. It is not
needed, if transitions are in a suitable order in the input. The algorithm uses
two instances of an array-based data structure for maintaining a refinable
partition. Its operations are all amortized constant time. One instance
represents the classical blocks and the other a partition of transitions. Our
measurements demonstrate the speed advantage of our algorithm on PT-DFAs over
an $O(\alpha n \lg n)$ time, $O(\alpha n)$ memory algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2827</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2827</id><created>2008-02-20</created><authors><author><keyname>Van Rooij</keyname><forenames>Johan M. M.</forenames></author><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author></authors><title>Design by Measure and Conquer, A Faster Exact Algorithm for Dominating
  Set</title><categories>cs.DS</categories><proxy>ccsd hal-00255946</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  The measure and conquer approach has proven to be a powerful tool to analyse
exact algorithms for combinatorial problems, like Dominating Set and
Independent Set. In this paper, we propose to use measure and conquer also as a
tool in the design of algorithms. In an iterative process, we can obtain a
series of branch and reduce algorithms. A mathematical analysis of an algorithm
in the series with measure and conquer results in a quasiconvex programming
problem. The solution by computer to this problem not only gives a bound on the
running time, but also can give a new reduction rule, thus giving a new,
possibly faster algorithm. This makes design by measure and conquer a form of
computer aided algorithm design. When we apply the methodology to a Set Cover
modelling of the Dominating Set problem, we obtain the currently fastest known
exact algorithms for Dominating Set: an algorithm that uses $O(1.5134^n)$ time
and polynomial space, and an algorithm that uses $O(1.5063^n)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2828</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2828</id><created>2008-02-20</created><authors><author><keyname>Ballier</keyname><forenames>Alexis</forenames><affiliation>LIF</affiliation></author><author><keyname>Durand</keyname><forenames>Bruno</forenames><affiliation>LIF</affiliation></author><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames><affiliation>LIF</affiliation></author></authors><title>Structural aspects of tilings</title><categories>cs.OH</categories><comments>11 pages</comments><proxy>ccsd hal-00145800</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  In this paper, we study the structure of the set of tilings produced by any
given tile-set. For better understanding this structure, we address the set of
finite patterns that each tiling contains. This set of patterns can be analyzed
in two different contexts: the first one is combinatorial and the other
topological. These two approaches have independent merits and, once combined,
provide somehow surprising results. The particular case where the set of
produced tilings is countable is deeply investigated while we prove that the
uncountable case may have a completely different structure. We introduce a
pattern preorder and also make use of Cantor-Bendixson rank. Our first main
result is that a tile-set that produces only periodic tilings produces only a
finite number of them. Our second main result exhibits a tiling with exactly
one vector of periodicity in the countable case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2829</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2829</id><created>2008-02-20</created><authors><author><keyname>Crochemore</keyname><forenames>Maxime</forenames><affiliation>IGM</affiliation></author><author><keyname>Ilie</keyname><forenames>Lucian</forenames></author></authors><title>Understanding maximal repetitions in strings</title><categories>cs.DS math.CO</categories><proxy>ccsd hal-00208087</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  The cornerstone of any algorithm computing all repetitions in a string of
length n in O(n) time is the fact that the number of runs (or maximal
repetitions) is O(n). We give a simple proof of this result. As a consequence
of our approach, the stronger result concerning the linearity of the sum of
exponents of all runs follows easily.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2831</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2831</id><created>2008-02-20</created><authors><author><keyname>Yannakakis</keyname><forenames>Mihalis</forenames></author></authors><title>Equilibria, Fixed Points, and Complexity Classes</title><categories>cs.CC cs.GT</categories><proxy>ccsd hal-00208088</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  Many models from a variety of areas involve the computation of an equilibrium
or fixed point of some kind. Examples include Nash equilibria in games; market
equilibria; computing optimal strategies and the values of competitive games
(stochastic and other games); stable configurations of neural networks;
analysing basic stochastic models for evolution like branching processes and
for language like stochastic context-free grammars; and models that incorporate
the basic primitives of probability and recursion like recursive Markov chains.
It is not known whether these problems can be solved in polynomial time. There
are certain common computational principles underlying different types of
equilibria, which are captured by the complexity classes PLS, PPAD, and FIXP.
Representative complete problems for these classes are respectively, pure Nash
equilibria in games where they are guaranteed to exist, (mixed) Nash equilibria
in 2-player normal form games, and (mixed) Nash equilibria in normal form games
with 3 (or more) players. This paper reviews the underlying computational
principles and the corresponding classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2832</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2832</id><created>2008-02-20</created><authors><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author><author><keyname>Patt-Shamir</keyname><forenames>Boaz</forenames></author><author><keyname>Rawitz</keyname><forenames>Dror</forenames></author></authors><title>Rent, Lease or Buy: Randomized Algorithms for Multislope Ski Rental</title><categories>cs.DS</categories><proxy>ccsd hal-00232970</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  In the Multislope Ski Rental problem, the user needs a certain resource for
some unknown period of time. To use the resource, the user must subscribe to
one of several options, each of which consists of a one-time setup cost
(``buying price''), and cost proportional to the duration of the usage
(``rental rate''). The larger the price, the smaller the rent. The actual usage
time is determined by an adversary, and the goal of an algorithm is to minimize
the cost by choosing the best option at any point in time. Multislope Ski
Rental is a natural generalization of the classical Ski Rental problem (where
the only options are pure rent and pure buy), which is one of the fundamental
problems of online computation. The Multislope Ski Rental problem is an
abstraction of many problems where online decisions cannot be modeled by just
two options, e.g., power management in systems which can be shut down in parts.
In this paper we study randomized algorithms for Multislope Ski Rental. Our
results include the best possible online randomized strategy for any additive
instance, where the cost of switching from one option to another is the
difference in their buying prices; and an algorithm that produces an
$e$-competitive randomized strategy for any (non-additive) instance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2833</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2833</id><created>2008-02-20</created><authors><author><keyname>Bienvenu</keyname><forenames>Laurent</forenames><affiliation>LIF</affiliation></author><author><keyname>Muchnik</keyname><forenames>Andrej</forenames><affiliation>LIF, LIFR-MI2P</affiliation></author><author><keyname>Shen</keyname><forenames>Alexander</forenames><affiliation>LIF, LIFR-MI2P</affiliation></author><author><keyname>Vereshchagin</keyname><forenames>Nikolay</forenames></author></authors><title>Limit complexities revisited</title><categories>cs.CC</categories><proxy>ccsd hal-00218279</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  The main goal of this paper is to put some known results in a common
perspective and to simplify their proofs. We start with a simple proof of a
result from (Vereshchagin, 2002) saying that $\limsup_n\KS(x|n)$ (here
$\KS(x|n)$ is conditional (plain) Kolmogorov complexity of $x$ when $n$ is
known) equals $\KS^{\mathbf{0'}(x)$, the plain Kolmogorov complexity with
$\mathbf{0'$-oracle. Then we use the same argument to prove similar results for
prefix complexity (and also improve results of (Muchnik, 1987) about limit
frequencies), a priori probability on binary tree and measure of effectively
open sets. As a by-product, we get a criterion of $\mathbf{0'}$ Martin-L\&quot;of
randomness (called also 2-randomness) proved in (Miller, 2004): a sequence
$\omega$ is 2-random if and only if there exists $c$ such that any prefix $x$
of $\omega$ is a prefix of some string $y$ such that $\KS(y)\ge |y|-c$. (In the
1960ies this property was suggested in (Kolmogorov, 1968) as one of possible
randomness definitions; its equivalence to 2-randomness was shown in (Miller,
2004) while proving another 2-randomness criterion (see also (Nies et al.
2005)): $\omega$ is 2-random if and only if $\KS(x)\ge |x|-c$ for some $c$ and
infinitely many prefixes $x$ of $\omega$. Finally, we show that the low-basis
theorem can be used to get alternative proofs for these results and to improve
the result about effectively open sets; this stronger version implies the
2-randomness criterion mentioned in the previous sentence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2834</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2834</id><created>2008-02-20</created><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames><affiliation>HIIT</affiliation></author><author><keyname>Husfeldt</keyname><forenames>Thore</forenames><affiliation>HIIT</affiliation></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames><affiliation>HIIT</affiliation></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames><affiliation>HIIT</affiliation></author></authors><title>Trimmed Moebius Inversion and Graphs of Bounded Degree</title><categories>cs.DS math.CO</categories><proxy>ccsd hal-00219770</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We study ways to expedite Yates's algorithm for computing the zeta and
Moebius transforms of a function defined on the subset lattice. We develop a
trimmed variant of Moebius inversion that proceeds point by point, finishing
the calculation at a subset before considering its supersets. For an
$n$-element universe $U$ and a family $\scr F$ of its subsets, trimmed Moebius
inversion allows us to compute the number of packings, coverings, and
partitions of $U$ with $k$ sets from $\scr F$ in time within a polynomial
factor (in $n$) of the number of supersets of the members of $\scr F$. Relying
on an intersection theorem of Chung et al. (1986) to bound the sizes of set
families, we apply these ideas to well-studied combinatorial optimisation
problems on graphs of maximum degree $\Delta$. In particular, we show how to
compute the Domatic Number in time within a polynomial factor of
$(2^{\Delta+1-2)^{n/(\Delta+1)$ and the Chromatic Number in time within a
polynomial factor of $(2^{\Delta+1-\Delta-1)^{n/(\Delta+1)$. For any constant
$\Delta$, these bounds are $O\bigl((2-\epsilon)^n\bigr)$ for $\epsilon&gt;0$
independent of the number of vertices $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2836</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2836</id><created>2008-02-20</created><authors><author><keyname>Bonifaci</keyname><forenames>Vincenzo</forenames><affiliation>CWI</affiliation></author><author><keyname>Korteweg</keyname><forenames>Peter</forenames><affiliation>CWI</affiliation></author><author><keyname>Marchetti-Spaccamela</keyname><forenames>Alberto</forenames><affiliation>CWI</affiliation></author><author><keyname>Stougie</keyname><forenames>Leen</forenames><affiliation>CWI</affiliation></author></authors><title>Minimizing Flow Time in the Wireless Gathering Problem</title><categories>cs.DS cs.NI</categories><proxy>ccsd hal-00220388</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We address the problem of efficient data gathering in a wireless network
through multi-hop communication. We focus on the objective of minimizing the
maximum flow time of a data packet. We prove that no polynomial time algorithm
for this problem can have approximation ratio less than $\Omega(m^{1/3)$ when
$m$ packets have to be transmitted, unless $P = NP$. We then use resource
augmentation to assess the performance of a FIFO-like strategy. We prove that
this strategy is 5-speed optimal, i.e., its cost remains within the optimal
cost if we allow the algorithm to transmit data at a speed 5 times higher than
that of the optimal solution we compare to.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2838</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2838</id><created>2008-02-20</created><authors><author><keyname>Saha</keyname><forenames>Chandan</forenames></author></authors><title>Factoring Polynomials over Finite Fields using Balance Test</title><categories>cs.DS cs.DM</categories><proxy>ccsd hal-00255827</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We study the problem of factoring univariate polynomials over finite fields.
Under the assumption of the Extended Riemann Hypothesis (ERH), (Gao, 2001)
designed a polynomial time algorithm that fails to factor only if the input
polynomial satisfies a strong symmetry property, namely square balance. In this
paper, we propose an extension of Gao's algorithm that fails only under an even
stronger symmetry property. We also show that our property can be used to
improve the time complexity of best deterministic algorithms on most input
polynomials. The property also yields a new randomized polynomial time
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2839</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2839</id><created>2008-02-20</created><authors><author><keyname>Bouyer</keyname><forenames>Patricia</forenames><affiliation>LSV</affiliation></author><author><keyname>Markey</keyname><forenames>Nicolas</forenames><affiliation>LSV</affiliation></author><author><keyname>Ouaknine</keyname><forenames>Jo&#xeb;l</forenames><affiliation>LSV</affiliation></author><author><keyname>Schnoebelen</keyname><forenames>Philippe</forenames><affiliation>LSV</affiliation></author><author><keyname>Worrell</keyname><forenames>James</forenames></author></authors><title>On Termination for Faulty Channel Machines</title><categories>cs.IT cs.CC math.IT</categories><proxy>ccsd hal-00220515</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  A channel machine consists of a finite controller together with several fifo
channels; the controller can read messages from the head of a channel and write
messages to the tail of a channel. In this paper, we focus on channel machines
with insertion errors, i.e., machines in whose channels messages can
spontaneously appear. Such devices have been previously introduced in the study
of Metric Temporal Logic. We consider the termination problem: are all the
computations of a given insertion channel machine finite? We show that this
problem has non-elementary, yet primitive recursive complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2841</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2841</id><created>2008-02-20</created><authors><author><keyname>Briest</keyname><forenames>Patrick</forenames></author><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Krysta</keyname><forenames>Piotr</forenames></author></authors><title>Stackelberg Network Pricing Games</title><categories>cs.DS cs.GT</categories><proxy>ccsd hal-00220519</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We study a multi-player one-round game termed Stackelberg Network Pricing
Game, in which a leader can set prices for a subset of $m$ priceable edges in a
graph. The other edges have a fixed cost. Based on the leader's decision one or
more followers optimize a polynomial-time solvable combinatorial minimization
problem and choose a minimum cost solution satisfying their requirements based
on the fixed costs and the leader's prices. The leader receives as revenue the
total amount of prices paid by the followers for priceable edges in their
solutions, and the problem is to find revenue maximizing prices. Our model
extends several known pricing problems, including single-minded and unit-demand
pricing, as well as Stackelberg pricing for certain follower problems like
shortest path or minimum spanning tree. Our first main result is a tight
analysis of a single-price algorithm for the single follower game, which
provides a $(1+\epsilon) \log m$-approximation for any $\epsilon &gt;0$. This can
be extended to provide a $(1+\epsilon)(\log k + \log m)$-approximation for the
general problem and $k$ followers. The latter result is essentially best
possible, as the problem is shown to be hard to approximate within
$\mathcal{O(\log^\epsilon k + \log^\epsilon m)$. If followers have demands, the
single-price algorithm provides a $(1+\epsilon)m^2$-approximation, and the
problem is hard to approximate within $\mathcal{O(m^\epsilon)$ for some
$\epsilon &gt;0$. Our second main result is a polynomial time algorithm for
revenue maximization in the special case of Stackelberg bipartite vertex cover,
which is based on non-trivial max-flow and LP-duality techniques. Our results
can be extended to provide constant-factor approximations for any constant
number of followers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2842</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2842</id><created>2008-02-20</created><authors><author><keyname>Murlak</keyname><forenames>Filip</forenames></author></authors><title>Weak index versus Borel rank</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00255821</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We investigate weak recognizability of deterministic languages of infinite
trees. We prove that for deterministic languages the Borel hierarchy and the
weak index hierarchy coincide. Furthermore, we propose a procedure computing
for a deterministic automaton an equivalent minimal index weak automaton with a
quadratic number of states. The algorithm works within the time of solving the
emptiness problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2843</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2843</id><created>2008-02-20</created><authors><author><keyname>Brody</keyname><forenames>Joshua</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Amit</forenames></author></authors><title>Sublinear Communication Protocols for Multi-Party Pointer Jumping and a
  Related Lower Bound</title><categories>cs.CC cs.DS</categories><proxy>ccsd hal-00221492</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We study the one-way number-on-the-forehead (NOF) communication complexity of
the $k$-layer pointer jumping problem with $n$ vertices per layer. This classic
problem, which has connections to many aspects of complexity theory, has seen a
recent burst of research activity, seemingly preparing the ground for an
$\Omega(n)$ lower bound, for constant $k$. Our first result is a surprising
sublinear -- i.e., $o(n)$ -- upper bound for the problem that holds for $k \ge
3$, dashing hopes for such a lower bound. A closer look at the protocol
achieving the upper bound shows that all but one of the players involved are
collapsing, i.e., their messages depend only on the composition of the layers
ahead of them. We consider protocols for the pointer jumping problem where all
players are collapsing. Our second result shows that a strong $n - O(\log n)$
lower bound does hold in this case. Our third result is another upper bound
showing that nontrivial protocols for (a non-Boolean version of) pointer
jumping are possible even when all players are collapsing. Our lower bound
result uses a novel proof technique, different from those of earlier lower
bounds that had an information-theoretic flavor. We hope this is useful in
further study of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2844</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2844</id><created>2008-02-20</created><authors><author><keyname>Mishna</keyname><forenames>Marni</forenames></author><author><keyname>Zabrocki</keyname><forenames>Mike</forenames></author></authors><title>Analytic aspects of the shuffle product</title><categories>cs.IT math.CO math.IT</categories><proxy>ccsd hal-00255817</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  There exist very lucid explanations of the combinatorial origins of rational
and algebraic functions, in particular with respect to regular and context free
languages. In the search to understand how to extend these natural
correspondences, we find that the shuffle product models many key aspects of
D-finite generating functions, a class which contains algebraic. We consider
several different takes on the shuffle product, shuffle closure, and shuffle
grammars, and give explicit generating function consequences. In the process,
we define a grammar class that models D-finite generating functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2845</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2845</id><created>2008-02-20</created><authors><author><keyname>De Verdi&#xe8;re</keyname><forenames>Eric Colin</forenames><affiliation>LIENS</affiliation></author><author><keyname>Schrijver</keyname><forenames>Alexander</forenames><affiliation>CWI</affiliation></author></authors><title>Shortest Vertex-Disjoint Two-Face Paths in Planar Graphs</title><categories>cs.DS math.CO</categories><proxy>ccsd hal-00221493</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  Let $G$ be a directed planar graph of complexity $n$, each arc having a
nonnegative length. Let $s$ and $t$ be two distinct faces of $G$; let
$s_1,...,s_k$ be vertices incident with $s$; let $t_1,...,t_k$ be vertices
incident with $t$. We give an algorithm to compute $k$ pairwise vertex-disjoint
paths connecting the pairs $(s_i,t_i)$ in $G$, with minimal total length, in
$O(kn\log n)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2846</identifier>
 <datestamp>2008-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2846</id><created>2008-02-20</created><authors><author><keyname>Cook</keyname><forenames>Atlas F.</forenames><suffix>IV</suffix></author><author><keyname>Wenk</keyname><forenames>Carola</forenames></author></authors><title>Geodesic Fr\'echet Distance Inside a Simple Polygon</title><categories>cs.DS cs.CG</categories><proxy>ccsd hal-00221494</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We unveil an alluring alternative to parametric search that applies to both
the non-geodesic and geodesic Fr\'echet optimization problems. This randomized
approach is based on a variant of red-blue intersections and is appealing due
to its elegance and practical efficiency when compared to parametric search. We
present the first algorithm for the geodesic Fr\'echet distance between two
polygonal curves $A$ and $B$ inside a simple bounding polygon $P$. The geodesic
Fr\'echet decision problem is solved almost as fast as its non-geodesic sibling
and requires $O(N^{2\log k)$ time and $O(k+N)$ space after $O(k)$
preprocessing, where $N$ is the larger of the complexities of $A$ and $B$ and
$k$ is the complexity of $P$. The geodesic Fr\'echet optimization problem is
solved by a randomized approach in $O(k+N^{2\log kN\log N)$ expected time and
$O(k+N^{2)$ space. This runtime is only a logarithmic factor larger than the
standard non-geodesic Fr\'echet algorithm (Alt and Godau 1995). Results are
also presented for the geodesic Fr\'echet distance in a polygonal domain with
obstacles and the geodesic Hausdorff distance for sets of points or sets of
line segments inside a simple polygon $P$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2847</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2847</id><created>2008-02-20</created><authors><author><keyname>Meyer</keyname><forenames>Ulrich</forenames></author></authors><title>On Dynamic Breadth-First Search in External-Memory</title><categories>cs.DS</categories><proxy>ccsd hal-00232975</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We provide the first non-trivial result on dynamic breadth-first search (BFS)
in external-memory: For general sparse undirected graphs of initially $n$ nodes
and O(n) edges and monotone update sequences of either $\Theta(n)$ edge
insertions or $\Theta(n)$ edge deletions, we prove an amortized
high-probability bound of $O(n/B^{2/3}+\sort(n)\cdot \log B)$ I/Os per update.
In contrast, the currently best approach for static BFS on sparse undirected
graphs requires $\Omega(n/B^{1/2}+\sort(n))$ I/Os.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2850</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2850</id><created>2008-02-20</created><authors><author><keyname>Datta</keyname><forenames>Samir</forenames><affiliation>IBM IRL</affiliation></author><author><keyname>Kulkarni</keyname><forenames>Raghav</forenames><affiliation>IBM IRL</affiliation></author><author><keyname>Roy</keyname><forenames>Sambuddha</forenames><affiliation>IBM IRL</affiliation></author></authors><title>Deterministically Isolating a Perfect Matching in Bipartite Planar
  Graphs</title><categories>cs.DS math.CO</categories><proxy>ccsd hal-00221495</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We present a deterministic way of assigning small (log bit) weights to the
edges of a bipartite planar graph so that the minimum weight perfect matching
becomes unique. The isolation lemma as described in (Mulmuley et al. 1987)
achieves the same for general graphs using a randomized weighting scheme,
whereas we can do it deterministically when restricted to bipartite planar
graphs. As a consequence, we reduce both decision and construction versions of
the matching problem to testing whether a matrix is singular, under the promise
that its determinant is 0 or 1, thus obtaining a highly parallel SPL algorithm
for bipartite planar graphs. This improves the earlier known bounds of
non-uniform SPL by (Allender et al. 1999) and $NC^2$ by (Miller and Naor 1995,
Mahajan and Varadarajan 2000). It also rekindles the hope of obtaining a
deterministic parallel algorithm for constructing a perfect matching in
non-bipartite planar graphs, which has been open for a long time. Our
techniques are elementary and simple.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2851</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2851</id><created>2008-02-20</created><authors><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author><author><keyname>Yu</keyname><forenames>Changyuan</forenames></author></authors><title>An Improved Randomized Truthful Mechanism for Scheduling Unrelated
  Machines</title><categories>cs.DS</categories><proxy>ccsd hal-00232972</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We study the scheduling problem on unrelated machines in the mechanism design
setting. This problem was proposed and studied in the seminal paper (Nisan and
Ronen 1999), where they gave a 1.75-approximation randomized truthful mechanism
for the case of two machines. We improve this result by a 1.6737-approximation
randomized truthful mechanism. We also generalize our result to a
$0.8368m$-approximation mechanism for task scheduling with $m$ machines, which
improve the previous best upper bound of $0.875m(Mu'alem and Schapira 2007).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2852</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2852</id><created>2008-02-20</created><authors><author><keyname>Dietzfelbinger</keyname><forenames>Martin</forenames></author><author><keyname>Rowe</keyname><forenames>Jonathan E.</forenames></author><author><keyname>Wegener</keyname><forenames>Ingo</forenames></author><author><keyname>Woelfel</keyname><forenames>Philipp</forenames></author></authors><title>Tight Bounds for Blind Search on the Integers</title><categories>cs.DS</categories><proxy>ccsd hal-00221499</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We analyze a simple random process in which a token is moved in the interval
$A=\{0,...,n\$: Fix a probability distribution $\mu$ over $\{1,...,n\$.
Initially, the token is placed in a random position in $A$. In round $t$, a
random value $d$ is chosen according to $\mu$. If the token is in position
$a\geq d$, then it is moved to position $a-d$. Otherwise it stays put. Let $T$
be the number of rounds until the token reaches position 0. We show tight
bounds for the expectation of $T$ for the optimal distribution $\mu$. More
precisely, we show that $\min_\mu\{E_\mu(T)\=\Theta((\log n)^2)$. For the
proof, a novel potential function argument is introduced. The research is
motivated by the problem of approximating the minimum of a continuous function
over $[0,1]$ with a ``blind'' optimization strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2853</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2853</id><created>2008-02-20</created><authors><author><keyname>Dufourd</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>LSIIT</affiliation></author></authors><title>Discrete Jordan Curve Theorem: A proof formalized in Coq with hypermaps</title><categories>cs.LO cs.DM</categories><proxy>ccsd hal-00221501</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  This paper presents a formalized proof of a discrete form of the Jordan Curve
Theorem. It is based on a hypermap model of planar subdivisions, formal
specifications and proofs assisted by the Coq system. Fundamental properties
are proven by structural or noetherian induction: Genus Theorem, Euler's
Formula, constructive planarity criteria. A notion of ring of faces is
inductively defined and a Jordan Curve Theorem is stated and proven for any
planar hypermap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2854</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2854</id><created>2008-02-20</created><authors><author><keyname>Erlebach</keyname><forenames>Thomas</forenames></author><author><keyname>Hagerup</keyname><forenames>Torben</forenames></author><author><keyname>Jansen</keyname><forenames>Klaus</forenames></author><author><keyname>Minzlaff</keyname><forenames>Moritz</forenames></author><author><keyname>Wolff</keyname><forenames>Alexander</forenames></author></authors><title>Trimming of Graphs, with Application to Point Labeling</title><categories>cs.DM cs.DS math.CO</categories><proxy>ccsd hal-00222069</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  For $t,g&gt;0$, a vertex-weighted graph of total weight $W$ is $(t,g)$-trimmable
if it contains a vertex-induced subgraph of total weight at least $(1-1/t)W$
and with no simple path of more than $g$ edges. A family of graphs is trimmable
if for each constant $t&gt;0$, there is a constant $g=g(t)$ such that every
vertex-weighted graph in the family is $(t,g)$-trimmable. We show that every
family of graphs of bounded domino treewidth is trimmable. This implies that
every family of graphs of bounded degree is trimmable if the graphs in the
family have bounded treewidth or are planar. Based on this result, we derive a
polynomial-time approximation scheme for the problem of labeling weighted
points with nonoverlapping sliding labels of unit height and given lengths so
as to maximize the total weight of the labeled points. This settles one of the
last major open questions in the theory of map labeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2855</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2855</id><created>2008-02-20</created><authors><author><keyname>Erlebach</keyname><forenames>Thomas</forenames></author><author><keyname>Hoffmann</keyname><forenames>Michael</forenames></author><author><keyname>Krizanc</keyname><forenames>Danny</forenames></author><author><keyname>Mihal'&#xe1;k</keyname><forenames>Mat&#xfa;s</forenames></author><author><keyname>Raman</keyname><forenames>Rajeev</forenames></author></authors><title>Computing Minimum Spanning Trees with Uncertainty</title><categories>cs.DS</categories><proxy>ccsd hal-00222077</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We consider the minimum spanning tree problem in a setting where information
about the edge weights of the given graph is uncertain. Initially, for each
edge $e$ of the graph only a set $A_e$, called an uncertainty area, that
contains the actual edge weight $w_e$ is known. The algorithm can `update' $e$
to obtain the edge weight $w_e \in A_e$. The task is to output the edge set of
a minimum spanning tree after a minimum number of updates. An algorithm is
$k$-update competitive if it makes at most $k$ times as many updates as the
optimum. We present a 2-update competitive algorithm if all areas $A_e$ are
open or trivial, which is the best possible among deterministic algorithms. The
condition on the areas $A_e$ is to exclude degenerate inputs for which no
constant update competitive algorithm can exist. Next, we consider a setting
where the vertices of the graph correspond to points in Euclidean space and the
weight of an edge is equal to the distance of its endpoints. The location of
each point is initially given as an uncertainty area, and an update reveals the
exact location of the point. We give a general relation between the edge
uncertainty and the vertex uncertainty versions of a problem and use it to
derive a 4-update competitive algorithm for the minimum spanning tree problem
in the vertex uncertainty model. Again, we show that this is best possible
among deterministic algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2856</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2856</id><created>2008-02-20</created><updated>2008-02-29</updated><authors><author><keyname>Esparza</keyname><forenames>Javier</forenames></author><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author><author><keyname>Luttenberger</keyname><forenames>Michael</forenames></author></authors><title>Convergence Thresholds of Newton's Method for Monotone Polynomial
  Equations</title><categories>cs.DS cs.IT cs.NA math.IT</categories><comments>version 2 deposited February 29, after the end of the STACS
  conference. Two minor mistakes corrected</comments><proxy>ccsd hal-00222086</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  Monotone systems of polynomial equations (MSPEs) are systems of fixed-point
equations $X_1 = f_1(X_1, ..., X_n),$ $..., X_n = f_n(X_1, ..., X_n)$ where
each $f_i$ is a polynomial with positive real coefficients. The question of
computing the least non-negative solution of a given MSPE $\vec X = \vec f(\vec
X)$ arises naturally in the analysis of stochastic models such as stochastic
context-free grammars, probabilistic pushdown automata, and back-button
processes. Etessami and Yannakakis have recently adapted Newton's iterative
method to MSPEs. In a previous paper we have proved the existence of a
threshold $k_{\vec f}$ for strongly connected MSPEs, such that after $k_{\vec
f}$ iterations of Newton's method each new iteration computes at least 1 new
bit of the solution. However, the proof was purely existential. In this paper
we give an upper bound for $k_{\vec f}$ as a function of the minimal component
of the least fixed-point $\mu\vec f$ of $\vec f(\vec X)$. Using this result we
show that $k_{\vec f}$ is at most single exponential resp. linear for strongly
connected MSPEs derived from probabilistic pushdown automata resp. from
back-button processes. Further, we prove the existence of a threshold for
arbitrary MSPEs after which each new iteration computes at least $1/w2^h$ new
bits of the solution, where $w$ and $h$ are the width and height of the DAG of
strongly connected components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2857</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2857</id><created>2008-02-20</created><authors><author><keyname>Lovett</keyname><forenames>Shachar</forenames></author></authors><title>Lower bounds for adaptive linearity tests</title><categories>cs.CC cs.DS</categories><proxy>ccsd hal-00232971</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  Linearity tests are randomized algorithms which have oracle access to the
truth table of some function f, and are supposed to distinguish between linear
functions and functions which are far from linear. Linearity tests were first
introduced by (Blum, Luby and Rubenfeld, 1993), and were later used in the PCP
theorem, among other applications. The quality of a linearity test is described
by its correctness c - the probability it accepts linear functions, its
soundness s - the probability it accepts functions far from linear, and its
query complexity q - the number of queries it makes. Linearity tests were
studied in order to decrease the soundness of linearity tests, while keeping
the query complexity small (for one reason, to improve PCP constructions).
Samorodnitsky and Trevisan (Samorodnitsky and Trevisan 2000) constructed the
Complete Graph Test, and prove that no Hyper Graph Test can perform better than
the Complete Graph Test. Later in (Samorodnitsky and Trevisan 2006) they prove,
among other results, that no non-adaptive linearity test can perform better
than the Complete Graph Test. Their proof uses the algebraic machinery of the
Gowers Norm. A result by (Ben-Sasson, Harsha and Raskhodnikova 2005) allows to
generalize this lower bound also to adaptive linearity tests. We also prove the
same optimal lower bound for adaptive linearity test, but our proof technique
is arguably simpler and more direct than the one used in (Samorodnitsky and
Trevisan 2006). We also study, like (Samorodnitsky and Trevisan 2006), the
behavior of linearity tests on quadratic functions. However, instead of
analyzing the Gowers Norm of certain functions, we provide a more direct
combinatorial proof, studying the behavior of linearity tests on random
quadratic functions...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2860</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2860</id><created>2008-02-20</created><authors><author><keyname>Li</keyname><forenames>Angsheng</forenames></author><author><keyname>Xia</keyname><forenames>Mingji</forenames></author></authors><title>A Theory for Valiant's Matchcircuits (Extended Abstract)</title><categories>cs.CC</categories><proxy>ccsd hal-00232969</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  The computational function of a matchgate is represented by its character
matrix. In this article, we show that all nonsingular character matrices are
closed under matrix inverse operation, so that for every $k$, the nonsingular
character matrices of $k$-bit matchgates form a group, extending the recent
work of Cai and Choudhary (2006) of the same result for the case of $k=2$, and
that the single and the two-bit matchgates are universal for matchcircuits,
answering a question of Valiant (2002).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2861</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2861</id><created>2008-02-20</created><authors><author><keyname>Laue</keyname><forenames>S&#xf6;ren</forenames></author></authors><title>Geometric Set Cover and Hitting Sets for Polytopes in $R^3$</title><categories>cs.CG</categories><proxy>ccsd hal-00232968</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  Suppose we are given a finite set of points $P$ in $\R^3$ and a collection of
polytopes $\mathcal{T}$ that are all translates of the same polytope $T$. We
consider two problems in this paper. The first is the set cover problem where
we want to select a minimal number of polytopes from the collection
$\mathcal{T}$ such that their union covers all input points $P$. The second
problem that we consider is finding a hitting set for the set of polytopes
$\mathcal{T}$, that is, we want to select a minimal number of points from the
input points $P$ such that every given polytope is hit by at least one point.
We give the first constant-factor approximation algorithms for both problems.
We achieve this by providing an epsilon-net for translates of a polytope in
$R^3$ of size $\bigO(\frac{1{\epsilon)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2862</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2862</id><created>2008-02-20</created><authors><author><keyname>Kuske</keyname><forenames>Dietrich</forenames></author></authors><title>Compatibility of Shelah and Stupp's and Muchnik's iteration with
  fragments of monadic second order logic</title><categories>cs.LO</categories><proxy>ccsd hal-00232967</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We investigate the relation between the theory of the iterations in the sense
of Shelah-Stupp and of Muchnik, resp., and the theory of the base structure for
several logics. These logics are obtained from the restriction of set
quantification in monadic second order logic to certain subsets like, e.g.,
finite sets, chains, and finite unions of chains. We show that these theories
of the Shelah-Stupp iteration can be reduced to corresponding theories of the
base structure. This fails for Muchnik's iteration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2863</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2863</id><created>2008-02-20</created><authors><author><keyname>Kojevnikov</keyname><forenames>Arist</forenames></author><author><keyname>Nikolenko</keyname><forenames>Sergey I.</forenames></author></authors><title>New Combinatorial Complete One-Way Functions</title><categories>cs.CC cs.CR</categories><proxy>ccsd hal-00232966</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  In 2003, Leonid A. Levin presented the idea of a combinatorial complete
one-way function and a sketch of the proof that Tiling represents such a
function. In this paper, we present two new one-way functions based on
semi-Thue string rewriting systems and a version of the Post Correspondence
Problem and prove their completeness. Besides, we present an alternative proof
of Levin's result. We also discuss the properties a combinatorial problem
should have in order to hold a complete one-way function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2864</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2864</id><created>2008-02-20</created><authors><author><keyname>Kanj</keyname><forenames>Iyad A.</forenames></author><author><keyname>Perkovic</keyname><forenames>Ljubomir</forenames></author></authors><title>On Geometric Spanners of Euclidean and Unit Disk Graphs</title><categories>cs.DS</categories><proxy>ccsd hal-00231084</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We consider the problem of constructing bounded-degree planar geometric
spanners of Euclidean and unit-disk graphs. It is well known that the Delaunay
subgraph is a planar geometric spanner with stretch factor $C_{del\approx
2.42$; however, its degree may not be bounded. Our first result is a very
simple linear time algorithm for constructing a subgraph of the Delaunay graph
with stretch factor $\rho =1+2\pi(k\cos{\frac{\pi{k)^{-1$ and degree bounded by
$k$, for any integer parameter $k\geq 14$. This result immediately implies an
algorithm for constructing a planar geometric spanner of a Euclidean graph with
stretch factor $\rho \cdot C_{del$ and degree bounded by $k$, for any integer
parameter $k\geq 14$. Moreover, the resulting spanner contains a Euclidean
Minimum Spanning Tree (EMST) as a subgraph. Our second contribution lies in
developing the structural results necessary to transfer our analysis and
algorithm from Euclidean graphs to unit disk graphs, the usual model for
wireless ad-hoc networks. We obtain a very simple distributed, {\em
strictly-localized algorithm that, given a unit disk graph embedded in the
plane, constructs a geometric spanner with the above stretch factor and degree
bound, and also containing an EMST as a subgraph. The obtained results
dramatically improve the previous results in all aspects, as shown in the
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2865</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2865</id><created>2008-02-20</created><authors><author><keyname>Chen</keyname><forenames>Chao</forenames></author><author><keyname>Freedman</keyname><forenames>Daniel</forenames></author></authors><title>Quantifying Homology Classes</title><categories>cs.CG cs.DM</categories><proxy>ccsd hal-00256542</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We develop a method for measuring homology classes. This involves three
problems. First, we define the size of a homology class, using ideas from
relative homology. Second, we define an optimal basis of a homology group to be
the basis whose elements' size have the minimal sum. We provide a greedy
algorithm to compute the optimal basis and measure classes in it. The algorithm
runs in $O(\beta^4 n^3 \log^2 n)$ time, where $n$ is the size of the simplicial
complex and $\beta$ is the Betti number of the homology group. Third, we
discuss different ways of localizing homology classes and prove some hardness
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2866</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2866</id><created>2008-02-20</created><authors><author><keyname>Kaiser</keyname><forenames>Lukasz</forenames></author><author><keyname>Rubin</keyname><forenames>Sasha</forenames></author><author><keyname>B&#xe1;r&#xe1;ny</keyname><forenames>Vince</forenames></author></authors><title>Cardinality and counting quantifiers on omega-automatic structures</title><categories>cs.LO</categories><proxy>ccsd hal-00227560</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We investigate structures that can be represented by omega-automata, so
called omega-automatic structures, and prove that relations defined over such
structures in first-order logic expanded by the first-order quantifiers `there
exist at most $\aleph_0$ many', 'there exist finitely many' and 'there exist
$k$ modulo $m$ many' are omega-regular. The proof identifies certain algebraic
properties of omega-semigroups. As a consequence an omega-regular equivalence
relation of countable index has an omega-regular set of representatives. This
implies Blumensath's conjecture that a countable structure with an
$\omega$-automatic presentation can be represented using automata on finite
words. This also complements a very recent result of Hj\&quot;orth, Khoussainov,
Montalban and Nies showing that there is an omega-automatic structure which has
no injective presentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2867</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2867</id><created>2008-02-20</created><authors><author><keyname>Hoang</keyname><forenames>Viet Tung</forenames></author><author><keyname>Sung</keyname><forenames>Wing-Kin</forenames></author></authors><title>Fixed Parameter Polynomial Time Algorithms for Maximum Agreement and
  Compatible Supertrees</title><categories>cs.DS</categories><proxy>ccsd hal-00227551</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  Consider a set of labels $L$ and a set of trees ${\mathcal T} = \{{\mathcal
T}^{(1), {\mathcal T}^{(2), ..., {\mathcal T}^{(k) \$ where each tree
${\mathcal T}^{(i)$ is distinctly leaf-labeled by some subset of $L$. One
fundamental problem is to find the biggest tree (denoted as supertree) to
represent $\mathcal T}$ which minimizes the disagreements with the trees in
${\mathcal T}$ under certain criteria. This problem finds applications in
phylogenetics, database, and data mining. In this paper, we focus on two
particular supertree problems, namely, the maximum agreement supertree problem
(MASP) and the maximum compatible supertree problem (MCSP). These two problems
are known to be NP-hard for $k \geq 3$. This paper gives the first polynomial
time algorithms for both MASP and MCSP when both $k$ and the maximum degree $D$
of the trees are constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2868</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2868</id><created>2008-02-20</created><authors><author><keyname>Glasser</keyname><forenames>Christian</forenames></author><author><keyname>Schmitz</keyname><forenames>Heinz</forenames></author><author><keyname>Selivanov</keyname><forenames>Victor</forenames></author></authors><title>Efficient Algorithms for Membership in Boolean Hierarchies of Regular
  Languages</title><categories>cs.CC</categories><proxy>ccsd hal-00227550</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  The purpose of this paper is to provide efficient algorithms that decide
membership for classes of several Boolean hierarchies for which efficiency (or
even decidability) were previously not known. We develop new forbidden-chain
characterizations for the single levels of these hierarchies and obtain the
following results: - The classes of the Boolean hierarchy over level $\Sigma_1$
of the dot-depth hierarchy are decidable in $NL$ (previously only the
decidability was known). The same remains true if predicates mod $d$ for fixed
$d$ are allowed. - If modular predicates for arbitrary $d$ are allowed, then
the classes of the Boolean hierarchy over level $\Sigma_1$ are decidable. - For
the restricted case of a two-letter alphabet, the classes of the Boolean
hierarchy over level $\Sigma_2$ of the Straubing-Th\'erien hierarchy are
decidable in $NL$. This is the first decidability result for this hierarchy. -
The membership problems for all mentioned Boolean-hierarchy classes are
logspace many-one hard for $NL$. - The membership problems for quasi-aperiodic
languages and for $d$-quasi-aperiodic languages are logspace many-one complete
for $PSPACE$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2869</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2869</id><created>2008-02-20</created><authors><author><keyname>Gelade</keyname><forenames>Wouter</forenames></author><author><keyname>Neven</keyname><forenames>Frank</forenames></author></authors><title>Succinctness of the Complement and Intersection of Regular Expressions</title><categories>cs.CC</categories><proxy>ccsd hal-00226864</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We study the succinctness of the complement and intersection of regular
expressions. In particular, we show that when constructing a regular expression
defining the complement of a given regular expression, a double exponential
size increase cannot be avoided. Similarly, when constructing a regular
expression defining the intersection of a fixed and an arbitrary number of
regular expressions, an exponential and double exponential size increase,
respectively, can in worst-case not be avoided. All mentioned lower bounds
improve the existing ones by one exponential and are tight in the sense that
the target expression can be constructed in the corresponding time class, i.e.,
exponential or double exponential time. As a by-product, we generalize a
theorem by Ehrenfeucht and Zeiger stating that there is a class of DFAs which
are exponentially more succinct than regular expressions, to a fixed
four-letter alphabet. When the given regular expressions are one-unambiguous,
as for instance required by the XML Schema specification, the complement can be
computed in polynomial time whereas the bounds concerning intersection continue
to hold. For the subclass of single-occurrence regular expressions, we prove a
tight exponential lower bound for intersection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2871</identifier>
 <datestamp>2008-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2871</id><created>2008-02-20</created><authors><author><keyname>Fischer</keyname><forenames>Diana</forenames></author><author><keyname>Gr&#xe4;del</keyname><forenames>Erich</forenames></author><author><keyname>Kaiser</keyname><forenames>Lukasz</forenames></author></authors><title>Model Checking Games for the Quantitative mu-Calculus</title><categories>cs.LO cs.GT</categories><proxy>ccsd hal-00255805</proxy><journal-ref>Dans Proceedings of the 25th Annual Symposium on the Theoretical
  Aspects of Computer Science - STACS 2008, Bordeaux : France (2008)</journal-ref><abstract>  We investigate quantitative extensions of modal logic and the modal
mu-calculus, and study the question whether the tight connection between logic
and games can be lifted from the qualitative logics to their quantitative
counterparts. It turns out that, if the quantitative mu-calculus is defined in
an appropriate way respecting the duality properties between the logical
operators, then its model checking problem can indeed be characterised by a
quantitative variant of parity games. However, these quantitative games have
quite different properties than their classical counterparts, in particular
they are, in general, not positionally determined. The correspondence between
the logic and the games goes both ways: the value of a formula on a
quantitative transition system coincides with the value of the associated
quantitative game, and conversely, the values of quantitative parity games are
definable in the quantitative mu-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2932</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2932</id><created>2008-02-20</created><authors><author><keyname>Sentence</keyname><forenames>Brian</forenames></author></authors><title>A New Approach to Spreadsheet Analytics Management in Financial Markets</title><categories>cs.SE cs.CY</categories><comments>9 Pages, 9 Colour Figures</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 65-72
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets in financial markets are frequently used as database, calculator
and reporting application combined. This paper describes an alternative
approach in which spreadsheet design and database technology have been brought
together in order to alleviate management and regulatory concerns over the
operational risks of spreadsheet usage. In particular, the paper focuses on the
rapid creation and centralised deployment of statistical analytics within a
software system now in use by major investment banks, and presents a novel
technique for the manipulation in spreadsheets of high volumes of intraday
market data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2975</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2975</id><created>2008-02-20</created><authors><author><keyname>Park</keyname><forenames>Daeyoung</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Hard Fairness Versus Proportional Fairness in Wireless Communications:
  The Multiple-Cell Case</title><categories>cs.IT math.IT</categories><comments>26 pages, 8 figures, submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the uplink of a cellular communication system with $K$ users per
cell and infinite base stations equally spaced on a line. The system is
conventional, i.e., it does not make use of joint cell-site processing. A hard
fairness (HF) system serves all users with the same rate in any channel state.
In contrast, a system based on proportional fairness serves the users with
variable instantaneous rates depending on their channel state. We compare these
two options in terms of the system spectral efficiency \textsf{C} (bit/s/Hz)
versus $E_b/N_0$. Proportional fair scheduling (PFS) performs generally better
than the more restrictive HF system in the regime of low to moderate SNR, but
for high SNR an optimized HF system achieves throughput comparable to that of
PFS system for finite $K$. The hard-fairness system is interference limited. We
characterize this limit and validate a commonly used simplified model that
treats outer cell interference power as proportional to the in-cell total power
and we analytically characterize the proportionality constant. In contrast, the
spectral efficiency of PFS can grow unbounded for $K \to \infty$ thanks to the
multiuser diversity effect. We also show that partial frequency/time reuse can
mitigate the throughput penalty of the HF system, especially at high SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2980</identifier>
 <datestamp>2008-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2980</id><created>2008-02-21</created><authors><author><keyname>Krot-Sieniawska</keyname><forenames>Ewa</forenames></author></authors><title>Characterization of Cobweb Posets as KoDAGs</title><categories>math.CO cs.DM</categories><comments>6 pages, 1 figure</comments><msc-class>05C20, 05C75, 06A07, 11B39</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The characterization of the large family of cobweb posets as DAGs and oDAGs
is given. The dim 2 poset such that its Hasse diagram coincide with digraf of
arbitrary cobweb poset is constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3013</identifier>
 <datestamp>2008-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3013</id><created>2008-02-21</created><updated>2008-03-14</updated><authors><author><keyname>Dias</keyname><forenames>Frederic</forenames><affiliation>CMLA, ENS de Cachan</affiliation></author><author><keyname>Dutykh</keyname><forenames>Denys</forenames><affiliation>CMLA, ENS de Cachan</affiliation></author><author><keyname>Ghidaglia</keyname><forenames>Jean-Michel</forenames><affiliation>CMLA, ENS de Cachan</affiliation></author></authors><title>Simulation of Free Surface Compressible Flows Via a Two Fluid Model</title><categories>physics.comp-ph cs.NA math.NA physics.ao-ph physics.flu-dyn</categories><comments>8 pages, 10 figures; OMAE2008, 27th International Conference on
  Offshore Mechanics and Arctic Engineering. Other authors papers and
  animations related to this work can be downloaded from:
  http://www.cmla.ens-cachan.fr/fileadmin/Membres/dutykh/ The paper was
  slightly modified according to referees comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this communication is to discuss the simulation of a free
surface compressible flow between two fluids, typically air and water. We use a
two fluid model with the same velocity, pressure and temperature for both
phases. In such a numerical model, the free surface becomes a thin three
dimensional zone. The present method has at least three advantages: (i) the
free-surface treatment is completely implicit; (ii) it can naturally handle
wave breaking and other topological changes in the flow; (iii) one can easily
vary the Equation of States (EOS) of each fluid (in principle, one can even
consider tabulated EOS). Moreover, our model is unconditionally hyperbolic for
reasonable EOS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3037</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3037</id><created>2008-02-21</created><authors><author><keyname>Yang</keyname><forenames>Hsiharng</forenames></author><author><keyname>Yang</keyname><forenames>Chung-Yao</forenames></author><author><keyname>Yeh</keyname><forenames>Mau-Shiun</forenames></author></authors><title>Fabrication of Miniaturized Variable-focus Lens Using Liquid Filling
  Technique</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257721</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper describes a simple method for fabricating a variable-focus lens by
using PDMS (polydimethylsiloxane) and filling with liquid for the
variable-focus lens. The lens diameter of 2-mm was designed in this experiment
and expected to reach the focal length in the range of 3 ~ 12 mm. The
theoretical value between the liquid volume and the lens contact angle at
different focal lengths were simulated and measured. The pumped-in volumes
ranged from 200 to 1400 $\mu$l, the contact angles ranged from 14.25 degrees to
49.02 degrees. Changing the deformation of PDMS film using different
micro-fluidic volume produces the variable focal length from 4 10 mm in this
experiment. The proposed method successfully fabricated a variable-focus lens.
Bonding PDMS only once using no expensive instrument such as oxygen plasma was
accomplished. The final objective is to insert the variable focus lens into
portable optical imagery products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3038</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3038</id><created>2008-02-21</created><authors><author><keyname>Duan</keyname><forenames>Fei</forenames></author><author><keyname>Jiao</keyname><forenames>Jiwei</forenames></author><author><keyname>Wang</keyname><forenames>Yucai</forenames></author><author><keyname>Zhang</keyname><forenames>Ying</forenames></author><author><keyname>Mi</keyname><forenames>Binwei</forenames></author><author><keyname>Li</keyname><forenames>Jinpeng</forenames></author><author><keyname>Zhu</keyname><forenames>Jian</forenames></author><author><keyname>Wang</keyname><forenames>Yuelin</forenames></author></authors><title>A Novel X-Axis Tuning Fork Gyroscope with &quot;8 Vertical Springs-Proofmass&quot;
  Structure on (111)-Silicon</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257720</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  A novel x-axis tuning fork MEMS gyroscope with &quot;8 vertical springs-proofmass&quot;
structure for Coriolis effect detection is presented. Compared with the common
single-plane springs, the 8 vertical springs, symmetrically located at the top
and bottom sides, more stably suspend the large thick proofmass featuring large
capacitance variation and low mechanical noise. A bulk-micromachining
technology is applied to obtain the large proofmass and twins-like dual beams.
During the fabrication process, the dimensions of the 8 vertical springs are
precisely confined by thermal oxide protected limit trenches (LTs) sidewalls
and the extreme slowly etched (111)-planes; therefore a small mismatch of less
than 30 Hz is achieved before tuning. Initial test shows a sensitivity of
0.15mV/(deg/s) and rate resolution around 0.1deg/s under atmosphere pressure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3040</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3040</id><created>2008-02-21</created><authors><author><keyname>Grogg</keyname><forenames>D.</forenames></author><author><keyname>Badila-Ciressan</keyname><forenames>Nicoleta Diana</forenames></author><author><keyname>Ionescu</keyname><forenames>Adrian Mihai</forenames></author></authors><title>Fabrication of MEMS Resonators in Thin SOI</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257708</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  A simple and fast process for micro-electromechanical (MEM) resonators with
deep sub-micron transduction gaps in thin SOI is presented in this paper. Thin
SOI wafers are important for advanced CMOS technology and thus are evaluated as
resonator substrates for future co-integration with CMOS circuitry on a single
chip. As the transduction capacitance scales with the resonator thickness, it
is important to fabricate deep sub-micron trenches in order to achieve a good
capacitive coupling. Through the combination of conventional UV-lithography and
focused ion beam (FIB) milling the process needs only two lithography steps,
enabling therefore a way for fast prototyping of MEM-resonators. Different FIB
parameters and etching parameters are compared in this paper and their effect
on the process are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3041</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3041</id><created>2008-02-21</created><authors><author><keyname>Tim&#xe1;r-Horv&#xe1;th</keyname><forenames>Veronika</forenames></author><author><keyname>Juh&#xe1;sz</keyname><forenames>L&#xe1;szl&#xf3;</forenames></author><author><keyname>Vass-V&#xe1;rnai</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Perlaky</keyname><forenames>Gergely</forenames></author></authors><title>Usage of Porous Al2O3 Layers for RH Sensing</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257719</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  At the Department of Electron Devices a cheap, more or less CMOS process
compatible capacitive type RH sensor has been developed. Capacitive sensors are
based on dielectric property changes of thin films upon water vapour uptake
which depends on the surrounding media's relative humidity content. Because of
the immense surface-to-volume ratio and the abundant void fraction, very high
sensitivities can be obtained with porous ceramics. One of the ceramics to be
used is porous Al2O3, obtained by electrochemical oxidation of aluminium under
anodic bias. The average pore sizes are between 6...9 nm. In our paper we
intend to demonstrate images representing the influence of the technological
parameters on the porous structure and the device sensitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3042</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3042</id><created>2008-02-21</created><authors><author><keyname>Worgull</keyname><forenames>M.</forenames></author><author><keyname>Kabanemi</keyname><forenames>K. K.</forenames></author><author><keyname>Marcotte</keyname><forenames>J. -P.</forenames></author><author><keyname>H&#xe9;tu</keyname><forenames>J. -F.</forenames></author><author><keyname>Heckele</keyname><forenames>M.</forenames></author></authors><title>Modeling of large area hot embossing</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257718</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Today, hot embossing and injection molding belong to the established plastic
molding processes in microengineering. Based on experimental findings, a
variety of microstructures have been replicated so far using the processes.
However, with increasing requirements regarding the embossing surface and the
simultaneous decrease of the structure size down into the nanorange, increasing
know-how is needed to adapt hot embossing to industrial standards. To reach
this objective, a German-Canadian cooperation project has been launched to
study hot embossing theoretically by a process simulation and experimentally.
The present publication shall report about the first results of the simulation
- the modeling and simulation of large area replication based on an eight inch
microstructured mold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3043</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3043</id><created>2008-02-21</created><authors><author><keyname>Yu</keyname><forenames>Jyh-Cheng</forenames></author><author><keyname>Lin</keyname><forenames>Huang-Yao</forenames></author></authors><title>Liquid Density Sensing Using Resonant Flexural Plate Wave Device with
  Sol-Gel PZT Thin Films</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257716</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper presents the design, fabrication and preliminary experimental
results of a flexure plate wave (FPW) resonator using sol-gel derived lead
zirconate titanates (PZT) thin films. The resonator adopts a two-port structure
with reflecting grates on the composite membrane of PZT and SiNx. The design of
the reflecting grate is derived from a SAW resonator model using COM theory to
produce a sharp resonant peak. The comparison between the mass and the
viscosity effects from the theoretical expression illustrates the applications
and the constraints of the proposed device in liquid sensing. Multiple coatings
of sol-gel derived PZT films are adopted because of the cost advantage and the
high electromechanical coupling effect over other piezoelectric films. The
fabrication issues of the proposed material structure are addressed.
Theoretical estimations of the mass and the viscosity effects are compared with
the experimental results. The resonant frequency has a good linear correlation
with the density of low viscosity liquids, which demonstrate the feasibility of
the proposed device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3044</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3044</id><created>2008-02-21</created><authors><author><keyname>Marzencki</keyname><forenames>M.</forenames><affiliation>TIMA</affiliation></author><author><keyname>Ammar</keyname><forenames>Y.</forenames><affiliation>TIMA</affiliation></author><author><keyname>Basrour</keyname><forenames>S.</forenames><affiliation>TIMA</affiliation></author></authors><title>Design, Fabrication and Characterization of a Piezoelectric
  Microgenerator Including a Power Management Circuit</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257715</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  We report in this paper the design, fabrication and experimental
characterization of a piezoelectric MEMS microgenerator. This device scavenges
the energy of ambient mechanical vibrations characterized by frequencies in the
range of 1 kHz. This component is made with Aluminum Nitride thin film
deposited with a CMOS compatible process. Moreover we analyze two possible
solutions for the signal rectification: a discrete doubler-rectifier and a full
custom power management circuit. The ASIC developed for this application takes
advantage of diodes with very low threshold voltage and therefore allows the
conversion of extremely low input voltages corresponding to very weak input
accelerations. The volume of the proposed generator is inferior to 1mm3 and the
generated powers are in the range of 1$\mu$W. This system is intended to supply
power to autonomous wireless sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3046</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3046</id><created>2008-02-21</created><authors><author><keyname>Jean-Mistral</keyname><forenames>C.</forenames><affiliation>LETI</affiliation></author><author><keyname>Basrour</keyname><forenames>S.</forenames><affiliation>TIMA</affiliation></author><author><keyname>Chaillout</keyname><forenames>J. J.</forenames><affiliation>LETI</affiliation></author><author><keyname>Bonvilain</keyname><forenames>A.</forenames><affiliation>TIMA</affiliation></author></authors><title>A complete study of electroactive polymers for energy scavenging:
  modelling and experiments</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257706</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Recent progresses in ultra low power microelectronics propelled the
development of several microsensors and particularly the self powered
microsystems (SPMS). One of their limitations is their size and their autonomy
due to short lifetime of the batteries available on the market. To ensure their
ecological energetic autonomy, a promising alternative is to scavenge the
ambient energy such as the mechanical one. Nowadays, few microgenerators
operate at low frequency. They are often rigid structures that can perturb the
application or the environment; none of them are perfectly flexible. Thus, our
objective is to create a flexible, non-intrusive scavenger using electroactive
polymers. The goal of this work is to design a generator which can provide
typically 100 ?W to supply a low consumption system. We report in this paper an
analytical model which predicts the energy produced by a simple electroactive
membrane, and some promising experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3047</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3047</id><created>2008-02-21</created><authors><author><keyname>Saha</keyname><forenames>C.</forenames></author><author><keyname>O'Donnell</keyname><forenames>T.</forenames></author><author><keyname>Godsell</keyname><forenames>J.</forenames></author><author><keyname>Carlioz</keyname><forenames>L.</forenames></author><author><keyname>Wang</keyname><forenames>N.</forenames></author><author><keyname>Mccloskey</keyname><forenames>P.</forenames></author><author><keyname>Beeby</keyname><forenames>S.</forenames></author><author><keyname>Tudor</keyname><forenames>J.</forenames></author><author><keyname>Torah</keyname><forenames>Russel</forenames></author></authors><title>Step-up converter for electromagnetic vibrational energy scavenger</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257714</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper introduces a voltage multiplier (VM) circuit which can step up a
minimum voltage of 150 mV (peak). The operation and characteristics of this
converter circuit are described. The voltage multiplier circuit is also tested
with micro and macro scale electromagnetic vibrational generators and the
effect of the VM on the optimum load conditions of the electromagnetic
generator is presented. The measured results show that 85% efficiency can be
achieved from this VM circuit at a power level of 18 ?W.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3048</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3048</id><created>2008-02-21</created><authors><author><keyname>Qiufen</keyname><forenames>G.</forenames></author><author><keyname>Yuansheng</keyname><forenames>G.</forenames></author><author><keyname>Feng</keyname><forenames>S.</forenames></author><author><keyname>Fuqiang</keyname><forenames>L.</forenames></author></authors><title>Gas Damping Coefficient Research for MEMS Comb Linear Vibration
  Gyroscope</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257697</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Silicon-MEMS gyroscope is an important part of MEMS (Micro Electrical
Mechanical System). There are some disturb ignored in traditional gyroscope
that must be evaluated newly because of its smaller size (reach the level of
micron). In these disturb, the air pressure largely influences the performance
of MEMS gyroscope. Different air pressure causes different gas damping
coefficient for the MEMS comb linear vibration gyroscope and different gas
damping coefficient influences the quality factor of the gyroscope directive.
The quality factor influences the dynamic working bandwidth of the MEMS comb
linear vibration gyroscope, so it is influences the output characteristic of
the MEMS comb linear vibration gyroscope. The paper shows the relationship
between the air pressure and the output amplified and phase of the detecting
axis through analyzing the air pressure influence on the MEMS comb linear
vibration gyroscope. It discusses the influence on the frequency distribute and
quality factor of the MEMS comb linear vibration gyroscope for different air
pressure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3049</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3049</id><created>2008-02-21</created><authors><author><keyname>Nagy</keyname><forenames>G.</forenames></author><author><keyname>Szucs</keyname><forenames>Z.</forenames></author><author><keyname>Hodossy</keyname><forenames>S.</forenames></author><author><keyname>Rencz</keyname><forenames>M.</forenames></author><author><keyname>Poppe</keyname><forenames>A.</forenames></author></authors><title>Comparison of Two Low-Power Electronic Interfaces for Capacitive Mems
  Sensors</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257695</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  The paper discusses the importance and the issues of interfacing capacitive
sensors. Two architectures applicable for interfacing capacitive sensors are
presented. The first solution was designed to interface a capacitive humidity
sensor designed and built for a humidity-dependent monolithic capacitor
developed at Budapest University of Technology and Economics. The second case
presents the possible read-out solutions for a SOI-MEMS accelerometer. Both of
the architectures were built and tested in a discrete implementation to qualify
the methods before the integrated realization. The paper presents a detailed
comparison of the two methods
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3050</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3050</id><created>2008-02-21</created><authors><author><keyname>Crebier</keyname><forenames>J. -C.</forenames><affiliation>G2ELab</affiliation></author><author><keyname>Lembeye</keyname><forenames>Y.</forenames><affiliation>G2ELab</affiliation></author><author><keyname>Raisigel</keyname><forenames>H.</forenames><affiliation>G2ELab</affiliation></author><author><keyname>Deleage</keyname><forenames>O.</forenames><affiliation>G2ELab</affiliation></author><author><keyname>Delamare</keyname><forenames>J.</forenames><affiliation>G2ELab</affiliation></author><author><keyname>Cugat</keyname><forenames>O.</forenames><affiliation>G2ELab</affiliation></author></authors><title>High Efficiency 3-Phase Cmos Rectifier with Step Up and Regulated</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257713</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper presents several design issues related to the monolithic
integration of a 3-phase AC to DC low voltage, low power rectifier for 3-phase
micro source electrical conditioning. Reduced input voltage operation (down to
1V), high efficiency, and output voltage regulations are implemented, based on
commercially available CMOS technology. Global design and system issues are
detailed. The management of start-up sequences under self supplied conditions
as well as output voltage regulations are specifically addressed. Simulation
results, practical implementation and validation are presented. They are based
on the association of three micro elements : a 3-phase micro-generator, a stand
alone 3-phase AC to DC integrated rectifier, and an output voltage conditioner
based on a commercially available IC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3051</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3051</id><created>2008-02-21</created><authors><author><keyname>Durand</keyname><forenames>C.</forenames><affiliation>ST-Crolles, Leti, Iemn</affiliation></author><author><keyname>Casset</keyname><forenames>F.</forenames><affiliation>LETI</affiliation></author><author><keyname>Ancey</keyname><forenames>P.</forenames><affiliation>ST-Crolles</affiliation></author><author><keyname>Judong</keyname><forenames>F.</forenames><affiliation>ST-Crolles</affiliation></author><author><keyname>Talbot</keyname><forenames>A.</forenames><affiliation>ST-Crolles</affiliation></author><author><keyname>Quenouillere</keyname><forenames>R.</forenames><affiliation>LETI</affiliation></author><author><keyname>Renaud</keyname><forenames>D.</forenames><affiliation>LETI</affiliation></author><author><keyname>Borel</keyname><forenames>S.</forenames><affiliation>LETI</affiliation></author><author><keyname>Florin</keyname><forenames>B.</forenames><affiliation>LETI</affiliation></author><author><keyname>Buchaillot</keyname><forenames>L.</forenames><affiliation>IEMN</affiliation></author></authors><title>Silicon on Nothing Mems Electromechanical Resonator</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257711</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  The very significant growth of the wireless communication industry has
spawned tremendous interest in the development of high performances radio
frequencies (RF) components. Micro Electro Mechanical Systems (MEMS) are good
candidates to allow reconfigurable RF functions such as filters, oscillators or
antennas. This paper will focus on the MEMS electromechanical resonators which
show interesting performances to replace SAW filters or quartz reference
oscillators, allowing smaller integrated functions with lower power
consumption. The resonant frequency depends on the material properties, such as
Young's modulus and density, and on the movable mechanical structure dimensions
(beam length defined by photolithography). Thus, it is possible to obtain multi
frequencies resonators on a wafer. The resonator performance (frequency,
quality factor) strongly depends on the environment, like moisture or pressure,
which imply the need for a vacuum package. This paper will present first
resonator mechanisms and mechanical behaviors followed by state of the art
descriptions with applications and specifications overview. Then MEMS resonator
developments at STMicroelectronics including FEM analysis, technological
developments and characterization are detailed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3052</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3052</id><created>2008-02-21</created><authors><author><keyname>Moulin</keyname><forenames>J.</forenames><affiliation>IEF</affiliation></author><author><keyname>Woytasik</keyname><forenames>M.</forenames><affiliation>IEF</affiliation></author><author><keyname>Martincic</keyname><forenames>E.</forenames><affiliation>IEF</affiliation></author><author><keyname>Dufour-Gergam</keyname><forenames>E.</forenames><affiliation>IEF</affiliation></author></authors><title>Copper Planar Microcoils Applied to Magnetic Actuation</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257693</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Recent advances in microtechnology allow realization of planar microcoils.
These components are integrated in MEMS as magnetic sensor or actuator. In the
latter case, it is necessary to maximize the effective magnetic field which is
proportional to the current passing through the copper track and depends on the
distance to the generation microcoil. The aim of this work was to determine the
optimal microcoil design configuration for magnetic field generation. The
results were applied to magnetic actuation, taking into account technological
constraints. In particular, we have considered different realistic
configurations that involve a magnetically actuated device coupled to a
microcoil. Calculations by a semi-analytical method using Matlab software were
validated by experimental measurements. The copper planar microcoils are
fabricated by U.V. micromoulding on different substrates: flexible polymer
(Kapton) and silicate on silicon. They are constituted by a spiral-like
continuous track. Their total surface is about 1 mm2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3053</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3053</id><created>2008-02-21</created><authors><author><keyname>Szente-Varga</keyname><forenames>D.</forenames></author><author><keyname>Horvath</keyname><forenames>D.</forenames></author><author><keyname>Rencz</keyname><forenames>M.</forenames></author></authors><title>Ni-MH battery modelling for ambient intelligence applications</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257712</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Mobile devices, like sensor networks and MEMS actuators use mobile power
supplies to ensure energy for their operation. These are mostly batteries. The
lifetime of the devices depends on the power consumption and on the quality and
capacitance of the battery. Though the integrated circuits and their power
consumption improve continually, their clock frequency also increases with the
time, and the resultant power consumption seems not to vary, or slightly
increase. On the other hand, the properties of batteries are developing much
slower, necessitating the optimization of their usage on system level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3054</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3054</id><created>2008-02-21</created><authors><author><keyname>Shamshirsaz</keyname><forenames>M.</forenames></author><author><keyname>Bahrami</keyname><forenames>M.</forenames></author><author><keyname>Asgari</keyname><forenames>M. B.</forenames></author><author><keyname>Tayefeh</keyname><forenames>M.</forenames></author></authors><title>Analysis of polysilicon micro beams buckling with temperature-dependent
  properties</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257689</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  The suspended electrothermal polysilicon micro beams generate displacements
and forces by thermal buckling effects. In the previous electro-thermal and
thermo-elastic models of suspended polysilicon micro beams, the
thermo-mechanical properties of polysilicon have been considered constant over
a wide rang of temperature (20- 900 degrees C). In reality, the
thermo-mechanical properties of polysilicon depend on temperature and change
significantly at high temperatures. This paper describes the development and
validation of theoretical and Finite Element Model (FEM) including the
temperature dependencies of polysilicon properties such as thermal expansion
coefficient and Young's modulus. In the theoretical models, two parts of
elastic deflection model and thermal elastic model of micro beams buckling have
been established and simulated. Also, temperature dependent buckling of
polysilicon micro beam under high temperature has been modeled by Finite
Element Analysis (FEA). Analytical results and numerical results using FEA are
compared with experimental data available in literature. Their reasonable
agreement validates analytical model and FEM. This validation indicates the
importance of including temperature dependencies of polysilicon
thermo-mechanical properties such as Coefficient of Thermal Expansion (CTE) in
the previous models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3055</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3055</id><created>2008-02-21</created><authors><author><keyname>Michael</keyname><forenames>S.</forenames></author><author><keyname>Kurth</keyname><forenames>S.</forenames></author><author><keyname>Klattenhoff</keyname><forenames>J.</forenames></author><author><keyname>Geissler</keyname><forenames>H.</forenames></author><author><keyname>Hering</keyname><forenames>S.</forenames></author></authors><title>Parameter Identification of Pressure Sensors by Static and Dynamic
  Measurements</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257690</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Fast identification methods of pressure sensors are investigated. With regard
to a complete accurate sensor parameter identification two different
measurement methods are combined. The approach consists on one hand in
performing static measurements - an applied pressure results in a membrane
deformation measured interferometrically and the corresponding output voltage.
On the other hand optical measurements of the modal responses of the sensor
membranes are performed. This information is used in an inverse identification
algorithm to identify geometrical and material parameters based on a FE model.
The number of parameters to be identified is thereby generally limited only by
the number of measurable modal frequencies. A quantitative evaluation of the
identification results permits furthermore the classification of processing
errors like etching errors. Algorithms and identification results for membrane
thickness, intrinsic stress and output voltage will be discussed in this
contribution on the basis of the parameter identification of relative pressure
sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3056</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3056</id><created>2008-02-21</created><authors><author><keyname>Lin</keyname><forenames>T. -H.</forenames></author><author><keyname>Yang</keyname><forenames>H.</forenames></author><author><keyname>Shyu</keyname><forenames>Ruey Fang</forenames></author><author><keyname>Chao</keyname><forenames>C. -K.</forenames></author></authors><title>New Horizontal Frustum Optical Waveguide Fabrication Using UV Proximity
  Printing</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257709</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper presents a novel method to fabricate the horizontal frustum
structure as a planar optical waveguide by using the proximity printing
technique. A horizontal frustum optical waveguide with a both lateral and
vertical taper structure was produced. The orthogonal and inclined masks with
the diffraction effect were employed in lithography process. This method can
precisely control each horizontal frustum optical waveguide geometric profile
in the fabrication process. The horizontal frustum optical waveguide and its
array with the same inclined angle were generated. The beam propagation
simulation software (BPM_CAD) was used to modeling the optical performance. The
simulation results reveal that the mode profile matched into horizontal frustum
optical waveguide and fiber from the laser diode. The optical loss of
horizontal hemi-frustum structure of optical waveguides was less than 0.2dB.
The horizontal hemifrustum waveguide will be used for fiber coupling on boards
for further optical communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3057</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3057</id><created>2008-02-21</created><authors><author><keyname>Iannacci</keyname><forenames>J.</forenames></author><author><keyname>Tian</keyname><forenames>J.</forenames></author><author><keyname>Gaddi</keyname><forenames>R.</forenames></author><author><keyname>Gnudi</keyname><forenames>A.</forenames></author><author><keyname>Bartek</keyname><forenames>M.</forenames></author></authors><title>A Fully Parameterized Fem Model for Electromagnetic Optimization of an
  RF Mems Wafer Level Package</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257710</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this work, we present a fully parameterized capped transmission line model
for electromagnetic optimization of a wafer level package (WLP) for RF MEMS
applications using the Ansoft HFSS-TM electromagnetic simulator. All the
degrees of freedom (DoF's) in the package fabrication can be modified within
the model in order to optimize for losses and mismatch (capacitive and
inductive couplings) introduced by the cap affecting the MEMS RF behaviour.
Ansoft HFSS-TM was also validated for the simulation of capped RF MEMS devices
by comparison against experimental data. A test run of capped 50 transmission
lines and shorts was fabricated and tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3059</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3059</id><created>2008-02-21</created><authors><author><keyname>Ju</keyname><forenames>Y.</forenames></author><author><keyname>Kobayashi</keyname><forenames>T.</forenames></author><author><keyname>Soyama</keyname><forenames>H.</forenames></author></authors><title>Development of a Nanostructual Microwave Probe Based on GaAs</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257707</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  With the development of nanotechnology, the measurement of electrical
properties in local area of materials and devices has become a great need.
Although a lot kind of scanning probe microscope have been developed for
satisfying the requirement of nanotechnology, a microscope technique which can
determine electrical properties in local area of materials and devices is not
yet developed. Recently, microwave microscope has been an interest to many
researchers, due to its potential in the evaluation of electrical properties of
materials and devices. The advance of microwave is that the response of
materials is directly relative to the electromagnetic properties of materials.
However, because of the problem of the structure of probes, nanometer-scale
resolution has not been successful. To achieve the goal, a new structure
microwave probe is required. In this paper, we report a nanostructural
microwave probe. To restrain the attenuation of microwave in the probe, GaAs
was used as the substrate of the probe. To obtain the desired structure, wet
etching was used to fabricate the probe. Different with the dry etching, a
side-etching will occur under the etching mask. Utilizing this property, a
micro tip can be fabricated by etching a wafer, of which a small mask was
introduced on the surface in advance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3060</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3060</id><created>2008-02-21</created><authors><author><keyname>Sterken</keyname><forenames>T.</forenames></author><author><keyname>Altena</keyname><forenames>Geert</forenames></author><author><keyname>Fiorini</keyname><forenames>P.</forenames></author><author><keyname>Puers</keyname><forenames>R.</forenames></author></authors><title>Characterisation of an Electrostatic Vibration Harvester</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257705</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Harvesting energy from ambient vibration is proposed as an alternative to
storage based power supplies for autonomous systems. The system presented
converts the mechanical energy of a vibration into electrical energy by means
of a variable capacitor, which is polarized by an electret. A lumped element
model is used to study the generator and design a prototype. The device has
been micromachined in silicon, based on a two-wafer process. The prototype was
successfully tested, both using an external polarization source and an
electret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3061</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3061</id><created>2008-02-21</created><authors><author><keyname>Wang</keyname><forenames>J.</forenames><affiliation>LGIPM</affiliation></author><author><keyname>Gong</keyname><forenames>Y.</forenames><affiliation>LGIPM</affiliation></author><author><keyname>Abba</keyname><forenames>G.</forenames><affiliation>LGIPM</affiliation></author><author><keyname>Chen</keyname><forenames>Kui</forenames></author><author><keyname>Shi</keyname><forenames>J.</forenames></author><author><keyname>Cai</keyname><forenames>G.</forenames></author></authors><title>Surface Generation Analysis in Micro End-Milling Considering the
  Influences of Grain</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257686</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Micro end-milling method is a universal micro manufacturing method, which can
be used to fabricating complex 3D structures and parts with many materials. But
compared with their micrometer order size, their surface roughness quality is
not satisfied. In this paper, the different metal phase grains influences are
researched, and the micro end-milling process is described while the material
is anisotropic. In this paper, the physical characteristics of different
grains, especially friction coefficient and elastic module, are very critical
to determine the chip formation process and surface generation. The chip is
often discontinues because of the grain boundary effect. Through the micro
end-milling experiment, the bottom surface results correlate very well with the
theory analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3062</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3062</id><created>2008-02-21</created><authors><author><keyname>Bruschi</keyname><forenames>P.</forenames></author><author><keyname>Nurra</keyname><forenames>V.</forenames></author></authors><title>An Integrated Circuit Compatible Compact Package for Thermal Gas
  Flowmeters</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257691</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  An original packaging method suitable for integrated thermal mass flow
sensors is presented. The method consists in the application of a plastic
transparent adapter to the chip surface. The adapter is sealed to the chip
surface by means of a thermal procedure. By this approach it is possible to
selectively convey the fluid flow to reduced chip areas, avoiding contact with
the pads. Fabrication and testing of a very compact flow sensor is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3063</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3063</id><created>2008-02-21</created><authors><author><keyname>Paracha</keyname><forenames>A. M.</forenames><affiliation>ESYCOM-Esiee</affiliation></author><author><keyname>Basset</keyname><forenames>Ph.</forenames><affiliation>ESYCOM-Esiee</affiliation></author><author><keyname>Marty</keyname><forenames>F.</forenames><affiliation>ESYCOM-Esiee</affiliation></author><author><keyname>Chasin</keyname><forenames>A. Vaisman</forenames><affiliation>ESYCOM-Esiee</affiliation></author><author><keyname>Poulichet</keyname><forenames>P.</forenames><affiliation>ESYCOM-Esiee</affiliation></author><author><keyname>Bourouina</keyname><forenames>T.</forenames><affiliation>ESYCOM-Esiee</affiliation></author></authors><title>A High Power Density Electrostatic Vibration-to-Electric Energy
  Converter Based On An In-Plane Overlap Plate (IPOP) Mechanism</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257704</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this paper, design, fabrication and characterization issues of a bulk
silicon-based, vibration powered, electric energy generator are addressed. The
converter is based on an In-Plane Overlap Plate (IPOP) configuration [1].
Measurements have shown that with a theoretically lossless electronics and a
starting voltage of 5 V, power density of 58 $\mu$W/cm3 is achievable at the
resonance frequency of 290 Hz. It can be further improved by reducing the
parasitic capacitance, which can be achieved by silicon etching, but a
considerable mass is lost. In [2], it is shown that 19% of mass reduction
improves power density from 12.95 $\mu$W/cm3 to 59 $\mu$W/cm3. Hence an
enhancement in fabrication process is proposed, which is termed as Backside
DRIE. It helps in increasing power density without loosing an important
quantity of mass. Simulations have shown that 2.5% of mass removal improves
power density up to 76.71 $\mu$W/cm3. Initial simulation results and problems
of associated electronics are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3064</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3064</id><created>2008-02-21</created><authors><author><keyname>Ng</keyname><forenames>S. H.</forenames></author><author><keyname>Tjeung</keyname><forenames>R. T.</forenames></author><author><keyname>Wang</keyname><forenames>Z. F.</forenames></author><author><keyname>Lu</keyname><forenames>A. C. W.</forenames></author><author><keyname>Rodriguez</keyname><forenames>I.</forenames></author><author><keyname>De Rooij</keyname><forenames>N.</forenames></author></authors><title>Formation of Embedded Microstructures by Thermal Activated Solvent
  Bonding</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257683</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  We present a thermal activated solvent bonding technique for the formation of
embedded microstrucutres in polymer. It is based on the temperature dependent
solubility of polymer in a liquid that is not a solvent at room temperature.
With thermal activation, the liquid is transformed into a solvent of the
polymer, creating a bonding capability through segmental or chain
interdiffusion at the bonding interface. The technique has advantages over the
more commonly used thermal bonding due to its much lower operation temperature
(30 degrees C lower than the material's Tg), lower load, as well as shorter
time. Lap shear test indicated bonding shear strength of up to 2.9 MPa. Leak
test based on the bubble emission technique showed that the bonded microfluidic
device can withstand at least 6 bars (87 psi) of internal pressure (gauge) in
the microchannel. This technique can be applied to other systems of polymer and
solvent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3065</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3065</id><created>2008-02-21</created><authors><author><keyname>Jakovenko</keyname><forenames>J.</forenames></author><author><keyname>Husak</keyname><forenames>M.</forenames></author><author><keyname>Lalinskytfh</keyname><forenames>T.</forenames></author><author><keyname>Drzik</keyname><forenames>M.</forenames></author><author><keyname>Vanko</keyname><forenames>G.</forenames></author></authors><title>Design and Modeling of Micromechanical GaAs based Hot Plate for Gas
  Sensors</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257678</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  For modern Gas sensors, high sensitivity and low power are expected. This
paper discusses design, simulation and fabrication of new Micromachined Thermal
Converters (MTCs) based on GaAs developed for Gas sensors. Metal oxide gas
sensors generally work in high temperature mode that is required for chemical
reactions to be performed between molecules of the specified gas and the
surface of sensing material. There is a low power consumption required to
obtain the operation temperatures in the range of 200 to 500 oC. High thermal
isolation of these devices solves consumption problem and can be made by
designing of free standing micromechanical hot plates. Mechanical stability and
a fast thermal response are especially significant parameters that can not be
neglected. These characteristics can be achieved with new concept of GaAs
thermal converter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3066</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3066</id><created>2008-02-21</created><authors><author><keyname>Smetana</keyname><forenames>W.</forenames></author><author><keyname>Unger</keyname><forenames>M.</forenames></author></authors><title>Set-up and characterization of a humidity sensor realized in
  LTCC-technology</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257674</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  A new type of integrated temperature and humidity sensor applying
LTCC-technology has been developed and characterized. In this approach, sensing
elements are implemented using heated metal resistors (Pt-elements), where one
is exposed to the humid environment that causes the sensor element to cool down
with increased humidity, while the other one is sealed from the environment.
Sensor design is based on FEA (Finite Element Analyses) where the critical
design parameters have been analyzed with regard to the performance
characteristic of the device. The set-up of sensor element will be shown and
the functional capability will be demonstrated by experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3067</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3067</id><created>2008-02-21</created><authors><author><keyname>Wang</keyname><forenames>Z.</forenames></author><author><keyname>Leonov</keyname><forenames>V.</forenames></author><author><keyname>Fiorini</keyname><forenames>P.</forenames></author><author><keyname>Van Hoof</keyname><forenames>C.</forenames></author></authors><title>Micromachined Polycrystalline Sige-Based Thermopiles for Micropower
  Generation on Human Body</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257703</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper presents a polycrystalline silicon germanium (poly-SiGe)
thermopile specially designed for thermoelectric generators used on human body.
Both the design of the single thermocouple and the arrangement of the
thermocouple array have been described. A rim structure has been introduced in
order to increase the temperature difference across the thermocouple junctions.
The modeling of the thermocouple and the thermopile has been performed
analytically and numerically. An output power of about 1 $\mu$W at an output
voltage of more than 1 V is expected from the current design of thermopiles in
a watch-size generator. The key material properties of the poly-SiGe have been
measured. The thermopile has been fabricated and tested. Experimental results
clearly demonstrate the advantage of the rim structure in increasing output
voltage. In presence of forced convection, the output voltage of a non-released
thermopile can increase from about 53 mV/K/cm2 to about 130 mV/K/cm2 after the
rim structure is formed. A larger output voltage from the thermopile is
expected upon process completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3068</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3068</id><created>2008-02-21</created><authors><author><keyname>Chen</keyname><forenames>B.</forenames></author><author><keyname>Wei</keyname><forenames>J.</forenames></author><author><keyname>Tay</keyname><forenames>Francis</forenames></author><author><keyname>Wong</keyname><forenames>Y. T.</forenames></author><author><keyname>Iliescu</keyname><forenames>C.</forenames></author></authors><title>Silicon microneedles array with biodegradable tips for transdermal drug
  delivery</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257701</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper presents the fabrication process, characterization results and
basic functionality of silicon microneedles array with biodegradable tips. In
order to avoid the main problems related to silicon microneedles : broking of
the top part of the needles inside the skin, a simple solution can be
fabrication of microneedles array with biodegradable tips. The silicon
microneedles array was fabricated by using reactive ion etching while the
biodegradable tips were performed using and anodization process that generates
selectively porous silicon only on the top part of the skin. The paper presents
also the results of in vitro release of calcein using microneedles array with
biodegradable tips
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3069</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3069</id><created>2008-02-21</created><authors><author><keyname>Wu</keyname><forenames>M. C.</forenames></author><author><keyname>Chang</keyname><forenames>J. S.</forenames></author><author><keyname>Yang</keyname><forenames>C. -K.</forenames></author></authors><title>2-D Analysis of Enhancement of Analytes Adsorption Due to Flow Stirring
  by Electrothermal Force in The Microcantilever Sensor</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257666</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Ac electrokinetic flows are commonly used for manipulating micron-scale
particles in a biosensor system. At the solid-liquid state there are two kinds
of processes in the reaction between analytes and ligands: the mass transport
process and the chemical reaction process. The mass transport process is
related to convection and diffusion. Total or partial limit of mass transport
would retard the diffusion from the bulk fluid to the interface of reaction.
This effect decreases the possibility of adsorption of analyte and ligand
because the chemical reaction is faster than the diffusion. In order to solve
this problem, we apply an ac electric field to induce a vortex field by the
electrothermal effect, which helps in increasing the rate of diffusion. By
using the finite element analysis software, COMSOL Multiphysics, we optimized
several parameters of the microelectrode structures and the position of the
reacting surface, i.e. the microcantilever, by a simplified 2-D model and a 3-D
model. It is successful in accelerating the reacting rate of the molecule which
is limited by mass transport. The factor of the efficiency is about 1.429 when
the operating voltage is 15 Vrms peak-to-peak. In addition, the surface
concentration of the complex on the microcantilever has been simulated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3070</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3070</id><created>2008-02-21</created><authors><author><keyname>Ma</keyname><forenames>H. K.</forenames></author><author><keyname>Hou</keyname><forenames>B. R.</forenames></author><author><keyname>Wu</keyname><forenames>H. Y.</forenames></author><author><keyname>Lin</keyname><forenames>C. Y.</forenames></author><author><keyname>Gao</keyname><forenames>J. J.</forenames></author><author><keyname>Kou</keyname><forenames>M. C.</forenames></author></authors><title>Development and Application of a Diaphragm Micro-Pump with Piezoelectric
  Device</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257702</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this study, a new type of thin, compact, and light weighed diaphragm
micro-pump has been successfully developed to actuate the liquid by the
vibration of a diaphragm. The micro-diaphragm pump with two valves is
fabricated in an aluminum case by using highly accurate CNC machine, and the
cross-section dimension is 5mm x 8mm. Both valves and diaphragm are
manufactured from PDMS. The amplitude of vibration by a piezoelectric device
produces an oscillating flow which may change the chamber volume by changing
the curvature of a diaphragm. Several experimental set-ups for performance test
in a single micro-diaphragm pump, isothermal flow open system, and a closed
liquid cooling system is designed and implemented. The performance of one-side
actuating micro-diaphragm pump is affected by the design of check valves,
diaphragm, piezoelectric device, chamber volume, input voltage and frequency.
The measured maximum flow rate of present design is 72 ml/min at zero total
pump head in the range of operation frequency 70-180 Hz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3071</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3071</id><created>2008-02-21</created><authors><author><keyname>Lan</keyname><forenames>W. P.</forenames></author><author><keyname>Chang</keyname><forenames>J. S.</forenames></author><author><keyname>Wu</keyname><forenames>K. C.</forenames></author><author><keyname>Shih</keyname><forenames>Y. C.</forenames></author></authors><title>Simulation of valveless micropump and mode analysis</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257665</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, Lago Maggiore : Italie (2007)</journal-ref><abstract>  In this work, a 3-D simulation is performed to study for the solid-fluid
coupling effect driven by piezoelectric materials and utilizes asymmetric
obstacles to control the flow direction. The result of simulation is also
verified. For a micropump, it is crucial to find the optimal working frequency
which produce maximum net flow rate. The PZT plate vibrates under the first
mode, which is symmetric. Adjusting the working frequency, the maximum flow
rate can be obtained. For the micrpump we studied, the optimal working
frequency is 3.2K Hz. At higher working frequency, say 20K Hz, the fluid-solid
membrane may come out a intermediate mode, which is different from the first
mode and the second mode. It is observed that the center of the mode drifts.
Meanwhile, the result shows that a phase shift lagging when the excitation
force exists in the vibration response. Finally, at even higher working
frequency, say 30K Hz, a second vibration mode is observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3072</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3072</id><created>2008-02-21</created><authors><author><keyname>Wang</keyname><forenames>Yu-Hsiang</forenames></author><author><keyname>Hsiao</keyname><forenames>C. -C.</forenames></author><author><keyname>Lee</keyname><forenames>Chia-Yen</forenames></author><author><keyname>Ma</keyname><forenames>R. -H.</forenames></author><author><keyname>Chou</keyname><forenames>Po-Cheng</forenames></author></authors><title>Enhanced Sensing Characteristics in MEMS-based Formaldehyde Gas Sensor</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257700</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This study has successfully demonstrated a novel self-heating formaldehyde
gas sensor based on a thin film of NiO sensing layer. A new fabrication process
has been developed in which the Pt micro heater and electrodes are deposited
directly on the substrate and the NiO thin film is deposited above on the micro
heater to serve as sensing layer. Pt electrodes are formed below the sensing
layer to measure the electrical conductivity changes caused by formaldehyde
oxidation at the oxide surface. Furthermore, the upper sensing layer and
NiO/Al2O3 co-sputtering significantly increases the sensitivity of the gas
sensor, improves its detection limit capability. The microfabricated
formaldehyde gas sensor presented in this study is suitable not only for
industrial process monitoring, but also for the detection of formaldehyde
concentrations in buildings in order to safeguard human health.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3073</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3073</id><created>2008-02-21</created><authors><author><keyname>Grasser</keyname><forenames>L.</forenames><affiliation>IEF</affiliation></author><author><keyname>Mathias</keyname><forenames>H.</forenames><affiliation>IEF</affiliation></author><author><keyname>Parrain</keyname><forenames>F.</forenames><affiliation>IEF</affiliation></author><author><keyname>Roux</keyname><forenames>X. Le</forenames><affiliation>IEF</affiliation></author><author><keyname>Gilles</keyname><forenames>J. -P.</forenames><affiliation>IEF</affiliation></author></authors><title>Mems Q-Factor Enhancement Using Parametric Amplification: Theoretical
  Study and Design of a Parametric Device</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257698</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Parametric amplification is an interesting way of artificially increasing a
MEMS Quality factor and could be helpful in many kinds of applications. This
paper presents a theoretical study of this principle, based on Matlab/Simulink
simulations, and proposes design guidelines for parametric structures. A new
device designed with this approach is presented together with the corresponding
FEM simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3074</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3074</id><created>2008-02-21</created><authors><author><keyname>Wang</keyname><forenames>G. -J.</forenames></author><author><keyname>Ho</keyname><forenames>K. -H.</forenames></author><author><keyname>Hsueh</keyname><forenames>C. -C.</forenames></author></authors><title>Biodegradable Polylactic Acid (PLA) Microstructures for Scaffold
  Applications</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257699</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this research, we present a simple and cost effective soft lithographic
process to fabricate PLA scaffolds for tissue engineering. In which, the
negative photoresist JSR THB-120N was spun on a glass subtract followed by
conventional UV lithographic processes to fabricate the master to cast the PDMS
elastomeric mold. A thin poly(vinyl alcohol) (PVA) layer was used as a mode
release such that the PLA scaffold can be easily peeled off. The PLA precursor
solution was then cast onto the PDMS mold to form the PLA microstructures.
After evaporating the solvent, the PLA microstructures can be easily peeled off
from the PDMS mold. Experimental results show that the desired microvessels
scaffold can be successfully transferred to the biodegradable polymer PLA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3075</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3075</id><created>2008-02-21</created><authors><author><keyname>Camon</keyname><forenames>H.</forenames><affiliation>LAAS</affiliation></author><author><keyname>Ganibal</keyname><forenames>C.</forenames><affiliation>LAAS</affiliation></author><author><keyname>Rapahoz</keyname><forenames>N.</forenames><affiliation>LETI</affiliation></author><author><keyname>Trzmiel</keyname><forenames>M.</forenames><affiliation>LETI</affiliation></author><author><keyname>Pisella</keyname><forenames>C.</forenames><affiliation>LETI</affiliation></author><author><keyname>Martinez</keyname><forenames>C.</forenames><affiliation>LETI</affiliation></author><author><keyname>Gilbert</keyname><forenames>K.</forenames><affiliation>LETI</affiliation></author><author><keyname>Valette</keyname><forenames>S.</forenames><affiliation>LETI</affiliation></author></authors><title>Solving functional reliability issue for an optical electrostatic switch</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257696</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this paper, we report the advantage of using AC actuating signal for
driving MEMS actuators instead of DC voltages. The study is based upon micro
mirror devices used in digital mode for optical switching operation. When the
pull-in effect is used, charge injection occurs when the micro mirror is
maintained in the deflected position. To avoid this effect, a geometrical
solution is to realize grounded landing electrodes which are electro-statically
separated from the control electrodes. Another solution is the use of AC signal
which eliminates charge injection particularly if a bipolar signal is used.
Long term experiments have demonstrated the reliability of such a signal
command to avoid injection of electric charges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3076</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3076</id><created>2008-02-21</created><authors><author><keyname>Soma</keyname><forenames>A.</forenames></author><author><keyname>De Pasquale</keyname><forenames>G.</forenames></author></authors><title>Identification of Test Structures for Reduced Order Modeling of the
  Squeeze Film Damping in Mems</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257694</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this study the dynamic behaviour of perforated microplates oscillating
under the effect of squeeze film damping is analyzed. A numerical approach is
adopted to predict the effects of damping and stiffness transferred from the
surrounding ambient air to oscillating structures ; the effect of hole's cross
section and plate's extension is observed. Results obtained by F.E.M. models
are compared with experimental measurements performed by an optical
interferometric microscope.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3077</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3077</id><created>2008-02-21</created><authors><author><keyname>Ghorba</keyname><forenames>M. El</forenames></author><author><keyname>Andr&#xe9;</keyname><forenames>N.</forenames></author><author><keyname>Sobieski</keyname><forenames>S.</forenames></author><author><keyname>Raskin</keyname><forenames>J. -P.</forenames></author></authors><title>Out-of-Plane Cmos Compatible Magnetometers</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257692</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Three-dimensional MEMS magnetometers with use of residual stresses in thin
multilayers cantilevers are presented. Half-loop cantilevers based on
Lorentz-force deflection convert magnetic flux in changes, thanks to
piezoresistive transducers mounted in Wheatstone bridge. Magnetic field in the
order of 10 Gauss was measured with a sensitivity of 0.015 mV/Gauss. A Finite
Element Model of the device has been developed with Ansys for static and
dynamic simulations. Novel out-of-plane ferromagnetic nickel plate magnetometer
is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3078</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3078</id><created>2008-02-21</created><authors><author><keyname>Soulimane</keyname><forenames>S.</forenames><affiliation>LETI</affiliation></author><author><keyname>Casset</keyname><forenames>F.</forenames><affiliation>LETI</affiliation></author><author><keyname>Chapuis</keyname><forenames>F.</forenames><affiliation>LETI</affiliation></author><author><keyname>Charvet</keyname><forenames>P. -L.</forenames><affiliation>LETI</affiliation></author><author><keyname>a&#xef;d</keyname><forenames>M.</forenames><affiliation>LETI</affiliation></author></authors><title>Tuneable Capacitor based on dual picks profile of the sacrificial layer</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257687</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this paper, we present a novel dual gap tuneable capacitor process based
on the profile of the sacrificial layer. This profile involves a tri-layer
photo-resist process with only one mask level. This realization is based on a
special profile of the sacrificial layer designed by two picks. The mechanism
of the sacrificial layer realisation is dependent on resist thickness, resist
formulation (viscosity, type of polymer and/or solvent, additives...), design
of the patterned layer (size or width) and the conditions under which this
layer is prepared: thermal treatment, etch back processes... In this
communication we demonstrate influence of the later parameters and discuss how
a dual pick profile was achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3079</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3079</id><created>2008-02-21</created><authors><author><keyname>Liou</keyname><forenames>J. -C.</forenames></author><author><keyname>Tseng</keyname><forenames>F. -G.</forenames></author></authors><title>Reduced 30% scanning time 3D multiplexer integrated circuit applied to
  large array format 20KHZ frequency inkjet print heads</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257671</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Enhancement of the number and array density of nozzles within an inkjet head
chip is one of the keys to raise the printing speed and printing resolutions.
However, traditional 2D architecture of driving circuits can not meet the
requirement for high scanning speed and low data accessing points when nozzle
numbers greater than 1000. This paper proposes a novel architecture of
high-selection-speed three-dimensional data registration for inkjet
applications. With the configuration of three-dimensional data registration,
the number of data accessing points as well as the scanning lines can be
greatly reduced for large array inkjet printheads with nozzles numbering more
than 1000. This IC (Integrated Circuit) architecture involves three-dimensional
multiplexing with the provision of a gating transistor for each ink firing
resistor, where ink firing resistors are triggered only by the selection of
their associated gating transistors. Three signals: selection (S), address (A),
and power supply (P), are employed together to activate a nozzle for droplet
ejection. The smart printhead controller has been designed by a 0.35 um CMOS
process with a total circuit area, 2500 x 500 microm2, which is 80% of the
cirucuit area by 2D configuration for 1000 nozzles. Experiment results
demonstrate the functionality of the fabricated IC in operation, signal
transmission and a potential to control more than 1000 nozzles with only 31
data access points and reduced 30% scanning time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3080</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3080</id><created>2008-02-21</created><authors><author><keyname>Chen</keyname><forenames>J. -S.</forenames></author><author><keyname>Chen</keyname><forenames>S. -H.</forenames></author><author><keyname>Wu</keyname><forenames>K. -C.</forenames></author></authors><title>Analysis of Asymmetric Piezoelectric Composite Beam</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257688</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper deals with the vibration analysis of an asymmetric composite beam
composed of glass a piezoelectric material. The Bernoulli's beam theory is
adopted for mechanical deformations, and the electric potential field of the
piezoelectric material is assumed such that the divergence-free requirement of
the electrical displacements is satisfied. The accuracy of the analytic model
is assessed by comparing the resonance frequencies obtained by the analytic
model with those obtained by the finite element method. The model developed can
be used as a tool for designing piezoelectric actuators such as micro-pumps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3081</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3081</id><created>2008-02-21</created><authors><author><keyname>Jian</keyname><forenames>Z.</forenames></author><author><keyname>Yuanwei</keyname><forenames>Y.</forenames></author><author><keyname>Yong</keyname><forenames>Z.</forenames></author><author><keyname>Chen</keyname><forenames>Chen</forenames></author><author><keyname>Shixing</keyname><forenames>J.</forenames></author></authors><title>A High-Q Microwave MEMS Resonator</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257668</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  A High-Q microwave (K band) MEMS resonator is presented, which empolys
substrate integrated waveguide (SIW) and micromachined via-hole arrays by ICP
process. Nonradiation dielectric waveguide (NRD) is formed by metal filled
via-hole arrays and grounded planes. The three dimensional (3D) high
resistivity silicon substrate filled cavity resonator is fed by current probes
using CPW line. This monolithic resonator results in low cost, high performance
and easy integration with planar cicuits. The measured quality factor is beyond
180 and the resonance frequency is 21GHz.It shows a good agreement with the
simulation results. The chip size is only 4.7mm x 4.6mm x 0.5mm. Finally, as an
example of applications, a filter using two SIW resonators is designed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3082</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3082</id><created>2008-02-21</created><authors><author><keyname>Jung</keyname><forenames>E.</forenames></author><author><keyname>Manessis</keyname><forenames>D.</forenames></author><author><keyname>Neumann</keyname><forenames>A.</forenames></author><author><keyname>Bottcher</keyname><forenames>L.</forenames></author><author><keyname>Braun</keyname><forenames>T.</forenames></author><author><keyname>Bauer</keyname><forenames>J.</forenames></author><author><keyname>Reichl</keyname><forenames>H.</forenames></author><author><keyname>Iafelice</keyname><forenames>B.</forenames></author><author><keyname>Destro</keyname><forenames>F.</forenames></author><author><keyname>Gambari</keyname><forenames>R.</forenames></author></authors><title>Lamination And Microstructuring Technology for a Bio-Cell Multiwell
  array</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257685</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Microtechnology becomes a versatile tool for biological and biomedical
applications. Microwells have been established long but remained
non-intelligent up to now. Merging new fabrication techniques and handling
concepts with microelectronics enables to realize intelligent microwells
suitable for future improved cancer treatment. The described technology depicts
the basis for the fabrication of a elecronically enhanced microwell. Thin
aluminium sheets are structured by laser micro machining and laminated
successively to obtain registration tolerances of the respective layers of
5..10\^A$\mu$m. The microwells lasermachined into the laminate are with
50..80\^A$\mu$m diameter, allowing to hold individual cells within the well.
The individual process steps are described and results on the microstructuring
are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3083</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3083</id><created>2008-02-21</created><authors><author><keyname>Lin</keyname><forenames>Ming-Tzer</forenames></author><author><keyname>Shiu</keyname><forenames>K. -S.</forenames></author><author><keyname>Tong</keyname><forenames>Chi-Jia</forenames></author></authors><title>Monotonic and fatigue testing of spring-bridged freestanding microbeams
  application for MEMS</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257661</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Microelectromechanical systems (MEMS) technologies are developing rapidly
with increasing study of the design, fabrication and commercialization of
microscale systems and devices. Accurate knowledge on the mechanical behaviors
of thin film materials used for MEMS is important for successful design and
development of MEMS. Here a novel electroplating spring-bridge micro-tensile
specimen integrates pin-pin align holes, misalignment compensate spring, load
sensor beam and freestanding thin film is demonstrated and fabricated. The
specimen is fit into a specially designed micro-mechanical apparatus to carry
out a series of monotonic tensile testing on sub-micron freestanding thin
films. Certain thin films applicable as structure or motion gears in MEMS were
tested including sputtered gold, copper and tantalum nitride thin films. Metal
specimens were fabricated by sputtering; for tantalum nitride film samples,
nitrogen gas was introduced into the chamber during sputtering tantalum films
on the silicon wafer. The sample fabrication method involves three steps of
lithography and two steps of electroplating copper to hold a dog bone
freestanding thin film. Using standard wet etching or lift off techniques, a
series of microtensile specimens were patterned in metal thin films, holes, and
seed layer for spring and frame structure on the underlying silicon oxide
coated silicon substrate. Two steps of electroplating processing to distinct
spring and frame portion of the test chip. Finally, chemical etched away the
silicon oxide to separated electroplated specimen and silicon substrate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3085</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3085</id><created>2008-02-21</created><authors><author><keyname>Akashi</keyname><forenames>T.</forenames></author><author><keyname>Yoshimura</keyname><forenames>Y.</forenames></author></authors><title>Profile Control of a Borosilicate-Glass Groove Formed by Deep Reactive
  Ion Etching</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257684</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><doi>10.1088/0960-1317/18/10/105004</doi><abstract>  Deep reactive ion etching (DRIE) of borosilicate glass and profile control of
an etched groove are reported. DRIE was carried out using an anodically bonded
silicon wafer as an etching mask. We controlled the groove profile, namely
improving its sidewall angle, by removing excessively thick polymer film
produced by carbonfluoride etching gases during DRIE. Two fabrication processes
were experimentally compared for effective removal of the film : DRIE with the
addition of argon to the etching gases and a novel combined process in which
DRIE and subsequent ultrasonic cleaning in DI water were alternately carried
out. Both processes improved the sidewall angle, and it reached 85o independent
of the mask-opening width. The results showed the processes can remove
excessive polymer film on sidewalls. Accordingly, the processes are an
effective way to control the groove profile of borosilicate glass.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3086</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3086</id><created>2008-02-21</created><authors><author><keyname>Hamzah</keyname><forenames>A. A.</forenames></author><author><keyname>Husaini</keyname><forenames>Y.</forenames></author><author><keyname>Husaini</keyname><forenames>Y.</forenames></author><author><keyname>Majlis</keyname><forenames>B. Y.</forenames></author><author><keyname>Ahmad</keyname><forenames>I.</forenames></author></authors><title>Selection of High Strength Encapsulant for MEMS Devices Undergoing High
  Pressure Packaging</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257660</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Deflection behavior of several encapsulant materials under uniform pressure
was studied to determine the best encapsulant for MEMS device. Encapsulation is
needed to protect movable parts of MEMS devices during high pressure transfer
molded packaging process. The selected encapsulant material has to have surface
deflection of less than 5 ?m under 100 atm vertical loading. Deflection was
simulated using CoventorWare ver.2005 software and verified with calculation
results obtained using shell bending theory. Screening design was used to
construct a systematic approach for selecting the best encapsulant material and
thickness under uniform pressure up to 100 atm. Materials considered for this
study were polyimide, parylene C and carbon based epoxy resin. It was observed
that carbon based epoxy resin has deflection of less than 5 ?m for all
thickness and pressure variations. Parylene C is acceptable and polyimide is
unsuitable as high strength encapsulant. Carbon based epoxy resin is considered
the best encapsulation material for MEMS under high pressure packaging process
due to its high strength.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3087</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3087</id><created>2008-02-21</created><authors><author><keyname>Wang</keyname><forenames>G. -J.</forenames></author><author><keyname>Chen</keyname><forenames>W. -Z.</forenames></author><author><keyname>Chang</keyname><forenames>K. J.</forenames></author></authors><title>A Two-Step Etching Method to Fabricate Nanopores in Silicon</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257682</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  A cost effectively method to fabricate nanopores in silicon by only using the
conventional wet-etching technique is developed in this research. The main
concept of the proposed method is a two-step etching process, including a
premier double-sided wet etching and a succeeding track-etching. A special
fixture is designed to hold the pre-etched silicon wafer inside it such that
the track-etching can be effectively carried out. An electrochemical system is
employed to detect and record the ion diffusion current once the pre-etched
cavities are etched into a through nanopore. Experimental results indicate that
the proposed method can cost effectively fabricate nanopores in silicon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3088</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3088</id><created>2008-02-21</created><authors><author><keyname>Bedani</keyname><forenames>M.</forenames></author><author><keyname>Carozza</keyname><forenames>F.</forenames></author><author><keyname>Gaddi</keyname><forenames>R.</forenames></author><author><keyname>Gnudi</keyname><forenames>A.</forenames></author><author><keyname>Margesin</keyname><forenames>B.</forenames></author><author><keyname>Giacomozzi</keyname><forenames>F.</forenames></author></authors><title>A Reconfigurable Impedance Matching Network Employing RF-MEMS Switches</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257653</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  We propose the design of a reconfigurable impedance matching network for the
lower RF frequency band, based on a developed RF-MEMS technology. The circuit
is composed of RF-MEMS ohmic relays, metal-insulator-metal (MIM) capacitors and
suspended spiral inductors, all integrated on a high resistivity Silicon
substrate. The presented circuit is well-suited for all applications requiring
adaptive impedance matching between two in principle unknown cascaded
RF-circuits. The fabrication and testing of a monolithic integrated prototype
in RF-MEMS technology from ITC-irst is currently underway.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3089</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3089</id><created>2008-02-21</created><authors><author><keyname>Schneider</keyname><forenames>P.</forenames></author><author><keyname>Reitz</keyname><forenames>S.</forenames></author><author><keyname>Wilde</keyname><forenames>A.</forenames></author><author><keyname>Elst</keyname><forenames>G.</forenames></author><author><keyname>Schwarz</keyname><forenames>P.</forenames></author></authors><title>Towards a Methodology for Analysis of Interconnect Structures for
  3D-Integration of Micro Systems</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257681</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Functional aspects as well as the influence of integration technology on the
system behavior have to be considered in the 3D integration design process of
micro systems. Therefore, information from different physical domains has to be
provided to designers. Due to the variety of structures and effects of
different physical domains, efficient modeling approaches and simulation
algorithms have to be combined. The paper describes a modular approach which
covers detailed analysis with PDE solvers and model generation for system level
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3090</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3090</id><created>2008-02-21</created><authors><author><keyname>Chaehoi</keyname><forenames>A.</forenames></author><author><keyname>Begbie</keyname><forenames>M.</forenames></author><author><keyname>Cornez</keyname><forenames>D.</forenames></author><author><keyname>Kirk</keyname><forenames>K.</forenames></author></authors><title>Modeling of a piezoelectric micro-scanner</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257679</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Micro-scanners have been widely used in many optical applications. The
micro-scanner presented in this paper uses multimorph-type bending actuators to
tilt a square plate mirror. This paper presents a complete analytical model of
the piezoelectric micro-scanner. This theoretical model based on strength of
material equations calculates the force generated by the multimorphs on the
mirror, the profile of the structure and the angular deflection of the mirror.
The proposed model, used to optimize the design of the piezoelectric silicon
micro-scanner, is intended for further HDL integration, allowing in this way
system level simulation and optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3091</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3091</id><created>2008-02-21</created><authors><author><keyname>Szucs</keyname><forenames>Z.</forenames></author><author><keyname>Rencz</keyname><forenames>M.</forenames></author></authors><title>A novel method for fatigue testing of MEMS devices containing movable
  elements</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257655</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this paper we present an electronic circuit for position or capacitance
estimation of MEMS electrostatic actuators based on a switched capacitor
technique. The circuit uses a capacitive divider configuration composed by a
fixed capacitor and the variable capacitance of the electrostatic actuator for
generating a signal that is a function of the input voltage and capacitive
ratio. The proposed circuit can be used to actuate and to sense position of an
electrostatic MEMS actuator without extra sensing elements. This approach is
compatible with the requirements of most analog feedback systems and the
circuit topology of pulsed digital oscillators (PDO).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3092</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3092</id><created>2008-02-21</created><authors><author><keyname>Levy</keyname><forenames>R.</forenames><affiliation>ONERA - Mfe</affiliation></author><author><keyname>Dupret</keyname><forenames>A.</forenames><affiliation>ONERA - Mfe</affiliation></author><author><keyname>Mathias</keyname><forenames>H.</forenames><affiliation>ONERA - Mfe</affiliation></author><author><keyname>Gilles</keyname><forenames>J. -P.</forenames><affiliation>ONERA - Mfe</affiliation></author><author><keyname>Parrain</keyname><forenames>F.</forenames><affiliation>ONERA - Mfe</affiliation></author><author><keyname>Eisenbeis</keyname><forenames>B.</forenames><affiliation>IEF</affiliation></author><author><keyname>Megherbi</keyname><forenames>S.</forenames><affiliation>IEF</affiliation></author></authors><title>Noise and thermal stability of vibrating micro-gyrometers preamplifiers</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257677</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  The preamplifier is a critical component of gyrometer's electronics. Indeed
the resolution of the sensor is limited by its signal to noise ratio, and the
gyrometer's thermal stability is limited by its gain drift. In this paper, five
different kinds of preamplifiers are presented and compared. Finally, the
design of an integrated preamplifier is shown in order to increase the gain
stability while reducing its noise and size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3093</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3093</id><created>2008-02-21</created><authors><author><keyname>Abel&#xe9;</keyname><forenames>N.</forenames><affiliation>LETI</affiliation></author><author><keyname>Grogg</keyname><forenames>D.</forenames><affiliation>LETI</affiliation></author><author><keyname>Hibert</keyname><forenames>C.</forenames><affiliation>LETI</affiliation></author><author><keyname>Casset</keyname><forenames>F.</forenames><affiliation>LETI</affiliation></author><author><keyname>Ancey</keyname><forenames>P.</forenames><affiliation>LETI</affiliation></author><author><keyname>Ionescu</keyname><forenames>A.</forenames></author></authors><title>0-level Vacuum Packaging RT Process for MEMS Resonators</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257657</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  A new Room Temperature (RT) 0-level vacuum package is demonstrated in this
work, using amorphous silicon (aSi) as sacrificial layer and SiO2 as structural
layer. The process is compatible with most of MEMS resonators and Resonant
Suspended-Gate MOSFET [1] fabrication processes. This paper presents a study on
the influence of releasing hole dimensions on the releasing time and hole
clogging. It discusses mass production compatibility in terms of packaging
stress during back-end plastic injection process. The packaging is done at room
temperature making it fully compatible with IC-processed wafers and avoiding
any subsequent degradation of the active devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3094</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3094</id><created>2008-02-21</created><authors><author><keyname>Soeraasen</keyname><forenames>O.</forenames></author><author><keyname>Ramstad</keyname><forenames>J. E.</forenames></author></authors><title>From MEMS Devices to Smart Integrated Systems</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257676</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  The smart integrated systems of tomorrow would demand a combination of
micromechanical components and traditional electronics. On-chip solutions will
be the ultimate goal. One way of making such systems is to implement the
mechanical parts in an ordinary CMOS process. This procedure has been used to
design an oscillator consisting of a resonating cantilever beam and a CMOS
Pierce feedback amplifier. The resonating frequency is changed if the beam is
bent by external forces. The paper describes central features of this procedure
and highlights the design considerations for the CMOS-MEMS oscillator. The
circuit is used as an example of a &quot;VLSI designer&quot; way of making future
integrated micromechanical and microelectronic systems on-chip. The possibility
for expansion to larger systems is reviewed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3095</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3095</id><created>2008-02-21</created><authors><author><keyname>Marenco</keyname><forenames>N.</forenames></author><author><keyname>Warnat</keyname><forenames>S.</forenames></author><author><keyname>Reinert</keyname><forenames>W.</forenames></author></authors><title>Interconnect Challenges in Highly Integrated MEMS/ASIC Subsystems</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257658</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Micromechanical devices like accelerometers or rotation sensors form an
increasing segment beneath the devices supplying the consumer market. A hybrid
integration approach to build smart sensor clusters for the precise detection
of movements in all spatial dimensions requires a large toolbox of interconnect
technologies, each with its own constraints regarding the total process
integration. Specific challenges described in this paper are post-CMOS
feedthroughs, front-to-front die contact arrays, vacuum-compliant lateral
interconnect and fine-pitch solder balling to finally form a Chip-Scale
System-in-Package (CSSiP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3097</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3097</id><created>2008-02-21</created><authors><author><keyname>Ballestra</keyname><forenames>A.</forenames></author><author><keyname>Brusa</keyname><forenames>E.</forenames></author><author><keyname>Munteanu</keyname><forenames>M. G.</forenames></author><author><keyname>Soma</keyname><forenames>A.</forenames></author></authors><title>Experimental Characterization of the static behaviour of
  microcatntilevers electrostatically actuated</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257675</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper concerns the experimental validation of some mathematical models
previously developed by the authors, to predict the static behaviour of
microelectrostatic actuators, basically free-clamped microbeams. This layout is
currently used in RF-MEMS design operation or even in material testing at
microscale. The analysis investigates preliminarily the static behaviour of a
set of microcantilevers bending in-plane. This investigation is aimed to
distinguish the geometrical linear behaviour, exhibited under small
displacement assumption, from the geometrical nonlinearity, caused by large
deflection. The applied electromechanical force, which nonlinearly depends on
displacement, charge and voltage, is predicted by a coupled-field approach,
based on numerical methods and herewith experimentally validated, by means of a
Fogale Zoomsurf 3D. Model performance is evaluated on pull-in prediction and on
the curve displacement vs. voltage. In fact, FEM nonlinear solution performed
by a coupled-field approach, available on commercial codes, and by a FEM
non-incremental approach are compared with linear solution, for different
values of the design parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3099</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3099</id><created>2008-02-21</created><authors><author><keyname>Pajot-Augy</keyname><forenames>E.</forenames><affiliation>NOPA</affiliation></author></authors><title>Nanobiosensors based on individual olfactory receptors</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257650</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In the SPOT-NOSED European project, nanoscale sensing elements bearing
olfactory receptors and grafted onto functionalized gold substrates are used as
odorant detectors to develop a new concept of nanobioelectronic nose, through
sensitive impedancemetric measurement of single receptor conformational change
upon ligand binding, with a better specificity and lower detection threshold
than traditional physical sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3100</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3100</id><created>2008-02-21</created><authors><author><keyname>Halvorsen</keyname><forenames>E.</forenames></author><author><keyname>Husa</keyname><forenames>S.</forenames></author></authors><title>Bridge configurations in piezoresistive two-axis accelerometers</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257673</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In piezoresisitive two-axis accelerometers with two proof masses suspended by
cantilever beams, there are generally many ways to configure the Wheatstone
bridges. The configurations are different both with respect to functionality
and performance. The main distinction is between bridges that contain resistors
belonging to both proof masses, and the one bridge that doesn't. We compare the
different bridge configurations by analytical calculations of bridge
non-linearity, robustness towards manufacturing variations and electronic
noise. We consider accelerometers where the ratio between the sensitivity to
acceleration normal and parallel to the chip plane vary over a wide range. For
numerical examples we use representative values for p-type silicon. The
performance of the configuration with one bridge connected to each proof mass
is superior to those that combine resistors belonging to different proof
masses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3101</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3101</id><created>2008-02-21</created><authors><author><keyname>Dumas</keyname><forenames>N.</forenames></author><author><keyname>Xu</keyname><forenames>Z.</forenames></author><author><keyname>Georgopopoulos</keyname><forenames>K.</forenames></author><author><keyname>Bunyan</keyname><forenames>J.</forenames></author><author><keyname>Richardson</keyname><forenames>A.</forenames></author></authors><title>Online Sensor Testing through Superposition of Encoded Stimulus</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257654</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Online monitoring remains an important requirement for a range of
microsystems. The solution based on the injection of an actuating test stimulus
into the bias structure of active devices holds great potential. This paper
presents an improved solution that aims to remove the measurand-induced signal
from the sensor output. It involves encoding the test stimulus and using a
covariance algorithm to reject the signal that does not contain the code. The
trade-off between the sine wave rejection ratio of the technique and the test
time response is studied and, in the case of a MEMS accelerometer, it is
demonstrated that the rejection is higher than 14dB for a test time of about
0.7s. Furthermore, the accuracy of the test signal can be evaluated to
guarantee the integrity of the online test output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3102</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3102</id><created>2008-02-21</created><authors><author><keyname>Narducci</keyname><forenames>M.</forenames></author><author><keyname>Figueras</keyname><forenames>E.</forenames></author><author><keyname>Gracia</keyname><forenames>I.</forenames></author><author><keyname>Fonseca</keyname><forenames>L.</forenames></author><author><keyname>Santander</keyname><forenames>J.</forenames></author><author><keyname>Can&#xe9;</keyname><forenames>C.</forenames></author></authors><title>Modeling of T-Shaped Microcantilever Resonators</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257670</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  The extensive research and development of micromechanical resonators is
trying to allow the use of these devices for highly sensitive applications.
Microcantilevers are some of the simplest MEMS structure and had been proved to
be a good platform due to its excellent mechanical properties. A cantilever
working in dynamic mode, adjust its resonance frequency depending on changes in
both the spring constant (k) and mass (m) of the resonator. The aim of this
work was to model a cantilever structure to determine the optimal dimensions in
which the resonance frequency would be a function dominated by mass changes and
not stiffness changes. In order to validate the model a set of microcantilevers
were fabricated and characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3103</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3103</id><created>2008-02-21</created><authors><author><keyname>Kirchberger</keyname><forenames>H.</forenames></author><author><keyname>Lindler</keyname><forenames>P.</forenames></author><author><keyname>Wimpliger</keyname><forenames>M.</forenames></author></authors><title>Novel Bonding technologies for wafer-level transparent packaging of
  MOEMS</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257659</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  Depending on the type of Micro-Electro-Mechanical System (MEMS), packaging
costs are contributing up to 80% of the total device cost. Each MEMS device
category, its function and operational environment will individually dictate
the packaging requirement. Due to the lack of standardized testing procedures,
the reliability of those MEMS packages sometimes can only be proven by taking
into consideration its functionality over lifetime. Innovation with regards to
cost reduction and standardization in the field of packaging is therefore of
utmost importance to the speed of commercialisation of MEMS devices. Nowadays
heavily driven by consumer applications the MEMS device market is forecasted to
enjoy a compound annual growth rate (CAGR) above 13%, which is when compared to
the IC device market, an outstanding growth rate. Nevertheless this forecasted
value can drift upwards or downwards depending on the rate of innovation in the
field of packaging. MEMS devices typically require a specific fabrication
process where the device wafer is bonded to a second wafer which effectively
encapsulates the MEMS structure. This method leaves the device free to move
within a vacuum or an inert gas atmosphere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3104</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3104</id><created>2008-02-21</created><authors><author><keyname>Hsieh</keyname><forenames>M. C.</forenames></author><author><keyname>Jair</keyname><forenames>D. K.</forenames></author><author><keyname>Fang</keyname><forenames>Y. K.</forenames></author><author><keyname>Lin</keyname><forenames>C. S.</forenames></author></authors><title>Design and Fabrication of the Suspended High-Q Spiral Inductors with
  X-Beams</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257669</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this paper, deep sub-micron CMOS process compatible high Q on chip spiral
inductors with air gap structure were designed and fabricated. In the design
the electromagnetic were used for electrical-characteristics and maximum
mechanical strength, respectively. The copper wires were capped with
electroless Ni plating to prevent the copper from oxidizing. A Si3N4/ SiO2
X-beam was designed to increase the mechanical strength of the inductor in air
gap. The enhancement of maximum mechanical strength of a spiral inductor with
X-beams is more than 4500 times. Among these structures, the measured maximum
quality factor (Q) of the suspending inductor and frequency at maximum Q are
improved from 5.2 and 1.6GHz of conventional spiral inductor to 7.3 and 2.1
GHz, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3105</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3105</id><created>2008-02-21</created><authors><author><keyname>Chang</keyname><forenames>H.</forenames></author><author><keyname>Xu</keyname><forenames>J.</forenames></author><author><keyname>Xie</keyname><forenames>J.</forenames></author><author><keyname>Zhang</keyname><forenames>Ch.</forenames></author><author><keyname>Yan</keyname><forenames>Z.</forenames></author><author><keyname>Yuan</keyname><forenames>W.</forenames></author></authors><title>One MEMS Design Tool with Maximal Six Design Flows</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257662</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  This paper presents one MEMS design tool with total six design flows, which
makes it possible that the MEMS designers are able to choose the most suitable
design flow for their specific devices. The design tool is divided into three
levels and interconnected by six interfaces. The three levels are
lumped-element model based system level, finite element analysis based device
level and process level, which covers nearly all modeling and simulation
functions for MEMS design. The six interfaces are proposed to automatically
transmit the design data between every two levels, thus the maximal six design
flows could be realized. The interfaces take the netlist, solid model and
layout as the data inlet and outlet for the system, device and process level
respectively. The realization of these interfaces are presented and verified by
design examples, which also proves that the enough flexibility in the design
flow can really increase the design efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3106</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3106</id><created>2008-02-21</created><authors><author><keyname>Shan</keyname><forenames>X. C.</forenames></author><author><keyname>Liu</keyname><forenames>Y. C.</forenames></author><author><keyname>Lu</keyname><forenames>H. J.</forenames></author><author><keyname>Wang</keyname><forenames>Z. F.</forenames></author><author><keyname>Lam</keyname><forenames>Y. C.</forenames></author></authors><title>Studies of Polymer Deformation and Recovery in Hot Embossing</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257667</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In large area micro hot embossing, the process temperature plays a critical
role to both the local fidelity of microstructure formation and global
uniformity. The significance of low temperature hot embossing is to improve
global flatness of embossed devices. This paper reports on experimental studies
of polymer deformation and relaxation in micro embossing when the process
temperatures are below or near its glass transition temperature (Tg). In this
investigation, an indentation system and a micro embosser were used to
investigate the relationship of microstructure formation versus process
temperature and load pressure. The depth of indentation was controlled and the
load force at a certain indentation depth was measured. Experiments were
carried out using 1 mm thick PMMA films with the process temperature ranging
from Tg-55 degrees C to Tg +20 degrees C. The embossed structures included a
single micro cavity and groups of micro cavity arrays. It was found that at
temperature of Tg-55 degrees C, elastic deformation dominated the formation of
microstructures and significant relaxation happened after embossing. From Tg-20
degrees C to Tg, plastic deformation dominated polymer deformation, and
permanent cavities could be formed on PMMA substrates without obvious
relaxation. However, the formation of protrusive structures as micro pillars
was not complete since there was little polymer flow. With an increase in
process temperature, microstructure could be formed under lower loading
pressure. Considering the fidelity of a single microstructure and global
flatness of embossed substrates, micro hot embossing at a low process
temperature, but with good fidelity, should be preferred.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3107</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3107</id><created>2008-02-21</created><authors><author><keyname>Tzanova</keyname><forenames>S.</forenames><affiliation>CIME</affiliation></author><author><keyname>Kamenova</keyname><forenames>L.</forenames><affiliation>CIME</affiliation></author><author><keyname>Avenas</keyname><forenames>Y.</forenames><affiliation>CIME</affiliation></author><author><keyname>Schaeffer</keyname><forenames>Ch.</forenames><affiliation>CIME</affiliation></author></authors><title>Evaluation of the thermal and hydraulic performances of a very thin
  sintered copper flat heat pipe for 3D microsystem packages</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257663</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  The reported research work presents numerical studies validated by
experimental results of a flat micro heat pipe with sintered copper wick
structure. The objectives of this project are to produce and demonstrate the
efficiency of the passive cooling technology (heat pipe) integrated in a very
thin electronic substrate that is a part of a multifunctional 3-D electronic
package. The enhanced technology is dedicated to the thermal management of high
dissipative microsystems having heat densities of more than 10W/cm2. Future
applications are envisaged in the avionics sector. In this research 2D
numerical hydraulic model has been developed to investigate the performance of
a very thin flat micro heat pipe with sintered copper wick structure, using
water as a refrigerant. Finite difference method has been used to develop the
model. The model has been used to determine the mass transfer and fluid flow in
order to evaluate the limits of heat transport capacity as functions of the
dimensions of the wick and the vapour space and for various copper spheres
radii. The results are presented in terms of liquid and vapour pressures within
the heat pipe. The simulated results are validated by experiments and proved
that the method can be further used to predict thermal performance of the heat
pipe and to optimise its design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3110</identifier>
 <datestamp>2008-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3110</id><created>2008-02-21</created><updated>2008-05-06</updated><authors><author><keyname>Bercher</keyname><forenames>J. -F.</forenames></author><author><keyname>Vignat</keyname><forenames>C.</forenames></author></authors><title>An entropic view of Pickands' theorem</title><categories>cs.IT math.IT</categories><comments>4 pages, accepted to ISIT08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that distributions arising in Renyi-Tsallis maximum entropy
setting are related to the Generalized Pareto Distributions (GPD) that are
widely used for modeling the tails of distributions. The relevance of such
modelization, as well as the ubiquity of GPD in practical situations follows
from Balkema-De Haan-Pickands theorem on the distribution of excesses (over a
high threshold). We provide an entropic view of this result, by showing that
the distribution of a suitably normalized excess variable converges to the
solution of a maximum Tsallis entropy, which is the GPD. This highlights the
relevance of the so-called Tsallis distributions in many applications as well
as some relevance to the use of the corresponding entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3137</identifier>
 <datestamp>2008-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3137</id><created>2008-02-21</created><authors><author><keyname>Faber</keyname><forenames>Wolfgang</forenames></author><author><keyname>Pfeifer</keyname><forenames>Gerald</forenames></author><author><keyname>Leone</keyname><forenames>Nicola</forenames></author><author><keyname>Dell'Armi</keyname><forenames>Tina</forenames></author><author><keyname>Ielpa</keyname><forenames>Giuseppe</forenames></author></authors><title>Design and Implementation of Aggregate Functions in the DLV System</title><categories>cs.AI cs.LO</categories><comments>34 pages, 7 figures. This article has been accepted for publication
  in Theory and Practice of Logic Programming, Cambridge University Press</comments><acm-class>I.2.3; I.2.4; D.3.1; D.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Disjunctive Logic Programming (DLP) is a very expressive formalism: it allows
for expressing every property of finite structures that is decidable in the
complexity class SigmaP2 (= NP^NP). Despite this high expressiveness, there are
some simple properties, often arising in real-world applications, which cannot
be encoded in a simple and natural manner. Especially properties that require
the use of arithmetic operators (like sum, times, or count) on a set or
multiset of elements, which satisfy some conditions, cannot be naturally
expressed in classic DLP.
  To overcome this deficiency, we extend DLP by aggregate functions in a
conservative way. In particular, we avoid the introduction of constructs with
disputed semantics, by requiring aggregates to be stratified. We formally
define the semantics of the extended language (called DLP^A), and illustrate
how it can be profitably used for representing knowledge. Furthermore, we
analyze the computational complexity of DLP^A, showing that the addition of
aggregates does not bring a higher cost in that respect. Finally, we provide an
implementation of DLP^A in DLV -- a state-of-the-art DLP system -- and report
on experiments which confirm the usefulness of the proposed extension also for
the efficiency of computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3235</identifier>
 <datestamp>2009-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3235</id><created>2008-02-21</created><updated>2009-07-02</updated><authors><author><keyname>Berrones</keyname><forenames>Arturo</forenames></author></authors><title>Characterization of the convergence of stationary Fokker-Planck learning</title><categories>cs.NE cond-mat.dis-nn cs.AI</categories><doi>10.1016/j.neucom.2008.12.042</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The convergence properties of the stationary Fokker-Planck algorithm for the
estimation of the asymptotic density of stochastic search processes is studied.
Theoretical and empirical arguments for the characterization of convergence of
the estimation in the case of separable and nonseparable nonlinear optimization
problems are given. Some implications of the convergence of stationary
Fokker-Planck learning for the inference of parameters in artificial neural
network models are outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3253</identifier>
 <datestamp>2008-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3253</id><created>2008-02-21</created><authors><author><keyname>Kim</keyname><forenames>Il Han</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author></authors><title>On the Capacity and Design of Limited Feedback Multiuser MIMO Uplinks</title><categories>cs.IT cs.MM math.IT</categories><comments>25 pages, submitted to the IEEE Transactions on Information Theory</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of multiple-input multiple-output (MIMO) technology has been
well-developed to increase fading channel capacity over single-input
single-output (SISO) systems. This capacity gain can often be leveraged by
utilizing channel state information at the transmitter and the receiver. Users
make use of this channel state information for transmit signal adaptation. In
this correspondence, we derive the capacity region for the MIMO multiple access
channel (MIMO MAC) when partial channel state information is available at the
transmitters, where we assume a synchronous MIMO multiuser uplink. The partial
channel state information feedback has a cardinality constraint and is fed back
from the basestation to the users using a limited rate feedback channel. Using
this feedback information, we propose a finite codebook design method to
maximize sum-rate. In this correspondence, the codebook is a set of transmit
signal covariance matrices. We also derive the capacity region and codebook
design methods in the case that the covariance matrix is rank-one (i.e.,
beamforming). This is motivated by the fact that beamforming is optimal in
certain conditions. The simulation results show that when the number of
feedback bits increases, the capacity also increases. Even with a small number
of feedback bits, the performance of the proposed system is close to an optimal
solution with the full feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3254</identifier>
 <datestamp>2008-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3254</id><created>2008-02-22</created><authors><author><keyname>Allauzen</keyname><forenames>Cyril</forenames></author><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author><author><keyname>Rastogi</keyname><forenames>Ashish</forenames></author></authors><title>General Algorithms for Testing the Ambiguity of Finite Automata</title><categories>cs.CC</categories><abstract>  This paper presents efficient algorithms for testing the finite, polynomial,
and exponential ambiguity of finite automata with $\epsilon$-transitions. It
gives an algorithm for testing the exponential ambiguity of an automaton $A$ in
time $O(|A|_E^2)$, and finite or polynomial ambiguity in time $O(|A|_E^3)$.
These complexities significantly improve over the previous best complexities
given for the same problem. Furthermore, the algorithms presented are simple
and are based on a general algorithm for the composition or intersection of
automata. We also give an algorithm to determine the degree of polynomial
ambiguity of a finite automaton $A$ that is polynomially ambiguous in time
$O(|A|_E^3)$. Finally, we present an application of our algorithms to an
approximate computation of the entropy of a probabilistic automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3267</identifier>
 <datestamp>2009-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3267</id><created>2008-02-22</created><authors><author><keyname>Hayes</keyname><forenames>Tom</forenames></author><author><keyname>Rustagi</keyname><forenames>Navin</forenames></author><author><keyname>Saia</keyname><forenames>Jared</forenames></author><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>The Forgiving Tree: A Self-Healing Distributed Data Structure</title><categories>cs.DC cs.NI</categories><comments>Submitted to Principles of Distributed Computing (PODC) 2008</comments><acm-class>C.2.1; C.2.3; C.2.4; C.4; H.3.4</acm-class><journal-ref>PODC '08: Proceedings of the twenty-seventh ACM symposium on
  Principles of distributed computing. 2008, pages 203--212</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of self-healing in peer-to-peer networks that are
under repeated attack by an omniscient adversary. We assume that the following
process continues for up to n rounds where n is the total number of nodes
initially in the network: the adversary deletes an arbitrary node from the
network, then the network responds by quickly adding a small number of new
edges.
  We present a distributed data structure that ensures two key properties.
First, the diameter of the network is never more than $O(\log \Delta)$ times
its original diameter, where $\Delta$ is the maximum degree of the network
initially. We note that for many peer-to-peer systems, $\Delta$ is
polylogarithmic, so the diameter increase would be a O(log log n)
multiplicative factor. Second, the degree of any node never increases by more
than 3 over its original degree. Our data structure is fully distributed, has
O(1) latency per round and requires each node to send and receive O(1) messages
per round. The data structure requires an initial setup phase that has latency
equal to the diameter of the original network, and requires, with high
probability, each node v to send O(log n) messages along every edge incident to
v. Our approach is orthogonal and complementary to traditional topology-based
approaches to defending against attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3283</identifier>
 <datestamp>2008-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3283</id><created>2008-02-22</created><authors><author><keyname>Holme</keyname><forenames>Petter</forenames></author><author><keyname>Karlin</keyname><forenames>Josh</forenames></author><author><keyname>Forrest</keyname><forenames>Stephanie</forenames></author></authors><title>An integrated model of traffic, geography and economy in the Internet</title><categories>cs.NI</categories><journal-ref>ACM SIGCOMM Computer Communication Review 38, 7-15 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling Internet growth is important both for understanding the current
network and to predict and improve its future. To date, Internet models have
typically attempted to explain a subset of the following characteristics:
network structure, traffic flow, geography, and economy. In this paper we
present a discrete, agent-based model, that integrates all of them. We show
that the model generates networks with topologies, dynamics, and (more
speculatively) spatial distributions that are similar to the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3284</identifier>
 <datestamp>2008-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3284</id><created>2008-02-22</created><authors><author><keyname>Bruy&#xe8;re</keyname><forenames>V&#xe9;ronique</forenames></author><author><keyname>M&#xe9;lot</keyname><forenames>Hadrien</forenames></author></authors><title>Tur\'an Graphs, Stability Number, and Fibonacci Index</title><categories>cs.DM</categories><comments>11 pages, 3 figures</comments><doi>10.1007/978-3-540-85097-7_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fibonacci index of a graph is the number of its stable sets. This
parameter is widely studied and has applications in chemical graph theory. In
this paper, we establish tight upper bounds for the Fibonacci index in terms of
the stability number and the order of general graphs and connected graphs.
Tur\'an graphs frequently appear in extremal graph theory. We show that Tur\'an
graphs and a connected variant of them are also extremal for these particular
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3285</identifier>
 <datestamp>2008-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3285</id><created>2008-02-22</created><authors><author><keyname>Arsinte</keyname><forenames>Radu</forenames></author><author><keyname>Ilioaei</keyname><forenames>Ciprian</forenames></author></authors><title>Some Aspects of Testing Process for Transport Streams in Digital Video
  Broadcasting</title><categories>cs.CV cs.MM</categories><comments>5 pages, 3 figures, 3 tables</comments><journal-ref>Acta Technica Napocensis, Electronics and Telecommunications,
  nr.1/2004 pp.59-74</journal-ref><abstract>  This paper presents some aspects related to the DVB (Digital Video
Broadcasting) investigation. The basic aspects of DVB are presented, with an
emphasis on DVB-T version of standard. The main purpose of this research is to
analyze the way that the transmission of the transport streams is realized in
case of the Terrestrial Digital Video Broadcasting (DVB-T). To accomplish this,
first, Digital Video Broadcasting standard is presented, and then the main
aspects of DVB testing and analysis of the transport streams are investigated.
The paper presents also the results obtained using two programs designed for
DVB analysis: Mosalina and TSA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3288</identifier>
 <datestamp>2008-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3288</id><created>2008-02-22</created><authors><author><keyname>Arsinte</keyname><forenames>Radu</forenames></author></authors><title>Implementing a Test Strategy for an Advanced Video Acquisition and
  Processing Architecture</title><categories>cs.CV cs.MM</categories><comments>5 pages, 17 figures</comments><journal-ref>Acta Technica Napocensis, Electronics and Telecommunications,
  nr.2/2005 pp.15-20</journal-ref><abstract>  This paper presents some aspects related to test process of an advanced video
system used in remote IP surveillance. The system is based on a Pentium
compatible architecture using the industrial standard PC104+. First the overall
architecture of the system is presented, involving both hardware or software
aspects. The acquisition board which is developed in a special, nonstandard
architecture, is also briefly presented. The main purpose of this research was
to set a coherent set of procedures in order to test all the aspects of the
video acquisition board. To accomplish this, it was necessary to set-up a
procedure in two steps: stand alone video board test (functional test) and an
in-system test procedure verifying the compatibility with both OS: Linux and
Windows. The paper presents also the results obtained using this procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3293</identifier>
 <datestamp>2008-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3293</id><created>2008-02-22</created><authors><author><keyname>Cetin</keyname><forenames>Burak</forenames></author><author><keyname>Bingol</keyname><forenames>Haluk</forenames></author></authors><title>Use of Rapid Probabilistic Argumentation for Ranking on Large Complex
  Networks</title><categories>cs.AI cs.IR</categories><comments>11 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a family of novel ranking algorithms called ERank which run in
linear/near linear time and build on explicitly modeling a network as uncertain
evidence. The model uses Probabilistic Argumentation Systems (PAS) which are a
combination of probability theory and propositional logic, and also a special
case of Dempster-Shafer Theory of Evidence. ERank rapidly generates approximate
results for the NP-complete problem involved enabling the use of the technique
in large networks. We use a previously introduced PAS model for citation
networks generalizing it for all networks. We propose a statistical test to be
used for comparing the performances of different ranking algorithms based on a
clustering validity test. Our experimentation using this test on a real-world
network shows ERank to have the best performance in comparison to well-known
algorithms including PageRank, closeness, and betweenness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3300</identifier>
 <datestamp>2014-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3300</id><created>2008-02-22</created><authors><author><keyname>La Mura</keyname><forenames>Pierfrancesco</forenames></author></authors><title>Projective Expected Utility</title><categories>quant-ph cs.GT</categories><comments>7 pages, to appear in the Proceedings of Quantum Interaction 2008</comments><journal-ref>J. of Math. Psychology, 53:5 (2009)</journal-ref><doi>10.1016/j.jmp.2009.02.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by several classic decision-theoretic paradoxes, and by analogies
with the paradoxes which in physics motivated the development of quantum
mechanics, we introduce a projective generalization of expected utility along
the lines of the quantum-mechanical generalization of probability theory. The
resulting decision theory accommodates the dominant paradoxes, while retaining
significant simplicity and tractability. In particular, every finite game
within this larger class of preferences still has an equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3328</identifier>
 <datestamp>2008-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3328</id><created>2008-02-22</created><authors><author><keyname>Patra</keyname><forenames>Manas K</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author></authors><title>An Algebraic Characterization of Security of Cryptographic Protocols</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several of the basic cryptographic constructs have associated algebraic
structures. Formal models proposed by Dolev and Yao to study the
(unconditional) security of public key protocols form a group. The security of
some types of protocols can be neatly formulated in this algebraic setting. We
investigate classes of two-party protocols. We then consider extension of the
formal algebraic framework to private-key protocols. We also discuss concrete
realization of the formal models. In this case, we propose a definition in
terms of pseudo-free groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3355</identifier>
 <datestamp>2008-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3355</id><created>2008-02-22</created><authors><author><keyname>Villatoro</keyname><forenames>Francisco R.</forenames></author><author><keyname>Nebro</keyname><forenames>Antonio J.</forenames></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Jose E.</forenames></author></authors><title>PVM-Distributed Implementation of the Radiance Code</title><categories>cs.DC cs.GR</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Parallel Virtual Machine (PVM) tool has been used for a distributed
implementation of Greg Ward's Radiance code. In order to generate exactly the
same primary rays with both the sequential and the parallel codes, the quincunx
sampling technique used in Radiance for the reduction of the number of primary
rays by interpolation, must be left untouched in the parallel implementation.
The octree of local ambient values used in Radiance for the indirect
illumination has been shared among all the processors. Both static and dynamic
image partitioning techniques which replicate the octree of the complete scene
in all the processors and have load-balancing, have been developed for one
frame rendering. Speedups larger than 7.5 have been achieved in a network of 8
workstations. For animation sequences, a new dynamic partitioning distribution
technique with superlinear speedups has also been developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3401</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3401</id><created>2008-02-22</created><authors><author><keyname>Marina</keyname><forenames>Ninoslav</forenames></author><author><keyname>Rimoldi</keyname><forenames>Bixio</forenames></author></authors><title>On the Structure of the Capacity Region of Asynchronous Memoryless
  Multiple-Access Channels</title><categories>cs.IT math.IT</categories><comments>21 pages, 5 figures and 1 table. Submitted to IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The asynchronous capacity region of memoryless multiple-access channels is
the union of certain polytopes. It is well-known that vertices of such
polytopes may be approached via a technique called successive decoding. It is
also known that an extension of successive decoding applies to the dominant
face of such polytopes. The extension consists of forming groups of users in
such a way that users within a group are decoded jointly whereas groups are
decoded successively. This paper goes one step further. It is shown that
successive decoding extends to every face of the above mentioned polytopes. The
group composition as well as the decoding order for all rates on a face of
interest are obtained from a label assigned to that face. From the label one
can extract a number of structural properties, such as the dimension of the
corresponding face and whether or not two faces intersect. Expressions for the
the number of faces of any given dimension are also derived from the labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3414</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3414</id><created>2008-02-22</created><updated>2011-12-30</updated><authors><author><keyname>Abel</keyname><forenames>Zachary</forenames></author><author><keyname>Kominers</keyname><forenames>Scott D.</forenames></author></authors><title>Universal Reconfiguration of (Hyper-)cubic Robots</title><categories>cs.CG cs.MA cs.RO</categories><comments>5 pages, 2 figures</comments><acm-class>I.2.11; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a simple reconfigurable robot model which has not been previously
examined: cubic robots comprised of three-dimensional cubic modules which can
slide across each other and rotate about each others' edges. We demonstrate
that the cubic robot model is universal, i.e., that an n-module cubic robot can
reconfigure itself into any specified n-module configuration. Additionally, we
provide an algorithm that efficiently plans and executes cubic robot motion.
Our results directly extend to a d-dimensional model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3419</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3419</id><created>2008-02-22</created><authors><author><keyname>Anthapadmanabhan</keyname><forenames>N. Prasanth</forenames></author><author><keyname>Barg</keyname><forenames>Alexander</forenames></author></authors><title>Randomized Frameproof Codes: Fingerprinting Plus Validation Minus
  Tracing</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, To appear in the Proceedings of Conference on Information
  Sciences and Systems (CISS), Princeton, NJ, Mar 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose randomized frameproof codes for content protection, which arise by
studying a variation of the Boneh-Shaw fingerprinting problem. In the modified
system, whenever a user tries to access his fingerprinted copy, the fingerprint
is submitted to a validation algorithm to verify that it is indeed permissible
before the content can be executed. We show an improvement in the achievable
rates compared to deterministic frameproof codes and traditional fingerprinting
codes.
  For coalitions of an arbitrary fixed size, we construct randomized frameproof
codes which have an $O(n^2)$ complexity validation algorithm and probability of
error $\exp(-\Omega(n)),$ where $n$ denotes the length of the fingerprints.
Finally, we present a connection between linear frameproof codes and minimal
vectors for size-2 coalitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3429</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3429</id><created>2008-02-23</created><authors><author><keyname>Sun</keyname><forenames>Yi</forenames></author></authors><title>Quasi-Large Sparse-Sequence CDMA: Approach to Single-User Bound by
  Linearly-Complex LAS Detectors</title><categories>cs.IT math.IT</categories><comments>CISS 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have proposed a quasi-large random-sequence (QLRS) CDMA where K users
access a point through a common channel with spectral spreading factor N. Each
bit is extended by a temporal spreading factor B and hopped on a BN-chip random
sequence that is spread in time and frequency. Each user multiplexes and
transmits B extended bits and the total channel load is alpha = K/N bits/s/Hz.
The linearly-complex LAS detectors detect the transmitted bits. We have
obtained that as B tends to infinity, if alpha &lt; 1/2 - 1/(4ln2), each
transmitted bit achieves the single-bit bound in BER in high SNR regime as if
there was no interference bit. In simulation, when bit number BK &gt;= 500, each
bit can approach the single-bit bound for alpha as high as 1 bit/s/Hz. In this
paper, we further propose the quasi-large sparse-sequence (QLSS) CDMA by
replacing the dense sequence in QLRS-CDMA with sparse sequence. Simulation
results show that when the nonzero chips are as few as 16, the BER is already
near that of QLRS-CDMA while the complexity is significantly reduced due to
sequence sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3430</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3430</id><created>2008-02-23</created><authors><author><keyname>Zeng</keyname><forenames>Xiangyong</forenames></author><author><keyname>Li</keyname><forenames>Nian</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author></authors><title>A Class of Nonbinary Codes and Their Weight Distribution</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, for an even integer $n\geq 4$ and any positive integer $k$
with ${\rm gcd}(n/2,k)={\rm gcd}(n/2-k,2k)=d$ being odd, a class of $p$-ary
codes $\mathcal{C}^k$ is defined and their weight distribution is completely
determined, where $p$ is an odd prime. As an application, a class of nonbinary
sequence families is constructed from these codes, and the correlation
distribution is also determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3437</identifier>
 <datestamp>2008-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3437</id><created>2008-02-23</created><updated>2008-04-14</updated><authors><author><keyname>Borissov</keyname><forenames>Yuri L.</forenames></author></authors><title>On Cusick-Cheon's Conjecture About Balanced Boolean Functions in the
  Cosets of the Binary Reed-Muller Code</title><categories>cs.IT math.IT</categories><comments>3 pages, Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is proved an amplification of Cusick-Cheon's conjecture on balanced
Boolean functions in the cosets of the binary Reed-Muller code RM(k,m) of order
k and length 2^m, in the cases where k = 1 or k &gt;= (m-1)/2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3441</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3441</id><created>2008-02-23</created><authors><author><keyname>Garcia-Lasheras</keyname><forenames>Javier D.</forenames></author></authors><title>Efficient implementation of GALS systems over commercial synchronous
  FPGAs: a new approach</title><categories>cs.AR</categories><comments>English version of the paper presented in the Spanish Workshop on
  Reconfigurable Computing and Applications, Zaragoza (2007)</comments><acm-class>B.6.1; B.7.1</acm-class><journal-ref>&quot;Implementacion eficiente de sistemas GALS sobre FPGAs&quot;, Jornadas
  de Computacion Reconfigurable y Aplicaciones (JCRA'07), Zaragoza (2007)</journal-ref><abstract>  The new vision presented is aimed to overcome the logic overhead issues that
previous works exhibit when applying GALS techniques to programmable logic
devices. The proposed new view relies in a 2-phase, bundled data parity based
protocol for data transfer and clock generation tasks. The ability of the
introduced methodology for smart real-time delay selection allows the
implementation of a variety of new methodologies for electromagnetic
interference mitigation and device environment changes adaptation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3444</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3444</id><created>2008-02-23</created><authors><author><keyname>Blanchet</keyname><forenames>Bruno</forenames></author></authors><title>Automatic Verification of Correspondences for Security Protocols</title><categories>cs.CR cs.LO</categories><comments>95 pages</comments><acm-class>D.2.4; D.4.6; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new technique for verifying correspondences in security
protocols. In particular, correspondences can be used to formalize
authentication. Our technique is fully automatic, it can handle an unbounded
number of sessions of the protocol, and it is efficient in practice. It
significantly extends a previous technique for the verification of secrecy. The
protocol is represented in an extension of the pi calculus with fairly
arbitrary cryptographic primitives. This protocol representation includes the
specification of the correspondence to be verified, but no other annotation.
This representation is then translated into an abstract representation by Horn
clauses, which is used to prove the desired correspondence. Our technique has
been proved correct and implemented. We have tested it on various protocols
from the literature. The experimental results show that these protocols can be
verified by our technique in less than 1 s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3448</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3448</id><created>2008-02-23</created><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author></authors><title>Sketch-Based Estimation of Subpopulation-Weight</title><categories>cs.DB cs.DS cs.NI cs.PF</categories><acm-class>H.3.3; H.2; F.2.2</acm-class><abstract>  Summaries of massive data sets support approximate query processing over the
original data. A basic aggregate over a set of records is the weight of
subpopulations specified as a predicate over records' attributes. Bottom-k
sketches are a powerful summarization format of weighted items that includes
priority sampling and the classic weighted sampling without replacement. They
can be computed efficiently for many representations of the data including
distributed databases and data streams.
  We derive novel unbiased estimators and efficient confidence bounds for
subpopulation weight. Our estimators and bounds are tailored by distinguishing
between applications (such as data streams) where the total weight of the
sketched set can be computed by the summarization algorithm without a
significant use of additional resources, and applications (such as sketches of
network neighborhoods) where this is not the case.
  Our rigorous derivations are based on clever applications of the
Horvitz-Thompson estimator, and are complemented by efficient computational
methods. We demonstrate their benefit on a wide range of Pareto distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3457</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3457</id><created>2008-02-23</created><authors><author><keyname>Panko</keyname><forenames>Raymond R.</forenames></author></authors><title>Spreadsheet Errors: What We Know. What We Think We Can Do</title><categories>cs.SE cs.HC</categories><comments>9 Pages, 2 Tables</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2000 7-17
  ISBN:1 86166 158 4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifteen years of research studies have concluded unanimously that spreadsheet
errors are both common and non-trivial. Now we must seek ways to reduce
spreadsheet errors. Several approaches have been suggested, some of which are
promising and others, while appealing because they are easy to do, are not
likely to be effective. To date, only one technique, cell-by-cell code
inspection, has been demonstrated to be effective. We need to conduct further
research to determine the degree to which other techniques can reduce
spreadsheet errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3473</identifier>
 <datestamp>2009-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3473</id><created>2008-02-23</created><updated>2009-04-02</updated><authors><author><keyname>Dziemianczuk</keyname><forenames>M.</forenames></author></authors><title>On Cobweb Posets and Discrete F-Boxes Tilings</title><categories>math.CO cs.DM</categories><comments>24 pages, 15 figures, Affiliated to The Internet Gian-Carlo Polish
  Seminar http://ii.uwb.edu.pl/akk/sem/sem_rota.htm</comments><msc-class>05A10, 05A19, 11B83, 11B65</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  F-boxes defined in [6] as hyper-boxes in N^{\infty} discrete space were
applied here for the geometric description of the cobweb posetes Hasse diagrams
tilings. The F-boxes edges sizes are taken to be values of terms of natural
numbers' valued sequence F. The problem of partitions of hyper-boxes
represented by graphs into blocks of special form is considered and these are
to be called F-tilings. The proof of such tilings' existence for certain
sub-family of admissible sequences F is delivered. The family of F-tilings
which we consider here includes among others F = Natural numbers, Fibonacci
numbers, Gaussian integers with their corresponding F-nomial (Binomial,
Fibonomial, Gaussian) coefficients. Extension of this tiling problem onto the
general case multi F-nomial coefficients is here proposed. Reformulation of the
present cobweb tiling problem into a clique problem of a graph specially
invented for that purpose - is proposed here too. To this end we illustrate the
area of our reconnaissance by means of the Venn type map of various cobweb
sequences families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3475</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3475</id><created>2008-02-23</created><authors><author><keyname>Kemmis</keyname><forenames>Patrick</forenames></author><author><keyname>Thomas</keyname><forenames>Giles</forenames></author></authors><title>Spreadsheet Development Methodologies using Resolver: Moving
  spreadsheets into the 21st Century</title><categories>cs.SE cs.HC</categories><comments>12 pages</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 93-104
  ISBN 978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We intend to demonstrate the innate problems with existing spreadsheet
products and to show how to tackle these issues using a new type of spreadsheet
program called Resolver. It addresses the issues head-on and thereby moves the
1980's &quot;VisiCalc paradigm&quot; on to match the advances in computer languages and
user requirements. Continuous display of the spreadsheet grid and the
equivalent computer program, together with the ability to interact and add code
through either interface, provides a number of new methodologies for
spreadsheet development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3476</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3476</id><created>2008-02-23</created><authors><author><keyname>Paine</keyname><forenames>Jocelyn</forenames></author></authors><title>Fun Boy Three Were Wrong: it is what you do, not the way that you do it</title><categories>cs.HC cs.SE</categories><comments>12 Pages</comments><acm-class>D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 105-116
  ISBN 978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I revisit some classic publications on modularity, to show what problems its
pioneers wanted to solve. These problems occur with spreadsheets too: to
recognise them may help us avoid them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3477</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3477</id><created>2008-02-23</created><authors><author><keyname>Thorne</keyname><forenames>Simon R.</forenames></author><author><keyname>Ball</keyname><forenames>David</forenames></author><author><keyname>Lawson</keyname><forenames>Z.</forenames></author></authors><title>Concerning the Feasibility of Example-driven Modelling Techniques</title><categories>cs.HC</categories><comments>14 Pages, 8 Figures, 1 Tables</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 117-130
  ISBN 978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on a series of experiments concerning the feasibility of example
driven modelling. The main aim was to establish experimentally within an
academic environment: the relationship between error and task complexity using
a) Traditional spreadsheet modelling; b) example driven techniques. We report
on the experimental design, sampling, research methods and the tasks set for
both control and treatment groups. Analysis of the completed tasks allows
comparison of several different variables. The experimental results compare the
performance indicators for the treatment and control groups by comparing
accuracy, experience, training, confidence measures, perceived difficulty and
perceived completeness. The various results are thoroughly tested for
statistical significance using: the Chi squared test, Fisher's exact test for
significance, Cochran's Q test and McNemar's test on difficulty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3478</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3478</id><created>2008-02-23</created><authors><author><keyname>Paine</keyname><forenames>Jocelyn</forenames></author></authors><title>It Ain't What You View, But The Way That You View It: documenting
  spreadsheets with Excelsior, semantic wikis, and literate programming</title><categories>cs.HC cs.SE</categories><comments>12 Pages</comments><acm-class>J.1; H.4.1; K.6.4; D.2.9</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 131-142
  ISBN 978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I describe preliminary experiments in documenting Excelsior versions of
spreadsheets using semantic wikis and literate programming. The objective is to
create well-structured and comprehensive documentation, easy to use by those
unfamiliar with the spreadsheets documented. I discuss why so much
documentation is hard to use, and briefly explain semantic wikis and literate
programming; although parts of the paper are Excelsior-specific, these sections
may be of more general interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3479</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3479</id><created>2008-02-23</created><authors><author><keyname>Bishop</keyname><forenames>Brian</forenames></author><author><keyname>McDaid</keyname><forenames>Kevin</forenames></author></authors><title>An Empirical Study of End-User Behaviour in Spreadsheet Error Detection
  &amp; Correction</title><categories>cs.HC cs.CY</categories><comments>12 Pages, 3 Figures</comments><acm-class>D.2.4; D.2.5; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 165-176
  ISBN 978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Very little is known about the process by which end-user developers detect
and correct spreadsheet errors. Any research pertaining to the development of
spreadsheet testing methodologies or auditing tools would benefit from
information on how end-users perform the debugging process in practice.
Thirteen industry-based professionals and thirty-four accounting &amp; finance
students took part in a current ongoing experiment designed to record and
analyse end-user behaviour in spreadsheet error detection and correction.
Professionals significantly outperformed students in correcting certain error
types. Time-based cell activity analysis showed that a strong correlation
exists between the percentage of cells inspected and the number of errors
corrected. The cell activity data was gathered through a purpose written VBA
Excel plug-in that records the time and detail of all cell selection and cell
change actions of individuals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3480</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3480</id><created>2008-02-23</created><authors><author><keyname>McGuire</keyname><forenames>Kath</forenames></author></authors><title>Why Task-Based Training is Superior to Traditional Training Methods</title><categories>cs.HC</categories><comments>6 Pages</comments><acm-class>D.2.4; D.2.5; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 191-196
  ISBN 978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The risks of spreadsheet use do not just come from the misuse of formulae. As
such, training needs to go beyond this technical aspect of spreadsheet use and
look at the spreadsheet in its full business context. While standard training
is by and large unable to do this, task-based training is perfectly suited to a
contextual approach to training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3481</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3481</id><created>2008-02-23</created><authors><author><keyname>Chadwick</keyname><forenames>David</forenames></author></authors><title>Establishing A Minimum Generic Skill Set For Risk Management Teaching In
  A Spreadsheet Training Course</title><categories>cs.HC</categories><comments>12 Pages</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1; K.3</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 197-208
  ISBN 978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Past research shows that spreadsheet models are prone to such a high
frequency of errors and data security implications that the risk management of
spreadsheet development and spreadsheet use is of great importance to both
industry and academia. The underlying rationale for this paper is that
spreadsheet training courses should specifically address risk management in the
development process both from a generic and a domain-specific viewpoint. This
research specifically focuses on one of these namely those generic issues of
risk management that should be present in a training course that attempts to
meet good-practice within industry. A pilot questionnaire was constructed
showing a possible minimum set of risk management issues and sent to academics
and industry practitioners for feedback. The findings from this pilot survey
will be used to refine the questionnaire for sending to a larger body of
possible respondents. It is expected these findings will form the basis of a
risk management teaching approach to be trialled in a number of selected
ongoing spreadsheet training courses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3483</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3483</id><created>2008-02-23</created><authors><author><keyname>Flood</keyname><forenames>Derek</forenames></author><author><keyname>Daid</keyname><forenames>Kevin Mc</forenames></author></authors><title>Voice-controlled Debugging of Spreadsheets</title><categories>cs.HC</categories><comments>10 Pages, 4 Tables</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2007 155-164
  ISBN 978-905617-58-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developments in Mobile Computing are putting pressure on the software
industry to research new modes of interaction that do not rely on the
traditional keyboard and mouse combination. Computer users suffering from
Repetitive Strain Injury also seek an alternative to keyboard and mouse devices
to reduce suffering in wrist and finger joints. Voice-control is an alternative
approach to spreadsheet development and debugging that has been researched and
used successfully in other domains. While voice-control technology for
spreadsheets is available its effectiveness has not been investigated. This
study is the first to compare the performance of a set of expert spreadsheet
developers that debugged a spreadsheet using voice-control technology and
another set that debugged the same spreadsheet using keyboard and mouse. The
study showed that voice, despite its advantages, proved to be slower and less
accurate. However, it also revealed ways in which the technology might be
improved to redress this imbalance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3490</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3490</id><created>2008-02-24</created><authors><author><keyname>Ma</keyname><forenames>Jing</forenames></author><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author></authors><title>On capacity of wireless ad hoc networks with MIMO MMSE receivers</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Widely adopted at home, business places, and hot spots, wireless ad-hoc
networks are expected to provide broadband services parallel to their wired
counterparts in near future. To address this need, MIMO techniques, which are
capable of offering several-fold increase in capacity, hold significant
promise. Most previous work on capacity analysis of ad-hoc networks is based on
an implicit assumption that each node has only one antenna. Core to the
analysis therein is the characterization of a geometric area, referred to as
the exclusion region, which quantizes the amount of spatial resource occupied
by a link. When multiple antennas are deployed at each node, however, multiple
links can transmit in the vicinity of each other simultaneously, as
interference can now be suppressed by spatial signal processing. As such, a
link no longer exclusively occupies a geometric area, making the concept of
&quot;exclusion region&quot; not applicable any more. In this paper, we investigate
link-layer throughput capacity of MIMO ad-hoc networks. In contrast to previous
work, the amount of spatial resource occupied by each link is characterized by
the actual interference it imposes on other links. To calculate the link-layer
capacity, we first derive the probability distribution of post-detection SINR
at a receiver. The result is then used to calculate the number of active links
and the corresponding data rates that can be sustained within an area. Our
analysis will serve as a guideline for the design of medium access protocols
for MIMO ad-hoc networks. To the best of knowledge, this paper is the first
attempt to characterize the capacity of MIMO ad-hoc networks by considering the
actual PHY-layer signal and interference model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3492</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3492</id><created>2008-02-24</created><updated>2010-03-25</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>The RDF Virtual Machine</title><categories>cs.PL</categories><comments>keywords: Resource Description Framework, Virtual Machines,
  Distributed Computing, Semantic Web</comments><report-no>LA-UR-08-03925</report-no><acm-class>F.1.2; I.2.4; E.1</acm-class><journal-ref>Knowledge-Based Systems, 24(6), 890-903, August 2011</journal-ref><doi>10.1016/j.knosys.2011.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Resource Description Framework (RDF) is a semantic network data model
that is used to create machine-understandable descriptions of the world and is
the basis of the Semantic Web. This article discusses the application of RDF to
the representation of computer software and virtual computing machines. The
Semantic Web is posited as not only a web of data, but also as a web of
programs and processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3495</identifier>
 <datestamp>2009-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3495</id><created>2008-02-24</created><updated>2009-02-15</updated><authors><author><keyname>Annapureddy</keyname><forenames>V. Sreekanth</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Gaussian Interference Networks: Sum Capacity in the Low Interference
  Regime and New Outer Bounds on the Capacity Region</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, February 2008.
  Revised Nov 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Establishing the capacity region of a Gaussian interference network is an
open problem in information theory. Recent progress on this problem has led to
the characterization of the capacity region of a general two user Gaussian
interference channel within one bit. In this paper, we develop new, improved
outer bounds on the capacity region. Using these bounds, we show that treating
interference as noise achieves the sum capacity of the two user Gaussian
interference channel in a low interference regime, where the interference
parameters are below certain thresholds. We then generalize our techniques and
results to Gaussian interference networks with more than two users. In
particular, we demonstrate that the total interference threshold, below which
treating interference as noise achieves the sum capacity, increases with the
number of users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3513</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3513</id><created>2008-02-24</created><authors><author><keyname>Dereniowski</keyname><forenames>Dariusz</forenames></author></authors><title>The Complexity of Node Blocking for Dags</title><categories>cs.GT cs.DM</categories><comments>7 pages, 3 figures</comments><acm-class>F.2.2</acm-class><journal-ref>Journal of Combinatorial Theory, Series A 118 (2011) 248-256</journal-ref><doi>10.1016/j.jcta.2010.03.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following modification of annihilation game called node
blocking. Given a directed graph, each vertex can be occupied by at most one
token. There are two types of tokens, each player can move his type of tokens.
The players alternate their moves and the current player $i$ selects one token
of type $i$ and moves the token along a directed edge to an unoccupied vertex.
If a player cannot make a move then he loses. We consider the problem of
determining the complexity of the game: given an arbitrary configuration of
tokens in a directed acyclic graph, does the current player has a winning
strategy? We prove that the problem is PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3522</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3522</id><created>2008-02-24</created><updated>2008-06-23</updated><authors><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>VALORIA</affiliation></author></authors><title>Time Warp Edit Distance</title><categories>cs.IR</categories><comments>Pattern Recognition - Clustering - Algorithms - Similarity Measures</comments><proxy>ccsd hal-00258669</proxy><report-no>VALORIA.2008.1V5</report-no><abstract>  This technical report details a family of time warp distances on the set of
discrete time series. This family is constructed as an editing distance whose
elementary operations apply on linear segments. A specific parameter allows
controlling the stiffness of the elastic matching. It is well suited for the
processing of event data for which each data sample is associated with a
timestamp, not necessarily obtained according to a constant sampling rate. Some
properties verified by these distances are proposed and proved in this report.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3528</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3528</id><created>2008-02-24</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Starck</keyname><forenames>Jean-Luc</forenames></author></authors><title>Wavelet and Curvelet Moments for Image Classification: Application to
  Aggregate Mixture Grading</title><categories>cs.CV</categories><comments>Submitted to Pattern Recognition Letters</comments><journal-ref>Pattern Recognition Letters, 29, 1557-1564, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show the potential for classifying images of mixtures of aggregate, based
themselves on varying, albeit well-defined, sizes and shapes, in order to
provide a far more effective approach compared to the classification of
individual sizes and shapes. While a dominant (additive, stationary) Gaussian
noise component in image data will ensure that wavelet coefficients are of
Gaussian distribution, long tailed distributions (symptomatic, for example, of
extreme values) may well hold in practice for wavelet coefficients. Energy (2nd
order moment) has often been used for image characterization for image
content-based retrieval, and higher order moments may be important also, not
least for capturing long tailed distributional behavior. In this work, we
assess 2nd, 3rd and 4th order moments of multiresolution transform -- wavelet
and curvelet transform -- coefficients as features. As analysis methodology,
taking account of image types, multiresolution transforms, and moments of
coefficients in the scales or bands, we use correspondence analysis as well as
k-nearest neighbors supervised classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3535</identifier>
 <datestamp>2008-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3535</id><created>2008-02-24</created><updated>2008-06-05</updated><authors><author><keyname>Avestimehr</keyname><forenames>Amir Salman</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas N.</forenames></author><author><keyname>Tse</keyname><forenames>David N C.</forenames></author></authors><title>Approximate Capacity of Gaussian Relay Networks</title><categories>cs.IT math.IT</categories><comments>This paper is submited to 2008 IEEE International Symposium on
  Information Theory (ISIT 2008) -In the revised format the approximation gap
  (\kappa) is sharpened</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an achievable rate for general Gaussian relay networks. We show
that the achievable rate is within a constant number of bits from the
information-theoretic cut-set upper bound on the capacity of these networks.
This constant depends on the topology of the network, but not the values of the
channel gains. Therefore, we uniformly characterize the capacity of Gaussian
relay networks within a constant number of bits, for all channel parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3554</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3554</id><created>2008-02-24</created><updated>2009-02-20</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Data Traffic Dynamics and Saturation on a Single Link</title><categories>cs.NI cs.PF</categories><comments>10 pages, 5 figures</comments><journal-ref>International Journal of Computer, Information, and Systems
  Science, and Engineering, vol 3, no. 1, 11-16 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamics of User Datagram Protocol (UDP) traffic over Ethernet between
two computers are analyzed using nonlinear dynamics which shows that there are
two clear regimes in the data flow: free flow and saturated. The two most
important variables affecting this are the packet size and packet flow rate.
However, this transition is due to a transcritical bifurcation rather than
phase transition in models such as in vehicle traffic or theorized large-scale
computer network congestion. It is hoped this model will help lay the
groundwork for further research on the dynamics of networks, especially
computer networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3563</identifier>
 <datestamp>2013-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3563</id><created>2008-02-25</created><updated>2008-08-06</updated><authors><author><keyname>Khan</keyname><forenames>Usman A.</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose' M. F.</forenames></author></authors><title>Distributed Sensor Localization in Random Environments using Minimal
  Number of Anchor Nodes</title><categories>cs.IT math.IT</categories><comments>30 pages, submitted to IEEE Transactions on Signal Processing</comments><journal-ref>U. A. Khan, S. Kar, and J. M. F. Moura, &quot;Distributed sensor
  localization in random environments using minimal number of anchor nodes,&quot;
  IEEE Transactions on Signal Processing, vol. 57, no. 5, pp. 2000-2016, May
  2009</journal-ref><doi>10.1109/TSP.2009.2014812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper develops DILOC, a \emph{distributive}, \emph{iterative} algorithm
that locates M sensors in $\mathbb{R}^m, m\geq 1$, with respect to a minimal
number of m+1 anchors with known locations. The sensors exchange data with
their neighbors only; no centralized data processing or communication occurs,
nor is there centralized knowledge about the sensors' locations. DILOC uses the
barycentric coordinates of a sensor with respect to its neighbors that are
computed using the Cayley-Menger determinants. These are the determinants of
matrices of inter-sensor distances. We show convergence of DILOC by associating
with it an absorbing Markov chain whose absorbing states are the anchors. We
introduce a stochastic approximation version extending DILOC to random
environments when the knowledge about the intercommunications among sensors and
the inter-sensor distances are noisy, and the communication links among
neighbors fail at random times. We show a.s. convergence of the modified DILOC
and characterize the error between the final estimates and the true values of
the sensors' locations. Numerical studies illustrate DILOC under a variety of
deterministic and random operating conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3569</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3569</id><created>2008-02-25</created><authors><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Chen</keyname><forenames>Darui</forenames></author></authors><title>Delay Analysis for Wireless Local Area Networks with Multipacket
  Reception under Finite Load</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To date, most analysis of WLANs has been focused on their operation under
saturation condition. This work is an attempt to understand the fundamental
performance of WLANs under unsaturated condition. In particular, we are
interested in the delay performance when collisions of packets are resolved by
an exponential backoff mechanism. Using a multiple-vacation queueing model, we
derive an explicit expression for packet delay distribution, from which
necessary conditions for finite mean delay and delay jitter are established. It
is found that under some circumstances, mean delay and delay jitter may
approach infinity even when the traffic load is way below the saturation
throughput. Saturation throughput is therefore not a sound measure of WLAN
capacity when the underlying applications are delay sensitive. To bridge the
gap, we define safe-bounded-mean-delay (SBMD) throughput and
safe-bounded-delay-jitter (SBDJ) throughput that reflect the actual network
capacity users can enjoy when they require bounded mean delay and delay jitter,
respectively. The analytical model in this paper is general enough to cover
both single-packet reception (SPR) and multi-packet reception (MPR) WLANs, as
well as carrier-sensing and non-carrier-sensing networks. We show that the SBMD
and SBDJ throughputs scale super-linearly with the MPR capability of a network.
Together with our earlier work that proves super-linear throughput scaling
under saturation condition, our results here complete the demonstration of MPR
as a powerful capacity-enhancement technique for both delay-sensitive and
delay-tolerant applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3570</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3570</id><created>2008-02-25</created><updated>2009-03-17</updated><authors><author><keyname>Ryan</keyname><forenames>\Oyvind</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Asymptotic Behaviour of Random Vandermonde Matrices with Entries on the
  Unit Circle</title><categories>cs.IT math.IT</categories><comments>28 pages. To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analytical methods for finding moments of random Vandermonde matrices with
entries on the unit circle are developed. Vandermonde Matrices play an
important role in signal processing and wireless applications such as direction
of arrival estimation, precoding, and sparse sampling theory, just to name a
few. Within this framework, we extend classical freeness results on random
matrices with independent, identically distributed (i.i.d.) entries and show
that Vandermonde structured matrices can be treated in the same vein with
different tools. We focus on various types of matrices, such as Vandermonde
matrices with and without uniform phase distributions, as well as generalized
Vandermonde matrices. In each case, we provide explicit expressions of the
moments of the associated Gram matrix, as well as more advanced models
involving the Vandermonde matrix. Comparisons with classical i.i.d. random
matrix theory are provided, and deconvolution results are discussed. We review
some applications of the results to the fields of signal processing and
wireless communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3572</identifier>
 <datestamp>2008-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3572</id><created>2008-02-25</created><updated>2008-11-21</updated><authors><author><keyname>Ryan</keyname><forenames>\Oyvind</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Random Vandermonde Matrices-Part II: Applications</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors, since it has been merged with
Part I (ID 0802.3570)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3582</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3582</id><created>2008-02-25</created><authors><author><keyname>Schikuta</keyname><forenames>Erich</forenames></author></authors><title>Neural Networks and Database Systems</title><categories>cs.DB cs.NE</categories><comments>19 pages, Festschrift Informationssysteme, in honor of G. Vinek</comments><acm-class>H.2.1</acm-class><journal-ref>pp. 133-152, 2007, publisher Austrian Computer Society</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object-oriented database systems proved very valuable at handling and
administrating complex objects. In the following guidelines for embedding
neural networks into such systems are presented. It is our goal to treat
networks as normal data in the database system. From the logical point of view,
a neural network is a complex data value and can be stored as a normal data
object. It is generally accepted that rule-based reasoning will play an
important role in future database applications. The knowledge base consists of
facts and rules, which are both stored and handled by the underlying database
system. Neural networks can be seen as representation of intensional knowledge
of intelligent database systems. So they are part of a rule based knowledge
pool and can be used like conventional rules. The user has a unified view about
his knowledge base regardless of the origin of the unique rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3597</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3597</id><created>2008-02-25</created><updated>2010-03-17</updated><authors><author><keyname>Yukalov</keyname><forenames>V. I.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author></authors><title>Processing Information in Quantum Decision Theory</title><categories>physics.soc-ph cs.AI quant-ph</categories><comments>Review article, 49 pages, Latex file</comments><journal-ref>Entropy 11 (2009) 1073-1120</journal-ref><doi>10.3390/e11041073</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A survey is given summarizing the state of the art of describing information
processing in Quantum Decision Theory, which has been recently advanced as a
novel variant of decision making, based on the mathematical theory of separable
Hilbert spaces. This mathematical structure captures the effect of
superposition of composite prospects, including many incorporated intended
actions. The theory characterizes entangled decision making, non-commutativity
of subsequent decisions, and intention interference. The self-consistent
procedure of decision making, in the frame of the quantum decision theory,
takes into account both the available objective information as well as
subjective contextual effects. This quantum approach avoids any paradox typical
of classical decision theory. Conditional maximization of entropy, equivalent
to the minimization of an information functional, makes it possible to connect
the quantum and classical decision theories, showing that the latter is the
limit of the former under vanishing interference terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3611</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3611</id><created>2008-02-25</created><authors><author><keyname>Nguyen</keyname><forenames>Khoa D.</forenames></author><author><keyname>Fabregas</keyname><forenames>Albert Guillen i</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars K.</forenames></author></authors><title>Power Allocation for Fading Channels with Peak-to-Average Power
  Constraints</title><categories>cs.IT math.IT</categories><comments>26 pages, 6 figures, submitted to IEEE Transaction on Wireless
  Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power allocation with peak-to-average power ratio constraints is investigated
for transmission over Nakagami-m fading channels with arbitrary input
distributions. In the case of delay-limited block-fading channels, we find the
solution to the minimum outage power allocation scheme with peak-to-average
power constraints and arbitrary input distributions, and show that the
signal-to-noise ratio exponent for any finite peak-to-average power ratio is
the same as that of the peak-power limited problem, resulting in an error
floor. In the case of the ergodic fully-interleaved channel, we find the power
allocation rule that yields the maximal information rate for an arbitrary input
distribution and show that capacities with peak-to-average power ratio
constraints, even for small ratios, are very close to capacities without
peak-power restrictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3617</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3617</id><created>2008-02-25</created><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Trenit&#xe9;</keyname><forenames>Sanne Nolst</forenames></author><author><keyname>van der Zwaag</keyname><forenames>Mark B.</forenames></author></authors><title>Towards a formalization of budgets</title><categories>cs.LO</categories><report-no>PRG0712</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We go into the need for, and the requirements on, a formal theory of budgets.
We present a simple algebraic theory of rational budgets, i.e., budgets in
which amounts of money are specified by functions on the rational numbers. This
theory is based on the tuplix calculus. We go into the importance of using
totalized models for the rational numbers. We present a case study on the
educational budget of a university department offering master programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3626</identifier>
 <datestamp>2008-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3626</id><created>2008-02-25</created><authors><author><keyname>Nayak</keyname><forenames>Birendra Kumar</forenames></author><author><keyname>Sahoo</keyname><forenames>Sudhakar</forenames></author><author><keyname>Rout</keyname><forenames>Sushant Kumar</forenames></author></authors><title>Color Graphs: An Efficient Model For Two-Dimensional Cellular Automata
  Linear Rules</title><categories>cs.LO</categories><comments>14 pages, presented at Orissa Mathematical Society Conference, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-dimensional nine neighbor hood rectangular Cellular Automata rules can be
modeled using many different techniques like Rule matrices, State Transition
Diagrams, Boolean functions, Algebraic Normal Form etc. In this paper, a new
model is introduced using color graphs to model all the 512 linear rules. The
graph theoretic properties therefore studied in this paper simplifies the
analysis of all linear rules in comparison with other ways of its study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3627</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3627</id><created>2008-02-25</created><updated>2008-02-29</updated><authors><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Ricci-Tersenghi</keyname><forenames>Federico</forenames></author><author><keyname>Semerjian</keyname><forenames>Guilhem</forenames></author></authors><title>Clusters of solutions and replica symmetry breaking in random
  k-satisfiability</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.CC</categories><comments>30 pages, 14 figures, typos corrected, discussion of appendix C
  expanded with a new figure</comments><journal-ref>J. Stat. Mech. P04004 (2008)</journal-ref><doi>10.1088/1742-5468/2008/04/P04004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the set of solutions of random k-satisfiability formulae through the
cavity method. It is known that, for an interval of the clause-to-variables
ratio, this decomposes into an exponential number of pure states (clusters). We
refine substantially this picture by: (i) determining the precise location of
the clustering transition; (ii) uncovering a second `condensation' phase
transition in the structure of the solution set for k larger or equal than 4.
These results both follow from computing the large deviation rate of the
internal entropy of pure states. From a technical point of view our main
contributions are a simplified version of the cavity formalism for special
values of the Parisi replica symmetry breaking parameter m (in particular for
m=1 via a correspondence with the tree reconstruction problem) and new large-k
expansions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3628</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3628</id><created>2008-02-25</created><authors><author><keyname>Thierry</keyname><forenames>Pierre</forenames></author><author><keyname>Thierry</keyname><forenames>Simon E. B.</forenames></author></authors><title>Dynamic data models: an application of MOP-based persistence in Common
  Lisp</title><categories>cs.SE</categories><comments>Presented at the 4th European Lisp Workshop, co-located with ECOOP
  2007. No proceedings</comments><acm-class>D.2.2; D.2.11; D.3.3; D.1.5; D.4.5; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The data model of an application, the nature and format of data stored across
executions, is typically a very rigid part of its early specification, even
when prototyping, and changing it after code that relies on it was written can
prove quite expensive and error-prone.
  Code and data in a running Lisp image can be dynamically modified. A
MOP-based persistence library can bring this dynamicity to the data model. This
enables to extend the easy prototyping way of development to the storage of
data and helps avoiding interruptions of service. This article presents the
conditions to do this portably and transparently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3634</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3634</id><created>2008-02-25</created><authors><author><keyname>Kujawski</keyname><forenames>B.</forenames></author><author><keyname>Rodgers</keyname><forenames>G. J.</forenames></author><author><keyname>Tadi&#x107;</keyname><forenames>Bosiljka</forenames></author></authors><title>Local Information Based Algorithms for Packet Transport in Complex
  Networks</title><categories>cs.NI</categories><journal-ref>In V.N. Alexnandrov et l., editor, ICCS 2006, volume \textbf{3993}
  of Lecture Notes in Computer Science, pages 1024-1031, Berlin, 2006, Springer</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce four algorithms for packet transport in complex networks. These
algorithms use deterministic rules which depend, in different ways, on the
degree of the node, the number of packets posted down each edge, the mean
delivery time of packets sent down each edge to each destination and the time
since an edge last transmitted a packet. On scale-free networks all our
algorithms are considerably more efficient and can handle a larger load than
the random walk algorithm. We consider in detail various attributes of our
algorithms, for instance we show that an algorithm that bases its decisions on
the mean delivery time jams unless it incorporates information about the degree
of the destination node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3665</identifier>
 <datestamp>2008-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3665</id><created>2008-02-25</created><authors><author><keyname>Traven&#xe7;olo</keyname><forenames>Bruno Augusto Nassif</forenames></author><author><keyname>Costa</keyname><forenames>Luciano da Fontoura</forenames></author></authors><title>Outward Accessibility in Urban Street Networks: Characterization and
  Improvements</title><categories>cs.CY</categories><comments>4 pages, 2 figures. The following article has been submitted to
  Applied Physics Letters. After it is published, it will be found at
  http://apl.aip.org</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamics of transportation through towns and cities is strongly affected
by the topology of the connections and routes. The current work describes an
approach combining complex networks and self-avoiding random walk dynamics in
order to quantify in objective and accurate manner, along a range of spatial
scales, the accessibility of places in towns and cities. The transition
probabilities are estimated for several lengths of the walks and used to
calculate the outward accessibility of each node. The potential of the
methodology is illustrated with respect to the characterization and
improvements of the accessibility of the town of Sao Carlos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3703</identifier>
 <datestamp>2008-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3703</id><created>2008-02-26</created><authors><author><keyname>Krot-Sieniawska</keyname><forenames>Ewa</forenames></author></authors><title>On incidence algebras description of cobweb posets</title><categories>math.CO cs.DM</categories><comments>9 pages</comments><msc-class>06A06, 06A07, 06A11, 11C08, 11B37</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The explicite formulas for Mobius function and some other important elements
of the incidence algebra of an arbitrary cobweb poset are delivered. For that
to do one uses Kwasniewski's construction of his cobweb posets . The digraph
representation of these cobweb posets constitutes a newly discovered class of
orderable DAG's named here down KoDAGs with a kind of universality now being
investigated. Namely cobweb posets' and thus KoDAGs's defining di-bicliques are
links of any complete relations' chains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3718</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3718</id><created>2008-02-26</created><authors><author><keyname>Garcia-Alfaro</keyname><forenames>Joaquin</forenames></author><author><keyname>Jaeger</keyname><forenames>Michael A.</forenames></author><author><keyname>Muehl</keyname><forenames>Gero</forenames></author><author><keyname>Borrell</keyname><forenames>Joan</forenames></author></authors><title>Preventing Coordinated Attacks Via Distributed Alert Exchange</title><categories>cs.CR cs.NI</categories><comments>19 pages, proposal reviewed</comments><journal-ref>IFIP International Conference on Intelligence in Communication
  Systems (INTELLCOMM 2005) (17/10/2005) 87-98</journal-ref><abstract>  Attacks on information systems followed by intrusions may cause large revenue
losses. The prevention of both is not always possible by just considering
information from isolated sources of the network. A global view of the whole
system is necessary to recognize and react to the different actions of such an
attack. The design and deployment of a decentralized system targeted at
detecting as well as reacting to information system attacks might benefit from
the loose coupling realized by publish/subscribe middleware. In this paper, we
present the advantages and convenience in using this communication paradigm for
a general decentralized attack prevention framework. Furthermore, we present
the design and implementation of our approach based on existing
publish/subscribe middleware and evaluate our approach for GNU/Linux systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3734</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3734</id><created>2008-02-25</created><authors><author><keyname>Myasnikov</keyname><forenames>Alex D.</forenames></author></authors><title>Generic case complexity and One-Way functions</title><categories>cs.CC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to introduce ideas and methodology of the generic
case complexity to cryptography community. This relatively new approach allows
one to analyze the behavior of an algorithm on ''most'' inputs in a simple and
intuitive fashion which has some practical advantages over classical methods
based on averaging. We present an alternative definition of one-way function
using the concepts of generic case complexity and show its equivalence to the
standard definition. In addition we demonstrate the convenience of the new
approach by giving a short proof that extending adversaries to a larger class
of partial algorithms with errors does not change the strength of the security
assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3746</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3746</id><created>2008-02-26</created><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author></authors><title>Information Hiding Techniques: A Tutorial Review</title><categories>cs.CR cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this tutorial is to present an overview of various information
hiding techniques. A brief history of steganography is provided along with
techniques that were used to hide information. Text, image and audio based
information hiding techniques are discussed. This paper also provides a basic
introduction to digital watermarking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3767</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3767</id><created>2008-02-26</created><authors><author><keyname>Mathias</keyname><forenames>H.</forenames><affiliation>IEF</affiliation></author><author><keyname>Parrain</keyname><forenames>F.</forenames><affiliation>IEF</affiliation></author><author><keyname>Gilles</keyname><forenames>J. -P.</forenames><affiliation>IEF</affiliation></author><author><keyname>Megherbi</keyname><forenames>S.</forenames><affiliation>IEF</affiliation></author><author><keyname>Zhang</keyname><forenames>M.</forenames><affiliation>IEF</affiliation></author><author><keyname>Coste</keyname><forenames>Ph.</forenames><affiliation>IEF</affiliation></author><author><keyname>Dupret</keyname><forenames>A.</forenames><affiliation>IEF</affiliation></author></authors><title>Architecture for Integrated Mems Resonators Quality Factor Measurement</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257651</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  In this paper, an architecture designed for electrical measurement of the
quality factor of MEMS resonators is proposed. An estimation of the measurement
performance is made using PSPICE simulations taking into account the
component's non-idealities. An error on the measured Q value of only several
percent is achievable, at a small integration cost, for sufficiently high
quality factor values (Q &gt; 100).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3768</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3768</id><created>2008-02-26</created><authors><author><keyname>Izadi</keyname><forenames>N.</forenames></author><author><keyname>Jaganatharaja</keyname><forenames>R. K.</forenames></author><author><keyname>Floris</keyname><forenames>J.</forenames></author><author><keyname>Krijnen</keyname><forenames>G.</forenames></author></authors><title>Optimization of Cricket-inspired, Biomimetic Artificial Hair Sensors for
  Flow Sensing</title><categories>cs.OH</categories><comments>Submitted on behalf of EDA Publishing Association
  (http://irevues.inist.fr/EDA-Publishing)</comments><proxy>ccsd hal-00257672</proxy><journal-ref>Dans Symposium on Design, Test, Integration and Packaging of
  MEMS/MOEMS - DTIP 2007, Stresa, lago Maggiore : Italie (2007)</journal-ref><abstract>  High density arrays of artificial hair sensors, biomimicking the extremely
sensitive mechanoreceptive filiform hairs found on cerci of crickets have been
fabricated successfully. We assess the sensitivity of these artificial sensors
and present a scheme for further optimization addressing the deteriorating
effects of stress in the structures. We show that, by removing a portion of
chromium electrodes close to the torsional beams, the upward lift at the edges
of the membrane due to the stress, will decrease hence increase the
sensitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3784</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3784</id><created>2008-02-26</created><authors><author><keyname>Overton</keyname><forenames>Jerry</forenames></author></authors><title>Pattern-Oriented Analysis and Design (POAD) Theory</title><categories>cs.SE cs.IT math.IT</categories><abstract>  Pattern-Oriented Analysis and Design (POAD) is the practice of building
complex software by applying proven designs to specific problem domains.
Although a great deal of research and practice has been devoted to formalizing
existing design patterns and discovering new ones, there has been relatively
little research into methods for combining these patterns into software
applications. This is partly because the creation of complex software
applications is so expensive. This paper proposes a mathematical model of POAD
that may allow future research in pattern-oriented techniques to be performed
using less expensive formal techniques rather than expensive, complex software
development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3789</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3789</id><created>2008-02-26</created><authors><author><keyname>Milton</keyname><forenames>Nick</forenames></author></authors><title>Knowledge Technologies</title><categories>cs.CY cs.AI cs.LG cs.SE</categories><comments>130 pages, ISBN 978-88-7699-099-1 (Printed edition), ISBN
  978-88-7699-100-4 (Electronic edition), printed edition available at
  http://stores.lulu.com/polimetrica and on http://www.amazon.com/</comments><journal-ref>&quot;Publishing studies&quot; book series, edited by Giandomenico Sica,
  ISSN 1973-6061 (Printed edition), ISSN 1973-6053 (Electronic edition)</journal-ref><abstract>  Several technologies are emerging that provide new ways to capture, store,
present and use knowledge. This book is the first to provide a comprehensive
introduction to five of the most important of these technologies: Knowledge
Engineering, Knowledge Based Engineering, Knowledge Webs, Ontologies and
Semantic Webs. For each of these, answers are given to a number of key
questions (What is it? How does it operate? How is a system developed? What can
it be used for? What tools are available? What are the main issues?). The book
is aimed at students, researchers and practitioners interested in Knowledge
Management, Artificial Intelligence, Design Engineering and Web Technologies.
  During the 1990s, Nick worked at the University of Nottingham on the
application of AI techniques to knowledge management and on various knowledge
acquisition projects to develop expert systems for military applications. In
1999, he joined Epistemics where he worked on numerous knowledge projects and
helped establish knowledge management programmes at large organisations in the
engineering, technology and legal sectors. He is author of the book &quot;Knowledge
Acquisition in Practice&quot;, which describes a step-by-step procedure for
acquiring and implementing expertise. He maintains strong links with leading
research organisations working on knowledge technologies, such as
knowledge-based engineering, ontologies and semantic technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3820</identifier>
 <datestamp>2014-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3820</id><created>2008-02-26</created><updated>2012-07-18</updated><authors><author><keyname>Skopenkov</keyname><forenames>A.</forenames></author></authors><title>On the Kuratowski graph planarity criterion</title><categories>math.GT cs.DM math.CO</categories><comments>English version: 4 pages and 4 figures, Russian version: 10 pages and
  13 figures. Exposition improved</comments><msc-class>57M15, 05C10</msc-class><journal-ref>Mat. Prosveschenie, 9 (2005), 116-128, and 11 (2007), 159--160</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is purely expositional. The statement of the Kuratowski graph
planarity criterion is simple and well-known. However, its classical proof is
not easy. In this paper we present the Makarychev proof (with further
simplifications by Prasolov, Telishev, Zaslavski and the author) which is
possibly the simplest. In the Rusian version before the proof we present all
the necessary definitions, and afterwards we state some close results on graphs
and more general spaces. The paper is accessible for students familiar with the
notion of a graph, and could be an interesting easy reading for mature
mathematicians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3851</identifier>
 <datestamp>2009-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3851</id><created>2008-02-26</created><authors><author><keyname>Wilson</keyname><forenames>Makesh Pravin</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Joint Source Channel Coding with Side Information Using Hybrid Digital
  Analog Codes</title><categories>cs.IT math.IT</categories><comments>22 pages, 10 figures, submitted to IEEE Transactions on Information
  Theory(Oct 2007)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the joint source channel coding problem of transmitting an analog
source over a Gaussian channel in two cases - (i) the presence of interference
known only to the transmitter and (ii) in the presence of side information
known only to the receiver. We introduce hybrid digital analog forms of the
Costa and Wyner-Ziv coding schemes. Our schemes are based on random coding
arguments and are different from the nested lattice schemes by Kochman and
Zamir that use dithered quantization. We also discuss superimposed digital and
analog schemes for the above problems which show that there are infinitely many
schemes for achieving the optimal distortion for these problems. This provides
an extension of the schemes by Bross et al to the interference/side information
case. We then discuss applications of the hybrid digital analog schemes for
transmitting under a channel signal-to-noise ratio mismatch and for
broadcasting a Gaussian source with bandwidth compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3855</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3855</id><created>2008-02-26</created><authors><author><keyname>Gangasani</keyname><forenames>Sumanth Kumar Reddy</forenames></author></authors><title>The Discrete Hilbert Transform for Non-Periodic Signals</title><categories>cs.CR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note investigates the size of the guard band for non-periodic discrete
Hilbert transform, which has recently been proposed for data hiding and
security applications. It is shown that a guard band equal to the duration of
the message is sufficient for a variety of analog signals and is, therefore,
likely to be adequate for discrete or digital data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3860</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3860</id><created>2008-02-26</created><authors><author><keyname>David</keyname><forenames>Matei</forenames></author><author><keyname>Pitassi</keyname><forenames>Toniann</forenames></author></authors><title>Separating NOF communication complexity classes RP and NP</title><categories>cs.CC</categories><acm-class>F.1.3</acm-class><abstract>  We provide a non-explicit separation of the number-on-forehead communication
complexity classes RP and NP when the number of players is up to \delta log(n)
for any \delta&lt;1. Recent lower bounds on Set-Disjointness [LS08,CA08] provide
an explicit separation between these classes when the number of players is only
up to o(loglog(n)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3875</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3875</id><created>2008-02-26</created><authors><author><keyname>Adamatzky</keyname><forenames>Andy</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>Are complex systems hard to evolve?</title><categories>cs.NE</categories><journal-ref>Volume 14, Issue 6, pages 15-20, July/August 2009</journal-ref><doi>10.1002/cplx.20269</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary complexity is here measured by the number of trials/evaluations
needed for evolving a logical gate in a non-linear medium. Behavioural
complexity of the gates evolved is characterised in terms of cellular automata
behaviour. We speculate that hierarchies of behavioural and evolutionary
complexities are isomorphic up to some degree, subject to substrate specificity
of evolution and the spectrum of evolution parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3881</identifier>
 <datestamp>2008-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3881</id><created>2008-02-26</created><authors><author><keyname>Almeida</keyname><forenames>Jos&#xe9; Bacelar</forenames></author><author><keyname>Pinto</keyname><forenames>Jorge Sousa</forenames></author></authors><title>Deriving Sorting Algorithms</title><categories>cs.DS cs.LO</categories><comments>Technical Report</comments><report-no>DI-PURe-06.04.01</report-no><abstract>  This paper proposes new derivations of three well-known sorting algorithms,
in their functional formulation. The approach we use is based on three main
ingredients: first, the algorithms are derived from a simpler algorithm, i.e.
the specification is already a solution to the problem (in this sense our
derivations are program transformations). Secondly, a mixture of inductive and
coinductive arguments are used in a uniform, algebraic style in our reasoning.
Finally, the approach uses structural invariants so as to strengthen the
equational reasoning with logical arguments that cannot be captured in the
algebraic framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3885</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3885</id><created>2008-02-26</created><authors><author><keyname>de Luca</keyname><forenames>Aldo</forenames></author><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames></author></authors><title>Rich, Sturmian, and trapezoidal words</title><categories>math.CO cs.DM</categories><comments>7 pages</comments><msc-class>68R15</msc-class><journal-ref>Theoretical Computer Science 407 (2008) 569--573</journal-ref><doi>10.1016/j.tcs.2008.06.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore various interconnections between rich words,
Sturmian words, and trapezoidal words. Rich words, first introduced in
arXiv:0801.1656 by the second and third authors together with J. Justin and S.
Widmer, constitute a new class of finite and infinite words characterized by
having the maximal number of palindromic factors. Every finite Sturmian word is
rich, but not conversely. Trapezoidal words were first introduced by the first
author in studying the behavior of the subword complexity of finite Sturmian
words. Unfortunately this property does not characterize finite Sturmian words.
In this note we show that the only trapezoidal palindromes are Sturmian. More
generally we show that Sturmian palindromes can be characterized either in
terms of their subword complexity (the trapezoidal property) or in terms of
their palindromic complexity. We also obtain a similar characterization of rich
palindromes in terms of a relation between palindromic complexity and subword
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3888</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3888</id><created>2008-02-26</created><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Lev&#xe9;</keyname><forenames>Florence</forenames></author><author><keyname>Richomme</keyname><forenames>Gw&#xe9;na&#xeb;l</forenames></author></authors><title>Directive words of episturmian words: equivalences and normalization</title><categories>cs.DM math.CO</categories><comments>15 pages</comments><journal-ref>RAIRO - Theoretical Informatics and Applications 43 (2009) 299-319</journal-ref><doi>10.1051/ita:2008029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Episturmian morphisms constitute a powerful tool to study episturmian words.
Indeed, any episturmian word can be infinitely decomposed over the set of pure
episturmian morphisms. Thus, an episturmian word can be defined by one of its
morphic decompositions or, equivalently, by a certain directive word. Here we
characterize pairs of words directing a common episturmian word. We also
propose a way to uniquely define any episturmian word through a normalization
of its directive words. As a consequence of these results, we characterize
episturmian words having a unique directive word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3895</identifier>
 <datestamp>2008-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3895</id><created>2008-02-26</created><authors><author><keyname>Bregar</keyname><forenames>Andrej</forenames></author></authors><title>Complexity Metrics for Spreadsheet Models</title><categories>cs.SE</categories><comments>9 pages, 5 figures</comments><acm-class>D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 85-93
  ISBN 1 902724 94 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several complexity metrics are described which are related to logic
structure, data structure and size of spreadsheet models. They primarily
concentrate on the dispersion of cell references and cell paths. Most metrics
are newly defined, while some are adapted from traditional software
engineering. Their purpose is the identification of cells which are liable to
errors. In addition, they can be used to estimate the values of dependent
process metrics, such as the development duration and effort, and especially to
adjust the cell error rate in accordance with the contents of each individual
cell, in order to accurately asses the reliability of a model. Finally, two
conceptual constructs - the reference branching condition cell and the
condition block - are discussed, aiming at improving the reliability,
modifiability, auditability and comprehensibility of logical tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3919</identifier>
 <datestamp>2008-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3919</id><created>2008-02-26</created><authors><author><keyname>Grossman</keyname><forenames>Thomas A.</forenames></author><author><keyname>Ozluk</keyname><forenames>Ozgur</forenames></author></authors><title>A Paradigm for Spreadsheet Engineering Methodologies</title><categories>cs.HC</categories><comments>11 Pages</comments><acm-class>D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 23-33
  ISBN 1 902724 94 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheet engineering methodologies are diverse and sometimes
contradictory. It is difficult for spreadsheet developers to identify a
spreadsheet engineering methodology that is appropriate for their class of
spreadsheet, with its unique combination of goals, type of problem, and
available time and resources. There is a lack of well-organized, proven
methodologies with known costs and benefits for well-defined spreadsheet
classes. It is difficult to compare and critically evaluate methodologies. We
present a paradigm for organizing and interpreting spreadsheet engineering
recommendations. It systematically addresses the myriad choices made when
developing a spreadsheet, and explicitly considers resource constraints and
other development parameters. This paradigm provides a framework for
evaluation, comparison, and selection of methodologies, and a list of essential
elements for developers or codifiers of new methodologies. This paradigm
identifies gaps in our knowledge that merit further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3924</identifier>
 <datestamp>2008-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3924</id><created>2008-02-26</created><authors><author><keyname>Clermont</keyname><forenames>Markus</forenames></author></authors><title>A Toolkit for Scalable Spreadsheet Visualization</title><categories>cs.HC</categories><comments>12 Pages</comments><acm-class>D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 95-106
  ISBN 1 902724 94 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a toolkit for spreadsheet visualization based on logical
areas, semantic classes and data modules. Logical areas, semantic classes and
data modules are abstract representations of spreadsheet programs that are
meant to reduce the auditing and comprehension effort, especially for large and
regular spreadsheets. The toolkit is integrated as a plug-in in the Gnumeric
spreadsheet system for Linux. It can process large, industry scale spreadsheet
programs in reasonable time and is tightly integrated with its host spreadsheet
system. Users can generate hierarchical and graph-based representations of
their spreadsheets. This allows them to spot conceptual similarities in
different regions of the spreadsheet, that would otherwise not fit on a screen.
As it is assumed that the learning effort for effective use of such a tool
should be kept low, we aim for intuitive handling of most of the tool's
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3939</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3939</id><created>2008-02-26</created><authors><author><keyname>Hipfl</keyname><forenames>Sabine</forenames></author></authors><title>Using Layout Information for Spreadsheet Visualization</title><categories>cs.HC</categories><comments>13 pages, 3 colour figures</comments><acm-class>D.2.4; D.2.5; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 107-119
  ISBN 1 902724 94 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends a spreadsheet visualization technique by using layout
information. The original approach identifies logically or semantically related
cells by relying exclusively on the content of cells for identifying semantic
classes. A disadvantage of semantic classes is that users have to supply
parameters which describe the possible shapes of these blocks. The correct
parametrization requires a certain degree of experience and is thus not
suitable for untrained users. To avoid this constraint, the approach reported
in this paper uses row/column-labels as well as common format information for
locating areas with common, recurring semantics. Heuristics are provided to
distinguish between cell groups with intended common semantics and cell groups
related in an ad-hoc manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3940</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3940</id><created>2008-02-26</created><authors><author><keyname>Paine</keyname><forenames>Jocelyn</forenames></author></authors><title>Spreadsheet Structure Discovery with Logic Programming</title><categories>cs.SE</categories><comments>11 pages, code fragments</comments><acm-class>D.1.7; D.2.1; D.2.11; D.3.2; D.3.3; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 121-133
  ISBN 1 902724 94 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our term &quot;structure discovery&quot; denotes the recovery of structure, such as the
grouping of cells, that was intended by a spreadsheet's author but is not
explicit in the spreadsheet. We are implementing structure discovery tools in
the logic-programming language Prolog for our spreadsheet analysis program
Model Master, by writing grammars for spreadsheet structures. The objective is
an &quot;intelligent structure monitor&quot; to run beside Excel, allowing users to
reconfigure spreadsheets to the representational needs of the task at hand.
This could revolutionise spreadsheet &quot;best practice&quot;. We also describe a
formulation of spreadsheet reverse-engineering based on &quot;arrows&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3950</identifier>
 <datestamp>2008-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3950</id><created>2008-02-27</created><updated>2008-04-11</updated><authors><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames></author><author><keyname>Teodorescu</keyname><forenames>Razvan</forenames></author></authors><title>Belief Propagation and Loop Series on Planar Graphs</title><categories>cond-mat.stat-mech cs.AI cs.IT math.IT</categories><comments>Accepted for publication in Journal of Statistical Mechanics: theory
  and experiment</comments><journal-ref>J. Stat. Mech. (2008) P05003</journal-ref><doi>10.1088/1742-5468/2008/05/P05003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a generic model of Bayesian inference with binary variables
defined on edges of a planar graph. The Loop Calculus approach of [1, 2] is
used to evaluate the resulting series expansion for the partition function. We
show that, for planar graphs, truncating the series at single-connected loops
reduces, via a map reminiscent of the Fisher transformation [3], to evaluating
the partition function of the dimer matching model on an auxiliary planar
graph. Thus, the truncated series can be easily re-summed, using the Pfaffian
formula of Kasteleyn [4]. This allows to identify a big class of
computationally tractable planar models reducible to a dimer model via the
Belief Propagation (gauge) transformation. The Pfaffian representation can also
be extended to the full Loop Series, in which case the expansion becomes a sum
of Pfaffian contributions, each associated with dimer matchings on an extension
to a subgraph of the original graph. Algorithmic consequences of the Pfaffian
representation, as well as relations to quantum and non-planar models, are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3974</identifier>
 <datestamp>2008-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3974</id><created>2008-02-27</created><updated>2008-02-28</updated><authors><author><keyname>Lapshin</keyname><forenames>Vladimir</forenames></author></authors><title>Syntax diagrams as a formalism for representation of syntactic relations
  of formal languages</title><categories>cs.LO</categories><comments>10 pages</comments><acm-class>F.4.2; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The new approach to representation of syntax of formal languages-- a
formalism of syntax diagrams is offered. Syntax diagrams look a convenient
language for the description of syntactic relations in the languages having
nonlinear representation of texts, for example, for representation of syntax
lows of the language of structural chemical formulas. The formalism of
neighbourhood grammar is used to describe the set of correct syntax constructs.
The neighbourhood the grammar consists of a set of families of
&quot;neighbourhoods&quot;-- the diagrams defined for each symbol of the language's
alphabet. The syntax diagram is correct if each symbol is included into this
diagram together with some neighbourhood. In other words, correct diagrams are
needed to be covered by elements of the neighbourhood grammar. Thus, the
grammar of formal language can be represented as system of the covers defined
for each correct syntax diagram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3992</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3992</id><created>2008-02-27</created><authors><author><keyname>Kokiopoulou</keyname><forenames>Effrosyni</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Polynomial Filtering for Fast Convergence in Distributed Consensus</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><report-no>LTS-2008-005</report-no><doi>10.1109/TSP.2008.2006147</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few years, the problem of distributed consensus has received a
lot of attention, particularly in the framework of ad hoc sensor networks. Most
methods proposed in the literature address the consensus averaging problem by
distributed linear iterative algorithms, with asymptotic convergence of the
consensus solution. The convergence rate of such distributed algorithms
typically depends on the network topology and the weights given to the edges
between neighboring sensors, as described by the network matrix. In this paper,
we propose to accelerate the convergence rate for given network matrices by the
use of polynomial filtering algorithms. The main idea of the proposed
methodology is to apply a polynomial filter on the network matrix that will
shape its spectrum in order to increase the convergence rate. Such an algorithm
is equivalent to periodic updates in each of the sensors by aggregating a few
of its previous estimates. We formulate the computation of the coefficients of
the optimal polynomial as a semi-definite program that can be efficiently and
globally solved for both static and dynamic network topologies. We finally
provide simulation results that demonstrate the effectiveness of the proposed
solutions in accelerating the convergence of distributed consensus averaging
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4002</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4002</id><created>2008-02-27</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author></authors><title>Sensing Danger: Innate Immunology for Intrusion Detection</title><categories>cs.NE cs.CR</categories><journal-ref>Information Security Technical Report, 12(4), pp 218-227, 2007</journal-ref><doi>10.1016/j.istr.2007.10.003</doi><abstract>  The immune system provides an ideal metaphor for anomaly detection in general
and computer security in particular. Based on this idea, artificial immune
systems have been used for a number of years for intrusion detection,
unfortunately so far with little success. However, these previous systems were
largely based on immunological theory from the 1970s and 1980s and over the
last decade our understanding of immunological processes has vastly improved.
In this paper we present two new immune inspired algorithms based on the latest
immunological discoveries, such as the behaviour of Dendritic Cells. The
resultant algorithms are applied to real world intrusion problems and show
encouraging results. Overall, we believe there is a bright future for these
next generation artificial immune algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4010</identifier>
 <datestamp>2008-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4010</id><created>2008-02-27</created><authors><author><keyname>Kaiser</keyname><forenames>Marcus</forenames></author></authors><title>Brain architecture: A design for natural computation</title><categories>q-bio.NC cs.AI cs.NE physics.soc-ph</categories><journal-ref>Philosophical Transactions of The Royal Society A, 365: 3033-3045,
  2007</journal-ref><doi>10.1098/rsta.2007.0007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifty years ago, John von Neumann compared the architecture of the brain with
that of computers that he invented and which is still in use today. In those
days, the organisation of computers was based on concepts of brain
organisation. Here, we give an update on current results on the global
organisation of neural systems. For neural systems, we outline how the spatial
and topological architecture of neuronal and cortical networks facilitates
robustness against failures, fast processing, and balanced network activation.
Finally, we discuss mechanisms of self-organization for such architectures.
After all, the organization of the brain might again inspire computer
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4018</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4018</id><created>2008-02-27</created><updated>2008-03-21</updated><authors><author><keyname>Ma</keyname><forenames>Qin</forenames></author><author><keyname>Maranget</keyname><forenames>Luc</forenames></author></authors><title>Algebraic Pattern Matching in Join Calculus</title><categories>cs.PL cs.DC</categories><acm-class>D.1.3; D.3.3; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 1 (March 21,
  2008) lmcs:770</journal-ref><doi>10.2168/LMCS-4(1:7)2008</doi><abstract>  We propose an extension of the join calculus with pattern matching on
algebraic data types. Our initial motivation is twofold: to provide an
intuitive semantics of the interaction between concurrency and pattern
matching; to define a practical compilation scheme from extended join
definitions into ordinary ones plus ML pattern matching. To assess the
correctness of our compilation scheme, we develop a theory of the applied join
calculus, a calculus with value passing and value matching. We implement this
calculus as an extension of the current JoCaml system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4040</identifier>
 <datestamp>2008-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4040</id><created>2008-02-27</created><updated>2008-10-03</updated><authors><author><keyname>Boettcher</keyname><forenames>Stefan</forenames></author><author><keyname>Mertens</keyname><forenames>Stephan</forenames></author></authors><title>Analysis of the Karmarkar-Karp Differencing Algorithm</title><categories>cs.NA cond-mat.dis-nn cs.DM cs.DS</categories><comments>9 pages, 8 figures; minor changes</comments><journal-ref>European Physics Journal B 65, 131-140 (2008)</journal-ref><doi>10.1140/epjb/e2008-00320-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Karmarkar-Karp differencing algorithm is the best known polynomial time
heuristic for the number partitioning problem, fundamental in both theoretical
computer science and statistical physics. We analyze the performance of the
differencing algorithm on random instances by mapping it to a nonlinear rate
equation. Our analysis reveals strong finite size effects that explain why the
precise asymptotics of the differencing solution is hard to establish by
simulations. The asymptotic series emerging from the rate equation satisfies
all known bounds on the Karmarkar-Karp algorithm and projects a scaling
$n^{-c\ln n}$, where $c=1/(2\ln2)=0.7213...$. Our calculations reveal subtle
relations between the algorithm and Fibonacci-like sequences, and we establish
an explicit identity to that effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4057</identifier>
 <datestamp>2008-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4057</id><created>2008-02-27</created><updated>2008-03-05</updated><authors><author><keyname>Masini</keyname><forenames>Andrea</forenames></author><author><keyname>Vigan&#xf2;</keyname><forenames>Luca</forenames></author><author><keyname>Zorzi</keyname><forenames>Margherita</forenames></author></authors><title>A Qualitative Modal Representation of Quantum Register Transformations</title><categories>cs.LO</categories><abstract>  We introduce two modal natural deduction systems that are suitable to
represent and reason about transformations of quantum registers in an abstract,
qualitative, way. Quantum registers represent quantum systems, and can be
viewed as the structure of quantum data for quantum operations. Our systems
provide a modal framework for reasoning about operations on quantum registers
(unitary transformations and measurements), in terms of possible worlds (as
abstractions of quantum registers) and accessibility relations between these
worlds. We give a Kripke--style semantics that formally describes quantum
register transformations and prove the soundness and completeness of our
systems with respect to this semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4079</identifier>
 <datestamp>2008-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4079</id><created>2008-02-27</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author></authors><title>Families of LDPC Codes Derived from Nonprimitive BCH Codes and
  Cyclotomic Cosets</title><categories>cs.IT math.IT</categories><comments>Private comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-density parity check (LDPC) codes are an important class of codes with
many applications. Two algebraic methods for constructing regular LDPC codes
are derived -- one based on nonprimitive narrow-sense BCH codes and the other
directly based on cyclotomic cosets. The constructed codes have high rates and
are free of cycles of length four; consequently, they can be decoded using
standard iterative decoding algorithms. The exact dimension and bounds for the
minimum distance and stopping distance are derived. These constructed codes can
be used to derive quantum error-correcting codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4089</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4089</id><created>2008-02-28</created><updated>2008-03-16</updated><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>An algorithmic complexity interpretation of Lin's third law of
  information theory</title><categories>cs.CC cs.IT math.IT</categories><doi>10.3390/entropy-e10010006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instead of static entropy we assert that the Kolmogorov complexity of a
static structure such as a solid is the proper measure of disorder (or
chaoticity). A static structure in a surrounding perfectly-random universe acts
as an interfering entity which introduces local disruption in randomness. This
is modeled by a selection rule $R$ which selects a subsequence of the random
input sequence that hits the structure. Through the inequality that relates
stochasticity and chaoticity of random binary sequences we maintain that Lin's
notion of stability corresponds to the stability of the frequency of 1s in the
selected subsequence. This explains why more complex static structures are less
stable. Lin's third law is represented as the inevitable change that static
structure undergo towards conforming to the universe's perfect randomness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4095</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4095</id><created>2008-02-27</created><authors><author><keyname>Currie</keyname><forenames>James D.</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>For each $\alpha$ &gt; 2 there is an infinite binary word with critical
  exponent $\alpha$</title><categories>math.CO cs.FL</categories><comments>5 pages</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For each $\alpha &gt; 2$ there is a binary word with critical exponent $\alpha$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4101</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4101</id><created>2008-02-27</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Zhang</keyname><forenames>Shengyu</forenames></author></authors><title>New bounds on classical and quantum one-way communication complexity</title><categories>cs.IT cs.DC math.IT</categories><comments>ver 1, 19 pages</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide new bounds on classical and quantum distributional
communication complexity in the two-party, one-way model of communication. In
the classical model, our bound extends the well known upper bound of Kremer,
Nisan and Ron to include non-product distributions. We show that for a boolean
function f:X x Y -&gt; {0,1} and a non-product distribution mu on X x Y and
epsilon in (0,1/2) constant: D_{epsilon}^{1, mu}(f)= O((I(X:Y)+1) vc(f)), where
D_{epsilon}^{1, mu}(f) represents the one-way distributional communication
complexity of f with error at most epsilon under mu; vc(f) represents the
Vapnik-Chervonenkis dimension of f and I(X:Y) represents the mutual
information, under mu, between the random inputs of the two parties. For a
non-boolean function f:X x Y -&gt;[k], we show a similar upper bound on
D_{epsilon}^{1, mu}(f) in terms of k, I(X:Y) and the pseudo-dimension of f' =
f/k. In the quantum one-way model we provide a lower bound on the
distributional communication complexity, under product distributions, of a
function f, in terms the well studied complexity measure of f referred to as
the rectangle bound or the corruption bound of f . We show for a non-boolean
total function f : X x Y -&gt; Z and a product distribution mu on XxY,
Q_{epsilon^3/8}^{1, mu}(f) = Omega(rec_ epsilon^{1, mu}(f)), where
Q_{epsilon^3/8}^{1, mu}(f) represents the quantum one-way distributional
communication complexity of f with error at most epsilon^3/8 under mu and rec_
epsilon^{1, mu}(f) represents the one-way rectangle bound of f with error at
most epsilon under mu . Similarly for a non-boolean partial function f:XxY -&gt; Z
U {*} and a product distribution mu on X x Y, we show, Q_{epsilon^6/(2 x
15^4)}^{1, mu}(f) = Omega(rec_ epsilon^{1, mu}(f)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4112</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4112</id><created>2008-02-27</created><authors><author><keyname>Makaruk</keyname><forenames>Hanna E.</forenames></author><author><keyname>Owczarek</keyname><forenames>Robert</forenames></author></authors><title>Hubs in Languages: Scale Free Networks of Synonyms</title><categories>physics.soc-ph cs.CL physics.data-an</categories><report-no>LA-UR-08-0084</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural languages are described in this paper in terms of networks of
synonyms: a word is identified with a node, and synonyms are connected by
undirected links. Our statistical analysis of the network of synonyms in Polish
language showed it is scale-free; similar to what is known for English. The
statistical properties of the networks are also similar. Thus, the statistical
aspects of the networks are good candidates for culture independent elements of
human language. We hypothesize that optimization for robustness and efficiency
is responsible for this universality. Despite the statistical similarity, there
is no one-to-one mapping between networks of these two languages. Although many
hubs in Polish are translated into similarly highly connected hubs in English,
there are also hubs specific to one of these languages only: a single word in
one language is equivalent to many different and disconnected words in the
other, in accordance with the Whorf hypothesis about language relativity.
Identifying language-specific hubs is vitally important for automatic
translation, and for understanding contextual, culturally related messages that
are frequently missed or twisted in a naive, literary translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4126</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4126</id><created>2008-02-27</created><authors><author><keyname>Andru</keyname><forenames>Peter</forenames></author><author><keyname>Botchkarev</keyname><forenames>Alexei</forenames></author></authors><title>Hospital Case Cost Estimates Modelling - Algorithm Comparison</title><categories>cs.CE cs.DB</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Ontario (Canada) Health System stakeholders support the idea and necessity of
the integrated source of data that would include both clinical (e.g. diagnosis,
intervention, length of stay, case mix group) and financial (e.g. cost per
weighted case, cost per diem) characteristics of the Ontario healthcare system
activities at the patient-specific level. At present, the actual patient-level
case costs in the explicit form are not available in the financial databases
for all hospitals. The goal of this research effort is to develop financial
models that will assign each clinical case in the patient-specific data
warehouse a dollar value, representing the cost incurred by the Ontario health
care facility which treated the patient. Five mathematical models have been
developed and verified using real dataset. All models can be classified into
two groups based on their underlying method: 1. Models based on using relative
intensity weights of the cases, and 2. Models based on using cost per diem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4130</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4130</id><created>2008-02-28</created><authors><author><keyname>Quan</keyname><forenames>Zhi</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Wideband Spectrum Sensing in Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><journal-ref>Proceedings of the 2008 IEEE International Conference on
  Communications, Beijing, May 19-23, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is an essential enabling functionality for cognitive radio
networks to detect spectrum holes and opportunistically use the under-utilized
frequency bands without causing harmful interference to legacy networks. This
paper introduces a novel wideband spectrum sensing technique, called multiband
joint detection, which jointly detects the signal energy levels over multiple
frequency bands rather than consider one band at a time. The proposed strategy
is efficient in improving the dynamic spectrum utilization and reducing
interference to the primary users. The spectrum sensing problem is formulated
as a class of optimization problems in interference limited cognitive radio
networks. By exploiting the hidden convexity in the seemingly non-convex
problem formulations, optimal solutions for multiband joint detection are
obtained under practical conditions. Simulation results show that the proposed
spectrum sensing schemes can considerably improve the system performance. This
paper establishes important principles for the design of wideband spectrum
sensing algorithms in cognitive radio networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4131</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4131</id><created>2008-02-28</created><authors><author><keyname>Nayak</keyname><forenames>Birendra Kumar</forenames></author><author><keyname>Sahoo</keyname><forenames>Sudhakar</forenames></author></authors><title>Language of Boolean functions its Grammar and Machine</title><categories>cs.LO</categories><comments>5 pages, two tables, presented in Orissa Mathematical Society
  Conference, January, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper an algorithm is designed which generates in-equivalent Boolean
functions of any number of variables from the four Boolean functions of single
variable. The grammar for such set of Boolean function is provided. The Turing
Machine that accepts such set is constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4191</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4191</id><created>2008-02-28</created><authors><author><keyname>Plumejeaud</keyname><forenames>Christine</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Vincent</keyname><forenames>Jean-Marc</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Grasland</keyname><forenames>Claude</forenames><affiliation>GC, RIATE</affiliation></author><author><keyname>Gensel</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LSR - IMAG</affiliation></author><author><keyname>Mathian</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>GC</affiliation></author><author><keyname>Guelton</keyname><forenames>Serge</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Boulier</keyname><forenames>Jo&#xeb;l</forenames><affiliation>GC</affiliation></author></authors><title>HyperSmooth : calcul et visualisation de cartes de potentiel
  interactives</title><categories>stat.AP cs.HC</categories><proxy>ccsd hal-00214274</proxy><journal-ref>Dans SAGEO 2007, Rencontres internationales G\'eomatique et
  territoire. CdRom. - SAGEO 2007, Rencontres internationales G\'eomatique et
  territoire, France (2007)</journal-ref><abstract>  The HyperCarte research group wishes to offer a new cartographic tool for
spatial analysis of social data, using the potential smoothing method. The
purpose of this method is to view the spreading of phenomena's in a continuous
way, at a macroscopic scale, basing on data sampled on administrative areas. We
aim to offer an interactive tool, accessible via the Web, but guarantying the
confidentiality of data. The major difficulty is induced by the high complexity
of the calculus, working on a great amount of data. We present our solution to
such a technical challenge, and our perspectives of enhancements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4198</identifier>
 <datestamp>2008-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4198</id><created>2008-02-28</created><authors><author><keyname>Buk</keyname><forenames>Solomija</forenames></author><author><keyname>Ma&#x10d;utek</keyname><forenames>J&#xe1;n</forenames></author><author><keyname>Rovenchak</keyname><forenames>Andrij</forenames></author></authors><title>Some properties of the Ukrainian writing system</title><categories>cs.CL</categories><comments>17 pages</comments><journal-ref>Glottometrics 16, 63-79 (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the grapheme-phoneme relation in Ukrainian and some properties
of the Ukrainian version of the Cyrillic alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4215</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4215</id><created>2008-02-28</created><authors><author><keyname>Ausloos</keyname><forenames>M.</forenames></author></authors><title>Equilibrium (Zipf) and Dynamic (Grasseberg-Procaccia) method based
  analyses of human texts. A comparison of natural (english) and artificial
  (esperanto) languages</title><categories>physics.soc-ph cs.CL physics.data-an</categories><comments>22 pages, 87 references, 5 tables, 8 figures</comments><journal-ref>Physica A 387 (25) 6411-6420 (2008)</journal-ref><doi>10.1016/j.physa.2008.07.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A comparison of two english texts from Lewis Carroll, one (Alice in
wonderland), also translated into esperanto, the other (Through a looking
glass) are discussed in order to observe whether natural and artificial
languages significantly differ from each other. One dimensional time series
like signals are constructed using only word frequencies (FTS) or word lengths
(LTS). The data is studied through (i) a Zipf method for sorting out
correlations in the FTS and (ii) a Grassberger-Procaccia (GP) technique based
method for finding correlations in LTS. Features are compared : different power
laws are observed with characteristic exponents for the ranking properties, and
the {\it phase space attractor dimensionality}. The Zipf exponent can take
values much less than unity ($ca.$ 0.50 or 0.30) depending on how a sentence is
defined. This non-universality is conjectured to be a measure of the author
$style$. Moreover the attractor dimension $r$ is a simple function of the so
called phase space dimension $n$, i.e., $r = n^{\lambda}$, with $\lambda =
0.79$. Such an exponent should also conjecture to be a measure of the author
$creativity$. However, even though there are quantitative differences between
the original english text and its esperanto translation, the qualitative
differences are very minutes, indicating in this case a translation relatively
well respecting, along our analysis lines, the content of the author writing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4233</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4233</id><created>2008-02-28</created><authors><author><keyname>Soundararajan</keyname><forenames>Rajiv</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Adaptive Sum Power Iterative Waterfilling for MIMO Cognitive Radio
  Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the sum capacity of the Gaussian Multiple Input Multiple
Output (MIMO) Cognitive Radio Channel (MCC) is expressed as a convex problem
with finite number of linear constraints, allowing for polynomial time interior
point techniques to find the solution. In addition, a specialized class of sum
power iterative waterfilling algorithms is determined that exploits the
inherent structure of the sum capacity problem. These algorithms not only
determine the maximizing sum capacity value, but also the transmit policies
that achieve this optimum. The paper concludes by providing numerical results
which demonstrate that the algorithm takes very few iterations to converge to
the optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4237</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4237</id><created>2008-02-28</created><updated>2010-04-09</updated><authors><author><keyname>Lazic</keyname><forenames>Ranko</forenames></author></authors><title>Safety alternating automata on data words</title><categories>cs.LO</categories><comments>23 pages</comments><acm-class>F.4.1; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data word is a sequence of pairs of a letter from a finite alphabet and an
element from an infinite set, where the latter can only be compared for
equality. Safety one-way alternating automata with one register on infinite
data words are considered, their nonemptiness is shown EXPSPACE-complete, and
their inclusion decidable but not primitive recursive. The same complexity
bounds are obtained for satisfiability and refinement, respectively, for the
safety fragment of linear temporal logic with freeze quantification. Dropping
the safety restriction, adding past temporal operators, or adding one more
register, each causes undecidability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4244</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4244</id><created>2008-02-28</created><authors><author><keyname>Tryfonas</keyname><forenames>Christos</forenames></author><author><keyname>Papamichail</keyname><forenames>Dimitris</forenames></author><author><keyname>Mehler</keyname><forenames>Andrew</forenames></author><author><keyname>Skiena</keyname><forenames>Steven</forenames></author></authors><title>Call Admission Control Algorithm for pre-stored VBR video streams</title><categories>cs.NI cs.DS</categories><comments>12 pages, 9 figures, includes appendix</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We examine the problem of accepting a new request for a pre-stored VBR video
stream that has been smoothed using any of the smoothing algorithms found in
the literature. The output of these algorithms is a piecewise constant-rate
schedule for a Variable Bit-Rate (VBR) stream. The schedule guarantees that the
decoder buffer does not overflow or underflow. The problem addressed in this
paper is the determination of the minimal time displacement of each new
requested VBR stream so that it can be accomodated by the network and/or the
video server without overbooking the committed traffic. We prove that this
call-admission control problem for multiple requested VBR streams is
NP-complete and inapproximable within a constant factor, by reducing it from
the VERTEX COLOR problem. We also present a deterministic morphology-sensitive
algorithm that calculates the minimal time displacement of a VBR stream
request. The complexity of the proposed algorithm make it suitable for
real-time determination of the time displacement parameter during the call
admission phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4270</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4270</id><created>2008-02-28</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author></authors><title>Propagation Rules of Subsystem Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>Private comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate propagation rules of subsystem code constructions by
extending, shortening and combining given subsystem codes. Given an
$[[n,k,r,d]]_q$ subsystem code, we drive new subsystem codes with parameters
$[[n+1,k,r,\geq d]]_q$, $[[n-1,k+1,r,\geq d-1]]_q$, $[[n,k-1,r+1,d]]_q$. The
interested readers shall consult our companion papers for upper and lower
bounds on subsystem codes parameters, and introduction, trading dimensions,
families, and references on subsystem codes [1][2][3] and references therein.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4282</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4282</id><created>2008-02-28</created><authors><author><keyname>Zheng</keyname><forenames>Dong</forenames></author><author><keyname>Pun</keyname><forenames>Man-On</forenames></author><author><keyname>Ge</keyname><forenames>Weiyan</forenames></author><author><keyname>Zhang</keyname><forenames>Junshan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Distributed Opportunistic Scheduling For Ad-Hoc Communications Under
  Noisy Channel Estimation</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Conference on
  Communications, Beijing, May 19-23, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed opportunistic scheduling is studied for wireless ad-hoc networks,
where many links contend for one channel using random access. In such networks,
distributed opportunistic scheduling (DOS) involves a process of joint channel
probing and distributed scheduling. It has been shown that under perfect
channel estimation, the optimal DOS for maximizing the network throughput is a
pure threshold policy. In this paper, this formalism is generalized to explore
DOS under noisy channel estimation, where the transmission rate needs to be
backed off from the estimated rate to reduce the outage. It is shown that the
optimal scheduling policy remains to be threshold-based, and that the rate
threshold turns out to be a function of the variance of the estimation error
and be a functional of the backoff rate function. Since the optimal backoff
rate is intractable, a suboptimal linear backoff scheme that backs off the
estimated signal-to-noise ratio (SNR) and hence the rate is proposed. The
corresponding optimal backoff ratio and rate threshold can be obtained via an
iterative algorithm. Finally, simulation results are provided to illustrate the
tradeoff caused by increasing training time to improve channel estimation at
the cost of probing efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4284</identifier>
 <datestamp>2008-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4284</id><created>2008-02-28</created><updated>2008-02-28</updated><authors><author><keyname>Pun</keyname><forenames>Man-On</forenames></author><author><keyname>Ge</keyname><forenames>Weiyan</forenames></author><author><keyname>Zheng</keyname><forenames>Dong</forenames></author><author><keyname>Zhang</keyname><forenames>Junshan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Distributed Opportunistic Scheduling for MIMO Ad-Hoc Networks</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Conference on
  Communications, Beijing, May 19-23, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed opportunistic scheduling (DOS) protocols are proposed for
multiple-input multiple-output (MIMO) ad-hoc networks with contention-based
medium access. The proposed scheduling protocols distinguish themselves from
other existing works by their explicit design for system throughput improvement
through exploiting spatial multiplexing and diversity in a {\em distributed}
manner. As a result, multiple links can be scheduled to simultaneously transmit
over the spatial channels formed by transmit/receiver antennas. Taking into
account the tradeoff between feedback requirements and system throughput, we
propose and compare protocols with different levels of feedback information.
Furthermore, in contrast to the conventional random access protocols that
ignore the physical channel conditions of contending links, the proposed
protocols implement a pure threshold policy derived from optimal stopping
theory, i.e. only links with threshold-exceeding channel conditions are allowed
for data transmission. Simulation results confirm that the proposed protocols
can achieve impressive throughput performance by exploiting spatial
multiplexing and diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4291</identifier>
 <datestamp>2008-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4291</id><created>2008-02-28</created><authors><author><keyname>Pun</keyname><forenames>Man-On</forenames></author><author><keyname>Kim</keyname><forenames>Kyeong Jin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Opportunistic Scheduling and Beamforming for MIMO-OFDMA Downlink Systems
  with Reduced Feedback</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Conference on
  Communications, Beijing, May 19-23, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistic scheduling and beamforming schemes with reduced feedback are
proposed for MIMO-OFDMA downlink systems. Unlike the conventional beamforming
schemes in which beamforming is implemented solely by the base station (BS) in
a per-subcarrier fashion, the proposed schemes take advantages of a novel
channel decomposition technique to perform beamforming jointly by the BS and
the mobile terminal (MT). The resulting beamforming schemes allow the BS to
employ only {\em one} beamforming matrix (BFM) to form beams for {\em all}
subcarriers while each MT completes the beamforming task for each subcarrier
locally. Consequently, for a MIMO-OFDMA system with $Q$ subcarriers, the
proposed opportunistic scheduling and beamforming schemes require only one BFM
index and $Q$ supportable throughputs to be returned from each MT to the BS, in
contrast to $Q$ BFM indices and $Q$ supportable throughputs required by the
conventional schemes. The advantage of the proposed schemes becomes more
evident when a further feedback reduction is achieved by grouping adjacent
subcarriers into exclusive clusters and returning only cluster information from
each MT. Theoretical analysis and computer simulation confirm the effectiveness
of the proposed reduced-feedback schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4293</identifier>
 <datestamp>2008-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4293</id><created>2008-02-29</created><authors><author><keyname>Krot-Sieniawska</keyname><forenames>Ewa</forenames></author></authors><title>Reduced Incidence algebras description of cobweb posets and KoDAGs</title><categories>math.CO cs.DM</categories><comments>8 pages</comments><msc-class>06A06, 06A07, 06A11, 11C08, 11B37</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After identifying the reduced incidence algebra of an arbitrary cobweb poset
the very first properties of these algebras are being disclosed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4299</identifier>
 <datestamp>2008-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4299</id><created>2008-02-28</created><authors><author><keyname>Pun</keyname><forenames>Man-On</forenames></author><author><keyname>Koivunen</keyname><forenames>Visa</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>SINR Analysis of Opportunistic MIMO-SDMA Downlink Systems with Linear
  Combining</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Conference on
  Communications, Beijing, May 19-23, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistic scheduling (OS) schemes have been proposed previously by the
authors for multiuser MIMO-SDMA downlink systems with linear combining. In
particular, it has been demonstrated that significant performance improvement
can be achieved by incorporating low-complexity linear combining techniques
into the design of OS schemes for MIMO-SDMA. However, this previous analysis
was performed based on the effective signal-to-interference ratio (SIR),
assuming an interference-limited scenario, which is typically a valid
assumption in SDMA-based systems. It was shown that the limiting distribution
of the effective SIR is of the Frechet type. Surprisingly, the corresponding
scaling laws were found to follow $\epsilon\log K$ with $0&lt;\epsilon&lt;1$, rather
than the conventional $\log\log K$ form.
  Inspired by this difference between the scaling law forms, in this paper a
systematic approach is developed to derive asymptotic throughput and scaling
laws based on signal-to-interference-noise ratio (SINR) by utilizing extreme
value theory. The convergence of the limiting distribution of the effective
SINR to the Gumbel type is established. The resulting scaling law is found to
be governed by the conventional $\log\log K$ form. These novel results are
validated by simulation results. The comparison of SIR and SINR-based analysis
suggests that the SIR-based analysis is more computationally efficient for
SDMA-based systems and it captures the asymptotic system performance with
higher fidelity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4307</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4307</id><created>2008-02-28</created><updated>2014-03-18</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>A O(n^8) X O(n^7) Linear Programming Model of the Quadratic Assignment
  Problem</title><categories>cs.DM cs.CC</categories><comments>Theorem 21 and Corollary 22 are in error; The modeling needs
  9-dimensional variables instead of the 8-dimensional variables defined in
  notations 6.9</comments><acm-class>G.1.6; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn because Theorem 21 and Corollary 22 are in
error; The modeling idea is OK, but it needs 9-dimensional variables instead of
the 8-dimensional variables defined in notations 6.9.
  Examples of the correct model (with 9-index variables) are: (1) Diaby, M.,
&quot;Linear Programming Formulation of the Set Partitioning Problem,&quot; International
Journal of Operational Research 8:4 (August 2010) pp. 399-427; (2) Diaby, M.,
&quot;Linear Programming Formulation of the Vertex Coloring Problem,&quot; International
Journal of Mathematics in Operational Research 2:3 (May 2010) pp. 259-289; (3)
Diaby, M., &quot;The Traveling Salesman Problem: A Linear Programming Formulation,&quot;
WSEAS Transactions on Mathematics, 6:6 (June 2007) pp. 745-754.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4312</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4312</id><created>2008-02-28</created><updated>2009-05-19</updated><authors><author><keyname>Gu</keyname><forenames>Xiaoyang</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Mayordomo</keyname><forenames>Elvira</forenames></author></authors><title>Curves That Must Be Retraced</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit a polynomial time computable plane curve GAMMA that has finite
length, does not intersect itself, and is smooth except at one endpoint, but
has the following property. For every computable parametrization f of GAMMA and
every positive integer n, there is some positive-length subcurve of GAMMA that
f retraces at least n times. In contrast, every computable curve of finite
length that does not intersect itself has a constant-speed (hence
non-retracing) parametrization that is computable relative to the halting
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4325</identifier>
 <datestamp>2008-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4325</id><created>2008-02-29</created><updated>2008-04-04</updated><authors><author><keyname>Damian</keyname><forenames>Mirela</forenames></author></authors><title>A Simple Yao-Yao-Based Spanner of Bounded Degree</title><categories>cs.CG cs.DS</categories><comments>7 pages, 5 figures</comments><acm-class>C.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a standing open question to decide whether the Yao-Yao structure for
unit disk graphs (UDGs) is a length spanner of not. This question is highly
relevant to the topology control problem for wireless ad hoc networks. In this
paper we make progress towards resolving this question by showing that the
Yao-Yao structure is a length spanner for UDGs of bounded aspect ratio. We also
propose a new local algorithm, called Yao-Sparse-Sink, based on the Yao-Sink
method introduced by Li, Wan, Wang and Frieder, that computes a (1+e)-spanner
of bounded degree for a given UDG and for given e &gt; 0. The Yao-Sparse-Sink
method enables an efficient local computation of sparse sink trees. Finally, we
show that all these structures for UDGs -- Yao, Yao-Yao, Yao-Sink and
Yao-Sparse-Sink -- have arbitrarily large weight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4326</identifier>
 <datestamp>2008-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4326</id><created>2008-02-29</created><authors><author><keyname>Jia</keyname><forenames>Jiyou</forenames></author></authors><title>The Generation of Textual Entailment with NLML in an Intelligent
  Dialogue system for Language Learning CSIEC</title><categories>cs.CL cs.AI cs.CY</categories><abstract>  This research report introduces the generation of textual entailment within
the project CSIEC (Computer Simulation in Educational Communication), an
interactive web-based human-computer dialogue system with natural language for
English instruction. The generation of textual entailment (GTE) is critical to
the further improvement of CSIEC project. Up to now we have found few
literatures related with GTE. Simulating the process that a human being learns
English as a foreign language we explore our naive approach to tackle the GTE
problem and its algorithm within the framework of CSIEC, i.e. rule annotation
in NLML, pattern recognition (matching), and entailment transformation. The
time and space complexity of our algorithm is tested with some entailment
examples. Further works include the rules annotation based on the English
textbooks and a GUI interface for normal users to edit the entailment rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4330</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4330</id><created>2008-02-29</created><updated>2011-05-09</updated><authors><author><keyname>Farrell</keyname><forenames>Brendan</forenames></author><author><keyname>Strohmer</keyname><forenames>Thomas</forenames></author></authors><title>Eigenvalue Estimates and Mutual Information for the Linear Time-Varying
  Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory This version is
  a substantial revision of the earlier version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider linear time-varying channels with additive white Gaussian noise.
For a large class of such channels we derive rigorous estimates of the
eigenvalues of the correlation matrix of the effective channel in terms of the
sampled time-varying transfer function and, thus, provide a theoretical
justification for a relationship that has been frequently observed in the
literature. We then use this eigenvalue estimate to derive an estimate of the
mutual information of the channel. Our approach is constructive and is based on
a careful balance of the trade-off between approximate operator
diagonalization, signal dimension loss, and accuracy of eigenvalue estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4344</identifier>
 <datestamp>2008-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4344</id><created>2008-02-29</created><authors><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Morelli</keyname><forenames>Michele</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>An Improved Scheme for Initial Ranging in OFDMA-based Networks</title><categories>cs.IT cs.OH math.IT</categories><comments>6 pages, 3 figures, To appear in the Proceedings of the 2008 IEEE
  International Conference on Communications, Beijing, May 19 - 23, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient scheme for initial ranging has recently been proposed by X. Fu
et al. in the context of orthogonal frequency-division multiple-access (OFDMA)
networks based on the IEEE 802.16e-2005 standard. The proposed solution aims at
estimating the power levels and timing offsets of the ranging subscriber
stations (RSSs) without taking into account the effect of possible carrier
frequency offsets (CFOs) between the received signals and the base station
local reference. Motivated by the above problem, in the present work we design
a novel ranging scheme for OFDMA in which the ranging signals are assumed to be
misaligned both in time and frequency. Our goal is to estimate the timing
errors and CFOs of each active RSS. Specifically, CFO estimation is
accomplished by resorting to subspacebased methods while a least-squares
approach is employed for timing recovery. Computer simulations are used to
assess the effectiveness of the proposed solution and to make comparisons with
existing alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4350</identifier>
 <datestamp>2008-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4350</id><created>2008-02-29</created><authors><author><keyname>Pellicer-Lostao</keyname><forenames>Carmen</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author></authors><title>Role of Symmetry and Geometry in a chaotic Pseudo-Random Bit Generator</title><categories>nlin.CD cs.CR physics.comp-ph stat.AP</categories><comments>21 pages, 10 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, Pseudo-Random Bit Generation (PRBG) based on 2D chaotic
mappings of logistic type is considered. The sequences generated with two
Pseudorandom Bit Generators (PRBGs) of this type are statistically tested and
the computational effectiveness of the generators is estimated. The role played
by the symmetry and the geometrical properties of the underlying chaotic
attractors is also explored. Considering these PRBGs valid for cryptography,
the size of the available key spaces are calculated. Additionally, a novel
mechanism called 'symmetry-swap' is introduced in order to enhance the PRBG
algorithm. It is shown that it can increase the degrees of freedom of the key
space, while maintaining the speed and performance in the PRBG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4363</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4363</id><created>2008-02-29</created><authors><author><keyname>Gao</keyname><forenames>Y.</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>I.</forenames></author><author><keyname>Bienenstock</keyname><forenames>E.</forenames></author></authors><title>Estimating the entropy of binary time series: Methodology, some theory
  and a simulation study</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>34 pages, 3 figures</comments><doi>10.3390/entropy-e10020071</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partly motivated by entropy-estimation problems in neuroscience, we present a
detailed and extensive comparison between some of the most popular and
effective entropy estimation methods used in practice: The plug-in method, four
different estimators based on the Lempel-Ziv (LZ) family of data compression
algorithms, an estimator based on the Context-Tree Weighting (CTW) method, and
the renewal entropy estimator.
  **Methodology. Three new entropy estimators are introduced. For two of the
four LZ-based estimators, a bootstrap procedure is described for evaluating
their standard error, and a practical rule of thumb is heuristically derived
for selecting the values of their parameters. ** Theory. We prove that, unlike
their earlier versions, the two new LZ-based estimators are consistent for
every finite-valued, stationary and ergodic process. An effective method is
derived for the accurate approximation of the entropy rate of a finite-state
HMM with known distribution. Heuristic calculations are presented and
approximate formulas are derived for evaluating the bias and the standard error
of each estimator. ** Simulation. All estimators are applied to a wide range of
data generated by numerous different processes with varying degrees of
dependence and memory. Some conclusions drawn from these experiments include:
(i) For all estimators considered, the main source of error is the bias. (ii)
The CTW method is repeatedly and consistently seen to provide the most accurate
results. (iii) The performance of the LZ-based estimators is often comparable
to that of the plug-in method. (iv) The main drawback of the plug-in method is
its computational inefficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4390</identifier>
 <datestamp>2008-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4390</id><created>2008-02-29</created><authors><author><keyname>Neder</keyname><forenames>Vadim</forenames></author><author><keyname>Ezri</keyname><forenames>Doron</forenames></author><author><keyname>Haridim</keyname><forenames>Motti</forenames></author></authors><title>Low Complexity Sphere Decoding for Spatial Multiplexing MIMO</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel method for decoding multiple input -
multiple output (MIMO) transmission, which combines sphere decoding (SD) and
zero forcing (ZF) techniques to provide near optimal low complexity and high
performance constant time modified sphere decoding algorithm. This algorithm
was designed especially for large number of transmit antennas, and allows
efficient implementation in hardware. We do this by limiting the number of
overall SD iterations. Moreover, we make sure that matrices with high condition
number are more likely to undergo SD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4450</identifier>
 <datestamp>2008-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4450</id><created>2008-02-29</created><authors><author><keyname>Keviczky</keyname><forenames>Tamas</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author></authors><title>A Study On Distributed Model Predictive Consensus</title><categories>cs.MA</categories><comments>20 pages, 4 figures, longer version of paper presented at 17th IFAC
  World Congress</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate convergence properties of a proposed distributed model
predictive control (DMPC) scheme, where agents negotiate to compute an optimal
consensus point using an incremental subgradient method based on primal
decomposition as described in Johansson et al. [2006, 2007]. The objective of
the distributed control strategy is to agree upon and achieve an optimal common
output value for a group of agents in the presence of constraints on the agent
dynamics using local predictive controllers. Stability analysis using a
receding horizon implementation of the distributed optimal consensus scheme is
performed. Conditions are given under which convergence can be obtained even if
the negotiations do not reach full consensus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0011</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0011</id><created>2008-02-29</created><authors><author><keyname>Bishop</keyname><forenames>Keith</forenames></author></authors><title>Qtier-Rapor: Managing Spreadsheet Systems &amp; Improving Corporate
  Performance, Compliance and Governance</title><categories>cs.OH</categories><comments>12 Pages, 6 Colour Figures</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 33-44
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much of what EuSpRIG discusses is concerned with the integrity of individual
spreadsheets. In businesses, interlocking spreadsheets are regularly used to
fill functional gaps in core administrative systems. The growth and deployment
of such integrated spreadsheet SYSTEMS raises the scale of issues to a whole
new level. The correct management of spreadsheet systems is necessary to ensure
that the business achieves its goals of improved performance and good corporate
governance, within the constraints of legislative compliance - poor management
will deliver the opposite. This paper is an anatomy of the real-life issues of
the commercial use of spreadsheets in business, and demonstrates how
Qtier-Rapor has been used to instil best practice in the use of integrated
commercial spreadsheet systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0014</identifier>
 <datestamp>2008-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0014</id><created>2008-03-02</created><updated>2008-09-01</updated><authors><author><keyname>Schneider-Kamp</keyname><forenames>P.</forenames></author><author><keyname>Giesl</keyname><forenames>J.</forenames></author><author><keyname>Serebrenik</keyname><forenames>A.</forenames></author><author><keyname>Thiemann</keyname><forenames>R.</forenames></author></authors><title>Automated Termination Proofs for Logic Programs by Term Rewriting</title><categories>cs.LO cs.AI cs.PL</categories><comments>49 pages</comments><acm-class>F.3.1; D.1.6; I.2.2; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are two kinds of approaches for termination analysis of logic programs:
&quot;transformational&quot; and &quot;direct&quot; ones. Direct approaches prove termination
directly on the basis of the logic program. Transformational approaches
transform a logic program into a term rewrite system (TRS) and then analyze
termination of the resulting TRS instead. Thus, transformational approaches
make all methods previously developed for TRSs available for logic programs as
well. However, the applicability of most existing transformations is quite
restricted, as they can only be used for certain subclasses of logic programs.
(Most of them are restricted to well-moded programs.) In this paper we improve
these transformations such that they become applicable for any definite logic
program. To simulate the behavior of logic programs by TRSs, we slightly modify
the notion of rewriting by permitting infinite terms. We show that our
transformation results in TRSs which are indeed suitable for automated
termination analysis. In contrast to most other methods for termination of
logic programs, our technique is also sound for logic programming without occur
check, which is typically used in practice. We implemented our approach in the
termination prover AProVE and successfully evaluated it on a large collection
of examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0015</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0015</id><created>2008-02-29</created><authors><author><keyname>Murphy</keyname><forenames>Simon</forenames></author></authors><title>EuSpRIG 2006 Commercial Spreadsheet Review</title><categories>cs.SE</categories><comments>8 Pages, 9 Colour Diagrams</comments><acm-class>D.2.4; D.2.5; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 45-52
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This management summary provides an outline of a commercial spreadsheet
review process. The aim of this process is to ensure remedial or enhancement
work can safely be undertaken on a spreadsheet with a commercially acceptable
level of risk of introducing new errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0018</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0018</id><created>2008-02-29</created><updated>2008-09-05</updated><authors><author><keyname>Chermakani</keyname><forenames>Deepak Ponvel</forenames></author></authors><title>Another approach to decide on real root existence for univariate
  Polynomials, and a multivariate extension for 3-SAT</title><categories>cs.NA cs.DM</categories><comments>8 pages, 6 Theorems on Univariate Polynomials, 1 Theorem on
  Multivariate Polynomial for 3SAT, 2 Conjectures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present six Theorems on the univariate real Polynomial, using which we
develop a new algorithm for deciding the existence of atleast one real root for
univariate integer Polynomials. Our algorithm outputs that no positive real
root exists, if and only if, the given Polynomial is a factor of a real
Polynomial with positive coefficients. Next, we define a transformation that
transforms any instance of 3-SAT into a multivariate real Polynomial with
positive coefficients, if and only if, the instance is not satisfiable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0032</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0032</id><created>2008-02-29</created><updated>2008-03-31</updated><authors><author><keyname>Ganta</keyname><forenames>Srivatsava Ranjit</forenames></author><author><keyname>Kasiviswanathan</keyname><forenames>Shiva Prasad</forenames></author><author><keyname>Smith</keyname><forenames>Adam</forenames></author></authors><title>Composition Attacks and Auxiliary Information in Data Privacy</title><categories>cs.DB cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy is an increasingly important aspect of data publishing. Reasoning
about privacy, however, is fraught with pitfalls. One of the most significant
is the auxiliary information (also called external knowledge, background
knowledge, or side information) that an adversary gleans from other channels
such as the web, public records, or domain knowledge. This paper explores how
one can reason about privacy in the face of rich, realistic sources of
auxiliary information. Specifically, we investigate the effectiveness of
current anonymization schemes in preserving privacy when multiple organizations
independently release anonymized data about overlapping populations. 1. We
investigate composition attacks, in which an adversary uses independent
anonymized releases to breach privacy. We explain why recently proposed models
of limited auxiliary information fail to capture composition attacks. Our
experiments demonstrate that even a simple instance of a composition attack can
breach privacy in practice, for a large class of currently proposed techniques.
The class includes k-anonymity and several recent variants. 2. On a more
positive note, certain randomization-based notions of privacy (such as
differential privacy) provably resist composition attacks and, in fact, the use
of arbitrary side information. This resistance enables stand-alone design of
anonymization schemes, without the need for explicitly keeping track of other
releases. We provide a precise formulation of this property, and prove that an
important class of relaxations of differential privacy also satisfy the
property. This significantly enlarges the class of protocols known to enable
modular design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0034</identifier>
 <datestamp>2008-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0034</id><created>2008-02-29</created><updated>2008-05-28</updated><authors><author><keyname>Andreev</keyname><forenames>Leonid</forenames></author></authors><title>From a set of parts to an indivisible whole. Part I: Operations in a
  closed mode</title><categories>cs.OH</categories><comments>28 pages, 10 figures; typos in equations (4) and (5) corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a description of a new method for information processing
based on holistic approach wherein analysis is a direct product of synthesis.
The core of the method is iterative averaging of all the elements of a system
according to all the parameters describing the elements. Contrary to common
logic, the iterative averaging of a system's elements does not result in
homogenization of the system; instead, it causes an obligatory subdivision of
the system into two alternative subgroups, leaving no outliers. Within each of
the formed subgroups, similarity coefficients between the elements reach the
value of 1, whereas similarity coefficients between the elements of different
subgroups equal a certain constant value greater than 0 but lower than 1. When
subjected to iterative averaging, any system consisting of three or more
elements of which at least two elements are not completely identical undergo
such a process of bifurcation that occurs non-linearly. Successive iterative
averaging of each of the forming subgroups eventually provides a hierarchical
system that reflects relationships between the elements of an input system
under analysis. We propose a definition of a natural hierarchy that can exist
only in conditions of closeness of a system and can be discovered upon
providing such an effect onto a system which allows its elements interact with
each other based on the principle of self-organization. Self-organization can
be achieved through an overall and total cross-averaging of a system's
elements. We demonstrate the application potentials of the proposed technology
on a number of examples, including a system of scattered points, randomized
datasets, as well as meteorological and demographical datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0037</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0037</id><created>2008-02-29</created><authors><author><keyname>AbuHmed</keyname><forenames>Tamer</forenames></author><author><keyname>Mohaisen</keyname><forenames>Abedelaziz</forenames></author><author><keyname>Nyang</keyname><forenames>DaeHun</forenames></author></authors><title>A Survey on Deep Packet Inspection for Intrusion Detection Systems</title><categories>cs.CR</categories><comments>10 pages, 7 figures, 1 table</comments><journal-ref>Magazine of Korea Telecommunication Society, vol. 24, No. 11, pp.
  25-36, November 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep packet inspection is widely recognized as a powerful way which is used
for intrusion detection systems for inspecting, deterring and deflecting
malicious attacks over the network. Fundamentally, almost intrusion detection
systems have the ability to search through packets and identify contents that
match with known attacks. In this paper, we survey the deep packet inspection
implementations techniques, research challenges and algorithms. Finally, we
provide a comparison between the different applied systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0046</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0046</id><created>2008-03-01</created><authors><author><keyname>Nagaraj</keyname><forenames>Nithin</forenames></author><author><keyname>Vaidya</keyname><forenames>Prabhakar G.</forenames></author></authors><title>One-Time Pad, Arithmetic Coding and Logic Gates: An unifying theme using
  Dynamical Systems</title><categories>nlin.CD cs.CR</categories><comments>9 pages, 7 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we prove that the perfectly secure One-Time Pad (OTP)
encryption can be seen as finding the initial condition on the binary map under
a random switch based on the perfectly random pad. This turns out to be a
special case of Grangetto's randomized arithmetic coding performed on the
Binary Map. Furthermore, we derive the set of possible perfect secrecy systems
using such an approach. Since OTP encryption is an XOR operation, we thus have
a dynamical systems implementation of the XOR gate. We show similar
implementations for other gates such as NOR, NAND, OR, XNOR, AND and NOT. The
dynamical systems framework unifies the three areas to which Shannon made
foundational contributions: lossless compression (Source Coding), perfect
encryption (Cryptography), and design of logic gates (Computation)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0048</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0048</id><created>2008-03-01</created><updated>2011-05-12</updated><authors><author><keyname>Dong</keyname><forenames>Xin</forenames></author><author><keyname>Cooperman</keyname><forenames>Gene</forenames></author></authors><title>A Bit-Compatible Shared Memory Parallelization for ILU(k)
  Preconditioning and a Bit-Compatible Generalization to Distributed Memory</title><categories>cs.DC</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ILU(k) is a commonly used preconditioner for iterative linear solvers for
sparse, non-symmetric systems. It is often preferred for the sake of its
stability. We present TPILU(k), the first efficiently parallelized ILU(k)
preconditioner that maintains this important stability property. Even better,
TPILU(k) preconditioning produces an answer that is bit-compatible with the
sequential ILU(k) preconditioning. In terms of performance, the TPILU(k)
preconditioning is shown to run faster whenever more cores are made available
to it --- while continuing to be as stable as sequential ILU(k). This is in
contrast to some competing methods that may become unstable if the degree of
thread parallelism is raised too far. Where Block Jacobi ILU(k) fails in an
application, it can be replaced by TPILU(k) in order to maintain good
performance, while also achieving full stability. As a further optimization,
TPILU(k) offers an optional level-based incomplete inverse method as a fast
approximation for the original ILU(k) preconditioned matrix. Although this
enhancement is not bit-compatible with classical ILU(k), it is bit-compatible
with the output from the single-threaded version of the same algorithm. In
experiments on a 16-core computer, the enhanced TPILU(k)-based iterative linear
solver performed up to 9 times faster. As we approach an era of many-core
computing, the ability to efficiently take advantage of many cores will become
ever more important. TPILU(k) also demonstrates good performance on cluster or
Grid. For example, the new algorithm achieves 50 times speedup with 80 nodes
for general sparse matrices of dimension 160,000 that are diagonally dominant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0053</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0053</id><created>2008-03-01</created><authors><author><keyname>Thampi</keyname><forenames>Sabu M.</forenames></author><author><keyname>Sekaran</keyname><forenames>K. Chandra</forenames></author></authors><title>Mobile Agents for Content-Based WWW Distributed Image Retrieval</title><categories>cs.DC cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At present, the de-facto standard for providing contents in the Internet is
the World Wide Web. A technology, which is now emerging on the Web, is
Content-Based Image Retrieval (CBIR). CBIR applies methods and algorithms from
computer science to analyse and index images based on their visual content.
Mobile agents push the flexibility of distributed systems to their limits since
not only computations are dynamically distributed but also the code that
performs them. The current commercial applet-based methodologies for accessing
image database systems offer limited flexibility, scalability and robustness.
In this paper the author proposes a new framework for content-based WWW
distributed image retrieval based on Java-based mobile agents. The
implementation of the framework shows that its performance is comparable to,
and in some cases outperforms, the current approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0055</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0055</id><created>2008-03-01</created><authors><author><keyname>Dennunzio</keyname><forenames>Alberto</forenames><affiliation>DISCo</affiliation></author><author><keyname>Guillon</keyname><forenames>Pierre</forenames><affiliation>IGM</affiliation></author><author><keyname>Masson</keyname><forenames>Beno&#xee;t</forenames><affiliation>LIF</affiliation></author></authors><title>A compact topology for sand automata</title><categories>cs.CC</categories><proxy>ccsd hal-00259945</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we exhibit a strong relation between the sand automata
configuration space and the cellular automata configuration space. This
relation induces a compact topology for sand automata, and a new context in
which sand automata are homeomorphic to cellular automata acting on a specific
subshift. We show that the existing topological results for sand automata,
including the Hedlund-like representation theorem, still hold. In this context,
we give a characterization of the cellular automata which are sand automata,
and study some dynamical behaviors such as equicontinuity. Furthermore, we deal
with the nilpotency. We show that the classical definition is not meaningful
for sand automata. Then, we introduce a suitable new notion of nilpotency for
sand automata. Finally, we prove that this simple dynamical behavior is
undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0134</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0134</id><created>2008-03-02</created><updated>2010-02-25</updated><authors><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Samvel S.</forenames></author><author><keyname>Vardanyan</keyname><forenames>Gagik N.</forenames></author></authors><title>On disjoint matchings in cubic graphs</title><categories>cs.DM</categories><comments>41 pages, 8 figures, minor chages</comments><journal-ref>Discrete Mathematics, 310/10-11 (2010), pp. 1588-1613</journal-ref><doi>10.1016/j.disc.2010.02.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For $i=2,3$ and a cubic graph $G$ let $\nu_{i}(G)$ denote the maximum number
of edges that can be covered by $i$ matchings. We show that $\nu_{2}(G)\geq
{4/5}| V(G)| $ and $\nu_{3}(G)\geq {7/6}| V(G)| $. Moreover, it turns out that
$\nu_{2}(G)\leq \frac{|V(G)|+2\nu_{3}(G)}{4}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0146</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0146</id><created>2008-03-02</created><authors><author><keyname>Hochbaum</keyname><forenames>Dorit S.</forenames></author></authors><title>Polynomial time algorithms for bi-criteria, multi-objective and ratio
  problems in clustering and imaging. Part I: Normalized cut and ratio regions</title><categories>cs.CV cs.DM</categories><comments>15 pages, 4 figures</comments><journal-ref>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  May 2010 32:5 889-898</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partitioning and grouping of similar objects plays a fundamental role in
image segmentation and in clustering problems. In such problems a typical goal
is to group together similar objects, or pixels in the case of image
processing. At the same time another goal is to have each group distinctly
dissimilar from the rest and possibly to have the group size fairly large.
These goals are often combined as a ratio optimization problem. One example of
such problem is the normalized cut problem, another is the ratio regions
problem. We devise here the first polynomial time algorithms solving these
problems optimally. The algorithms are efficient and combinatorial. This
contrasts with the heuristic approaches used in the image segmentation
literature that formulate those problems as nonlinear optimization problems,
which are then relaxed and solved with spectral techniques in real numbers.
These approaches not only fail to deliver an optimal solution, but they are
also computationally expensive. The algorithms presented here use as a
subroutine a minimum $s,t-cut procedure on a related graph which is of
polynomial size. The output consists of the optimal solution to the respective
ratio problem, as well as a sequence of nested solution with respect to any
relative weighting of the objectives of the numerator and denominator.
  An extension of the results here to bi-criteria and multi-criteria objective
functions is presented in part II.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0159</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0159</id><created>2008-03-02</created><authors><author><keyname>Vemula</keyname><forenames>V. R.</forenames></author><author><keyname>Ball</keyname><forenames>David</forenames></author><author><keyname>Thorne</keyname><forenames>Simon</forenames></author></authors><title>Towards a Spreadsheet Engineering</title><categories>cs.CY</categories><comments>12 Pages, One Figure</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 53-64
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we report some on-going focused research, but are further keen
to set it in the context of a proposed bigger picture, as follows. There is a
certain depressing pattern about the attitude of industry to spreadsheet error
research and a certain pattern about conferences highlighting these issues. Is
it not high time to move on from measuring spreadsheet errors to developing an
armoury of disciplines and controls? In short, we propose the need to
rigorously lay the foundations of a spreadsheet engineering discipline.
Clearly, multiple research teams would be required to tackle such a big task.
This suggests the need for both national and international collaborative
research, since any given group can only address a small segment of the whole.
There are already a small number of examples of such on-going international
collaborative research. Having established the need for a directed research
effort, the rest of the paper then attempts to act as an exemplar in
demonstrating and applying this focus. With regard to one such of research, in
a recent paper, Panko (2005) stated that: &quot;...group development and testing
appear to be promising areas to pursue&quot;. Of particular interest to us are some
gaps in the published research record on techniques to reduce errors. We
further report on the topics: techniques for cross-checking, time constraints
effects, and some aspects of developer perception.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0162</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0162</id><created>2008-03-02</created><authors><author><keyname>Kumiega</keyname><forenames>Andrew</forenames></author><author><keyname>Van Vliet</keyname><forenames>Ben</forenames></author></authors><title>A Software Development Methodology for Research and Prototyping in
  Financial Markets</title><categories>cs.SE</categories><comments>22 Pages</comments><acm-class>D.1.7; D.2.1; D.2.11; D.3.2; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 107-127
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is to develop a standardized methodology for
software development in the very unique industry and culture of financial
markets. The prototyping process we present allows the development team to
deliver for review and comment intermediate-level models based upon clearly
defined customer requirements. This spreadsheet development methodology is
presented within a larger business context, that of trading system development,
the subject of an upcoming book by the authors of this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0163</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0163</id><created>2008-03-02</created><authors><author><keyname>Paine</keyname><forenames>Jocelyn</forenames></author><author><keyname>Tek</keyname><forenames>Emre</forenames></author><author><keyname>Williamson</keyname><forenames>Duncan</forenames></author></authors><title>Rapid Spreadsheet Reshaping with Excelsior: multiple drastic changes to
  content and layout are easy when you represent enough structure</title><categories>cs.SE</categories><comments>18 Pages, code examples</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 129-146
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets often need changing in ways made tedious and risky by Excel. For
example: simultaneously altering many tables' size, orientation, and position;
inserting cross-tabulations; moving data between sheets; splitting and merging
sheets. A safer, faster restructuring tool is, we claim, Excelsior. The result
of a research project into reducing spreadsheet risk, Excelsior is the first
ever tool for modularising spreadsheets; i.e. for building them from components
which can be independently created, tested, debugged, and updated. It
represents spreadsheets in a way that makes these components explicit,
separates them from layout, and allows both components and layout to be changed
without breaking dependent formulae. Here, we report experiments to test that
this does indeed make such changes easier. In one, we automatically generated a
cross-tabulation and added it to a spreadsheet. In the other, we generated new
versions of a 10,000-cell housing-finance spreadsheet containing many
interconnected 20*40 tables. We varied table sizes from 5*10 to 200*2,000;
moved tables between sheets; and flipped table orientations. Each change
generated a spreadsheet with different structure but identical outputs; each
change took just a few minutes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0164</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0164</id><created>2008-03-02</created><authors><author><keyname>Thorne</keyname><forenames>Simon</forenames></author><author><keyname>Ball</keyname><forenames>David</forenames></author></authors><title>Considering Functional Spreadsheet Operator Usage Suggests the Value of
  Example Driven Modelling for Decision Support Systems</title><categories>cs.HC cs.SE</categories><comments>12 Pages, 6 Figures, 3 Tables</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>roc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 147-158
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most spreadsheet surveys both for reporting use and error focus on the
practical application of the spreadsheet in a particular industry. Typically
these studies will illustrate that a particular percentage of spreadsheets are
used for optimisation and a further percentage are used for 'What if' analysis.
Much less common is examining the classes of function, as defined by the
vendor, used by modellers to build their spreadsheet models. This alternative
analysis allows further insight into the programming nature of spreadsheets and
may assist researchers in targeting particular structures in spreadsheet
software for further investigation. Further, understanding the functional
make-up of spreadsheets allows effective evaluation of novel approaches from a
programming point of view. It allows greater insight into studies that report
what spreadsheets are used for since it is explicit which functional structures
are in use in spreadsheets. We conclude that a deeper understanding of the use
of operators and the operator's relationship to error would provide fresh
insight into the spreadsheet error problem. Considering functional spreadsheet
operator usage suggests the value of Example Driven Modelling for Decision
Support Systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0165</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0165</id><created>2008-03-02</created><authors><author><keyname>Payette</keyname><forenames>Raymond</forenames></author></authors><title>Documenting Spreadsheets</title><categories>cs.HC</categories><comments>12 Pages, 15 screen shots</comments><acm-class>D.2.4; D.2.5; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 163-173
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses spreadsheets documentation and new means to achieve this
end by using Excel's built-in &quot;Comment&quot; function. By structuring comments, they
can be used as an essential tool to fully explain spreadsheet. This will
greatly facilitate spreadsheet change control, risk management and auditing. It
will fill a crucial gap in corporate governance by adding essential information
that can be managed in order to satisfy internal controls and accountability
standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0166</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0166</id><created>2008-03-02</created><authors><author><keyname>Brath</keyname><forenames>Richard</forenames></author><author><keyname>Peters</keyname><forenames>Michael</forenames></author></authors><title>Spreadsheet Validation and Analysis through Content Visualization</title><categories>cs.HC</categories><comments>10 Pages, 11 Colour Figures</comments><acm-class>D.2.4; D.2.5; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 175-183
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visualizing spreadsheet content provides analytic insight and visual
validation of large amounts of spreadsheet data. Oculus Excel Visualizer is a
point and click data visualization experiment which directly visualizes Excel
data and re-uses the layout and formatting already present in the spreadsheet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0167</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0167</id><created>2008-03-02</created><authors><author><keyname>Purser</keyname><forenames>Michael</forenames></author><author><keyname>Chadwick</keyname><forenames>David</forenames></author></authors><title>Does an awareness of differing types of spreadsheet errors aid end-users
  in identifying spreadsheets errors?</title><categories>cs.HC</categories><comments>20 Pages, 14 Tables and Figures, many in colour</comments><acm-class>D.2.4; D.2.5; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 185-204
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research presented in this paper establishes a valid, and simplified,
revision of previous spreadsheet error classifications. This investigation is
concerned with the results of a web survey and two web-based gender and
domain-knowledge free spreadsheet error identification exercises. The
participants of the survey and exercises were a test group of professionals
(all of whom regularly use spreadsheets) and a control group of students from
the University of Greenwich (UK). The findings show that over 85% of users are
also the spreadsheet's developer, supporting the revised spreadsheet error
classification. The findings also show that spreadsheet error identification
ability is directly affected both by spreadsheet experience and by error-type
awareness. In particular, that spreadsheet error-type awareness significantly
improves the user's ability to identify, the more surreptitious, qualitative
error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0168</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0168</id><created>2008-03-02</created><authors><author><keyname>Baker</keyname><forenames>Kenneth R.</forenames></author><author><keyname>Powell</keyname><forenames>Stephen G.</forenames></author><author><keyname>Lawson</keyname><forenames>Barry</forenames></author><author><keyname>Foster-Johnson</keyname><forenames>Lynn</forenames></author></authors><title>Comparison of Characteristics and Practices amongst Spreadsheet Users
  with Different Levels of Experience</title><categories>cs.HC</categories><comments>16 Pages, 11 Tables</comments><acm-class>J.1; H.4.1; K.6.4; D.2.5; D.2.9; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 205-219
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We developed an internet-based questionnaire on spreadsheet use that we
administered to a large number of users in several companies and organizations
to document how spreadsheets are currently being developed and used in
business. In this paper, we discuss the results drawn from of a comparison of
responses from individuals with the most experience and expertise with those
from individuals with the least. These results describe two views of
spreadsheet design and use in organizations, and reflect gaps between these two
groups and between these groups and the entire population of nearly 1600
respondents. Moreover, our results indicate that these gaps have multiple
dimensions: they reflect not only the context, skill, and practices of
individual users but also the policies of large organizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0169</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0169</id><created>2008-03-02</created><authors><author><keyname>Blayney</keyname><forenames>Paul J.</forenames></author></authors><title>An Investigation of the Incidence and Effect of Spreadsheet Errors
  Caused by the Hard Coding of Input Data Values into Formulas</title><categories>cs.HC</categories><comments>10 Pages, 5 Tables</comments><acm-class>D.2.4; D.2.5; H.4.1; K.6.4; K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2006 22-230
  ISBN:1-905617-08-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hard coding of input data or constants into spreadsheet formulas is
widely recognised as poor spreadsheet model design. However, the importance of
avoiding such practice appears to be underestimated perhaps in light of the
lack of quantitative error at the time of occurrence and the recognition that
this design defect may never result in a bottom-line error. The paper examines
both the academic and practitioner view of such hard coding design flaws. The
practitioner or industry viewpoint is gained indirectly through a review of
commercial spreadsheet auditing software. The development of an automated
(electronic) means for detecting such hard coding is described together with a
discussion of some results obtained through analysis of a number of student and
practitioner spreadsheet models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0189</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0189</id><created>2008-03-03</created><updated>2008-03-04</updated><authors><author><keyname>Masuzawa</keyname><forenames>Toshimitsu</forenames><affiliation>LIP6, INRIA Futurs</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, INRIA Futurs</affiliation></author></authors><title>Quiescence of Self-stabilizing Gossiping among Mobile Agents in Graphs</title><categories>cs.DC cs.PF cs.RO</categories><proxy>ccsd inria-00260011</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers gossiping among mobile agents in graphs: agents move on
the graph and have to disseminate their initial information to every other
agent. We focus on self-stabilizing solutions for the gossip problem, where
agents may start from arbitrary locations in arbitrary states.
Self-stabilization requires (some of the) participating agents to keep moving
forever, hinting at maximizing the number of agents that could be allowed to
stop moving eventually. This paper formalizes the self-stabilizing agent gossip
problem, introduces the quiescence number (i.e., the maximum number of
eventually stopping agents) of self-stabilizing solutions and investigates the
quiescence number with respect to several assumptions related to agent
anonymity, synchrony, link duplex capacity, and whiteboard capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0194</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0194</id><created>2008-03-03</created><authors><author><keyname>Arsinte</keyname><forenames>Radu</forenames></author><author><keyname>Miron</keyname><forenames>Costin</forenames></author></authors><title>Acquisition Accuracy Evaluation in Visual Inspection Systems - a
  Practical Approach</title><categories>cs.CV cs.MM</categories><comments>6 pages, 4 figures, ETc'96 Conference paper</comments><journal-ref>Proceeedings of ETc '96 Conference, 1996, Timisoara, Romania</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper draws a proposal of a set of parameters and methods for accuracy
evaluation of visual inspection systems. The case of a monochrome board is
treated, but practically all conclusions and methods may be extended for colour
acquisition. Basically, the proposed parameters are grouped in five sets as
follows:Internal noise;Video ADC cuantisation parameters;Analogue processing
section parameters;Dominant frequencies;Synchronisation (lock-in) accuracy. On
basis of this set of parameters was developed a software environment, in
conjunction with a test signal generator that allows the &quot;test&quot; images. The
paper also presents conclusions of evaluation for two types of video
acquisition boards
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0197</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0197</id><created>2008-03-03</created><authors><author><keyname>Arsinte</keyname><forenames>Radu</forenames></author><author><keyname>Ferencz</keyname><forenames>Attila</forenames></author><author><keyname>Miron</keyname><forenames>Costin</forenames></author></authors><title>DSP Based System for Real time Voice Synthesis Applications Development</title><categories>cs.SD</categories><comments>4 pages, 3 figures, SPECOM' 96 Conference</comments><journal-ref>Proceedings of SPECOM' 96 Conference, 1996, St. Petersburg, Russia</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an experimental system designed for development of real
time voice synthesis applications. The system is composed from a DSP
coprocessor card, equipped with an TMS320C25 or TMS320C50 chip, voice
acquisition module (ADDA2),host computer (IBM-PC compatible), software specific
tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0225</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0225</id><created>2008-03-03</created><updated>2008-06-20</updated><authors><author><keyname>Andriamampianina</keyname><forenames>Tsiriniaina</forenames></author></authors><title>Random hypergraphs and algorithmics</title><categories>cs.DM</categories><comments>103 pages, french</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hypergraphs are structures that can be decomposed or described; in other
words they are recursively countable. Here, we get exact and asymptotic
enumeration results on hypergraphs by means of exponential generating
functions. The number of hypergraph component is bounded, as a generalisation
of Wright inequalities for graphs: the proof is a combinatorial understanding
of the structure by inclusion exclusion. Asymptotic results are obtained,
thanks to generating functions proofs are at the end very easy to read, through
complex analysis by saddle point method. By this way, we characterized:
  - the components with a given number of vertices and of hyperedges by the
expected size of a random hypermatching in these structures.
  - the random hypergraphs (evolving hyperedge by hyperedge) according to the
expected number of hyperedges when the first cycle appears in the evolving
structure.
  This work is an open road to further works on random hypergraphs such as
threshold phenomenon, tools used here seem to be sufficient at first sight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0241</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0241</id><created>2008-03-03</created><updated>2008-03-04</updated><authors><author><keyname>Daliot</keyname><forenames>Ariel</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Parnas</keyname><forenames>Hanna</forenames></author></authors><title>Self-Stabilizing Pulse Synchronization Inspired by Biological Pacemaker
  Networks</title><categories>cs.DC</categories><comments>This is the full and revised version. A previous (obsolete) version
  appeared as TR2003-1, The Hebrew University of Jerusalem, 2003</comments><acm-class>C.1.4; C.2.4; D.4.5</acm-class><journal-ref>In Proceedings of the Sixth Symposium on Self-Stabilizing Systems
  (SSS'03), San Francisco, June 2003. See also LNCS 2704</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the ``Pulse Synchronization'' problem that requires nodes to
achieve tight synchronization of regular pulse events, in the settings of
distributed computing systems. Pulse-coupled synchronization is a phenomenon
displayed by a large variety of biological systems, typically overcoming a high
level of noise. Inspired by such biological models, a robust and
self-stabilizing Byzantine pulse synchronization algorithm for distributed
computer systems is presented. The algorithm attains near optimal
synchronization tightness while tolerating up to a third of the nodes
exhibiting Byzantine behavior concurrently. Pulse synchronization has been
previously shown to be a powerful building block for designing algorithms in
this severe fault model. We have previously shown how to stabilize general
Byzantine algorithms, using pulse synchronization. To the best of our knowledge
there is no other scheme to do this without the use of synchronized pulses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0248</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0248</id><created>2008-03-03</created><authors><author><keyname>Chaintreau</keyname><forenames>Augustin</forenames></author><author><keyname>Fraigniaud</keyname><forenames>Pierre</forenames></author><author><keyname>Lebhar</keyname><forenames>Emmanuelle</forenames></author></authors><title>Networks become navigable as nodes move and forget</title><categories>cs.DS</categories><comments>21 pages, 1 figure</comments><acm-class>C.2.1; C.2.2; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a dynamical process for network evolution, aiming at explaining
the emergence of the small world phenomenon, i.e., the statistical observation
that any pair of individuals are linked by a short chain of acquaintances
computable by a simple decentralized routing algorithm, known as greedy
routing. Previously proposed dynamical processes enabled to demonstrate
experimentally (by simulations) that the small world phenomenon can emerge from
local dynamics. However, the analysis of greedy routing using the probability
distributions arising from these dynamics is quite complex because of mutual
dependencies. In contrast, our process enables complete formal analysis. It is
based on the combination of two simple processes: a random walk process, and an
harmonic forgetting process. Both processes reflect natural behaviors of the
individuals, viewed as nodes in the network of inter-individual acquaintances.
We prove that, in k-dimensional lattices, the combination of these two
processes generates long-range links mutually independently distributed as a
k-harmonic distribution. We analyze the performances of greedy routing at the
stationary regime of our process, and prove that the expected number of steps
for routing from any source to any target in any multidimensional lattice is a
polylogarithmic function of the distance between the two nodes in the lattice.
Up to our knowledge, these results are the first formal proof that navigability
in small worlds can emerge from a dynamical process for network evolution. Our
dynamical process can find practical applications to the design of spatial
gossip and resource location protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0265</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0265</id><created>2008-03-03</created><authors><author><keyname>Wang</keyname><forenames>Ying</forenames></author><author><keyname>Moulin</keyname><forenames>Pierre</forenames></author></authors><title>Blind Fingerprinting</title><categories>cs.IT math.IT</categories><comments>36 pages, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study blind fingerprinting, where the host sequence into which
fingerprints are embedded is partially or completely unknown to the decoder.
This problem relates to a multiuser version of the Gel'fand-Pinsker problem.
The number of colluders and the collusion channel are unknown, and the
colluders and the fingerprint embedder are subject to distortion constraints.
  We propose a conditionally constant-composition random binning scheme and a
universal decoding rule and derive the corresponding false-positive and
false-negative error exponents. The encoder is a stacked binning scheme and
makes use of an auxiliary random sequence. The decoder is a {\em maximum
doubly-penalized mutual information decoder}, where the significance of each
candidate coalition is assessed relative to a threshold that trades off
false-positive and false-negative error exponents. The penalty is proportional
to coalition size and is a function of the conditional type of host sequence.
Positive exponents are obtained at all rates below a certain value, which is
therefore a lower bound on public fingerprinting capacity. We conjecture that
this value is the public fingerprinting capacity. A simpler threshold decoder
is also given, which has similar universality properties but also lower
achievable rates. An upper bound on public fingerprinting capacity is also
derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0316</identifier>
 <datestamp>2008-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0316</id><created>2008-03-03</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Ishaque</keyname><forenames>Mashhood</forenames></author><author><keyname>Rafalin</keyname><forenames>Eynat</forenames></author><author><keyname>Schweller</keyname><forenames>Robert T.</forenames></author><author><keyname>Souvaine</keyname><forenames>Diane</forenames></author></authors><title>Staged Self-Assembly:Nanomanufacture of Arbitrary Shapes with O(1) Glues</title><categories>cs.CG</categories><comments>22 pages, 15 figures, 1table, PDFLatex; conference version in
  Proceedings of the 13th International Meeting on DNA Computing (DNA13), 2007,
  pp. 46-55, full version to appear in Natural Computing</comments><acm-class>F.1.1; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce staged self-assembly of Wang tiles, where tiles can be added
dynamically in sequence and where intermediate constructions can be stored for
later mixing. This model and its various constraints and performance measures
are motivated by a practical nanofabrication scenario through protein-based
bioengineering. Staging allows us to break through the traditional lower bounds
in tile self-assembly by encoding the shape in the staging algorithm instead of
the tiles. All of our results are based on the practical assumption that only a
constant number of glues, and thus only a constant number of tiles, can be
engineered, as each new glue type requires significant biochemical research and
experiments. Under this assumption, traditional tile self-assembly cannot even
manufacture an n*n square; in contrast, we show how staged assembly enables
manufacture of arbitrary orthogonal shapes in a variety of precise formulations
of the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0378</identifier>
 <datestamp>2011-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0378</id><created>2008-03-04</created><updated>2008-07-16</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Thread algebra for poly-threading</title><categories>cs.LO</categories><comments>24 pages, sections 9, 10, and 11 are added</comments><report-no>PRG0810</report-no><acm-class>D.4.1; F.1.1; F.1.2; F.3.2</acm-class><journal-ref>Formal Aspects of Computing, 23(4):567--583, 2011</journal-ref><doi>10.1007/s00165-011-0178-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Threads as considered in basic thread algebra are primarily looked upon as
behaviours exhibited by sequential programs on execution. It is a fact of life
that sequential programs are often fragmented. Consequently, fragmented program
behaviours are frequently found. In this paper, we consider this phenomenon. We
extend basic thread algebra with the barest mechanism for sequencing of threads
that are taken for fragments. This mechanism, called poly-threading, supports
both autonomous and non-autonomous thread selection in sequencing. We relate
the resulting theory to the algebraic theory of processes known as ACP and use
it to describe analytic execution architectures suited for fragmented programs.
We also consider the case where the steps of fragmented program behaviours are
interleaved in the ways of non-distributed and distributed multi-threading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0398</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0398</id><created>2008-03-04</created><authors><author><keyname>Baronchelli</keyname><forenames>Andrea</forenames></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author><author><keyname>Steels</keyname><forenames>Luc</forenames></author></authors><title>In-depth analysis of the Naming Game dynamics: the homogeneous mixing
  case</title><categories>physics.soc-ph cond-mat.stat-mech cs.GT cs.MA</categories><comments>30 pages, 19 figures (few in reduced definition). In press in IJMPC</comments><journal-ref>Int. J. Mod. Phys. C 19, 785 (2008)</journal-ref><doi>10.1142/S0129183108012522</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Language emergence and evolution has recently gained growing attention
through multi-agent models and mathematical frameworks to study their behavior.
Here we investigate further the Naming Game, a model able to account for the
emergence of a shared vocabulary of form-meaning associations through
social/cultural learning. Due to the simplicity of both the structure of the
agents and their interaction rules, the dynamics of this model can be analyzed
in great detail using numerical simulations and analytical arguments. This
paper first reviews some existing results and then presents a new overall
understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0404</identifier>
 <datestamp>2008-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0404</id><created>2008-03-04</created><authors><author><keyname>Freixas</keyname><forenames>Josep</forenames></author><author><keyname>Molinero</keyname><forenames>Xavier</forenames></author><author><keyname>Olsen</keyname><forenames>Martin</forenames></author><author><keyname>Serna</keyname><forenames>Maria</forenames></author></authors><title>The Complexity of Testing Properties of Simple Games</title><categories>cs.GT cs.CC</categories><comments>18 pages, LaTex file</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simple games cover voting systems in which a single alternative, such as a
bill or an amendment, is pitted against the status quo. A simple game or a
yes-no voting system is a set of rules that specifies exactly which collections
of ``yea'' votes yield passage of the issue at hand. A collection of ``yea''
voters forms a winning coalition.
  We are interested on performing a complexity analysis of problems on such
games depending on the game representation. We consider four natural explicit
representations, winning, loosing, minimal winning, and maximal loosing. We
first analyze the computational complexity of obtaining a particular
representation of a simple game from a different one. We show that some cases
this transformation can be done in polynomial time while the others require
exponential time. The second question is classifying the complexity for testing
whether a game is simple or weighted. We show that for the four types of
representation both problem can be solved in polynomial time. Finally, we
provide results on the complexity of testing whether a simple game or a
weighted game is of a special type. In this way, we analyze strongness,
properness, decisiveness and homogeneity, which are desirable properties to be
fulfilled for a simple game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0405</identifier>
 <datestamp>2008-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0405</id><created>2008-03-04</created><authors><author><keyname>Franciosi</keyname><forenames>Marco</forenames></author><author><keyname>Menconi</keyname><forenames>Giulia</forenames></author></authors><title>Multi-dimensional sparse time series: feature extraction</title><categories>cs.MM cs.IR</categories><comments>Keywords: multimedia mining, trend, entropy, Zipf law</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show an analysis of multi-dimensional time series via entropy and
statistical linguistic techniques. We define three markers encoding the
behavior of the series, after it has been translated into a multi-dimensional
symbolic sequence. The leading component and the trend of the series with
respect to a mobile window analysis result from the entropy analysis and label
the dynamical evolution of the series. The diversification formalizes the
differentiation in the use of recurrent patterns, from a Zipf law point of
view. These markers are the starting point of further analysis such as
classification or clustering of large database of multi-dimensional time
series, prediction of future behavior and attribution of new data. We also
present an application to economic data. We deal with measurements of money
investments of some business companies in advertising market for different
media sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0412</identifier>
 <datestamp>2008-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0412</id><created>2008-03-04</created><updated>2008-09-06</updated><authors><author><keyname>Feigel</keyname><forenames>A.</forenames></author></authors><title>Essential conditions for evolution of communication within a species</title><categories>q-bio.PE cs.GT physics.soc-ph</categories><comments>Final version to appear in Journal of Theoretical Biology, see DOI
  Extended introduction, notation is changed to fit the standard</comments><doi>10.1016/j.jtbi.2008.07.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major obstacle in analyzing the evolution of information exchange and
processing is our insufficient understanding of the underlying signaling and
decision-making biological mechanisms. For instance, it is unclear why are
humans unique in developing such extensive communication abilities. To treat
this problem, a method based on the mutual information approach is developed
that evaluates the information content of communication between interacting
individuals through correlations of their behavior patterns (rather than
calculating the information load of exchanged discrete signals, e.g. Shannon
entropy). It predicts that correlated interactions of the indirect reciprocity
type together with affective behavior and selection rules changing with time
are necessary conditions for the emergence of significant information exchange.
Population size variations accelerate this development. These results are
supported by evidence of demographic bottlenecks, distinguishing human from
other species' (e.g. apes) evolution line. They indicate as well new pathways
for evolution of information based phenomena, such as intelligence and
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0428</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0428</id><created>2008-03-04</created><updated>2008-10-27</updated><authors><author><keyname>Wahls</keyname><forenames>Sander</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author><author><keyname>Pohl</keyname><forenames>Volker</forenames></author></authors><title>Zero-Forcing Precoding for Frequency Selective MIMO Channels with
  $H^\infty$ Criterion and Causality Constraint</title><categories>cs.IT math.IT</categories><comments>Minor Revisions, mainly in introduction and problem statement.
  Submitted to Signal Processing</comments><journal-ref>Signal Processing, Vol. 89, No. 9, pp. 1754-1761, Sep. 2009</journal-ref><doi>10.1016/j.sigpro.2009.03.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider zero-forcing equalization of frequency selective MIMO channels by
causal and linear time-invariant precoders in the presence of intersymbol
interference. Our motivation is twofold. First, we are concerned with the
optimal performance of causal precoders from a worst case point of view.
Therefore we construct an optimal causal precoder, whereas contrary to other
works our construction is not limited to finite or rational impulse responses.
Moreover we derive a novel numerical approach to computation of the optimal
perfomance index achievable by causal precoders for given channels. This
quantity is important in the numerical determination of optimal precoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0439</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0439</id><created>2008-03-04</created><authors><author><keyname>De Dinechin</keyname><forenames>Florent</forenames><affiliation>LIP</affiliation></author><author><keyname>Lauter</keyname><forenames>Christoph Quirin</forenames><affiliation>LIP</affiliation></author></authors><title>Optimizing polynomials for floating-point implementation</title><categories>cs.NA cs.MS</categories><comments>12 pages</comments><proxy>ccsd ensl-00260563</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The floating-point implementation of a function on an interval often reduces
to polynomial approximation, the polynomial being typically provided by Remez
algorithm. However, the floating-point evaluation of a Remez polynomial
sometimes leads to catastrophic cancellations. This happens when some of the
polynomial coefficients are very small in magnitude with respects to others. In
this case, it is better to force these coefficients to zero, which also reduces
the operation count. This technique, classically used for odd or even
functions, may be generalized to a much larger class of functions. An algorithm
is presented that forces to zero the smaller coefficients of the initial
polynomial thanks to a modified Remez algorithm targeting an incomplete
monomial basis. One advantage of this technique is that it is purely numerical,
the function being used as a numerical black box. This algorithm is implemented
within a larger polynomial implementation tool that is demonstrated on a range
of examples, resulting in polynomials with less coefficients than those
obtained the usual way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0450</identifier>
 <datestamp>2008-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0450</id><created>2008-03-04</created><updated>2008-03-10</updated><authors><author><keyname>Patnaik</keyname><forenames>Debprakash</forenames><affiliation>Electical Engg. Dept., Indian Institute of Science, Bangalore</affiliation></author><author><keyname>Sastry</keyname><forenames>P. S.</forenames><affiliation>Electrical Engg. Dept., Indian Institute of Science, Bangalore</affiliation></author><author><keyname>Unnikrishnan</keyname><forenames>K. P.</forenames><affiliation>General Motors R&amp;D, Warren</affiliation></author></authors><title>Inferring Neuronal Network Connectivity from Spike Data: A Temporal
  Datamining Approach</title><categories>cs.DB q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the functioning of a neural system in terms of its underlying
circuitry is an important problem in neuroscience. Recent developments in
electrophysiology and imaging allow one to simultaneously record activities of
hundreds of neurons. Inferring the underlying neuronal connectivity patterns
from such multi-neuronal spike train data streams is a challenging statistical
and computational problem. This task involves finding significant temporal
patterns from vast amounts of symbolic time series data. In this paper we show
that the frequent episode mining methods from the field of temporal data mining
can be very useful in this context. In the frequent episode discovery
framework, the data is viewed as a sequence of events, each of which is
characterized by an event type and its time of occurrence and episodes are
certain types of temporal patterns in such data. Here we show that, using the
set of discovered frequent episodes from multi-neuronal data, one can infer
different types of connectivity patterns in the neural system that generated
it. For this purpose, we introduce the notion of mining for frequent episodes
under certain temporal constraints; the structure of these temporal constraints
is motivated by the application. We present algorithms for discovering serial
and parallel episodes under these temporal constraints. Through extensive
simulation studies we demonstrate that these methods are useful for unearthing
patterns of neuronal network connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0473</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0473</id><created>2008-03-04</created><updated>2010-11-15</updated><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Duffield</keyname><forenames>Nick</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Lund</keyname><forenames>Carsten</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>Stream sampling for variance-optimal estimation of subset sums</title><categories>cs.DS</categories><comments>31 pages. An extended abstract appeared in the proceedings of the
  20th ACM-SIAM Symposium on Discrete Algorithms (SODA 2009)</comments><acm-class>C.2.3; E.1; F.2; G.3; H.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From a high volume stream of weighted items, we want to maintain a generic
sample of a certain limited size $k$ that we can later use to estimate the
total weight of arbitrary subsets. This is the classic context of on-line
reservoir sampling, thinking of the generic sample as a reservoir. We present
an efficient reservoir sampling scheme, $\varoptk$, that dominates all previous
schemes in terms of estimation quality.
  $\varoptk$ provides {\em variance optimal unbiased estimation of subset
sums}. More precisely, if we have seen $n$ items of the stream, then for {\em
any} subset size $m$, our scheme based on $k$ samples minimizes the average
variance over all subsets of size $m$. In fact, the optimality is against any
off-line scheme with $k$ samples tailored for the concrete set of items seen.
In addition to optimal average variance, our scheme provides tighter worst-case
bounds on the variance of {\em particular} subsets than previously possible. It
is efficient, handling each new item of the stream in $O(\log k)$ time.
Finally, it is particularly well suited for combination of samples from
different streams in a distributed setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0476</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0476</id><created>2008-03-04</created><updated>2008-07-25</updated><authors><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author><author><keyname>Guillaume</keyname><forenames>Jean-Loup</forenames></author><author><keyname>Lambiotte</keyname><forenames>Renaud</forenames></author><author><keyname>Lefebvre</keyname><forenames>Etienne</forenames></author></authors><title>Fast unfolding of communities in large networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.CY cs.DS</categories><comments>6 pages, 5 figures, 1 table; new version with new figures in order to
  clarify our method, where we look more carefully at the role played by the
  ordering of the nodes and where we compare our method with that of Wakita and
  Tsurumi</comments><journal-ref>J. Stat. Mech. (2008) P10008</journal-ref><doi>10.1088/1742-5468/2008/10/P10008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple method to extract the community structure of large
networks. Our method is a heuristic method that is based on modularity
optimization. It is shown to outperform all other known community detection
method in terms of computation time. Moreover, the quality of the communities
detected is very good, as measured by the so-called modularity. This is shown
first by identifying language communities in a Belgian mobile phone network of
2.6 million customers and by analyzing a web graph of 118 million nodes and
more than one billion links. The accuracy of our algorithm is also verified on
ad-hoc modular networks. .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0515</identifier>
 <datestamp>2008-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0515</id><created>2008-03-04</created><authors><author><keyname>Pearson</keyname><forenames>Christopher</forenames></author><author><keyname>Gibbs</keyname><forenames>Celina</forenames></author><author><keyname>Coady</keyname><forenames>Yvonne</forenames></author></authors><title>Intuitive Source Code Visualization Tools for Improving Student
  Comprehension: BRICS</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even relatively simple code analysis can be a daunting task for many first
year students. Perceived complexity, coupled with foreign and harsh syntax,
often outstrips the ability for students to take in what they are seeing in
terms of their verbal memory. That is, first year students often lack the
experience to encode critical building blocks in source code, and their
interrelationships, into their own words. We believe this argues for the need
for IDEs to provide additional support for representations that would appeal
directly to visual memory. In this paper, we examine this need for intuitive
source code visualization tools that are easily accessible to novice
programmers, discuss the requirements for such a tool, and suggest a novel idea
that takes advantage of human peripheral vision to achieve stronger overall
code structure awareness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0528</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0528</id><created>2008-03-04</created><authors><author><keyname>Hoceini</keyname><forenames>Said</forenames><affiliation>LISSI - Ea 3956</affiliation></author><author><keyname>Mellouk</keyname><forenames>Abdelhamid</forenames><affiliation>LISSI - Ea 3956</affiliation></author><author><keyname>Hafi</keyname><forenames>Hayet</forenames><affiliation>LISSI - Ea 3956</affiliation></author></authors><title>Une approche modulaire probabiliste pour le routage \`a Qualit\'e de
  Service int\'egr\'ee</title><categories>cs.NI</categories><proxy>ccsd hal-00260545</proxy><journal-ref>Colloque Francophone sur l'Ing\'enierie des Protocoles (CFIP), Les
  Arcs : France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to emerging real-time and multimedia applications, efficient routing of
information packets in dynamically changing communication network requires that
as the load levels, traffic patterns and topology of the network change, the
routing policy also adapts. We focused in this paper on QoS based routing by
developing a neuro-dynamic programming to construct dynamic state dependent
routing policies. We propose an approach based on adaptive algorithm for packet
routing using reinforcement learning which optimizes two criteria: cumulative
cost path and end-to-end delay. Numerical results obtained with OPNET simulator
for different packet interarrival times statistical distributions with
different levels of traffic's load show that the proposed approach gives better
results compared to standard optimal path routing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0529</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0529</id><created>2008-03-04</created><authors><author><keyname>Barcikowski</keyname><forenames>M.</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Pernelle</keyname><forenames>P.</forenames><affiliation>AIB_ERN</affiliation></author><author><keyname>Lefebvre</keyname><forenames>A.</forenames><affiliation>AIB_ERN</affiliation></author><author><keyname>Martinez</keyname><forenames>M.</forenames></author><author><keyname>Renaud</keyname><forenames>J.</forenames></author></authors><title>Evaluation and exploitation of knowledge robustness in knowledge-based
  systems</title><categories>cs.OH</categories><proxy>ccsd hal-00260535</proxy><journal-ref>Dans Proceedings - 9th IFAC (IEEE Control Systems Society) Symp.
  Automated Syst. Based on Human Skill and Knowledge (ASBoHS'06), Nancy :
  France (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Industrial knowledge is complex, difficult to formalize and very dynamic in
reason of the continuous development of techniques and technologies. The
verification of the validity of the knowledge base at the time of its
elaboration is not sufficient. To be exploitable, this knowledge must then be
able to be used under conditions (slightly) different from the conditions in
which it was formalized. So, it becomes vital for the company to permanently
evaluate the quality of the industrial knowledge implemented in the system.
This evaluation is founded on the concept of robustness of the knowledge
formalized by conceptual graphs. The evaluation method is supported by a
computerized tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0597</identifier>
 <datestamp>2008-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0597</id><created>2008-03-05</created><authors><author><keyname>Cardoso</keyname><forenames>L. S.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author><author><keyname>Bianchi</keyname><forenames>P.</forenames></author><author><keyname>Najim</keyname><forenames>J.</forenames></author></authors><title>Cooperative Spectrum Sensing Using Random Matrix Theory</title><categories>cs.IT math.IT</categories><comments>Submitted to International Symposium on Wireless Pervasive Computing
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, using tools from asymptotic random matrix theory, a new
cooperative scheme for frequency band sensing is introduced for both AWGN and
fading channels. Unlike previous works in the field, the new scheme does not
require the knowledge of the noise statistics or its variance and is related to
the behavior of the largest and smallest eigenvalue of random matrices.
Remarkably, simulations show that the asymptotic claims hold even for a small
number of observations (which makes it convenient for time-varying topologies),
outperforming classical energy detection techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0610</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0610</id><created>2008-03-05</created><updated>2008-07-10</updated><authors><author><keyname>Jung</keyname><forenames>Peter</forenames></author></authors><title>On the Approximate Eigenstructure of Time-Varying Channels</title><categories>cs.IT math.IT</categories><comments>30 onecolumn-pages, 2 figures, replaced with revised version,
  submitted (Dec07) to Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we consider the approximate description of doubly--dispersive
channels by its symbol. We focus on channel operators with compactly supported
spreading, which are widely used to represent fast fading multipath
communication channels. The concept of approximate eigenstructure is
introduced, which measures the accuracy E_p of the approximation of the channel
operation as a pure multiplication in a given L_p-norm. Two variants of such an
approximate Weyl symbol calculus are studied, which have important applications
in several models for time--varying mobile channels. Typically, such channels
have random spreading functions (inverse Weyl transform) defined on a common
support U of finite non--zero size such that approximate eigenstructure has to
be measured with respect to certain norms of the spreading process. We derive
several explicit relations to the size |U| of the support. We show that the
characterization of the ratio of E_p to some L_q-norm of the spreading function
is related to weighted norms of ambiguity and Wigner functions. We present the
connection to localization operators and give new bounds on the ability of
localization of ambiguity functions and Wigner functions in U. Our analysis
generalizes and improves recent results for the case p=2 and q=1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0632</identifier>
 <datestamp>2008-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0632</id><created>2008-03-05</created><authors><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author><author><keyname>Wu</keyname><forenames>Yunnan</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Network Coding for Distributed Storage Systems</title><categories>cs.NI cs.IT math.IT</categories><report-no>EECS 14546</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed storage systems provide reliable access to data through
redundancy spread over individually unreliable nodes. Application scenarios
include data centers, peer-to-peer storage systems, and storage in wireless
networks. Storing data using an erasure code, in fragments spread across nodes,
requires less redundancy than simple replication for the same level of
reliability. However, since fragments must be periodically replaced as nodes
fail, a key question is how to generate encoded fragments in a distributed way
while transferring as little data as possible across the network.
  For an erasure coded system, a common practice to repair from a node failure
is for a new node to download subsets of data stored at a number of surviving
nodes, reconstruct a lost coded block using the downloaded data, and store it
at the new node. We show that this procedure is sub-optimal. We introduce the
notion of regenerating codes, which allow a new node to download
\emph{functions} of the stored data from the surviving nodes. We show that
regenerating codes can significantly reduce the repair bandwidth. Further, we
show that there is a fundamental tradeoff between storage and repair bandwidth
which we theoretically characterize using flow arguments on an appropriately
constructed graph. By invoking constructive results in network coding, we
introduce regenerating codes that can achieve any point in this optimal
tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0653</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0653</id><created>2008-03-05</created><authors><author><keyname>Garcia-Alfaro</keyname><forenames>Joaquin</forenames></author><author><keyname>Cuppens</keyname><forenames>Frederic</forenames></author><author><keyname>Cuppens-Boulahia</keyname><forenames>Nora</forenames></author></authors><title>Aggregating and Deploying Network Access Control Policies</title><categories>cs.CR cs.NI</categories><comments>9 pages</comments><journal-ref>Proc. 2007 International Symposium on Frontiers in Availability,
  Reliability and Security (FARES), Vienna (Austria), 10-13 April 2007
  (10/04/2007), 532-539</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existence of errors or inconsistencies in the configuration of security
components, such as filtering routers and/or firewalls, may lead to weak access
control policies -- potentially easy to be evaded by unauthorized parties. We
present in this paper a proposal to create, manage, and deploy consistent
policies in those components in an efficient way. To do so, we combine two main
approaches. The first approach is the use of an aggregation mechanism that
yields consistent configurations or signals inconsistencies. Through this
mechanism we can fold existing policies of a given system and create a
consistent and global set of access control rules -- easy to maintain and
manage by using a single syntax. The second approach is the use of a refinement
mechanism that guarantees the proper deployment of such a global set of rules
into the system, yet free of inconsistencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0661</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0661</id><created>2008-03-05</created><authors><author><keyname>Nordstr&#xf6;m</keyname><forenames>Jakob</forenames></author><author><keyname>H&#xe5;stad</keyname><forenames>Johan</forenames></author></authors><title>Towards an Optimal Separation of Space and Length in Resolution</title><categories>cs.CC cs.LO</categories><acm-class>F.4.1; F.1.3; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most state-of-the-art satisfiability algorithms today are variants of the
DPLL procedure augmented with clause learning. The main bottleneck for such
algorithms, other than the obvious one of time, is the amount of memory used.
In the field of proof complexity, the resources of time and memory correspond
to the length and space of resolution proofs. There has been a long line of
research trying to understand these proof complexity measures, but while strong
results have been proven on length our understanding of space is still quite
poor. For instance, it remains open whether the fact that a formula is provable
in short length implies that it is also provable in small space or whether on
the contrary these measures are unrelated in the sense that short proofs can be
arbitrarily complex with respect to space.
  In this paper, we present some evidence that the true answer should be that
the latter case holds. We do this by proving a tight bound of Theta(sqrt(n)) on
the space needed for so-called pebbling contradictions over pyramid graphs of
size n. This yields the first polynomial lower bound on space that is not a
consequence of a corresponding lower bound on width, another well-studied
measure in resolution, as well as an improvement of the weak separation in
(Nordstrom 2006) of space and width from logarithmic to polynomial.
  Also, continuing the line of research initiated by (Ben-Sasson 2002) into
trade-offs between different proof complexity measures, we present a simplified
proof of the recent length-space trade-off result in (Hertel and Pitassi 2007),
and show how our ideas can be used to prove a couple of other exponential
trade-offs in resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0666</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0666</id><created>2008-03-05</created><authors><author><keyname>Kadiri</keyname><forenames>Soumaya El</forenames><affiliation>LIESP</affiliation></author><author><keyname>Pernelle</keyname><forenames>Philippe</forenames><affiliation>LIESP</affiliation></author><author><keyname>Delattre</keyname><forenames>Miguel</forenames><affiliation>LIESP</affiliation></author><author><keyname>Bouras</keyname><forenames>Abdelaziz</forenames><affiliation>LIESP</affiliation></author></authors><title>An approach to control collaborative processes in PLM systems</title><categories>cs.SE</categories><proxy>ccsd hal-00260859</proxy><journal-ref>Dans Workshop on Extended Product and Process Analysis aNd Design
  - Extended Product and Process Analysis aNd Design, Bordeaux : France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Companies that collaborate within the product development processes need to
implement an effective management of their collaborative activities. Despite
the implementation of a PLM system, the collaborative activities are not
efficient as it might be expected. This paper presents an analysis of the
problems related to the collaborative work using a PLM system. From this
analysis, we propose an approach for improving collaborative processes within a
PLM system, based on monitoring indicators. This approach leads to identify and
therefore to mitigate the brakes of the collaborative work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0701</identifier>
 <datestamp>2008-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0701</id><created>2008-03-05</created><authors><author><keyname>Alon</keyname><forenames>N</forenames></author><author><keyname>Fomin</keyname><forenames>F. V.</forenames></author><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Krivelevich</keyname><forenames>M.</forenames></author><author><keyname>Saurabh</keyname><forenames>S.</forenames></author></authors><title>Spanning directed trees with many leaves</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\sc Directed Maximum Leaf Out-Branching} problem is to find an
out-branching (i.e. a rooted oriented spanning tree) in a given digraph with
the maximum number of leaves. In this paper, we obtain two combinatorial
results on the number of leaves in out-branchings. We show that
  - every strongly connected $n$-vertex digraph $D$ with minimum in-degree at
least 3 has an out-branching with at least $(n/4)^{1/3}-1$ leaves;
  - if a strongly connected digraph $D$ does not contain an out-branching with
$k$ leaves, then the pathwidth of its underlying graph UG($D$) is $O(k\log k)$.
Moreover, if the digraph is acyclic, the pathwidth is at most $4k$.
  The last result implies that it can be decided in time $2^{O(k\log^2 k)}\cdot
n^{O(1)}$ whether a strongly connected digraph on $n$ vertices has an
out-branching with at least $k$ leaves. On acyclic digraphs the running time of
our algorithm is $2^{O(k\log k)}\cdot n^{O(1)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0726</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0726</id><created>2008-03-05</created><updated>2013-05-30</updated><authors><author><keyname>B&#xe9;al</keyname><forenames>Marie-Pierre</forenames></author><author><keyname>Perrin</keyname><forenames>Dominique</forenames></author></authors><title>A quadratic algorithm for road coloring</title><categories>cs.DS cs.DM</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Road Coloring Theorem states that every aperiodic directed graph with
constant out-degree has a synchronized coloring. This theorem had been
conjectured during many years as the Road Coloring Problem before being settled
by A. Trahtman. Trahtman's proof leads to an algorithm that finds a
synchronized labeling with a cubic worst-case time complexity. We show a
variant of his construction with a worst-case complexity which is quadratic in
time and linear in space. We also extend the Road Coloring Theorem to the
periodic case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0731</identifier>
 <datestamp>2008-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0731</id><created>2008-03-05</created><updated>2008-05-07</updated><authors><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Complexity Analysis of Reed-Solomon Decoding over GF(2^m) Without Using
  Syndromes</title><categories>cs.IT cs.CC cs.DS math.IT</categories><comments>11 pages, submitted to EURASIP Journal on Wireless Communications and
  Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the majority of the applications of Reed-Solomon (RS) codes, hard
decision decoding is based on syndromes. Recently, there has been renewed
interest in decoding RS codes without using syndromes. In this paper, we
investigate the complexity of syndromeless decoding for RS codes, and compare
it to that of syndrome-based decoding. Aiming to provide guidelines to
practical applications, our complexity analysis differs in several aspects from
existing asymptotic complexity analysis, which is typically based on
multiplicative fast Fourier transform (FFT) techniques and is usually in big O
notation. First, we focus on RS codes over characteristic-2 fields, over which
some multiplicative FFT techniques are not applicable. Secondly, due to
moderate block lengths of RS codes in practice, our analysis is complete since
all terms in the complexities are accounted for. Finally, in addition to fast
implementation using additive FFT techniques, we also consider direct
implementation, which is still relevant for RS codes with moderate lengths.
Comparing the complexities of both syndromeless and syndrome-based decoding
algorithms based on direct and fast implementations, we show that syndromeless
decoding algorithms have higher complexities than syndrome-based ones for high
rate RS codes regardless of the implementation. Both errors-only and
errors-and-erasures decoding are considered in this paper. We also derive
tighter bounds on the complexities of fast polynomial multiplications based on
Cantor's approach and the fast extended Euclidean algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0755</identifier>
 <datestamp>2008-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0755</id><created>2008-03-05</created><authors><author><keyname>Sebert</keyname><forenames>Florian</forenames></author><author><keyname>Ying</keyname><forenames>Leslie</forenames></author><author><keyname>Zou</keyname><forenames>Yi Ming</forenames></author></authors><title>Toeplitz Block Matrices in Compressed Sensing</title><categories>cs.IT math.IT math.PR</categories><comments>Preprint 16 pages, 1 figure</comments><msc-class>94A20; 94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work in compressed sensing theory shows that $n\times N$ independent
and identically distributed (IID) sensing matrices whose entries are drawn
independently from certain probability distributions guarantee exact recovery
of a sparse signal with high probability even if $n\ll N$. Motivated by signal
processing applications, random filtering with Toeplitz sensing matrices whose
elements are drawn from the same distributions were considered and shown to
also be sufficient to recover a sparse signal from reduced samples exactly with
high probability. This paper considers Toeplitz block matrices as sensing
matrices. They naturally arise in multichannel and multidimensional filtering
applications and include Toeplitz matrices as special cases. It is shown that
the probability of exact reconstruction is also high. Their performance is
validated using simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0764</identifier>
 <datestamp>2008-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0764</id><created>2008-03-06</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author></authors><title>Asymmetric and Symmetric Subsystem BCH Codes and Beyond</title><categories>quant-ph cs.IT math.IT</categories><comments>10 pages, 2 figures, and 2 tables of independent work. Private
  comments and corrections are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the theory of quantum error control codes has been extended to
subsystem codes over symmetric and asymmetric quantum channels -- qubit-flip
and phase-shift errors may have equal or different probabilities. Previous work
in constructing quantum error control codes has focused on code constructions
for symmetric quantum channels. In this paper, we develop a theory and
establish the connection between asymmetric quantum codes and subsystem codes.
We present families of subsystem and asymmetric quantum codes derived, once
again, from classical BCH and RS codes over finite fields. Particularly, we
derive an interesting asymmetric and symmetric subsystem codes based on
classical BCH codes with parameters $[[n,k,r,d]]_q$, $[[n,k,r,d_z/d_x]]_q$ and
$[[n,k',0,d_z/d_x]]_q$ for arbitrary values of code lengths and dimensions. We
establish asymmetric Singleton and Hamming bounds on asymmetric quantum and
subsystem code parameters; and derive optimal asymmetric MDS subsystem codes.
Finally, our constructions are well explained by an illustrative example.
  This paper is written on the occasion of the 50th anniversary of the
discovery of classical BCH codes and their quantum counterparts were derived
nearly 10 years ago.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0778</identifier>
 <datestamp>2008-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0778</id><created>2008-03-05</created><updated>2008-05-07</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Constant-Rank Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in Proc. IEEE ISIT 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant-dimension codes have recently received attention due to their
significance to error control in noncoherent random network coding. In this
paper, we show that constant-rank codes are closely related to
constant-dimension codes and we study the properties of constant-rank codes. We
first introduce a relation between vectors in $\mathrm{GF}(q^m)^n$ and
subspaces of $\mathrm{GF}(q)^m$ or $\mathrm{GF}(q)^n$, and use it to establish
a relation between constant-rank codes and constant-dimension codes. We then
derive bounds on the maximum cardinality of constant-rank codes with given rank
weight and minimum rank distance. Finally, we investigate the asymptotic
behavior of the maximal cardinality of constant-rank codes with given rank
weight and minimum rank distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0792</identifier>
 <datestamp>2008-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0792</id><created>2008-03-06</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Sen</keyname><forenames>Siddhartha</forenames></author><author><keyname>Tarjan</keyname><forenames>Robert E.</forenames></author></authors><title>Incremental Topological Ordering and Strong Component Maintenance</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an on-line algorithm for maintaining a topological order of a
directed acyclic graph as arcs are added, and detecting a cycle when one is
created. Our algorithm takes O(m^{1/2}) amortized time per arc, where m is the
total number of arcs. For sparse graphs, this bound improves the best previous
bound by a logarithmic factor and is tight to within a constant factor for a
natural class of algorithms that includes all the existing ones. Our main
insight is that the bidirectional search method of previous algorithms does not
require an ordered search, but can be more general. This allows us to avoid the
use of heaps (priority queues) entirely. Instead, the deterministic version of
our algorithm uses (approximate) median-finding. The randomized version of our
algorithm avoids this complication, making it very simple. We extend our
topological ordering algorithm to give the first detailed algorithm for
maintaining the strong components of a directed graph, and a topological order
of these components, as arcs are added. This extension also has an amortized
time bound of O(m^{1/2}) per arc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0803</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0803</id><created>2008-03-06</created><authors><author><keyname>Ali</keyname><forenames>Husnain Mansoor</forenames><affiliation>IEF</affiliation></author><author><keyname>Busson</keyname><forenames>Anthony</forenames><affiliation>IEF</affiliation></author><author><keyname>Naimi</keyname><forenames>Amina Meraihi</forenames><affiliation>IEF</affiliation></author><author><keyname>Veque</keyname><forenames>Veronique</forenames><affiliation>IEF</affiliation></author></authors><title>Un Algorithme de Gestion des Adjacences bas\'e sur la Puissance du
  Signal</title><categories>cs.NI</categories><proxy>ccsd hal-00260330</proxy><acm-class>C.2.1; C.2.2</acm-class><journal-ref>Colloque Francophone sur l'Ing\'enierie des Protocoles (CFIP), Les
  Arcs : France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this proposition, we present a link management technique for pro-active
routing protocols for ad-hoc networks. This new mechanism is based on signal
strength hence cross layer approach is used. The hysteresis mechanism provided
by OLSR is improved upon by using signal strength in combination with the hello
loss based hysteresis. The signal power is used to determine if the
link-quality is improving or deteriorating while packet losses are handled
through the hysteresis mechanism specified in OLSR RFC. This not only makes the
link management more robust but also helps in anticipating link breakages
thereby greatly improving the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0811</identifier>
 <datestamp>2009-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0811</id><created>2008-03-06</created><updated>2009-01-08</updated><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Subspace Pursuit for Compressive Sensing Signal Reconstruction</title><categories>cs.NA cs.IT math.IT</categories><comments>The first version was submitted on Mar. 6th, 2008. The 2nd version
  was updated on Mar. 10th, 2008. The 3rd version was submitted on Jan 8th,
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method for reconstruction of sparse signals with and without
noisy perturbations, termed the subspace pursuit algorithm. The algorithm has
two important characteristics: low computational complexity, comparable to that
of orthogonal matching pursuit techniques when applied to very sparse signals,
and reconstruction accuracy of the same order as that of LP optimization
methods. The presented analysis shows that in the noiseless setting, the
proposed algorithm can exactly reconstruct arbitrary sparse signals provided
that the sensing matrix satisfies the restricted isometry property with a
constant parameter. In the noisy setting and in the case that the signal is not
exactly sparse, it can be shown that the mean squared error of the
reconstruction is upper bounded by constant multiples of the measurement and
signal perturbation energies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0822</identifier>
 <datestamp>2008-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0822</id><created>2008-03-06</created><authors><author><keyname>Biswal</keyname><forenames>Biswajit</forenames></author></authors><title>Website Optimization through Mining User Navigational Pattern</title><categories>cs.IR</categories><comments>10 pages, 6 figures</comments><acm-class>H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the World Wide Web's ubiquity increase and the rapid development of
various online businesses, the complexity of web sites grow. The analysis of
web user's navigational pattern within a web site can provide useful
information for server performance enhancements, restructuring a website and
direct marketing in e-commerce etc. In this paper, an algorithm is proposed for
mining such navigation patterns. The key insight is that users access
information of interest and follow a certain path while navigating a web site.
If they don't find it, they would backtrack and choose among the alternate
paths till they reach the destination. The point they backtrack is the
Intermediate Reference Location. Identifying such Intermediate locations and
destinations out of the pattern will be the main endeavor in the rest of this
report.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0845</identifier>
 <datestamp>2008-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0845</id><created>2008-03-06</created><authors><author><keyname>Evain</keyname><forenames>Laurent</forenames></author></authors><title>Knapsack cryptosystems built on NP-hard instance</title><categories>cs.CR cs.CC cs.DM cs.DS</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct three public key knapsack cryptosystems. Standard knapsack
cryptosystems hide easy instances of the knapsack problem and have been broken.
The systems considered in the article face this problem: They hide a random
(possibly hard) instance of the knapsack problem. We provide both complexity
results (size of the key, time needed to encypher/decypher...) and experimental
results. Security results are given for the second cryptosystem (the fastest
one and the one with the shortest key). Probabilistic polynomial reductions
show that finding the private key is as difficult as factorizing a product of
two primes. We also consider heuristic attacks. First, the density of the
cryptosystem can be chosen arbitrarily close to one, discarding low density
attacks. Finally, we consider explicit heuristic attacks based on the LLL
algorithm and we prove that with respect to these attacks, the public key is as
secure as a random key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0858</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0858</id><created>2008-03-06</created><updated>2010-11-23</updated><authors><author><keyname>Kang</keyname><forenames>Mihyun</forenames></author><author><keyname>Pikhurko</keyname><forenames>Oleg</forenames></author><author><keyname>Ravsky</keyname><forenames>Alexander</forenames></author><author><keyname>Schacht</keyname><forenames>Mathias</forenames></author><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>Untangling planar graphs from a specified vertex position - Hard cases</title><categories>cs.DM cs.CG</categories><comments>18 pages, 4 figures. Lemma 3.3 is corrected, several amendments are
  made throughout the paper</comments><journal-ref>Discrete Applied Mathematics 159:8 (2011) 789-799</journal-ref><doi>10.1016/j.dam.2011.01.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a planar graph $G$, we consider drawings of $G$ in the plane where
edges are represented by straight line segments (which possibly intersect).
Such a drawing is specified by an injective embedding $\pi$ of the vertex set
of $G$ into the plane. We prove that a wheel graph $W_n$ admits a drawing $\pi$
such that, if one wants to eliminate edge crossings by shifting vertices to new
positions in the plane, then at most $(2+o(1))\sqrt n$ of all $n$ vertices can
stay fixed. Moreover, such a drawing $\pi$ exists even if it is presupposed
that the vertices occupy any prescribed set of points in the plane. Similar
questions are discussed for other families of planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0862</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0862</id><created>2008-03-06</created><authors><author><keyname>Martin-Garcia</keyname><forenames>Jose M.</forenames></author></authors><title>xPerm: fast index canonicalization for tensor computer algebra</title><categories>cs.SC gr-qc hep-th</categories><comments>16 pages, 3 figures. Package can be downloaded from
  http://metric.iem.csic.es/Martin-Garcia/xAct/</comments><journal-ref>Comp. Phys. Commun. 179 (2008) 597-603</journal-ref><doi>10.1016/j.cpc.2008.05.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a very fast implementation of the Butler-Portugal algorithm for
index canonicalization with respect to permutation symmetries. It is called
xPerm, and has been written as a combination of a Mathematica package and a C
subroutine. The latter performs the most demanding parts of the computations
and can be linked from any other program or computer algebra system. We
demonstrate with tests and timings the effectively polynomial performance of
the Butler-Portugal algorithm with respect to the number of indices, though we
also show a case in which it is exponential. Our implementation handles generic
tensorial expressions with several dozen indices in hundredths of a second, or
one hundred indices in a few seconds, clearly outperforming all other current
canonicalizers. The code has been already under intensive testing for several
years and has been essential in recent investigations in large-scale tensor
computer algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0874</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0874</id><created>2008-03-06</created><updated>2008-03-14</updated><authors><author><keyname>Batista</keyname><forenames>Milan</forenames></author></authors><title>A Method for Solving Cyclic Block Penta-diagonal Systems of Linear
  Equations</title><categories>cs.MS cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for solving cyclic block three-diagonal systems of equations is
generalized for solving a block cyclic penta-diagonal system of equations.
Introducing a special form of two new variables the original system is split
into three block pentagonal systems, which can be solved by the known methods.
As such method belongs to class of direct methods without pivoting.
Implementation of the algorithm is discussed in some details and the numerical
examples are present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0875</identifier>
 <datestamp>2008-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0875</id><created>2008-03-06</created><authors><author><keyname>Cardoso</keyname><forenames>L. S.</forenames></author><author><keyname>Kobayashi</keyname><forenames>M.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author><author><keyname>Ryan</keyname><forenames>O.</forenames></author></authors><title>Vandermonde Frequency Division Multiplexing for Cognitive Radio</title><categories>cs.IT math.IT</categories><comments>Submitted to Signal Processing Advances in Wireless Communications,
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a cognitive radio scenario where a primary and a secondary user
wish to communicate with their corresponding receivers simultaneously over
frequency selective channels. Under realistic assumptions that the secondary
transmitter has no side information about the primary's message and each
transmitter knows only its local channels, we propose a Vandermonde precoder
that cancels the interference from the secondary user by exploiting the
redundancy of a cyclic prefix. Our numerical examples show that VFDM, with an
appropriate design of the input covariance, enables the secondary user to
achieve a considerable rate while generating zero interference to the primary
user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0924</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0924</id><created>2008-03-06</created><updated>2010-02-18</updated><authors><author><keyname>Kasiviswanathan</keyname><forenames>Shiva Prasad</forenames></author><author><keyname>Lee</keyname><forenames>Homin K.</forenames></author><author><keyname>Nissim</keyname><forenames>Kobbi</forenames></author><author><keyname>Raskhodnikova</keyname><forenames>Sofya</forenames></author><author><keyname>Smith</keyname><forenames>Adam</forenames></author></authors><title>What Can We Learn Privately?</title><categories>cs.LG cs.CC cs.CR cs.DB</categories><comments>35 pages, 2 figures</comments><journal-ref>SIAM Journal of Computing 40(3) (2011) 793-826</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning problems form an important category of computational tasks that
generalizes many of the computations researchers apply to large real-life data
sets. We ask: what concept classes can be learned privately, namely, by an
algorithm whose output does not depend too heavily on any one input or specific
training example? More precisely, we investigate learning algorithms that
satisfy differential privacy, a notion that provides strong confidentiality
guarantees in contexts where aggregate information is released about a database
containing sensitive information about individuals. We demonstrate that,
ignoring computational constraints, it is possible to privately agnostically
learn any concept class using a sample size approximately logarithmic in the
cardinality of the concept class. Therefore, almost anything learnable is
learnable privately: specifically, if a concept class is learnable by a
(non-private) algorithm with polynomial sample complexity and output size, then
it can be learned privately using a polynomial number of samples. We also
present a computationally efficient private PAC learner for the class of parity
functions. Local (or randomized response) algorithms are a practical class of
private algorithms that have received extensive investigation. We provide a
precise characterization of local private learning algorithms. We show that a
concept class is learnable by a local algorithm if and only if it is learnable
in the statistical query (SQ) model. Finally, we present a separation between
the power of interactive and noninteractive local learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0929</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0929</id><created>2008-03-06</created><updated>2009-11-18</updated><authors><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author><author><keyname>Srivastava</keyname><forenames>Nikhil</forenames></author></authors><title>Graph Sparsification by Effective Resistances</title><categories>cs.DS</categories><acm-class>G.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present a nearly-linear time algorithm that produces high-quality
sparsifiers of weighted graphs. Given as input a weighted graph $G=(V,E,w)$ and
a parameter $\epsilon&gt;0$, we produce a weighted subgraph
$H=(V,\tilde{E},\tilde{w})$ of $G$ such that $|\tilde{E}|=O(n\log
n/\epsilon^2)$ and for all vectors $x\in\R^V$ $(1-\epsilon)\sum_{uv\in
E}(x(u)-x(v))^2w_{uv}\le \sum_{uv\in\tilde{E}}(x(u)-x(v))^2\tilde{w}_{uv} \le
(1+\epsilon)\sum_{uv\in E}(x(u)-x(v))^2w_{uv}. (*)$
  This improves upon the sparsifiers constructed by Spielman and Teng, which
had $O(n\log^c n)$ edges for some large constant $c$, and upon those of
Bencz\'ur and Karger, which only satisfied (*) for $x\in\{0,1\}^V$.
  A key ingredient in our algorithm is a subroutine of independent interest: a
nearly-linear time algorithm that builds a data structure from which we can
query the approximate effective resistance between any two vertices in a graph
in $O(\log n)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0952</identifier>
 <datestamp>2008-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0952</id><created>2008-03-06</created><updated>2008-09-20</updated><authors><author><keyname>Chandrasekhar</keyname><forenames>Vikram</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey</forenames></author><author><keyname>Gatherer</keyname><forenames>Alan</forenames></author></authors><title>Femtocell Networks: A Survey</title><categories>cs.NI</categories><comments>IEEE Communications Magazine, vol. 46, no.9, pp. 59-67, Sept. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The surest way to increase the system capacity of a wireless link is by
getting the transmitter and receiver closer to each other, which creates the
dual benefits of higher quality links and more spatial reuse. In a network with
nomadic users, this inevitably involves deploying more infrastructure,
typically in the form of microcells, hotspots, distributed antennas, or relays.
A less expensive alternative is the recent concept of femtocells, also called
home base-stations, which are data access points installed by home users get
better indoor voice and data coverage. In this article, we overview the
technical and business arguments for femtocells, and describe the
state-of-the-art on each front. We also describe the technical challenges
facing femtocell networks, and give some preliminary ideas for how to overcome
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0954</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0954</id><created>2008-03-06</created><authors><author><keyname>Hahsler</keyname><forenames>Michael</forenames></author><author><keyname>Buchta</keyname><forenames>Christian</forenames></author><author><keyname>Hornik</keyname><forenames>Kurt</forenames></author></authors><title>Selective association rule generation</title><categories>cs.DB cs.DS</categories><journal-ref>Computational Statistics, 2007. Online First, Published: 25 July
  2007</journal-ref><doi>10.1007/s00180-007-0062-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mining association rules is a popular and well researched method for
discovering interesting relations between variables in large databases. A
practical problem is that at medium to low support values often a large number
of frequent itemsets and an even larger number of association rules are found
in a database. A widely used approach is to gradually increase minimum support
and minimum confidence or to filter the found rules using increasingly strict
constraints on additional measures of interestingness until the set of rules
found is reduced to a manageable size. In this paper we describe a different
approach which is based on the idea to first define a set of ``interesting''
itemsets (e.g., by a mixture of mining and expert knowledge) and then, in a
second step to selectively generate rules for only these itemsets. The main
advantage of this approach over increasing thresholds or filtering rules is
that the number of rules found is significantly reduced while at the same time
it is not necessary to increase the support and confidence thresholds which
might lead to missing important information in the database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0956</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0956</id><created>2008-03-06</created><updated>2008-04-17</updated><authors><author><keyname>L&#xe9;v&#xea;que</keyname><forenames>Benjamin</forenames><affiliation>LGS</affiliation></author><author><keyname>Maffray</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LGS</affiliation></author><author><keyname>Preissmann</keyname><forenames>Myriam</forenames><affiliation>LGS</affiliation></author></authors><title>Characterizing path graphs by forbidden induced subgraphs</title><categories>cs.DM</categories><proxy>ccsd hal-00261413</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is a path graph if it is the intersection graph of a family of
subpaths of a tree. In 1970, Renz asked for a characterizaton of path graphs by
forbidden induced subgraphs. Here we answer this question by listing all graphs
that are not path graphs and are minimal with this property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0966</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0966</id><created>2008-03-06</created><authors><author><keyname>Hahsler</keyname><forenames>Michael</forenames></author><author><keyname>Hornik</keyname><forenames>Kurt</forenames></author></authors><title>New probabilistic interest measures for association rules</title><categories>cs.DB stat.ML</categories><journal-ref>Intelligent Data Analysis, 11(5):437-455, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mining association rules is an important technique for discovering meaningful
patterns in transaction databases. Many different measures of interestingness
have been proposed for association rules. However, these measures fail to take
the probabilistic properties of the mined data into account. In this paper, we
start with presenting a simple probabilistic framework for transaction data
which can be used to simulate transaction data when no associations are
present. We use such data and a real-world database from a grocery outlet to
explore the behavior of confidence and lift, two popular interest measures used
for rule mining. The results show that confidence is systematically influenced
by the frequency of the items in the left hand side of rules and that lift
performs poorly to filter random noise in transaction data. Based on the
probabilistic framework we develop two new interest measures, hyper-lift and
hyper-confidence, which can be used to filter or order mined association rules.
The new measures show significantly better performance than lift for
applications where spurious rules are problematic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0988</identifier>
 <datestamp>2008-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0988</id><created>2008-03-06</created><updated>2008-04-07</updated><authors><author><keyname>Daitch</keyname><forenames>Samuel I.</forenames></author><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author></authors><title>Faster Approximate Lossy Generalized Flow via Interior Point Algorithms</title><categories>cs.DS cs.NA</categories><comments>v2: bug fixes and some expanded proofs</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present faster approximation algorithms for generalized network flow
problems. A generalized flow is one in which the flow out of an edge differs
from the flow into the edge by a constant factor. We limit ourselves to the
lossy case, when these factors are at most 1.
  Our algorithm uses a standard interior-point algorithm to solve a linear
program formulation of the network flow problem. The system of linear equations
that arises at each step of the interior-point algorithm takes the form of a
symmetric M-matrix. We present an algorithm for solving such systems in nearly
linear time. The algorithm relies on the Spielman-Teng nearly linear time
algorithm for solving linear systems in diagonally-dominant matrices.
  For a graph with m edges, our algorithm obtains an additive epsilon
approximation of the maximum generalized flow and minimum cost generalized flow
in time tildeO(m^(3/2) * log(1/epsilon)). In many parameter ranges, this
improves over previous algorithms by a factor of approximately m^(1/2). We also
obtain a similar improvement for exactly solving the standard min-cost flow
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1025</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1025</id><created>2008-03-07</created><authors><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author></authors><title>Asymptotic Concentration Behaviors of Linear Combinations of Weight
  Distributions on Random Linear Code Ensemble</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asymptotic concentration behaviors of linear combinations of weight
distributions on the random linear code ensemble are presented. Many important
properties of a binary linear code can be expressed as the form of a linear
combination of weight distributions such as number of codewords, undetected
error probability and upper bound on the maximum likelihood error probability.
The key in this analysis is the covariance formula of weight distributions of
the random linear code ensemble, which reveals the second-order statistics of a
linear function of the weight distributions. Based on the covariance formula,
several expressions of the asymptotic concentration rate, which indicate the
speed of convergence to the average, are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1030</identifier>
 <datestamp>2009-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1030</id><created>2008-03-07</created><updated>2009-01-28</updated><authors><author><keyname>Soloveichik</keyname><forenames>David</forenames></author></authors><title>Robust Stochastic Chemical Reaction Networks and Bounded Tau-Leaping</title><categories>cs.CC</categories><comments>Tightened up section 5</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The behavior of some stochastic chemical reaction networks is largely
unaffected by slight inaccuracies in reaction rates. We formalize the
robustness of state probabilities to reaction rate deviations, and describe a
formal connection between robustness and efficiency of simulation. Without
robustness guarantees, stochastic simulation seems to require computational
time proportional to the total number of reaction events. Even if the
concentration (molecular count per volume) stays bounded, the number of
reaction events can be linear in the duration of simulated time and total
molecular count. We show that the behavior of robust systems can be predicted
such that the computational work scales linearly with the duration of simulated
time and concentration, and only polylogarithmically in the total molecular
count. Thus our asymptotic analysis captures the dramatic speedup when
molecular counts are large, and shows that for bounded concentrations the
computation time is essentially invariant with molecular count. Finally, by
noticing that even robust stochastic chemical reaction networks are capable of
embedding complex computational problems, we argue that the linear dependence
on simulated time and concentration is likely optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1087</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1087</id><created>2008-03-07</created><updated>2008-12-02</updated><authors><author><keyname>Vidal</keyname><forenames>Clement</forenames></author></authors><title>The Future of Scientific Simulations: from Artificial Life to Artificial
  Cosmogenesis</title><categories>cs.AI</categories><comments>The text was improved in many respects, and a new figure was added.
  Cite as: Vidal, C. 2008. The Future of Scientific Simulations: from
  Artificial Life to Artificial Cosmogenesis. In Death And Anti-Death, Volume
  6: Thirty Years After Kurt Godel (1906-1978), Ed. Charles Tandy, in press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This philosophical paper explores the relation between modern scientific
simulations and the future of the universe. We argue that a simulation of an
entire universe will result from future scientific activity. This requires us
to tackle the challenge of simulating open-ended evolution at all levels in a
single simulation. The simulation should encompass not only biological
evolution, but also physical evolution (a level below) and cultural evolution
(a level above). The simulation would allow us to probe what would happen if we
would &quot;replay the tape of the universe&quot; with the same or different laws and
initial conditions. We also distinguish between real-world and artificial-world
modelling. Assuming that intelligent life could indeed simulate an entire
universe, this leads to two tentative hypotheses. Some authors have argued that
we may already be in a simulation run by an intelligent entity. Or, if such a
simulation could be made real, this would lead to the production of a new
universe. This last direction is argued with a careful speculative
philosophical approach, emphasizing the imperative to find a solution to the
heat death problem in cosmology. The reader is invited to consult Annex 1 for
an overview of the logical structure of this paper. -- Keywords: far future,
future of science, ALife, simulation, realization, cosmology, heat death,
fine-tuning, physical eschatology, cosmological natural selection, cosmological
artificial selection, artificial cosmogenesis, selfish biocosm hypothesis,
meduso-anthropic principle, developmental singularity hypothesis, role of
intelligent life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1090</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1090</id><created>2008-03-07</created><updated>2009-01-13</updated><authors><author><keyname>Savin</keyname><forenames>Valentin</forenames></author></authors><title>Self-Corrected Min-Sum decoding of LDPC codes</title><categories>cs.IT math.IT</categories><comments>5 pages, ISIT08 second version: acknowledgement footnote added (no
  content modification)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a very simple but powerful self-correction method
for the Min-Sum decoding of LPDC codes. Unlike other correction methods known
in the literature, our method does not try to correct the check node processing
approximation, but it modifies the variable node processing by erasing
unreliable messages. However, this positively affects check node messages,
which become symmetric Gaussian distributed, and we show that this is
sufficient to ensure a quasi-optimal decoding performance. Monte-Carlo
simulations show that the proposed Self-Corrected Min-Sum decoding performs
very close to the Sum-Product decoding, while preserving the main features of
the Min-Sum decoding, that is low complexity and independence with respect to
noise variance estimation errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1094</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1094</id><created>2008-03-07</created><updated>2009-01-13</updated><authors><author><keyname>Savin</keyname><forenames>Valentin</forenames></author></authors><title>Min-Max decoding for non binary LDPC codes</title><categories>cs.IT math.IT</categories><comments>5 pages, ISIT08 version v2: acknowledgement footnote, and appendix
  containing proofs of some statements in the paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative decoding of non-binary LDPC codes is currently performed using
either the Sum-Product or the Min-Sum algorithms or slightly different versions
of them. In this paper, several low-complexity quasi-optimal iterative
algorithms are proposed for decoding non-binary codes. The Min-Max algorithm is
one of them and it has the benefit of two possible LLR domain implementations:
a standard implementation, whose complexity scales as the square of the Galois
field's cardinality and a reduced complexity implementation called selective
implementation, which makes the Min-Max decoding very attractive for practical
purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1096</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1096</id><created>2008-03-07</created><authors><author><keyname>Savin</keyname><forenames>Valentin</forenames></author></authors><title>Algebraic-geometric codes from vector bundles and their decoding</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algebraic-geometric codes can be constructed by evaluating a certain set of
functions on a set of distinct rational points of an algebraic curve. The set
of functions that are evaluated is the linear space of a given divisor or,
equivalently, the set of section of a given line bundle. Using arbitrary rank
vector bundles on algebraic curves, we propose a natural generalization of the
above construction. Our codes can also be seen as interleaved versions of
classical algebraic-geometric codes. We show that the algorithm of Brown,
Minder and Shokrollahi can be extended to this new class of codes and it
corrects any number of errors up to $t^{*} - g/2$, where $t^{*}$ is the
designed correction capacity of the code and $g$ is the curve genus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1104</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1104</id><created>2008-03-07</created><authors><author><keyname>Hahsler</keyname><forenames>Michael</forenames></author></authors><title>Optimizing Web Sites for Customer Retention</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With customer relationship management (CRM) companies move away from a mainly
product-centered view to a customer-centered view. Resulting from this change,
the effective management of how to keep contact with customers throughout
different channels is one of the key success factors in today's business world.
Company Web sites have evolved in many industries into an extremely important
channel through which customers can be attracted and retained. To analyze and
optimize this channel, accurate models of how customers browse through the Web
site and what information within the site they repeatedly view are crucial.
Typically, data mining techniques are used for this purpose. However, there
already exist numerous models developed in marketing research for traditional
channels which could also prove valuable to understanding this new channel. In
this paper we propose the application of an extension of the Logarithmic Series
Distribution (LSD) model repeat-usage of Web-based information and thus to
analyze and optimize a Web Site's capability to support one goal of CRM, to
retain customers. As an example, we use the university's blended learning web
portal with over a thousand learning resources to demonstrate how the model can
be used to evaluate and improve the Web site's effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1110</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1110</id><created>2008-03-07</created><authors><author><keyname>Diatta</keyname><forenames>Daouda Niang</forenames><affiliation>XLIM</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Ruatta</keyname><forenames>Olivier</forenames><affiliation>XLIM</affiliation></author></authors><title>On the Computation of the Topology of a Non-Reduced Implicit Space Curve</title><categories>math.AC cs.CG cs.SC</categories><proxy>ccsd hal-00218271</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm is presented for the computation of the topology of a
non-reduced space curve defined as the intersection of two implicit algebraic
surfaces. It computes a Piecewise Linear Structure (PLS) isotopic to the
original space curve. The algorithm is designed to provide the exact result for
all inputs. It's a symbolic-numeric algorithm based on subresultant
computation. Simple algebraic criteria are given to certify the output of the
algorithm. The algorithm uses only one projection of the non-reduced space
curve augmented with adjacency information around some &quot;particular points&quot; of
the space curve. The algorithm is implemented with the Mathemagix Computer
Algebra System (CAS) using the SYNAPS library as a backend.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1111</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1111</id><created>2008-03-07</created><authors><author><keyname>Mohaisen</keyname><forenames>Abedelaziz</forenames></author><author><keyname>Nyang</keyname><forenames>DaeHun</forenames></author><author><keyname>Lee</keyname><forenames>KyungHee</forenames></author></authors><title>Hierarchical Grid-Based Pairwise Key Pre-distribution in Wireless Sensor
  Networks</title><categories>cs.CR</categories><comments>13 pages, 9 figures, 2 tables, to appear in the International Journal
  of Networks and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The security of wireless sensor networks is an active topic of research where
both symmetric and asymmetric key cryptography issues have been studied. Due to
their computational feasibility on typical sensor nodes, symmetric key
algorithms that use the same key to encrypt and decrypt messages have been
intensively studied and perfectly deployed in such environment. Because of the
wireless sensor's limited infrastructure, the bottleneck challenge for
deploying these algorithms is the key distribution. For the same reason of
resources restriction, key distribution mechanisms which are used in
traditional wireless networks are not efficient for sensor networks.
  To overcome the key distribution problem, several key pre-distribution
algorithms and techniques that assign keys or keying material for the networks
nodes in an offline phase have been introduced recently. In this paper, we
introduce a supplemental distribution technique based on the communication
pattern and deployment knowledge modeling. Our technique is based on the
hierarchical grid deployment. For granting a proportional security level with
number of dependent sensors, we use different polynomials in different orders
with different weights. In seek of our proposed work's value, we provide a
detailed analysis on the used resources, resulting security, resiliency, and
connectivity compared with other related works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1120</identifier>
 <datestamp>2008-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1120</id><created>2008-03-07</created><updated>2008-03-27</updated><authors><author><keyname>Philosof</keyname><forenames>Tal</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author></authors><title>The Rate Loss of Single-Letter Characterization: The &quot;Dirty&quot; Multiple
  Access Channel</title><categories>cs.IT math.IT</categories><comments>23 pages, 5 figures</comments><acm-class>F.2.2; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For general memoryless systems, the typical information theoretic solution -
when exists - has a &quot;single-letter&quot; form. This reflects the fact that optimum
performance can be approached by a random code (or a random binning scheme),
generated using independent and identically distributed copies of some
single-letter distribution. Is that the form of the solution of any
(information theoretic) problem? In fact, some counter examples are known. The
most famous is the &quot;two help one&quot; problem: Korner and Marton showed that if we
want to decode the modulo-two sum of two binary sources from their independent
encodings, then linear coding is better than random coding. In this paper we
provide another counter example, the &quot;doubly-dirty&quot; multiple access channel
(MAC). Like the Korner-Marton problem, this is a multi-terminal scenario where
side information is distributed among several terminals; each transmitter knows
part of the channel interference but the receiver is not aware of any part of
it. We give an explicit solution for the capacity region of a binary version of
the doubly-dirty MAC, demonstrate how the capacity region can be approached
using a linear coding scheme, and prove that the &quot;best known single-letter
region&quot; is strictly contained in it. We also state a conjecture regarding a
similar rate loss of single letter characterization in the Gaussian case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1144</identifier>
 <datestamp>2008-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1144</id><created>2008-03-07</created><authors><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>Zarifi</keyname><forenames>Keyvan</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Asymptotic Capacity and Optimal Precoding Strategy of Multi-Level
  Precode &amp; Forward in Correlated Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, to be published in proceedings of IEEE
  Information Theory Workshop 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze a multi-level MIMO relaying system where a multiple-antenna
transmitter sends data to a multipleantenna receiver through several relay
levels, also equipped with multiple antennas. Assuming correlated fading in
each hop, each relay receives a faded version of the signal transmitted by the
previous level, performs precoding on the received signal and retransmits it to
the next level. Using free probability theory and assuming that the noise power
at the relay levels - but not at the receiver - is negligible, a closed-form
expression of the end-to-end asymptotic instantaneous mutual information is
derived as the number of antennas in all levels grow large with the same rate.
This asymptotic expression is shown to be independent from the channel
realizations, to only depend on the channel statistics and to also serve as the
asymptotic value of the end-to-end average mutual information. We also provide
the optimal singular vectors of the precoding matrices that maximize the
asymptotic mutual information : the optimal transmit directions represented by
the singular vectors of the precoding matrices are aligned on the eigenvectors
of the channel correlation matrices, therefore they can be determined only
using the known statistics of the channel matrices and do not depend on a
particular channel realization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1189</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1189</id><created>2008-03-07</created><updated>2008-04-04</updated><authors><author><keyname>Currie</keyname><forenames>James D.</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>Infinite words containing squares at every position</title><categories>math.CO cs.FL</categories><comments>12 pages; minor revisions and clarifications</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Richomme asked the following question: what is the infimum of the real
numbers $\alpha$ &gt; 2 such that there exists an infinite word that avoids
$\alpha$-powers but contains arbitrarily large squares beginning at every
position? We resolve this question in the case of a binary alphabet by showing
that the answer is $\alpha$ = 7/3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1195</identifier>
 <datestamp>2008-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1195</id><created>2008-03-07</created><authors><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Secure Lossless Compression with Side Information</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the 2008 IEEE Information Theory
  Workshop, Porto, Portugal, May 5-9, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure data compression in the presence of side information at both a
legitimate receiver and an eavesdropper is explored. A noise-free, limited rate
link between the source and the receiver, whose output can be perfectly
observed by the eavesdropper, is assumed. As opposed to the wiretap channel
model, in which secure communication can be established by exploiting the noise
in the channel, here the existence of side information at the receiver is used.
Both coded and uncoded side information are considered. In the coded side
information scenario, inner and outer bounds on the compression-equivocation
rate region are given. In the uncoded side information scenario, the
availability of the legitimate receiver's and the eavesdropper's side
information at the encoder is considered, and the compression-equivocation rate
region is characterized for these cases. It is shown that the side information
at the encoder can increase the equivocation rate at the eavesdropper. Hence,
the side information at the encoder is shown to be useful in terms of security;
this is in contrast with the pure lossless data compression case where side
information at the encoder would not help.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1207</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1207</id><created>2008-03-07</created><updated>2010-09-28</updated><authors><author><keyname>Dinh</keyname><forenames>Hang</forenames></author></authors><title>Serious Flaws in Korf et al.'s Analysis on Time Complexity of A*</title><categories>cs.AI</categories><comments>This paper has been withdrawn</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1217</identifier>
 <datestamp>2008-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1217</id><created>2008-03-08</created><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author></authors><title>Hsiao-Code Check Matrices and Recursively Balanced Matrices</title><categories>cs.DM</categories><comments>8 pages</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key step of generating the well-known Hsiao code is to construct a
{0,1}-check-matrix in which each column contains the same odd-number of 1's and
each row contains the same number of 1's or differs at most by one for the
number of 1's. We also require that no two columns are identical in the matrix.
The author solved this problem in 1986 by introducing a type of recursively
balanced matrices. However, since the paper was published in Chinese, the
solution for such an important problem was not known by international
researchers in coding theory. In this note, we focus on how to practically
generate the check matrix of Hsiao codes. We have modified the original
algorithm to be more efficient and effective. We have also corrected an error
in algorithm analysis presented in the earlier paper. The result shows that the
algorithm attained optimum in average cases if a divide-and-conquer technique
must be involved in the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1220</identifier>
 <datestamp>2008-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1220</id><created>2008-03-08</created><authors><author><keyname>Sanadhya</keyname><forenames>Somitra Kumar</forenames></author><author><keyname>Sarkar</keyname><forenames>Palash</forenames></author></authors><title>22-Step Collisions for SHA-2</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we provide the first 22-step collisions for SHA-256 and
SHA-512. Detailed technique of generating these collisions will be provided in
the next revision of this note.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1221</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1221</id><created>2008-03-08</created><authors><author><keyname>Zein</keyname><forenames>Mazen</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Non-Singular Assembly-mode Changing Motions for 3-RPR Parallel
  Manipulators</title><categories>cs.RO physics.class-ph</categories><proxy>ccsd hal-00261669</proxy><journal-ref>Mechanism and Machine Theory 23, 4 (2008) 480-490</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When moving from one arbitrary location at another, a parallel manipulator
may change its assembly-mode without crossing a singularity. Because the
non-singular change of assembly-mode cannot be simply detected, the actual
assembly-mode during motion is difficult to track. This paper proposes a global
explanatory approach to help better understand non-singular assembly-mode
changing motions for 3-RPR planar parallel manipulators. The approach consists
in fixing one of the actuated joints and analyzing the configuration-space as a
surface in a 3-dimensional space. Such a global description makes it possible
to display all possible non-singular assembly-mode changing trajectories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1227</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1227</id><created>2008-03-08</created><authors><author><keyname>Creignou</keyname><forenames>Jean</forenames><affiliation>IMB</affiliation></author><author><keyname>Diet</keyname><forenames>Herv&#xe9;</forenames><affiliation>IMB</affiliation></author></authors><title>Linear programming bounds for unitary space time codes</title><categories>cs.IT math.IT</categories><comments>Submitted to ISIT 2008 4 figures</comments><proxy>ccsd hal-00261674</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear programming method is applied to the space $\U_n(\C)$ of unitary
matrices in order to obtain bounds for codes relative to the diversity sum and
the diversity product. Theoretical and numerical results improving previously
known bounds are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1245</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1245</id><created>2008-03-08</created><updated>2009-01-13</updated><authors><author><keyname>Bell</keyname><forenames>George I.</forenames></author></authors><title>The shortest game of Chinese Checkers and related problems</title><categories>math.CO cs.DM cs.DS</categories><comments>22 pages, 10 figures; published version</comments><msc-class>00A08, 97A20</msc-class><journal-ref>INTEGERS: Electronic Journal of Combinatorial Number Theory 9
  (2009) #G01</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1979, David Fabian found a complete game of two-person Chinese Checkers in
30 moves (15 by each player) [Martin Gardner, Penrose Tiles to Trapdoor
Ciphers, MAA, 1997]. This solution requires that the two players cooperate to
generate a win as quickly as possible for one of them. We show, using
computational search techniques, that no shorter game is possible. We also
consider a solitaire version of Chinese Checkers where one player attempts to
move her pieces across the board in as few moves as possible. In 1971, Octave
Levenspiel found a solution in 27 moves [Ibid.]; we demonstrate that no shorter
solution exists. To show optimality, we employ a variant of A* search, as well
as bidirectional search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1296</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1296</id><created>2008-03-09</created><authors><author><keyname>Oudot</keyname><forenames>Steve Y.</forenames></author></authors><title>On the Topology of the Restricted Delaunay Triangulation and Witness
  Complex in Higher Dimensions</title><categories>cs.CG</categories><proxy>ccsd inria-00260861</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a well-known fact that, under mild sampling conditions, the restricted
Delaunay triangulation provides good topological approximations of 1- and
2-manifolds. We show that this is not the case for higher-dimensional
manifolds, even under stronger sampling conditions. Specifically, it is not
true that, for any compact closed submanifold M of R^n, and any sufficiently
dense uniform sampling L of M, the Delaunay triangulation of L restricted to M
is homeomorphic to M, or even homotopy equivalent to it. Besides, it is not
true either that, for any sufficiently dense set W of witnesses, the witness
complex of L relative to M contains or is contained in the restricted Delaunay
triangulation of L.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1321</identifier>
 <datestamp>2008-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1321</id><created>2008-03-09</created><updated>2008-05-05</updated><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>Treewidth computation and extremal combinatorics</title><categories>cs.DS</categories><comments>Corrected typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a given graph G and integers b,f &gt;= 0, let S be a subset of vertices of G
of size b+1 such that the subgraph of G induced by S is connected and S can be
separated from other vertices of G by removing f vertices. We prove that every
graph on n vertices contains at most n\binom{b+f}{b} such vertex subsets. This
result from extremal combinatorics appears to be very useful in the design of
several enumeration and exact algorithms. In particular, we use it to provide
algorithms that for a given n-vertex graph G - compute the treewidth of G in
time O(1.7549^n) by making use of exponential space and in time O(2.6151^n) and
polynomial space; - decide in time O(({\frac{2n+k+1}{3})^{k+1}\cdot kn^6}) if
the treewidth of G is at most k; - list all minimal separators of G in time
O(1.6181^n) and all potential maximal cliques of G in time O(1.7549^n). This
significantly improves previous algorithms for these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1323</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1323</id><created>2008-03-09</created><updated>2008-06-23</updated><authors><author><keyname>Perlaza</keyname><forenames>Samir Medina</forenames></author><author><keyname>Cottatellucci</keyname><forenames>Laura</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>A Game Theoretic Framework for Decentralized Power Allocation in IDMA
  Systems</title><categories>cs.IT cs.GT math.IT</categories><comments>To appear in IEEE International Symposium on Personal, Indoor and
  Mobile Radio Communications (PIMRC 2008)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution we present a decentralized power allocation algorithm
for the uplink interleave division multiple access (IDMA) channel. Within the
proposed optimal strategy for power allocation, each user aims at selfishly
maximizing its own utility function. An iterative chip by chip (CBC) decoder at
the receiver and a rational selfish behavior of all the users according to a
classical game-theoretical framework are the underlying assumptions of this
work. This approach leads to a power allocation based on a channel inversion
policy where the optimal power level is set locally at each terminal based on
the knowledge of its own channel realization, the noise level at the receiver
and the number of active users in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1360</identifier>
 <datestamp>2008-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1360</id><created>2008-03-10</created><authors><author><keyname>Kutz</keyname><forenames>Nadja</forenames></author></authors><title>On the need for a global academic internet platform</title><categories>cs.CY</categories><comments>22 pages, no figures</comments><acm-class>K.4.1; K.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article collects arguments for the necessity of a global academic
internet platform, which is organized as a kind of ``global scientific
parliament''. With such a constitution educational and research institutions
will have direct means for communicating scientific results, as well as a
platform for representing academia and scientific life in the public.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1393</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1393</id><created>2008-03-10</created><authors><author><keyname>Kwa&#x15b;niewski</keyname><forenames>A. Krzysztof</forenames></author><author><keyname>Krot-Sieniawska</keyname><forenames>Ewa</forenames></author></authors><title>On inversion formulas and Fibonomial coefficients</title><categories>math.CO cs.DM math.GM</categories><comments>4 pages, presented at the Gian-Carlo Rota Polish Seminar,
  http://ii.uwb.edu.pl/akk/sem/sem_rota.htm, submitted to FECS'08: The 2008
  International Conference on Frontiers in Education: WORLDCOMP'08</comments><msc-class>05A19, 11B39, 15A09</msc-class><journal-ref>Proc. Jangjeon Math. Soc. volume 11 (1), 2008 (June),65-68</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A research problem for undergraduates and graduates is being posed as a cap
for the prior antecedent regular discrete mathematics exercises. [Here cap is
not necessarily CAP=Competitive Access Provider, though nevertheless ...] The
object of the cap problem of final interest i.e. array of fibonomial
coefficients and the issue of its combinatorial meaning is to be found in
A.K.Kwa\'sniewski's source papers. The cap problem number seven - still opened
for students has been placed on Mathemagics page of the first author
[http://ii.uwb.edu.pl/akk/dydaktyka/dyskr/dyskretna.htm]. The indicatory
references are to point at a part of the vast domain of the foundations of
computer science in ArXiv affiliation noted as CO.cs.DM. The presentation has
been verified in a tutor system of communication with a couple of intelligent
students. The result is top secret.Temporarily. [Contact: Wikipedia; Theory of
cognitive development].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1416</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1416</id><created>2008-03-10</created><updated>2009-01-19</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>New formulas for Stirling-like numbers and Dobinski-like formulas</title><categories>math.CO cs.DM</categories><comments>9 pages, presented at the Gian-Carlo Rota Polish Seminar,
  http://ii.uwb.edu.pl/akk/sem/sem_rota.htm</comments><msc-class>05A40, 11B73, 81S99</msc-class><journal-ref>Proc. Jangjeon Math. Soc. Vol. 11 No 2, (2008),137-144</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extensions of the $Stirling$ numbers of the second kind and $Dobinski$ -like
formulas are proposed in a series of exercises for graduates. Some of these new
formulas recently discovered by me are to be found in the source paper $ [1]$.
These extensions naturally encompass the well known $q$- extensions. The
indicatory references are to point at a part of the vast domain of the
foundations of computer science in arxiv affiliation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1443</identifier>
 <datestamp>2009-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1443</id><created>2008-03-10</created><updated>2009-12-31</updated><authors><author><keyname>Shour</keyname><forenames>Robert</forenames></author></authors><title>Lexical growth, entropy and the benefits of networking</title><categories>cs.IT math.IT q-bio.QM</categories><comments>About 27 pages, double spaced; v3 changes remarks on zeroth
  generation in proposition 8, and makes some minor changes to wording and
  spelling; v4 is intended to correct remarks relating to glottochronology</comments><acm-class>E.4; H.1.1; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If each node of an idealized network has an equal capacity to efficiently
exchange benefits, then the network's capacity to use energy is scaled by the
average amount of energy required to connect any two of its nodes. The scaling
factor equals \textit{e}, and the network's entropy is $\ln(n)$. Networking
emerges in consequence of nodes minimizing the ratio of their energy use to the
benefits obtained for such use, and their connectability. Networking leads to
nested hierarchical clustering, which multiplies a network's capacity to use
its energy to benefit its nodes. Network entropy multiplies a node's capacity.
For a real network in which the nodes have the capacity to exchange benefits,
network entropy may be estimated as $C \log_L(n)$, where the base of the log is
the path length $L$, and $C$ is the clustering coefficient. Since $n$, $L$ and
$C$ can be calculated for real networks, network entropy for real networks can
be calculated and can reveal aspects of emergence and also of economic,
biological, conceptual and other networks, such as the relationship between
rates of lexical growth and divergence, and the economic benefit of adding
customers to a commercial communications network. \textit{Entropy dating} can
help estimate the age of network processes, such as the growth of hierarchical
society and of language.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="2000" completeListSize="102538">1122234|3001</resumptionToken>
</ListRecords>
</OAI-PMH>
