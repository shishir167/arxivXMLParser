<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:37:55Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|4001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1806</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1806</id><created>2008-06-11</created><authors><author><keyname>Schulte</keyname><forenames>Christian</forenames></author><author><keyname>Tack</keyname><forenames>Guido</forenames></author></authors><title>Perfect Derived Propagators</title><categories>cs.AI</categories><comments>17 pages, 2 tables</comments><acm-class>D.3.2; D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When implementing a propagator for a constraint, one must decide about
variants: When implementing min, should one also implement max? Should one
implement linear equations both with and without coefficients? Constraint
variants are ubiquitous: implementing them requires considerable (if not
prohibitive) effort and decreases maintainability, but will deliver better
performance.
  This paper shows how to use variable views, previously introduced for an
implementation architecture, to derive perfect propagator variants. A model for
views and derived propagators is introduced. Derived propagators are proved to
be indeed perfect in that they inherit essential properties such as correctness
and domain and bounds consistency. Techniques for systematically deriving
propagators such as transformation, generalization, specialization, and
channeling are developed for several variable domains. We evaluate the massive
impact of derived propagators. Without derived propagators, Gecode would
require 140000 rather than 40000 lines of code for propagators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1812</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1812</id><created>2008-06-11</created><authors><author><keyname>Liagkou</keyname><forenames>V.</forenames></author><author><keyname>Makri</keyname><forenames>E.</forenames></author><author><keyname>Spirakis</keyname><forenames>P.</forenames></author><author><keyname>Stamatiou</keyname><forenames>Y. C.</forenames></author></authors><title>A probabilistic key agreement scheme for sensor networks without key
  predistribution</title><categories>cs.CR</categories><comments>14 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic establishment of shared information (e.g. secret key) between two
entities is particularly important in networks with no pre-determined structure
such as wireless sensor networks (and in general wireless mobile ad-hoc
networks). In such networks, nodes establish and terminate communication
sessions dynamically with other nodes which may have never been encountered
before, in order to somehow exchange information which will enable them to
subsequently communicate in a secure manner. In this paper we give and
theoretically analyze a series of protocols that enables two entities that have
never encountered each other before to establish a shared piece of information
for use as a key in setting up a secure communication session with the aid of a
shared key encryption algorithm. These protocols do not require previous
pre-distribution of candidate keys or some other piece of information of
specialized form except a small seed value, from which the two entities can
produce arbitrarily long strings with many similarities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1816</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1816</id><created>2008-06-11</created><authors><author><keyname>Mrissa</keyname><forenames>M.</forenames></author><author><keyname>Thiran</keyname><forenames>Ph.</forenames></author><author><keyname>Jacquet</keyname><forenames>J-M.</forenames></author><author><keyname>Benslimane</keyname><forenames>D.</forenames></author><author><keyname>Maamar</keyname><forenames>Z.</forenames></author></authors><title>Cardinality heterogeneities in Web service composition: Issues and
  solutions</title><categories>cs.SE cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data exchanges between Web services engaged in a composition raise several
heterogeneities. In this paper, we address the problem of data cardinality
heterogeneity in a composition. Firstly, we build a theoretical framework to
describe different aspects of Web services that relate to data cardinality, and
secondly, we solve this problem by developing a solution for cardinality
mediation based on constraint logic programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1819</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1819</id><created>2008-06-11</created><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Low-Complexity, Full-Rate, Full-Diversity 2 X 2 STBC with Golden
  Code's Coding Gain</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Globecom - 2008. 6 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a low-ML-decoding-complexity, full-rate, full-diversity
space-time block code (STBC) for a 2 transmit antenna, 2 receive antenna
multiple-input multiple-output (MIMO) system, with coding gain equal to that of
the best and well known Golden code for any QAM constellation. Recently, two
codes have been proposed (by Paredes, Gershman and Alkhansari and by Sezginer
and Sari), which enjoy a lower decoding complexity relative to the Golden code,
but have lesser coding gain. The $2\times 2$ STBC presented in this paper has
lesser decoding complexity for non-square QAM constellations, compared with
that of the Golden code, while having the same decoding complexity for square
QAM constellations. Compared with the Paredes-Gershman-Alkhansari and
Sezginer-Sari codes, the proposed code has the same decoding complexity for
non-rectangular QAM constellations. Simulation results, which compare the
codeword error rate (CER) performance, are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1827</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1827</id><created>2008-06-11</created><authors><author><keyname>M&#xfc;ller</keyname><forenames>Fritz</forenames></author></authors><title>Full Abstraction for a Recursively Typed Lambda Calculus with Parallel
  Conditional</title><categories>cs.LO</categories><comments>54 pages</comments><report-no>revised Report 12/1993 of SFB 124, Informatik, Universitaet des
  Saarlandes</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the syntax and reduction relation of a recursively typed lambda
calculus with a parallel case-function (a parallel conditional). The reduction
is shown to be confluent. We interpret the recursive types as information
systems in a restricted form, which we call prime systems. A denotational
semantics is defined with this interpretation. We define the syntactical normal
form approximations of a term and prove the Approximation Theorem: The
semantics of a term equals the limit of the semantics of its approximations.
The proof uses inclusive predicates (logical relations). The semantics is
adequate with respect to the observation of Boolean values. It is also fully
abstract in the presence of the parallel case-function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1834</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1834</id><created>2008-06-11</created><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Low-decoding-complexity, Large coding Gain, Full-rate, Full-diversity
  STBC for 4 X 2 MIMO System</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a low decoding complexity, full-diversity and full-rate
space-time block code (STBC) for 4 transmit and 2 receive ($4\times 2$)
multiple-input multiple-output (MIMO) systems. For such systems, the best code
known is the DjABBA code and recently, Biglieri, Hong and Viterbo have proposed
another STBC (BHV code) which has lower decoding complexity than DjABBA but
does not have full-diversity like the DjABBA code. The code proposed in this
paper has the same decoding complexity as the BHV code for square QAM
constellations but has full-diversity as well. Compared to the best code in the
DjABBA family of codes, our code has lower decoding complexity, a better coding
gain and hence a better error performance as well. Simulation results
confirming these are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1843</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1843</id><created>2008-06-11</created><authors><author><keyname>Zhang</keyname><forenames>Huan</forenames></author><author><keyname>Liu</keyname><forenames>Zonghua</forenames></author><author><keyname>Tang</keyname><forenames>Ming</forenames></author><author><keyname>Hui</keyname><forenames>P. M.</forenames></author></authors><title>An adaptive routing strategy for packet delivery in complex networks</title><categories>cs.NI</categories><comments>6 pages, 4 figures</comments><doi>10.1016/j.physleta.2006.12.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient routing approach for delivering packets in complex
networks. On delivering a message from a node to a destination, a node forwards
the message to a neighbor by estimating the waiting time along the shortest
path from each of its neighbors to the destination. This projected waiting time
is dynamical in nature and the path through which a message is delivered would
be adapted to the distribution of messages in the network. Implementing the
approach on scale-free networks, we show that the present approach performs
better than the shortest-path approach and another approach that takes into
account of the waiting time only at the neighboring nodes. Key features in
numerical results are explained by a mean field theory. The approach has the
merit that messages are distributed among the nodes according to the
capabilities of the nodes in handling messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1845</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1845</id><created>2008-06-11</created><authors><author><keyname>Liua</keyname><forenames>Zonghua</forenames></author><author><keyname>Ma</keyname><forenames>Weichuan</forenames></author><author><keyname>Zhang</keyname><forenames>Huan</forenames></author><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Hui</keyname><forenames>P. M.</forenames></author></authors><title>An efficient approach of controlling traffic congestion in scale-free
  networks</title><categories>cs.NI</categories><comments>7 pages, 5 figures</comments><doi>10.1016/j.physa.2006.02.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and study a model of traffic in communication networks. The
underlying network has a structure that is tunable between a scale-free growing
network with preferential attachments and a random growing network. To model
realistic situations where different nodes in a network may have different
capabilities, the message or packet creation and delivering rates at a node are
assumed to depend on the degree of the node. Noting that congestions are more
likely to take place at the nodes with high degrees in networks with scale-free
character, an efficient approach of selectively enhancing the
message-processing capability of a small fraction (e.g. 3%) of the nodes is
shown to perform just as good as enhancing the capability of all nodes. The
interplay between the creation rate and the delivering rate in determining
non-congested or congested traffic in a network is studied more numerically and
analytically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1846</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1846</id><created>2008-06-11</created><authors><author><keyname>Zhu</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Liu</keyname><forenames>Zonghua</forenames></author><author><keyname>Tang</keyname><forenames>Ming</forenames></author></authors><title>Detrended fluctuation analysis of traffic data</title><categories>cs.NI</categories><comments>4 pages, 4 figures</comments><journal-ref>CPL 24,7(2007)2142</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different routing strategies may result in different behaviors of traffic on
internet. We analyze the correlation of traffic data for three typical routing
strategies by the detrended fluctuation analysis (DFA) and find that the degree
of correlation of the data can be divided into three regions, i.e., weak,
medium, and strong correlation. The DFA scalings are constants in both the
regions of weak and strong correlation but monotonously increase in the region
of medium correlation. We suggest that it is better to consider the traffic on
complex network as three phases, i.e., the free, buffer, and congestion phase,
than just as two phases believed before, i.e., the free and congestion phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1893</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1893</id><created>2008-06-11</created><authors><author><keyname>Chebira</keyname><forenames>Sabri</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Mercier</keyname><forenames>Gilles</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Francomme</keyname><forenames>Jackson</forenames><affiliation>LATTIS</affiliation></author></authors><title>D\'efinition d'une structure adaptative de r\'eseau local sans fil \`a
  consommation optimis\'ee</title><categories>cs.NI</categories><proxy>ccsd hal-00287105</proxy><journal-ref>3\`eme Conf\'erence internationale Sciences \'Electroniques,
  Technologies de l'Information et des T\'el\'ecommunications, Sousse : Tunisie
  (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The strong growth of low rate wireless personal area networks (LR-WPAN),
leads us to consider the autonomy problems, thus node lifetime in a network,
knowing that the power supplies replacement is often difficult to realize. The
inherent mobility in this type of equipment is an essential element. It will
provide routing constraints, so a complex problem to solve. This article
provides work lines to assess the performance of such a network in terms of
energy consumption and mobility. The objectives are contradictory; it will
necessarily find a compromise. In addition, if we want to guarantee a maximum
delay for the transmitted messages, possibility offered by the IEEE 802.15-4
standard, another compromise necessitate a strictly fixed structure and a fully
mobile structure. Therefore, we present a quantization of the energy cost
related to the desired data rate and compared to the sleep duration of nodes in
the network. Then, we open reflexion lines to find the best compromise:
consumption / mobility / guaranteed deadlines, in suggesting an adaptive
network structure from a concept of MANET.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1895</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1895</id><created>2008-06-11</created><authors><author><keyname>Francomme</keyname><forenames>Jackson</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Mercier</keyname><forenames>Gilles</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Chebira</keyname><forenames>Sabri</forenames></author></authors><title>\'Evaluation d'une application de transmission d'images m\'edicales avec
  un r\'eseau sans fil</title><categories>cs.NI</categories><comments>12 pages</comments><proxy>ccsd hal-00287104</proxy><journal-ref>3\`eme Conf\'erence internationale Sciences \'Electroniques,
  Technologies de l'Information et des T\'el\'ecommunications, Sousse : Tunisie
  (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We offer a platform for database consultations and/or biomedical images
exchanges, adapted to the low rate wireless transmission, and intended for
general practitioners or specialists. The goal can be preventive, diagnostic
and therapeutic. it Concerns specialties such as radiology, ultrasound, the
anatomical pathology or endoscopy. The main features required in such a context
are to adjust the data compression of both the specific needs of telemedicine
and limited capabilities of wireless communication networks. We present our
approach in which we have set out criteria on Biomedical images quality,
compressed by the wavelet method to retain all the necessary information for an
accurate diagnosis, and determined the characteristics of a wireless network
with minimal performances for the transmission of these images within
constraints related to the modality and the data flow, in this case Wifi based
on the IEEE 802.11 standard. Our results will assess the capacity of this
standard in terms of speed, to transmit images at a rate of 10 frames per
second. It will be necessary to quantify the amount of information to add to
the image datas to enable a transmission in good conditions and the appropriate
modus operandi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1918</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1918</id><created>2008-06-11</created><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author></authors><title>Analysis of Social Voting Patterns on Digg</title><categories>cs.CY cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The social Web is transforming the way information is created and
distributed. Blog authoring tools enable users to publish content, while sites
such as Digg and Del.icio.us are used to distribute content to a wider
audience. With content fast becoming a commodity, interest in using social
networks to promote and find content has grown, both on the side of content
producers (viral marketing) and consumers (recommendation). Here we study the
role of social networks in promoting content on Digg, a social news aggregator
that allows users to submit links to and vote on news stories. Digg's goal is
to feature the most interesting stories on its front page, and it aggregates
opinions of its many users to identify them. Like other social networking
sites, Digg allows users to designate other users as ``friends'' and see what
stories they found interesting. We studied the spread of interest in news
stories submitted to Digg in June 2006. Our results suggest that pattern of the
spread of interest in a story on the network is indicative of how popular the
story will become. Stories that spread mainly outside of the submitter's
neighborhood go on to be very popular, while stories that spread mainly through
submitter's social neighborhood prove not to be very popular. This effect is
visible already in the early stages of voting, and one can make a prediction
about the potential audience of a story simply by analyzing where the initial
votes come from.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1919</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1919</id><created>2008-06-11</created><authors><author><keyname>Lubetzky</keyname><forenames>Eyal</forenames></author><author><keyname>Stav</keyname><forenames>Uri</forenames></author></authors><title>Non-linear index coding outperforming the linear optimum</title><categories>cs.IT math.IT</categories><comments>16 pages; Preliminary version appeared in FOCS 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following source coding problem was introduced by Birk and Kol: a sender
holds a word $x\in\{0,1\}^n$, and wishes to broadcast a codeword to $n$
receivers, $R_1,...,R_n$. The receiver $R_i$ is interested in $x_i$, and has
prior \emph{side information} comprising some subset of the $n$ bits. This
corresponds to a directed graph $G$ on $n$ vertices, where $i j$ is an edge iff
$R_i$ knows the bit $x_j$. An \emph{index code} for $G$ is an encoding scheme
which enables each $R_i$ to always reconstruct $x_i$, given his side
information. The minimal word length of an index code was studied by
Bar-Yossef, Birk, Jayram and Kol (FOCS 2006). They introduced a graph
parameter, $\minrk_2(G)$, which completely characterizes the length of an
optimal \emph{linear} index code for $G$. The authors of BBJK showed that in
various cases linear codes attain the optimal word length, and conjectured that
linear index coding is in fact \emph{always} optimal.
  In this work, we disprove the main conjecture of BBJK in the following strong
sense: for any $\epsilon &gt; 0$ and sufficiently large $n$, there is an
$n$-vertex graph $G$ so that every linear index code for $G$ requires codewords
of length at least $n^{1-\epsilon}$, and yet a non-linear index code for $G$
has a word length of $n^\epsilon$. This is achieved by an explicit
construction, which extends Alon's variant of the celebrated Ramsey
construction of Frankl and Wilson.
  In addition, we study optimal index codes in various, less restricted,
natural models, and prove several related properties of the graph parameter
$\minrk(G)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1931</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1931</id><created>2008-06-11</created><authors><author><keyname>Broadbent</keyname><forenames>Anne</forenames></author><author><keyname>Tapp</keyname><forenames>Alain</forenames></author></authors><title>Information-Theoretically Secure Voting Without an Honest Majority</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present three voting protocols with unconditional privacy and
information-theoretic correctness, without assuming any bound on the number of
corrupt voters or voting authorities. All protocols have polynomial complexity
and require private channels and a simultaneous broadcast channel. Our first
protocol is a basic voting scheme which allows voters to interact in order to
compute the tally. Privacy of the ballot is unconditional, but any voter can
cause the protocol to fail, in which case information about the tally may
nevertheless transpire. Our second protocol introduces voting authorities which
allow the implementation of the first protocol, while reducing the interaction
and limiting it to be only between voters and authorities and among the
authorities themselves. The simultaneous broadcast is also limited to the
authorities. As long as a single authority is honest, the privacy is
unconditional, however, a single corrupt authority or a single corrupt voter
can cause the protocol to fail. Our final protocol provides a safeguard against
corrupt voters by enabling a verification technique to allow the authorities to
revoke incorrect votes. We also discuss the implementation of a simultaneous
broadcast channel with the use of temporary computational assumptions, yielding
versions of our protocols achieving everlasting security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1945</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1945</id><created>2008-06-11</created><authors><author><keyname>Sanudo</keyname><forenames>Jaime</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author></authors><title>Complexity in atoms: an approach with a new analytical density</title><categories>nlin.CD cs.IT math.IT physics.atom-ph quant-ph</categories><comments>24 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the calculation of complexity on atomic systems is considered.
In order to unveil the increasing of this statistical magnitude with the atomic
number due to the relativistic effects, recently reported in [A. Borgoo, F. De
Proft, P. Geerlings, K.D. Sen, Chem. Phys. Lett., 444 (2007) 186], a new
analytical density to describe neutral atoms is proposed. This density is
inspired in the Tietz potential model. The parameters of this density are
determined from the normalization condition and from a variational calculation
of the energy, which is a functional of the density. The density is
non-singular at the origin and its specific form is selected so as to fit the
results coming from non-relativistic Hartree-Fock calculations. The main
ingredients of the energy functional are the non-relativistic kinetic energy,
the nuclear-electron attraction energy and the classical term of the electron
repulsion. The relativistic correction to the kinetic energy and the Weizsacker
term are also taken into account. The Dirac and the correlation terms are shown
to be less important than the other terms and they have been discarded in this
study. When the statistical measure of complexity is calculated in position
space with the analytical density derived from this model, the increasing trend
of this magnitude as the atomic number increases is also found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1948</identifier>
 <datestamp>2008-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1948</id><created>2008-06-11</created><authors><author><keyname>Chung</keyname><forenames>Kai-Min</forenames></author><author><keyname>Vadhan</keyname><forenames>Salil</forenames></author></authors><title>Tight Bounds for Hashing Block Sources</title><categories>cs.DS</categories><comments>An extended abstract of this paper will appear in RANDOM08</comments><acm-class>E.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that if a 2-universal hash function $H$ is applied to elements of
a {\em block source} $(X_1,...,X_T)$, where each item $X_i$ has enough
min-entropy conditioned on the previous items, then the output distribution
$(H,H(X_1),...,H(X_T))$ will be ``close'' to the uniform distribution. We
provide improved bounds on how much min-entropy per item is required for this
to hold, both when we ask that the output be close to uniform in statistical
distance and when we only ask that it be statistically close to a distribution
with small collision probability. In both cases, we reduce the dependence of
the min-entropy on the number $T$ of items from $2\log T$ in previous work to
$\log T$, which we show to be optimal. This leads to corresponding improvements
to the recent results of Mitzenmacher and Vadhan (SODA `08) on the analysis of
hashing-based algorithms and data structures when the data items come from a
block source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1978</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1978</id><created>2008-06-12</created><updated>2008-12-08</updated><authors><author><keyname>Trevisan</keyname><forenames>Luca</forenames></author></authors><title>Max Cut and the Smallest Eigenvalue</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new approximation algorithm for Max Cut. Our algorithm runs in
$\tilde O(n^2)$ time, where $n$ is the number of vertices, and achieves an
approximation ratio of $.531$. On instances in which an optimal solution cuts a
$1-\epsilon$ fraction of edges, our algorithm finds a solution that cuts a
$1-4\sqrt{\epsilon} + 8\epsilon-o(1)$ fraction of edges.
  Our main result is a variant of spectral partitioning, which can be
implemented in nearly linear time. Given a graph in which the Max Cut optimum
is a $1-\epsilon$ fraction of edges, our spectral partitioning algorithm finds
a set $S$ of vertices and a bipartition $L,R=S-L$ of $S$ such that at least a
$1-O(\sqrt \epsilon)$ fraction of the edges incident on $S$ have one endpoint
in $L$ and one endpoint in $R$. (This can be seen as an analog of Cheeger's
inequality for the smallest eigenvalue of the adjacency matrix of a graph.)
Iterating this procedure yields the approximation results stated above.
  A different, more complicated, variant of spectral partitioning leads to an
$\tilde O(n^3)$ time algorithm that cuts $1/2 + e^{-\Omega(1/\eps)}$ fraction
of edges in graphs in which the optimum is $1/2 + \epsilon$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1984</identifier>
 <datestamp>2008-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1984</id><created>2008-06-11</created><authors><author><keyname>Feng</keyname><forenames>S.</forenames></author><author><keyname>Kogan</keyname><forenames>I. A.</forenames></author><author><keyname>Krim</keyname><forenames>H.</forenames></author></authors><title>Classification of curves in 2D and 3D via affine integral signatures</title><categories>cs.CV</categories><comments>30 pages, 16 figures</comments><acm-class>I.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a robust classification algorithm for curves in 2D and 3D, under
the special and full groups of affine transformations. To each plane or spatial
curve we assign a plane signature curve. Curves, equivalent under an affine
transformation, have the same signature. The signatures introduced in this
paper are based on integral invariants, which behave much better on noisy
images than classically known differential invariants. The comparison with
other types of invariants is given in the introduction. Though the integral
invariants for planar curves were known before, the affine integral invariants
for spatial curves are proposed here for the first time. Using the inductive
variation of the moving frame method we compute affine invariants in terms of
Euclidean invariants. We present two types of signatures, the global signature
and the local signature. Both signatures are independent of parameterization
(curve sampling). The global signature depends on the choice of the initial
point and does not allow us to compare fragments of curves, and is therefore
sensitive to occlusions. The local signature, although is slightly more
sensitive to noise, is independent of the choice of the initial point and is
not sensitive to occlusions in an image. It helps establish local equivalence
of curves. The robustness of these invariants and signatures in their
application to the problem of classification of noisy spatial curves extracted
from a 3D object is analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2006</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2006</id><created>2008-06-12</created><updated>2012-01-06</updated><authors><author><keyname>Martin</keyname><forenames>Arnaud</forenames><affiliation>E3I2</affiliation></author></authors><title>Fusion de classifieurs pour la classification d'images sonar</title><categories>cs.CV cs.AI</categories><proxy>ccsd</proxy><journal-ref>Revue Nationale des Technologies de l'Information E, 5 (2005)
  259-268</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present some high level information fusion approaches for
numeric and symbolic data. We study the interest of such method particularly
for classifier fusion. A comparative study is made in a context of sea bed
characterization from sonar images. The classi- fication of kind of sediment is
a difficult problem because of the data complexity. We compare high level
information fusion and give the obtained performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2007</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2007</id><created>2008-06-12</created><authors><author><keyname>Martin</keyname><forenames>Arnaud</forenames><affiliation>E3I2</affiliation></author><author><keyname>Osswald</keyname><forenames>Christophe</forenames><affiliation>E3I2</affiliation></author></authors><title>Experts Fusion and Multilayer Perceptron Based on Belief Learning for
  Sonar Image Classification</title><categories>cs.CV cs.AI</categories><comments>International Conference on Information &amp; Communication Technologies:
  from Theory to Applications (ICTTA), Damascus : Syrie (2008)</comments><proxy>ccsd hal-00286533</proxy><acm-class>I.4; I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sonar images provide a rapid view of the seabed in order to characterize
it. However, in such as uncertain environment, real seabed is unknown and the
only information we can obtain, is the interpretation of different human
experts, sometimes in conflict. In this paper, we propose to manage this
conflict in order to provide a robust reality for the learning step of
classification algorithms. The classification is conducted by a multilayer
perceptron, taking into account the uncertainty of the reality in the learning
stage. The results of this seabed characterization are presented on real sonar
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2008</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2008</id><created>2008-06-12</created><authors><author><keyname>Martin</keyname><forenames>Arnaud</forenames><affiliation>E3I2</affiliation></author><author><keyname>Osswald</keyname><forenames>Christophe</forenames><affiliation>E3I2</affiliation></author></authors><title>Generalized proportional conflict redistribution rule applied to Sonar
  imagery and Radar targets classification</title><categories>cs.CV cs.AI</categories><proxy>ccsd hal-00286587</proxy><acm-class>I.4; I.5</acm-class><journal-ref>Advances and Applications of DSmT for Information Fusion,
  Florentin Smarandache &amp; Jean Dezert (Ed.) (2006) 289-304</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter, we present two applications in information fusion in order
to evaluate the generalized proportional conflict redistribution rule presented
in the chapter \cite{Martin06a}. Most of the time the combination rules are
evaluated only on simple examples. We study here different combination rules
and compare them in terms of decision on real data. Indeed, in real
applications, we need a reliable decision and it is the final results that
matter. Two applications are presented here: a fusion of human experts opinions
on the kind of underwater sediments depict on sonar image and a classifier
fusion for radar targets recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2035</identifier>
 <datestamp>2008-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2035</id><created>2008-06-12</created><authors><author><keyname>Cardona</keyname><forenames>Gabriel</forenames></author><author><keyname>Llabres</keyname><forenames>Merce</forenames></author><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author><author><keyname>Valiente</keyname><forenames>Gabriel</forenames></author></authors><title>Nodal distances for rooted phylogenetic trees</title><categories>q-bio.PE cs.CE cs.DM</categories><comments>26 pages, Supplementary Material available at
  http://bioinfo.uib.es/~recerca/phylotrees/nodal/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Dissimilarity measures for (possibly weighted) phylogenetic trees based on
the comparison of their vectors of path lengths between pairs of taxa, have
been present in the systematics literature since the early seventies. But, as
far as rooted phylogenetic trees goes, these vectors can only separate
non-weighted binary trees, and therefore these dissimilarity measures are
metrics only on this class. In this paper we overcome this problem, by
splitting in a suitable way each path length between two taxa into two lengths.
We prove that the resulting splitted path lengths matrices single out arbitrary
rooted phylogenetic trees with nested taxa and arcs weighted in the set of
positive real numbers. This allows the definition of metrics on this general
class by comparing these matrices by means of metrics in spaces of real-valued
$n\times n$ matrices. We conclude this paper by establishing some basic facts
about the metrics for non-weighted phylogenetic trees defined in this way using
$L^p$ metrics on these spaces of matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2068</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2068</id><created>2008-06-12</created><updated>2009-09-08</updated><authors><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author></authors><title>A simple, polynomial-time algorithm for the matrix torsion problem</title><categories>cs.DM cs.DS</categories><comments>6 pages. Not intended to be submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Matrix Torsion Problem (MTP) is: given a square matrix M with rational
entries, decide whether two distinct powers of M are equal. It has been shown
by Cassaigne and the author that the MTP reduces to the Matrix Power Problem
(MPP) in polynomial time: given two square matrices A and B with rational
entries, the MTP is to decide whether B is a power of A. Since the MPP is
decidable in polynomial time, it is also the case of the MTP. However, the
algorithm for MPP is highly non-trivial. The aim of this note is to present a
simple, direct, polynomial-time algorithm for the MTP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2084</identifier>
 <datestamp>2008-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2084</id><created>2008-06-12</created><authors><author><keyname>Garcia</keyname><forenames>A. G.</forenames></author><author><keyname>Hernandez-Medina</keyname><forenames>M. A.</forenames></author><author><keyname>Perez-Villalon</keyname><forenames>G.</forenames></author></authors><title>On the existence of compactly supported reconstruction functions in a
  sampling problem</title><categories>cs.IT math.FA math.IT math.NA</categories><comments>24 pages</comments><msc-class>15A21; 15A22; 42C15; 42C40; 94A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assume that samples of a filtered version of a function in a shift-invariant
space are avalaible. This work deals with the existence of a sampling formula
involving these samples and having reconstruction functions with compact
support. Thus, low computational complexity is involved and truncation errors
are avoided. This is done in the light of the generalized sampling theory by
using the oversampling technique: more samples than strictly necessary are
used. For a suitable choice of the sampling period, a necessary and sufficient
condition is given in terms of the Kronecker canonical form of a matrix pencil.
Comparing with other characterizations in the mathematical literature, the
given here has an important advantage: it can be reliable computed by using the
GUPTRI form of the matrix pencil. Finally, a practical method for computing the
compactly supported reconstruction functions is given for the important case
where the oversampling rate is minimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2090</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2090</id><created>2008-06-12</created><updated>2008-09-11</updated><authors><author><keyname>Matijevi&#x107;</keyname><forenames>Domagoj</forenames></author><author><keyname>Osbild</keyname><forenames>Ralf</forenames></author></authors><title>Finding the theta-Guarded Region</title><categories>cs.CG</categories><comments>21 pages, 13 figures; revised version with new results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are given a finite set of n points (guards) G in the plane R^2 and an
angle 0 &lt; theta &lt; 2 pi. A theta-cone is a cone with apex angle theta. We call a
theta-cone empty (with respect to G) if it does not contain any point of G. A
point p in R^2 is called theta-guarded if every theta-cone with its apex
located at p is non-empty. Furthermore, the set of all theta-guarded points is
called the theta-guarded region, or the theta-region for short.
  We present several results on this topic. The main contribution of our work
is to describe the theta-region with O(n/theta) circular arcs, and we give an
algorithm to compute it. We prove a tight O(n) worst-case bound on the
complexity of the theta-region for theta &gt;= pi/2. In case theta is bounded from
below by a positive constant, we prove an almost linear bound O(n^(1+epsilon))
for any epsilon &gt; 0 on the complexity. Moreover, we show that there is a
sequence of inputs such that the asymptotic bound on the complexity of their
theta-region is Omega(n^2). In addition we point out gaps in the proofs of a
recent publication that claims an O(n) bound on the complexity for any constant
angle theta.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2096</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2096</id><created>2008-06-12</created><authors><author><keyname>Kempner</keyname><forenames>Yulia</forenames></author><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author></authors><title>Geometry of antimatroidal point sets</title><categories>math.CO cs.DM</categories><comments>14 pages, 3 figures</comments><msc-class>52B40 (Primary); 05B50 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of &quot;antimatroid with repetition&quot; was conceived by Bjorner, Lovasz
and Shor in 1991 as a multiset extension of the notion of antimatroid. When the
underlying set consists of only two elements, such two-dimensional antimatroids
correspond to point sets in the plane. In this research we concentrate on
geometrical properties of antimatroidal point sets in the plane and prove that
these sets are exactly parallelogram polyominoes. Our results imply that
two-dimensional antimatroids have convex dimension 2. The second part of the
research is devoted to geometrical properties of three-dimensional antimatroids
closed under intersection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2139</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2139</id><created>2008-06-12</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Beyond Nash Equilibrium: Solution Concepts for the 21st Century</title><categories>cs.GT cs.AI cs.CR cs.DC</categories><acm-class>C.2.4; F.0; I.2.11; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nash equilibrium is the most commonly-used notion of equilibrium in game
theory. However, it suffers from numerous problems. Some are well known in the
game theory community; for example, the Nash equilibrium of repeated prisoner's
dilemma is neither normatively nor descriptively reasonable. However, new
problems arise when considering Nash equilibrium from a computer science
perspective: for example, Nash equilibrium is not robust (it does not tolerate
``faulty'' or ``unexpected'' behavior), it does not deal with coalitions, it
does not take computation cost into account, and it does not deal with cases
where players are not aware of all aspects of the game. Solution concepts that
try to address these shortcomings of Nash equilibrium are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2140</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2140</id><created>2008-06-12</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Defaults and Normality in Causal Structures</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A serious defect with the Halpern-Pearl (HP) definition of causality is
repaired by combining a theory of causality with a theory of defaults. In
addition, it is shown that (despite a claim to the contrary) a cause according
to the HP condition need not be a single conjunct. A definition of causality
motivated by Wright's NESS test is shown to always hold for a single conjunct.
Moreover, conditions that hold for all the examples considered by HP are given
that guarantee that causality according to (this version) of the NESS test is
equivalent to the HP definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2159</identifier>
 <datestamp>2008-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2159</id><created>2008-06-12</created><updated>2008-08-29</updated><authors><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Grigori</keyname><forenames>Laura</forenames></author><author><keyname>Hoemmen</keyname><forenames>Mark</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author></authors><title>Communication-optimal parallel and sequential QR and LU factorizations:
  theory and practice</title><categories>cs.NA</categories><report-no>LAPACK Working Note 204</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present parallel and sequential dense QR factorization algorithms that are
both optimal (up to polylogarithmic factors) in the amount of communication
they perform, and just as stable as Householder QR. Our first algorithm, Tall
Skinny QR (TSQR), factors m-by-n matrices in a one-dimensional (1-D) block
cyclic row layout, and is optimized for m &gt;&gt; n. Our second algorithm, CAQR
(Communication-Avoiding QR), factors general rectangular matrices distributed
in a two-dimensional block cyclic layout. It invokes TSQR for each block column
factorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2198</identifier>
 <datestamp>2008-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2198</id><created>2008-06-13</created><authors><author><keyname>Perotti</keyname><forenames>Alberto</forenames></author><author><keyname>Tarable</keyname><forenames>Alberto</forenames></author><author><keyname>Benedetto</keyname><forenames>Sergio</forenames></author><author><keyname>Montorsi</keyname><forenames>Guido</forenames></author></authors><title>Capacity-achieving CPM schemes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pragmatic approach to coded continuous-phase modulation (CPM) is proposed
as a capacity-achieving low-complexity alternative to the serially-concatenated
CPM (SC-CPM) coding scheme. In this paper, we first perform a selection of the
best spectrally-efficient CPM modulations to be embedded into SC-CPM schemes.
Then, we consider the pragmatic capacity (a.k.a. BICM capacity) of CPM
modulations and optimize it through a careful design of the mapping between
input bits and CPM waveforms. The so obtained schemes are cascaded with an
outer serially-concatenated convolutional code to form a pragmatic
coded-modulation system. The resulting schemes exhibit performance very close
to the CPM capacity without requiring iterations between the outer decoder and
the CPM demodulator. As a result, the receiver exhibits reduced complexity and
increased flexibility due to the separation of the demodulation and decoding
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2216</identifier>
 <datestamp>2008-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2216</id><created>2008-06-13</created><authors><author><keyname>Marivate</keyname><forenames>Vukosi N.</forenames></author><author><keyname>Ssali</keyname><forenames>George</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>An Intelligent Multi-Agent Recommender System for Human Capacity
  Building</title><categories>cs.AI cs.HC</categories><comments>Proceedings of the 14th IEEE Mediterranean Electrotechnical
  Conference, 2008, pages 909 to 915</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a Multi-Agent approach to the problem of recommending
training courses to engineering professionals. The recommendation system is
built as a proof of concept and limited to the electrical and mechanical
engineering disciplines. Through user modelling and data collection from a
survey, collaborative filtering recommendation is implemented using intelligent
agents. The agents work together in recommending meaningful training courses
and updating the course information. The system uses a users profile and
keywords from courses to rank courses. A ranking accuracy for courses of 90% is
achieved while flexibility is achieved using an agent that retrieves
information autonomously using data mining techniques from websites. This
manner of recommendation is scalable and adaptable. Further improvements can be
made using clustering and recording user feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2264</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2264</id><created>2008-06-13</created><authors><author><keyname>Berline</keyname><forenames>Chantal</forenames><affiliation>PPS</affiliation></author><author><keyname>Manzonetto</keyname><forenames>Giulio</forenames><affiliation>PPS</affiliation></author><author><keyname>Salibra</keyname><forenames>Antonio</forenames></author></authors><title>Effective lambda-models vs recursively enumerable lambda-theories</title><categories>math.LO cs.LO</categories><comments>34 p</comments><proxy>ccsd hal-00288081</proxy><msc-class>03B40; 03D45; 03C65</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A longstanding open problem is whether there exists a non syntactical model
of the untyped lambda-calculus whose theory is exactly the least lambda-theory
(l-beta). In this paper we investigate the more general question of whether the
equational/order theory of a model of the (untyped) lambda-calculus can be
recursively enumerable (r.e. for brevity). We introduce a notion of effective
model of lambda-calculus calculus, which covers in particular all the models
individually introduced in the literature. We prove that the order theory of an
effective model is never r.e.; from this it follows that its equational theory
cannot be l-beta or l-beta-eta. We then show that no effective model living in
the stable or strongly stable semantics has an r.e. equational theory.
Concerning Scott's semantics, we investigate the class of graph models and
prove that no order theory of a graph model can be r.e., and that there exists
an effective graph model whose equational/order theory is minimum among all
theories of graph models. Finally, we show that the class of graph models
enjoys a kind of downwards Lowenheim-Skolem theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2274</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2274</id><created>2008-06-13</created><updated>2009-12-09</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Shinavier</keyname><forenames>Joshua</forenames></author></authors><title>Exposing Multi-Relational Networks to Single-Relational Network Analysis
  Algorithms</title><categories>cs.DM cs.DS</categories><comments>ISSN:1751-1577</comments><report-no>LA-UR-08-03931</report-no><acm-class>F.2.2; G.1.3</acm-class><journal-ref>Journal of Informetrics, volume 4, number 1, pages 29-41, 2009</journal-ref><doi>10.1016/j.joi.2009.06.004</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Many, if not most network analysis algorithms have been designed specifically
for single-relational networks; that is, networks in which all edges are of the
same type. For example, edges may either represent &quot;friendship,&quot; &quot;kinship,&quot; or
&quot;collaboration,&quot; but not all of them together. In contrast, a multi-relational
network is a network with a heterogeneous set of edge labels which can
represent relationships of various types in a single data structure. While
multi-relational networks are more expressive in terms of the variety of
relationships they can capture, there is a need for a general framework for
transferring the many single-relational network analysis algorithms to the
multi-relational domain. It is not sufficient to execute a single-relational
network analysis algorithm on a multi-relational network by simply ignoring
edge labels. This article presents an algebra for mapping multi-relational
networks to single-relational networks, thereby exposing them to
single-relational network analysis algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2287</identifier>
 <datestamp>2014-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2287</id><created>2008-06-13</created><updated>2013-06-21</updated><authors><author><keyname>Furer</keyname><forenames>Martin</forenames></author><author><keyname>Kasiviswanathan</keyname><forenames>Shiva Prasad</forenames></author></authors><title>Approximately Counting Embeddings into Random Graphs</title><categories>cs.DS cs.DM</categories><comments>Earlier version appeared in Random 2008. Fixed an typo in Definition
  3.1</comments><doi>10.1017/S0963548314000339</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let H be a graph, and let C_H(G) be the number of (subgraph isomorphic)
copies of H contained in a graph G. We investigate the fundamental problem of
estimating C_H(G). Previous results cover only a few specific instances of this
general problem, for example, the case when H has degree at most one
(monomer-dimer problem). In this paper, we present the first general subcase of
the subgraph isomorphism counting problem which is almost always efficiently
approximable. The results rely on a new graph decomposition technique.
Informally, the decomposition is a labeling of the vertices such that every
edge is between vertices with different labels and for every vertex all
neighbors with a higher label have identical labels. The labeling implicitly
generates a sequence of bipartite graphs which permits us to break the problem
of counting embeddings of large subgraphs into that of counting embeddings of
small subgraphs. Using this method, we present a simple randomized algorithm
for the counting problem. For all decomposable graphs H and all graphs G, the
algorithm is an unbiased estimator. Furthermore, for all graphs H having a
decomposition where each of the bipartite graphs generated is small and almost
all graphs G, the algorithm is a fully polynomial randomized approximation
scheme.
  We show that the graph classes of H for which we obtain a fully polynomial
randomized approximation scheme for almost all G includes graphs of degree at
most two, bounded-degree forests, bounded-length grid graphs, subdivision of
bounded-degree graphs, and major subclasses of outerplanar graphs,
series-parallel graphs and planar graphs, whereas unbounded-length grid graphs
are excluded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2312</identifier>
 <datestamp>2008-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2312</id><created>2008-06-13</created><authors><author><keyname>Joo</keyname><forenames>Balint</forenames></author><author><keyname>Collaboration</keyname><forenames>for the USQCD</forenames></author></authors><title>Continuing Progress on a Lattice QCD Software Infrastructure</title><categories>hep-lat cs.CE</categories><comments>5 Pages, to appear in the Proceedings of SciDAC 2008 conference,
  (Seattle, July 13-17, 2008), Conference Poster Presentation Proceedings</comments><report-no>JLAB-IT-08-02</report-no><journal-ref>J.Phys.Conf.Ser.125:012066,2008</journal-ref><doi>10.1088/1742-6596/125/1/012066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on the progress of the software effort in the QCD Application Area
of SciDAC. In particular, we discuss how the software developed under SciDAC
enabled the aggressive exploitation of leadership computers, and we report on
progress in the area of QCD software for multi-core architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2332</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2332</id><created>2008-06-13</created><updated>2008-08-05</updated><authors><author><keyname>VanderZee</keyname><forenames>Evan</forenames></author><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Guoy</keyname><forenames>Damrong</forenames></author></authors><title>Triangulation of Simple 3D Shapes with Well-Centered Tetrahedra</title><categories>cs.CG cs.NA</categories><comments>Accepted at the conference &quot;17th International Meshing Roundtable&quot;,
  Pittsburgh, Pennsylvania, October 12-15, 2008. Will appear in proceedings of
  the conference, published by Springer. For this version, we fixed some typos</comments><report-no>UIUCDCS-R-2008-2970</report-no><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A completely well-centered tetrahedral mesh is a triangulation of a three
dimensional domain in which every tetrahedron and every triangle contains its
circumcenter in its interior. Such meshes have applications in scientific
computing and other fields. We show how to triangulate simple domains using
completely well-centered tetrahedra. The domains we consider here are space,
infinite slab, infinite rectangular prism, cube and regular tetrahedron. We
also demonstrate single tetrahedra with various combinations of the properties
of dihedral acuteness, 2-well-centeredness and 3-well-centeredness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2351</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2351</id><created>2008-06-13</created><authors><author><keyname>Wang</keyname><forenames>Li</forenames></author><author><keyname>Zhu</keyname><forenames>Chen-Ping</forenames></author><author><keyname>Gu</keyname><forenames>Zhi-Ming</forenames></author><author><keyname>Xiong</keyname><forenames>Shi-Jie</forenames></author><author><keyname>He</keyname><forenames>Da-Ren</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author></authors><title>Scaling of critical connectivity of mobile ad hoc communication networks</title><categories>cs.NI cond-mat.dis-nn physics.soc-ph</categories><comments>6 pages, 6 figures</comments><doi>10.1103/PhysRevE.78.066107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, critical global connectivity of mobile ad hoc communication
networks (MAHCN) is investigated. We model the two-dimensional plane on which
nodes move randomly with a triangular lattice. Demanding the best communication
of the network, we account the global connectivity $\eta$ as a function of
occupancy $\sigma$ of sites in the lattice by mobile nodes. Critical phenomena
of the connectivity for different transmission ranges $r$ are revealed by
numerical simulations, and these results fit well to the analysis based on the
assumption of homogeneous mixing . Scaling behavior of the connectivity is
found as $\eta \sim f(R^{\beta}\sigma)$, where $R=(r-r_{0})/r_{0}$, $r_{0}$ is
the length unit of the triangular lattice and $\beta$ is the scaling index in
the universal function $f(x)$. The model serves as a sort of site percolation
on dynamic complex networks relative to geometric distance. Moreover, near each
critical $\sigma_c(r)$ corresponding to certain transmission range $r$, there
exists a cut-off degree $k_c$ below which the clustering coefficient of such
self-organized networks keeps a constant while the averaged nearest neighbor
degree exhibits a unique linear variation with the degree k, which may be
useful to the designation of real MAHCN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2356</identifier>
 <datestamp>2008-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2356</id><created>2008-06-13</created><authors><author><keyname>Owladeghaffari</keyname><forenames>Hamed</forenames></author></authors><title>Development of Hybrid Intelligent Systems and their Applications from
  Engineering Systems to Complex Systems</title><categories>cs.AI cs.MA</categories><comments>A Brief Report for 10th Young Khwarizmi Award</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we introduce general frame of MAny Connected Intelligent
Particles Systems (MACIPS). Connections and interconnections between particles
get a complex behavior of such merely simple system (system in
system).Contribution of natural computing, under information granulation
theory, are the main topic of this spacious skeleton. Upon this clue, we
organize different algorithms involved a few prominent intelligent computing
and approximate reasoning methods such as self organizing feature map (SOM)[9],
Neuro- Fuzzy Inference System[10], Rough Set Theory (RST)[11], collaborative
clustering, Genetic Algorithm and Ant Colony System. Upon this, we have
employed our algorithms on the several engineering systems, especially emerged
systems in Civil and Mineral processing. In other process, we investigated how
our algorithms can be taken as a linkage of government-society interaction,
where government catches various fashions of behavior: solid (absolute) or
flexible. So, transition of such society, by changing of connectivity
parameters (noise) from order to disorder is inferred. Add to this, one may
find an indirect mapping among finical systems and eventual market fluctuations
with MACIPS. In the following sections, we will mention the main topics of the
suggested proposal, briefly Details of the proposed algorithms can be found in
the references.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2360</identifier>
 <datestamp>2008-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2360</id><created>2008-06-14</created><updated>2008-10-06</updated><authors><author><keyname>Tarasov</keyname><forenames>Alexey S</forenames></author></authors><title>Existence of a polyhedron which does not have a non-overlapping
  pseudo-edge unfolding</title><categories>cs.CG</categories><comments>24 pages, 20 figuers, minor grammatical changes</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  There exists a surface of a convex polyhedron P and a partition L of P into
geodesic convex polygons such that there are no connected &quot;edge&quot; unfoldings of
P without self-intersections (whose spanning tree is a subset of the edge
skeleton of L).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2395</identifier>
 <datestamp>2008-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2395</id><created>2008-06-14</created><authors><author><keyname>Guclu</keyname><forenames>Hasan</forenames></author><author><keyname>Kumari</keyname><forenames>Durgesh</forenames></author><author><keyname>Yuksel</keyname><forenames>Murat</forenames></author></authors><title>Ad-hoc Limited Scale-Free Models for Unstructured Peer-to-Peer Networks</title><categories>cs.DC</categories><comments>10 pages, 6 figures, 43 references. Proceedings of The 8th IEEE
  International Conference on Peer-to-Peer Computing 2008 (IEEE P2P 2008),
  Aachen, Germany</comments><report-no>LA-UR 08-3219</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several protocol efficiency metrics (e.g., scalability, search success rate,
routing reachability and stability) depend on the capability of preserving
structure even over the churn caused by the ad-hoc nodes joining or leaving the
network. Preserving the structure becomes more prohibitive due to the
distributed and potentially uncooperative nature of such networks, as in the
peer-to-peer (P2P) networks. Thus, most practical solutions involve
unstructured approaches while attempting to maintain the structure at various
levels of protocol stack. The primary focus of this paper is to investigate
construction and maintenance of scale-free topologies in a distributed manner
without requiring global topology information at the time when nodes join or
leave. We consider the uncooperative behavior of peers by limiting the number
of neighbors to a pre-defined hard cutoff value (i.e., no peer is a major hub),
and the ad-hoc behavior of peers by rewiring the neighbors of nodes leaving the
network. We also investigate the effect of these hard cutoffs and rewiring of
ad-hoc nodes on the P2P search efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2448</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2448</id><created>2008-06-15</created><updated>2008-10-20</updated><authors><author><keyname>Yoshida</keyname><forenames>Nobuko</forenames></author><author><keyname>Honda</keyname><forenames>Kohei</forenames></author><author><keyname>Berger</keyname><forenames>Martin</forenames></author></authors><title>Logical Reasoning for Higher-Order Functions with Local State</title><categories>cs.LO cs.PL</categories><comments>68 pages</comments><acm-class>D.3.3; D.3.2; F.3.1; F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (October
  20, 2008) lmcs:830</journal-ref><doi>10.2168/LMCS-4(4:2)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an extension of Hoare logic for call-by-value higher-order
functions with ML-like local reference generation. Local references may be
generated dynamically and exported outside their scope, may store higher-order
functions and may be used to construct complex mutable data structures. This
primitive is captured logically using a predicate asserting reachability of a
reference name from a possibly higher-order datum and quantifiers over hidden
references. We explore the logic's descriptive and reasoning power with
non-trivial programming examples combining higher-order procedures and
dynamically generated local state. Axioms for reachability and local invariant
play a central role for reasoning about the examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2469</identifier>
 <datestamp>2008-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2469</id><created>2008-06-15</created><authors><author><keyname>Shah</keyname><forenames>Parikshit</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author></authors><title>Polynomial stochastic games via sum of squares optimization</title><categories>math.OC cs.GT</categories><comments>28 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic games are an important class of problems that generalize Markov
decision processes to game theoretic scenarios. We consider finite state
two-player zero-sum stochastic games over an infinite time horizon with
discounted rewards. The players are assumed to have infinite strategy spaces
and the payoffs are assumed to be polynomials. In this paper we restrict our
attention to a special class of games for which the single-controller
assumption holds. It is shown that minimax equilibria and optimal strategies
for such games may be obtained via semidefinite programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2509</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2509</id><created>2008-06-16</created><authors><author><keyname>Bossche</keyname><forenames>Adrien Van Den</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Val</keyname><forenames>Thierry</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Campo</keyname><forenames>Eric</forenames><affiliation>LATTIS</affiliation></author></authors><title>Proposition of a full deterministic medium access method for wireless
  network in a robotic application</title><categories>cs.NI</categories><proxy>ccsd hal-00258749</proxy><journal-ref>2006 IEEE 63rd Vehicular Technology Conference, Melbourne :
  Australie (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, many network applications require shorter react time. Robotic field is
an excellent example of these needs: robot react time has a direct effect on
its task's complexity. Here, we propose a full deterministic medium access
method for a wireless robotic application. This contribution is based on some
low-power wireless personal area networks, like ZigBee standard. Indeed, ZigBee
has identified limits with Quality of Service due to non-determinist medium
access and probable collisions during medium reservation requests. In this
paper, two major improvements are proposed: an efficient polling of the star
nodes and a temporal deterministic distribution of peer-to-peer messages. This
new MAC protocol with no collision offers some QoS faculties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2513</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2513</id><created>2008-06-16</created><updated>2009-12-30</updated><authors><author><keyname>&#xd6;sterg&#xe5;rd</keyname><forenames>Patric R. J.</forenames></author><author><keyname>Pottonen</keyname><forenames>Olli</forenames></author></authors><title>The Perfect Binary One-Error-Correcting Codes of Length 15: Part
  I--Classification</title><categories>cs.IT math.IT</categories><comments>6 pages. v3: made the codes available in the source of this paper</comments><journal-ref>IEEE Trans. Inform. Theory 55 (2009), 4657-4660</journal-ref><doi>10.1109/TIT.2009.2027525</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complete classification of the perfect binary one-error-correcting codes of
length 15 as well as their extensions of length 16 is presented. There are 5983
such inequivalent perfect codes and 2165 extended perfect codes. Efficient
generation of these codes relies on the recent classification of Steiner
quadruple systems of order 16. Utilizing a result of Blackmore, the optimal
binary one-error-correcting codes of length 14 and the (15, 1024, 4) codes are
also classified; there are 38408 and 5983 such codes, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2517</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2517</id><created>2008-06-16</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Jouannaud</keyname><forenames>Jean-Pierre</forenames><affiliation>LIX, INRIA Saclay Ile de France</affiliation></author><author><keyname>Rubio</keyname><forenames>Albert</forenames></author></authors><title>The computability path ordering: the end of a quest</title><categories>cs.LO</categories><comments>Dans CSL'08 (2008)</comments><proxy>ccsd inria-00288209</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first briefly survey automated termination proof methods
for higher-order calculi. We then concentrate on the higher-order recursive
path ordering, for which we provide an improved definition, the Computability
Path Ordering. This new definition appears indeed to capture the essence of
computability arguments \`a la Tait and Girard, therefore explaining the name
of the improved ordering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2533</identifier>
 <datestamp>2009-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2533</id><created>2008-06-16</created><updated>2009-10-31</updated><authors><author><keyname>Mohammed</keyname><forenames>Saif K.</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Asymptotic Analysis of the Performance of LAS Algorithm for Large-MIMO
  Detection</title><categories>cs.IT math.IT</categories><comments>This work in part was presented in IEEE PIMRC'2008, Cannes, France,
  September 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our recent work, we reported an exhaustive study on the simulated bit
error rate (BER) performance of a low-complexity likelihood ascent search (LAS)
algorithm for detection in large multiple-input multiple-output (MIMO) systems
with large number of antennas that achieve high spectral efficiencies. Though
the algorithm was shown to achieve increasingly closer to near
maximum-likelihood (ML) performance through simulations, no BER analysis was
reported. Here, we extend our work on LAS and report an asymptotic BER analysis
of the LAS algorithm in the large system limit, where $N_t,N_r \to \infty$ with
$N_t=N_r$, where $N_t$ and $N_r$ are the number of transmit and receive
antennas. We prove that the error performance of the LAS detector in V-BLAST
with 4-QAM in i.i.d. Rayleigh fading converges to that of the ML detector as
$N_t,N_r \to \infty$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2548</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2548</id><created>2008-06-16</created><authors><author><keyname>Goualard</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LINA</affiliation></author><author><keyname>Goldsztejn</keyname><forenames>Alexandre</forenames><affiliation>LINA</affiliation></author></authors><title>A Data-Parallel Algorithm to Reliably Solve Systems of Nonlinear
  Equations</title><categories>cs.NA</categories><comments>10 pages</comments><proxy>ccsd hal-00288207</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical methods based on interval arithmetic are efficient means to
reliably solve nonlinear systems of equations. Algorithm bc3revise is an
interval method that tightens variables' domains by enforcing a property called
box consistency. It has been successfully used on difficult problems whose
solving eluded traditional numerical methods. We present a new algorithm to
enforce box consistency that is simpler than bc3revise, faster, and easily data
parallelizable. A parallel implementation with Intel SSE2 SIMD instructions
shows that an increase in performance of up to an order of magnitude and more
is achievable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2549</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2549</id><created>2008-06-16</created><authors><author><keyname>Bossche</keyname><forenames>Adrien Van Den</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Val</keyname><forenames>Thierry</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Campo</keyname><forenames>Eric</forenames><affiliation>LATTIS</affiliation></author></authors><title>Prototyping and Performance Analysis of a QoS MAC Layer for Industrial
  Wireless Network</title><categories>cs.NI</categories><comments>7th IFAC International Conference on. Fieldbuses and nETworks in
  industrial and embedded systems, Toulouse : France (2007)</comments><proxy>ccsd hal-00288179</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's industrial sensor networks require strong reliability and guarantees
on messages delivery. These needs are even more important in real time
applications like control/command, such as robotic wireless communications
where strong temporal constraints are critical. For these reasons, classical
random-based Medium Access Control (MAC) protocols present a non-null frame
collision probability. In this paper we present an original full deterministic
MAC-layer for industrial wireless network and its performance evaluation thanks
to the development of a material prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2550</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2550</id><created>2008-06-16</created><authors><author><keyname>Bossche</keyname><forenames>Adrien Van Den</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Val</keyname><forenames>Thierry</forenames><affiliation>LATTIS</affiliation></author><author><keyname>Campo</keyname><forenames>Eric</forenames><affiliation>LATTIS</affiliation></author></authors><title>Proposition and validation of an original MAC layer with simultaneous
  medium accesses for low latency wireless control/command applications</title><categories>cs.NI</categories><proxy>ccsd hal-00288170</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Control/command processes require a transmission system with some
characteristics like high reliability, low latency and strong guarantees on
messages delivery. Concerning wire networks, field buses technologies like FIP
offer this kind of service (periodic tasks, real time constraints...).
Unfortunately, few wireless technologies can propose a communication system
which respects such constraints. Indeed, wireless transmissions must deal with
medium characteristics which make impossible the direct translation of
mechanisms used with wire networks. The purpose of this paper is to present an
original Medium Access Control (MAC) layer for a real time Low Power-Wireless
Personal Area Network (LP-WPAN). The proposed MAC-layer has been validated by
several complementary methods; in this paper, we focus on the specific
Simultaneous Guaranteed Time Slot (SGTS) part.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2555</identifier>
 <datestamp>2008-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2555</id><created>2008-06-16</created><authors><author><keyname>Erdelyi</keyname><forenames>Gabor</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author><author><keyname>Spakowski</keyname><forenames>Holger</forenames></author></authors><title>Frequency of Correctness versus Average-Case Polynomial Time and
  Generalized Juntas</title><categories>cs.CC cs.GT cs.MA</categories><report-no>URCS-TR-2008-934</report-no><acm-class>F.1.3; F.2.2; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that every distributional problem solvable in polynomial time on the
average with respect to the uniform distribution has a frequently
self-knowingly correct polynomial-time algorithm. We also study some features
of probability weight of correctness with respect to generalizations of
Procaccia and Rosenschein's junta distributions [PR07b].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2581</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2581</id><created>2008-06-16</created><authors><author><keyname>Tatar</keyname><forenames>Doina</forenames></author><author><keyname>Serban</keyname><forenames>Gabriela</forenames></author><author><keyname>Mihis</keyname><forenames>Andreea</forenames></author><author><keyname>Lupea</keyname><forenames>Mihaiela</forenames></author><author><keyname>Lupsa</keyname><forenames>Dana</forenames></author><author><keyname>Frentiu</keyname><forenames>Militon</forenames></author></authors><title>A chain dictionary method for Word Sense Disambiguation and applications</title><categories>cs.CL</categories><comments>8 pages, 5 figures</comments><acm-class>I.2.7</acm-class><journal-ref>Studia Universitatis Babes-Bolyai, Special Issue, KEPT 2007,
  Knowledge Engineering: Principles and Technologies, Cluj-Napoca, June 6-8,
  2007, pp 33-40,</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large class of unsupervised algorithms for Word Sense Disambiguation (WSD)
is that of dictionary-based methods. Various algorithms have as the root Lesk's
algorithm, which exploits the sense definitions in the dictionary directly. Our
approach uses the lexical base WordNet for a new algorithm originated in
Lesk's, namely &quot;chain algorithm for disambiguation of all words&quot;, CHAD. We show
how translation from a language into another one and also text entailment
verification could be accomplished by this disambiguation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2643</identifier>
 <datestamp>2008-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2643</id><created>2008-06-16</created><updated>2008-06-18</updated><authors><author><keyname>Peng</keyname><forenames>Yong</forenames></author><author><keyname>Rajan</keyname><forenames>Dinesh</forenames></author></authors><title>On the Capacity Equivalence with Side Information at Transmitter and
  Receiver</title><categories>cs.IT math.IT</categories><comments>5 pages in IEEE 2 column format, submitted to IEEE Trans. Information
  Theory in June, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a channel that is contaminated by two independent Gaussian
noises $S ~ N(0,Q)$ and $Z_0 ~ N(0,N_0)$ is considered. The capacity of this
channel is computed when independent noisy versions of $S$ are known to the
transmitter and/or receiver. It is shown that the channel capacity is greater
then the capacity when $S$ is completely unknown, but is less then the capacity
when $S$ is perfectly known at the transmitter or receiver. For example, if
there is one noisy version of $S$ known at the transmitter only, the capacity
is $0.5\log(1+\frac{P}{Q(N_1/(Q+N_1))+N_0})$, where $P$ is the input power
constraint and $N_1$ is the power of the noise corrupting $S$. Further, it is
shown that the capacity with knowledge of any independent noisy versions of $S$
at the transmitter is equal to the capacity with knowledge of the statistically
equivalent noisy versions of $S$ at the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2674</identifier>
 <datestamp>2008-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2674</id><created>2008-06-16</created><authors><author><keyname>Levy</keyname><forenames>Nathan</forenames><affiliation>Shitz</affiliation></author><author><keyname>Somekh</keyname><forenames>Oren</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Zeitouni</keyname><forenames>Ofer</forenames></author></authors><title>On Certain Large Random Hermitian Jacobi Matrices with Applications to
  Wireless Communications</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the spectrum of certain large random Hermitian Jacobi
matrices. These matrices are known to describe certain communication setups. In
particular we are interested in an uplink cellular channel which models mobile
users experiencing a soft-handoff situation under joint multicell decoding.
Considering rather general fading statistics we provide a closed form
expression for the per-cell sum-rate of this channel in high-SNR, when an
intra-cell TDMA protocol is employed. Since the matrices of interest are
tridiagonal, their eigenvectors can be considered as sequences with second
order linear recurrence. Therefore, the problem is reduced to the study of the
exponential growth of products of two by two matrices. For the case where $K$
users are simultaneously active in each cell, we obtain a series of lower and
upper bound on the high-SNR power offset of the per-cell sum-rate, which are
considerably tighter than previously known bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2680</identifier>
 <datestamp>2008-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2680</id><created>2008-06-16</created><updated>2008-07-19</updated><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Grabmayer</keyname><forenames>Clemens</forenames></author><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author></authors><title>Data-Oblivious Stream Productivity</title><categories>cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are concerned with demonstrating productivity of specifications of
infinite streams of data, based on orthogonal rewrite rules. In general, this
property is undecidable, but for restricted formats computable sufficient
conditions can be obtained. The usual analysis disregards the identity of data,
thus leading to approaches that we call data-oblivious. We present a method
that is provably optimal among all such data-oblivious approaches. This means
that in order to improve on the algorithm in this paper one has to proceed in a
data-aware fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2682</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2682</id><created>2008-06-16</created><authors><author><keyname>Dai</keyname><forenames>Wei</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Weighted Superimposed Codes and Constrained Integer Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new family of codes, termed weighted superimposed codes
(WSCs). This family generalizes the class of Euclidean superimposed codes
(ESCs), used in multiuser identification systems. WSCs allow for discriminating
all bounded, integer-valued linear combinations of real-valued codewords that
satisfy prescribed norm and non-negativity constraints. By design, WSCs are
inherently noise tolerant. Therefore, these codes can be seen as special
instances of robust compressed sensing schemes. The main results of the paper
are lower and upper bounds on the largest achievable code rates of several
classes of WSCs. These bounds suggest that with the codeword and weighting
vector constraints at hand, one can improve the code rates achievable by
standard compressive sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2707</identifier>
 <datestamp>2008-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2707</id><created>2008-06-17</created><authors><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Howat</keyname><forenames>John</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Biased Range Trees</title><categories>cs.CG cs.DS</categories><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data structure, called a biased range tree, is presented that preprocesses
a set S of n points in R^2 and a query distribution D for 2-sided orthogonal
range counting queries. The expected query time for this data structure, when
queries are drawn according to D, matches, to within a constant factor, that of
the optimal decision tree for S and D. The memory and preprocessing
requirements of the data structure are O(n log n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2710</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2710</id><created>2008-06-17</created><updated>2008-06-27</updated><authors><author><keyname>Coudert</keyname><forenames>David</forenames><affiliation>INRIA Sophia Antipolis / Laboratoire I3S</affiliation></author><author><keyname>Huc</keyname><forenames>Florian</forenames><affiliation>INRIA Sophia Antipolis / Laboratoire I3S</affiliation></author><author><keyname>Mazauric</keyname><forenames>Dorian</forenames><affiliation>INRIA Sophia Antipolis / Laboratoire I3S</affiliation></author></authors><title>A distributed algorithm for computing and updating the process number of
  a forest</title><categories>cs.DM</categories><proxy>ccsd inria-00288304</proxy><report-no>RR-6560</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a distributed algorithm to compute various
parameters of a tree such as the process number, the edge search number or the
node search number and so the pathwidth. This algorithm requires n steps, an
overall computation time of O(n log(n)), and n messages of size log_3(n)+3. We
then propose a distributed algorithm to update the process number (or the node
search number, or the edge search number) of each component of a forest after
adding or deleting an edge. This second algorithm requires O(D) steps, an
overall computation time of O(D log(n)), and O(D) messages of size log_3(n)+3,
where D is the diameter of the modified connected component. Finally, we show
how to extend our algorithms to trees and forests of unknown size using
messages of less than 2a+4+e bits, where a is the parameter to be determined
and e=1 for updates algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2726</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2726</id><created>2008-06-17</created><authors><author><keyname>Hesse</keyname><forenames>Matthias</forenames><affiliation>I3S</affiliation></author><author><keyname>Lebrun</keyname><forenames>Jerome</forenames><affiliation>I3S</affiliation></author><author><keyname>Deneire</keyname><forenames>Luc</forenames><affiliation>I3S</affiliation></author></authors><title>L2 Orthogonal Space Time Code for Continuous Phase Modulation</title><categories>cs.IT math.IT</categories><proxy>ccsd inria-00288334</proxy><journal-ref>Dans 9th IEEE International Workshop on Signal Processing Advances
  in Wireless Communications (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To combine the high power efficiency of Continuous Phase Modulation (CPM)
with either high spectral efficiency or enhanced performance in low Signal to
Noise conditions, some authors have proposed to introduce CPM in a MIMO frame,
by using Space Time Codes (STC). In this paper, we address the code design
problem of Space Time Block Codes combined with CPM and introduce a new design
criterion based on L2 orthogonality. This L2 orthogonality condition, with the
help of simplifying assumption, leads, in the 2x2 case, to a new family of
codes. These codes generalize the Wang and Xia code, which was based on
pointwise orthogonality. Simulations indicate that the new codes achieve full
diversity and a slightly better coding gain. Moreover, one of the codes can be
interpreted as two antennas fed by two conventional CPMs using the same data
but with different alphabet sets. Inspection of these alphabet sets lead also
to a simple explanation of the (small) spectrum broadening of Space Time Coded
CPM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2730</identifier>
 <datestamp>2008-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2730</id><created>2008-06-17</created><authors><author><keyname>Diertens</keyname><forenames>B.</forenames></author></authors><title>A Process Algebra Software Engineering Environment</title><categories>cs.SE</categories><report-no>prg0808</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work we described how the process algebra based language PSF can
be used in software engineering, using the ToolBus, a coordination architecture
also based on process algebra, as implementation model. In this article we
summarize that work and describe the software development process more formally
by presenting the tools we use in this process in a CASE setting, leading to
the PSF-ToolBus software engineering environment. We generalize the refine step
in this environment towards a process algebra based software engineering
workbench of which several instances can be combined to form an environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2735</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2735</id><created>2008-06-17</created><updated>2008-07-21</updated><authors><author><keyname>Grattage</keyname><forenames>Jonathan</forenames></author></authors><title>An overview of QML with a concrete implementation in Haskell</title><categories>quant-ph cs.PL</categories><comments>9 pages, final conference version (Quantum Physics and Logic 2008)</comments><journal-ref>ENTCS: Proceedings of QPL V - DCV IV, 157-165, Reykjavik, Iceland,
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives an introduction to and overview of the functional quantum
programming language QML. The syntax of this language is defined and explained,
along with a new QML definition of the quantum teleport algorithm. The
categorical operational semantics of QML is also briefly introduced, in the
form of annotated quantum circuits. This definition leads to a denotational
semantics, given in terms of superoperators. Finally, an implementation in
Haskell of the semantics for QML is presented as a compiler. The compiler takes
QML programs as input, which are parsed into a Haskell datatype. The output
from the compiler is either a quantum circuit (operational), an isometry (pure
denotational) or a superoperator (impure denotational). Orthogonality
judgements and problems with coproducts in QML are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2738</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2738</id><created>2008-06-17</created><authors><author><keyname>Lande</keyname><forenames>D. V.</forenames></author></authors><title>Identification of information tonality based on Bayesian approach and
  neural networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model of the identification of information tonality, based on Bayesian
approach and neural networks was described. In the context of this paper
tonality means positive or negative tone of both the whole information and its
parts which are related to particular concepts. The method, its application is
presented in the paper, is based on statistic regularities connected with the
presence of definite lexemes in the texts. A distinctive feature of the method
is its simplicity and versatility. At present ideologically similar approaches
are widely used to control spam.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2760</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2760</id><created>2008-06-17</created><authors><author><keyname>Hesse</keyname><forenames>Matthias</forenames><affiliation>I3S</affiliation></author><author><keyname>Lebrun</keyname><forenames>Jerome</forenames><affiliation>I3S</affiliation></author><author><keyname>Deneire</keyname><forenames>Luc</forenames><affiliation>I3S</affiliation></author></authors><title>L2 OSTC-CPM: Theory and design</title><categories>cs.IT math.IT</categories><proxy>ccsd inria-00288297</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The combination of space-time coding (STC) and continuous phase modulation
(CPM) is an attractive field of research because both STC and CPM bring many
advantages for wireless communications. Zhang and Fitz [1] were the first to
apply this idea by constructing a trellis based scheme. But for these codes the
decoding effort grows exponentially with the number of transmitting antennas.
This was circumvented by orthogonal codes introduced by Wang and Xia [2].
Unfortunately, based on Alamouti code [3], this design is restricted to two
antennas. However, by relaxing the orthogonality condition, we prove here that
it is possible to design L2-orthogonal space-time codes which achieve full rate
and full diversity with low decoding effort. In part one, we generalize the
two-antenna code proposed by Wang and Xia [2] from pointwise to
L2-orthogonality and in part two we present the first L2-orthogonal code for
CPM with three antennas. In this report, we detail these results and focus on
the properties of these codes. Of special interest is the optimization of the
bit error rate which depends on the initial phase of the system. Our simulation
results illustrate the systemic behavior of these conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2802</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2802</id><created>2008-06-17</created><authors><author><keyname>Lisitsa</keyname><forenames>Alexei</forenames></author></authors><title>A logic with temporally accessible iteration</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deficiency in expressive power of the first-order logic has led to developing
its numerous extensions by fixed point operators, such as Least Fixed-Point
(LFP), inflationary fixed-point (IFP), partial fixed-point (PFP), etc. These
logics have been extensively studied in finite model theory, database theory,
descriptive complexity. In this paper we introduce unifying framework, the
logic with iteration operator, in which iteration steps may be accessed by
temporal logic formulae. We show that proposed logic FO+TAI subsumes all
mentioned fixed point extensions as well as many other fixed point logics as
natural fragments. On the other hand we show that over finite structures FO+TAI
is no more expressive than FO+PFP. Further we show that adding the same
machinery to the logic of monotone inductions (FO+LFP) does not increase its
expressive power either.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2843</identifier>
 <datestamp>2008-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2843</id><created>2008-06-17</created><updated>2008-06-18</updated><authors><author><keyname>Araujo</keyname><forenames>Lourdes</forenames></author><author><keyname>Guervos</keyname><forenames>Juan J. Merelo</forenames></author><author><keyname>Cotta</keyname><forenames>Carlos</forenames></author><author><keyname>de Vega</keyname><forenames>Francisco Fernandez</forenames></author></authors><title>MultiKulti Algorithm: Migrating the Most Different Genotypes in an
  Island Model</title><categories>cs.NE cs.DC</categories><comments>First description of the multikulti distributed evolutionary
  computation migration policy</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Migration policies in distributed evolutionary algorithms has not been an
active research area until recently. However, in the same way as operators have
an impact on performance, the choice of migrants is due to have an impact too.
In this paper we propose a new policy (named multikulti) for choosing the
individuals that are going to be sent to other nodes, based on
multiculturality: the individual sent should be as different as possible to the
receiving population. We have checked this policy on different discrete
optimization problems, and found that, in average or in median, this policy
outperforms classical ones like sending the best or a random individual.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2850</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2850</id><created>2008-06-17</created><authors><author><keyname>Costiris</keyname><forenames>N. J.</forenames></author><author><keyname>Mavrommatis</keyname><forenames>E.</forenames></author><author><keyname>Gernoth</keyname><forenames>K. A.</forenames></author><author><keyname>Clark</keyname><forenames>J. W.</forenames></author></authors><title>Decoding Beta-Decay Systematics: A Global Statistical Model for Beta^-
  Halflives</title><categories>nucl-th astro-ph cond-mat.dis-nn cs.LG stat.ML</categories><comments>20 pages, 19 figures</comments><journal-ref>Phys.Rev.C80:044332,2009</journal-ref><doi>10.1103/PhysRevC.80.044332</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical modeling of nuclear data provides a novel approach to nuclear
systematics complementary to established theoretical and phenomenological
approaches based on quantum theory. Continuing previous studies in which global
statistical modeling is pursued within the general framework of machine
learning theory, we implement advances in training algorithms designed to
improved generalization, in application to the problem of reproducing and
predicting the halflives of nuclear ground states that decay 100% by the beta^-
mode. More specifically, fully-connected, multilayer feedforward artificial
neural network models are developed using the Levenberg-Marquardt optimization
algorithm together with Bayesian regularization and cross-validation. The
predictive performance of models emerging from extensive computer experiments
is compared with that of traditional microscopic and phenomenological models as
well as with the performance of other learning systems, including earlier
neural network models as well as the support vector machines recently applied
to the same problem. In discussing the results, emphasis is placed on
predictions for nuclei that are far from the stability line, and especially
those involved in the r-process nucleosynthesis. It is found that the new
statistical models can match or even surpass the predictive performance of
conventional models for beta-decay systematics and accordingly should provide a
valuable additional tool for exploring the expanding nuclear landscape.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2890</identifier>
 <datestamp>2008-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2890</id><created>2008-06-17</created><authors><author><keyname>Caetano</keyname><forenames>Tiberio S.</forenames></author><author><keyname>McAuley</keyname><forenames>Julian J.</forenames></author><author><keyname>Cheng</keyname><forenames>Li</forenames></author><author><keyname>Le</keyname><forenames>Quoc V.</forenames></author><author><keyname>Smola</keyname><forenames>Alex J.</forenames></author></authors><title>Learning Graph Matching</title><categories>cs.CV cs.LG</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a fundamental problem in pattern recognition, graph matching has
applications in a variety of fields, from computer vision to computational
biology. In graph matching, patterns are modeled as graphs and pattern
recognition amounts to finding a correspondence between the nodes of different
graphs. Many formulations of this problem can be cast in general as a quadratic
assignment problem, where a linear term in the objective function encodes node
compatibility and a quadratic term encodes edge compatibility. The main
research focus in this theme is about designing efficient algorithms for
approximately solving the quadratic assignment problem, since it is NP-hard. In
this paper we turn our attention to a different question: how to estimate
compatibility functions such that the solution of the resulting graph matching
problem best matches the expected solution that a human would manually provide.
We present a method for learning graph matching: the training examples are
pairs of graphs and the `labels' are matches between them. Our experimental
results reveal that learning can substantially improve the performance of
standard graph matching algorithms. In particular, we find that simple linear
assignment with such a learning scheme outperforms Graduated Assignment with
bistochastic normalisation, a state-of-the-art quadratic assignment relaxation
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2923</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2923</id><created>2008-06-18</created><updated>2012-03-19</updated><authors><author><keyname>Luttenberger</keyname><forenames>Michael</forenames></author></authors><title>Strategy Iteration using Non-Deterministic Strategies for Solving Parity
  Games</title><categories>cs.GT cs.LO</categories><acm-class>D.2.4; F.3.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article extends the idea of solving parity games by strategy iteration
to non-deterministic strategies: In a non-deterministic strategy a player
restricts himself to some non-empty subset of possible actions at a given node,
instead of limiting himself to exactly one action. We show that a
strategy-improvement algorithm by by Bjoerklund, Sandberg, and Vorobyov can
easily be adapted to the more general setting of non-deterministic strategies.
Further, we show that applying the heuristic of &quot;all profitable switches&quot; leads
to choosing a &quot;locally optimal&quot; successor strategy in the setting of
non-deterministic strategies, thereby obtaining an easy proof of an algorithm
by Schewe. In contrast to the algorithm by Bjoerklund et al., we present our
algorithm directly for parity games which allows us to compare it to the
algorithm by Jurdzinski and Voege: We show that the valuations used in both
algorithm coincide on parity game arenas in which one player can &quot;surrender&quot;.
Thus, our algorithm can also be seen as a generalization of the one by
Jurdzinski and Voege to non-deterministic strategies. Finally, using
non-deterministic strategies allows us to show that the number of improvement
steps is bound from above by O(1.724^n). For strategy-improvement algorithms,
this bound was previously only known to be attainable by using randomization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2924</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2924</id><created>2008-06-18</created><authors><author><keyname>Laddomada</keyname><forenames>Massimiliano</forenames></author><author><keyname>Mesiti</keyname><forenames>Fabio</forenames></author></authors><title>On the Optimization of the IEEE 802.11 DCF: A Cross-Layer Perspective</title><categories>cs.NI</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is focused on the problem of optimizing the aggregate throughput
of the Distributed Coordination Function (DCF) employing the basic access
mechanism at the data link layer of IEEE 802.11 protocols. In order to broaden
the applicability of the proposed analysis, we consider general operating
conditions accounting for both non-saturated and saturated traffic in the
presence of transmission channel errors, as exemplified by the packet error
rate $P_e$.
  The main clue of this work stems from the relation that links the aggregate
throughput of the network to the packet rate $\lambda$ of the contending
stations. In particular, we show that the aggregate throughput $S(\lambda)$
presents two clearly distinct operating regions that depend on the actual value
of the packet rate $\lambda$ with respect to a critical value $\lambda_c$,
theoretically derived in this work.
  The behavior of $S(\lambda)$ paves the way to a cross-layer optimization
algorithm, which proved to be effective for maximizing the aggregate throughput
in a variety of network operating conditions. A nice consequence of the
proposed optimization framework relies on the fact that the aggregate
throughput can be predicted quite accurately with a simple, yet effective,
closed-form expression, which is also derived in the article.
  Finally, theoretical and simulation results are presented throughout the work
in order to unveil, as well as verify, the key ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2925</identifier>
 <datestamp>2009-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2925</id><created>2008-06-18</created><updated>2009-06-12</updated><authors><author><keyname>Zuki&#x107;</keyname><forenames>D&#x17e;enan</forenames></author><author><keyname>Elsner</keyname><forenames>Andreas</forenames></author><author><keyname>Avdagi&#x107;</keyname><forenames>Zikrija</forenames></author><author><keyname>Domik</keyname><forenames>Gitta</forenames></author></authors><title>Neural networks in 3D medical scan visualization</title><categories>cs.AI cs.GR</categories><comments>8 pages, 6 figures published on conference 3IA'2008 in Athens, Greece
  (http://3ia.teiath.gr)</comments><acm-class>I.3; I.2.6</acm-class><journal-ref>International Conference on Computer Graphics and Artificial
  Intelligence, Proceedings (2008) 183-190</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For medical volume visualization, one of the most important tasks is to
reveal clinically relevant details from the 3D scan (CT, MRI ...), e.g. the
coronary arteries, without obscuring them with less significant parts. These
volume datasets contain different materials which are difficult to extract and
visualize with 1D transfer functions based solely on the attenuation
coefficient. Multi-dimensional transfer functions allow a much more precise
classification of data which makes it easier to separate different surfaces
from each other. Unfortunately, setting up multi-dimensional transfer functions
can become a fairly complex task, generally accomplished by trial and error.
This paper explains neural networks, and then presents an efficient way to
speed up visualization process by semi-automatic transfer function generation.
We describe how to use neural networks to detect distinctive features shown in
the 2D histogram of the volume data and how to use this information for data
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2937</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2937</id><created>2008-06-18</created><authors><author><keyname>Kaczor</keyname><forenames>Gregor</forenames></author><author><keyname>Gros</keyname><forenames>Claudius</forenames></author></authors><title>Evolving complex networks with conserved clique distributions</title><categories>physics.soc-ph cond-mat.dis-nn cs.NI</categories><comments>Physical Review E, in press</comments><journal-ref>Physical Review E, Vol. 78, 016107 (2008).</journal-ref><doi>10.1103/PhysRevE.78.016107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and study a hierarchical algorithm to generate graphs having a
predetermined distribution of cliques, the fully connected subgraphs. The
construction mechanism may be either random or incorporate preferential
attachment. We evaluate the statistical properties of the graphs generated,
such as the degree distribution and network diameters, and compare them to some
real-world graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2943</identifier>
 <datestamp>2008-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2943</id><created>2008-06-18</created><authors><author><keyname>Tanaka</keyname><forenames>Jun</forenames></author></authors><title>Modern Set</title><categories>math.GM cs.IT math.IT</categories><msc-class>03E72</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we intend to generalize the classical set theory as much as
possible. we will do this by freeing sets from the regular properties of
classical sets; e.g., the law of excluded middle, the law of non-contradiction,
the distributive law, the commutative law,etc....
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2947</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2947</id><created>2008-06-18</created><updated>2009-07-10</updated><authors><author><keyname>Kamouna</keyname><forenames>Rafee Ebrahim</forenames></author></authors><title>The Kleene-Rosser Paradox, The Liar's Paradox &amp; A Fuzzy Logic
  Programming Paradox Imply SAT is (NOT) NP-complete</title><categories>cs.LO</categories><comments>Submitted to the ACM Transactions on Computation Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After examining the {\bf P} versus {\bf NP} problem against the Kleene-Rosser
paradox of the $\lambda$-calculus [94], it was found that it represents a
counter-example to NP-completeness. We prove that it contradicts the proof of
Cook's theorem. A logical formalization of the liar's paradox leads to the same
result. This formalization of the liar's paradox into a computable form is a
2-valued instance of a fuzzy logic programming paradox discovered in the system
of [90]. Three proofs that show that {\bf SAT} is (NOT) NP-complete are
presented. The counter-example classes to NP-completeness are also
counter-examples to Fagin's theorem [36] and the Immermann-Vardi theorem
[89,110], the fundamental results of descriptive complexity. All these results
show that {\bf ZF$\not$C} is inconsistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2991</identifier>
 <datestamp>2008-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2991</id><created>2008-06-18</created><authors><author><keyname>Levy</keyname><forenames>Nathan</forenames><affiliation>Shitz</affiliation></author><author><keyname>Zeitouni</keyname><forenames>Ofer</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>On Information Rates of the Fading Wyner Cellular Model via the Thouless
  Formula for the Strip</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply the theory of random Schr\&quot;odinger operators to the analysis of
multi-users communication channels similar to the Wyner model, that are
characterized by short-range intra-cell broadcasting. With $H$ the channel
transfer matrix, $HH^\dagger$ is a narrow-band matrix and in many aspects is
similar to a random Schr\&quot;odinger operator. We relate the per-cell sum-rate
capacity of the channel to the integrated density of states of a random
Schr\&quot;odinger operator; the latter is related to the top Lyapunov exponent of a
random sequence of matrices via a version of the Thouless formula. Unlike
related results in classical random matrix theory, limiting results do depend
on the underlying fading distributions. We also derive several bounds on the
limiting per-cell sum-rate capacity, some based on the theory of random
Schr\&quot;odinger operators, and some derived from information theoretical
considerations. Finally, we get explicit results in the high-SNR regime for
some particular cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3015</identifier>
 <datestamp>2008-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3015</id><created>2008-06-18</created><authors><author><keyname>Leventhal</keyname><forenames>D.</forenames></author><author><keyname>Lewis</keyname><forenames>A. S.</forenames></author></authors><title>Randomized Methods for Linear Constraints: Convergence Rates and
  Conditioning</title><categories>math.OC cs.NA</categories><comments>22 pages</comments><msc-class>15A12; 15A39; 65F10; 90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study randomized variants of two classical algorithms: coordinate descent
for systems of linear equations and iterated projections for systems of linear
inequalities. Expanding on a recent randomized iterated projection algorithm of
Strohmer and Vershynin for systems of linear equations, we show that, under
appropriate probability distributions, the linear rates of convergence (in
expectation) can be bounded in terms of natural linear-algebraic condition
numbers for the problems. We relate these condition measures to distances to
ill-posedness, and discuss generalizations to convex systems under metric
regularity assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3023</identifier>
 <datestamp>2010-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3023</id><created>2008-06-18</created><updated>2010-07-13</updated><authors><author><keyname>Lin</keyname><forenames>C.</forenames></author><author><keyname>Veeravalli</keyname><forenames>V. V.</forenames></author><author><keyname>Meyn</keyname><forenames>S.</forenames></author></authors><title>A Random Search Framework for Convergence Analysis of Distributed
  Beamforming with Feedback</title><categories>cs.DC cs.IT math.IT</categories><comments>8 pages, 3 figures, presented partially at ITA '08 and PSU School of
  Info. Theory '08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of this work is on the analysis of transmit beamforming schemes
with a low-rate feedback link in wireless sensor/relay networks, where nodes in
the network need to implement beamforming in a distributed manner.
Specifically, the problem of distributed phase alignment is considered, where
neither the transmitters nor the receiver has perfect channel state
information, but there is a low-rate feedback link from the receiver to the
transmitters. In this setting, a framework is proposed for systematically
analyzing the performance of distributed beamforming schemes. To illustrate the
advantage of this framework, a simple adaptive distributed beamforming scheme
that was recently proposed by Mudambai et al. is studied. Two important
properties for the received signal magnitude function are derived. Using these
properties and the systematic framework, it is shown that the adaptive
distributed beamforming scheme converges both in probability and in mean.
Furthermore, it is established that the time required for the adaptive scheme
to converge in mean scales linearly with respect to the number of sensor/relay
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3031</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3031</id><created>2008-06-18</created><authors><author><keyname>Monteiro</keyname><forenames>Thibaud</forenames><affiliation>LGIPM, INRIA Lorraine</affiliation></author><author><keyname>Roy</keyname><forenames>Daniel</forenames><affiliation>LGIPM, INRIA Lorraine</affiliation></author><author><keyname>Anciaux</keyname><forenames>Didier</forenames><affiliation>LGIPM, INRIA Lorraine</affiliation></author></authors><title>Multi Site Coordination using a Multi-Agent System</title><categories>cs.MA</categories><proxy>ccsd hal-00288760</proxy><journal-ref>Computers in Industry 58, 4 (2007) pp. 367-377</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach of coordination of decisions in a multi site system is
proposed. It is based this approach on a multi-agent concept and on the
principle of distributed network of enterprises. For this purpose, each
enterprise is defined as autonomous and performs simultaneously at the local
and global levels. The basic component of our approach is a so-called Virtual
Enterprise Node (VEN), where the enterprise network is represented as a set of
tiers (like in a product breakdown structure). Within the network, each partner
constitutes a VEN, which is in contact with several customers and suppliers.
Exchanges between the VENs ensure the autonomy of decision, and guarantiee the
consistency of information and material flows. Only two complementary VEN
agents are necessary: one for external interactions, the Negotiator Agent (NA)
and one for the planning of internal decisions, the Planner Agent (PA). If
supply problems occur in the network, two other agents are defined: the Tier
Negotiator Agent (TNA) working at the tier level only and the Supply Chain
Mediator Agent (SCMA) working at the level of the enterprise network. These two
agents are only active when the perturbation occurs. Otherwise, the VENs
process the flow of information alone. With this new approach, managing
enterprise network becomes much more transparent and looks like managing a
simple enterprise in the network. The use of a Multi-Agent System (MAS) allows
physical distribution of the decisional system, and procures a heterarchical
organization structure with a decentralized control that guaranties the
autonomy of each entity and the flexibility of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3032</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3032</id><created>2008-06-18</created><authors><author><keyname>Roy</keyname><forenames>Daniel</forenames><affiliation>LGIPM, Inria Lorraine - Loria</affiliation></author><author><keyname>Anciaux</keyname><forenames>Didier</forenames><affiliation>LGIPM, Inria Lorraine - Loria</affiliation></author><author><keyname>Monteiro</keyname><forenames>Thibaud</forenames><affiliation>LGIPM, Inria Lorraine - Loria</affiliation></author><author><keyname>Ouzizi</keyname><forenames>Latifa</forenames><affiliation>LGIPM, Inria Lorraine - Loria</affiliation></author></authors><title>Multi-agents architecture for supply chain management</title><categories>cs.MA</categories><proxy>ccsd hal-00288755</proxy><journal-ref>Journal of Manufacturing Technology Management 15, 8 (2004) pp.
  745-755</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to propose a new approach for the supply chain
management. This approach is based on the virtual enterprise paradigm and the
used of multi-agent concept. Each entity (like enterprise) is autonomous and
must perform local and global goals in relation with its environment. The base
component of our approach is a Virtual Enterprise Node (VEN). The supply chain
is viewed as a set of tiers (corresponding to the levels of production), in
which each partner of the supply chain (VEN) is in relation with several
customers and suppliers. Each VEN belongs to one tier. The main customer gives
global objectives (quantity, cost and delay) to the supply chain. The Mediator
Agent (MA) is in charge to manage the supply chain in order to respect those
objectives as global level. Those objectives are taking over to Negotiator
Agent at the tier level (NAT). These two agents are only active if a
perturbation occurs; otherwise information flows are only exchange between
VENs. This architecture allows supply chains management which is completely
transparent seen from simple enterprise of the supply chain. The used of
Multi-Agent System (MAS) allows physical distribution of the decisional system.
Moreover, the hierarchical organizational structure with a decentralized
control guaranties, in the same time, the autonomy of each entity and the whole
flexibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3033</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3033</id><created>2008-06-18</created><updated>2009-01-05</updated><authors><author><keyname>Guignard</keyname><forenames>Adrien</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Sopena</keyname><forenames>Eric</forenames><affiliation>LaBRI</affiliation></author></authors><title>Compound Node-Kayles on Paths</title><categories>cs.DM</categories><comments>Theoretical Computer Science (2009) to appear</comments><proxy>ccsd hal-00288659</proxy><journal-ref>Theoretical Computer Science 410, 21-23 (2009) 2033-2044</journal-ref><doi>10.1016/j.tcs.2008.12.053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In his celebrated book &quot;On Number and Games&quot; (Academic Press, New-York,
1976), J.H. Conway introduced twelve versions of compound games. We analyze
these twelve versions for the Node-Kayles game on paths. For usual disjunctive
compound, Node-Kayles has been solved for a long time under normal play, while
it is still unsolved under mis\`ere play. We thus focus on the ten remaining
versions, leaving only one of them unsolved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3099</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3099</id><created>2008-06-18</created><updated>2008-06-20</updated><authors><author><keyname>Turner</keyname><forenames>D. Z.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Hjelmstad</keyname><forenames>K. D.</forenames></author></authors><title>On the stability of bubble functions and a stabilized mixed finite
  element formulation for the Stokes problem</title><categories>cs.NA</categories><comments>25 pages, 13 figures (The previous version was compiled by mistake
  with the wrong style file, the current one uses amsart, and there is no
  difference in the text or the figures)</comments><doi>10.1002/fld.1936</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the relationship between stabilized and enriched
finite element formulations for the Stokes problem. We also present a new
stabilized mixed formulation for which the stability parameter is derived
purely by the method of weighted residuals. This new formulation allows equal
order interpolation for the velocity and pressure fields. Finally, we show by
counterexample that a direct equivalence between subgrid-based stabilized
finite element methods and Galerkin methods enriched by bubble functions cannot
be constructed for quadrilateral and hexahedral elements using standard bubble
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3115</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3115</id><created>2008-06-18</created><authors><author><keyname>Hazel</keyname><forenames>Dan</forenames><affiliation>Technology One</affiliation></author></authors><title>Using rational numbers to key nested sets</title><categories>cs.DB</categories><comments>18 pages</comments><report-no>DocSetID-311997</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report details the generation and use of tree node ordering keys in a
single relational database table. The keys for each node are calculated from
the keys of its parent, in such a way that the sort order places every node in
the tree before all of its descendants and after all siblings having a lower
index. The calculation from parent keys to child keys is simple, and reversible
in the sense that the keys of every ancestor of a node can be calculated from
that node's keys without having to consult the database.
  Proofs of the above properties of the key encoding process and of its
correspondence to a finite continued fraction form are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3121</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3121</id><created>2008-06-18</created><authors><author><keyname>Bosilca</keyname><forenames>George</forenames></author><author><keyname>Delmas</keyname><forenames>Remi</forenames></author><author><keyname>Dongarra</keyname><forenames>Jack</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author></authors><title>Algorithmic Based Fault Tolerance Applied to High Performance Computing</title><categories>cs.DC cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach to fault tolerance for High Performance Computing
system. Our approach is based on a careful adaptation of the Algorithmic Based
Fault Tolerance technique (Huang and Abraham, 1984) to the need of parallel
distributed computation. We obtain a strongly scalable mechanism for fault
tolerance. We can also detect and correct errors (bit-flip) on the fly of a
computation. To assess the viability of our approach, we have developed a fault
tolerant matrix-matrix multiplication subroutine and we propose some models to
predict its running time. Our parallel fault-tolerant matrix-matrix
multiplication scores 1.4 TFLOPS on 484 processors (cluster jacquard.nersc.gov)
and returns a correct result while one process failure has happened. This
represents 65% of the machine peak efficiency and less than 12% overhead with
respect to the fastest failure-free implementation. We predict (and have
observed) that, as we increase the processor count, the overhead of the fault
tolerance drops significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3133</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3133</id><created>2008-06-19</created><authors><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Kanter</keyname><forenames>Ido</forenames></author></authors><title>Shannon Meets Carnot: Mutual Information Via Thermodynamics</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, the Gaussian channel is represented as an equivalent
thermal system allowing to express its input-output mutual information in terms
of thermodynamic quantities. This thermodynamic description of the mutual
information is based upon a generalization of the $2^{nd}$ thermodynamic law
and provides an alternative proof to the Guo-Shamai-Verd\'{u} theorem, giving
an intriguing connection between this remarkable theorem and the most
fundamental laws of nature - the laws of thermodynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3152</identifier>
 <datestamp>2008-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3152</id><created>2008-06-19</created><updated>2008-08-30</updated><authors><author><keyname>Kontopoulos</keyname><forenames>Stavros</forenames></author><author><keyname>Tsakalidis</keyname><forenames>Athanasios K.</forenames></author></authors><title>TRANS-Net: an Efficient Peer-to-Peer Overlay Network Based on a Full
  Transposition Graph</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a new practical P2P system based on a full
transposition network topology named TRANS-Net. Full transposition networks
achieve higher fault-tolerance and lower congestion among the class of
transposition networks. TRANS-Net provides an efficient lookup service i.e. k
hops with high probability, where k satisfies Theta(log_n m) less than k less
than Theta(log_2 m), where m denotes the number of system nodes and n is a
system parameter related to the maximum number that m can take (up to n!).
Experiments show that the look-up performance achieves the lower limit of the
complexity relation. TRANS-Net also preserves data locality and provides
efficient look-up performance for complex queries such as multi-dimensional
queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3201</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3201</id><created>2008-06-19</created><authors><author><keyname>Kossinets</keyname><forenames>Gueorgi</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author><author><keyname>Watts</keyname><forenames>Duncan</forenames></author></authors><title>The Structure of Information Pathways in a Social Communication Network</title><categories>physics.soc-ph cs.DS physics.data-an</categories><comments>9 pages, 10 figures, to appear in Proceedings of the 14th ACM SIGKDD
  International Conference on Knowledge Discovery and Data Mining (KDD'08),
  August 24-27, 2008, Las Vegas, Nevada, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks are of interest to researchers in part because they are
thought to mediate the flow of information in communities and organizations.
Here we study the temporal dynamics of communication using on-line data,
including e-mail communication among the faculty and staff of a large
university over a two-year period. We formulate a temporal notion of &quot;distance&quot;
in the underlying social network by measuring the minimum time required for
information to spread from one node to another -- a concept that draws on the
notion of vector-clocks from the study of distributed computing systems. We
find that such temporal measures provide structural insights that are not
apparent from analyses of the pure social network topology. In particular, we
define the network backbone to be the subgraph consisting of edges on which
information has the potential to flow the quickest. We find that the backbone
is a sparse graph with a concentration of both highly embedded edges and
long-range bridges -- a finding that sheds new light on the relationship
between tie strength and connectivity in social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3209</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3209</id><created>2008-06-19</created><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>A Computer Verified Theory of Compact Sets</title><categories>cs.LO</categories><comments>This paper is to be part of the proceedings of the Symbolic
  Computation in Software Science Austrian-Japanese Workshop (SCSS 2008)</comments><report-no>RISC-Linz Report Series 08-08</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Compact sets in constructive mathematics capture our intuition of what
computable subsets of the plane (or any other complete metric space) ought to
be. A good representation of compact sets provides an efficient means of
creating and displaying images with a computer. In this paper, I build upon
existing work about complete metric spaces to define compact sets as the
completion of the space of finite sets under the Hausdorff metric. This
definition allowed me to quickly develop a computer verified theory of compact
sets. I applied this theory to compute provably correct plots of uniformly
continuous functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3215</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3215</id><created>2008-06-19</created><authors><author><keyname>Lin</keyname><forenames>Xiahong</forenames></author><author><keyname>Gao</keyname><forenames>Lin</forenames></author><author><keyname>Chen</keyname><forenames>Kefei</forenames></author><author><keyname>Chiu</keyname><forenames>David K. Y.</forenames></author></authors><title>MOHCS: Towards Mining Overlapping Highly Connected Subgraphs</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many networks in real-life typically contain parts in which some nodes are
more highly connected to each other than the other nodes of the network. The
collection of such nodes are usually called clusters, communities, cohesive
groups or modules. In graph terminology, it is called highly connected graph.
In this paper, we first prove some properties related to highly connected
graph. Based on these properties, we then redefine the highly connected
subgraph which results in an algorithm that determines whether a given graph is
highly connected in linear time. Then we present a computationally efficient
algorithm, called MOHCS, for mining overlapping highly connected subgraphs. We
have evaluated experimentally the performance of MOHCS using real and synthetic
data sets from computer-generated graph and yeast protein network. Our results
show that MOHCS is effective and reliable in finding overlapping highly
connected subgraphs. Keywords-component; Highly connected subgraph, clustering
algorithms, minimum cut, minimum degree
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3227</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3227</id><created>2008-06-19</created><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Non-differential Distributed Space-Time Coding for Partially-Coherent
  Cooperative Communication</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Wireless Communications. 06 pages,
  04 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a distributed space-time coding scheme, based on the relay channel model,
the relay nodes co-operate to linearly process the transmitted signal from the
source and forward them to the destination such that the signal at the
destination appears as a space time block code. Recently, a code design
criteria for achieving full diversity in a partially-coherent environment have
been proposed along with codes based on differential encoding and decoding
techniques. For such a set up, in this paper, a non-differential encoding
technique and construction of distributed space time block codes from unitary
matrix groups at the source and a set of diagonal unitary matrices for the
relays are proposed. It is shown that, the performance of our scheme is
independent of the choice of unitary matrices at the relays. When the group is
cyclic, a necessary and sufficient condition on the generator of the cyclic
group to achieve full diversity and to minimize the pairwise error probability
is proved. Various choices on the generator of cyclic group to reduce the ML
decoding complexity at the destination is presented. It is also shown that, at
the source, if non-cyclic abelian unitary matrix groups are used, then
full-diversity can not be obtained. The presented scheme is also robust to
failure of any subset of relay nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3243</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3243</id><created>2008-06-19</created><updated>2011-06-24</updated><authors><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Analysis of Verification-based Decoding on the q-ary Symmetric Channel
  for Large q</title><categories>cs.IT math.IT</categories><comments>This is the final version for IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss and analyze a list-message-passing decoder with verification for
low-density parity-check (LDPC) codes on the q-ary symmetric channel (q-SC).
Rather than passing messages consisting of symbol probabilities, this decoder
passes lists of possible symbols and marks some lists as verified. The density
evolution (DE) equations for this decoder are derived and used to compute
decoding thresholds. If the maximum list size is unbounded, then we find that
any capacity-achieving LDPC code for the binary erasure channel can be used to
achieve capacity on the q-SC for large q. The decoding thresholds are also
computed via DE for the case where each list is truncated to satisfy a maximum
list size constraint. Simulation results are also presented to confirm the DE
results. During the simulations, we observed differences between two
verification-based decoding algorithms, introduced by Luby and Mitzenmacher,
that were implicitly assumed to be identical. In this paper, we provide an
analysis of the node-based algorithms from that paper and verify that it
matches simulation results. The probability of false verification (FV) is also
considered and techniques are discussed to mitigate the FV. Optimization of the
degree distribution is also used to improve the threshold for a fixed maximum
list size. Finally, the proposed algorithm is compared with a variety of other
algorithms using both density evolution thresholds and simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3246</identifier>
 <datestamp>2008-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3246</id><created>2008-06-19</created><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Hasidim</keyname><forenames>Avinatan</forenames></author><author><keyname>Lubetzky</keyname><forenames>Eyal</forenames></author><author><keyname>Stav</keyname><forenames>Uri</forenames></author><author><keyname>Weinstein</keyname><forenames>Amit</forenames></author></authors><title>Broadcasting with side information</title><categories>cs.IT math.IT</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sender holds a word x consisting of n blocks x_i, each of t bits, and
wishes to broadcast a codeword to m receivers, R_1,...,R_m. Each receiver R_i
is interested in one block, and has prior side information consisting of some
subset of the other blocks. Let \beta_t be the minimum number of bits that has
to be transmitted when each block is of length t, and let \beta be the limit
\beta = \lim_{t \to \infty} \beta_t/t. In words, \beta is the average
communication cost per bit in each block (for long blocks). Finding the coding
rate \beta, for such an informed broadcast setting, generalizes several coding
theoretic parameters related to Informed Source Coding on Demand, Index Coding
and Network Coding.
  In this work we show that usage of large data blocks may strictly improve
upon the trivial encoding which treats each bit in the block independently. To
this end, we provide general bounds on \beta_t, and prove that for any constant
C there is an explicit broadcast setting in which \beta = 2 but \beta_1 &gt; C.
One of these examples answers a question of Lubetzky and Stav.
  In addition, we provide examples with the following counterintuitive
direct-sum phenomena. Consider a union of several mutually independent
broadcast settings. The optimal code for the combined setting may yield a
significant saving in communication over concatenating optimal encodings for
the individual settings. This result also provides new non-linear coding
schemes which improve upon the largest known gap between linear and non-linear
Network Coding, thus improving the results of Dougherty, Freiling, and Zeger.
  The proofs use ideas related to Witsenhausen's rate, OR graph products,
colorings of Cayley graphs and the chromatic numbers of Kneser graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3258</identifier>
 <datestamp>2015-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3258</id><created>2008-06-19</created><updated>2009-07-25</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author></authors><title>Local Search Heuristics For The Multidimensional Assignment Problem</title><categories>cs.DS</categories><comments>30 pages. A preliminary version is published in volume 5420 of
  Lecture Notes Comp. Sci., pages 100-115, 2009</comments><journal-ref>Journal of Heuristics 17(3) (2011), 201--249</journal-ref><doi>10.1007/s10732-010-9133-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Multidimensional Assignment Problem (MAP) (abbreviated s-AP in the case
of s dimensions) is an extension of the well-known assignment problem. The most
studied case of MAP is 3-AP, though the problems with larger values of s also
have a large number of applications. We consider several known neighborhoods,
generalize them and propose some new ones. The heuristics are evaluated both
theoretically and experimentally and dominating algorithms are selected. We
also demonstrate a combination of two neighborhoods may yield a heuristics
which is superior to both of its components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3277</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3277</id><created>2008-06-19</created><updated>2008-06-21</updated><authors><author><keyname>Foldes</keyname><forenames>Stephan</forenames></author></authors><title>On McMillan's theorem about uniquely decipherable codes</title><categories>math.CO cs.IT math.IT</categories><msc-class>05E99, 94A45, 20M05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Karush's proof of McMillan's theorem is recast as an argument involving
polynomials with non-commuting indeterminates certain evaluations of which
yield the Kraft sums of codes, proving a strengthened version of McMillan's
theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3284</identifier>
 <datestamp>2009-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3284</id><created>2008-06-20</created><updated>2009-10-15</updated><authors><author><keyname>Gordon</keyname><forenames>Daniel M.</forenames></author><author><keyname>Miller</keyname><forenames>Victor</forenames></author><author><keyname>Ostapenko</keyname><forenames>Peter</forenames></author></authors><title>Optimal hash functions for approximate closest pairs on the n-cube</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One way to find closest pairs in large datasets is to use hash functions. In
recent years locality-sensitive hash functions for various metrics have been
given: projecting an n-cube onto k bits is simple hash function that performs
well. In this paper we investigate alternatives to projection. For various
parameters hash functions given by complete decoding algorithms for codes work
better, and asymptotically random codes perform better than projection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3301</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3301</id><created>2008-06-19</created><updated>2009-05-12</updated><authors><author><keyname>Tibshirani</keyname><forenames>Ryan J.</forenames></author></authors><title>Fast computation of the median by successive binning</title><categories>stat.CO cs.DS stat.AP</categories><comments>14 pages, 1 Postscript figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new median algorithm and a median approximation
algorithm. The former has O(n) average running time and the latter has O(n)
worst-case running time. These algorithms are highly competitive with the
standard algorithm when computing the median of a single data set, but are
significantly faster in updating the median when more data is added.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3317</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3317</id><created>2008-06-20</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Tjhung</keyname><forenames>Tjeng Thiang</forenames></author></authors><title>Differential Transmit Diversity Based on Quasi-Orthogonal Space-Time
  Block Code</title><categories>cs.IT math.IT</categories><journal-ref>Globecom 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By using joint modulation and customized constellation set, we show that
Quasi-Orthogonal Space-Time Block Code (QO-STBC) can be used to form a new
differential space-time modulation (DSTM) scheme to provide full transmit
diversity with non-coherent detection. Our new scheme can provide higher code
rate than existing DSTM schemes based on Orthogonal STBC. It also has a lower
decoding complexity than the other DSTM schemes, such as those based on Group
Codes, because it only requires a joint detection of two complex symbols. We
derive the design criteria for the customized constellation set and use them to
construct a constellation set that provides a wide range of spectral efficiency
with full diversity and maximum coding gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3320</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3320</id><created>2008-06-20</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Tjhung</keyname><forenames>T. T.</forenames></author></authors><title>Unitary Differential Space-Time Modulation with Joint Modulation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop two new designs of unitary differential space-time modulation
(DSTM) with low decoding complexity. Their decoder can be separated into a few
parallel decoders, each of which has a decoding search space of less than
sqrt(N) if the DSTM codebook contains N codewords. Both designs are based on
the concept of joint modulation, which means that several information symbols
are jointly modulated, unlike the conventional symbol-by-symbol modulation. The
first design is based on Orthogonal Space-Time Block Code (O-STBC) with joint
constellation constructed from spherical codes. The second design is based on
Quasi-Orthogonal Space-Time Block Code (QO-STBC) with specially designed
pair-wise constellation sets. Both the proposed unitary DSTM schemes have
considerably lower decoding complexity than many prior DSTM schemes, including
those based on Group Codes and Sp(2) which generally have a decoding search
space of N for a codebook size of N codewords, and much better decoding
performance than the existing O-STBC DSTM scheme. Between two designs, the
proposed DSTM based on O-STBC generally has better decoding performance, while
the proposed DSTM based on QO-STBC has lower decoding complexity when 8
transmit antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3321</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3321</id><created>2008-06-20</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Hochwald</keyname><forenames>Bertrand M.</forenames></author></authors><title>Achieving Near-Capacity at Low SNR on a Multiple-Antenna Multiple-User
  Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the sensitivity of the capacity of a multi-antenna multi-user
system to the number of users being served. We show analytically that, for a
given desired sum-rate, the extra power needed to serve a subset of the users
at low SNR (signal-to-noise ratio) can be very small, and is generally much
smaller than the extra power needed to serve the same subset at high SNR. The
advantages of serving only subsets of the users are many: multi-user algorithms
have lower complexity, reduced channel-state information requirements, and,
often, better performance. We provide guidelines on how many users to serve to
get near-capacity performance with low complexity. For example, we show how in
an eight-antenna eight-user system we can serve only four users and still be
approximately 2 dB from capacity at very low SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3322</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3322</id><created>2008-06-20</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Tjhung</keyname><forenames>Tjeng Thiang</forenames></author></authors><title>Power-Balanced Orthogonal Space-Time Block Code</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose two new systematic ways to construct amicable
orthogonal designs (AOD), with an aim to facilitate the construction of
power-balanced orthogonal spacetime block codes (O-STBC) with favorable
practical attributes. We also show that an AOD can be constructed from an
Amicable Family (AF), and such a construction is crucial for achieving a
power-balanced O-STBC. In addition, we develop design guidelines on how to
select the &quot;type&quot; parameter of an AOD so that the resultant O-STBC will have
better power-distribution and code-coefficient attributes. Among the new
O-STBCs obtained, one is shown to be optimal in terms of power distribution
attributes. In addition, one of the proposed construction methods is shown to
generalize some other construction methods proposed in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3324</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3324</id><created>2008-06-20</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Tjhung</keyname><forenames>Tjeng Thiang</forenames></author></authors><title>Optimizing Quasi-Orthogonal STBC Through Group-Constrained Linear
  Transformation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first derive the generic algebraic structure of a
Quasi-Orthogonal STBC (QO-STBC). Next we propose Group-Constrained Linear
Transformation (GCLT) as a means to optimize the diversity and coding gains of
a QO-STBC with square or rectangular QAM constellations. Compared with QO-STBC
with constellation rotation (CR), we show that QO-STBC with GCLT requires only
half the number of symbols for joint detection, hence lower maximum-likelihood
decoding complexity. We also derive analytically the optimum GCLT parameters
for QO-STBC with square QAM constellation. The optimized QO-STBCs with GCLT are
able to achieve full transmit diversity, and have negligible performance loss
compared with QO-STBCs with CR at the same code rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3325</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3325</id><created>2008-06-20</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Tjhung</keyname><forenames>Tjeng Thiang</forenames></author></authors><title>On the Search for High-Rate Quasi-Orthogonal Space-Time Block Code</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Quasi-Orthogonal Space-Time Block Code (QO-STBC) is attractive because it
achieves higher code rate than Orthogonal STBC and lower decoding complexity
than nonorthogonal STBC. In this paper, we first derive the algebraic structure
of QO-STBC, then we apply it in a novel graph-based search algorithm to find
high-rate QO-STBCs with code rates greater than 1. From the four-antenna codes
found using this approach, it is found that the maximum code rate is limited to
5/4 with symbolwise diversity level of four, and 4 with symbolwise diversity
level of two. The maximum likelihood decoding of these high-rate QO-STBCs can
be performed on two separate sub-groups of symbols. The rate-5/4 codes are the
first known QO-STBCs with code rate greater 1 that has full symbolwise
diversity level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3328</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3328</id><created>2008-06-20</created><authors><author><keyname>Chua</keyname><forenames>Wee Seng</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Chin</keyname><forenames>Francois</forenames></author></authors><title>Limited Feedback for Multi-Antenna Multi-user Communications with
  Generalized Multi-Unitary Decomposition</title><categories>cs.IT math.IT</categories><comments>PIMRC 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a decomposition method called Generalized
Multi-Unitary Decomposition (GMUD) which is useful in multi-user MIMO
precoding. This decomposition transforms a complex matrix H into PRQ, where R
is a special matrix whose first row contains only a non-zero user defined value
at the left-most position, P and Q are a pair of unitary matrices. The major
attraction of our proposed GMUD is we can obtain multiple solutions of P and Q
&gt;. With GMUD, we propose a precoding method for a MIMO multi-user system that
does not require full channel state information (CSI) at the transmitter. The
proposed precoding method uses the multiple unitary matrices property to
compensate the inaccurate feedback information as the transmitter can steer the
transmission beams of individual users such that the inter-user interference is
kept minimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3329</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3329</id><created>2008-06-20</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Sun</keyname><forenames>Sumei</forenames></author><author><keyname>Ho</keyname><forenames>Mel Meau Shin</forenames></author></authors><title>Beamforming Matrix Quantization with Variable Feedback Rate</title><categories>cs.IT math.IT</categories><comments>PIMRC 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an improved beamforming matrix compression by Givens Rotation with
the use of variable feedback rate. The variable feedback rate means that the
number of bits used to represent the quantized beamforming matrix is based on
the value of the matrix. Compared with the fixed feedback rate scheme, the
proposed method has better performance without additional feedback bandwidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3332</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3332</id><created>2008-06-20</created><updated>2009-03-16</updated><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Compressed Sensing of Analog Signals in Shift-Invariant Spaces</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Trans. on Signal Processing</comments><doi>10.1109/TSP.2009.2020750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A traditional assumption underlying most data converters is that the signal
should be sampled at a rate exceeding twice the highest frequency. This
statement is based on a worst-case scenario in which the signal occupies the
entire available bandwidth. In practice, many signals are sparse so that only
part of the bandwidth is used. In this paper, we develop methods for low-rate
sampling of continuous-time sparse signals in shift-invariant (SI) spaces,
generated by m kernels with period T. We model sparsity by treating the case in
which only k out of the m generators are active, however, we do not know which
k are chosen. We show how to sample such signals at a rate much lower than m/T,
which is the minimal sampling rate without exploiting sparsity. Our approach
combines ideas from analog sampling in a subspace with a recently developed
block diagram that converts an infinite set of sparse equations to a finite
counterpart. Using these two components we formulate our problem within the
framework of finite compressed sensing (CS) and then rely on algorithms
developed in that context. The distinguishing feature of our results is that in
contrast to standard CS, which treats finite-length vectors, we consider
sampling of analog signals for which no underlying finite-dimensional model
exists. The proposed framework allows to extend much of the recent literature
on CS to the analog domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3437</identifier>
 <datestamp>2008-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3437</id><created>2008-06-20</created><authors><author><keyname>Dinh</keyname><forenames>Hang</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author></authors><title>Quantum and Randomized Lower Bounds for Local Search on
  Vertex-Transitive Graphs</title><categories>quant-ph cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of \emph{local search} on a graph. Given a real-valued
black-box function f on the graph's vertices, this is the problem of
determining a local minimum of f--a vertex v for which f(v) is no more than f
evaluated at any of v's neighbors. In 1983, Aldous gave the first strong lower
bounds for the problem, showing that any randomized algorithm requires
$\Omega(2^{n/2 - o(1)})$ queries to determine a local minima on the
n-dimensional hypercube. The next major step forward was not until 2004 when
Aaronson, introducing a new method for query complexity bounds, both
strengthened this lower bound to $\Omega(2^{n/2}/n^2)$ and gave an analogous
lower bound on the quantum query complexity. While these bounds are very
strong, they are known only for narrow families of graphs (hypercubes and
grids). We show how to generalize Aaronson's techniques in order to give
randomized (and quantum) lower bounds on the query complexity of local search
for the family of vertex-transitive graphs. In particular, we show that for any
vertex-transitive graph G of N vertices and diameter d, the randomized and
quantum query complexities for local search on G are $\Omega(N^{1/2}/d\log N)$
and $\Omega(N^{1/4}/\sqrt{d\log N})$, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3456</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3456</id><created>2008-06-20</created><authors><author><keyname>Elbassioni</keyname><forenames>Khaled</forenames></author><author><keyname>Tiwary</keyname><forenames>Hans Raj</forenames></author></authors><title>On Computing the Vertex Centroid of a Polyhedron</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal{P}$ be an $\mathcal{H}$-polytope in $\mathbb{R}^d$ with vertex
set $V$. The vertex centroid is defined as the average of the vertices in $V$.
We prove that computing the vertex centroid of an $\mathcal{H}$-polytope is
#P-hard. Moreover, we show that even just checking whether the vertex centroid
lies in a given halfspace is already #P-hard for $\mathcal{H}$-polytopes. We
also consider the problem of approximating the vertex centroid by finding a
point within an $\epsilon$ distance from it and prove this problem to be
#P-easy by showing that given an oracle for counting the number of vertices of
an $\mathcal{H}$-polytope, one can approximate the vertex centroid in
polynomial time. We also show that any algorithm approximating the vertex
centroid to \emph{any} ``sufficiently'' non-trivial (for example constant)
distance, can be used to construct a fully polynomial approximation scheme for
approximating the centroid and also an output-sensitive polynomial algorithm
for the Vertex Enumeration problem. Finally, we show that for unbounded
polyhedra the vertex centroid can not be approximated to a distance of
$d^{{1/2}-\delta}$ for any fixed constant $\delta&gt;0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3471</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3471</id><created>2008-06-20</created><updated>2010-06-15</updated><authors><author><keyname>Canepa</keyname><forenames>Davide</forenames></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria Gradinariu</forenames></author></authors><title>Stabilizing Tiny Interaction Protocols</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the self-stabilizing implementation of a class of
token based algorithms. In the current work we only consider interactions
between weak nodes. They are uniform, they do not have unique identifiers, are
static and their interactions are restricted to a subset of nodes called
neighbours. While interacting, a pair of neighbouring nodes may create mobile
agents (that materialize in the current work the token abstraction) that
perform traversals of the network and accelerate the system stabilization. In
this work we only explore the power of oblivious stateless agents.
  Our work shows that the agent paradigm is an elegant distributed tool for
achieving self-stabilization in Tiny Interaction Protocols (TIP). Nevertheless,
in order to reach the full power of classical self-stabilizing algorithms more
complex classes of agents have to be considered (e.g. agents with memory,
identifiers or communication skills). Interestingly, our work proposes for the
first time a model that unifies the recent studies in mobile robots(agents)
that evolve in a discrete space and the already established population
protocols paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3474</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3474</id><created>2008-06-20</created><updated>2009-09-29</updated><authors><author><keyname>Ensslin</keyname><forenames>Torsten A.</forenames></author><author><keyname>Frommert</keyname><forenames>Mona</forenames></author><author><keyname>Kitaura</keyname><forenames>Francisco S.</forenames></author></authors><title>Information field theory for cosmological perturbation reconstruction
  and non-linear signal analysis</title><categories>astro-ph cs.IT hep-th math.IT physics.data-an stat.CO</categories><comments>38 pages, 6 figures, LaTeX; version accepted by PRD</comments><report-no>J-MPA2270e</report-no><doi>10.1103/PhysRevD.80.105005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop information field theory (IFT) as a means of Bayesian inference on
spatially distributed signals, the information fields. A didactical approach is
attempted. Starting from general considerations on the nature of measurements,
signals, noise, and their relation to a physical reality, we derive the
information Hamiltonian, the source field, propagator, and interaction terms.
Free IFT reproduces the well known Wiener-filter theory. Interacting IFT can be
diagrammatically expanded, for which we provide the Feynman rules in position-,
Fourier-, and spherical harmonics space, and the Boltzmann-Shannon information
measure. The theory should be applicable in many fields. However, here, two
cosmological signal recovery problems are discussed in their IFT-formulation.
1) Reconstruction of the cosmic large-scale structure matter distribution from
discrete galaxy counts in incomplete galaxy surveys within a simple model of
galaxy formation. We show that a Gaussian signal, which should resemble the
initial density perturbations of the Universe, observed with a strongly
non-linear, incomplete and Poissonian-noise affected response, as the processes
of structure and galaxy formation and observations provide, can be
reconstructed thanks to the virtue of a response-renormalization flow equation.
2) We design a filter to detect local non-linearities in the cosmic microwave
background, which are predicted from some Early-Universe inflationary
scenarios, and expected due to measurement imperfections. This filter is the
optimal Bayes' estimator up to linear order in the non-linearity parameter and
can be used even to construct sky maps of non-linearities in the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3480</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3480</id><created>2008-06-20</created><updated>2009-12-13</updated><authors><author><keyname>German</keyname><forenames>Oleg</forenames></author><author><keyname>Lakshtanov</keyname><forenames>Evgeny</forenames></author></authors><title>&quot;Minesweeper&quot; and spectrum of discrete Laplacians</title><categories>cs.DM</categories><comments>We add consideration of tables based on the triangle tiling of the
  plane. Its paper version encounters situations typical for the computer
  &quot;Minesweeper&quot; game</comments><journal-ref>Applicable Analysis, Vol. 89, No. 12, December 2010, 1907-1916</journal-ref><doi>10.1080/00036811.2010.505189</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to a problem inspired by the &quot;Minesweeper&quot; computer
game. It is shown that certain configurations of open cells guarantee the
existence and the uniqueness of solution. Mathematically the problem is reduced
to some spectral properties of discrete differential operators. It is shown how
the uniqueness can be used to create a new game which preserves the spirit of
&quot;Minesweeper&quot; but does not require a computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3514</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3514</id><created>2008-06-21</created><authors><author><keyname>Turner</keyname><forenames>D. Z.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Hjelmstad</keyname><forenames>K. D.</forenames></author></authors><title>Consistent Newton-Raphson vs. fixed-point for variational multiscale
  formulations for incompressible Navier-Stokes</title><categories>cs.NA</categories><comments>32 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following paper compares a consistent Newton-Raphson and fixed-point
iteration based solution strategy for a variational multiscale finite element
formulation for incompressible Navier-Stokes. The main contributions of this
work include a consistent linearization of the Navier-Stokes equations, which
provides an avenue for advanced algorithms that require origins in a consistent
method. We also present a comparison between formulations that differ only in
their linearization, but maintain all other equivalences. Using the variational
multiscale concept, we construct a stabilized formulation (that may be
considered an extension of the MINI element to nonlinear Navier-Stokes). We
then linearize the problem using fixed-point iteration and by deriving a
consistent tangent matrix for the update equation to obtain the solution via
Newton-Raphson iterations. We show that the consistent formulation converges in
fewer iterations, as expected, for several test problems. We also show that the
consistent formulation converges for problems for which fixed-point iteration
diverges. We present the results of both methods for problems of Reynold's
number up to 5000.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3536</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3536</id><created>2008-06-21</created><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>In Pursuit of Spreadsheet Excellence</title><categories>cs.SE cs.HC</categories><comments>7 pages, 2 tables. To Appear Proc. European Spreadsheet Risks
  Interest Group, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first fully-documented study into the quantitative impact of errors in
operational spreadsheets identified an interesting anomaly. One of the five
participating organisations involved in the study contributed a set of five
spreadsheets of such quality that they set the organisation apart in a
statistical sense. This virtuoso performance gave rise to a simple sampling
test - The Clean Sheet Test - which can be used to objectively evaluate if an
organisation is in control of the spreadsheets it is using in important
processes such as financial reporting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3537</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3537</id><created>2008-06-21</created><updated>2008-07-09</updated><authors><author><keyname>Soloveichik</keyname><forenames>David</forenames></author></authors><title>Statistical Learning of Arbitrary Computable Classifiers</title><categories>cs.LG</categories><comments>Expanded the section on prior work and added references</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical learning theory chiefly studies restricted hypothesis classes,
particularly those with finite Vapnik-Chervonenkis (VC) dimension. The
fundamental quantity of interest is the sample complexity: the number of
samples required to learn to a specified level of accuracy. Here we consider
learning over the set of all computable labeling functions. Since the
VC-dimension is infinite and a priori (uniform) bounds on the number of samples
are impossible, we let the learning algorithm decide when it has seen
sufficient samples to have learned. We first show that learning in this setting
is indeed possible, and develop a learning algorithm. We then show, however,
that bounding sample complexity independently of the distribution is
impossible. Notably, this impossibility is entirely due to the requirement that
the learning algorithm be computable, and not due to the statistical nature of
the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3542</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3542</id><created>2008-06-21</created><authors><author><keyname>Lee</keyname><forenames>Jiwoong</forenames></author><author><keyname>Walrand</keyname><forenames>Jean C.</forenames></author></authors><title>Design and Analysis of an Asynchronous Zero Collision MAC Protocol</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes and analyzes a distributed MAC protocol that achieves
zero collision with no control message exchange nor synchronization. ZC
(ZeroCollision) is neither reservation-based nor dynamic TDMA; the protocol
supports variable-length packets and does not lose efficiency when some of the
stations do not transmit. At the same time, ZC is not a CSMA; in its steady
state, it is completely collision-free. The stations transmit repeatedly in a
round-robin order once the convergence state is reached. If some stations skip
their turn, their transmissions are replaced by idle $20 \mu$-second mini-slots
that enable the other stations to keep track of their order. Because of its
short medium access delay and its efficiency, the protocol supports both
real-time and elastic applications. The protocol allows for nodes leaving and
joining the network; it can allocate more throughput to specific nodes (such as
an access point). The protocol is robust against carrier sensing errors or
clock drift. While collision avoidance is guaranteed in a single collision
domain, it is not the case in a multiple collision one. However, experiments
show ZC supports a comparable amount of goodput to CSMA in a multiple collision
domain environment. The paper presents an analysis and extensive simulations of
the protocol, confirming that ZC outperforms both CSMA and TDMA at high and low
load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3626</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3626</id><created>2008-06-23</created><updated>2008-12-22</updated><authors><author><keyname>Dziemianczuk</keyname><forenames>M.</forenames></author></authors><title>On multi F-nomial coefficients and Inversion formula for F-nomial
  coefficients</title><categories>math.CO cs.DM</categories><comments>11 pages, 2 figures</comments><msc-class>05A19, 11B39, 15A09</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In response to [6], we discover the looked for inversion formula for F-nomial
coefficients. Before supplying its proof, we generalize F-nomial coefficients
to multi F-nomial coefficients and we give their combinatorial interpretation
in cobweb posets language, as the number of maximal-disjoint blocks of the form
sP_{k_1,k_2,...,k_s} of layer &lt;Phi_1--&gt;Phi_n&gt;. Then we present inversion
formula for F-nomial coefficients using multi F-nomial coefficients for all
cobweb-admissible sequences. To this end we infer also some identities as
conclusions of that inversion formula for the case of binomial, Gaussian and
Fibonomial coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3628</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3628</id><created>2008-06-23</created><authors><author><keyname>Kuek</keyname><forenames>Su Kiang</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Chin</keyname><forenames>Woon Hau</forenames></author></authors><title>Four-node Relay Network with Bi-directional Traffic Employing Wireless
  Network Coding with Pre-cancellation</title><categories>cs.IT math.IT</categories><journal-ref>VTC Spring 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding has the potential to improve the overall throughput of a
network by combining different streams of data and forwarding them. In wireless
networks, the wireless channel provide an excellent medium for physical layer
network coding as signals from different transmitters are combined
automatically by the wireless channel. In such scenarios, it would be
interesting to investigate protocols and algorithms which can optimally relay
information. In this paper, we look at a four-node two-way or bidirectional
relay network, and propose a relay protocol which can relay information
efficiently in this network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3629</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3629</id><created>2008-06-23</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Chin</keyname><forenames>Woon Hau</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Chen</keyname><forenames>Wenhua</forenames></author><author><keyname>Tee</keyname><forenames>Taoyi</forenames></author></authors><title>Bi-Directional Multi-Antenna Relay Communications with Wireless Network
  Coding</title><categories>cs.IT math.IT</categories><journal-ref>VTC Spring 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a two-way or bidirectional communications system
with a relay equipped with multiple antennas. We show that when the downlink
channel state information is not known at the relay, the benefit of having
additional antennas at the relay can only be obtained by using decode and
forward (DF) but not amplify and forward (AF). The gain becomes significant
when we employ transmit diversity together with wireless network coding. We
also demonstrate how the performance of such system can be improved by
performing antenna selection at the relay. Our results show that if downlink
channel state information is known at the relay, network coding may not provide
additional gain than simple antenna selection scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3630</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3630</id><created>2008-06-23</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Sun</keyname><forenames>Sumei</forenames></author><author><keyname>Zhang</keyname><forenames>Jian-Kang</forenames></author></authors><title>Comparative Study of SVD and QRS in Closed-Loop Beamforming Systems</title><categories>cs.IT math.IT</categories><comments>Milcom 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compare two closed-loop beamforming algorithms, one based on singular
value decomposition (SVD) and the other based on equal diagonal QR
decomposition (QRS). SVD has the advantage of parallelizing the MIMO channel,
but each of the sub-channels has different gain. QRS has the advantage of
having equal diagonal value for the decomposed channel, but the subchannels are
not fully parallelized, hence requiring successive interference cancellation or
other techniques to perform decoding. We consider a closed-loop system where
the feedback information is a unitary beamforming matrix. Due to the discrete
and limited modulation set, SVD may have inferior performance to QRS when no
modulation set selection is performed. However, if the selection of modulation
set is performed optimally, we show that SVD can outperform QRS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3631</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3631</id><created>2008-06-23</created><authors><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Wu</keyname><forenames>Yan</forenames></author><author><keyname>Sun</keyname><forenames>Sumei</forenames></author></authors><title>Comparative Study of Open-loop Transmit Diversity Schemes for Four
  Transmit Antennas in Coded OFDM Systems</title><categories>cs.IT math.IT</categories><journal-ref>VTC Fall 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compare four open-loop transmit diversity schemes in a coded Orthogonal
Frequency Division Multiplexing (OFDM) system with four transmit antennas,
namely cyclic delay diversity (CDD), Space-Time Block Code (STBC, Alamouti code
is used) with CDD, Quasi-Orthogonal STBC (QO-STBC) and
Minimum-Decoding-Complexity QOSTBC (MDC-QOSTBC). We show that in a coded system
with low code rate, a scheme with spatial transmit diversity of second order
can achieve similar performance to that with spatial transmit diversity of
fourth order due to the additional diversity provided by the phase shift
diversity with channel coding. In addition, we also compare the decoding
complexity and other features of the above four mentioned schemes, such as the
requirement for the training signals, hybrid automatic retransmission request
(HARQ), etc. The discussions in this paper can be readily applied to future
wireless communication systems, such as mobile systems beyond 3G, IEEE 802.11
wireless LAN, or IEEE 802.16 WiMAX, that employ more than two transmit antennas
and OFDM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3633</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3633</id><created>2008-06-23</created><authors><author><keyname>Chua</keyname><forenames>Wee Seng</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Chin</keyname><forenames>Francois</forenames></author></authors><title>A Continuous Vector-Perturbation for Multi-Antenna Multi-User
  Communication</title><categories>cs.IT math.IT</categories><journal-ref>VTC Spring 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sum-rate of the broadcast channel in a multi-antenna multi-user
communication system can be achieved by using precoding and adding a regular
perturbation to the data vector. The perturbation can be removed by the modulus
function, thus transparent to the receiver, but the information of the
precoding matrix is needed to decode the symbols. This paper proposes a new
technique to improve the multi-antenna multi-user system, by adding a
continuous perturbation to the data vector without the need of information on
the precoding matrix to be known at the receiver. The perturbation vector will
be treated as interference at the receiver, thus it will be transparent to the
receiver. The derivation of the continuous vector perturbation is provided by
maximizing the signal-to-interference plus noise ratio or minimizing the
minimum mean square error of the received signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3646</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3646</id><created>2008-06-23</created><updated>2008-08-09</updated><authors><author><keyname>Eskander</keyname><forenames>George S.</forenames></author><author><keyname>Atiya</keyname><forenames>Amir</forenames></author><author><keyname>Chong</keyname><forenames>Kil To</forenames></author><author><keyname>Kim</keyname><forenames>Hyongsuk</forenames></author><author><keyname>Yoo</keyname><forenames>Sung Goo</forenames></author></authors><title>Round Trip Time Prediction Using the Symbolic Function Network Approach</title><categories>cs.NE cs.SC</categories><journal-ref>ISITC, pp. 3-7, 2007 International Symposium on Information
  Technology Convergence (ISITC 2007), 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a novel approach to model the Internet round trip
time using a recently proposed symbolic type neural network model called
symbolic function network. The developed predictor is shown to have good
generalization performance and simple representation compared to the multilayer
perceptron based predictors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3650</identifier>
 <datestamp>2009-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3650</id><created>2008-06-23</created><updated>2009-10-16</updated><authors><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author></authors><title>Recursive Code Construction for Random Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A modification of Koetter-Kschischang codes for random networks is presented
(these codes were also studied by Wang et al. in the context of authentication
problems). The new codes have higher information rate, while maintaining the
same error-correcting capabilities. An efficient error-correcting algorithm is
proposed for these codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3653</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3653</id><created>2008-06-23</created><updated>2008-06-24</updated><authors><author><keyname>Perlaza</keyname><forenames>Samir Medina</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Chaufray</keyname><forenames>Jean-Marie</forenames></author></authors><title>Opportunistic Interference Alignment in MIMO Interference Channels</title><categories>cs.GT cs.IT math.IT</categories><comments>To appear in proc. IEEE PIMRC 2008 - Workshop in Emerging Network
  Perspectives in Multiuser and Cooperative MIMO (NWMIMO). 5 pages and 4
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two interference alignment techniques such that an opportunistic
point-to-point multiple input multiple output (MIMO) link can reuse, without
generating any additional interference, the same frequency band of a similar
pre-existing primary link. In this scenario, we exploit the fact that under
power constraints, although each radio maximizes independently its rate by
water-filling on their channel transfer matrix singular values, frequently, not
all of them are used. Therefore, by aligning the interference of the
opportunistic radio it is possible to transmit at a significant rate while
insuring zero-interference on the pre-existing link. We propose a linear
pre-coder for a perfect interference alignment and a power allocation scheme
which maximizes the individual data rate of the secondary link. Our numerical
results show that significant data rates are achieved even for a reduced number
of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3668</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3668</id><created>2008-06-23</created><authors><author><keyname>Bl&#xe4;ser</keyname><forenames>Markus</forenames></author><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author><author><keyname>Putz</keyname><forenames>Oliver</forenames></author></authors><title>Approximating Multi-Criteria Max-TSP</title><categories>cs.DS</categories><comments>An extended abstract of this worl will appear in Proc. of the 16th
  Ann. European Symposium on Algorithms (ESA 2008)</comments><acm-class>F.2.2; G.2.1; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present randomized approximation algorithms for multi-criteria Max-TSP.
For Max-STSP with k &gt; 1 objective functions, we obtain an approximation ratio
of $1/k - \eps$ for arbitrarily small $\eps &gt; 0$. For Max-ATSP with k objective
functions, we obtain an approximation ratio of $1/(k+1) - \eps$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3681</identifier>
 <datestamp>2008-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3681</id><created>2008-06-23</created><authors><author><keyname>Nordio</keyname><forenames>Alessandro</forenames></author><author><keyname>Chiasserini</keyname><forenames>Carla-Fabiana</forenames></author><author><keyname>Viterbo</keyname><forenames>Emanuele</forenames></author></authors><title>On the d-dimensional Quasi-Equally Spaced Sampling</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a class of random matrices that appear in several communication and
signal processing applications, and whose asymptotic eigenvalue distribution is
closely related to the reconstruction error of an irregularly sampled
bandlimited signal. We focus on the case where the random variables
characterizing these matrices are d-dimensional vectors, independent, and
quasi-equally spaced, i.e., they have an arbitrary distribution and their
averages are vertices of a d-dimensional grid. Although a closed form
expression of the eigenvalue distribution is still unknown, under these
conditions we are able (i) to derive the distribution moments as the matrix
size grows to infinity, while its aspect ratio is kept constant, and (ii) to
show that the eigenvalue distribution tends to the Marcenko-Pastur law as
d-&gt;infinity. These results can find application in several fields, as an
example we show how they can be used for the estimation of the mean square
error provided by linear reconstruction techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3708</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3708</id><created>2008-06-23</created><authors><author><keyname>Martin</keyname><forenames>S&#xe9;bastien</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Atlas-Based Prostate Segmentation Using an Hybrid Registration</title><categories>cs.OH</categories><comments>International Journal of Computer Assisted Radiology and Surgery
  (2008) 000-999</comments><proxy>ccsd hal-00289854</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: This paper presents the preliminary results of a semi-automatic
method for prostate segmentation of Magnetic Resonance Images (MRI) which aims
to be incorporated in a navigation system for prostate brachytherapy. Methods:
The method is based on the registration of an anatomical atlas computed from a
population of 18 MRI exams onto a patient image. An hybrid registration
framework which couples an intensity-based registration with a robust
point-matching algorithm is used for both atlas building and atlas
registration. Results: The method has been validated on the same dataset that
the one used to construct the atlas using the &quot;leave-one-out method&quot;. Results
gives a mean error of 3.39 mm and a standard deviation of 1.95 mm with respect
to expert segmentations. Conclusions: We think that this segmentation tool may
be a very valuable help to the clinician for routine quantitative image
exploitation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3710</identifier>
 <datestamp>2008-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3710</id><created>2008-06-23</created><updated>2008-07-14</updated><authors><author><keyname>Masse</keyname><forenames>A. Blondin</forenames></author><author><keyname>Chicoisne</keyname><forenames>G.</forenames></author><author><keyname>Gargouri</keyname><forenames>Y.</forenames></author><author><keyname>Harnad</keyname><forenames>S.</forenames></author><author><keyname>Picard</keyname><forenames>O.</forenames></author><author><keyname>Marcotte</keyname><forenames>O.</forenames></author></authors><title>How Is Meaning Grounded in Dictionary Definitions?</title><categories>cs.CL cs.DB</categories><comments>8 pages, 3 figures, TextGraphs-3 Workshop at the 22nd International
  Conference on Computational Linguistics, Coling 2008, Manchester, 18-22
  August, 2008</comments><acm-class>A.2; H.3.1; I.2.7; I.2.0; I.2.4; H.3.2; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meaning cannot be based on dictionary definitions all the way down: at some
point the circularity of definitions must be broken in some way, by grounding
the meanings of certain words in sensorimotor categories learned from
experience or shaped by evolution. This is the &quot;symbol grounding problem.&quot; We
introduce the concept of a reachable set -- a larger vocabulary whose meanings
can be learned from a smaller vocabulary through definition alone, as long as
the meanings of the smaller vocabulary are themselves already grounded. We
provide simple algorithms to compute reachable sets for any given dictionary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3765</identifier>
 <datestamp>2008-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3765</id><created>2008-06-23</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Petras</keyname><forenames>Vivien</forenames></author></authors><title>Cross-concordances: terminology mapping and its effectiveness for
  information retrieval</title><categories>cs.DL cs.IR</categories><comments>19 pages, 4 figures, 11 tables, IFLA conference 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The German Federal Ministry for Education and Research funded a major
terminology mapping initiative, which found its conclusion in 2007. The task of
this terminology mapping initiative was to organize, create and manage
'cross-concordances' between controlled vocabularies (thesauri, classification
systems, subject heading lists) centred around the social sciences but quickly
extending to other subject areas. 64 crosswalks with more than 500,000
relations were established. In the final phase of the project, a major
evaluation effort to test and measure the effectiveness of the vocabulary
mappings in an information system environment was conducted. The paper reports
on the cross-concordance work and evaluation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3787</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3787</id><created>2008-06-23</created><updated>2010-10-18</updated><authors><author><keyname>Pedersen</keyname><forenames>Ted</forenames><affiliation>University of Minnesota, Duluth</affiliation></author></authors><title>Computational Approaches to Measuring the Similarity of Short Contexts :
  A Review of Applications and Methods</title><categories>cs.CL</categories><comments>23 pages</comments><journal-ref>University of Minnesota Supercomputing Institute Research Report
  UMSI 2010/118, October 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measuring the similarity of short written contexts is a fundamental problem
in Natural Language Processing. This article provides a unifying framework by
which short context problems can be categorized both by their intended
application and proposed solution. The goal is to show that various problems
and methodologies that appear quite different on the surface are in fact very
closely related. The axes by which these categorizations are made include the
format of the contexts (headed versus headless), the way in which the contexts
are to be measured (first-order versus second-order similarity), and the
information used to represent the features in the contexts (micro versus macro
views). The unifying thread that binds together many short context applications
and methods is the fact that similarity decisions must be made between contexts
that share few (if any) words in common.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3799</identifier>
 <datestamp>2009-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3799</id><created>2008-06-23</created><updated>2009-10-17</updated><authors><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author><author><keyname>Howard</keyname><forenames>Stephen</forenames></author><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author></authors><title>A Sublinear Algorithm for Sparse Reconstruction with l2/l2 Recovery
  Guarantees</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Sensing aims to capture attributes of a sparse signal using very
few measurements. Cand\`{e}s and Tao showed that sparse reconstruction is
possible if the sensing matrix acts as a near isometry on all
$\boldsymbol{k}$-sparse signals. This property holds with overwhelming
probability if the entries of the matrix are generated by an iid Gaussian or
Bernoulli process. There has been significant recent interest in an alternative
signal processing framework; exploiting deterministic sensing matrices that
with overwhelming probability act as a near isometry on $\boldsymbol{k}$-sparse
vectors with uniformly random support, a geometric condition that is called the
Statistical Restricted Isometry Property or StRIP. This paper considers a
family of deterministic sensing matrices satisfying the StRIP that are based on
\srm codes (binary chirps) and a $\boldsymbol{k}$-sparse reconstruction
algorithm with sublinear complexity. In the presence of stochastic noise in the
data domain, this paper derives bounds on the $\boldsymbol{\ell_2}$ accuracy of
approximation in terms of the $\boldsymbol{\ell_2}$ norm of the measurement
noise and the accuracy of the best $\boldsymbol{k}$-sparse approximation, also
measured in the $\boldsymbol{\ell_2}$ norm. This type of $\boldsymbol{\ell_2
/\ell_2}$ bound is tighter than the standard $\boldsymbol{\ell_2 /\ell_1}$ or
$\boldsymbol{\ell_1/ \ell_1}$ bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3802</identifier>
 <datestamp>2008-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3802</id><created>2008-06-23</created><authors><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Efficient and Robust Compressed Sensing using High-Quality Expander
  Graphs</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expander graphs have been recently proposed to construct efficient compressed
sensing algorithms. In particular, it has been shown that any $n$-dimensional
vector that is $k$-sparse (with $k\ll n$) can be fully recovered using
$O(k\log\frac{n}{k})$ measurements and only $O(k\log n)$ simple recovery
iterations. In this paper we improve upon this result by considering expander
graphs with expansion coefficient beyond 3/4 and show that, with the same
number of measurements, only $O(k)$ recovery iterations are required, which is
a significant improvement when $n$ is large. In fact, full recovery can be
accomplished by at most $2k$ very simple iterations. The number of iterations
can be made arbitrarily close to $k$, and the recovery algorithm can be
implemented very efficiently using a simple binary search tree. We also show
that by tolerating a small penalty on the number of measurements, and not on
the number of recovery iterations, one can use the efficient construction of a
family of expander graphs to come up with explicit measurement matrices for
this method. We compare our result with other recently developed
expander-graph-based methods and argue that it compares favorably both in terms
of the number of required measurements and in terms of the recovery time
complexity. Finally we will show how our analysis extends to give a robust
algorithm that finds the position and sign of the $k$ significant elements of
an almost $k$-sparse signal and then, using very simple optimization
techniques, finds in sublinear time a $k$-sparse signal which approximates the
original signal with very high precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3827</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3827</id><created>2008-06-24</created><updated>2012-12-20</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>Optimal Scheduling of File Transfers with Divisible Sizes on Multiple
  Disjoint Paths</title><categories>cs.DS cs.NI</categories><comments>The algorithmic techniques presented in this paper (particularly the
  block partitioning framework) were used as part of the official solutions for
  several tasks proposed by the author in the 2012 Romanian National Olympiad
  in Informatics (the statements and solutions for these tasks can be found in
  the attached zip archive)</comments><proxy>ccsd</proxy><journal-ref>Proceedings of the IEEE Romania International Conference
  &quot;Communications&quot;, 2008. (ISBN: 978-606-521-008-0), Bucharest : Romania (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I investigate several offline and online data transfer
scheduling problems and propose efficient algorithms and techniques for
addressing them. In the offline case, I present a novel, heuristic, algorithm
for scheduling files with divisible sizes on multiple disjoint paths, in order
to maximize the total profit (the problem is equivalent to the multiple
knapsack problem with divisible item sizes). I then consider a cost
optimization problem for transferring a sequence of identical files, subject to
time constraints imposed by the data transfer providers. For the online case I
propose an algorithmic framework based on the block partitioning method, which
can speed up the process of resource allocation and reservation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3849</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3849</id><created>2008-06-24</created><updated>2008-09-04</updated><authors><author><keyname>Hirschkoff</keyname><forenames>Daniel</forenames></author><author><keyname>Lozes</keyname><forenames>Etienne</forenames></author><author><keyname>Sangiorgi</keyname><forenames>Davide</forenames></author></authors><title>Separability in the Ambient Logic</title><categories>cs.LO cs.MA cs.PL</categories><comments>logical methods in computer science, 44 pages</comments><acm-class>F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (September
  4, 2008) lmcs:682</journal-ref><doi>10.2168/LMCS-4(3:4)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \it{Ambient Logic} (AL) has been proposed for expressing properties of
process mobility in the calculus of Mobile Ambients (MA), and as a basis for
query languages on semistructured data. We study some basic questions
concerning the discriminating power of AL, focusing on the equivalence on
processes induced by the logic $(=_L&gt;)$. As underlying calculi besides MA we
consider a subcalculus in which an image-finiteness condition holds and that we
prove to be Turing complete. Synchronous variants of these calculi are studied
as well. In these calculi, we provide two operational characterisations of
$_=L$: a coinductive one (as a form of bisimilarity) and an inductive one
(based on structual properties of processes). After showing $_=L$ to be stricly
finer than barbed congruence, we establish axiomatisations of $_=L$ on the
subcalculus of MA (both the asynchronous and the synchronous version), enabling
us to relate $_=L$ to structural congruence. We also present some
(un)decidability results that are related to the above separation properties
for AL: the undecidability of $_=L$ on MA and its decidability on the
subcalculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3885</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3885</id><created>2008-06-24</created><authors><author><keyname>Tariel</keyname><forenames>Vincent</forenames></author></authors><title>Conceptualization of seeded region growing by pixels aggregation. Part
  1: the framework</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adams and Bishop have proposed in 1994 a novel region growing algorithm
called seeded region growing by pixels aggregation (SRGPA). This paper
introduces a framework to implement an algorithm using SRGPA. This framework is
built around two concepts: localization and organization of applied action.
This conceptualization gives a quick implementation of algorithms, a direct
translation between the mathematical idea and the numerical implementation, and
an improvement of algorithms efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3887</identifier>
 <datestamp>2008-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3887</id><created>2008-06-24</created><authors><author><keyname>Tariel</keyname><forenames>Vincent</forenames></author></authors><title>Conceptualization of seeded region growing by pixels aggregation. Part
  2: how to localize a final partition invariant about the seeded region
  initialisation order</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the previous paper, we have conceptualized the localization and the
organization of seeded region growing by pixels aggregation (SRGPA) but we do
not give the issue when there is a collision between two distinct regions
during the growing process. In this paper, we propose two implementations to
manage two classical growing processes: one without a boundary region region to
divide the other regions and another with. Unfortunately, as noticed by Mehnert
and Jakway (1997), this partition depends on the seeded region initialisation
order (SRIO). We propose a growing process, invariant about SRIO such as the
boundary region is the set of ambiguous pixels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3906</identifier>
 <datestamp>2009-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3906</id><created>2008-06-24</created><updated>2009-03-16</updated><authors><author><keyname>Kirsch</keyname><forenames>Werner</forenames></author><author><keyname>Langner</keyname><forenames>Jessica</forenames></author></authors><title>Power Indices and minimal winning Coalitions</title><categories>math.CO cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Penrose-Banzhaf index and the Shapley-Shubik index are the best-known and
the most used tools to measure political power of voters in simple voting
games. Most methods to calculate these power indices are based on counting
winning coalitions, in particular those coalitions a voter is decisive for. We
present a new combinatorial formula how to calculate both indices solely using
the set of minimal winning coalitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3928</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3928</id><created>2008-06-24</created><authors><author><keyname>Tariel</keyname><forenames>Vincent</forenames></author></authors><title>Conceptualization of seeded region growing by pixels aggregation. Part
  3: a wide range of algorithms</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the two previous papers of this serie, we have created a library, called
Population, dedicated to seeded region growing by pixels aggregation and we
have proposed different growing processes to get a partition with or without a
boundary region to divide the other regions or to get a partition invariant
about the seeded region initialisation order. Using this work, we implement
some algorithms belonging to the field of SRGPA using this library and these
growing processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3938</identifier>
 <datestamp>2008-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3938</id><created>2008-06-24</created><authors><author><keyname>Yildirim</keyname><forenames>Ilker</forenames></author><author><keyname>Bingol</keyname><forenames>Haluk</forenames></author></authors><title>Cooperation with Complement is Better</title><categories>cs.MA physics.soc-ph</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a setting where heterogeneous agents interact to accomplish a given set of
goals, cooperation is of utmost importance, especially when agents cannot
achieve their individual goals by exclusive use of their own efforts. Even when
we consider friendly environments and benevolent agents, cooperation involves
several issues: with whom to cooperate, reciprocation, how to address credit
assignment and complex division of gains, etc. We propose a model where
heterogeneous agents cooperate by forming groups and formation of larger groups
is promoted. Benefit of agents is proportional to the performance and the size
of the group. There is a time pressure to form a group. We investigate how
preferring similar or complement agents in group formation affects an agent's
success. Preferring complement in group formation is found to be better, yet
there is no need to push the strategy to the extreme since the effect of
complementing partners is saturated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3939</identifier>
 <datestamp>2008-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3939</id><created>2008-06-24</created><updated>2008-07-23</updated><authors><author><keyname>Tariel</keyname><forenames>Vincent</forenames></author></authors><title>Conceptualization of seeded region growing by pixels aggregation. Part
  4: Simple, generic and robust extraction of grains in granular materials
  obtained by X-ray tomography</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a simple, generic and robust method to extract the grains
from experimental tridimensionnal images of granular materials obtained by
X-ray tomography. This extraction has two steps: segmentation and splitting.
For the segmentation step, if there is a sufficient contrast between the
different components, a classical threshold procedure followed by a succession
of morphological filters can be applied. If not, and if the boundary needs to
be localized precisely, a watershed transformation controlled by labels is
applied. The basement of this transformation is to localize a label included in
the component and another label in the component complementary. A &quot;soft&quot;
threshold following by an opening is applied on the initial image to localize a
label in a component. For any segmentation procedure, the visualisation shows a
problem: some groups of two grains, close one to each other, become connected.
So if a classical cluster procedure is applied on the segmented binary image,
these numerical connected grains are considered as a single grain. To overcome
this problem, we applied a procedure introduced by L. Vincent in 1993. This
grains extraction is tested for various complexes porous media and granular
material, to predict various properties (diffusion, electrical conductivity,
deformation field) in a good agreement with experiment data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3949</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3949</id><created>2008-06-24</created><updated>2008-07-29</updated><authors><author><keyname>Tucci</keyname><forenames>Robert R.</forenames></author></authors><title>Use of a Quantum Computer and the Quick Medical Reference To Give an
  Approximate Diagnosis</title><categories>quant-ph cs.AI</categories><comments>v1:14 pages (files: 1 .tex, 1 .sty, 5 .eps);v2:19 pages (files: 1
  .tex, 1 .sty, 5 .eps)added stuff about likelihood weighting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Quick Medical Reference (QMR) is a compendium of statistical knowledge
connecting diseases to findings (symptoms). The information in QMR can be
represented as a Bayesian network. The inference problem (or, in more medical
language, giving a diagnosis) for the QMR is to, given some findings, find the
probability of each disease. Rejection sampling and likelihood weighted
sampling (a.k.a. likelihood weighting) are two simple algorithms for making
approximate inferences from an arbitrary Bayesian net (and from the QMR
Bayesian net in particular). Heretofore, the samples for these two algorithms
have been obtained with a conventional &quot;classical computer&quot;. In this paper, we
will show that two analogous algorithms exist for the QMR Bayesian net, where
the samples are obtained with a quantum computer. We expect that these two
algorithms, implemented on a quantum computer, can also be used to make
inferences (and predictions) with other Bayesian nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3963</identifier>
 <datestamp>2008-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3963</id><created>2008-06-24</created><authors><author><keyname>Turner</keyname><forenames>D. Z.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Hjelmstad</keyname><forenames>K. D.</forenames></author></authors><title>A stabilized finite element formulation for advection-diffusion using
  the generalized finite element framework</title><categories>cs.NA</categories><comments>24 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following work presents a generalized (extended) finite element
formulation for the advection-diffusion equation. Using enrichment functions
that represent the exponential nature of the exact solution, smooth numerical
solutions are obtained for problems with steep gradients and high Peclet
numbers (up to Pe = 25) in one and two-dimensions. As opposed to traditional
stabilized methods that require the construction of stability parameters and
stabilization terms, the present work avoids numerical instabilities by
improving the classical Galerkin solution with an enrichment function. To
contextualize this method among other stabilized methods, we show by
decomposition of the solution (in a multiscale manner) an equivalence to both
Galerkin/least-squares type methods and those that use bubble functions. This
work also presents a strategy for constructing the enrichment function for
problems with complex geometries by employing a global-local approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3978</identifier>
 <datestamp>2008-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3978</id><created>2008-06-24</created><updated>2008-07-18</updated><authors><author><keyname>Vu</keyname><forenames>Vincent Q.</forenames></author><author><keyname>Yu</keyname><forenames>Bin</forenames></author><author><keyname>Kass</keyname><forenames>Robert E.</forenames></author></authors><title>Information In The Non-Stationary Case</title><categories>q-bio.NC cs.IT math.IT q-bio.QM stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information estimates such as the ``direct method'' of Strong et al. (1998)
sidestep the difficult problem of estimating the joint distribution of response
and stimulus by instead estimating the difference between the marginal and
conditional entropies of the response. While this is an effective estimation
strategy, it tempts the practitioner to ignore the role of the stimulus and the
meaning of mutual information. We show here that, as the number of trials
increases indefinitely, the direct (or ``plug-in'') estimate of marginal
entropy converges (with probability 1) to the entropy of the time-averaged
conditional distribution of the response, and the direct estimate of the
conditional entropy converges to the time-averaged entropy of the conditional
distribution of the response. Under joint stationarity and ergodicity of the
response and stimulus, the difference of these quantities converges to the
mutual information. When the stimulus is deterministic or non-stationary the
direct estimate of information no longer estimates mutual information, which is
no longer meaningful, but it remains a measure of variability of the response
distribution across time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4020</identifier>
 <datestamp>2008-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4020</id><created>2008-06-24</created><authors><author><keyname>Muljowidodo</keyname></author><author><keyname>Jenie</keyname><forenames>Said D.</forenames></author><author><keyname>Budiyono</keyname><forenames>Agus</forenames></author><author><keyname>Nugroho</keyname><forenames>Sapto A.</forenames></author></authors><title>Design, Development and Testing of Underwater Vehicles: ITB Experience</title><categories>cs.RO</categories><comments>6 pages, 8 figures, 1 table; The International Conference on
  Underwater System Technology: Theory and Application, Penang, Malaysia, 18-21
  July 2006</comments><acm-class>I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last decade has witnessed increasing worldwide interest in the research
of underwater robotics with particular focus on the area of autonomous
underwater vehicles (AUVs). The underwater robotics technology has enabled
human to access the depth of the ocean to conduct environmental surveys,
resources mapping as well as scientific and military missions. This capability
is especially valuable for countries with major water or oceanic resources. As
an archipelagic nation with more than 13,000 islands, Indonesia has one of the
most abundant living and non-organic oceanic resources. The needs for the
mapping, exploration, and environmental preservation of the vast marine
resources are therefore imperative. The challenge of the deep water exploration
has been the complex issues associated with hazardous and unstructured undersea
and sea-bed environments. The paper reports the design, development and testing
efforts of underwater vehicle that have been conducted at Institut Teknologi
Bandung. Key technology areas have been identified and step-by-step development
is presented in conjunction with the need to meet the challenge of underwater
vehicle operation. A number of future research directions are also highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4021</identifier>
 <datestamp>2008-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4021</id><created>2008-06-25</created><authors><author><keyname>Budiyono</keyname><forenames>Agus</forenames></author><author><keyname>Sutarto</keyname><forenames>H. Y</forenames></author></authors><title>Linear Parameter Varying Model Identification for Control of
  Rotorcraft-based UAV</title><categories>cs.RO</categories><comments>6 pages, 6 figures; Fifth Indonesia-Taiwan Workshop on Aeronautical
  Science, Technology and Industry, Tainan, Taiwan, November 13-16, 2006</comments><acm-class>I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rotorcraft-based unmanned aerial vehicle exhibits more complex properties
compared to its full-size counterparts due to its increased sensitivity to
control inputs and disturbances and higher bandwidth of its dynamics. As an
aerial vehicle with vertical take-off and landing capability, the helicopter
specifically poses a difficult problem of transition between forward flight and
unstable hover and vice versa. The LPV control technique explicitly takes into
account the change in performance due to the real-time parameter variations.
The technique therefore theoretically guarantees the performance and robustness
over the entire operating envelope. In this study, we investigate a new
approach implementing model identification for use in the LPV control
framework. The identification scheme employs recursive least square technique
implemented on the LPV system represented by dynamics of helicopter during a
transition. The airspeed as the scheduling of parameter trajectory is not
assumed to vary slowly. The exclusion of slow parameter change requirement
allows for the application of the algorithm for aggressive maneuvering
capability without the need of expensive computation. The technique is tested
numerically and will be validated in the autonomous flight of a small scale
helicopter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4034</identifier>
 <datestamp>2012-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4034</id><created>2008-06-25</created><updated>2010-05-07</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Data linkage dynamics with shedding</title><categories>cs.LO</categories><comments>22 pages; introduction improved. arXiv admin note: substantial text
  overlap with arXiv:0804.4565</comments><report-no>PRG0809</report-no><acm-class>D.3.3; D.4.2; F.1.1; F.3.3</acm-class><journal-ref>Fundamenta Informaticae, 103(1--4):31--52, 2010</journal-ref><doi>10.3233/FI-2010-317</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study shedding in the setting of data linkage dynamics, a simple model of
computation that bears on the use of dynamic data structures in programming.
Shedding is complementary to garbage collection. With shedding, each time a
link to a data object is updated by a program, it is determined whether or not
the link will possibly be used once again by the program, and if not the link
is automatically removed. Thus, everything is made garbage as soon as it can be
viewed as garbage. By that, the effectiveness of garbage collection becomes
maximal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4073</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4073</id><created>2008-06-25</created><authors><author><keyname>Gurski</keyname><forenames>Frank</forenames></author></authors><title>A comparison of two approaches for polynomial time algorithms computing
  basic graph parameters</title><categories>cs.DS cs.DM</categories><comments>25 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we compare and illustrate the algorithmic use of graphs of
bounded tree-width and graphs of bounded clique-width. For this purpose we give
polynomial time algorithms for computing the four basic graph parameters
independence number, clique number, chromatic number, and clique covering
number on a given tree structure of graphs of bounded tree-width and graphs of
bounded clique-width in polynomial time. We also present linear time algorithms
for computing the latter four basic graph parameters on trees, i.e. graphs of
tree-width 1, and on co-graphs, i.e. graphs of clique-width at most 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4112</identifier>
 <datestamp>2009-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4112</id><created>2008-06-25</created><authors><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author></authors><title>Statistical Physics of Hard Optimization Problems</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC</categories><comments>PhD thesis</comments><journal-ref>Acta Physica Slovaca 59, No.3, 169-303 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimization is fundamental in many areas of science, from computer science
and information theory to engineering and statistical physics, as well as to
biology or social sciences. It typically involves a large number of variables
and a cost function depending on these variables. Optimization problems in the
NP-complete class are particularly difficult, it is believed that the number of
operations required to minimize the cost function is in the most difficult
cases exponential in the system size. However, even in an NP-complete problem
the practically arising instances might, in fact, be easy to solve. The
principal question we address in this thesis is: How to recognize if an
NP-complete constraint satisfaction problem is typically hard and what are the
main reasons for this? We adopt approaches from the statistical physics of
disordered systems, in particular the cavity method developed originally to
describe glassy systems. We describe new properties of the space of solutions
in two of the most studied constraint satisfaction problems - random
satisfiability and random graph coloring. We suggest a relation between the
existence of the so-called frozen variables and the algorithmic hardness of a
problem. Based on these insights, we introduce a new class of problems which we
named &quot;locked&quot; constraint satisfaction, where the statistical description is
easily solvable, but from the algorithmic point of view they are even more
challenging than the canonical satisfiability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4127</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4127</id><created>2008-06-25</created><authors><author><keyname>Dohm</keyname><forenames>Marc</forenames><affiliation>JAD, INRIA Sophia Antipolis</affiliation></author><author><keyname>Zube</keyname><forenames>Severinas</forenames></author></authors><title>The implicit equation of a canal surface</title><categories>math.AG cs.SC math.AC</categories><comments>26 pages, to be published in Journal of Symbolic Computation</comments><proxy>ccsd hal-00290577</proxy><doi>10.1016/j.jsc.2008.06.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A canal surface is an envelope of a one parameter family of spheres. In this
paper we present an efficient algorithm for computing the implicit equation of
a canal surface generated by a rational family of spheres. By using Laguerre
and Lie geometries, we relate the equation of the canal surface to the equation
of a dual variety of a certain curve in 5-dimensional projective space. We
define the \mu-basis for arbitrary dimension and give a simple algorithm for
its computation. This is then applied to the dual variety, which allows us to
deduce the implicit equations of the the dual variety, the canal surface and
any offset to the canal surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4130</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4130</id><created>2008-06-25</created><authors><author><keyname>Mundhenk</keyname><forenames>Martin</forenames><affiliation>University of Jena</affiliation></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames><affiliation>University of Manchester</affiliation></author><author><keyname>Schwentick</keyname><forenames>Thomas</forenames><affiliation>University of Dortmund</affiliation></author><author><keyname>Weber</keyname><forenames>Volker</forenames><affiliation>University of Dortmund</affiliation></author></authors><title>Complexity of Hybrid Logics over Transitive Frames</title><categories>cs.LO</categories><comments>21 pages, 6 figures (only 2 thereof are in external files)</comments><acm-class>F.4.1</acm-class><journal-ref>Workshop &quot;Methods for Modalities&quot; (M4M-4), Informatik-Berichte,
  194, pp. 62-78, 2005. ISSN 0863-095X</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the complexity of hybrid logics over transitive frames,
transitive trees, and linear frames. We show that satisfiability over
transitive frames for the hybrid language extended with the downarrow operator
is NEXPTIME-complete. This is in contrast to undecidability of satisfiability
over arbitrary frames for this language (Areces, Blackburn, Marx 1999). It is
also shown that adding the @ operator or the past modality leads to
undecidability over transitive frames. This is again in contrast to the case of
transitive trees and linear frames, where we show these languages to be
nonelementarily decidable. Moreover, we establish 2EXPTIME and EXPTIME upper
bounds for satisfiability over transitive frames and transitive trees,
respectively, for the hybrid Until/Since language. An EXPTIME lower bound is
shown to hold for the modal Until language over both frame classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4168</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4168</id><created>2008-06-25</created><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Established Clustering Procedures for Network Analysis</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In light of the burgeoning interest in network analysis in the new millenium,
we bring to the attention of contemporary network theorists, a two-stage
double-standarization and hierarchical clustering (single-linkage-like)
procedure devised in 1974. In its many applications over the next
decade--primarily to the migration flows between geographic subdivisions within
nations--the presence was often revealed of ``hubs''. These are, typically,
``cosmopolitan/non-provincial'' areas--such as the French capital, Paris--which
send and receive people relatively broadly across their respective nations.
Additionally, this two-stage procedure--which ``might very well be the most
successful application of cluster analysis'' (R. C. Dubes)--has detected many
(physically or socially) isolated groups (regions) of areas, such as those
forming the southern islands, Shikoku and Kyushu, of Japan, the Italian islands
of Sardinia and Sicily, and the New England region of the United States.
Further, we discuss a (complementary) approach developed in 1976, involving the
application of the max-flow/min-cut theorem to raw/non-standardized flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4200</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4200</id><created>2008-06-25</created><updated>2008-07-30</updated><authors><author><keyname>Bagherikaram</keyname><forenames>Ghadamali</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>The Secrecy Rate Region of the Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a scenario where a source node wishes to broadcast
two confidential messages for two respective receivers, while a wire-tapper
also receives the transmitted signal. This model is motivated by wireless
communications, where individual secure messages are broadcast over open media
and can be received by any illegitimate receiver. The secrecy level is measured
by equivocation rate at the eavesdropper. We first study the general
(non-degraded) broadcast channel with confidential messages. We present an
inner bound on the secrecy capacity region for this model. The inner bound
coding scheme is based on a combination of random binning and the
Gelfand-Pinsker bining. This scheme matches the Marton's inner bound on the
broadcast channel without confidentiality constraint. We further study the
situation where the channels are degraded. For the degraded broadcast channel
with confidential messages, we present the secrecy capacity region. Our
achievable coding scheme is based on Cover's superposition scheme and random
binning. We refer to this scheme as Secret Superposition Scheme. In this
scheme, we show that randomization in the first layer increases the secrecy
rate of the second layer. This capacity region matches the capacity region of
the degraded broadcast channel without security constraint. It also matches the
secrecy capacity for the conventional wire-tap channel. Our converse proof is
based on a combination of the converse proof of the conventional degraded
broadcast channel and Csiszar lemma. Finally, we assume that the channels are
Additive White Gaussian Noise (AWGN) and show that secret superposition scheme
with Gaussian codebook is optimal. The converse proof is based on the
generalized entropy power inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4210</identifier>
 <datestamp>2008-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4210</id><created>2008-06-25</created><authors><author><keyname>Arpe</keyname><forenames>Jan</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author></authors><title>Agnostically Learning Juntas from Random Walks</title><categories>cs.LG</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the class of functions g:{-1,+1}^n -&gt; {-1,+1} that only depend
on an unknown subset of k&lt;&lt;n variables (so-called k-juntas) is agnostically
learnable from a random walk in time polynomial in n, 2^{k^2}, epsilon^{-k},
and log(1/delta). In other words, there is an algorithm with the claimed
running time that, given epsilon, delta &gt; 0 and access to a random walk on
{-1,+1}^n labeled by an arbitrary function f:{-1,+1}^n -&gt; {-1,+1}, finds with
probability at least 1-delta a k-junta that is (opt(f)+epsilon)-close to f,
where opt(f) denotes the distance of a closest k-junta to f.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4221</identifier>
 <datestamp>2008-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4221</id><created>2008-06-25</created><authors><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Pemmaraju</keyname><forenames>Sriram V.</forenames></author></authors><title>Localized Spanners for Wireless Networks</title><categories>cs.DC</categories><comments>21 pages</comments><acm-class>C.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new efficient localized algorithm to construct, for any given
quasi-unit disk graph G=(V,E) and any e &gt; 0, a (1+e)-spanner for G of maximum
degree O(1) and total weight O(w(MST)), where w(MST) denotes the weight of a
minimum spanning tree for V. We further show that similar localized techniques
can be used to construct, for a given unit disk graph G = (V, E), a planar
Cdel(1+e)(1+pi/2)-spanner for G of maximum degree O(1) and total weight
O(w(MST)). Here Cdel denotes the stretch factor of the unit Delaunay
triangulation for V. Both constructions can be completed in O(1) communication
rounds, and require each node to know its own coordinates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4264</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4264</id><created>2008-06-26</created><updated>2008-09-29</updated><authors><author><keyname>Sundararajan</keyname><forenames>Jay Kumar</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Online network coding for optimal throughput and delay -- the
  three-receiver case</title><categories>cs.IT math.IT</categories><comments>This is the final version. The content has been changed to
  incorporate reviewer comments and recent results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a packet erasure broadcast channel with three receivers, we propose a new
coding algorithm that makes use of feedback to dynamically adapt the code. Our
algorithm is throughput optimal, and we conjecture that it also achieves an
asymptotically optimal average decoding delay at the receivers. We consider
heavy traffic asymptotics, where the load factor \rho approaches 1 from below
with either the arrival rate (\lambda) or the channel parameter (\mu) being
fixed at a number less than 1. We verify through simulations that our algorithm
achieves an asymptotically optimal decoding delay of O(1/(1-\rho)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4286</identifier>
 <datestamp>2008-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4286</id><created>2008-06-26</created><authors><author><keyname>Arnold</keyname><forenames>M. D.</forenames></author><author><keyname>Khokhlov</keyname><forenames>A. V.</forenames></author></authors><title>Implementation for blow up of tornado-type solutions for complex version
  of 3D Navier-Stokes system</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Cauchy problem for Fourier transformation of 3-dimensional
Navier-Stokes system with zero external force. Using initial data purposed by
Dong Li and Ya.G.Sinai we implement self-similar regime producing fast growing
behavior of the energy of solution while time tends to critical value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4293</identifier>
 <datestamp>2008-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4293</id><created>2008-06-26</created><authors><author><keyname>Kudryashov</keyname><forenames>Boris D.</forenames></author><author><keyname>Porov</keyname><forenames>Anton V.</forenames></author><author><keyname>Oh</keyname><forenames>Eunmi L.</forenames></author></authors><title>Scalar Quantization for Audio Data Coding</title><categories>cs.MM cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with scalar quantization of transform coefficients in
an audio codec. The generalized Gaussian distribution (GGD) is used as an
approximation of one-dimensional probability density function for transform
coefficients obtained by modulated lapped transform (MLT) or modified cosine
transform (MDCT) filterbank. The rationale of the model is provided in
comparison with theoretically achievable rate-distortion function. The
rate-distortion function computed for the random sequence obtained from a real
sequence of samples from a large database is compared with that computed for
random sequence obtained by a GGD random generator. A simple algorithm of
constructing the Extended Zero Zone (EZZ) quantizer is proposed. Simulation
results show that the EZZ quantizer yields a negligible loss in terms of coding
efficiency compared to optimal scalar quantizers. Furthermore, we describe an
adaptive version of the EZZ quantizer which works efficiently with low bitrate
requirements for transmitting side information
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4326</identifier>
 <datestamp>2008-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4326</id><created>2008-06-26</created><updated>2008-09-12</updated><authors><author><keyname>Agarwal</keyname><forenames>Pankaj K.</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author></authors><title>An Efficient Algorithm for 2D Euclidean 2-Center with Outliers</title><categories>cs.CG</categories><comments>19 pages, 6 figures. Longer version of paper in ESA08. Adds section
  on l_\infty (p,k)-center</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a set P of n points in R^2, the Euclidean 2-center problem computes a
pair of congruent disks of the minimal radius that cover P. We extend this to
the (2,k)-center problem where we compute the minimal radius pair of congruent
disks to cover n-k points of P. We present a randomized algorithm with O(n k^7
log^3 n) expected running time for the (2,k)-center problem. We also study the
(p,k)-center problem in R}^2 under the \ell_\infty-metric. We give solutions
for p=4 in O(k^{O(1)} n log n) time and for p=5 in O(k^{O(1)} n log^5 n) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4341</identifier>
 <datestamp>2008-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4341</id><created>2008-06-26</created><authors><author><keyname>V'yugin</keyname><forenames>Vladimir V.</forenames></author></authors><title>On Sequences with Non-Learnable Subsequences</title><categories>cs.AI cs.LG</categories><acm-class>F.4.1; I.2.6</acm-class><journal-ref>LNCS 5010, pp. 302-313, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The remarkable results of Foster and Vohra was a starting point for a series
of papers which show that any sequence of outcomes can be learned (with no
prior knowledge) using some universal randomized forecasting algorithm and
forecast-dependent checking rules. We show that for the class of all
computationally efficient outcome-forecast-based checking rules, this property
is violated. Moreover, we present a probabilistic algorithm generating with
probability close to one a sequence with a subsequence which simultaneously
miscalibrates all partially weakly computable randomized forecasting
algorithms. %subsequences non-learnable by each randomized algorithm.
  According to the Dawid's prequential framework we consider partial recursive
randomized algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4344</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4344</id><created>2008-06-26</created><authors><author><keyname>Hansen</keyname><forenames>Kristoffer Arnsfelt</forenames></author><author><keyname>Hansen</keyname><forenames>Thomas Dueholm</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author><author><keyname>S&#xf8;rensen</keyname><forenames>Troels Bjerre</forenames></author></authors><title>Approximability and parameterized complexity of minmax values</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider approximating the minmax value of a multi-player game in
strategic form. Tightening recent bounds by Borgs et al., we observe that
approximating the value with a precision of epsilon log n digits (for any
constant epsilon&gt;0 is NP-hard, where n is the size of the game. On the other
hand, approximating the value with a precision of c log log n digits (for any
constant c &gt;= 1) can be done in quasi-polynomial time. We consider the
parameterized complexity of the problem, with the parameter being the number of
pure strategies k of the player for which the minmax value is computed. We show
that if there are three players, k=2 and there are only two possible rational
payoffs, the minmax value is a rational number and can be computed exactly in
linear time. In the general case, we show that the value can be approximated
with any polynomial number of digits of accuracy in time n^(O(k)). On the other
hand, we show that minmax value approximation is W[1]-hard and hence not likely
to be fixed parameter tractable. Concretely, we show that if k-CLIQUE requires
time n^(Omega(k)) then so does minmax value computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4361</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4361</id><created>2008-06-26</created><updated>2009-04-24</updated><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Space Efficient Multi-Dimensional Range Reporting</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a data structure that supports three-dimensional range reporting
queries in $O(\log \log U + (\log \log n)^3+k)$ time and uses $O(n\log^{1+\eps}
n)$ space, where $U$ is the size of the universe, $k$ is the number of points
in the answer,and $\eps$ is an arbitrary constant. This result improves over
the data structure of Alstrup, Brodal, and Rauhe (FOCS 2000) that uses
$O(n\log^{1+\eps} n)$ space and supports queries in $O(\log n+k)$ time,the data
structure of Nekrich (SoCG'07) that uses $O(n\log^{3} n)$ space and supports
queries in $O(\log \log U + (\log \log n)^2 + k)$ time, and the data structure
of Afshani (ESA'08) that uses $O(n\log^{3} n)$ space and also supports queries
in $O(\log \log U + (\log \log n)^2 + k)$ time but relies on randomization
during the preprocessing stage. Our result allows us to significantly reduce
the space usage of the fastest previously known static and incremental
$d$-dimensional data structures, $d\geq 3$, at a cost of increasing the query
time by a negligible $O(\log \log n)$ factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4372</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4372</id><created>2008-06-26</created><authors><author><keyname>Asdre</keyname><forenames>Katerina</forenames></author><author><keyname>Nikolopoulos</keyname><forenames>Stavros D.</forenames></author></authors><title>The 1-fixed-endpoint Path Cover Problem is Polynomial on Interval Graph</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a variant of the path cover problem, namely, the
$k$-fixed-endpoint path cover problem, or kPC for short, on interval graphs.
Given a graph $G$ and a subset $\mathcal{T}$ of $k$ vertices of $V(G)$, a
$k$-fixed-endpoint path cover of $G$ with respect to $\mathcal{T}$ is a set of
vertex-disjoint paths $\mathcal{P}$ that covers the vertices of $G$ such that
the $k$ vertices of $\mathcal{T}$ are all endpoints of the paths in
$\mathcal{P}$. The kPC problem is to find a $k$-fixed-endpoint path cover of
$G$ of minimum cardinality; note that, if $\mathcal{T}$ is empty the stated
problem coincides with the classical path cover problem. In this paper, we
study the 1-fixed-endpoint path cover problem on interval graphs, or 1PC for
short, generalizing the 1HP problem which has been proved to be NP-complete
even for small classes of graphs. Motivated by a work of Damaschke, where he
left both 1HP and 2HP problems open for the class of interval graphs, we show
that the 1PC problem can be solved in polynomial time on the class of interval
graphs. The proposed algorithm is simple, runs in $O(n^2)$ time, requires
linear space, and also enables us to solve the 1HP problem on interval graphs
within the same time and space complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4391</identifier>
 <datestamp>2008-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4391</id><created>2008-06-26</created><authors><author><keyname>V'yugin</keyname><forenames>Vladimir V.</forenames></author></authors><title>Prediction with Expert Advice in Games with Unbounded One-Step Gains</title><categories>cs.LG cs.AI</categories><comments>16 pages</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The games of prediction with expert advice are considered in this paper. We
present some modification of Kalai and Vempala algorithm of following the
perturbed leader for the case of unrestrictedly large one-step gains. We show
that in general case the cumulative gain of any probabilistic prediction
algorithm can be much worse than the gain of some expert of the pool.
Nevertheless, we give the lower bound for this cumulative gain in general case
and construct a universal algorithm which has the optimal performance; we also
prove that in case when one-step gains of experts of the pool have ``limited
deviations'' the performance of our algorithm is close to the performance of
the best expert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4415</identifier>
 <datestamp>2009-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4415</id><created>2008-06-26</created><updated>2009-01-06</updated><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Zizhou</keyname><forenames>Vincent Wang</forenames></author></authors><title>On the inner and outer bounds of 3-receiver broadcast channels with
  2-degraded message sets</title><categories>cs.IT math.IT</categories><comments>5 pages,</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a broadcast channel with 3 receivers and 2 messages (M0, M1)
where two of the three receivers need to decode messages (M0, M1) while the
remaining one just needs to decode the message M0. We study the best known
inner and outer bounds under this setting, in an attempt to find the
deficiencies with the current techniques of establishing the bounds. We produce
a simple example where we are able to explicitly evaluate the inner bound and
show that it differs from the general outer bound. For a class of channels
where the general inner and outer bounds differ, we use a new argument to show
that the inner bound is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4422</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4422</id><created>2008-06-27</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>Computationally Efficient Estimators for Dimension Reductions Using
  Stable Random Projections</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The method of stable random projections is a tool for efficiently computing
the $l_\alpha$ distances using low memory, where $0&lt;\alpha \leq 2$ is a tuning
parameter. The method boils down to a statistical estimation task and various
estimators have been proposed, based on the geometric mean, the harmonic mean,
and the fractional power etc.
  This study proposes the optimal quantile estimator, whose main operation is
selecting, which is considerably less expensive than taking fractional power,
the main operation in previous estimators. Our experiments report that the
optimal quantile estimator is nearly one order of magnitude more
computationally efficient than previous estimators. For large-scale learning
tasks in which storing and computing pairwise distances is a serious
bottleneck, this estimator should be desirable.
  In addition to its computational advantages, the optimal quantile estimator
exhibits nice theoretical properties. It is more accurate than previous
estimators when $\alpha&gt;1$. We derive its theoretical error bounds and
establish the explicit (i.e., no hidden constants) sample complexity bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4423</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4423</id><created>2008-06-27</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>On Approximating the Lp Distances for p&gt;2</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications in machine learning and data mining require computing pairwise
Lp distances in a data matrix A. For massive high-dimensional data, computing
all pairwise distances of A can be infeasible. In fact, even storing A or all
pairwise distances of A in the memory may be also infeasible. This paper
proposes a simple method for p = 2, 4, 6, ... We first decompose the l_p (where
p is even) distances into a sum of 2 marginal norms and p-1 ``inner products''
at different orders. Then we apply normal or sub-Gaussian random projections to
approximate the resultant ``inner products,'' assuming that the marginal norms
can be computed exactly by a linear scan. We propose two strategies for
applying random projections. The basic projection strategy requires only one
projection matrix but it is more difficult to analyze, while the alternative
projection strategy requires p-1 projection matrices but its theoretical
analysis is much easier. In terms of the accuracy, at least for p=4, the basic
strategy is always more accurate than the alternative strategy if the data are
non-negative, which is common in reality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4451</identifier>
 <datestamp>2009-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4451</id><created>2008-06-27</created><updated>2009-03-27</updated><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>Counteracting Byzantine Adversaries with Network Coding: An Overhead
  Analysis</title><categories>cs.IT cs.CR math.IT</categories><comments>7 pages, 5 figures, MILCOM 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding increases throughput and is robust against failures and
erasures. However, since it allows mixing of information within the network, a
single corrupted packet generated by a Byzantine attacker can easily
contaminate the information to multiple destinations.
  In this paper, we study the transmission overhead associated with three
different schemes for detecting Byzantine adversaries at a node using network
coding: end-to-end error correction, packet-based Byzantine detection scheme,
and generation-based Byzantine detection scheme. In end-to-end error
correction, it is known that we can correct up to the min-cut between the
source and destinations. However, if we use Byzantine detection schemes, we can
detect polluted data, drop them, and therefore, only transmit valid data. For
the dropped data, the destinations perform erasure correction, which is
computationally lighter than error correction. We show that, with enough
attackers present in the network, Byzantine detection schemes may improve the
throughput of the network since we choose to forward only reliable information.
When the probability of attack is high, a packet-based detection scheme is the
most bandwidth efficient; however, when the probability of attack is low, the
overhead involved with signing each packet becomes costly, and the
generation-based scheme may be preferred. Finally, we characterize the tradeoff
between generation size and overhead of detection in bits as the probability of
attack increases in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4468</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4468</id><created>2008-06-27</created><updated>2009-08-03</updated><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author></authors><title>On Ergodic Sum Capacity of Fading Cognitive Multiple-Access and
  Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the information-theoretic limits of a secondary or
cognitive radio (CR) network under spectrum sharing with an existing primary
radio network. In particular, the fading cognitive multiple-access channel
(C-MAC) is first studied, where multiple secondary users transmit to the
secondary base station (BS) under both individual transmit-power constraints
and a set of interference-power constraints each applied at one of the primary
receivers. This paper considers the long-term (LT) or the short-term (ST)
transmit-power constraint over the fading states at each secondary transmitter,
combined with the LT or ST interference-power constraint at each primary
receiver. In each case, the optimal power allocation scheme is derived for the
secondary users to achieve the ergodic sum capacity of the fading C-MAC, as
well as the conditions for the optimality of the dynamic
time-division-multiple-access (D-TDMA) scheme in the secondary network. The
fading cognitive broadcast channel (C-BC) that models the downlink transmission
in the secondary network is then studied under the LT/ST transmit-power
constraint at the secondary BS jointly with the LT/ST interference-power
constraint at each of the primary receivers. It is shown that D-TDMA is indeed
optimal for achieving the ergodic sum capacity of the fading C-BC for all
combinations of transmit-power and interference-power constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4484</identifier>
 <datestamp>2009-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4484</id><created>2008-06-27</created><updated>2009-06-25</updated><authors><author><keyname>V'yugin</keyname><forenames>Vladimir</forenames></author></authors><title>On empirical meaning of randomness with respect to a real parameter</title><categories>cs.LG cs.AI</categories><comments>14 pages</comments><acm-class>I.2.6</acm-class><journal-ref>LNCS 4649, pp. 387-396, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the empirical meaning of randomness with respect to a family of
probability distributions $P_\theta$, where $\theta$ is a real parameter, using
algorithmic randomness theory. In the case when for a computable probability
distribution $P_\theta$ an effectively strongly consistent estimate exists, we
show that the Levin's a priory semicomputable semimeasure of the set of all
$P_\theta$-random sequences is positive if and only if the parameter $\theta$
is a computable real number. The different methods for generating
``meaningful'' $P_\theta$-random sequences with noncomputable $\theta$ are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4510</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4510</id><created>2008-06-27</created><authors><author><keyname>Geil</keyname><forenames>Olav</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Thomsen</keyname><forenames>Casper</forenames></author></authors><title>On Field Size and Success Probability in Network Coding</title><categories>cs.IT math.IT</categories><comments>16 pages, 3 figures, 2 tables. Accepted for publication at
  International Workshop on the Arithmetic of Finite Fields, WAIFI 2008</comments><journal-ref>Proceedings of the 2nd International Workshop on the Arithmetic of
  Finite Fields, WAIFI 2008, pp. 157-173</journal-ref><doi>10.1007/978-3-540-69499-1_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using tools from algebraic geometry and Groebner basis theory we solve two
problems in network coding. First we present a method to determine the smallest
field size for which linear network coding is feasible. Second we derive
improved estimates on the success probability of random linear network coding.
These estimates take into account which monomials occur in the support of the
determinant of the product of Edmonds matrices. Therefore we finally
investigate which monomials can occur in the determinant of the Edmonds matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4511</identifier>
 <datestamp>2013-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4511</id><created>2008-06-27</created><updated>2013-10-23</updated><authors><author><keyname>Wishnevsky</keyname><forenames>Konstantin P.</forenames></author></authors><title>The model of quantum evolution</title><categories>cs.AI</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to extremely unscientific
errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4526</identifier>
 <datestamp>2008-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4526</id><created>2008-06-27</created><updated>2008-12-23</updated><authors><author><keyname>Claveirole</keyname><forenames>Thomas</forenames></author><author><keyname>de Amorim</keyname><forenames>Marcelo Dias</forenames></author></authors><title>WiPal: Efficient Offline Merging of IEEE 802.11 Traces</title><categories>cs.NI</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Merging wireless traces is a fundamental step in measurement-based studies
involving multiple packet sniffers. Existing merging tools either require a
wired infrastructure or are limited in their usability. We propose WiPal, an
offline merging tool for IEEE 802.11 traces that has been designed to be
efficient and simple to use. WiPal is flexible in the sense that it does not
require any specific services, neither from monitors (like synchronization,
access to a wired network, or embedding specific software) nor from its
software environment (e.g. an SQL server). We present WiPal's operation and
show how its features - notably, its modular design - improve both ease of use
and efficiency. Experiments on real traces show that WiPal is an order of
magnitude faster than other tools providing the same features. To our
knowledge, WiPal is the only offline trace merger that can be used by the
research community in a straightforward fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4553</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4553</id><created>2008-06-27</created><updated>2008-10-16</updated><authors><author><keyname>Sofronie-Stokkermans</keyname><forenames>Viorica</forenames></author></authors><title>Interpolation in local theory extensions</title><categories>cs.LO cs.SE</categories><comments>31 pages, 1 figure</comments><acm-class>F.4.1; F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (October
  17, 2008) lmcs:1143</journal-ref><doi>10.2168/LMCS-4(4:1)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study interpolation in local extensions of a base theory. We
identify situations in which it is possible to obtain interpolants in a
hierarchical manner, by using a prover and a procedure for generating
interpolants in the base theory as black-boxes. We present several examples of
theory extensions in which interpolants can be computed this way, and discuss
applications in verification, knowledge representation, and modular reasoning
in combinations of local theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4572</identifier>
 <datestamp>2008-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4572</id><created>2008-06-27</created><authors><author><keyname>V'yugin</keyname><forenames>V. V.</forenames></author></authors><title>Problems of robustness for universal coding schemes</title><categories>cs.IT cs.OH math.IT</categories><comments>23 pages</comments><acm-class>F.2</acm-class><journal-ref>Problems of Information Transmission, 39 (2003), pp. 32-46</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lempel-Ziv universal coding scheme is asymptotically optimal for the
class of all stationary ergodic sources. A problem of robustness of this
property under small violations of ergodicity is studied. A notion of
deficiency of algorithmic randomness is used as a measure of disagreement
between data sequence and probability measure. We prove that universal
compressing schemes from a large class are non-robust in the following sense:
if the randomness deficiency grows arbitrarily slowly on initial fragments of
an infinite sequence then the property of asymptotic optimality of any
universal compressing algorithm can be violated. Lempel-Ziv compressing
algorithms are robust on infinite sequences generated by ergodic Markov chains
when the randomness deficiency of its initial fragments of length $n$ grows as
$o(n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4627</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4627</id><created>2008-06-30</created><updated>2008-10-21</updated><authors><author><keyname>Schmidt</keyname><forenames>Michael</forenames></author><author><keyname>Hornung</keyname><forenames>Thomas</forenames></author><author><keyname>Lausen</keyname><forenames>Georg</forenames></author><author><keyname>Pinkel</keyname><forenames>Christoph</forenames></author></authors><title>SP2Bench: A SPARQL Performance Benchmark</title><categories>cs.DB cs.PF</categories><comments>Conference paper to appear in Proc. ICDE'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the SPARQL query language for RDF has reached the W3C
recommendation status. In response to this emerging standard, the database
community is currently exploring efficient storage techniques for RDF data and
evaluation strategies for SPARQL queries. A meaningful analysis and comparison
of these approaches necessitates a comprehensive and universal benchmark
platform. To this end, we have developed SP^2Bench, a publicly available,
language-specific SPARQL performance benchmark. SP^2Bench is settled in the
DBLP scenario and comprises both a data generator for creating arbitrarily
large DBLP-like documents and a set of carefully designed benchmark queries.
The generated documents mirror key characteristics and social-world
distributions encountered in the original DBLP data set, while the queries
implement meaningful requests on top of this data, covering a variety of SPARQL
operator constellations and RDF access patterns. As a proof of concept, we
apply SP^2Bench to existing engines and discuss their strengths and weaknesses
that follow immediately from the benchmark results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4631</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4631</id><created>2008-06-27</created><updated>2010-11-04</updated><authors><author><keyname>Salikhmetov</keyname><forenames>Anton</forenames></author></authors><title>The Heap Lambda Machine</title><categories>cs.LO</categories><comments>14 pages, 4 figures, source code appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new machine architecture for evaluating lambda
expressions using the normal-order reduction, which guarantees that every
lambda expression will be evaluated if the expression has its normal form and
the system has enough memory. The architecture considered here operates using
heap memory only. Lambda expressions are represented as graphs, and all
algorithms used in the processing unit of this machine are non-recursive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4648</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4648</id><created>2008-06-28</created><authors><author><keyname>Budiyono</keyname><forenames>A.</forenames></author><author><keyname>Sudiyanto</keyname><forenames>T.</forenames></author></authors><title>An Algebraic Approach for the MIMO Control of Small Scale Helicopter</title><categories>cs.RO</categories><comments>Uploaded by ICIUS2007 Conference Organizer on behalf of the
  author(s). 9 pages, 11 figures</comments><acm-class>I.2.8</acm-class><journal-ref>Proceedings of the International Conference on Intelligent
  Unmanned System (ICIUS 2007), Bali, Indonesia, October 24-25, 2007, Paper No.
  ICIUS2007-A014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The control of small-scale helicopter is a MIMO problem. To use of classical
control approach to formally solve a MIMO problem, one needs to come up with
multidimensional Root Locus diagram to tune the control parameters. The problem
with the required dimension of the RL diagram for MIMO design has forced the
design procedure of classical approach to be conducted in cascaded multi-loop
SISO system starting from the innermost loop outward. To implement this control
approach for a helicopter, a pitch and roll attitude control system is often
subordinated to a, respectively, longitudinal and lateral velocity control
system in a nested architecture. The requirement for this technique to work is
that the inner attitude control loop must have a higher bandwidth than the
outer velocity control loop which is not the case for high performance mini
helicopter. To address the above problems, an algebraic design approach is
proposed in this work. The designed control using s-CDM approach is
demonstrated for hovering control of small-scale helicopter simultaneously
subjected to plant parameter uncertainties and wind disturbances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4650</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4650</id><created>2008-06-28</created><authors><author><keyname>Haryanto</keyname><forenames>Ismoyo</forenames></author><author><keyname>Setiawan</keyname><forenames>Joga Dharma</forenames></author><author><keyname>Budiyono</keyname><forenames>Agus</forenames></author></authors><title>Structural Damage Detection Using Randomized Trained Neural Networks</title><categories>cs.NE</categories><comments>Uploaded by ICIUS2007 Conference Organizer on behalf of the
  author(s). 5 pages, 9 figures, and 4 tables</comments><acm-class>I.2.8</acm-class><journal-ref>Proceedings of the International Conference on Intelligent
  Unmanned System (ICIUS 2007), Bali, Indonesia, October 24-25, 2007, Paper No.
  ICIUS2007-C022</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A computationally method on damage detection problems in structures was
conducted using neural networks. The problem that is considered in this works
consists of estimating the existence, location and extent of stiffness
reduction in structure which is indicated by the changes of the structural
static parameters such as deflection and strain. The neural network was trained
to recognize the behaviour of static parameter of the undamaged structure as
well as of the structure with various possible damage extent and location which
were modelled as random states. The proposed techniques were applied to detect
damage in a simply supported beam. The structure was analyzed using
finite-element-method (FEM) and the damage identification was conducted by a
back-propagation neural network using the change of the structural strain and
displacement. The results showed that using proposed method the strain is more
efficient for identification of damage than the displacement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4652</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4652</id><created>2008-06-28</created><authors><author><keyname>Gao</keyname><forenames>Yong</forenames></author></authors><title>A Fixed-Parameter Algorithm for Random Instances of Weighted d-CNF
  Satisfiability</title><categories>cs.DS cs.AI cs.CC</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study random instances of the weighted $d$-CNF satisfiability problem
(WEIGHTED $d$-SAT), a generic W[1]-complete problem. A random instance of the
problem consists of a fixed parameter $k$ and a random $d$-CNF formula
$\weicnf{n}{p}{k, d}$ generated as follows: for each subset of $d$ variables
and with probability $p$, a clause over the $d$ variables is selected uniformly
at random from among the $2^d - 1$ clauses that contain at least one negated
literals.
  We show that random instances of WEIGHTED $d$-SAT can be solved in $O(k^2n +
n^{O(1)})$-time with high probability, indicating that typical instances of
WEIGHTED $d$-SAT under this instance distribution are fixed-parameter
tractable. The result also hold for random instances from the model
$\weicnf{n}{p}{k,d}(d')$ where clauses containing less than $d' (1 &lt; d' &lt; d)$
negated literals are forbidden, and for random instances of the renormalized
(miniaturized) version of WEIGHTED $d$-SAT in certain range of the random
model's parameter $p(n)$. This, together with our previous results on the
threshold behavior and the resolution complexity of unsatisfiable instances of
$\weicnf{n}{p}{k, d}$, provides an almost complete characterization of the
typical-case behavior of random instances of WEIGHTED $d$-SAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4667</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4667</id><created>2008-06-28</created><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Chen</keyname><forenames>Bin</forenames></author><author><keyname>Yang</keyname><forenames>Xia</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Overlaid Cellular and Mobile Ad Hoc Networks</title><categories>cs.IT math.IT</categories><comments>5 pages; submitted to IEEE ICCS 2008 (Guangzhou, P.R.China)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cellular systems using frequency division duplex, growing Internet
services cause unbalance of uplink and downlink traffic, resulting in poor
uplink spectrum utilization. Addressing this issue, this paper considers
overlaying an ad hoc network onto a cellular uplink network for improving
spectrum utilization and spatial reuse efficiency. Transmission capacities of
the overlaid networks are analyzed, which are defined as the maximum densities
of the ad hoc nodes and mobile users under an outage constraint. Using tools
from stochastic geometry, the capacity tradeoff curves for the overlaid
networks are shown to be linear. Deploying overlaid networks based on frequency
separation is proved to achieve higher network capacities than that based on
spatial separation. Furthermore, spatial diversity is shown to enhance network
capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4686</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4686</id><created>2008-06-28</created><updated>2008-07-03</updated><authors><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Li</keyname><forenames>Lihong</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Sparse Online Learning via Truncated Gradient</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a general method called truncated gradient to induce sparsity in
the weights of online learning algorithms with convex loss functions. This
method has several essential properties: The degree of sparsity is continuous
-- a parameter controls the rate of sparsification from no sparsification to
total sparsification. The approach is theoretically motivated, and an instance
of it can be regarded as an online counterpart of the popular
$L_1$-regularization method in the batch setting. We prove that small rates of
sparsification result in only small additional regret with respect to typical
online learning guarantees. The approach works well empirically. We apply the
approach to several datasets and find that for datasets with large numbers of
features, substantial sparsity is discoverable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4695</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4695</id><created>2008-06-28</created><authors><author><keyname>Daneshgaran</keyname><forenames>F.</forenames></author><author><keyname>Laddomada</keyname><forenames>M.</forenames></author><author><keyname>Mesiti</keyname><forenames>F.</forenames></author><author><keyname>Mondin</keyname><forenames>M.</forenames></author></authors><title>On the Throughput Allocation for Proportional Fairness in Multirate IEEE
  802.11 DCF</title><categories>cs.NI</categories><comments>Submitted to IEEE CCNC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a modified proportional fairness (PF) criterion suitable
for mitigating the \textit{rate anomaly} problem of multirate IEEE 802.11
Wireless LANs employing the mandatory Distributed Coordination Function (DCF)
option. Compared to the widely adopted assumption of saturated network, the
proposed criterion can be applied to general networks whereby the contending
stations are characterized by specific packet arrival rates, $\lambda_s$, and
transmission rates $R_d^{s}$.
  The throughput allocation resulting from the proposed algorithm is able to
greatly increase the aggregate throughput of the DCF while ensuring fairness
levels among the stations of the same order of the ones available with the
classical PF criterion. Put simply, each station is allocated a throughput that
depends on a suitable normalization of its packet rate, which, to some extent,
measures the frequency by which the station tries to gain access to the
channel. Simulation results are presented for some sample scenarios, confirming
the effectiveness of the proposed criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4703</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4703</id><created>2008-06-28</created><updated>2008-07-24</updated><authors><author><keyname>Li</keyname><forenames>Feng</forenames></author><author><keyname>Zhou</keyname><forenames>Shuigeng</forenames></author></authors><title>Challenging More Updates: Towards Anonymous Re-publication of Fully
  Dynamic Datasets</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most existing anonymization work has been done on static datasets, which have
no update and need only one-time publication. Recent studies consider
anonymizing dynamic datasets with external updates: the datasets are updated
with record insertions and/or deletions. This paper addresses a new problem:
anonymous re-publication of datasets with internal updates, where the attribute
values of each record are dynamically updated. This is an important and
challenging problem for attribute values of records are updating frequently in
practice and existing methods are unable to deal with such a situation.
  We initiate a formal study of anonymous re-publication of dynamic datasets
with internal updates, and show the invalidation of existing methods. We
introduce theoretical definition and analysis of dynamic datasets, and present
a general privacy disclosure framework that is applicable to all anonymous
re-publication problems. We propose a new counterfeited generalization
principle alled m-Distinct to effectively anonymize datasets with both external
updates and internal updates. We also develop an algorithm to generalize
datasets to meet m-Distinct. The experiments conducted on real-world data
demonstrate the effectiveness of the proposed solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4722</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4722</id><created>2008-06-28</created><authors><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author><author><keyname>Kusuma</keyname><forenames>Julius</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author></authors><title>Malleable Coding: Compressed Palimpsests</title><categories>cs.IT math.IT</categories><comments>39 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A malleable coding scheme considers not only compression efficiency but also
the ease of alteration, thus encouraging some form of recycling of an old
compressed version in the formation of a new one. Malleability cost is the
difficulty of synchronizing compressed versions, and malleable codes are of
particular interest when representing information and modifying the
representation are both expensive. We examine the trade-off between compression
efficiency and malleability cost under a malleability metric defined with
respect to a string edit distance. This problem introduces a metric topology to
the compressed domain. We characterize the achievable rates and malleability as
the solution of a subgraph isomorphism problem. This can be used to argue that
allowing conditional entropy of the edited message given the original message
to grow linearly with block length creates an exponential increase in code
length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4735</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4735</id><created>2008-06-29</created><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Gutner</keyname><forenames>Shai</forenames></author></authors><title>Linear Time Algorithms for Finding a Dominating Set of Fixed Size in
  Degenerated Graphs</title><categories>cs.DS cs.DM</categories><journal-ref>Proc. of 13th COCOON (2007), 394-405</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is substantial literature dealing with fixed parameter algorithms for
the dominating set problem on various families of graphs. In this paper, we
give a $k^{O(dk)} n$ time algorithm for finding a dominating set of size at
most $k$ in a $d$-degenerated graph with $n$ vertices. This proves that the
dominating set problem is fixed-parameter tractable for degenerated graphs. For
graphs that do not contain $K_h$ as a topological minor, we give an improved
algorithm for the problem with running time $(O(h))^{hk} n$. For graphs which
are $K_h$-minor-free, the running time is further reduced to $(O(\log
h))^{hk/2} n$. Fixed-parameter tractable algorithms that are linear in the
number of vertices of the graph were previously known only for planar graphs.
  For the families of graphs discussed above, the problem of finding an induced
cycle of a given length is also addressed. For every fixed $H$ and $k$, we show
that if an $H$-minor-free graph $G$ with $n$ vertices contains an induced cycle
of size $k$, then such a cycle can be found in O(n) expected time as well as in
$O(n \log n)$ worst-case time. Some results are stated concerning the
(im)possibility of establishing linear time algorithms for the more general
family of degenerated graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4737</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4737</id><created>2008-06-29</created><authors><author><keyname>Choi</keyname><forenames>Sang Won</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>On the Multiplexing Gain of K-user Partially Connected Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory
  (Correspondence), June 29, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multiplexing gain (MUXG) of $K$-user interference channel (IC) with
partially connected interfering links is analyzed. The motivation for the
partially connected IC comes from the fact that not all interferences are
equally strong in practice. The MUXG is characterized as a function of the
number ($K$) of users and the number ($N \geq 1$) of interfering links. Our
analysis is mainly based on the interference alignment (IA) technique to
mitigate interference. Our main results are as follows: One may expect that
higher MUXG can be attained when some of interfering links do not exist.
However, when $N$ is odd and $K=N+2$, the MUXG is not increased beyond the
optimal MUXG of fully connected IC, which is $\frac{KM}{2}$. The number of
interfering links has no influence on the achievable MUXG using IA, but affects
the efficiency in terms of the number of required channel realizations: When
N=1 or 2, the optimal MUXG of the fully connected IC is achievable with a
finite number of channel realizations. In case of $N \geq 3$, however, the MUXG
of $\frac{KM}{2}$ can be achieved asymptotically as the number of channel
realizations tends to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4746</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4746</id><created>2008-06-29</created><updated>2010-09-26</updated><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Concept-Oriented Programming</title><categories>cs.PL</categories><comments>46 pages, 8 figures, 11 listings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object-oriented programming (OOP) is aimed at describing the structure and
behaviour of objects by hiding the mechanism of their representation and access
in primitive references. In this article we describe an approach, called
concept-oriented programming (COP), which focuses on modelling references
assuming that they also possess application-specific structure and behaviour
accounting for a great deal or even most of the overall program complexity.
References in COP are completely legalized and get the same status as objects
while the functions are distributed among both objects and references. In order
to support this design we introduce a new programming construct, called
concept, which generalizes conventional classes and concept inclusion relation
generalizing class inheritance. The main advantage of COP is that it allows
programmers to describe two sides of any program: explicitly used functions of
objects and intermediate functionality of references having cross-cutting
nature and executed implicitly behind the scenes during object access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4749</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4749</id><created>2008-06-29</created><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Nested Ordered Sets and their Use for Data Modelling</title><categories>cs.DB</categories><comments>15 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new approach to data modelling, called the
concept-oriented model (CoM), and describe its main features and
characteristics including data semantics and operations. The distinguishing
feature of this model is that it is based on the formalism of nested ordered
sets where any element participates in two structures simultaneously:
hierarchical (nested) and multi-dimensional (ordered). An element of the model
is postulated to consist of two parts, called identity and entity, and the
whole approach can be naturally broken into two branches: identity modelling
and entity modelling. We also propose a new query language with the main
construct, called concept, defined as a pair of two classes: identity class and
entity class. We describe how its operations of projection, de-projection and
product can be used to solve typical data modelling tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4773</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4773</id><created>2008-06-29</created><authors><author><keyname>Shalvi</keyname><forenames>Ofir</forenames></author><author><keyname>Sommer</keyname><forenames>Naftali</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Signal Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by signal processing, we present a new class of channel codes,
called signal codes, for continuous-alphabet channels. Signal codes are lattice
codes whose encoding is done by convolving an integer information sequence with
a fixed filter pattern. Decoding is based on the bidirectional sequential stack
decoder, which can be implemented efficiently using the heap data structure.
Error analysis and simulation results indicate that signal codes can achieve
low error rate at approximately 1dB from channel capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4787</identifier>
 <datestamp>2008-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4787</id><created>2008-06-29</created><updated>2008-07-12</updated><authors><author><keyname>Haverkort</keyname><forenames>Herman</forenames></author><author><keyname>van Walderveen</keyname><forenames>Freek</forenames></author></authors><title>Locality and Bounding-Box Quality of Two-Dimensional Space-Filling
  Curves</title><categories>cs.CG cs.DB</categories><comments>24 pages, full version of paper to appear in ESA. Difference with
  first version: minor editing; Fig. 2(m) corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space-filling curves can be used to organise points in the plane into
bounding-box hierarchies (such as R-trees). We develop measures of the
bounding-box quality of space-filling curves that express how effective
different space-filling curves are for this purpose. We give general lower
bounds on the bounding-box quality measures and on locality according to
Gotsman and Lindenbaum for a large class of space-filling curves. We describe a
generic algorithm to approximate these and similar quality measures for any
given curve. Using our algorithm we find good approximations of the locality
and the bounding-box quality of several known and new space-filling curves.
Surprisingly, some curves with relatively bad locality by Gotsman and
Lindenbaum's measure, have good bounding-box quality, while the curve with the
best-known locality has relatively bad bounding-box quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4790</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4790</id><created>2008-06-29</created><updated>2010-02-03</updated><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Chung</keyname><forenames>Kai-Min</forenames></author><author><keyname>Liu</keyname><forenames>Zhenming</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>AMS Without 4-Wise Independence on Product Domains</title><categories>cs.DS</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In their seminal work, Alon, Matias, and Szegedy introduced several sketching
techniques, including showing that 4-wise independence is sufficient to obtain
good approximations of the second frequency moment. In this work, we show that
their sketching technique can be extended to product domains $[n]^k$ by using
the product of 4-wise independent functions on $[n]$. Our work extends that of
Indyk and McGregor, who showed the result for $k = 2$. Their primary motivation
was the problem of identifying correlations in data streams. In their model, a
stream of pairs $(i,j) \in [n]^2$ arrive, giving a joint distribution $(X,Y)$,
and they find approximation algorithms for how close the joint distribution is
to the product of the marginal distributions under various metrics, which
naturally corresponds to how close $X$ and $Y$ are to being independent. By
using our technique, we obtain a new result for the problem of approximating
the $\ell_2$ distance between the joint distribution and the product of the
marginal distributions for $k$-ary vectors, instead of just pairs, in a single
pass. Our analysis gives a randomized algorithm that is a $(1 \pm \epsilon)$
approximation (with probability $1-\delta$) that requires space logarithmic in
$n$ and $m$ and proportional to $3^k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4802</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4802</id><created>2008-06-30</created><authors><author><keyname>Freund</keyname><forenames>Yoav</forenames></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author></authors><title>A new Hedging algorithm and its application to inferring latent random
  variables</title><categories>cs.GT cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new online learning algorithm for cumulative discounted gain.
This learning algorithm does not use exponential weights on the experts.
Instead, it uses a weighting scheme that depends on the regret of the master
algorithm relative to the experts. In particular, experts whose discounted
cumulative gain is smaller (worse) than that of the master algorithm receive
zero weight. We also sketch how a regret-based algorithm can be used as an
alternative to Bayesian averaging in the context of inferring latent random
variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4858</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4858</id><created>2008-06-30</created><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>Csaba D.</forenames></author><author><keyname>Xu</keyname><forenames>Guangwu</forenames></author></authors><title>On stars and Steiner stars. II</title><categories>cs.CG</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A {\em Steiner star} for a set $P$ of $n$ points in $\RR^d$ connects an
arbitrary center point to all points of $P$, while a {\em star} connects a
point $p\in P$ to the remaining $n-1$ points of $P$. All connections are
realized by straight line segments. Fekete and Meijer showed that the minimum
star is at most $\sqrt{2}$ times longer than the minimum Steiner star for any
finite point configuration in $\RR^d$. The maximum ratio between them, over all
finite point configurations in $\RR^d$, is called the {\em star Steiner ratio}
in $\RR^d$. It is conjectured that this ratio is $4/\pi = 1.2732...$ in the
plane and $4/3=1.3333...$ in three dimensions. Here we give upper bounds of
1.3631 in the plane, and 1.3833 in 3-space, thereby substantially improving
recent upper bounds of 1.3999, and $\sqrt{2}-10^{-4}$, respectively. Our
results also imply improved bounds on the maximum ratios between the minimum
star and the maximum matching in two and three dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4859</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4859</id><created>2008-06-30</created><updated>2008-09-02</updated><authors><author><keyname>Lengrand</keyname><forenames>St&#xe9;phane</forenames><affiliation>LIX</affiliation></author></authors><title>Termination of lambda-calculus with the extra Call-By-Value rule known
  as assoc</title><categories>cs.LO</categories><proxy>ccsd inria-00292029</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove that any lambda-term that is strongly normalising for
beta-reduction is also strongly normalising for beta,assoc-reduction. assoc is
a call-by-value rule that has been used in works by Moggi, Joachimsky, Espirito
Santo and others. The result has often been justified with incomplete or
incorrect proofs. Here we give one in full details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4874</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4874</id><created>2008-06-30</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Myopic Coding in Multiterminal Networks</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, Vol. 54, No. 7, pp.
  3295-3314, Jul. 2008</journal-ref><doi>10.1109/TIT.2008.924675</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the interplay between cooperation and achievable
rates in multi-terminal networks. Cooperation refers to the process of nodes
working together to relay data toward the destination. There is an inherent
tradeoff between achievable information transmission rates and the level of
cooperation, which is determined by how many nodes are involved and how the
nodes encode/decode the data. We illustrate this trade-off by studying
information-theoretic decode-forward based coding strategies for data
transmission in multi-terminal networks. Decode-forward strategies are usually
discussed in the context of omniscient coding, in which all nodes in the
network fully cooperate with each other, both in encoding and decoding. In this
paper, we investigate myopic coding, in which each node cooperates with only a
few neighboring nodes. We show that achievable rates of myopic decode-forward
can be as large as that of omniscient decode-forward in the low SNR regime. We
also show that when each node has only a few cooperating neighbors, adding one
node into the cooperation increases the transmission rate significantly.
Furthermore, we show that myopic decode-forward can achieve non-zero rates as
the network size grows without bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4899</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4899</id><created>2008-06-30</created><authors><author><keyname>Golin</keyname><forenames>Mordecai</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author></authors><title>A Dynamic Programming Approach To Length-Limited Huffman Coding</title><categories>cs.DS cs.IT math.IT</categories><acm-class>E.1; E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ``state-of-the-art'' in Length Limited Huffman Coding algorithms is the
$\Theta(ND)$-time, $\Theta(N)$-space one of Hirschberg and Larmore, where $D\le
N$ is the length restriction on the code. This is a very clever, very problem
specific, technique. In this note we show that there is a simple
Dynamic-Programming (DP) method that solves the problem with the same time and
space bounds. The fact that there was an $\Theta(ND)$ time DP algorithm was
previously known; it is a straightforward DP with the Monge property (which
permits an order of magnitude speedup). It was not interesting, though, because
it also required $\Theta(ND)$ space. The main result of this paper is the
technique developed for reducing the space. It is quite simple and applicable
to many other problems modeled by DPs with the Monge property. We illustrate
this with examples from web-proxy design and wireless mobile paging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4920</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4920</id><created>2008-06-30</created><authors><author><keyname>Dang-Ngoc</keyname><forenames>Tuyet-Tram</forenames><affiliation>PRISM</affiliation></author><author><keyname>Gardarin</keyname><forenames>Georges</forenames><affiliation>PRISM</affiliation></author></authors><title>Conception et Evaluation de XQuery dans une architecture de m\'ediation
  &quot;Tout-XML&quot;</title><categories>cs.DB</categories><proxy>ccsd hal-00292108</proxy><journal-ref>Revue ISI (Integration de syst\`emes d'information) : Num\'ero
  sp\'ecial sur les Bases de Donn\'ees Semi-structur\'ees 8, 5-6 (2003) 11-25</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML has emerged as the leading language for representing and exchanging data
not only on the Web, but also in general in the enterprise. XQuery is emerging
as the standard query language for XML. Thus, tools are required to mediate
between XML queries and heterogeneous data sources to integrate data in XML.
This paper presents the XMedia mediator, a unique tool for integrating and
querying disparate heterogeneous information as unified XML views. It describes
the mediator architecture and focuses on the unique distributed query
processing technology implemented in this component. Query evaluation is based
on an original XML algebra simply extending classical operators to process
tuples of tree elements. Further, we present a set of performance evaluation on
a relational benchmark, which leads to discuss possible performance
enhancements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4921</identifier>
 <datestamp>2008-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4921</id><created>2008-06-30</created><authors><author><keyname>Popovici</keyname><forenames>Eugen</forenames><affiliation>VALORIA</affiliation></author><author><keyname>M&#xe9;nier</keyname><forenames>Gilbas</forenames><affiliation>VALORIA</affiliation></author><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>VALORIA</affiliation></author></authors><title>Interpr\'etation vague des contraintes structurelles pour la RI dans des
  corpus de documents XML - \'Evaluation d'une m\'ethode approch\'ee de RI
  structur\'ee</title><categories>cs.IR</categories><comments>26 pages, ISBN 978-2-7462-1969-4</comments><proxy>ccsd hal-00290634</proxy><journal-ref>Document num\'erique 10, 1 (2007) 63--88</journal-ref><doi>10.3166/dn.10.63-88</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose specific data structures designed to the indexing and retrieval of
information elements in heterogeneous XML data bases. The indexing scheme is
well suited to the management of various contextual searches, expressed either
at a structural level or at an information content level. The approximate
search mechanisms are based on a modified Levenshtein editing distance and
information fusion heuristics. The implementation described highlights the
mixing of structured information presented as field/value instances and free
text elements. The retrieval performances of the proposed approach are
evaluated within the INEX 2005 evaluation campaign. The evaluation results rank
the proposed approach among the best evaluated XML IR systems for the VVCAS
task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4956</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4956</id><created>2008-06-30</created><updated>2008-09-10</updated><authors><author><keyname>de Alfaro</keyname><forenames>Luca</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author><author><keyname>Raman</keyname><forenames>Vishwanath</forenames></author><author><keyname>Stoelinga</keyname><forenames>Mari&#xeb;lle</forenames></author></authors><title>Game Refinement Relations and Metrics</title><categories>cs.LO</categories><acm-class>F.4.1; F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (September
  11, 2008) lmcs:781</journal-ref><doi>10.2168/LMCS-4(3:7)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two-player games played over finite state spaces for an infinite
number of rounds. At each state, the players simultaneously choose moves; the
moves determine a successor state. It is often advantageous for players to
choose probability distributions over moves, rather than single moves. Given a
goal, for example, reach a target state, the question of winning is thus a
probabilistic one: what is the maximal probability of winning from a given
state?
  On these game structures, two fundamental notions are those of equivalences
and metrics. Given a set of winning conditions, two states are equivalent if
the players can win the same games with the same probability from both states.
Metrics provide a bound on the difference in the probabilities of winning
across states, capturing a quantitative notion of state similarity.
  We introduce equivalences and metrics for two-player game structures, and we
show that they characterize the difference in probability of winning games
whose goals are expressed in the quantitative mu-calculus. The quantitative
mu-calculus can express a large set of goals, including reachability, safety,
and omega-regular properties. Thus, we claim that our relations and metrics
provide the canonical extensions to games, of the classical notion of
bisimulation for transition systems. We develop our results both for
equivalences and metrics, which generalize bisimulation, and for asymmetrical
versions, which generalize simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4958</identifier>
 <datestamp>2008-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4958</id><created>2008-06-30</created><updated>2008-07-28</updated><authors><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Deterministic Designs with Deterministic Guarantees: Toeplitz Compressed
  Sensing Matrices, Sequence Designs and System Identification</title><categories>cs.IT math.IT</categories><comments>added references. streamlined introduction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new family of discrete sequences having &quot;random
like&quot; uniformly decaying auto-correlation properties. The new class of infinite
length sequences are higher order chirps constructed using irrational numbers.
Exploiting results from the theory of continued fractions and diophantine
approximations, we show that the class of sequences so formed has the property
that the worst-case auto-correlation coefficients for every finite length
sequence decays at a polynomial rate. These sequences display doppler immunity
as well. We also show that Toeplitz matrices formed from such sequences satisfy
restricted-isometry-property (RIP), a concept that has played a central role
recently in Compressed Sensing applications. Compressed sensing has
conventionally dealt with sensing matrices with arbitrary components.
Nevertheless, such arbitrary sensing matrices are not appropriate for linear
system identification and one must employ Toeplitz structured sensing matrices.
Linear system identification plays a central role in a wide variety of
applications such as channel estimation for multipath wireless systems as well
as control system applications. Toeplitz matrices are also desirable on account
of their filtering structure, which allows for fast implementation together
with reduced storage requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4979</identifier>
 <datestamp>2008-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4979</id><created>2008-06-30</created><authors><author><keyname>Rouayheb</keyname><forenames>Salim Y. El</forenames></author><author><keyname>Georghiades</keyname><forenames>C. N.</forenames></author><author><keyname>Soljanin</keyname><forenames>E.</forenames></author><author><keyname>Sprintson</keyname><forenames>A.</forenames></author></authors><title>Bounds on Codes Based on Graph Theory</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $A_q(n,d)$ be the maximum order (maximum number of codewords) of a
$q$-ary code of length $n$ and Hamming distance at least $d$. And let
$A(n,d,w)$ that of a binary code of constant weight $w$. Building on results
from algebraic graph theory and Erd\H{o}s-ko-Rado like theorems in extremal
combinatorics, we show how several known bounds on $A_q(n,d)$ and $A(n,d,w)$
can be easily obtained in a single framework. For instance, both the Hamming
and Singleton bounds can derived as an application of a property relating the
clique number and the independence number of vertex transitive graphs. Using
the same techniques, we also derive some new bounds and present some additional
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0007</identifier>
 <datestamp>2009-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0007</id><created>2008-06-30</created><updated>2009-05-13</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Finding Large Clique Minors is Hard</title><categories>cs.DM</categories><comments>5 pages, 1 figure</comments><acm-class>F.1.3</acm-class><journal-ref>J. Graph Algorithms and Applications 13(2):197-204, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that it is NP-complete, given a graph G and a parameter h, to
determine whether G contains a complete graph K_h as a minor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0023</identifier>
 <datestamp>2009-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0023</id><created>2008-06-30</created><updated>2009-03-06</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Automatic Metadata Generation using Associative Networks</title><categories>cs.IR cs.DL</categories><report-no>LA-UR-06-3445</report-no><acm-class>H.3.1; H.3.7</acm-class><journal-ref>ACM Transactions on Information Systems, volume 27, number 2,
  pages 1-20, ISSN: 1046-8188, ACM Press, February 2009</journal-ref><doi>10.1145/1462198.1462199</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In spite of its tremendous value, metadata is generally sparse and
incomplete, thereby hampering the effectiveness of digital information
services. Many of the existing mechanisms for the automated creation of
metadata rely primarily on content analysis which can be costly and
inefficient. The automatic metadata generation system proposed in this article
leverages resource relationships generated from existing metadata as a medium
for propagation from metadata-rich to metadata-poor resources. Because of its
independence from content analysis, it can be applied to a wide variety of
resource media types and is shown to be computationally inexpensive. The
proposed method operates through two distinct phases. Occurrence and
co-occurrence algorithms first generate an associative network of repository
resources leveraging existing repository metadata. Second, using the
associative network as a substrate, metadata associated with metadata-rich
resources is propagated to metadata-poor resources by means of a discrete-form
spreading activation algorithm. This article discusses the general framework
for building associative networks, an algorithm for disseminating metadata
through such networks, and the results of an experiment and validation of the
proposed method using a standard bibliographic dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0038</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0038</id><created>2008-06-30</created><updated>2010-03-04</updated><authors><author><keyname>Zhang</keyname><forenames>Changyong</forenames></author></authors><title>A Novel Mathematical Model for the Unique Shortest Path Routing Problem</title><categories>math.OC cs.DS</categories><comments>31 pages, 4 figures</comments><msc-class>90B10; 90B18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link weights are the principal parameters of shortest path routing protocols,
the most commonly used protocols for IP networks. The problem of optimally
setting link weights for unique shortest path routing is addressed. Due to the
complexity of the constraints involved, there exist challenges to formulate the
problem properly, so that a solution algorithm may be developed which could
prove to be more efficient than those already in existence. In this paper, a
novel complete formulation with a polynomial number of constraints is first
introduced and then mathematically proved to be correct. It is further
illustrated that the formulation has advantages over a prior one in terms of
both constraint structure and model size for a proposed decomposition method to
solve the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0042</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0042</id><created>2008-06-30</created><authors><author><keyname>Liu</keyname><forenames>Youjian</forenames></author></authors><title>A Simple Converse Proof and a Unified Capacity Formula for Channels with
  Input Constraints</title><categories>cs.IT math.IT</categories><comments>A single column version of this paper was submitted to IEEE
  Transactions on Information Theory on June 17, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the single-letter capacity formula and the converse proof of a channel
without constraints, we provide a simple approach to extend the results for the
same channel but with constraints. The resulting capacity formula is the
minimum of a Lagrange dual function. It gives an unified formula in the sense
that it works regardless whether the problem is convex. If the problem is
non-convex, we show that the capacity can be larger than the formula obtained
by the naive approach of imposing constraints on the maximization in the
capacity formula of the case without the constraints.
  The extension on the converse proof is simply by adding a term involving the
Lagrange multiplier and the constraints. The rest of the proof does not need to
be changed. We name the proof method the Lagrangian Converse Proof. In
contrast, traditional approaches need to construct a better input distribution
for convex problems or need to introduce a time sharing variable for non-convex
problems. We illustrate the Lagrangian Converse Proof for three channels, the
classic discrete time memoryless channel, the channel with non-causal
channel-state information at the transmitter, the channel with limited
channel-state feedback. The extension to the rate distortion theory is also
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0070</identifier>
 <datestamp>2008-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0070</id><created>2008-07-01</created><authors><author><keyname>Arkhipkin</keyname><forenames>Yuri</forenames></author></authors><title>Quantitative Paradigm of Software Reliability as Content Relevance</title><categories>cs.SE cs.IR</categories><comments>14 pages, 3 figures</comments><acm-class>D.2.5; D.2.8; D.2.9; H.3.1; D.1.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a quantitative approach to software reliability and
content relevance definitions validated by the systems' potential reliability
law.Thus it is argued for the unified math nature or quantitative paradigm of
software reliability and content relevance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0087</identifier>
 <datestamp>2008-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0087</id><created>2008-07-01</created><authors><author><keyname>Cardona</keyname><forenames>Gabriel</forenames></author><author><keyname>Llabres</keyname><forenames>Merce</forenames></author><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author><author><keyname>Valiente</keyname><forenames>Gabriel</forenames></author></authors><title>Path lengths in tree-child time consistent hybridization networks</title><categories>q-bio.PE cs.CE cs.DM q-bio.QM</categories><comments>31 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Hybridization networks are representations of evolutionary histories that
allow for the inclusion of reticulate events like recombinations,
hybridizations, or lateral gene transfers. The recent growth in the number of
hybridization network reconstruction algorithms has led to an increasing
interest in the definition of metrics for their comparison that can be used to
assess the accuracy or robustness of these methods. In this paper we establish
some basic results that make it possible the generalization to tree-child time
consistent (TCTC) hybridization networks of some of the oldest known metrics
for phylogenetic trees: those based on the comparison of the vectors of path
lengths between leaves. More specifically, we associate to each hybridization
network a suitably defined vector of `splitted' path lengths between its
leaves, and we prove that if two TCTC hybridization networks have the same such
vectors, then they must be isomorphic. Thus, comparing these vectors by means
of a metric for real-valued vectors defines a metric for TCTC hybridization
networks. We also consider the case of fully resolved hybridization networks,
where we prove that simpler, `non-splitted' vectors can be used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0093</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0093</id><created>2008-07-01</created><authors><author><keyname>Vishwanathan</keyname><forenames>S. V. N.</forenames></author><author><keyname>Borgwardt</keyname><forenames>Karsten M.</forenames></author><author><keyname>Kondor</keyname><forenames>Imre Risi</forenames></author><author><keyname>Schraudolph</keyname><forenames>Nicol N.</forenames></author></authors><title>Graph Kernels</title><categories>cs.LG</categories><comments>http://jmlr.csail.mit.edu/papers/v11/vishwanathan10a.html</comments><journal-ref>Journal of Machine Learning Research 11 (Apr): 1201-1242, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a unified framework to study graph kernels, special cases of which
include the random walk graph kernel \citep{GaeFlaWro03,BorOngSchVisetal05},
marginalized graph kernel \citep{KasTsuIno03,KasTsuIno04,MahUedAkuPeretal04},
and geometric kernel on graphs \citep{Gaertner02}. Through extensions of linear
algebra to Reproducing Kernel Hilbert Spaces (RKHS) and reduction to a
Sylvester equation, we construct an algorithm that improves the time complexity
of kernel computation from $O(n^6)$ to $O(n^3)$. When the graphs are sparse,
conjugate gradient solvers or fixed-point iterations bring our algorithm into
the sub-cubic domain. Experiments on graphs from bioinformatics and other
application domains show that it is often more than a thousand times faster
than previous approaches. We then explore connections between diffusion kernels
\citep{KonLaf02}, regularization on graphs \citep{SmoKon03}, and graph kernels,
and use these connections to propose new graph kernels. Finally, we show that
rational kernels \citep{CorHafMoh02,CorHafMoh03,CorHafMoh04} when specialized
to graphs reduce to the random walk graph kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0140</identifier>
 <datestamp>2008-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0140</id><created>2008-07-01</created><authors><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>The Dynamics of Probabilistic Population Protocols</title><categories>cs.DC cs.GT</categories><comments>To appear as a Brief Announced in Proc. of 22nd International
  Symposium on Distributed Computing (DISC 2008), September 22-24, 2008,
  Arcachon, France</comments><acm-class>C.2.4; C.2.1; F.1.1; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study here the dynamics (and stability) of Probabilistic Population
Protocols, via the differential equations approach. We provide a quite general
model and we show that it includes the model of Angluin et. al. in the case of
very large populations. For the general model we give a sufficient condition
for stability that can be checked in polynomial time. We also study two
interesting subcases: (a) protocols whose specifications (in our terms) are
configuration independent. We show that they are always stable and that their
eventual subpopulation percentages are actually a Markov Chain stationary
distribution. (b) protocols that have dynamics resembling virus spread. We show
that their dynamics are actually similar to the well-known Replicator Dynamics
of Evolutionary Games. We also provide a sufficient condition for stability in
this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0161</identifier>
 <datestamp>2008-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0161</id><created>2008-07-01</created><authors><author><keyname>Khandjian</keyname><forenames>Arkadiy</forenames></author></authors><title>Increase of Software Safety</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  New model of software safety is offered. Distribution of mistakes in program
on stages of life cycle is researched. Study of ways of increase of reliability
of software at help simulation program is leaded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0199</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0199</id><created>2008-07-01</created><updated>2011-04-11</updated><authors><author><keyname>Unger</keyname><forenames>Thomas</forenames></author><author><keyname>Markin</keyname><forenames>Nadya</forenames></author></authors><title>Quadratic Forms and Space-Time Block Codes from Generalized Quaternion
  and Biquaternion Algebras</title><categories>cs.IT math.IT</categories><comments>8 pages, final version</comments><journal-ref>IEEE Trans. Inform. Theory 57 (2011), no. 9, 6148-6156</journal-ref><doi>10.1109/TIT.2011.2161909</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of space-time block codes (STBCs), the theory of generalized
quaternion and biquaternion algebras (i.e., tensor products of two quaternion
algebras) over arbitrary base fields is presented, as well as quadratic form
theoretic criteria to check if such algebras are division algebras. For base
fields relevant to STBCs, these criteria are exploited, via Springer's theorem,
to construct several explicit infinite families of (bi-)quaternion division
algebras. These are used to obtain new $2\x 2$ and $4\x 4$ STBCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0204</identifier>
 <datestamp>2008-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0204</id><created>2008-07-01</created><authors><author><keyname>Krishnakumar</keyname><forenames>R. N.</forenames></author><author><keyname>Naveen</keyname><forenames>N.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Diversity Multiplexing Tradeoff of Asynchronous Cooperative Relay
  Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The assumption of nodes in a cooperative communication relay network
operating in synchronous fashion is often unrealistic. In the present paper, we
consider two different models of asynchronous operation in
cooperative-diversity networks experiencing slow fading and examine the
corresponding diversity-multiplexing tradeoffs (DMT). For both models, we
propose protocols and distributed space-time codes that asymptotically achieve
the transmit diversity bound for all multiplexing gains and for any number of
relays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0222</identifier>
 <datestamp>2008-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0222</id><created>2008-07-01</created><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Range Medians</title><categories>cs.DS cs.OH</categories><comments>To appear in ESA 08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a generalization of the classical median finding problem to batched
query case: given an array of unsorted $n$ items and $k$ (not necessarily
disjoint) intervals in the array, the goal is to determine the median in {\em
each} of the intervals in the array. We give an algorithm that uses $O(n\log n
+ k\log k \log n)$ comparisons and show a lower bound of $\Omega(n\log k)$
comparisons for this problem. This is optimal for $k=O(n/\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0245</identifier>
 <datestamp>2008-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0245</id><created>2008-07-01</created><authors><author><keyname>Liu</keyname><forenames>Jing</forenames></author><author><keyname>Zhang</keyname><forenames>Jian-Kang</forenames></author><author><keyname>Wong</keyname><forenames>Kon Max</forenames></author></authors><title>Full Diversity Codes for MISO Systems Equipped with Linear or ML
  Detectors</title><categories>cs.IT math.IT</categories><comments>16 pages, 8 figures. accepted for publication in IEEE Trans.
  Information theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a general criterion for space time block codes (STBC) to
achieve full-diversity with a linear receiver is proposed for a wireless
communication system having multiple transmitter and single receiver antennas
(MISO). Particularly, the STBC with Toeplitz structure satisfies this criterion
and therefore, enables full-diversity. Further examination of this Toeplitz
STBC reveals the following important properties: a) The symbol transmission
rate can be made to approach unity. b) Applying the Toeplitz code to any
signalling scheme having nonzero distance between the nearest constellation
points results in a non-vanishing determinant. In addition, if QAM is used as
the signalling scheme, then for independent MISO flat fading channels, the
Toeplitz codes is proved to approach the optimal diversity-vs-multiplexing
tradeoff with a ZF receiver when the number of channel uses is large. This is,
so far, the first non-orthogonal STBC shown to achieve the optimal tradeoff for
such a receiver. On the other hand, when ML detection is employed in a MISO
system, the Toeplitz STBC achieves the maximum coding gain for independent
channels. When the channel fading coefficients are correlated, the inherent
transmission matrix in the Toeplitz STBC can be designed to minimize the
average worst case pair-wise error probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0311</identifier>
 <datestamp>2008-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0311</id><created>2008-07-02</created><authors><author><keyname>Lande</keyname><forenames>D. V.</forenames></author><author><keyname>Zhygalo</keyname><forenames>V. V.</forenames></author></authors><title>About the creation of a parallel bilingual corpora of web-publications</title><categories>cs.CL</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The algorithm of the creation texts parallel corpora was presented. The
algorithm is based on the use of &quot;key words&quot; in text documents, and on the
means of their automated translation. Key words were singled out by means of
using Russian and Ukrainian morphological dictionaries, as well as dictionaries
of the translation of nouns for the Russian and Ukrainianlanguages. Besides, to
calculate the weights of the terms in the documents, empiric-statistic rules
were used. The algorithm under consideration was realized in the form of a
program complex, integrated into the content-monitoring InfoStream system. As a
result, a parallel bilingual corpora of web-publications containing about 30
thousand documents, was created
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0336</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0336</id><created>2008-07-02</created><updated>2009-04-22</updated><authors><author><keyname>Matou&#x161;ek</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Tancer</keyname><forenames>Martin</forenames></author><author><keyname>Wagner</keyname><forenames>Uli</forenames></author></authors><title>Hardness of embedding simplicial complexes in $\R^d$</title><categories>cs.CG math.GT</categories><comments>36 pages, 17 figures; revised version incorporating changes suggested
  by anonymous referees; added linear-time algorithm for deciding planarity of
  2-dimensional complexes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let EMBED(k,d) be the following algorithmic problem: Given a finite
simplicial complex K of dimension at most k, does there exist a (piecewise
linear) embedding of K into R^d? Known results easily imply polynomiality of
EMBED(k,2) (k=1,2; the case k=1, d=2 is graph planarity) and of EMBED(k,2k) for
all k&gt;2 (even if k is not considered fixed).
  We observe that the celebrated result of Novikov on the algorithmic
unsolvability of recognizing the 5-sphere implies that EMBED(d,d) and
EMBED(d-1,d) are undecidable for each d&gt;4. Our main result is NP-hardness of
EMBED(2,4) and, more generally, of EMBED(k,d) for all k,d with d&gt;3 and d\geq k
\geq (2d-2)/3. These dimensions fall outside the so-called metastable range of
a theorem of Haefliger and Weber, which characterizes embeddability using the
deleted product obstruction. Our reductions are based on examples, due to
Segal, Spie\.z, Freedman, Krushkal, Teichner, and Skopenkov, showing that
outside the metastable range the deleted product obstruction is not sufficient
to characterize embeddability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0337</identifier>
 <datestamp>2008-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0337</id><created>2008-07-02</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>Unveiling the mystery of visual information processing in human brain</title><categories>cs.AI cs.IR cs.IT math.IT q-bio.NC</categories><comments>Accepted to be published in Brain Research (BRES-38102)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is generally accepted that human vision is an extremely powerful
information processing system that facilitates our interaction with the
surrounding world. However, despite extended and extensive research efforts,
which encompass many exploration fields, the underlying fundamentals and
operational principles of visual information processing in human brain remain
unknown. We still are unable to figure out where and how along the path from
eyes to the cortex the sensory input perceived by the retina is converted into
a meaningful object representation, which can be consciously manipulated by the
brain. Studying the vast literature considering the various aspects of brain
information processing, I was surprised to learn that the respected scholarly
discussion is totally indifferent to the basic keynote question: &quot;What is
information?&quot; in general or &quot;What is visual information?&quot; in particular. In the
old days, it was assumed that any scientific research approach has first to
define its basic departure points. Why was it overlooked in brain information
processing research remains a conundrum. In this paper, I am trying to find a
remedy for this bizarre situation. I propose an uncommon definition of
&quot;information&quot;, which can be derived from Kolmogorov's Complexity Theory and
Chaitin's notion of Algorithmic Information. Embracing this new definition
leads to an inevitable revision of traditional dogmas that shape the state of
the art of brain information processing research. I hope this revision would
better serve the challenging goal of human visual information processing
modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0425</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0425</id><created>2008-07-02</created><authors><author><keyname>Cho</keyname><forenames>Song Yean</forenames><affiliation>INRIA Rocquencourt, LIX</affiliation></author><author><keyname>Adjih</keyname><forenames>C&#xe9;dric</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Wireless Broadcast with Network Coding in Mobile Ad-Hoc Networks:
  DRAGONCAST</title><categories>cs.NI</categories><proxy>ccsd inria-00292867</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding is a recently proposed method for transmitting data, which has
been shown to have potential to improve wireless network performance. We study
network coding for one specific case of multicast, broadcasting, from one
source to all nodes of the network. We use network coding as a loss tolerant,
energy-efficient, method for broadcast. Our emphasis is on mobile networks. Our
contribution is the proposal of DRAGONCAST, a protocol to perform network
coding in such a dynamically evolving environment. It is based on three
building blocks: a method to permit real-time decoding of network coding, a
method to adjust the network coding transmission rates, and a method for
ensuring the termination of the broadcast. The performance and behavior of the
method are explored experimentally by simulations; they illustrate the
excellent performance of the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0462</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0462</id><created>2008-07-03</created><authors><author><keyname>Hoang</keyname><forenames>Chinh T.</forenames></author></authors><title>On the complexity of finding a sun in a graph</title><categories>cs.DM</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sun is the graph obtained from a cycle of length even and at least six by
adding edges to make the even-indexed vertices pairwise adjacent. Suns play an
important role in the study of strongly chordal graphs. A graph is chordal if
it does not contain an induced cycle of length at least four. A graph is
strongly chordal if it is chordal and every even cycle has a chord joining
vertices whose distance on the cycle is odd. Farber proved that a graph is
strongly chordal if and only if it is chordal and contains no induced suns.
There are well known polynomial-time algorithms for recognizing a sun in a
chordal graph. Recently, polynomial-time algorithms for finding a sun for a
larger class of graphs, the so-called HHD-free graphs, have been discovered. In
this paper, we prove the problem of deciding whether an arbitrary graph
contains a sun in NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0476</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0476</id><created>2008-07-02</created><authors><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author></authors><title>Research report: State complexity of operations on two-way quantum
  finite automata</title><categories>cs.DM cs.CC</categories><comments>This is a draft and primary version, and a deep study will be done</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the size complexity of minimal {\it two-way quantum
finite automata} (2qfa's) necessary for operations to perform on all inputs of
each fixed length. Such a complexity measure, known as state complexity of
operations, is useful in measuring how much information is necessary to convert
languages. We focus on intersection, union, reversals, and catenation
operations and show some upper bounds of state complexity of operations on
2qfa's. Also, we present a number of non-regular languages and prove that these
languages can be accepted by 2qfa's with one-sided error probabilities within
linear time. Notably, these examples show that our bounds obtained for these
operations are not tight, and therefore worth improving. We give an instance to
show that the upper bound of the state number for the simulation of one-way
deterministic finite automata by two-way reversible finite automata is not
tight in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0484</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0484</id><created>2008-07-03</created><updated>2009-12-09</updated><authors><author><keyname>Nivasch</keyname><forenames>Gabriel</forenames></author></authors><title>Improved bounds and new techniques for Davenport-Schinzel sequences and
  their generalizations</title><categories>cs.DM cs.CG</categories><comments>To appear in Journal of the ACM. 48 pages, 3 figures</comments><journal-ref>Journal of the ACM, 57, article 17, 44 pages, 2010</journal-ref><doi>10.1145/1706591.1706597</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let lambda_s(n) denote the maximum length of a Davenport-Schinzel sequence of
order s on n symbols. For s=3 it is known that lambda_3(n) = Theta(n alpha(n))
(Hart and Sharir, 1986). For general s&gt;=4 there are almost-tight upper and
lower bounds, both of the form n * 2^poly(alpha(n)) (Agarwal, Sharir, and Shor,
1989). Our first result is an improvement of the upper-bound technique of
Agarwal et al. We obtain improved upper bounds for s&gt;=6, which are tight for
even s up to lower-order terms in the exponent. More importantly, we also
present a new technique for deriving upper bounds for lambda_s(n). With this
new technique we: (1) re-derive the upper bound of lambda_3(n) &lt;= 2n alpha(n) +
O(n sqrt alpha(n)) (first shown by Klazar, 1999); (2) re-derive our own new
upper bounds for general s; and (3) obtain improved upper bounds for the
generalized Davenport-Schinzel sequences considered by Adamec, Klazar, and
Valtr (1992). Regarding lower bounds, we show that lambda_3(n) &gt;= 2n alpha(n) -
O(n), and therefore, the coefficient 2 is tight. We also present a simpler
version of the construction of Agarwal, Sharir, and Shor that achieves the
known lower bounds for even s&gt;=4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0517</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0517</id><created>2008-07-03</created><authors><author><keyname>Antal</keyname><forenames>Miklos</forenames></author><author><keyname>Balogh</keyname><forenames>Laszlo</forenames></author></authors><title>Modeling belief systems with scale-free networks</title><categories>cs.AI physics.soc-ph</categories><comments>23 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Evolution of belief systems has always been in focus of cognitive research.
In this paper we delineate a new model describing belief systems as a network
of statements considered true. Testing the model a small number of parameters
enabled us to reproduce a variety of well-known mechanisms ranging from opinion
changes to development of psychological problems. The self-organizing opinion
structure showed a scale-free degree distribution. The novelty of our work lies
in applying a convenient set of definitions allowing us to depict opinion
network dynamics in a highly favorable way, which resulted in a scale-free
belief network. As an additional benefit, we listed several conjectural
consequences in a number of areas related to thinking and reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0552</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0552</id><created>2008-07-03</created><authors><author><keyname>Aloupis</keyname><forenames>G.</forenames></author><author><keyname>Cardinal</keyname><forenames>J.</forenames></author><author><keyname>Collette</keyname><forenames>S.</forenames></author><author><keyname>Langerman</keyname><forenames>S.</forenames></author><author><keyname>Orden</keyname><forenames>D.</forenames></author><author><keyname>Ramos</keyname><forenames>P.</forenames></author></authors><title>Decomposition of Multiple Coverings into More Parts</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that for every centrally symmetric convex polygon Q, there exists a
constant alpha such that any alpha*k-fold covering of the plane by translates
of Q can be decomposed into k coverings. This improves on a quadratic upper
bound proved by Pach and Toth (SoCG'07). The question is motivated by a sensor
network problem, in which a region has to be monitored by sensors with limited
battery lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0564</identifier>
 <datestamp>2008-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0564</id><created>2008-07-03</created><updated>2008-09-18</updated><authors><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author></authors><title>Linear-Programming Receivers</title><categories>cs.IT math.IT</categories><comments>7 pages (double-column), presented at the 46th Annual Allerton
  Conference on Communication, Control and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that any communication system which admits a sum-product (SP)
receiver also admits a corresponding linear-programming (LP) receiver. The two
receivers have a relationship defined by the local structure of the underlying
graphical model, and are inhibited by the same phenomenon, which we call
'pseudoconfigurations'. This concept is a generalization of the concept of
'pseudocodewords' for linear codes. It is proved that the LP receiver has the
'optimum certificate' property, and that the receiver output is the lowest cost
pseudoconfiguration. Equivalence of graph-cover pseudoconfigurations and
linear-programming pseudoconfigurations is also proved. While the LP receiver
is generally more complex than the corresponding SP receiver, the LP receiver
and its associated pseudoconfiguration structure provide an analytic tool for
the analysis of SP receivers. As an example application, we show how the LP
design technique may be applied to the problem of joint equalization and
decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0565</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0565</id><created>2008-07-03</created><authors><author><keyname>Zanette</keyname><forenames>Damian H.</forenames></author></authors><title>Music, Complexity, Information</title><categories>physics.soc-ph cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These are the preparatory notes for a Science &amp; Music essay, &quot;Playing by
numbers&quot;, appeared in Nature 453 (2008) 988-989.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0595</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0595</id><created>2008-07-03</created><authors><author><keyname>Hollmann</keyname><forenames>Henk D. L.</forenames></author></authors><title>Nonstandard linear recurring sequence subgroups in finite fields and
  automorphisms of cyclic codes</title><categories>cs.IT cs.DM math.CO math.IT</categories><report-no>Philips Research manuscript number PR-MS 29.450</report-no><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $q=p^r$ be a prime power, and let $f(x)=x^m-\gs_{m-1}x^{m-1}-
&gt;...-\gs_1x-\gs_0$ be an irreducible polynomial over the finite field $\GF(q)$
of size $q$. A zero $\xi$ of $f$ is called {\em nonstandard (of degree $m$)
over $\GF(q)$} if the recurrence relation $u_m=\gs_{m-1}u_{m-1} + ... +
\gs_1u_1+\gs_0u_0$ with characteristic polynomial $f$ can generate the powers
of $\xi$ in a nontrivial way, that is, with $u_0=1$ and $f(u_1)\neq 0$. In
2003, Brison and Nogueira asked for a characterisation of all nonstandard cases
in the case $m=2$, and solved this problem for $q$ a prime, and later for
$q=p^r$ with $r\leq4$.
  In this paper, we first show that classifying nonstandard finite field
elements is equivalent to classifying those cyclic codes over $\GF(q)$
generated by a single zero that posses extra permutation automorphisms.
  Apart from two sporadic examples of degree 11 over $\GF(2)$ and of degree 5
over $\GF(3)$, related to the Golay codes, there exist two classes of examples
of nonstandard finite field elements. One of these classes (type I) involves
irreducible polynomials $f$ of the form $f(x)=x^m-f_0$, and is well-understood.
The other class (type II) can be obtained from a primitive element in some
subfield by a process that we call extension and lifting. We will use the known
classification of the subgroups of $\PGL(2,q)$ in combination with a recent
result by Brison and Nogueira to show that a nonstandard element of degree two
over $\GF(q)$ necessarily is of type I or type II, thus solving completely the
classification problem for the case $m=2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0610</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0610</id><created>2008-07-03</created><authors><author><keyname>Vilela</keyname><forenames>Joao P.</forenames></author><author><keyname>Lima</keyname><forenames>Luisa</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>Lightweight Security for Network Coding</title><categories>cs.CR cs.NI</categories><comments>Proc. of the IEEE International Conference on Communications (ICC
  2008), Beijing, China, May 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under the emerging network coding paradigm, intermediate nodes in the network
are allowed not only to store and forward packets but also to process and mix
different data flows. We propose a low-complexity cryptographic scheme that
exploits the inherent security provided by random linear network coding and
offers the advantage of reduced overhead in comparison to traditional
end-to-end encryption of the entire data. Confidentiality is achieved by
protecting (or &quot;locking&quot;) the source coefficients required to decode the
encoded data, without preventing intermediate nodes from running their standard
network coding operations. Our scheme can be easily combined with existing
techniques that counter active attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0626</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0626</id><created>2008-07-03</created><authors><author><keyname>Tanguy</keyname><forenames>Christian</forenames></author></authors><title>Asymptotic Mean Time To Failure and Higher Moments for Large, Recursive
  Networks</title><categories>cs.PF</categories><proxy>ccsd hal-00293225</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with asymptotic expressions of the Mean Time To Failure
(MTTF) and higher moments for large, recursive, and non-repairable systems in
the context of two-terminal reliability. Our aim is to extend the well-known
results of the series and parallel cases. We first consider several exactly
solvable configurations of identical components with exponential failure-time
distribution functions to illustrate different (logarithmic or power-law)
behaviors as the size of the system, indexed by an integer n, increases. The
general case is then addressed: it provides a simple interpretation of the
origin of the power-law exponent and an efficient asymptotic expression for the
total reliability of large, recursive systems. Finally, we assess the influence
of the non-exponential character of the component reliability on the
n-dependence of the MTTF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0627</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0627</id><created>2008-07-03</created><authors><author><keyname>Martin</keyname><forenames>Arnaud</forenames><affiliation>E3I2</affiliation></author></authors><title>Belief decision support and reject for textured images characterization</title><categories>cs.AI</categories><proxy>ccsd hal-00293209</proxy><acm-class>I.4; I.5</acm-class><journal-ref>International Conference on Information Fusion, Lens : France
  (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The textured images' classification assumes to consider the images in terms
of area with the same texture. In uncertain environment, it could be better to
take an imprecise decision or to reject the area corresponding to an unlearning
class. Moreover, on the areas that are the classification units, we can have
more than one texture. These considerations allows us to develop a belief
decision model permitting to reject an area as unlearning and to decide on
unions and intersections of learning classes. The proposed approach finds all
its justification in an application of seabed characterization from sonar
images, which contributes to an illustration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0629</identifier>
 <datestamp>2008-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0629</id><created>2008-07-03</created><authors><author><keyname>Tanguy</keyname><forenames>Christian</forenames></author></authors><title>Exact two-terminal reliability of some directed networks</title><categories>cs.PF</categories><proxy>ccsd hal-00293217</proxy><journal-ref>Proceedings of the 6th International Workshop on the Design of
  Reliable Communication, La Rochelle : France (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The calculation of network reliability in a probabilistic context has long
been an issue of practical and academic importance. Conventional approaches
(determination of bounds, sums of disjoint products algorithms, Monte Carlo
evaluations, studies of the reliability polynomials, etc.) only provide
approximations when the network's size increases, even when nodes do not fail
and all edges have the same reliability p. We consider here a directed, generic
graph of arbitrary size mimicking real-life long-haul communication networks,
and give the exact, analytical solution for the two-terminal reliability. This
solution involves a product of transfer matrices, in which individual
reliabilities of edges and nodes are taken into account. The special case of
identical edge and node reliabilities (p and rho, respectively) is addressed.
We consider a case study based on a commonly-used configuration, and assess the
influence of the edges being directed (or not) on various measures of network
performance. While the two-terminal reliability, the failure frequency and the
failure rate of the connection are quite similar, the locations of complex
zeros of the two-terminal reliability polynomials exhibit strong differences,
and various structure transitions at specific values of rho. The present work
could be extended to provide a catalog of exactly solvable networks in terms of
reliability, which could be useful as building blocks for new and improved
bounds, as well as benchmarks, in the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0644</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0644</id><created>2008-07-04</created><updated>2011-12-30</updated><authors><author><keyname>Koufogiannakis</keyname><forenames>Christos</forenames></author><author><keyname>Young</keyname><forenames>Neal E.</forenames></author></authors><title>Greedy D-Approximation Algorithm for Covering with Arbitrary Constraints
  and Submodular Cost</title><categories>cs.DS cs.DC</categories><msc-class>68W25</msc-class><acm-class>G.1.6</acm-class><journal-ref>Algorithmica 66(1):113-152 (2013)</journal-ref><doi>10.1007/978-3-642-02927-1_53</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a simple greedy D-approximation algorithm for any
covering problem whose objective function is submodular and non-decreasing, and
whose feasible region can be expressed as the intersection of arbitrary (closed
upwards) covering constraints, each of which constrains at most D variables of
the problem. (A simple example is Vertex Cover, with D = 2.) The algorithm
generalizes previous approximation algorithms for fundamental covering problems
and online paging and caching problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0661</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0661</id><created>2008-07-03</created><authors><author><keyname>Burgain</keyname><forenames>Pierrick</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author><author><keyname>Clarke</keyname><forenames>John-Paul</forenames></author></authors><title>Collaborative Virtual Queue: Fair Management of Congested Departure
  Operations and Benefit Analysis</title><categories>cs.OH</categories><comments>LaTex, 30 pages with 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the stochastic nature of departure operations, working at full
capacity makes major US airports very sensitive to uncertainties. Consequently,
airport ground operations face critically congested taxiways and long runway
queues. In this report, we show how improved management of departure operations
from the ready-to-push-back time to the wheels-off time can potentially yield
significant benefits to airlines and air traffic services. We develop a
Collaborative Virtual Queue to enable better optimization capabilities during
congested situations while taking into account the laissez-faire competitive
environment. Results are evaluated using a departure system model, validated
using current statistics and previous studies. First, the Collaborative Virtual
Queue enables keeping aircraft away from runway queues, which increases
wheels-off time predictability. Second, holding aircraft enables last-minute
intra-airline flight switching. This creates new optimization capabilities for
airlines i.e. it gives airlines the flexibility to prioritize their flight
sequence in real-time. These capabilities are illustrated by the trade-off
between minimizing the average passenger waiting time and minimizing the level
of unfairness between aircraft of the same airline. For instance, airlines
could choose to decrease by up to 15% their average passenger waiting time by
prioritizing heavy planes over small planes when the taxiway system is
congested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0672</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0672</id><created>2008-07-03</created><authors><author><keyname>Burgin</keyname><forenames>Mark</forenames></author></authors><title>Algorithmic Problem Complexity</title><categories>cs.CC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People solve different problems and know that some of them are simple, some
are complex and some insoluble. The main goal of this work is to develop a
mathematical theory of algorithmic complexity for problems. This theory is
aimed at determination of computer abilities in solving different problems and
estimation of resources that computers need to do this. Here we build the part
of this theory related to static measures of algorithms. At first, we consider
problems for finite words and study algorithmic complexity of such problems,
building optimal complexity measures. Then we consider problems for such
infinite objects as functions and study algorithmic complexity of these
problems, also building optimal complexity measures. In the second part of the
work, complexity of algorithmic problems, such as the halting problem for
Turing machines, is measured by the classes of automata that are necessary to
solve this problem. To classify different problems with respect to their
complexity, inductive Turing machines, which extend possibilities of Turing
machines, are used. A hierarchy of inductive Turing machines generates an
inductive hierarchy of algorithmic problems. Here we specifically consider
algorithmic problems related to Turing machines and inductive Turing machines,
and find a place for these problems in the inductive hierarchy of algorithmic
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0704</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0704</id><created>2008-07-04</created><authors><author><keyname>Marina</keyname><forenames>Knyazhansky</forenames></author><author><keyname>Tatjana</keyname><forenames>Plotkin</forenames></author></authors><title>Knowledge bases over algebraic models. Some notes about informational
  equivalence</title><categories>cs.LO</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent advances in knowledge base research and the growing importance of
effective knowledge management raised an important question of knowledge base
equivalence verification. This problem has not been stated earlier, at least in
a way that allows speaking about algorithms for verification of informational
equivalence, because the informal definition of knowledge bases makes formal
solution of this problem impossible. In this paper we provide an implementable
formal algorithm for knowledge base equivalence verification based on the
formal definition of knowledge base proposed by Plotkin B. and Plotkin T., and
study some important properties of automorphic equivalence of models. We also
describe the concept of equivalence and formulate the criterion for the
equivalence of knowledge bases defined over finite models. Further we define
multi-models and automorphic equivalence of models and multi-models, that is
generalization of automorphic equivalence of algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0718</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0718</id><created>2008-07-04</created><authors><author><keyname>D'Alessandro</keyname><forenames>Flavio</forenames></author><author><keyname>Intrigila</keyname><forenames>Benedetto</forenames></author><author><keyname>Varricchio</keyname><forenames>Stefano</forenames></author></authors><title>The Parikh functions of sparse context-free languages are
  quasi-polynomials</title><categories>cs.DM</categories><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the Parikh map of a bounded context-free language is a box
spline. Moreover we prove that in this case, such a function is rational.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0799</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0799</id><created>2008-07-04</created><updated>2008-08-08</updated><authors><author><keyname>Kanukurthi</keyname><forenames>Bhavana</forenames></author><author><keyname>Reyzin</keyname><forenames>Leonid</forenames></author></authors><title>An Improved Robust Fuzzy Extractor</title><categories>cs.CR</categories><comments>15 pages; to appear in SCN 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of building robust fuzzy extractors, which allow two
parties holding similar random variables W, W' to agree on a secret key R in
the presence of an active adversary. Robust fuzzy extractors were defined by
Dodis et al. in Crypto 2006 to be noninteractive, i.e., only one message P,
which can be modified by an unbounded adversary, can pass from one party to the
other. This allows them to be used by a single party at different points in
time (e.g., for key recovery or biometric authentication), but also presents an
additional challenge: what if R is used, and thus possibly observed by the
adversary, before the adversary has a chance to modify P. Fuzzy extractors
secure against such a strong attack are called post-application robust.
  We construct a fuzzy extractor with post-application robustness that extracts
a shared secret key of up to (2m-n)/2 bits (depending on error-tolerance and
security parameters), where n is the bit-length and m is the entropy of W. The
previously best known result, also of Dodis et al., extracted up to (2m-n)/3
bits (depending on the same parameters).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0807</identifier>
 <datestamp>2009-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0807</id><created>2008-07-04</created><updated>2009-02-11</updated><authors><author><keyname>Ahmed</keyname><forenames>Mustaq</forenames></author><author><keyname>Lubiw</keyname><forenames>Anna</forenames></author></authors><title>Shortest Paths Avoiding Forbidden Subpaths</title><categories>cs.DM cs.DS</categories><comments>12 pages, 2 figures. Fixed a few typos, rephrased a few sentences,
  and used the STACS style</comments><acm-class>G.2.2; F.2.2</acm-class><journal-ref>Proceedings of the 26th International Symposium on Theoretical
  Aspects of Computer Science (STACS), Freiburg, Germany, 2009, pp. 63-74</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a variant of the shortest path problem in graphs:
given a weighted graph G and vertices s and t, and given a set X of forbidden
paths in G, find a shortest s-t path P such that no path in X is a subpath of
P. Path P is allowed to repeat vertices and edges. We call each path in X an
exception, and our desired path a shortest exception-avoiding path. We
formulate a new version of the problem where the algorithm has no a priori
knowledge of X, and finds out about an exception x in X only when a path
containing x fails. This situation arises in computing shortest paths in
optical networks. We give an algorithm that finds a shortest exception avoiding
path in time polynomial in |G| and |X|. The main idea is to run Dijkstra's
algorithm incrementally after replicating vertices when an exception is
discovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0821</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0821</id><created>2008-07-04</created><authors><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>On Wiretap Networks II</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of securing a multicast network against a wiretapper
that can intercept the packets on a limited number of arbitrary network links
of his choice. We assume that the network implements network coding techniques
to simultaneously deliver all the packets available at the source to all the
destinations. We show how this problem can be looked at as a network
generalization of the Ozarow-Wyner Wiretap Channel of type II. In particular,
we show that network security can be achieved by using the Ozarow-Wyner
approach of coset coding at the source on top of the implemented network code.
This way, we quickly and transparently recover some of the results available in
the literature on secure network coding for wiretapped networks. We also derive
new bounds on the required secure code alphabet size and an algorithm for code
construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0868</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0868</id><created>2008-07-05</created><authors><author><keyname>Astaneh</keyname><forenames>Saeed A.</forenames></author><author><keyname>Gazor</keyname><forenames>Saeed</forenames></author><author><keyname>Behroozi</keyname><forenames>Hamid</forenames></author></authors><title>On the Capacity of Pairwise Collaborative Networks</title><categories>cs.IT math.IT</categories><comments>Accepted for publication at PIMRC'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive expressions for the achievable rate region of a collaborative
coding scheme in a two-transmitter, two-receiver Pairwise Collaborative Network
(PCN) where one transmitter and receiver pair, namely relay pair, assists the
other pair, namely the source pair, by partially decoding and forwarding the
transmitted message to the intended receiver. The relay pair provides such
assistance while handling a private message. We assume that users can use the
past channel outputs and can transmit and receive at the same time and in the
same frequency band. In this collaborative scheme, the transmitter of the
source pair splits its information into two independent parts. Ironically, the
relay pair employs the decode and forward coding to assist the source pair in
delivering a part of its message and re-encodes the decoded message along with
private message, which is intended to the receiver of the relay pair, and
broadcasts the results. The receiver of the relay pair decodes both messages,
retrieves the private message, re-encodes and transmits the decoded massage to
the intended destination. We also characterize the achievable rate region for
Gaussian PCN. Finally, we provide numerical results to study the rate trade off
for the involved pairs. Numerical result shows that the collaboration offers
gain when the channel gain between the users of the relay pair are strong. It
also shows that if the channel conditions between transmitters or between the
receivers of the relay and source pairs are poor, such a collaboration is not
beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0887</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0887</id><created>2008-07-06</created><authors><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author><author><keyname>Serrano</keyname><forenames>M. Angeles</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author></authors><title>On Cycles in AS Relationships</title><categories>cs.NI</categories><comments>This note is an addendum to cs/0604017</comments><acm-class>C.2.5; C.2.1</acm-class><journal-ref>ACM SIGCOMM Computer Communication Review (CCR), v.38, n.3,
  p.103-104, 2008</journal-ref><doi>10.1145/1384609.1384624</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several users of our AS relationship inference data
(http://www.caida.org/data/active/as-relationships/), released with cs/0604017,
asked us why it contained AS relationship cycles, e.g., cases where AS A is a
provider of AS B, B is a provider of C, and C is a provider of A, or other
cycle types. Having been answering these questions in private communications,
we have eventually decided to write down our answers here for future reference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0908</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0908</id><created>2008-07-06</created><updated>2008-09-02</updated><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>The Correspondence Analysis Platform for Uncovering Deep Structure in
  Data and Information</title><categories>cs.AI</categories><comments>Sixth Annual Boole Lecture in Informatics, Boole Centre for Research
  in Informatics, Cork, Ireland, 29 April 2008. 28 pp., 17 figures. To appear,
  Computer Journal. This version: 3 typos corrected</comments><acm-class>I.5.4; H.3.1; I.2.7</acm-class><journal-ref>Computer Journal, 53 (3), 304-315, 2010</journal-ref><doi>10.1093/comjnl/bxn045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two aspects of information semantics: (i) the collection of all
relationships, (ii) tracking and spotting anomaly and change. The first is
implemented by endowing all relevant information spaces with a Euclidean metric
in a common projected space. The second is modelled by an induced ultrametric.
A very general way to achieve a Euclidean embedding of different information
spaces based on cross-tabulation counts (and from other input data formats) is
provided by Correspondence Analysis. From there, the induced ultrametric that
we are particularly interested in takes a sequential - e.g. temporal - ordering
of the data into account. We employ such a perspective to look at narrative,
&quot;the flow of thought and the flow of language&quot; (Chafe). In application to
policy decision making, we show how we can focus analysis in a small number of
dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0928</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0928</id><created>2008-07-06</created><authors><author><keyname>Charles</keyname><forenames>Denis</forenames></author><author><keyname>Chellapilla</keyname><forenames>Kumar</forenames></author></authors><title>Bloomier Filters: A second look</title><categories>cs.DS</categories><comments>13 Pages, 3 figures, to appear in ESA - 2008</comments><acm-class>E.1; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Bloom filter is a space efficient structure for storing static sets, where
the space efficiency is gained at the expense of a small probability of
false-positives. A Bloomier filter generalizes a Bloom filter to compactly
store a function with a static support. In this article we give a simple
construction of a Bloomier filter. The construction is linear in space and
requires constant time to evaluate. The creation of our Bloomier filter takes
linear time which is faster than the existing construction. We show how one can
improve the space utilization further at the cost of increasing the time for
creating the data structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0942</identifier>
 <datestamp>2012-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0942</id><created>2008-07-07</created><updated>2012-06-12</updated><authors><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Eswaran</keyname><forenames>Krishnan</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Secrecy via Sources and Channels</title><categories>cs.IT math.IT</categories><comments>42 pages, 7 figures, to appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alice and Bob want to share a secret key and to communicate an independent
message, both of which they desire to be kept secret from an eavesdropper Eve.
We study this problem of secret communication and secret key generation when
two resources are available -- correlated sources at Alice, Bob, and Eve, and a
noisy broadcast channel from Alice to Bob and Eve which is independent of the
sources. We are interested in characterizing the fundamental trade-off between
the rates of the secret message and secret key. We present an achievable
solution and prove its optimality for the parallel channels and sources case
when each sub-channel and source component satisfies a degradation order
(either in favor of the legitimate receiver or the eavesdropper). This includes
the case of jointly Gaussian sources and an additive Gaussian channel, for
which the secrecy region is evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0967</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0967</id><created>2008-07-07</created><authors><author><keyname>Brescia</keyname><forenames>M.</forenames></author><author><keyname>Cavuoti</keyname><forenames>S.</forenames></author><author><keyname>D'Angelo</keyname><forenames>G.</forenames></author><author><keyname>D'Abrusco</keyname><forenames>R.</forenames></author><author><keyname>Donalek</keyname><forenames>C.</forenames></author><author><keyname>Deniskina</keyname><forenames>N.</forenames></author><author><keyname>Laurino</keyname><forenames>O.</forenames></author><author><keyname>Longo</keyname><forenames>G.</forenames></author></authors><title>Astrophysics in S.Co.P.E</title><categories>astro-ph cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  S.Co.P.E. is one of the four projects funded by the Italian Government in
order to provide Southern Italy with a distributed computing infrastructure for
fundamental science. Beside being aimed at building the infrastructure,
S.Co.P.E. is also actively pursuing research in several areas among which
astrophysics and observational cosmology. We shortly summarize the most
significant results obtained in the first two years of the project and related
to the development of middleware and Data Mining tools for the Virtual
Observatory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0992</identifier>
 <datestamp>2008-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0992</id><created>2008-07-07</created><authors><author><keyname>Darrasse</keyname><forenames>Alexis</forenames><affiliation>LIP6</affiliation></author></authors><title>Random XML sampling the Boltzmann way</title><categories>cs.OH</categories><proxy>ccsd hal-00293555</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present the prototype of a framework capable of producing,
with linear complexity, uniformly random XML documents with respect to a given
RELAX NG grammar. The generation relies on powerful combinatorial methods
together with numerical and symbolic resolution of polynomial systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0993</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0993</id><created>2008-07-07</created><authors><author><keyname>Hardy</keyname><forenames>Damien</forenames><affiliation>IRISA</affiliation></author><author><keyname>Puaut</keyname><forenames>Isabelle</forenames><affiliation>IRISA</affiliation></author></authors><title>WCET analysis of multi-level set-associative instruction caches</title><categories>cs.PF</categories><proxy>ccsd inria-00286358</proxy><report-no>RR-6574</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advent of increasingly complex hardware in real-time embedded
systems (processors with performance enhancing features such as pipelines,
cache hierarchy, multiple cores), many processors now have a set-associative L2
cache. Thus, there is a need for considering cache hierarchies when validating
the temporal behavior of real-time systems, in particular when estimating
tasks' worst-case execution times (WCETs). To the best of our knowledge, there
is only one approach for WCET estimation for systems with cache hierarchies
[Mueller, 1997], which turns out to be unsafe for set-associative caches. In
this paper, we highlight the conditions under which the approach described in
[Mueller, 1997] is unsafe. A safe static instruction cache analysis method is
then presented. Contrary to [Mueller, 1997] our method supports set-associative
and fully associative caches. The proposed method is experimented on
medium-size and large programs. We show that the method is most of the time
tight. We further show that in all cases WCET estimations are much tighter when
considering the cache hierarchy than when considering only the L1 cache. An
evaluation of the analysis time is conducted, demonstrating that analysing the
cache hierarchy has a reasonable computation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1005</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1005</id><created>2008-07-07</created><authors><author><keyname>van Erven</keyname><forenames>Tim</forenames></author><author><keyname>Grunwald</keyname><forenames>Peter</forenames></author><author><keyname>de Rooij</keyname><forenames>Steven</forenames></author></authors><title>Catching Up Faster by Switching Sooner: A Prequential Solution to the
  AIC-BIC Dilemma</title><categories>math.ST cs.IT cs.LG math.IT stat.ME stat.ML stat.TH</categories><comments>A preliminary version of a part of this paper appeared at the NIPS
  2007 conference</comments><msc-class>62G99; 94A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian model averaging, model selection and its approximations such as BIC
are generally statistically consistent, but sometimes achieve slower rates og
convergence than other methods such as AIC and leave-one-out cross-validation.
On the other hand, these other methods can br inconsistent. We identify the
&quot;catch-up phenomenon&quot; as a novel explanation for the slow convergence of
Bayesian methods. Based on this analysis we define the switch distribution, a
modification of the Bayesian marginal distribution. We show that, under broad
conditions,model selection and prediction based on the switch distribution is
both consistent and achieves optimal convergence rates, thereby resolving the
AIC-BIC dilemma. The method is practical; we give an efficient implementation.
The switch distribution has a data compression interpretation, and can thus be
viewed as a &quot;prequential&quot; or MDL method; yet it is different from the MDL
methods that are usually considered in the literature. We compare the switch
distribution to Bayes factor model selection and leave-one-out
cross-validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1016</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1016</id><created>2008-07-07</created><authors><author><keyname>Arthan</keyname><forenames>Rob</forenames></author><author><keyname>Martin</keyname><forenames>Ursula</forenames></author><author><keyname>Mathiesen</keyname><forenames>Erik A.</forenames></author><author><keyname>Oliva</keyname><forenames>Paulo</forenames></author></authors><title>A General Framework for Sound and Complete Floyd-Hoare Logics</title><categories>cs.LO cs.OH</categories><comments>27 pages</comments><acm-class>F.3.1</acm-class><journal-ref>ACM Transactions on Computational Logic, 11(1), 2009</journal-ref><doi>10.1145/1614431.1614438</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an abstraction of Hoare logic to traced symmetric
monoidal categories, a very general framework for the theory of systems. Our
abstraction is based on a traced monoidal functor from an arbitrary traced
monoidal category into the category of pre-orders and monotone relations. We
give several examples of how our theory generalises usual Hoare logics (partial
correctness of while programs, partial correctness of pointer programs), and
provide some case studies on how it can be used to develop new Hoare logics
(run-time analysis of while programs and stream circuits).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1139</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1139</id><created>2008-07-07</created><authors><author><keyname>Korula</keyname><forenames>Nitish</forenames></author><author><keyname>Pal</keyname><forenames>Martin</forenames></author></authors><title>Algorithms for Secretary Problems on Graphs and Hypergraphs</title><categories>cs.DS</categories><comments>15 pages, 2 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine several online matching problems, with applications to Internet
advertising reservation systems. Consider an edge-weighted bipartite graph G,
with partite sets L, R. We develop an 8-competitive algorithm for the following
secretary problem: Initially given R, and the size of L, the algorithm receives
the vertices of L sequentially, in a random order. When a vertex l \in L is
seen, all edges incident to l are revealed, together with their weights. The
algorithm must immediately either match l to an available vertex of R, or
decide that l will remain unmatched.
  Dimitrov and Plaxton show a 16-competitive algorithm for the transversal
matroid secretary problem, which is the special case with weights on vertices,
not edges. (Equivalently, one may assume that for each l \in L, the weights on
all edges incident to l are identical.) We use a similar algorithm, but
simplify and improve the analysis to obtain a better competitive ratio for the
more general problem. Perhaps of more interest is the fact that our analysis is
easily extended to obtain competitive algorithms for similar problems, such as
to find disjoint sets of edges in hypergraphs where edges arrive online. We
also introduce secretary problems with adversarially chosen groups. Finally, we
give a 2e-competitive algorithm for the secretary problem on graphic matroids,
where, with edges appearing online, the goal is to find a maximum-weight
acyclic subgraph of a given graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1153</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1153</id><created>2008-07-07</created><authors><author><keyname>Hsu</keyname><forenames>Wei-jen</forenames></author><author><keyname>Dutta</keyname><forenames>Debojyoti</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>CSI: A Paradigm for Behavior-oriented Delivery Services in Mobile Human
  Networks</title><categories>cs.NI</categories><comments>12 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose behavior-oriented services as a new paradigm of communication in
mobile human networks. Our study is motivated by the tight user-network
coupling in future mobile societies. In such a paradigm, messages are sent to
inferred behavioral profiles, instead of explicit IDs. Our paper provides a
systematic framework in providing such services. First, user behavioral
profiles are constructed based on traces collected from two large wireless
networks, and their spatio-temporal stability is analyzed. The implicit
relationship discovered between mobile users could be utilized to provide a
service for message delivery and discovery in various network environments. As
an example application, we provide a detailed design of such a service in
challenged opportunistic network architecture, named CSI. We provide a fully
distributed solution using behavioral profile space gradients and small world
structures.
  Our analysis shows that user behavioral profiles are surprisingly stable,
i.e., the similarity of the behavioral profile of a user to its future
behavioral profile is above 0.8 for two days and 0.75 for one week, and remains
above 0.6 for five weeks. The correlation coefficient of the similarity metrics
between a user pair at different time instants is above 0.7 for four days, 0.62
for a week, and remains above 0.5 for two weeks. Leveraging such a stability in
user behaviors, the CSI service achieves delivery rate very close to the
delay-optimal strategy (above 94%), with minimal overhead (less than 84% of the
optimal). We believe that this new paradigm will act as an enabler of multiple
new services in mobile societies, and is potentially applicable in
server-based, heterogeneous or infrastructure-less wireless environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1158</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1158</id><created>2008-07-07</created><updated>2010-06-19</updated><authors><author><keyname>Subramanian</keyname><forenames>Abhay T.</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author></authors><title>Path Gain Algebraic Formulation for the Scalar Linear Network Coding
  Problem</title><categories>cs.IT math.IT</categories><comments>12 pages, 6 figures. Accepted for publication in IEEE Transactions on
  Information Theory (May 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the algebraic view, the solution to a network coding problem is seen as a
variety specified by a system of polynomial equations typically derived by
using edge-to-edge gains as variables. The output from each sink is equated to
its demand to obtain polynomial equations. In this work, we propose a method to
derive the polynomial equations using source-to-sink path gains as the
variables. In the path gain formulation, we show that linear and quadratic
equations suffice; therefore, network coding becomes equivalent to a system of
polynomial equations of maximum degree 2. We present algorithms for generating
the equations in the path gains and for converting path gain solutions to
edge-to-edge gain solutions. Because of the low degree, simplification is
readily possible for the system of equations obtained using path gains. Using
small-sized network coding problems, we show that the path gain approach
results in simpler equations and determines solvability of the problem in
certain cases. On a larger network (with 87 nodes and 161 edges), we show how
the path gain approach continues to provide deterministic solutions to some
network coding problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1160</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1160</id><created>2008-07-07</created><authors><author><keyname>Shen</keyname><forenames>Charles</forenames></author><author><keyname>Schulzrinne</keyname><forenames>Henning</forenames></author><author><keyname>Nahum</keyname><forenames>Erich</forenames></author></authors><title>Session Initiation Protocol (SIP) Server Overload Control: Design and
  Evaluation</title><categories>cs.NI cs.PF</categories><comments>In Proceedings of IPTComm 2008</comments><acm-class>C.2.2; C.2.3; C.2.1; D.4.8; K.6.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Session Initiation Protocol (SIP) server may be overloaded by
emergency-induced call volume, ``American Idol'' style flash crowd effects or
denial of service attacks. The SIP server overload problem is interesting
especially because the costs of serving or rejecting a SIP session can be
similar. For this reason, the built-in SIP overload control mechanism based on
generating rejection messages cannot prevent the server from entering
congestion collapse under heavy load. The SIP overload problem calls for a
pushback control solution in which the potentially overloaded receiving server
may notify its upstream sending servers to have them send only the amount of
load within the receiving server's processing capacity. The pushback framework
can be achieved by either a rate-based feedback or a window-based feedback. The
centerpiece of the feedback mechanism is the algorithm used to generate load
regulation information. We propose three new window-based feedback algorithms
and evaluate them together with two existing rate-based feedback algorithms. We
compare the different algorithms in terms of the number of tuning parameters
and performance under both steady and variable load. Furthermore, we identify
two categories of fairness requirements for SIP overload control, namely,
user-centric and provider-centric fairness. With the introduction of a new
double-feed SIP overload control architecture, we show how the algorithms can
meet those fairness criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1162</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1162</id><created>2008-07-07</created><authors><author><keyname>Shen</keyname><forenames>Charles</forenames></author><author><keyname>Schulzrinne</keyname><forenames>Henning</forenames></author></authors><title>Measurement and Evaluation of ENUM Server Performance</title><categories>cs.PF cs.NI</categories><acm-class>K.6.2; D.4.8; C.2.3</acm-class><journal-ref>Proceedings of IEEE ICC 2007 p. 1967-1972</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ENUM is a DNS-based protocol standard for mapping E.164 telephone numbers to
Internet Uniform Resource Identifiers (URIs). It places unique requirements on
the existing DNS infrastructure, such as data scalability, query throughput,
response time, and database update rates. This paper measures and evaluates the
performance of existing name server implementation as ENUM servers. We compared
PowerDNS (PDNS), BIND and Navitas. Results show that BIND is not suitable for
ENUM due to its poor scaling property. Both PDNS and Navitas can serve ENUM.
However, Navitas turns out to be highly optimized and clearly outperforms PDNS
in all aspects we have tested. We also instrumented the PDNS server to identify
its performance bottleneck and investigated ways to improve it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1165</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1165</id><created>2008-07-08</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Prabhu</keyname><forenames>Vinayak</forenames></author></authors><title>Timed Parity Games: Complexity and Robustness</title><categories>cs.LO cs.GT</categories><comments>Accepted in conference FORMATS 2008. Pages 22</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two-player games played in real time on game structures with
clocks and parity objectives. The games are concurrent in that at each turn,
both players independently propose a time delay and an action, and the action
with the shorter delay is chosen. To prevent a player from winning by blocking
time, we restrict each player to strategies that ensure that the player cannot
be responsible for causing a zeno run. First, we present an efficient reduction
of these games to turn-based (i.e., nonconcurrent) finite-state (i.e., untimed)
parity games. The states of the resulting game are pairs of clock regions of
the original game. Our reduction improves the best known complexity for solving
timed parity games. Moreover, the rich class of algorithms for classical parity
games can now be applied to timed parity games.
  Second, we consider two restricted classes of strategies for the player that
represents the controller in a real-time synthesis problem, namely,
limit-robust and bounded-robust strategies. Using a limit-robust strategy, the
controller cannot choose an exact real-valued time delay but must allow for
some nonzero jitter in each of its actions. If there is a given lower bound on
the jitter, then the strategy is bounded-robust. We show that exact strategies
are more powerful than limit-robust strategies, which are more powerful than
bounded-robust strategies for any bound. For both kinds of robust strategies,
we present efficient reductions to standard timed automaton games. These
reductions provide algorithms for the synthesis of robust real-time
controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1169</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1169</id><created>2008-07-08</created><authors><author><keyname>Shen</keyname><forenames>Charles</forenames></author><author><keyname>Schulzrinne</keyname><forenames>Henning</forenames></author></authors><title>A VoIP Privacy Mechanism and its Application in VoIP Peering for Voice
  Service Provider Topology and Identity Hiding</title><categories>cs.NI</categories><report-no>cucs-039-06</report-no><acm-class>C.2.1; C.2.2; C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voice Service Providers (VSPs) participating in VoIP peering frequently want
to withhold their identity and related privacy-sensitive information from other
parties during the VoIP communication. A number of existing documents on VoIP
privacy exist, but most of them focus on end user privacy. By summarizing and
extending existing work, we present a unified privacy mechanism for both VoIP
users and service providers. We also show a case study on how VSPs can use this
mechanism for identity and topology hiding in VoIP peering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1173</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1173</id><created>2008-07-08</created><authors><author><keyname>Chadha</keyname><forenames>Rohit</forenames></author><author><keyname>Viswanthan</keyname><forenames>Mahesh</forenames></author></authors><title>A Counterexample Guided Abstraction-Refinement Framework for Markov
  Decision Processes</title><categories>cs.SE cs.LO</categories><acm-class>D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main challenge in using abstractions effectively, is to construct a
suitable abstraction for the system being verified. One approach that tries to
address this problem is that of {\it counterexample guided
abstraction-refinement (CEGAR)}, wherein one starts with a coarse abstraction
of the system, and progressively refines it, based on invalid counterexamples
seen in prior model checking runs, until either an abstraction proves the
correctness of the system or a valid counterexample is generated. While CEGAR
has been successfully used in verifying non-probabilistic systems
automatically, CEGAR has not been applied in the context of probabilistic
systems. The main issues that need to be tackled in order to extend the
approach to probabilistic systems is a suitable notion of ``counterexample'',
algorithms to generate counterexamples, check their validity, and then
automatically refine an abstraction based on an invalid counterexample. In this
paper, we address these issues, and present a CEGAR framework for Markov
Decision Processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1182</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1182</id><created>2008-07-08</created><authors><author><keyname>Bentley</keyname><forenames>R. Alexander</forenames></author></authors><title>Random drift versus selection in academic vocabulary: an evolutionary
  analysis of published keywords</title><categories>physics.soc-ph cs.DL</categories><comments>9 pages, 4 figures</comments><journal-ref>PLoS ONE, 3 (2008) e3057</journal-ref><doi>10.1371/journal.pone.0003057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of vocabulary in academic publishing is characterized via
keyword frequencies recorded the ISI Web of Science citations database. In four
distinct case-studies, evolutionary analysis of keyword frequency change
through time is compared to a model of random copying used as the null
hypothesis, such that selection may be identified against it. The case studies
from the physical sciences indicate greater selection in keyword choice than in
the social sciences. Similar evolutionary analyses can be applied to a wide
range of phenomena; wherever the popularity of multiple items through time has
been recorded, as with web searches, or sales of popular music and books, for
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1211</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1211</id><created>2008-07-08</created><authors><author><keyname>Cheney</keyname><forenames>James</forenames></author></authors><title>Flux: FunctionaL Updates for XML (extended report)</title><categories>cs.PL cs.DB</categories><comments>Extended version of ICFP 2008 paper</comments><acm-class>D.3.1; H.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML database query languages have been studied extensively, but XML database
updates have received relatively little attention, and pose many challenges to
language design. We are developing an XML update language called Flux, which
stands for FunctionaL Updates for XML, drawing upon ideas from functional
programming languages. In prior work, we have introduced a core language for
Flux with a clear operational semantics and a sound, decidable static type
system based on regular expression types.
  Our initial proposal had several limitations. First, it lacked support for
recursive types or update procedures. Second, although a high-level source
language can easily be translated to the core language, it is difficult to
propagate meaningful type errors from the core language back to the source.
Third, certain updates are well-formed yet contain path errors, or ``dead''
subexpressions which never do any useful work. It would be useful to detect
path errors, since they often represent errors or optimization opportunities.
  In this paper, we address all three limitations. Specifically, we present an
improved, sound type system that handles recursion. We also formalize a source
update language and give a translation to the core language that preserves and
reflects typability. We also develop a path-error analysis (a form of dead-code
analysis) for updates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1221</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1221</id><created>2008-07-08</created><authors><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Rubin</keyname><forenames>Natan</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author></authors><title>Line Transversals of Convex Polyhedra in $\reals^3$</title><categories>cs.CG</categories><comments>10 pages+ 15 page appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a bound of $O(n^2k^{1+\eps})$, for any $\eps&gt;0$, on the
combinatorial complexity of the set $\T$ of line transversals of a collection
$\P$ of $k$ convex polyhedra in $\reals^3$ with a total of $n$ facets, and
present a randomized algorithm which computes the boundary of $\T$ in
comparable expected time. Thus, when $k\ll n$, the new bounds on the complexity
(and construction cost) of $\T$ improve upon the previously best known bounds,
which are nearly cubic in $n$.
  To obtain the above result, we study the set $\TL$ of line transversals which
emanate from a fixed line $\ell_0$, establish an almost tight bound of
$O(nk^{1+\eps})$ on the complexity of $\TL$, and provide a randomized algorithm
which computes $\TL$ in comparable expected time. Slightly improved
combinatorial bounds for the complexity of $\TL$, and comparable improvements
in the cost of constructing this set, are established for two special cases,
both assuming that the polyhedra of $\P$ are pairwise disjoint: the case where
$\ell_0$ is disjoint from the polyhedra of $\P$, and the case where the
polyhedra of $\P$ are unbounded in a direction parallel to $\ell_0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1228</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1228</id><created>2008-07-08</created><authors><author><keyname>Garetto</keyname><forenames>Michele</forenames></author><author><keyname>Leonardi</keyname><forenames>Emilio</forenames></author></authors><title>Restricted Mobility Improves Delay-Throughput Trade-offs in Mobile
  Ad-Hoc Networks</title><categories>cs.PF cs.NI</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze asymptotic delay-throughput trade-offs in mobile
ad-hoc networks comprising heterogeneous nodes with restricted mobility. We
show that node spatial heterogeneity has the ability to drastically improve
upon existing scaling laws established under the assumption that nodes are
identical and uniformly visit the entire network area. In particular, we
consider the situation in which each node moves around its own home-point
according to a restricted mobility process which results into a spatial
stationary distribution that decays as a power law of exponent delta with the
distance from the home-point. For such restricted mobility model, we propose a
novel class of scheduling and routing schemes, which significantly outperforms
all delay-throughput results previously obtained in the case of identical
nodes. In particular, for delta = 2 it is possible to achieve almost constant
delay and almost constant per-node throughput (except for a poly-logarithmic
factor) as the number of nodes increases, even without resorting to
sophisticated coding or signal processing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1253</identifier>
 <datestamp>2013-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1253</id><created>2008-07-08</created><updated>2008-11-17</updated><authors><author><keyname>Brody</keyname><forenames>Dorje C.</forenames></author><author><keyname>Davis</keyname><forenames>Mark H. A.</forenames></author><author><keyname>Friedman</keyname><forenames>Robyn L.</forenames></author><author><keyname>Hughston</keyname><forenames>Lane P.</forenames></author></authors><title>Informed Traders</title><categories>q-fin.TR cs.IT math.IT math.PR</categories><comments>20 pages, 5 figures. Version to appear in the Proceedings of the
  Royal Society A</comments><journal-ref>Proceedings of the Royal Society London A465, 1103-1122 (2009)</journal-ref><doi>10.1098/rspa.2008.0465</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An asymmetric information model is introduced for the situation in which
there is a small agent who is more susceptible to the flow of information in
the market than the general market participant, and who tries to implement
strategies based on the additional information. In this model market
participants have access to a stream of noisy information concerning the future
return of an asset, whereas the informed trader has access to a further
information source which is obscured by an additional noise that may be
correlated with the market noise. The informed trader uses the extraneous
information source to seek statistical arbitrage opportunities, while at the
same time accommodating the additional risk. The amount of information
available to the general market participant concerning the asset return is
measured by the mutual information of the asset price and the associated cash
flow. The worth of the additional information source is then measured in terms
of the difference of mutual information between the general market participant
and the informed trader. This difference is shown to be nonnegative when the
signal-to-noise ratio of the information flow is known in advance. Explicit
trading strategies leading to statistical arbitrage opportunities, taking
advantage of the additional information, are constructed, illustrating how
excess information can be translated into profit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1267</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1267</id><created>2008-07-08</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Sen</keyname><forenames>Pranab</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>Jaikumar</forenames></author></authors><title>Optimal Direct Sum and Privacy Trade-off Results for Quantum and
  Classical Communication Complexity</title><categories>cs.DC cs.IT math.IT</categories><comments>Full version (version 1), 31 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show optimal Direct Sum result for the one-way entanglement-assisted
quantum communication complexity for any relation f subset of X x Y x Z. We
show: Q^{1,pub}(f^m) = Omega(m Q^{1,pub}(f)), where Q^{1,pub}(f), represents
the one-way entanglement-assisted quantum communication complexity of f with
error at most 1/3 and f^m represents m-copies of f. Similarly for the one-way
public-coin classical communication complexity we show: R^{1,pub}(f^m) =
Omega(m R^{1,pub}(f)), where R^{1,pub}(f), represents the one-way public-coin
classical communication complexity of f with error at most 1/3. We show similar
optimal Direct Sum results for the Simultaneous Message Passing quantum and
classical models. For two-way protocols we present optimal Privacy Trade-off
results leading to a Weak Direct Sum result for such protocols. We show our
Direct Sum and Privacy Trade-off results via message compression arguments
which also imply a new round elimination lemma in quantum communication. This
allows us to extend classical lower bounds on the cell probe complexity of some
data structure problems, e.g. Approximate Nearest Neighbor Searching on the
Hamming cube {0,1}^n and Predecessor Search to the quantum setting. In a
separate result we show that Newman's technique of reducing the number of
public-coins in a classical protocol cannot be lifted to the quantum setting.
We do this by defining a general notion of black-box reduction of prior
entanglement that subsumes Newman's technique. We prove that such a black-box
reduction is impossible for quantum protocols. In the final result in the theme
of message compression, we provide an upper bound on the problem of Exact
Remote State Preparation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1277</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1277</id><created>2008-07-08</created><authors><author><keyname>Gamarnik</keyname><forenames>David</forenames></author><author><keyname>Goldberg</keyname><forenames>David</forenames></author></authors><title>Randomized greedy algorithms for independent sets and matchings in
  regular graphs: Exact results and finite girth corrections</title><categories>cs.DM cs.DS</categories><comments>24 pages</comments><acm-class>F.2.2; G.1.6; G.2.1; G.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive new results for the performance of a simple greedy algorithm for
finding large independent sets and matchings in constant degree regular graphs.
We show that for $r$-regular graphs with $n$ nodes and girth at least $g$, the
algorithm finds an independent set of expected cardinality $f(r)n -
O\big(\frac{(r-1)^{\frac{g}{2}}}{\frac{g}{2}!} n\big)$, where $f(r)$ is a
function which we explicitly compute. A similar result is established for
matchings. Our results imply improved bounds for the size of the largest
independent set in these graphs, and provide the first results of this type for
matchings. As an implication we show that the greedy algorithm returns a nearly
perfect matching when both the degree $r$ and girth $g$ are large. Furthermore,
we show that the cardinality of independent sets and matchings produced by the
greedy algorithm in \emph{arbitrary} bounded degree graphs is concentrated
around the mean. Finally, we analyze the performance of the greedy algorithm
for the case of random i.i.d. weighted independent sets and matchings, and
obtain a remarkably simple expression for the limiting expected values produced
by the algorithm. In fact, all the other results are obtained as
straightforward corollaries from the results for the weighted case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1282</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1282</id><created>2008-07-08</created><updated>2008-07-10</updated><authors><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author></authors><title>Satisfiability of Almost Disjoint CNF Formulas</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We call a CNF formula linear if any two clauses have at most one variable in
common. Let m(k) be the largest integer m such that any linear k-CNF formula
with &lt;= m clauses is satisfiable. We show that 4^k / (4e^2k^3) &lt;= m(k) &lt; ln(2)
k^4 4^k. More generally, a (k,d)-CSP is a constraint satisfaction problem in
conjunctive normal form where each variable can take on one of d values, and
each constraint contains k variables and forbids exacty one of the d^k possible
assignments to these variables. Call a (k,d)-CSP l-disjoint if no two distinct
constraints have l or more variables in common. Let m_l(k,d) denote the largest
integer m such that any l-disjoint (k,d)-CSP with at most m constraints is
satisfiable. We show that 1/k (d^k/(ed^(l-1)k))^(1+1/(l-1))&lt;= m_l(k,d) &lt; c
(k^2/l ln(d) d^k)^(1+1/(l-1)). for some constant c. This means for constant l,
upper and lower bound differ only in a polynomial factor in d and k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1297</identifier>
 <datestamp>2008-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1297</id><created>2008-07-08</created><authors><author><keyname>Aggarwal</keyname><forenames>Gagan</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Pal</keyname><forenames>David</forenames></author><author><keyname>Pal</keyname><forenames>Martin</forenames></author></authors><title>General Auction Mechanism for Search Advertising</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sponsored search, a number of advertising slots is available on a search
results page, and have to be allocated among a set of advertisers competing to
display an ad on the page. This gives rise to a bipartite matching market that
is typically cleared by the way of an automated auction. Several auction
mechanisms have been proposed, with variants of the Generalized Second Price
(GSP) being widely used in practice.
  A rich body of work on bipartite matching markets builds upon the stable
marriage model of Gale and Shapley and the assignment model of Shapley and
Shubik. We apply insights from this line of research into the structure of
stable outcomes and their incentive properties to advertising auctions.
  We model advertising auctions in terms of an assignment model with linear
utilities, extended with bidder and item specific maximum and minimum prices.
Auction mechanisms like the commonly used GSP or the well-known
Vickrey-Clarke-Groves (VCG) are interpreted as simply computing a
\emph{bidder-optimal stable matching} in this model, for a suitably defined set
of bidder preferences. In our model, the existence of a stable matching is
guaranteed, and under a non-degeneracy assumption a bidder-optimal stable
matching exists as well. We give an algorithm to find such matching in
polynomial time, and use it to design truthful mechanism that generalizes GSP,
is truthful for profit-maximizing bidders, implements features like
bidder-specific minimum prices and position-specific bids, and works for rich
mixtures of bidders and preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1313</identifier>
 <datestamp>2009-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1313</id><created>2008-07-08</created><updated>2009-02-18</updated><authors><author><keyname>Chen</keyname><forenames>Yingda</forenames></author><author><keyname>Kishore</keyname><forenames>Shalinee</forenames></author></authors><title>On the Tradeoffs of Implementing Randomized Network Coding in Multicast
  Networks</title><categories>cs.IT math.IT</categories><comments>22 pages, 5 figures, submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized network coding (RNC) greatly reduces the complexity of
implementing network coding in large-scale, heterogeneous networks. This paper
examines two tradeoffs in applying RNC: The first studies how the performance
of RNC varies with a node's randomizing capabilities. Specifically, a limited
randomized network coding (L-RNC) scheme - in which intermediate nodes perform
randomized encoding based on only a limited number of random coefficients - is
proposed and its performance bounds are analyzed. Such a L-RNC approach is
applicable to networks in which nodes have either limited computation/storage
capacity or have ambiguity about downstream edge connectivity (e.g., as in ad
hoc sensor networks). A second tradeoff studied here examines the relationship
between the reliability and the capacity gains of generalized RNC, i.e., how
the outage probability of RNC relates to the transmission rate at the source
node. This tradeoff reveals that significant reductions in outage probability
are possible when the source transmits deliberately and only slightly below
network capacity. This approach provides an effective means to improve the
feasibility probability of RNC when the size of the finite field is fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1372</identifier>
 <datestamp>2009-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1372</id><created>2008-07-09</created><updated>2009-09-14</updated><authors><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author><author><keyname>K&#xf6;tter</keyname><forenames>Ralf</forenames></author></authors><title>Communication over Finite-Field Matrix Channels</title><categories>cs.IT math.IT</categories><comments>24 pages, to be published at the IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is motivated by the problem of error control in network coding
when errors are introduced in a random fashion (rather than chosen by an
adversary). An additive-multiplicative matrix channel is considered as a model
for random network coding. The model assumes that n packets of length m are
transmitted over the network, and up to t erroneous packets are randomly chosen
and injected into the network. Upper and lower bounds on capacity are obtained
for any channel parameters, and asymptotic expressions are provided in the
limit of large field or matrix size. A simple coding scheme is presented that
achieves capacity in both limiting cases. The scheme has decoding complexity
O(n^2 m) and a probability of error that decreases exponentially both in the
packet length and in the field size in bits. Extensions of these results for
coherent network coding are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1412</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1412</id><created>2008-07-09</created><authors><author><keyname>Arvind</keyname><forenames>V.</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Partha</forenames></author></authors><title>Quantum Query Complexity of Multilinear Identity Testing</title><categories>cs.CC</categories><comments>12 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Motivated by the quantum algorithm in \cite{MN05} for testing commutativity
of black-box groups, we study the following problem: Given a black-box finite
ring $R=\angle{r_1,...,r_k}$ where $\{r_1,r_2,...,r_k\}$ is an additive
generating set for $R$ and a multilinear polynomial $f(x_1,...,x_m)$ over $R$
also accessed as a black-box function $f:R^m\to R$ (where we allow the
indeterminates $x_1,...,x_m$ to be commuting or noncommuting), we study the
problem of testing if $f$ is an \emph{identity} for the ring $R$. More
precisely, the problem is to test if $f(a_1,a_2,...,a_m)=0$ for all $a_i\in R$.
  We give a quantum algorithm with query complexity $O(m(1+\alpha)^{m/2}
k^{\frac{m}{m+1}})$ assuming $k\geq (1+1/\alpha)^{m+1}$. Towards a lower bound,
we also discuss a reduction from a version of $m$-collision to this problem.
  We also observe a randomized test with query complexity $4^mmk$ and constant
success probability and a deterministic test with $k^m$ query complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1458</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1458</id><created>2008-07-09</created><authors><author><keyname>Nekovee</keyname><forenames>Maziar</forenames></author><author><keyname>Moreno</keyname><forenames>Y.</forenames></author><author><keyname>Bianconi</keyname><forenames>G.</forenames></author><author><keyname>Marsili</keyname><forenames>M.</forenames></author></authors><title>Theory of Rumour Spreading in Complex Social Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.CR physics.bio-ph</categories><journal-ref>Physica A, Vol 374, 457 (2007)</journal-ref><doi>10.1016/j.physa.2006.07.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a general stochastic model for the spread of rumours, and derive
mean-field equations that describe the dynamics of the model on complex social
networks (in particular those mediated by the Internet). We use analytical and
numerical solutions of these equations to examine the threshold behavior and
dynamics of the model on several models of such networks: random graphs,
uncorrelated scale-free networks and scale-free networks with assortative
degree correlations. We show that in both homogeneous networks and random
graphs the model exhibits a critical threshold in the rumour spreading rate
below which a rumour cannot propagate in the system. In the case of scale-free
networks, on the other hand, this threshold becomes vanishingly small in the
limit of infinite system size. We find that the initial rate at which a rumour
spreads is much higher in scale-free networks than in random graphs, and that
the rate at which the spreading proceeds on scale-free networks is further
increased when assortative degree correlations are introduced. The impact of
degree correlations on the final fraction of nodes that ever hears a rumour,
however, depends on the interplay between network topology and the rumour
spreading rate. Our results show that scale-free social networks are prone to
the spreading of rumours, just as they are to the spreading of infections. They
are relevant to the spreading dynamics of chain emails, viral advertising and
large-scale information dissemination algorithms on the Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1475</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1475</id><created>2008-07-09</created><authors><author><keyname>Nekovee</keyname><forenames>Maziar</forenames></author></authors><title>Simulations of Large-scale WiFi-based Wireless Networks:
  Interdisciplinary Challenges and Applications</title><categories>cs.CE cs.DC</categories><comments>Future Generation Computer Systems, Article in Press</comments><doi>10.1016/j.future.2008.05.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Fidelity (WiFi) is the fastest growing wireless technology to date.
In addition to providing wire-free connectivity to the Internet WiFi technology
also enables mobile devices to connect directly to each other and form highly
dynamic wireless adhoc networks. Such distributed networks can be used to
perform cooperative communication tasks such ad data routing and information
dissemination in the absence of a fixed infrastructure. Furthermore, adhoc
grids composed of wirelessly networked portable devices are emerging as a new
paradigm in grid computing. In this paper we review computational and
algorithmic challenges of high-fidelity simulations of such WiFi-based wireless
communication and computing networks, including scalable topology maintenance,
mobility modelling, parallelisation and synchronisation. We explore
similarities and differences between the simulations of these networks and
simulations of interacting many-particle systems, such as molecular dynamics
(MD) simulations. We show how the cell linked-list algorithm which we have
adapted from our MD simulations can be used to greatly improve the
computational performance of wireless network simulators in the presence of
mobility, and illustrate with an example from our simulation studies of worm
attacks on mobile wireless adhoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1494</identifier>
 <datestamp>2013-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1494</id><created>2008-07-09</created><authors><author><keyname>Gagliolo</keyname><forenames>Matteo</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Algorithm Selection as a Bandit Problem with Unbounded Losses</title><categories>cs.AI cs.GT cs.LG</categories><comments>15 pages, 2 figures</comments><report-no>IDSIA-07-08</report-no><acm-class>F.2.2; G.3; I.1.2; I.2.6; I.2.8</acm-class><doi>10.1007/978-3-642-13800-3_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithm selection is typically based on models of algorithm performance,
learned during a separate offline training sequence, which can be prohibitively
expensive. In recent work, we adopted an online approach, in which a
performance model is iteratively updated and used to guide selection on a
sequence of problem instances. The resulting exploration-exploitation trade-off
was represented as a bandit problem with expert advice, using an existing
solver for this game, but this required the setting of an arbitrary bound on
algorithm runtimes, thus invalidating the optimal regret of the solver. In this
paper, we propose a simpler framework for representing algorithm selection as a
bandit problem, with partial information, and an unknown bound on losses. We
adapt an existing solver to this game, proving a bound on its expected regret,
which holds also for the resulting algorithm selection technique. We present
preliminary experiments with a set of SAT solvers on a mixed SAT-UNSAT
benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1496</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1496</id><created>2008-07-09</created><authors><author><keyname>Goyal</keyname><forenames>Navin</forenames></author><author><keyname>Rademacher</keyname><forenames>Luis</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>Expanders via Random Spanning Trees</title><categories>cs.DM cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the problem of routing reliably and scalably in a graph, we
introduce the notion of a splicer, the union of spanning trees of a graph. We
prove that for any bounded-degree n-vertex graph, the union of two random
spanning trees approximates the expansion of every cut of the graph to within a
factor of O(log n). For the random graph G_{n,p}, for p&gt; c log{n}/n, two
spanning trees give an expander. This is suggested by the case of the complete
graph, where we prove that two random spanning trees give an expander. The
construction of the splicer is elementary -- each spanning tree can be produced
independently using an algorithm by Aldous and Broder: a random walk in the
graph with edges leading to previously unvisited vertices included in the tree.
  A second important application of splicers is to graph sparsification where
the goal is to approximate every cut (and more generally the quadratic form of
the Laplacian) using only a small subgraph of the original graph.
Benczur-Karger as well as Spielman-Srivastava have shown sparsifiers with O(n
log n/eps^2)$ edges that achieve approximation within factors 1+eps and 1-eps.
Their methods, based on independent sampling of edges, need Omega(n log n)
edges to get any approximation (else the subgraph could be disconnected) and
leave open the question of linear-size sparsifiers. Splicers address this
question for random graphs by providing sparsifiers of size O(n) that
approximate every cut to within a factor of O(log n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1513</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1513</id><created>2008-07-09</created><authors><author><keyname>Tapson</keyname><forenames>J.</forenames></author><author><keyname>Jin</keyname><forenames>C.</forenames></author><author><keyname>van Schaik</keyname><forenames>A.</forenames></author><author><keyname>Etienne-Cummings</keyname><forenames>R.</forenames></author></authors><title>A First-Order Non-Homogeneous Markov Model for the Response of Spiking
  Neurons Stimulated by Small Phase-Continuous Signals</title><categories>q-bio.NC cs.NE</categories><comments>Accepted for publication in Neural Computation</comments><journal-ref>Neural Computation Volume 21 Issue 6 Pages 1554-1588 Year 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a first-order non-homogeneous Markov model for the
interspike-interval density of a continuously stimulated spiking neuron. The
model allows the conditional interspike-interval density and the stationary
interspike-interval density to be expressed as products of two separate
functions, one of which describes only the neuron characteristics, and the
other of which describes only the signal characteristics. This allows the use
of this model to predict the response when the underlying neuron model is not
known or well determined. The approximation shows particularly clearly that
signal autocorrelations and cross-correlations arise as natural features of the
interspike-interval density, and are particularly clear for small signals and
moderate noise. We show that this model simplifies the design of spiking neuron
cross-correlation systems, and describe a four-neuron mutual inhibition network
that generates a cross-correlation output for two input signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1523</identifier>
 <datestamp>2008-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1523</id><created>2008-07-09</created><updated>2008-08-21</updated><authors><author><keyname>Dumas</keyname><forenames>Philippe</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Mean asymptotic behaviour of radix-rational sequences and dilation
  equations (Extended version)</title><categories>cs.DM math.CO</categories><proxy>ccsd inria-00294520</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generating series of a radix-rational sequence is a rational formal power
series from formal language theory viewed through a fixed radix numeration
system. For each radix-rational sequence with complex values we provide an
asymptotic expansion for the sequence of its Ces\`aro means. The precision of
the asymptotic expansion depends on the joint spectral radius of the linear
representation of the sequence; the coefficients are obtained through some
dilation equations. The proofs are based on elementary linear algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1524</identifier>
 <datestamp>2008-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1524</id><created>2008-07-09</created><authors><author><keyname>Bertot</keyname><forenames>Yves</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Komendantskaya</keyname><forenames>Ekaterina</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Inductive and Coinductive Components of Corecursive Functions in Coq</title><categories>cs.LO</categories><comments>Dans Coalgebraic Methods in Computer Science (2008)</comments><proxy>ccsd inria-00277075</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Constructive Type Theory, recursive and corecursive definitions are
subject to syntactic restrictions which guarantee termination for recursive
functions and productivity for corecursive functions. However, many terminating
and productive functions do not pass the syntactic tests. Bove proposed in her
thesis an elegant reformulation of the method of accessibility predicates that
widens the range of terminative recursive functions formalisable in
Constructive Type Theory. In this paper, we pursue the same goal for productive
corecursive functions. Notably, our method of formalisation of coinductive
definitions of productive functions in Coq requires not only the use of ad-hoc
predicates, but also a systematic algorithm that separates the inductive and
coinductive parts of functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1543</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1543</id><created>2008-07-09</created><updated>2008-09-25</updated><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On the Capacity of MIMO Interference Channels</title><categories>cs.IT math.IT</categories><comments>8 pages, 2 figures, submitted to Allerton 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity region of a multiple-input-multiple-output interference channel
(MIMO IC) where the channel matrices are square and invertible is studied. The
capacity region for strong interference is established where the definition of
strong interference parallels that of scalar channels. Moreover, the sum-rate
capacity for Z interference, noisy interference, and mixed interference is
established. These results generalize known results for the scalar Gaussian IC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1550</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1550</id><created>2008-07-10</created><updated>2008-07-23</updated><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Discernment of Hubs and Clusters in Socioeconomic Networks</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>17 pages, small mathematical expression for the probability 0.973469
  now correctly written (mid. p. 9)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interest in the analysis of networks has grown rapidly in the new millennium.
Consequently, we promote renewed attention to a certain methodological approach
introduced in 1974. Over the succeeding decade, this
two-stage--double-standardization and hierarchical clustering
(single-linkage-like)--procedure was applied to a wide variety of weighted,
directed networks of a socioeconomic nature, frequently revealing the presence
of ``hubs''. These were, typically--in the numerous instances studied of
migration flows between geographic subdivisions within
nations--``cosmopolitan/non-provincial'' areas, a prototypical example being
the French capital, Paris. Such locations emit and absorb people broadly across
their respective nations. Additionally, the two-stage procedure--which ``might
very well be the most successful application of cluster analysis'' (R. C.
Dubes, 1985)--detected many (physically or socially) isolated, functional
groups (regions) of areas, such as the southern islands, Shikoku and Kyushu, of
Japan, the Italian islands of Sardinia and Sicily, and the New England region
of the United States. Further, we discuss a (complementary) approach developed
in 1976, in which the max-flow/min-cut theorem was applied to
raw/non-standardized (interindustry, as well as migration) flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1560</identifier>
 <datestamp>2008-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1560</id><created>2008-07-09</created><authors><author><keyname>Qazvinian</keyname><forenames>Vahed</forenames></author><author><keyname>Radev</keyname><forenames>Dragomir R.</forenames></author></authors><title>Scientific Paper Summarization Using Citation Summary Networks</title><categories>cs.IR cs.CL</categories><acm-class>H.3.3; H.3.1; I.2.7; G.2.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Quickly moving to a new area of research is painful for researchers due to
the vast amount of scientific literature in each field of study. One possible
way to overcome this problem is to summarize a scientific topic. In this paper,
we propose a model of summarizing a single article, which can be further used
to summarize an entire topic. Our model is based on analyzing others' viewpoint
of the target article's contributions and the study of its citation summary
network using a clustering approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1603</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1603</id><created>2008-07-10</created><updated>2009-02-09</updated><authors><author><keyname>Latapy</keyname><forenames>Matthieu</forenames></author><author><keyname>Magnien</keyname><forenames>Clemence</forenames></author><author><keyname>Ouedraogo</keyname><forenames>Frederic</forenames></author></authors><title>A Radar for the Internet</title><categories>cs.NI</categories><comments>8 pages</comments><journal-ref>Proceedings of ADN'08: 1st International Workshop on Analysis of
  Dynamic Networks, in conjonction with IEEE ICDM 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contrast with most internet topology measurement research, our concern
here is not to obtain a map as complete and precise as possible of the whole
internet. Instead, we claim that each machine's view of this topology, which we
call ego-centered view, is an object worth of study in itself. We design and
implement an ego-centered measurement tool, and perform radar-like measurements
consisting of repeated measurements of such views of the internet topology. We
conduct long-term (several weeks) and high-speed (one round every few minutes)
measurements of this kind from more than one hundred monitors, and we provide
the obtained data. We also show that these data may be used to detect events in
the dynamics of internet topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1667</identifier>
 <datestamp>2008-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1667</id><created>2008-07-10</created><authors><author><keyname>Toporensky</keyname><forenames>A. V.</forenames></author></authors><title>Quasi-Mandelbrot sets for perturbed complex analytic maps: visual
  patterns</title><categories>cs.GR</categories><comments>6 pages with 10 JPEG pictures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider perturbations of the complex quadratic map $ z \to z^2 +c$ and
corresponding changes in their quasi-Mandelbrot sets. Depending on particular
perturbation, visual forms of quasi-Mandelbrot set changes either sharply (when
the perturbation reaches some critical value) or continuously. In the latter
case we have a smooth transition from the classical form of the set to some
forms, constructed from mostly linear structures, as it is typical for
two-dimensional real number dynamics. Two examples of continuous evolution of
the quasi-Mandelbrot set are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1669</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1669</id><created>2008-07-10</created><updated>2008-09-10</updated><authors><author><keyname>Niqui</keyname><forenames>Milad</forenames></author></authors><title>Coinductive Formal Reasoning in Exact Real Arithmetic</title><categories>cs.LO</categories><comments>40 pages</comments><acm-class>F.3.1; D.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (September
  10, 2008) lmcs:953</journal-ref><doi>10.2168/LMCS-4(3:6)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present a method for formally proving the correctness of
the lazy algorithms for computing homographic and quadratic transformations --
of which field operations are special cases-- on a representation of real
numbers by coinductive streams. The algorithms work on coinductive stream of
M\&quot;{o}bius maps and form the basis of the Edalat--Potts exact real arithmetic.
We use the machinery of the Coq proof assistant for the coinductive types to
present the formalisation. The formalised algorithms are only partially
productive, i.e., they do not output provably infinite streams for all possible
inputs. We show how to deal with this partiality in the presence of syntactic
restrictions posed by the constructive type theory of Coq. Furthermore we show
that the type theoretic techniques that we develop are compatible with the
semantics of the algorithms as continuous maps on real numbers. The resulting
Coq formalisation is available for public download.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1720</identifier>
 <datestamp>2008-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1720</id><created>2008-07-10</created><authors><author><keyname>Benoit</keyname><forenames>Anne</forenames><affiliation>LIP</affiliation></author><author><keyname>Casanova</keyname><forenames>Henri</forenames><affiliation>LIP</affiliation></author><author><keyname>Rehn-Sonigo</keyname><forenames>Veronika</forenames><affiliation>LIP</affiliation></author><author><keyname>Robert</keyname><forenames>Yves</forenames><affiliation>LIP</affiliation></author></authors><title>Resource Allocation Strategies for In-Network Stream Processing</title><categories>cs.DC</categories><proxy>ccsd inria-00294972</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the operator mapping problem for in-network stream
processing applications. In-network stream processing consists in applying a
tree of operators in steady-state to multiple data objects that are continually
updated at various locations on a network. Examples of in-network stream
processing include the processing of data in a sensor network, or of continuous
queries on distributed relational databases. We study the operator mapping
problem in a ``constructive'' scenario, i.e., a scenario in which one builds a
platform dedicated to the application buy purchasing processing servers with
various costs and capabilities. The objective is to minimize the cost of the
platform while ensuring that the application achieves a minimum steady-state
throughput. The first contribution of this paper is the formalization of a set
of relevant operator-placement problems as linear programs, and a proof that
even simple versions of the problem are NP-complete. Our second contribution is
the design of several polynomial time heuristics, which are evaluated via
extensive simulations and compared to theoretical bounds for optimal solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1734</identifier>
 <datestamp>2008-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1734</id><created>2008-07-10</created><updated>2008-10-06</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Faster Sequential Search with a Two-Pass Dynamic-Time-Warping Lower
  Bound</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dynamic Time Warping (DTW) is a popular similarity measure between time
series. The DTW fails to satisfy the triangle inequality and its computation
requires quadratic time. Hence, to find closest neighbors quickly, we use
bounding techniques. We can avoid most DTW computations with an inexpensive
lower bound (LB_Keogh). We compare LB_Keogh with a tighter lower bound
(LB_Improved). We find that LB_Improved-based search is faster for sequential
search. As an example, our approach is 3 times faster over random-walk and
shape time series. We also review some of the mathematical properties of the
DTW. We derive a tight triangle inequality for the DTW. We show that the DTW
becomes the l_1 distance when time series are separated by a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1753</identifier>
 <datestamp>2008-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1753</id><created>2008-07-10</created><authors><author><keyname>Clement</keyname><forenames>Julien</forenames><affiliation>LRI, Universite Paris 11, France</affiliation></author><author><keyname>Defago</keyname><forenames>Xavier</forenames><affiliation>JAIST, Japon</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria Gradinariu</forenames><affiliation>JAIST, Japon</affiliation></author><author><keyname>Messika</keyname><forenames>Stephane</forenames><affiliation>LRI, Universite Paris 11, France</affiliation></author></authors><title>The cost of probabilistic gathering in oblivious robot networks</title><categories>cs.DC cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the complexity issues of two agreement problems in
oblivious robot networks namely gathering and scattering. These abstractions
are fundamental coordination problems in cooperative mobile robotics. Moreover,
their oblivious characteristics makes them appealing for self-stabilization
since they are self-stabilizing with no extra-cost. Given a set of robots with
arbitrary initial location and no initial agreement on a global coordinate
system, gathering requires that all robots reach the exact same but not
predetermined location while scattering aims at scatter robots such that no two
robots share the same location. Both deterministic gathering and scattering
have been proved impossible under arbitrary schedulers therefore probabilistic
solutions have been recently proposed. The contribution of this paper is
twofold. First, we propose a detailed complexity analysis of the existent
probabilistic gathering algorithms in both fault-free and fault-prone
environments. We consider both crash and byzantine-prone environments.
Moreover, using Markov chains tools and additional assumptions on the
environment we prove that the gathering convergence time can be reduced from
O(n^2) (the best known tight bound) to O(nln(n)). Additionally, we prove that
in crash-prone environments gathering is achieved in O(nln(n)+2f). Second,
using the same technique we prove that the best known scattering strategy
converges in fault-free systems is O(n) (which is one to optimal) while in
crash-prone environments it needs O(n-f). Finally, we conclude the paper with a
discussion related to different strategies to gather oblivious robots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1765</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1765</id><created>2008-07-10</created><authors><author><keyname>Figueiredo</keyname><forenames>Renato</forenames></author><author><keyname>Boykin</keyname><forenames>P. Oscar</forenames></author><author><keyname>Fortes</keyname><forenames>Jose A. B.</forenames></author><author><keyname>Li</keyname><forenames>Tao</forenames></author><author><keyname>Peir</keyname><forenames>Jie-Kwon</forenames></author><author><keyname>Wolinsky</keyname><forenames>David</forenames></author><author><keyname>John</keyname><forenames>Lizy</forenames></author><author><keyname>Kaeli</keyname><forenames>David</forenames></author><author><keyname>Lilja</keyname><forenames>David</forenames></author><author><keyname>McKee</keyname><forenames>Sally</forenames></author><author><keyname>Memik</keyname><forenames>Gokhan</forenames></author><author><keyname>Roy</keyname><forenames>Alain</forenames></author><author><keyname>Tyson</keyname><forenames>Gary</forenames></author></authors><title>Archer: A Community Distributed Computing Infrastructure for Computer
  Architecture Research and Education</title><categories>cs.AR</categories><comments>11 pages, 2 figures. Describes the Archer project,
  http://archer-project.org</comments><acm-class>C.0; I.6.3; C.2.4</acm-class><doi>10.1007/978-3-642-03354-4_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces Archer, a community-based computing resource for
computer architecture research and education. The Archer infrastructure
integrates virtualization and batch scheduling middleware to deliver
high-throughput computing resources aggregated from resources distributed
across wide-area networks and owned by different participating entities in a
seamless manner. The paper discusses the motivations leading to the design of
Archer, describes its core middleware components, and presents an analysis of
the functionality and performance of a prototype wide-area deployment running a
representative computer architecture simulation workload.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1773</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1773</id><created>2008-07-11</created><updated>2010-09-24</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Heath,</keyname><forenames>Robert W.</forenames><suffix>Jr.</suffix></author><author><keyname>Berry</keyname><forenames>Randall A.</forenames></author></authors><title>Spatial Interference Cancellation for Multi-Antenna Mobile Ad Hoc
  Networks</title><categories>cs.IT math.IT</categories><comments>28 pages; submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference between nodes is a critical impairment in mobile ad hoc networks
(MANETs). This paper studies the role of multiple antennas in mitigating such
interference. Specifically, a network is studied in which receivers apply
zero-forcing beamforming to cancel the strongest interferers. Assuming a
network with Poisson distributed transmitters and independent Rayleigh fading
channels, the transmission capacity is derived, which gives the maximum number
of successful transmissions per unit area. Mathematical tools from stochastic
geometry are applied to obtain the asymptotic transmission capacity scaling and
characterize the impact of inaccurate channel state information (CSI). It is
shown that, if each node cancels L interferers, the transmission capacity
decreases as the outage probability to the power of 1/(L+1) as the outage
probability vanishes. For fixed outage probability, as L grows, the
transmission capacity increases as L to the power of (1-2/alpha) where alpha is
the path-loss exponent. Moreover, CSI inaccuracy is shown to have no effect on
the transmission capacity scaling as the outage probability vanishes, provided
that the CSI training sequence has an appropriate length, which we derived.
Numerical results suggest that canceling merely one interferer by each node
increases the transmission capacity by an order of magnitude or more, even when
the CSI is imperfect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1775</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1775</id><created>2008-07-11</created><updated>2009-09-08</updated><authors><author><keyname>Libert</keyname><forenames>Beno&#xee;t</forenames></author><author><keyname>Vergnaud</keyname><forenames>Damien</forenames></author></authors><title>Towards Black-Box Accountable Authority IBE with Short Ciphertexts and
  Private Keys</title><categories>cs.CR</categories><comments>32 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At Crypto'07, Goyal introduced the concept of Accountable Authority
Identity-Based Encryption as a convenient tool to reduce the amount of trust in
authorities in Identity-Based Encryption. In this model, if the Private Key
Generator (PKG) maliciously re-distributes users' decryption keys, it runs the
risk of being caught and prosecuted. Goyal proposed two constructions: the
first one is efficient but can only trace well-formed decryption keys to their
source; the second one allows tracing obfuscated decryption boxes in a model
(called weak black-box model) where cheating authorities have no decryption
oracle. The latter scheme is unfortunately far less efficient in terms of
decryption cost and ciphertext size. In this work, we propose a new
construction that combines the efficiency of Goyal's first proposal with a very
simple weak black-box tracing mechanism. Our scheme is described in the
selective-ID model but readily extends to meet all security properties in the
adaptive-ID sense, which is not known to be true for prior black-box schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1891</identifier>
 <datestamp>2008-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1891</id><created>2008-07-11</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Moseley</keyname><forenames>Benjamin</forenames></author></authors><title>Online Scheduling to Minimize the Maximum Delay Factor</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper two scheduling models are addressed. First is the standard
model (unicast) where requests (or jobs) are independent. The other is the
broadcast model where broadcasting a page can satisfy multiple outstanding
requests for that page. We consider online scheduling of requests when they
have deadlines. Unlike previous models, which mainly consider the objective of
maximizing throughput while respecting deadlines, here we focus on scheduling
all the given requests with the goal of minimizing the maximum {\em delay
factor}.We prove strong lower bounds on the achievable competitive ratios for
delay factor scheduling even with unit-time requests.For the unicast model we
give algorithms that are $(1 + \eps)$-speed $O({1 \over \eps})$-competitive in
both the single machine and multiple machine settings. In the broadcast model
we give an algorithm for similar-sized pages that is $(2+ \eps)$-speed $O({1
\over \eps^2})$-competitive. For arbitrary page sizes we give an algorithm that
is $(4+\eps)$-speed $O({1 \over \eps^2})$-competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1906</identifier>
 <datestamp>2009-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1906</id><created>2008-07-11</created><updated>2008-10-04</updated><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author></authors><title>Extension of Inagaki General Weighted Operators and A New Fusion Rule
  Class of Proportional Redistribution of Intersection Masses</title><categories>cs.AI</categories><comments>6 pages; SWIFT 2008 - Skovde Workshop on Information Fusion Topics,
  Sweden;</comments><acm-class>I.4.8</acm-class><journal-ref>International Journal of Artificial Intelligence, Vol. 3, No. A09,
  79-85, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we extend Inagaki Weighted Operators fusion rule (WO) in
information fusion by doing redistribution of not only the conflicting mass,
but also of masses of non-empty intersections, that we call Double Weighted
Operators (DWO). Then we propose a new fusion rule Class of Proportional
Redistribution of Intersection Masses (CPRIM), which generates many interesting
particular fusion rules in information fusion. Both formulas are presented for
any number of sources of information. An application and comparison with other
fusion rules are given in the last section.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1919</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1919</id><created>2008-07-11</created><authors><author><keyname>Johnson</keyname><forenames>William B.</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>The Johnson-Lindenstrauss lemma almost characterizes Hilbert space, but
  not quite</title><categories>math.FA cs.CG math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $X$ be a normed space that satisfies the Johnson-Lindenstrauss lemma (J-L
lemma, in short) in the sense that for any integer $n$ and any
$x_1,\ldots,x_n\in X$ there exists a linear mapping $L:X\to F$, where
$F\subseteq X$ is a linear subspace of dimension $O(\log n)$, such that
$\|x_i-x_j\|\le\|L(x_i)-L(x_j)\|\le O(1)\cdot\|x_i-x_j\|$ for all $i,j\in
\{1,\ldots, n\}$. We show that this implies that $X$ is almost Euclidean in the
following sense: Every $n$-dimensional subspace of $X$ embeds into Hilbert
space with distortion $2^{2^{O(\log^*n)}}$. On the other hand, we show that
there exists a normed space $Y$ which satisfies the J-L lemma, but for every
$n$ there exists an $n$-dimensional subspace $E_n\subseteq Y$ whose Euclidean
distortion is at least $2^{\Omega(\alpha(n))}$, where $\alpha$ is the inverse
Ackermann function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1949</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1949</id><created>2008-07-11</created><updated>2010-09-07</updated><authors><author><keyname>Wei</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Virtual Transmission Method, A New Distributed Algorithm to Solve Sparse
  Linear System</title><categories>math.NA cs.DC</categories><comments>v1: short paper to describe VTM, published by NCM'08; v2: add an
  example of level-two splitting; v3: full paper; v4: rename EVS to GNBT; add
  lines coupling technique; v5: reuse EVS, get rid of GNBT; more info, see
  http://weifei00.googlepages.com</comments><msc-class>65F10, 65F50, 68M14</msc-class><acm-class>G.1.0; B.7.2</acm-class><doi>10.1109/NCM.2008.160</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new parallel algorithm which could work naturally
on the parallel computer with arbitrary number of processors. This algorithm is
named Virtual Transmission Method (VTM). Its physical backgroud is the lossless
transmission line and microwave network. The basic idea of VTM is to insert
lossless transmission lines into the sparse linear system to achieve
distributed computing.
  VTM is proved to be convergent to solve SPD linear system. Preconditioning
method and performance model are presented. Numerical experiments show that VTM
is efficient, accurate and stable.
  Accompanied with VTM, we bring in a new technique to partition the symmetric
linear system, which is named Generalized Node &amp; Branch Tearing (GNBT). It is
based on Kirchhoff's Current Law from circuit theory. We proved that GNBT is
feasible to partition any SPD linear system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1997</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1997</id><created>2008-07-12</created><updated>2009-05-13</updated><authors><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author><author><keyname>Sun</keyname><forenames>Yu-Yin</forenames></author><author><keyname>Li</keyname><forenames>Yu-Feng</forenames></author></authors><title>Multi-Instance Learning by Treating Instances As Non-I.I.D. Samples</title><categories>cs.LG cs.AI</categories><comments>ICML, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-instance learning attempts to learn from a training set consisting of
labeled bags each containing many unlabeled instances. Previous studies
typically treat the instances in the bags as independently and identically
distributed. However, the instances in a bag are rarely independent, and
therefore a better performance can be expected if the instances are treated in
an non-i.i.d. way that exploits the relations among instances. In this paper,
we propose a simple yet effective multi-instance learning method, which regards
each bag as a graph and uses a specific kernel to distinguish the graphs by
considering the features of the nodes as well as the features of the edges that
convey some relations among instances. The effectiveness of the proposed method
is validated by experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2011</identifier>
 <datestamp>2009-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2011</id><created>2008-07-13</created><updated>2009-02-04</updated><authors><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Skopalik</keyname><forenames>Alexander</forenames></author></authors><title>Altruism in Atomic Congestion Games</title><categories>cs.GT</categories><comments>13 pages, 1 figure, includes some minor adjustments</comments><acm-class>F.1.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the effects of introducing altruistic agents into atomic
congestion games. Altruistic behavior is modeled by a trade-off between selfish
and social objectives. In particular, we assume agents optimize a linear
combination of personal delay of a strategy and the resulting increase in
social cost. Our model can be embedded in the framework of congestion games
with player-specific latency functions. Stable states are the Nash equilibria
of these games, and we examine their existence and the convergence of
sequential best-response dynamics. Previous work shows that for symmetric
singleton games with convex delays Nash equilibria are guaranteed to exist. For
concave delay functions we observe that there are games without Nash equilibria
and provide a polynomial time algorithm to decide existence for symmetric
singleton games with arbitrary delay functions. Our algorithm can be extended
to compute best and worst Nash equilibria if they exist. For more general
congestion games existence becomes NP-hard to decide, even for symmetric
network games with quadratic delay functions. Perhaps surprisingly, if all
delay functions are linear, then there is always a Nash equilibrium in any
congestion game with altruists and any better-response dynamics converges. In
addition to these results for uncoordinated dynamics, we consider a scenario in
which a central altruistic institution can motivate agents to act
altruistically. We provide constructive and hardness results for finding the
minimum number of altruists to stabilize an optimal congestion profile and more
general mechanisms to incentivize agents to adopt favorable behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2023</identifier>
 <datestamp>2008-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2023</id><created>2008-07-13</created><authors><author><keyname>Haddadi</keyname><forenames>Hamed</forenames></author><author><keyname>Fay</keyname><forenames>Damien</forenames></author><author><keyname>Jamakovic</keyname><forenames>Almerima</forenames></author><author><keyname>Maennel</keyname><forenames>Olaf</forenames></author><author><keyname>Moore</keyname><forenames>Andrew W.</forenames></author><author><keyname>Mortier</keyname><forenames>Richard</forenames></author><author><keyname>Rio</keyname><forenames>Miguel</forenames></author><author><keyname>Uhlig</keyname><forenames>Steve</forenames></author></authors><title>Beyond Node Degree: Evaluating AS Topology Models</title><categories>cs.NI</categories><acm-class>C.2.1; I.6.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many models have been proposed to generate Internet Autonomous System (AS)
topologies, most of which make structural assumptions about the AS graph. In
this paper we compare AS topology generation models with several observed AS
topologies. In contrast to most previous works, we avoid making assumptions
about which topological properties are important to characterize the AS
topology. Our analysis shows that, although matching degree-based properties,
the existing AS topology generation models fail to capture the complexity of
the local interconnection structure between ASs. Furthermore, we use BGP data
from multiple vantage points to show that additional measurement locations
significantly affect local structure properties, such as clustering and node
centrality. Degree-based properties, however, are not notably affected by
additional measurements locations. These observations are particularly valid in
the core. The shortcomings of AS topology generation models stems from an
underestimation of the complexity of the connectivity in the core caused by
inappropriate use of BGP data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2028</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2028</id><created>2008-07-13</created><updated>2009-03-12</updated><authors><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author><author><keyname>Hendrickx</keyname><forenames>Julien M.</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>On Krause's multi-agent consensus model with state-dependent
  connectivity (Extended version)</title><categories>cs.MA</categories><comments>11 tex files, 13 eps files, 1 style file, 15 double columns pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a model of opinion dynamics introduced by Krause: each agent has an
opinion represented by a real number, and updates its opinion by averaging all
agent opinions that differ from its own by less than 1. We give a new proof of
convergence into clusters of agents, with all agents in the same cluster
holding the same opinion. We then introduce a particular notion of equilibrium
stability and provide lower bounds on the inter-cluster distances at a stable
equilibrium. To better understand the behavior of the system when the number of
agents is large, we also introduce and study a variant involving a continuum of
agents, obtaining partial convergence results and lower bounds on inter-cluster
distances, under some mild assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2043</identifier>
 <datestamp>2008-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2043</id><created>2008-07-13</created><authors><author><keyname>Mitrokotsa</keyname><forenames>Aikaterini</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Douligeris</keyname><forenames>Christos</forenames></author></authors><title>Intrusion Detection Using Cost-Sensitive Classification</title><categories>cs.CR cs.CV cs.NI</categories><comments>13 pages, 6 figures, presented at EC2ND 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intrusion Detection is an invaluable part of computer networks defense. An
important consideration is the fact that raising false alarms carries a
significantly lower cost than not detecting at- tacks. For this reason, we
examine how cost-sensitive classification methods can be used in Intrusion
Detection systems. The performance of the approach is evaluated under different
experimental conditions, cost matrices and different classification models, in
terms of expected cost, as well as detection and false alarm rates. We find
that even under unfavourable conditions, cost-sensitive classification can
improve performance significantly, if only slightly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2047</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2047</id><created>2008-07-13</created><updated>2008-07-16</updated><authors><author><keyname>Kalantari</keyname><forenames>Mahzad</forenames></author><author><keyname>Jung</keyname><forenames>Franck</forenames></author><author><keyname>Guedon</keyname><forenames>JeanPierre</forenames></author><author><keyname>Paparoditis</keyname><forenames>Nicolas</forenames></author></authors><title>The Five Points Pose Problem : A New and Accurate Solution Adapted to
  any Geometric Configuration</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to estimate directly the rotation and translation
between two stereoscopic images with the help of five homologous points. The
methodology presented does not mix the rotation and translation parameters,
which is comparably an important advantage over the methods using the
well-known essential matrix. This results in correct behavior and accuracy for
situations otherwise known as quite unfavorable, such as planar scenes, or
panoramic sets of images (with a null base length), while providing quite
comparable results for more &quot;standard&quot; cases. The resolution of the algebraic
polynomials resulting from the modeling of the coplanarity constraint is made
with the help of powerful algebraic solver tools (the Groebner bases and the
Rational Univariate Representation).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2049</identifier>
 <datestamp>2008-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2049</id><created>2008-07-13</created><authors><author><keyname>Mitrokotsa</keyname><forenames>Aikaterini</forenames></author><author><keyname>Tsagkaris</keyname><forenames>Manolis</forenames></author><author><keyname>Douligeris</keyname><forenames>Christos</forenames></author></authors><title>Intrusion Detection in Mobile Ad Hoc Networks Using Classification
  Algorithms</title><categories>cs.CR cs.NI</categories><comments>12 pages, 7 figures, presented at MedHocNet 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the design and evaluation of intrusion detection
models for MANETs using supervised classification algorithms. Specifically, we
evaluate the performance of the MultiLayer Perceptron (MLP), the Linear
classifier, the Gaussian Mixture Model (GMM), the Naive Bayes classifier and
the Support Vector Machine (SVM). The performance of the classification
algorithms is evaluated under different traffic conditions and mobility
patterns for the Black Hole, Forging, Packet Dropping, and Flooding attacks.
The results indicate that Support Vector Machines exhibit high accuracy for
almost all simulated attacks and that Packet Dropping is the hardest attack to
detect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2053</identifier>
 <datestamp>2008-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2053</id><created>2008-07-13</created><authors><author><keyname>Mitrokotsa</keyname><forenames>Aikaterini</forenames></author><author><keyname>Komninos</keyname><forenames>Nikos</forenames></author><author><keyname>Douligeris</keyname><forenames>Christos</forenames></author></authors><title>Towards an Effective Intrusion Response Engine Combined with Intrusion
  Detection in Ad Hoc Networks</title><categories>cs.CR cs.NI</categories><comments>8 pages, 9 figures, presented at MedHocNet07</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an effective intrusion response engine combined
with intrusion detection in ad hoc networks. The intrusion response engine is
composed of a secure communication module, a local and a global response
module. Its function is based on an innovative tree-based key agreement
protocol while the intrusion detection engine is based on a class of neural
networks called eSOM. The proposed intrusion response model and the tree-based
protocol, it is based on, are analyzed concerning key secrecy while the
intrusion detection engine is evaluated for MANET under different traffic
conditions and mobility patterns. The results show a high detection rate for
packet dropping attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2108</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2108</id><created>2008-07-14</created><updated>2009-07-23</updated><authors><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Prakash</keyname><forenames>A.</forenames></author><author><keyname>Hjelmstad</keyname><forenames>K. D.</forenames></author></authors><title>On dual Schur domain decomposition method for linear first-order
  transient problems</title><categories>cs.NA cs.CE</categories><comments>22 Figures, 49 pages (double spacing using amsart)</comments><doi>10.1016/j.jcp.2009.07.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses some numerical and theoretical aspects of dual Schur
domain decomposition methods for linear first-order transient partial
differential equations. In this work, we consider the trapezoidal family of
schemes for integrating the ordinary differential equations (ODEs) for each
subdomain and present four different coupling methods, corresponding to
different algebraic constraints, for enforcing kinematic continuity on the
interface between the subdomains.
  Method 1 (d-continuity) is based on the conventional approach using
continuity of the primary variable and we show that this method is unstable for
a lot of commonly used time integrators including the mid-point rule. To
alleviate this difficulty, we propose a new Method 2 (Modified d-continuity)
and prove its stability for coupling all time integrators in the trapezoidal
family (except the forward Euler). Method 3 (v-continuity) is based on
enforcing the continuity of the time derivative of the primary variable.
However, this constraint introduces a drift in the primary variable on the
interface. We present Method 4 (Baumgarte stabilized) which uses Baumgarte
stabilization to limit this drift and we derive bounds for the stabilization
parameter to ensure stability.
  Our stability analysis is based on the ``energy'' method, and one of the main
contributions of this paper is the extension of the energy method (which was
previously introduced in the context of numerical methods for ODEs) to assess
the stability of numerical formulations for index-2 differential-algebraic
equations (DAEs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2120</identifier>
 <datestamp>2008-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2120</id><created>2008-07-14</created><updated>2008-09-15</updated><authors><author><keyname>Moser</keyname><forenames>Robin A.</forenames></author></authors><title>Derandomizing the Lovasz Local Lemma more effectively</title><categories>cs.DS cs.CC</categories><comments>8 pages; added acknowledgement</comments><acm-class>F.2; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The famous Lovasz Local Lemma [EL75] is a powerful tool to non-constructively
prove the existence of combinatorial objects meeting a prescribed collection of
criteria. Kratochvil et al. applied this technique to prove that a k-CNF in
which each variable appears at most 2^k/(ek) times is always satisfiable
[KST93]. In a breakthrough paper, Beck found that if we lower the occurrences
to O(2^(k/48)/k), then a deterministic polynomial-time algorithm can find a
satisfying assignment to such an instance [Bec91]. Alon randomized the
algorithm and required O(2^(k/8)/k) occurrences [Alo91]. In [Mos06], we
exhibited a refinement of his method which copes with O(2^(k/6)/k) of them. The
hitherto best known randomized algorithm is due to Srinivasan and is capable of
solving O(2^(k/4)/k) occurrence instances [Sri08]. Answering two questions
asked by Srinivasan, we shall now present an approach that tolerates
O(2^(k/2)/k) occurrences per variable and which can most easily be
derandomized. The new algorithm bases on an alternative type of witness tree
structure and drops a number of limiting aspects common to all previous
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2158</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2158</id><created>2008-07-14</created><updated>2009-05-19</updated><authors><author><keyname>Masanes</keyname><forenames>Lluis</forenames></author></authors><title>Universally-composable privacy amplification from causality constraints</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>4 pages</comments><journal-ref>Phys. Rev. Lett. 102, 140501 (2009)</journal-ref><doi>10.1103/PhysRevLett.102.140501</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider schemes for secret key distribution which use as a resource
correlations that violate Bell inequalities. We provide the first security
proof for such schemes, according to the strongest notion of security, the so
called universally-composable security. Our security proof does not rely on the
validity of quantum mechanics, it solely relies on the impossibility of
arbitrarily-fast signaling between separate physical systems. This allows for
secret communication in situations where the participants distrust their
quantum devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2178</identifier>
 <datestamp>2008-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2178</id><created>2008-07-14</created><authors><author><keyname>G&#xe4;rtner</keyname><forenames>Bernd</forenames></author></authors><title>Ranking Unit Squares with Few Visibilities</title><categories>cs.CG cs.DS</categories><comments>4 pages, 2 EPS-figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of n unit squares in the plane, the goal is to rank them in space
in such a way that only few squares see each other vertically. We prove that
ranking the squares according to the lexicographic order of their centers
results in at most 3n-7 pairwise visibilities for n at least 4. We also show
that this bound is best possible, by exhibiting a set of n squares with at
least 3n-7 pairwise visibilities under any ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2218</identifier>
 <datestamp>2008-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2218</id><created>2008-07-14</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Isometric Diamond Subgraphs</title><categories>cs.CG</categories><comments>6 pages, 4 figures. To appear at 16th Int. Symp. Graph Drawing (GD08)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe polynomial time algorithms for determining whether an undirected
graph may be embedded in a distance-preserving way into the hexagonal tiling of
the plane, the diamond structure in three dimensions, or analogous structures
in higher dimensions. The graphs that may be embedded in this way form an
interesting subclass of the partial cubes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2268</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2268</id><created>2008-07-14</created><authors><author><keyname>Oyman</keyname><forenames>Ozgur</forenames></author><author><keyname>Laneman</keyname><forenames>J. Nicholas</forenames></author></authors><title>Multihop Diversity in Wideband OFDM Systems: The Impact of Spatial Reuse
  and Frequency Selectivity</title><categories>cs.IT math.IT</categories><comments>6 pages, to be published in Proc. 2008 IEEE International Symposium
  on Spread Spectrum Techniques and Applications (IEEE ISSSTA'08), Bologna,
  Italy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to establish which practical routing schemes for
wireless networks are most suitable for wideband systems in the power-limited
regime, which is, for example, a practically relevant mode of operation for the
analysis of ultrawideband (UWB) mesh networks. For this purpose, we study the
tradeoff between energy efficiency and spectral efficiency (known as the
power-bandwidth tradeoff) in a wideband linear multihop network in which
transmissions employ orthogonal frequency-division multiplexing (OFDM)
modulation and are affected by quasi-static, frequency-selective fading.
Considering open-loop (fixed-rate) and closed-loop (rate-adaptive) multihop
relaying techniques, we characterize the impact of routing with spatial reuse
on the statistical properties of the end-to-end conditional mutual information
(conditioned on the specific values of the channel fading parameters and
therefore treated as a random variable) and on the energy and spectral
efficiency measures of the wideband regime. Our analysis particularly deals
with the convergence of these end-to-end performance measures in the case of
large number of hops, i.e., the phenomenon first observed in \cite{Oyman06b}
and named as ``multihop diversity''. Our results demonstrate the realizability
of the multihop diversity advantages in the case of routing with spatial reuse
for wideband OFDM systems under wireless channel effects such as path-loss and
quasi-static frequency-selective multipath fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2269</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2269</id><created>2008-07-15</created><authors><author><keyname>Goldsztejn</keyname><forenames>Alexandre</forenames><affiliation>LINA</affiliation></author><author><keyname>Michel</keyname><forenames>Claude</forenames><affiliation>I3S, Laboratoire I3S</affiliation></author><author><keyname>Rueher</keyname><forenames>Michel</forenames><affiliation>I3S, Laboratoire I3S</affiliation></author></authors><title>An Efficient Algorithm for a Sharp Approximation of Universally
  Quantified Inequalities</title><categories>cs.NA cs.DS</categories><comments>ACM symposium on Applied computing, Fortaleza, Ceara : Br\'esil
  (2008)</comments><proxy>ccsd hal-00297250</proxy><acm-class>G.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new algorithm for solving a sub-class of quantified
constraint satisfaction problems (QCSP) where existential quantifiers precede
universally quantified inequalities on continuous domains. This class of QCSPs
has numerous applications in engineering and design. We propose here a new
generic branch and prune algorithm for solving such continuous QCSPs. Standard
pruning operators and solution identification operators are specialized for
universally quantified inequalities. Special rules are also proposed for
handling the parameters of the constraints. First experimentation show that our
algorithm outperforms the state of the art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2282</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2282</id><created>2008-07-14</created><authors><author><keyname>Ghani</keyname><forenames>Arfan</forenames></author><author><keyname>McGinnity</keyname><forenames>Martin</forenames></author><author><keyname>Maguire</keyname><forenames>Liam</forenames></author><author><keyname>Harkin</keyname><forenames>Jim</forenames></author></authors><title>Hardware/Software Co-Design for Spike Based Recognition</title><categories>cs.NE cs.AI cs.CE</categories><comments>6 pages</comments><acm-class>C.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The practical applications based on recurrent spiking neurons are limited due
to their non-trivial learning algorithms. The temporal nature of spiking
neurons is more favorable for hardware implementation where signals can be
represented in binary form and communication can be done through the use of
spikes. This work investigates the potential of recurrent spiking neurons
implementations on reconfigurable platforms and their applicability in temporal
based applications. A theoretical framework of reservoir computing is
investigated for hardware/software implementation. In this framework, only
readout neurons are trained which overcomes the burden of training at the
network level. These recurrent neural networks are termed as microcircuits
which are viewed as basic computational units in cortical computation. This
paper investigates the potential of recurrent neural reservoirs and presents a
novel hardware/software strategy for their implementation on FPGAs. The design
is implemented and the functionality is tested in the context of speech
recognition application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2292</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2292</id><created>2008-07-14</created><updated>2009-06-09</updated><authors><author><keyname>Li</keyname><forenames>Shizheng</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author></authors><title>Rate and power allocation under the pairwise distributed source coding
  constraint</title><categories>cs.IT math.IT</categories><comments>The first version was published in ISIT 2008. The new version
  includes all detailed proofs and more simulation results. The latest version
  has been accepted by IEEE Transactions on Communications</comments><acm-class>E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rate and power allocation for a sensor network
under the pairwise distributed source coding constraint. For noiseless
source-terminal channels, we show that the minimum sum rate assignment can be
found by finding a minimum weight arborescence in an appropriately defined
directed graph. For orthogonal noisy source-terminal channels, the minimum sum
power allocation can be found by finding a minimum weight matching forest in a
mixed graph. Numerical results are presented for both cases showing that our
solutions always outperform previously proposed solutions. The gains are
considerable when source correlations are high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2303</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2303</id><created>2008-07-15</created><authors><author><keyname>Bucci</keyname><forenames>Michelangelo</forenames></author><author><keyname>De Luca</keyname><forenames>Alessandro</forenames></author><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames></author></authors><title>A new characteristic property of rich words</title><categories>math.CO cs.DM</categories><comments>6 pages</comments><msc-class>68R15</msc-class><journal-ref>Theoretical Computer Science 410 (2009) 2860-2863</journal-ref><doi>10.1016/j.tcs.2008.11.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Originally introduced and studied by the third and fourth authors together
with J. Justin and S. Widmer in arXiv:0801.1656, rich words constitute a new
class of finite and infinite words characterized by containing the maximal
number of distinct palindromes. Several characterizations of rich words have
already been established. A particularly nice characteristic property is that
all 'complete returns' to palindromes are palindromes. In this note, we prove
that rich words are also characterized by the property that each factor is
uniquely determined by its longest palindromic prefix and its longest
palindromic suffix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2328</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2328</id><created>2008-07-15</created><authors><author><keyname>Liang</keyname><forenames>Huiguang</forenames></author><author><keyname>Tay</keyname><forenames>Ian</forenames></author><author><keyname>Neo</keyname><forenames>Ming Feng</forenames></author><author><keyname>Ooi</keyname><forenames>Wei Tsang</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Avatar Mobility in Networked Virtual Environments: Measurements,
  Analysis, and Implications</title><categories>cs.NI cs.MM</categories><acm-class>H.5.1; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We collected mobility traces of 84,208 avatars spanning 22 regions over two
months in Second Life, a popular networked virtual environment. We analyzed the
traces to characterize the dynamics of the avatars mobility and behavior, both
temporally and spatially. We discuss the implications of the our findings to
the design of peer-to-peer networked virtual environments, interest management,
mobility modeling of avatars, server load balancing and zone partitioning,
client-side caching, and prefetching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2330</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2330</id><created>2008-07-15</created><updated>2008-07-24</updated><authors><author><keyname>Mchedlidze</keyname><forenames>Tamara</forenames></author><author><keyname>Symvonis</keyname><forenames>Antonios</forenames></author></authors><title>Optimal Acyclic Hamiltonian Path Completion for Outerplanar Triangulated
  st-Digraphs (with Application to Upward Topological Book Embeddings)</title><categories>cs.DS cs.DM</categories><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an embedded planar acyclic digraph G, we define the problem of &quot;acyclic
hamiltonian path completion with crossing minimization (Acyclic-HPCCM)&quot; to be
the problem of determining an hamiltonian path completion set of edges such
that, when these edges are embedded on G, they create the smallest possible
number of edge crossings and turn G to a hamiltonian digraph. Our results
include:
  --We provide a characterization under which a triangulated st-digraph G is
hamiltonian.
  --For an outerplanar triangulated st-digraph G, we define the st-polygon
decomposition of G and, based on its properties, we develop a linear-time
algorithm that solves the Acyclic-HPCCM problem with at most one crossing per
edge of G.
  --For the class of st-planar digraphs, we establish an equivalence between
the Acyclic-HPCCM problem and the problem of determining an upward 2-page
topological book embedding with minimum number of spine crossings. We infer
(based on this equivalence) for the class of outerplanar triangulated
st-digraphs an upward topological 2-page book embedding with minimum number of
spine crossings and at most one spine crossing per edge.
  To the best of our knowledge, it is the first time that edge-crossing
minimization is studied in conjunction with the acyclic hamiltonian completion
problem and the first time that an optimal algorithm with respect to spine
crossing minimization is presented for upward topological book embeddings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2358</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2358</id><created>2008-07-15</created><updated>2010-09-27</updated><authors><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Schmidt</keyname><forenames>Christiane</forenames></author></authors><title>Polygon Exploration with Time-Discrete Vision</title><categories>cs.CG cs.RO</categories><comments>28 pages, 17 figures, 2 photographs, 3 tables, Latex. Updated some
  details (title, figures and text) for final journal revision, including
  explicit assumption of full edge visibility</comments><acm-class>F.2.2; I.2.9</acm-class><journal-ref>Computational Geometry: Theory and Applications, 43 (2010),
  148-168</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advent of autonomous robots with two- and three-dimensional scanning
capabilities, classical visibility-based exploration methods from computational
geometry have gained in practical importance. However, real-life laser scanning
of useful accuracy does not allow the robot to scan continuously while in
motion; instead, it has to stop each time it surveys its environment. This
requirement was studied by Fekete, Klein and Nuechter for the subproblem of
looking around a corner, but until now has not been considered in an online
setting for whole polygonal regions.
  We give the first algorithmic results for this important algorithmic problem
that combines stationary art gallery-type aspects with watchman-type issues in
an online scenario: We demonstrate that even for orthoconvex polygons, a
competitive strategy can be achieved only for limited aspect ratio A (the ratio
of the maximum and minimum edge length of the polygon), i.e., for a given lower
bound on the size of an edge; we give a matching upper bound by providing an
O(log A)-competitive strategy for simple rectilinear polygons, using the
assumption that each edge of the polygon has to be fully visible from some scan
point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2381</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2381</id><created>2008-07-15</created><authors><author><keyname>Martin</keyname><forenames>Bruno</forenames><affiliation>I3S</affiliation></author></authors><title>Analyse des suites al\'eatoires engendr\'ees par des automates
  cellulaires et applications \`a la cryptographie</title><categories>cs.CR</categories><comments>Journ\'ee de cryptanalyse et de s\'ecurit\'e de l'information,
  Casablanca : Maroc (2007)</comments><proxy>ccsd hal-00296811</proxy><acm-class>F.1.1; E.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers interactions between cellular automata and cryptology.
It is known that non-linear elementary rule which is correlation-immune don't
exist. This results limits the use of cellular automata as pseudo-random
generators suitable for cryptographic applications. In addition, for this kind
of pseudo-random generators, a successful cryptanalysis was proposed by Meier
and Staffelbach. However, other ways to design cellular automata capable to
generate good pseudo-random sequences remain and will be discussed in the end
of this article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2382</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2382</id><created>2008-07-15</created><authors><author><keyname>Goldsztejn</keyname><forenames>Alexandre</forenames><affiliation>I3S</affiliation></author><author><keyname>Lebbah</keyname><forenames>Yahia</forenames><affiliation>I3S</affiliation></author><author><keyname>Michel</keyname><forenames>Claude</forenames><affiliation>I3S</affiliation></author><author><keyname>Rueher</keyname><forenames>Michel</forenames><affiliation>I3S</affiliation></author></authors><title>Revisiting the upper bounding process in a safe Branch and Bound
  algorithm</title><categories>cs.NA cs.MS math.OC</categories><comments>Optimization, continuous domains, nonlinear constraint problems, safe
  constraint based approaches; 14th International Conference on Principles and
  Practice of Constraint Programming, Sydney : Australie (2008)</comments><proxy>ccsd hal-00297086</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding feasible points for which the proof succeeds is a critical issue in
safe Branch and Bound algorithms which handle continuous problems. In this
paper, we introduce a new strategy to compute very accurate approximations of
feasible points. This strategy takes advantage of the Newton method for
under-constrained systems of equations and inequalities. More precisely, it
exploits the optimal solution of a linear relaxation of the problem to compute
efficiently a promising upper bound. First experiments on the Coconuts
benchmarks demonstrate that this approach is very effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2383</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2383</id><created>2008-07-15</created><authors><author><keyname>Collavizza</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>I3S</affiliation></author><author><keyname>Rueher</keyname><forenames>Michel</forenames><affiliation>I3S</affiliation></author><author><keyname>Van Hentenryck</keyname><forenames>Pascal</forenames><affiliation>Brown University</affiliation></author></authors><title>CPBVP: A Constraint-Programming Framework for Bounded Program
  Verification</title><categories>cs.SE cs.AI cs.LO</categories><proxy>ccsd hal-00297007</proxy><journal-ref>The 14th International Conference on Principles and Practice of
  Constraint Programming, Sydney : Australie (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies how to verify the conformity of a program with its
specification and proposes a novel constraint-programming framework for bounded
program verification (CPBPV). The CPBPV framework uses constraint stores to
represent the specification and the program and explores execution paths
nondeterministically. The input program is partially correct if each constraint
store so produced implies the post-condition. CPBPV does not explore spurious
execution paths as it incrementally prunes execution paths early by detecting
that the constraint store is not consistent. CPBPV uses the rich language of
constraint programming to express the constraint store. Finally, CPBPV is
parametrized with a list of solvers which are tried in sequence, starting with
the least expensive and less general. Experimental results often produce orders
of magnitude improvements over earlier approaches, running times being often
independent of the variable domains. Moreover, CPBPV was able to detect subtle
errors in some programs while other frameworks based on model checking have
failed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2387</identifier>
 <datestamp>2008-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2387</id><created>2008-07-15</created><authors><author><keyname>Kritsikis</keyname><forenames>Evaggelos</forenames><affiliation>SPINTEC</affiliation></author><author><keyname>Toussaint</keyname><forenames>Jean-Christophe</forenames><affiliation>NEEL</affiliation></author><author><keyname>Fruchart</keyname><forenames>Olivier</forenames><affiliation>NEEL</affiliation></author></authors><title>Fast computation of magnetostatic fields by Non-uniform Fast Fourier
  Transforms</title><categories>cond-mat.mtrl-sci cs.NA</categories><proxy>ccsd hal-00297240</proxy><journal-ref>Applied Physics Letters 93, 13 (2008) 132508</journal-ref><doi>10.1063/1.2995850</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bottleneck of micromagnetic simulations is the computation of the
long-ranged magnetostatic fields. This can be tackled on regular N-node grids
with Fast Fourier Transforms in time N logN, whereas the geometrically more
versatile finite element methods (FEM) are bounded to N^4/3 in the best case.
We report the implementation of a Non-uniform Fast Fourier Transform algorithm
which brings a N logN convergence to FEM, with no loss of accuracy in the
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2440</identifier>
 <datestamp>2008-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2440</id><created>2008-07-15</created><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author></authors><title>Construction of Error-Correcting Codes for Random Network Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present error-correcting codes for random network coding
based on rank- metric codes, Ferrers diagrams, and puncturing. For most
parameters, the constructed codes are larger than all previously known codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2464</identifier>
 <datestamp>2008-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2464</id><created>2008-07-15</created><authors><author><keyname>Akay</keyname><forenames>E.</forenames></author><author><keyname>Park</keyname><forenames>H. J.</forenames></author><author><keyname>Ayanoglu</keyname><forenames>E.</forenames></author></authors><title>On &quot;Bit-Interleaved Coded Multiple Beamforming&quot;</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interleaver design criteria described in [1] should take into account all
error patterns of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2466</identifier>
 <datestamp>2009-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2466</id><created>2008-07-15</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Gintautas</keyname><forenames>Vadas</forenames></author><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author></authors><title>A Grateful Dead Analysis: The Relationship Between Concert and Listening
  Behavior</title><categories>cs.CY cs.GL</categories><report-no>LA-UR-08-04421</report-no><acm-class>K.4.0</acm-class><journal-ref>First Monday, volume 14, number 1, ISSN:1396-0466, University of
  Illinois at Chicago Library, January 2009.</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The Grateful Dead were an American band that was born out of the San
Francisco, California psychedelic movement of the 1960s. The band played music
together from 1965 to 1995 and is well known for concert performances
containing extended improvisations and long and unique set lists. This article
presents a comparative analysis between 1,590 of the Grateful Dead's concert
set lists from 1972 to 1995 and 2,616,990 last.fm Grateful Dead listening
events from August 2005 to October 2007. While there is a strong correlation
between how songs were played in concert and how they are listened to by
last.fm members, the outlying songs in this trend identify interesting aspects
of the band and their fans 10 years after the band's dissolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2471</identifier>
 <datestamp>2008-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2471</id><created>2008-07-16</created><authors><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Morelli</keyname><forenames>Michele</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>An ESPRIT-based approach for Initial Ranging in OFDMA systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures; Proceedings of the Ninth IEEE Workshop on Signal
  Processing Advances in Wireless Communications, Recife, Brazil, July 6 - 9,
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a novel Initial Ranging scheme for orthogonal
frequency-division multiple-access networks. Users that intend to establish a
communication link with the base station (BS) are normally misaligned both in
time and frequency and the goal is to jointly estimate their timing errors and
carrier frequency offsets with respect to the BS local references. This is
accomplished with affordable complexity by resorting to the ESPRIT algorithm.
Computer simulations are used to assess the effectiveness of the proposed
solution and to make comparisons with existing alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2472</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2472</id><created>2008-07-15</created><authors><author><keyname>Matousek</keyname><forenames>Jiri</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author></authors><title>Inapproximability for metric embeddings into R^d</title><categories>cs.CG cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing the smallest possible distortion for
embedding of a given n-point metric space into R^d, where d is fixed (and
small). For d=1, it was known that approximating the minimum distortion with a
factor better than roughly n^(1/12) is NP-hard. From this result we derive
inapproximability with factor roughly n^(1/(22d-10)) for every fixed d\ge 2, by
a conceptually very simple reduction. However, the proof of correctness
involves a nontrivial result in geometric topology (whose current proof is
based on ideas due to Jussi Vaisala).
  For d\ge 3, we obtain a stronger inapproximability result by a different
reduction: assuming P \ne NP, no polynomial-time algorithm can distinguish
between spaces embeddable in R^d with constant distortion from spaces requiring
distortion at least n^(c/d), for a constant c&gt;0. The exponent c/d has the
correct order of magnitude, since every n-point metric space can be embedded in
R^d with distortion O(n^{2/d}\log^{3/2}n) and such an embedding can be
constructed in polynomial time by random projection.
  For d=2, we give an example of a metric space that requires a large
distortion for embedding in R^2, while all not too large subspaces of it embed
almost isometrically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2475</identifier>
 <datestamp>2008-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2475</id><created>2008-07-15</created><authors><author><keyname>Pun</keyname><forenames>Man-On</forenames></author><author><keyname>Brown</keyname><forenames>D. Richard</forenames><suffix>III</suffix></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Opportunistic Collaborative Beamforming with One-Bit Feedback</title><categories>cs.IT math.IT</categories><comments>Proceedings of the Ninth IEEE Workshop on Signal Processing Advances
  in Wireless Communications, Recife, Brazil, July 6-9, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An energy-efficient opportunistic collaborative beamformer with one-bit
feedback is proposed for ad hoc sensor networks over Rayleigh fading channels.
In contrast to conventional collaborative beamforming schemes in which each
source node uses channel state information to correct its local carrier offset
and channel phase, the proposed beamforming scheme opportunistically selects a
subset of source nodes whose received signals combine in a quasi-coherent
manner at the intended receiver. No local phase-precompensation is performed by
the nodes in the opportunistic collaborative beamformer. As a result, each node
requires only one-bit of feedback from the destination in order to determine if
it should or shouldn't participate in the collaborative beamformer. Theoretical
analysis shows that the received signal power obtained with the proposed
beamforming scheme scales linearly with the number of available source nodes.
Since the the optimal node selection rule requires an exhaustive search over
all possible subsets of source nodes, two low-complexity selection algorithms
are developed. Simulation results confirm the effectiveness of opportunistic
collaborative beamforming with the low-complexity selection algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2496</identifier>
 <datestamp>2009-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2496</id><created>2008-07-16</created><updated>2009-01-25</updated><authors><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Munagala</keyname><forenames>Kamesh</forenames></author></authors><title>Hybrid Keyword Search Auctions</title><categories>cs.GT cs.DS cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search auctions have become a dominant source of revenue generation on the
Internet. Such auctions have typically used per-click bidding and pricing. We
propose the use of hybrid auctions where an advertiser can make a
per-impression as well as a per-click bid, and the auctioneer then chooses one
of the two as the pricing mechanism. We assume that the advertiser and the
auctioneer both have separate beliefs (called priors) on the click-probability
of an advertisement. We first prove that the hybrid auction is truthful,
assuming that the advertisers are risk-neutral. We then show that this auction
is superior to the existing per-click auction in multiple ways: 1) It takes
into account the risk characteristics of the advertisers. 2) For obscure
keywords, the auctioneer is unlikely to have a very sharp prior on the
click-probabilities. In such situations, the hybrid auction can result in
significantly higher revenue. 3) An advertiser who believes that its
click-probability is much higher than the auctioneer's estimate can use
per-impression bids to correct the auctioneer's prior without incurring any
extra cost. 4) The hybrid auction can allow the advertiser and auctioneer to
implement complex dynamic programming strategies. As Internet commerce matures,
we need more sophisticated pricing models to exploit all the information held
by each of the participants. We believe that hybrid auctions could be an
important step in this direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2515</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2515</id><created>2008-07-16</created><authors><author><keyname>Mohr</keyname><forenames>Joseph J.</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Barkhouse</keyname><forenames>Wayne</forenames><affiliation>University of North Dakota</affiliation></author><author><keyname>Beldica</keyname><forenames>Cristina</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Bertin</keyname><forenames>Emmanuel</forenames><affiliation>Institut d'Astrophysque, Paris</affiliation></author><author><keyname>Cai</keyname><forenames>Y. Dora</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>da Costa</keyname><forenames>Luiz</forenames><affiliation>Observatorio Nacional, Brasil</affiliation></author><author><keyname>Darnell</keyname><forenames>J. Anthony</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Daues</keyname><forenames>Gregory E.</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Jarvis</keyname><forenames>Michael</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Gower</keyname><forenames>Michelle</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Lin</keyname><forenames>Huan</forenames><affiliation>Fermilab</affiliation></author><author><keyname>Martelli</keyname><forenames>leandro</forenames><affiliation>Observatorio Nacional, Brasil</affiliation></author><author><keyname>Neilsen</keyname><forenames>Eric</forenames><affiliation>Fermilab</affiliation></author><author><keyname>Ngeow</keyname><forenames>Chow-Choong</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Ogando</keyname><forenames>Ricardo</forenames><affiliation>Observatorio Nacional, Brasil</affiliation></author><author><keyname>Parga</keyname><forenames>Alex</forenames><affiliation>University of Illinois</affiliation></author><author><keyname>Sheldon</keyname><forenames>Erin</forenames><affiliation>New York University</affiliation></author><author><keyname>Tucker</keyname><forenames>Douglas</forenames><affiliation>Fermilab</affiliation></author><author><keyname>Kuropatkin</keyname><forenames>Nikolay</forenames><affiliation>Fermilab</affiliation></author><author><keyname>Stoughton</keyname><forenames>Chris</forenames><affiliation>Fermilab</affiliation></author></authors><title>The Dark Energy Survey Data Management System</title><categories>astro-ph cs.DC</categories><comments>To be published in the proceedings of the SPIE conference on
  Astronomical Instrumentation (held in Marseille in June 2008). This preprint
  is made available with the permission of SPIE. Further information together
  with preprint containing full quality images is available at
  http://desweb.cosmology.uiuc.edu/wiki</comments><doi>10.1117/12.789550</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dark Energy Survey collaboration will study cosmic acceleration with a
5000 deg2 griZY survey in the southern sky over 525 nights from 2011-2016. The
DES data management (DESDM) system will be used to process and archive these
data and the resulting science ready data products. The DESDM system consists
of an integrated archive, a processing framework, an ensemble of astronomy
codes and a data access framework. We are developing the DESDM system for
operation in the high performance computing (HPC) environments at NCSA and
Fermilab. Operating the DESDM system in an HPC environment offers both speed
and flexibility. We will employ it for our regular nightly processing needs,
and for more compute-intensive tasks such as large scale image coaddition
campaigns, extraction of weak lensing shear from the full survey dataset, and
massive seasonal reprocessing of the DES data. Data products will be available
to the Collaboration and later to the public through a virtual-observatory
compatible web portal. Our approach leverages investments in publicly available
HPC systems, greatly reducing hardware and maintenance costs to the project,
which must deploy and maintain only the storage, database platforms and
orchestration and web portal nodes that are specific to DESDM. In Fall 2007, we
tested the current DESDM system on both simulated and real survey data. We used
Teragrid to process 10 simulated DES nights (3TB of raw data), ingesting and
calibrating approximately 250 million objects into the DES Archive database. We
also used DESDM to process and calibrate over 50 nights of survey data acquired
with the Mosaic2 camera. Comparison to truth tables in the case of the
simulated data and internal crosschecks in the case of the real data indicate
that astrometric and photometric data quality is excellent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2543</identifier>
 <datestamp>2009-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2543</id><created>2008-07-16</created><updated>2009-03-20</updated><authors><author><keyname>Kamouna</keyname><forenames>Rafee Ebrahim</forenames></author></authors><title>Two Fuzzy Logic Programming Paradoxes Imply Continuum Hypothesis=&quot;False&quot;
  &amp; Axiom of Choice=&quot;False&quot; Imply ZFC is Inconsistent</title><categories>cs.LO</categories><comments>Submitted to ACM Transactions on Computational Logic</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two different paradoxes of the fuzzy logic programming system of [29] are
presented. The first paradox is due to two distinct (contradictory) truth
values for every ground atom of FLP, one is syntactical, the other is
semantical. The second paradox concerns the cardinality of the valid FLP
formulas which is found to have contradictory values: both $\aleph_0$ the
cardinality of the natural numbers, and $c$, the cardinality of the continuum.
The result is that CH=&quot;False&quot; and Axiom of Choice=&quot;False&quot;. Hence, ZFC is
inconsistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2569</identifier>
 <datestamp>2008-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2569</id><created>2008-07-16</created><authors><author><keyname>Solka</keyname><forenames>Jeffrey</forenames></author></authors><title>Text Data Mining: Theory and Methods</title><categories>stat.ML cs.IR stat.CO</categories><comments>Published in at http://dx.doi.org/10.1214/07-SS016 the Statistics
  Surveys (http://www.i-journals.org/ss/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-SS-SS_2007_16</report-no><msc-class>62-01 (Primary) 62A01 (Secondary)</msc-class><journal-ref>Statistics Surveys 2008, Vol. 2, 94-112</journal-ref><doi>10.1214/07-SS016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides the reader with a very brief introduction to some of the
theory and methods of text data mining. The intent of this article is to
introduce the reader to some of the current methodologies that are employed
within this discipline area while at the same time making the reader aware of
some of the interesting challenges that remain to be solved within the area.
Finally, the articles serves as a very rudimentary tutorial on some of
techniques while also providing the reader with a list of references for
additional study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2628</identifier>
 <datestamp>2008-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2628</id><created>2008-07-16</created><authors><author><keyname>Lard</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>LRI</affiliation></author><author><keyname>Landragin</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LaTTice</affiliation></author><author><keyname>Grisvard</keyname><forenames>Olivier</forenames><affiliation>ATOL</affiliation></author><author><keyname>Faure</keyname><forenames>David</forenames></author></authors><title>Un cadre de conception pour r\'eunir les mod\`eles d'interaction et
  l'ing\'enierie des interfaces</title><categories>cs.HC</categories><proxy>ccsd hal-00298492</proxy><journal-ref>Ing\'enierie des Syst\`emes d'Information (ISI) 12, 6 (2007) 67-91</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present HIC (Human-system Interaction Container), a general framework for
the integration of advanced interaction in the software development process. We
show how this framework allows to reconcile the software development methods
(such MDA, MDE) with the architectural models of software design such as MVC or
PAC. We illustrate our approach thanks to two different types of implementation
for this concept in two different business areas: one software design pattern,
MVIC (Model View Interaction Control) and one architectural model, IM
(Interaction Middleware).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2636</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2636</id><created>2008-07-14</created><authors><author><keyname>Hirschowitz</keyname><forenames>Andr&#xe9;</forenames><affiliation>JAD</affiliation></author><author><keyname>Hirschowitz</keyname><forenames>Michel</forenames><affiliation>LIX, LIST</affiliation></author><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LM-Savoie</affiliation></author></authors><title>Topological Observations on Multiplicative Additive Linear Logic</title><categories>cs.LO</categories><comments>12 pages in two columns, submitted to POPL '09. Uses Paul Taylor's
  diagrams</comments><proxy>ccsd hal-00295949</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an attempt to uncover the topological nature of composition of strategies
in game semantics, we present a ``topological'' game for Multiplicative
Additive Linear Logic without propositional variables, including cut moves. We
recast the notion of (winning) strategy and the question of cut elimination in
this context, and prove a cut elimination theorem. Finally, we prove soundness
and completeness. The topology plays a crucial role, in particular through the
fact that strategies form a sheaf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2648</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2648</id><created>2008-07-16</created><updated>2008-07-17</updated><authors><author><keyname>Savla</keyname><forenames>Ketan</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>On Endogenous Reconfiguration in Mobile Robotic Networks</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, our focus is on certain applications for mobile robotic
networks, where reconfiguration is driven by factors intrinsic to the network
rather than changes in the external environment. In particular, we study a
version of the coverage problem useful for surveillance applications, where the
objective is to position the robots in order to minimize the average distance
from a random point in a given environment to the closest robot. This problem
has been well-studied for omni-directional robots and it is shown that optimal
configuration for the network is a centroidal Voronoi configuration and that
the coverage cost belongs to $\Theta(m^{-1/2})$, where $m$ is the number of
robots in the network. In this paper, we study this problem for more realistic
models of robots, namely the double integrator (DI) model and the differential
drive (DD) model. We observe that the introduction of these motion constraints
in the algorithm design problem gives rise to an interesting behavior. For a
\emph{sparser} network, the optimal algorithm for these models of robots mimics
that for omni-directional robots. We propose novel algorithms whose
performances are within a constant factor of the optimal asymptotically (i.e.,
as $m \to +\infty$). In particular, we prove that the coverage cost for the DI
and DD models of robots is of order $m^{-1/3}$. Additionally, we show that, as
the network grows, these novel algorithms outperform the conventional
algorithm; hence necessitating a reconfiguration in the network in order to
maintain optimal quality of service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2666</identifier>
 <datestamp>2009-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2666</id><created>2008-07-16</created><updated>2009-07-09</updated><authors><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Source and Channel Coding for Correlated Sources Over Multiuser Channels</title><categories>cs.IT math.IT</categories><comments>Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Source and channel coding over multiuser channels in which receivers have
access to correlated source side information is considered. For several
multiuser channel models necessary and sufficient conditions for optimal
separation of the source and channel codes are obtained. In particular, the
multiple access channel, the compound multiple access channel, the interference
channel and the two-way channel with correlated sources and correlated receiver
side information are considered, and the optimality of separation is shown to
hold for certain source and side information structures. Interestingly, the
optimal separate source and channel codes identified for these models are not
necessarily the optimal codes for the underlying source coding or the channel
coding problems. In other words, while separation of the source and channel
codes is optimal, the nature of these optimal codes is impacted by the joint
design criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2677</identifier>
 <datestamp>2010-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2677</id><created>2008-07-16</created><updated>2010-02-06</updated><authors><author><keyname>Unnikrishnan</keyname><forenames>Jayakrishnan</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal</forenames></author></authors><title>Algorithms for Dynamic Spectrum Access with Learning for Cognitive Radio</title><categories>cs.NI cs.LG</categories><comments>Published in IEEE Transactions on Signal Processing, February 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of dynamic spectrum sensing and access in cognitive
radio systems as a partially observed Markov decision process (POMDP). A group
of cognitive users cooperatively tries to exploit vacancies in primary
(licensed) channels whose occupancies follow a Markovian evolution. We first
consider the scenario where the cognitive users have perfect knowledge of the
distribution of the signals they receive from the primary users. For this
problem, we obtain a greedy channel selection and access policy that maximizes
the instantaneous reward, while satisfying a constraint on the probability of
interfering with licensed transmissions. We also derive an analytical universal
upper bound on the performance of the optimal policy. Through simulation, we
show that our scheme achieves good performance relative to the upper bound and
improved performance relative to an existing scheme.
  We then consider the more practical scenario where the exact distribution of
the signal from the primary is unknown. We assume a parametric model for the
distribution and develop an algorithm that can learn the true distribution,
still guaranteeing the constraint on the interference probability. We show that
this algorithm outperforms the naive design that assumes a worst case value for
the parameter. We also provide a proof for the convergence of the learning
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2678</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2678</id><created>2008-07-16</created><updated>2008-10-27</updated><authors><author><keyname>Davis</keyname><forenames>Philip M.</forenames></author></authors><title>Eigenfactor : Does the Principle of Repeated Improvement Result in
  Better Journal Impact Estimates than Raw Citation Counts?</title><categories>cs.DL cs.DB</categories><comments>bibliographic information corrected</comments><journal-ref>Journal of the American Society for Information Science &amp;
  Technology (2008) v59 n12 p.2186-2188</journal-ref><doi>10.1002/asi.20943</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Eigenfactor.org, a journal evaluation tool which uses an iterative algorithm
to weight citations (similar to the PageRank algorithm used for Google) has
been proposed as a more valid method for calculating the impact of journals.
The purpose of this brief communication is to investigate whether the principle
of repeated improvement provides different rankings of journals than does a
simple unweighted citation count (the method used by ISI).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2680</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2680</id><created>2008-07-16</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Ge</keyname><forenames>Gennian</forenames></author><author><keyname>Ling</keyname><forenames>Alan C. H.</forenames></author></authors><title>Group Divisible Codes and Their Application in the Construction of
  Optimal Constant-Composition Codes of Weight Three</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>13 pages, 1 figure, 4 tables</comments><journal-ref>IEEE Transactions on Information Theory, vol. 54, no. 8, pp.
  3552-3564, 2008</journal-ref><doi>10.1109/TIT.2008.926349</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of group divisible codes, a generalization of group divisible
designs with constant block size, is introduced in this paper. This new class
of codes is shown to be useful in recursive constructions for constant-weight
and constant-composition codes. Large classes of group divisible codes are
constructed which enabled the determination of the sizes of optimal
constant-composition codes of weight three (and specified distance), leaving
only four cases undetermined. Previously, the sizes of constant-composition
codes of weight three were known only for those of sufficiently large length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2694</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2694</id><created>2008-07-17</created><updated>2009-02-07</updated><authors><author><keyname>Li</keyname><forenames>Fei</forenames></author></authors><title>Algorithms for Scheduling Weighted Packets with Deadlines in a Bounded
  Queue</title><categories>cs.DS</categories><comments>19 pages. Appears in the Proceedings of the 28th IEEE International
  Conference on Computer Communications (INFOCOM 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the Quality-of-Service (QoS) buffer management problem, we
consider online scheduling of packets with hard deadlines in a finite capacity
queue. At any time, a queue can store at most $b \in \mathbb Z^+$ packets.
Packets arrive over time. Each packet is associated with a non-negative value
and an integer deadline. In each time step, only one packet is allowed to be
sent. Our objective is to maximize the total value gained by the packets sent
by their deadlines in an online manner. Due to the Internet traffic's chaotic
characteristics, no stochastic assumptions are made on the packet input
sequences. This model is called a {\em finite-queue model}.
  We use competitive analysis to measure an online algorithm's performance
versus an unrealizable optimal offline algorithm who constructs the worst
possible input based on the knowledge of the online algorithm. For the
finite-queue model, we first present a deterministic 3-competitive memoryless
online algorithm. Then, we give a randomized ($\phi^2 = ((1 + \sqrt{5}) / 2)^2
\approx 2.618$)-competitive memoryless online algorithm.
  The algorithmic framework and its theoretical analysis include several
interesting features. First, our algorithms use (possibly) modified
characteristics of packets; these characteristics may not be same as those
specified in the input sequence. Second, our analysis method is different from
the classical potential function approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2701</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2701</id><created>2008-07-17</created><authors><author><keyname>Miwa</keyname><forenames>Makoto</forenames></author><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author><author><keyname>Takumi</keyname><forenames>Ichi</forenames></author></authors><title>A Cutting Plane Method based on Redundant Rows for Improving Fractional
  Distance</title><categories>cs.IT math.IT</categories><comments>8 pages, To be presented at Turbo Coding 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an idea of the cutting plane method is employed to improve the
fractional distance of a given binary parity check matrix. The fractional
distance is the minimum weight (with respect to l1-distance) of vertices of the
fundamental polytope. The cutting polytope is defined based on redundant rows
of the parity check matrix and it plays a key role to eliminate unnecessary
fractional vertices in the fundamental polytope. We propose a greedy algorithm
and its efficient implementation for improving the fractional distance based on
the cutting plane method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2724</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2724</id><created>2008-07-17</created><authors><author><keyname>Hunger</keyname><forenames>Raphael</forenames></author><author><keyname>Joham</keyname><forenames>Michael</forenames></author></authors><title>An Asymptotic Analysis of the MIMO BC under Linear Filtering</title><categories>cs.IT math.IT</categories><comments>Submitted to ICC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the MIMO broadcast channel in the high SNR regime when linear
filtering is applied instead of dirty paper coding. Using a user-wise rate
duality where the streams of every single user are not treated as
self-interference as in the hitherto existing stream-wise rate dualities for
linear filtering, we solve the weighted sum rate maximization problem of the
broadcast channel in the dual multiple access channel. Thus, we can exactly
quantify the asymptotic rate loss of linear filtering compared to dirty paper
coding for any channel realization. Having converted the optimum covariance
matrices to the broadcast channel by means of the duality, we observe that the
optimal covariance matrices in the broadcast channel feature quite complicated
but still closed form expressions although the respective transmit covariance
matrices in the dual multiple access channel share a very simple structure. We
immediately come to the conclusion that block-diagonalization is the
asymptotically optimum transmit strategy in the broadcast channel. Out of the
set of block-diagonalizing precoders, we present the one which achieves the
largest sum rate and thus corresponds to the optimum solution found in the dual
multiple access channel. Additionally, we quantify the ergodic rate loss of
linear coding compared to dirty paper coding for Gaussian channels with
correlations at the mobiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2728</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2728</id><created>2008-07-17</created><authors><author><keyname>Fishler</keyname><forenames>E.</forenames></author><author><keyname>Gezici</keyname><forenames>S.</forenames></author><author><keyname>Poor</keyname><forenames>H. V.</forenames></author></authors><title>Iterative ('Turbo') Multiuser Detectors For Impulse Radio Systems</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there has been a growing interest in multiple access
communication systems that spread their transmitted energy over very large
bandwidths. These systems, which are referred to as ultra wide-band (UWB)
systems, have various advantages over narrow-band and conventional wide-band
systems. The importance of multiuser detection for achieving high data or low
bit error rates in these systems has already been established in several
studies. This paper presents iterative ('turbo') multiuser detection for
impulse radio (IR) UWB systems over multipath channels. While this approach is
demonstrated for UWB signals, it can also be used in other systems that use
similar types of signaling. When applied to the type of signals used by UWB
systems, the complexity of the proposed detector can be quite low. Also, two
very low complexity implementations of the iterative multiuser detection scheme
are proposed based on Gaussian approximation and soft interference
cancellation. The performance of these detectors is assessed using simulations
that demonstrate their favorable properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2730</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2730</id><created>2008-07-17</created><authors><author><keyname>Gezici</keyname><forenames>S.</forenames></author><author><keyname>Poor</keyname><forenames>H. V.</forenames></author></authors><title>Position Estimation via Ultra-Wideband Signals</title><categories>cs.IT math.IT</categories><comments>To appear in Proceedings of the IEEE (Special Issue on UWB Technology
  and Emerging Applications)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The high time resolution of ultra-wideband (UWB) signals facilitates very
precise position estimation in many scenarios, which makes a variety
applications possible. This paper reviews the problem of position estimation in
UWB systems, beginning with an overview of the basic structure of UWB signals
and their positioning applications. This overview is followed by a discussion
of various position estimation techniques, with an emphasis on time-based
approaches, which are particularly suitable for UWB positioning systems.
Practical issues arising in UWB signal design and hardware implementation are
also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2743</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2743</id><created>2008-07-17</created><authors><author><keyname>Sorj</keyname><forenames>Bernardo</forenames></author></authors><title>Information Societies and Digital Divides</title><categories>cs.CY</categories><comments>103 pages, ISBN 978-88-7699-127-1 (Printed edition), ISBN
  978-88-7699-128-8 (Electronic edition), printed edition available at
  http://www.amazon.com/ and http://stores.lulu.com/polimetrica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The book argues ICT are part of the set of goods and services that determine
quality of life, social inequality and the chances for economic development.
Therefore understanding the digital divide demands a broader discussion of the
place of ICT within each society and in the international system. The author
argues against the perspectives that either isolates ICT from other basic
social goods (in particular education and employment) as well as those that
argue that new technologies are luxury of a consumer society. Though the author
accepts that new technologies are not a panacea for the problems of inequality,
access to them become a condition of full integration of social life. Using
examples mainly from Latin America, the work presents some general policy
proposals on the fight against the digital divide which take in consideration
other dimensions of social inequality and access to public goods.
  Bernardo Sorj was born in Montevideo, Uruguay. He is a naturalized Brazilian,
living in Brazil since 1976. He studied anthropology and philosophy in Uruguay,
and holds a B.A. and an M.A. in History and Sociology from Haifa University,
Israel. He received his Ph.D. in Sociology from the University of Manchester in
England. Sorj was a professor at the Department of Political Science at the
Federal University of Minas Gerais and at the Institute for International
Relations, PUC/RJ. The author of 20 books and more than 100 articles, was
visiting professor and chair at many European and North American
universities...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2829</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2829</id><created>2008-07-17</created><authors><author><keyname>Hewer</keyname><forenames>Thomas D.</forenames></author><author><keyname>Nekovee</keyname><forenames>Maziar</forenames></author></authors><title>Congestion Reduction Using Ad hoc Message Dissemination in Vehicular
  Networks</title><categories>cs.NI</categories><comments>Workshop, 9 pages, 7 figures</comments><acm-class>I.6.3; C.2.0</acm-class><journal-ref>Proceedings of the 4th IEEE International Workshop on
  Vehicle-to-Vehicle Communications, pages 1-7, 2008</journal-ref><doi>10.1007/978-3-642-11284-3_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicle-to-vehicle communications can be used effectively for intelligent
transport systems (ITS) and location-aware services. The ability to disseminate
information in an ad-hoc fashion allows pertinent information to propagate
faster through the network. In the realm of ITS, the ability to spread warning
information faster and further is of great advantage to the receivers of this
information. In this paper we propose and present a message-dissemination
procedure that uses vehicular wireless protocols for influencing traffic flow,
reducing congestion in road networks. The computational experiments presented
in this paper show how an intelligent driver model (IDM) and car-following
model can be adapted to 'react' to the reception of information. This model
also presents the advantages of coupling together traffic modelling tools and
network simulation tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2836</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2836</id><created>2008-07-17</created><authors><author><keyname>Champalle</keyname><forenames>Olivier</forenames><affiliation>ICTT, Liesp</affiliation></author><author><keyname>David</keyname><forenames>Bertrand</forenames><affiliation>ICTT, Liesp</affiliation></author><author><keyname>Chalon</keyname><forenames>Ren&#xe9;</forenames><affiliation>ICTT, Liesp</affiliation></author><author><keyname>Masserey</keyname><forenames>Guillaume</forenames><affiliation>ICTT, Liesp</affiliation></author></authors><title>Ordinateur port\'e support de r\'ealit\'e augment\'ee pour des
  activit\'es de maintenance et de d\'epannage</title><categories>cs.HC</categories><comments>Ubimob'06 3e Journ\'ees Francophones Mobilit\'e et Ubiquit\'e, Paris
  : France (2006)</comments><proxy>ccsd hal-00298064</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a case study of use of wearable computer within the
framework of activities of maintenance and repairing. Besides the study of
configuration of this wearable computer and its peripherals, we show the
integration of context, in-situ storage, traceability and regulation in these
activities. This case study is in the scope of a huge project called HMTD (Help
Me To Do) which aim is to apply MOCOCO (Mobility, COoperation,
COntextualisation) and IMERA (Mobile Interaction in the Augmented Real
Environment) principles for better use, maintenance and repairing of equipments
in the domestic, public and professional situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2844</identifier>
 <datestamp>2008-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2844</id><created>2008-07-17</created><authors><author><keyname>Adinoyi</keyname><forenames>Abdulkareem</forenames></author><author><keyname>Fan</keyname><forenames>Yijia</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On the Performance of Selection Relaying</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE Vehicular Technology Conference,
  Calgary, Alberta, September 21-24, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interest in selection relaying is growing. The recent developments in this
area have largely focused on information theoretic analyses such as outage
performance. Some of these analyses are accurate only at high SNR regimes. In
this paper error rate analyses that are sufficiently accurate over a wide range
of SNR regimes are provided. The motivations for this work are that practical
systems operate at far lower SNR values than those supported by the high SNR
analysis. To enable designers to make informed decisions regarding network
design and deployment, it is imperative that system performance is evaluated
with a reasonable degree of accuracy over practical SNR regimes. Simulations
have been used to corroborate the analytical results, as close agreement
between the two is observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2859</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2859</id><created>2008-07-17</created><authors><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>The Transport Capacity of a Wireless Network is a Subadditive Euclidean
  Functional</title><categories>cs.IT math.IT</categories><doi>10.1239/jap/1285335416</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transport capacity of a dense ad hoc network with n nodes scales like
\sqrt(n). We show that the transport capacity divided by \sqrt(n) approaches a
non-random limit with probability one when the nodes are i.i.d. distributed on
the unit square. We prove that the transport capacity under the protocol model
is a subadditive Euclidean functional and use the machinery of subadditive
functions in the spirit of Steele to show the existence of the limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2928</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2928</id><created>2008-07-18</created><authors><author><keyname>Yu</keyname><forenames>Guoshen</forenames></author><author><keyname>Slotine</keyname><forenames>Jean-Jacques</forenames></author></authors><title>Visual Grouping by Neural Oscillators</title><categories>cs.CV cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed synchronization is known to occur at several scales in the brain,
and has been suggested as playing a key functional role in perceptual grouping.
State-of-the-art visual grouping algorithms, however, seem to give
comparatively little attention to neural synchronization analogies. Based on
the framework of concurrent synchronization of dynamic systems, simple networks
of neural oscillators coupled with diffusive connections are proposed to solve
visual grouping problems. Multi-layer algorithms and feedback mechanisms are
also studied. The same algorithm is shown to achieve promising results on
several classical visual grouping problems, including point clustering, contour
integration and image segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2961</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2961</id><created>2008-07-18</created><authors><author><keyname>Goubault</keyname><forenames>Eric</forenames></author><author><keyname>Putot</keyname><forenames>Sylvie</forenames></author></authors><title>Perturbed affine arithmetic for invariant computation in numerical
  program analysis</title><categories>cs.LO cs.NA</categories><comments>12 pages in two-column style</comments><acm-class>D.2.4; F.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We completely describe a new domain for abstract interpretation of numerical
programs. Fixpoint iteration in this domain is proved to converge to finite
precise invariants for (at least) the class of stable linear recursive filters
of any order. Good evidence shows it behaves well also for some non-linear
schemes. The result, and the structure of the domain, rely on an interesting
interplay between order and topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2972</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2972</id><created>2008-07-18</created><authors><author><keyname>Rizzolo</keyname><forenames>Flavio</forenames></author></authors><title>DescribeX: A Framework for Exploring and Querying XML Web Collections</title><categories>cs.DB</categories><comments>PhD thesis, University of Toronto, 2008, 163 pages</comments><acm-class>H.2.5; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis introduces DescribeX, a powerful framework that is capable of
describing arbitrarily complex XML summaries of web collections, providing
support for more efficient evaluation of XPath workloads. DescribeX permits the
declarative description of document structure using all axes and language
constructs in XPath, and generalizes many of the XML indexing and summarization
approaches in the literature. DescribeX supports the construction of
heterogeneous summaries where different document elements sharing a common
structure can be declaratively defined and refined by means of path regular
expressions on axes, or axis path regular expression (AxPREs). DescribeX can
significantly help in the understanding of both the structure of complex,
heterogeneous XML collections and the behaviour of XPath queries evaluated on
them.
  Experimental results demonstrate the scalability of DescribeX summary
refinements and stabilizations (the key enablers for tailoring summaries) with
multi-gigabyte web collections. A comparative study suggests that using a
DescribeX summary created from a given workload can produce query evaluation
times orders of magnitude better than using existing summaries. DescribeX's
light-weight approach of combining summaries with a file-at-a-time XPath
processor can be a very competitive alternative, in terms of performance, to
conventional fully-fledged XML query engines that provide DB-like functionality
such as security, transaction processing, and native storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2983</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2983</id><created>2008-07-18</created><authors><author><keyname>Denis</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIF</affiliation></author><author><keyname>Habrard</keyname><forenames>Amaury</forenames><affiliation>LIF</affiliation></author><author><keyname>Gilleron</keyname><forenames>R&#xe9;mi</forenames><affiliation>LIFL, INRIA Futurs</affiliation></author><author><keyname>Tommasi</keyname><forenames>Marc</forenames><affiliation>LIFL, INRIA Futurs, GRAPPA</affiliation></author><author><keyname>Gilbert</keyname><forenames>&#xc9;douard</forenames><affiliation>INRIA Futurs</affiliation></author></authors><title>On Probability Distributions for Trees: Representations, Inference and
  Learning</title><categories>cs.LG</categories><proxy>ccsd inria-00294636</proxy><journal-ref>Dans NIPS Workshop on Representations and Inference on Probability
  Distributions (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study probability distributions over free algebras of trees. Probability
distributions can be seen as particular (formal power) tree series [Berstel et
al 82, Esik et al 03], i.e. mappings from trees to a semiring K . A widely
studied class of tree series is the class of rational (or recognizable) tree
series which can be defined either in an algebraic way or by means of
multiplicity tree automata. We argue that the algebraic representation is very
convenient to model probability distributions over a free algebra of trees.
First, as in the string case, the algebraic representation allows to design
learning algorithms for the whole class of probability distributions defined by
rational tree series. Note that learning algorithms for rational tree series
correspond to learning algorithms for weighted tree automata where both the
structure and the weights are learned. Second, the algebraic representation can
be easily extended to deal with unranked trees (like XML trees where a symbol
may have an unbounded number of children). Both properties are particularly
relevant for applications: nondeterministic automata are required for the
inference problem to be relevant (recall that Hidden Markov Models are
equivalent to nondeterministic string automata); nowadays applications for Web
Information Extraction, Web Services and document processing consider unranked
trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2993</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2993</id><created>2008-07-18</created><authors><author><keyname>Cleere</keyname><forenames>Garry</forenames></author></authors><title>Establishing and Measuring Standard Spreadsheet Practices for End-Users</title><categories>cs.HC</categories><comments>15 Pages, 5 Tables, 9 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 1-15
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper offers a brief review of cognitive verbs typically used in the
literature to describe standard spreadsheet practices. The verbs identified are
then categorised in terms of Bloom's Taxonomy of Hierarchical Levels, and then
rated and arranged to distinguish some of their qualities and characteristics.
Some measurement items are then evaluated to see how well computerised test
question items validate or reinforce training or certification. The paper
considers how establishing standard practices in spreadsheet training and
certification can help reduce some of the risks associated with spreadsheets,
and help promote productivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2997</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2997</id><created>2008-07-18</created><authors><author><keyname>Bekenn</keyname><forenames>Bill</forenames></author><author><keyname>Hooper</keyname><forenames>Ray</forenames></author></authors><title>Reducing Spreadsheet Risk with FormulaDataSleuth</title><categories>cs.HC cs.SE</categories><comments>10 pages, 12 colour figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 33-44
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new MS Excel application has been developed which seeks to reduce the risks
associated with the development, operation and auditing of Excel spreadsheets.
FormulaDataSleuth provides a means of checking spreadsheet formulas and data as
they are developed or used, enabling the users to identify actual or potential
errors quickly and thereby halt their propagation. In this paper, we will
describe, with examples, how the application works and how it can be applied to
reduce the risks associated with Excel spreadsheets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3006</identifier>
 <datestamp>2008-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3006</id><created>2008-07-18</created><authors><author><keyname>Peserico</keyname><forenames>Enoch</forenames></author><author><keyname>Pretto</keyname><forenames>Luca</forenames></author></authors><title>The rank convergence of HITS can be slow</title><categories>cs.DS cs.IR</categories><comments>5 pages, 1 figure. Keywords: algorithm analysis, information
  retrieval, rank convergence</comments><acm-class>F.2.2; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that HITS, to &quot;get right&quot; h of the top k ranked nodes of an N&gt;=2k
node graph, can require h^(Omega(N h/k)) iterations (i.e. a substantial Omega(N
h log(h)/k) matrix multiplications even with a &quot;squaring trick&quot;). Our proof
requires no algebraic tools and is entirely self-contained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3026</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3026</id><created>2008-07-18</created><updated>2008-11-08</updated><authors><author><keyname>Williams</keyname><forenames>Ryan</forenames></author></authors><title>Finding paths of length k in O*(2^k) time</title><categories>cs.DS cs.DM</categories><comments>7 pages. Revised version to appear in Information Processing Letters</comments><journal-ref>Information Processing Letters, 109(6):315--318, February 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a randomized algorithm that determines if a given graph has a simple
path of length at least k in O(2^k poly(n,k)) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3050</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3050</id><created>2008-07-18</created><authors><author><keyname>Zheng</keyname><forenames>Haipeng</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Dimensionally Distributed Learning: Models and Algorithm</title><categories>cs.IT math.IT</categories><comments>Proceedings of the Eleventh International Conference on Information
  Fusion, Cologne, Germany, June 30 - July 3, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a framework for regression with dimensionally
distributed data with a fusion center. A cooperative learning algorithm, the
iterative conditional expectation algorithm (ICEA), is designed within this
framework. The algorithm can effectively discover linear combinations of
individual estimators trained by each agent without transferring and storing
large amount of data amongst the agents and the fusion center. The convergence
of ICEA is explored. Specifically, for a two agent system, each complete round
of ICEA is guaranteed to be a non-expansive map on the function space of each
agent. The advantages and limitations of ICEA are also discussed for data sets
with various distributions and various hidden rules. Moreover, several
techniques are also designed to leverage the algorithm to effectively learn
more complex hidden rules that are not linearly decomposable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3065</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3065</id><created>2008-07-19</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author></authors><title>Sharp Bounds for Optimal Decoding of Low Density Parity Check Codes</title><categories>cs.IT math.IT</categories><comments>40 Pages, Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider communication over a binary-input memoryless output-symmetric
channel with low density parity check (LDPC) codes and maximum a posteriori
(MAP) decoding. The replica method of spin glass theory allows to conjecture an
analytic formula for the average input-output conditional entropy per bit in
the infinite block length limit. Montanari proved a lower bound for this
entropy, in the case of LDPC ensembles with convex check degree polynomial,
which matches the replica formula. Here we extend this lower bound to any
irregular LDPC ensemble. The new feature of our work is an analysis of the
second derivative of the conditional input-output entropy with respect to
noise. A close relation arises between this second derivative and correlation
or mutual information of codebits. This allows us to extend the realm of the
interpolation method, in particular we show how channel symmetry allows to
control the fluctuations of the overlap parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3094</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3094</id><created>2008-07-19</created><authors><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Saturnino</keyname><forenames>Daniela</forenames></author></authors><title>Energy-Efficient Resource Allocation in Multiuser MIMO Systems: A
  Game-Theoretic Framework</title><categories>cs.IT cs.GT math.IT</categories><comments>Proceedings of the 16th European Signal Processing Conference,
  Lausanne, Switzerland, August 25-29, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the cross-layer issue of resource allocation for energy
efficiency in the uplink of a multiuser MIMO wireless communication system.
Assuming that all of the transmitters and the uplink receiver are equipped with
multiple antennas, the situation considered is that in which each terminal is
allowed to vary its transmit power, beamforming vector, and uplink receiver in
order to maximize its own utility, which is defined as the ratio of data
throughput to transmit power; the case in which non-linear interference
cancellation is used at the receiver is also investigated. Applying a
game-theoretic formulation, several non-cooperative games for utility
maximization are thus formulated, and their performance is compared in terms of
achieved average utility, achieved average SINR and average transmit power at
the Nash equilibrium. Numerical results show that the use of the proposed
cross-layer resource allocation policies brings remarkable advantages to the
network performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3096</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3096</id><created>2008-07-19</created><updated>2011-02-22</updated><authors><author><keyname>Guatteri</keyname><forenames>Giuseppina</forenames></author></authors><title>Stochastic Maximum Principle for a PDEs with noise and control on the
  boundary</title><categories>math.PR cs.SY math.OC</categories><comments>15pgs</comments><msc-class>60H15, 90C46, 93E03, 93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove necessary conditions for optimality of a stochastic
control problem for a class of stochastic partial differential equations that
is controlled through the boundary. This kind of problems can be interpreted as
a stochastic control problem for an evolution system in an Hilbert space. The
regularity of the solution of the adjoint equation, that is a backward
stochastic equation in infinite dimension, plays a crucial role in the
formulation of the maximum principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3097</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3097</id><created>2008-07-19</created><authors><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Massaro</keyname><forenames>Valeria</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Energy-Efficient Power Control in Multipath CDMA Channels via Large
  System Analysis</title><categories>cs.IT cs.GT math.IT</categories><comments>Proceedings of the IEEE International Symposium on Personal, Indoor
  and Mobile Radio Communications, Cannes, France, September 15-18, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is focused on the design and analysis of power control procedures
for the uplink of multipath code-division-multiple-access (CDMA) channels based
on the large system analysis (LSA). Using the tools of LSA, a new decentralized
power control algorithm aimed at energy efficiency maximization and requiring
very little prior information on the interference background is proposed;
moreover, it is also shown that LSA can be used to predict with good accuracy
the performance and operational conditions of a large network operating at the
equilibrium over a multipath channel, i.e. the power,
signal-to-interference-plus-noise ratio (SINR) and utility profiles across
users, wherein the utility is defined as the number of bits reliably delivered
to the receiver for each energy-unit used for transmission. Additionally, an
LSA-based performance comparison among linear receivers is carried out in terms
of achieved energy efficiency at the equilibrium. Finally, the problem of the
choice of the utility-maximizing training length is also considered. Numerical
results show a very satisfactory agreement of the theoretical analysis with
simulation results obtained with reference to systems with finite (and not so
large) numbers of users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3156</identifier>
 <datestamp>2008-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3156</id><created>2008-07-21</created><updated>2008-11-28</updated><authors><author><keyname>Muchnik</keyname><forenames>Andrej</forenames></author></authors><title>Algorithmic randomness and splitting of supermartingales</title><categories>cs.IT math.IT</categories><comments>The same text in English (13 pages) and in Russian (14 pages).
  Journal version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomness in the sense of Martin-L\&quot;of can be defined in terms of lower
semicomputable supermartingales. We show that such a supermartingale cannot be
replaced by a pair of supermartingales that bet only on the even bits (the
first one) and on the odd bits (the second one) knowing all preceding bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3168</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3168</id><created>2008-07-20</created><authors><author><keyname>Nash</keyname><forenames>John C.</forenames></author><author><keyname>Smith</keyname><forenames>Neil</forenames></author><author><keyname>Adler</keyname><forenames>Andy</forenames></author></authors><title>Audit and Change Analysis of Spreadsheets</title><categories>cs.HC cs.SE</categories><comments>10 pages, 3 figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 81-90
  ISBN 1 86166 199 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because spreadsheets have a large and growing importance in real-world work,
their contents need to be controlled and validated. Generally spreadsheets have
been difficult to verify, since data and executable information are stored
together. Spreadsheet applications with multiple authors are especially
difficult to verify, since controls over access are difficult to enforce.
Facing similar problems, traditional software engineering has developed
numerous tools and methodologies to control, verify and audit large
applications with multiple developers. We present some tools we have developed
to enable 1) the audit of selected, filtered, or all changes in a spreadsheet,
that is, when a cell was changed, its original and new contents and who made
the change, and 2) control of access to the spreadsheet file(s) so that
auditing is trustworthy. Our tools apply to OpenOffice.org calc spreadsheets,
which can generally be exchanged with Microsoft Excel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3183</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3183</id><created>2008-07-20</created><authors><author><keyname>Grossman</keyname><forenames>Thomas A.</forenames></author></authors><title>Accuracy in Spreadsheet Modelling Systems</title><categories>cs.HC cs.SE</categories><comments>12 pages, 5 figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 91-97
  ISBN 1 86166 199 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accuracy in spreadsheet modelling systems can be reduced due to difficulties
with the inputs, the model itself, or the spreadsheet implementation of the
model. When the &quot;true&quot; outputs from the system are unknowable, accuracy is
evaluated subjectively. Less than perfect accuracy can be acceptable depending
on the purpose of the model, problems with inputs, or resource constraints.
Users build modelling systems iteratively, and choose to allocate limited
resources to the inputs, the model, the spreadsheet implementation, and to
employing the system for business analysis. When making these choices, users
can suffer from expectation bias and diagnosis bias. Existing research results
tend to focus on errors in the spreadsheet implementation. Because industry has
tolerance for system inaccuracy, errors in spreadsheet implementations may not
be a serious concern. Spreadsheet productivity may be of more interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3184</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3184</id><created>2008-07-20</created><authors><author><keyname>Grossman</keyname><forenames>Thomas A.</forenames></author><author><keyname>Ozluk</keyname><forenames>Ozgur</forenames></author></authors><title>Research Strategy and Scoping Survey on Spreadsheet Practices</title><categories>cs.HC</categories><comments>10 pages, 2 figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 23-32
  ISBN 1 86166 199 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a research strategy for creating and deploying prescriptive
recommendations for spreadsheet practice. Empirical data on usage can be used
to create a taxonomy of spreadsheet classes. Within each class, existing
practices and ideal practices can he combined into proposed best practices for
deployment. As a first step we propose a scoping survey to gather non-anecdotal
data on spreadsheet usage. The scoping survey will interview people who develop
spreadsheets. We will investigate the determinants of spreadsheet importance,
identify current industry practices, and document existing standards for
creation and use of spreadsheets. The survey will provide insight into user
attributes, spreadsheet importance, and current practices. Results will be
valuable in themselves, and will guide future empirical research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3186</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3186</id><created>2008-07-20</created><authors><author><keyname>Raffensperger</keyname><forenames>John F.</forenames></author></authors><title>New Guidelines For Spreadsheets</title><categories>cs.HC</categories><comments>16 pages, 5 figures, 1 table</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2001 61-76
  ISBN:1 86166 179 7</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current prescriptions for spreadsheet style specify modular separation of
data, calcu1ation and output, based on the notion that writing a spreadsheet is
like writing a computer program. Instead of a computer programming style, this
article examines rules of style for text, graphics, and mathematics. Much
'common wisdom' in spreadsheets contradicts rules for these well-developed
arts. A case is made here for a new style for spreadsheets that emphasises
readability. The new style is described in detail with an example, and
contrasted with the programming style.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3187</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3187</id><created>2008-07-20</created><authors><author><keyname>Pryor</keyname><forenames>Louise</forenames></author></authors><title>When, why and how to test spreadsheets</title><categories>cs.SE</categories><comments>7 pages, 5 colour figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2004 145-151
  ISBN 1 902724 94 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Testing is a vital part of software development, and spreadsheets are like
any other software in this respect. This paper discusses the testing of
spreadsheets in the light of one practitioner's experience. It considers the
concept of software testing and how it differs from reviewing, and describes
when it might take place. Different types of testing are described, and some
techniques for performing them presented. Some of the commonly encountered
problems are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3198</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3198</id><created>2008-07-20</created><authors><author><keyname>Carvalho</keyname><forenames>Cicero</forenames></author><author><keyname>Silva</keyname><forenames>Ercilio</forenames></author></authors><title>On algebras admitting a complete set of near weights, evaluation codes
  and Goppa codes</title><categories>cs.IT math.IT</categories><comments>17 pages</comments><acm-class>H.1.1; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1998 Hoholdt, van Lint and Pellikaan introduced the concept of a ``weight
function'' defined on a F_q-algebra and used it to construct linear codes,
obtaining among them the algebraic-geometric (AG) codes supported on one point.
Later it was proved by Matsumoto that all codes produced using a weight
function are actually AG codes supported on one point. Recently, ``near weight
functions'' (a generalization of weight functions), also defined on a
F_q-algebra, were introduced to study codes supported on two points. In this
paper we show that an algebra admits a set of m near weight functions having a
compatibility property, namely, the set is a ``complete set'', if and only if
it is the ring of regular functions of an affine geometrically irreducible
algebraic curve defined over F_q whose points at infinity have a total of m
rational branches. Then the codes produced using the near weight functions are
exactly the AG codes supported on m points. A formula for the minimum distance
of these codes is presented with examples which show that in some situations it
compares better than the usual Goppa bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3212</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3212</id><created>2008-07-21</created><authors><author><keyname>Kohnert</keyname><forenames>Axel</forenames></author><author><keyname>Kurz</keyname><forenames>Sascha</forenames></author></authors><title>Construction of Large Constant Dimension Codes With a Prescribed Minimum
  Distance</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>13 pages, 1 figure, 1 table, submitted</comments><journal-ref>Lecture Notes Computer Science Vol. 5393, 2008, p. 31 - 42</journal-ref><doi>10.1007/978-3-540-89994-5_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we construct constant dimension space codes with prescribed
minimum distance. There is an increased interest in space codes since a paper
by Koetter and Kschischang were they gave an application in network coding.
There is also a connection to the theory of designs over finite fields. We will
modify a method of Braun, Kerber and Laue which they used for the construction
of designs over finite fields to do the construction of space codes. Using this
approach we found many new constant dimension spaces codes with a larger number
of codewords than previously known codes. We will finally give a table of the
best found constant dimension space codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3222</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3222</id><created>2008-07-21</created><authors><author><keyname>Bresler</keyname><forenames>Guy</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>The two-user Gaussian interference channel: a deterministic view</title><categories>cs.IT math.IT</categories><comments>34 pages, 20 figures</comments><journal-ref>Draft of version in Euro. Trans. Telecomm., Volume 19, Issue 4,
  pp. 333-354, June 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the two-user Gaussian interference channel through the
lens of a natural deterministic channel model. The main result is that the
deterministic channel uniformly approximates the Gaussian channel, the capacity
regions differing by a universal constant. The problem of finding the capacity
of the Gaussian channel to within a constant error is therefore reduced to that
of finding the capacity of the far simpler deterministic channel. Thus, the
paper provides an alternative derivation of the recent constant gap capacity
characterization of Etkin, Tse, and Wang. Additionally, the deterministic model
gives significant insight towards the Gaussian channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3223</identifier>
 <datestamp>2008-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3223</id><created>2008-07-21</created><updated>2008-09-21</updated><authors><author><keyname>Gouaillier</keyname><forenames>David</forenames></author><author><keyname>Hugel</keyname><forenames>Vincent</forenames></author><author><keyname>Blazevic</keyname><forenames>Pierre</forenames></author><author><keyname>Kilner</keyname><forenames>Chris</forenames></author><author><keyname>Monceaux</keyname><forenames>Jerome</forenames></author><author><keyname>Lafourcade</keyname><forenames>Pascal</forenames></author><author><keyname>Marnier</keyname><forenames>Brice</forenames></author><author><keyname>Serre</keyname><forenames>Julien</forenames></author><author><keyname>Maisonnier</keyname><forenames>Bruno</forenames></author></authors><title>The NAO humanoid: a combination of performance and affordability</title><categories>cs.RO</categories><comments>This paper has been withdrawn by the author(s) for revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents the design of the autonomous humanoid robot called NAO
that is built by the French company Aldebaran-Robotics. With its height of 0.57
m and its weight about 4.5 kg, this innovative robot is lightweight and
compact. It distinguishes itself from its existing Japanese, American, and
other counterparts thanks to its pelvis kinematics design, its proprietary
actuation system based on brush DC motors, its electronic, computer and
distributed software architectures. This robot has been designed to be
affordable without sacrificing quality and performance. It is an open and
easy-to-handle platform where the user can change all the embedded system
software or just add some applications to make the robot adopt specific
behaviours. The robot's head and forearms are modular and can be changed to
promote further evolution. The comprehensive and functional design is one of
the reasons that helped select NAO to replace the AIBO quadrupeds in the 2008
RoboCup standard league.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3225</identifier>
 <datestamp>2008-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3225</id><created>2008-07-21</created><updated>2008-09-21</updated><authors><author><keyname>Hugel</keyname><forenames>Vincent</forenames></author><author><keyname>Hackert</keyname><forenames>Remi</forenames></author><author><keyname>Abourachid</keyname><forenames>Anick</forenames></author></authors><title>Exploiting Bird Locomotion Kinematics Data for Robotics Modeling</title><categories>cs.RO</categories><comments>This paper has been withdrawn by the author(s) for revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here the results of an analysis carried out by biologists and
roboticists with the aim of modeling bird locomotion kinematics for robotics
purposes. The aim was to develop a bio-inspired kinematic model of the bird leg
from biological data. We first acquired and processed kinematic data for
sagittal and top views obtained by X-ray radiography of quails walking. Data
processing involved filtering and specific data reconstruction in three
dimensions, as two-dimensional views cannot be synchronized. We then designed a
robotic model of a bird-like leg based on a kinematic analysis of the
biological data. Angular velocity vectors were calculated to define the number
of degrees of freedom (DOF) at each joint and the orientation of the rotation
axes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3277</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3277</id><created>2008-07-21</created><authors><author><keyname>Martin</keyname><forenames>Bruno</forenames><affiliation>I3S</affiliation></author></authors><title>Another Co*cryption Method</title><categories>cs.CR</categories><proxy>ccsd hal-00301817</proxy><acm-class>F.1.1; E.3</acm-class><journal-ref>International Conference on Science and Technology (JICT), Malaga
  : Espagne (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the enciphering of a data stream while being compressed by a LZ
algorithm. This has to be compared to the classical encryption after
compression methods used in security protocols. Actually, most cryptanalysis
techniques exploit patterns found in the plaintext to crack the cipher;
compression techniques reduce these attacks. Our scheme is based on a LZ
compression in which a Vernam cipher has been added. We make some security
remarks by trying to measure its randomness with statistical tests. Such a
scheme could be employed to increase the speed of security protocols and to
decrease the computing power for mobile devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3287</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3287</id><created>2008-07-21</created><authors><author><keyname>Wollbold</keyname><forenames>Johannes</forenames></author><author><keyname>Guthke</keyname><forenames>Reinhard</forenames></author><author><keyname>Ganter</keyname><forenames>Bernhard</forenames></author></authors><title>Constructing a Knowledge Base for Gene Regulatory Dynamics by Formal
  Concept Analysis Methods</title><categories>q-bio.MN cs.AI math.LO</categories><comments>15 pages, 1 figure, LaTeX style llncsdoc.sty</comments><journal-ref>K. Horimoto et al. (Eds.): AB 2008, LNCS 5147. Springer,
  Heidelberg 2008, pp. 230-244</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our aim is to build a set of rules, such that reasoning over temporal
dependencies within gene regulatory networks is possible. The underlying
transitions may be obtained by discretizing observed time series, or they are
generated based on existing knowledge, e.g. by Boolean networks or their
nondeterministic generalization. We use the mathematical discipline of formal
concept analysis (FCA), which has been applied successfully in domains as
knowledge representation, data mining or software engineering. By the attribute
exploration algorithm, an expert or a supporting computer program is enabled to
decide about the validity of a minimal set of implications and thus to
construct a sound and complete knowledge base. From this all valid implications
are derivable that relate to the selected properties of a set of genes. We
present results of our method for the initiation of sporulation in Bacillus
subtilis. However the formal structures are exhibited in a most general manner.
Therefore the approach may be adapted to signal transduction or metabolic
networks, as well as to discrete temporal transitions in many biological and
nonbiological areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3326</identifier>
 <datestamp>2008-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3326</id><created>2008-07-21</created><authors><author><keyname>Gonen</keyname><forenames>Mira</forenames></author><author><keyname>Shavitt</keyname><forenames>Yuval</forenames></author></authors><title>An $O(\log n)$-approximation for the Set Cover Problem with Set
  Ownership</title><categories>cs.NI cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In highly distributed Internet measurement systems distributed agents
periodically measure the Internet using a tool called {\tt traceroute}, which
discovers a path in the network graph. Each agent performs many traceroute
measurement to a set of destinations in the network, and thus reveals a portion
of the Internet graph as it is seen from the agent locations. In every period
we need to check whether previously discovered edges still exist in this
period, a process termed {\em validation}. For this end we maintain a database
of all the different measurements performed by each agent. Our aim is to be
able to {\em validate} the existence of all previously discovered edges in the
minimum possible time. In this work we formulate the validation problem as a
generalization of the well know set cover problem. We reduce the set cover
problem to the validation problem, thus proving that the validation problem is
${\cal NP}$-hard. We present a $O(\log n)$-approximation algorithm to the
validation problem, where $n$ in the number of edges that need to be validated.
We also show that unless ${\cal P = NP}$ the approximation ratio of the
validation problem is $\Omega(\log n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3332</identifier>
 <datestamp>2008-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3332</id><created>2008-07-21</created><authors><author><keyname>Lee</keyname><forenames>Juyul</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Energy-efficient Scheduling of Delay Constrained Traffic over Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>16 pages, 7 figures, Submitted to IEEE Transations on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A delay-constrained scheduling problem for point-to-point communication is
considered: a packet of $B$ bits must be transmitted by a hard deadline of $T$
slots over a time-varying channel. The transmitter/scheduler must determine how
many bits to transmit, or equivalently how much energy to transmit with, during
each time slot based on the current channel quality and the number of unserved
bits, with the objective of minimizing expected total energy. In order to focus
on the fundamental scheduling problem, it is assumed that no other packets are
scheduled during this time period and no outage is allowed. Assuming
transmission at capacity of the underlying Gaussian noise channel, a
closed-form expression for the optimal scheduling policy is obtained for the
case T=2 via dynamic programming; for $T&gt;2$, the optimal policy can only be
numerically determined. Thus, the focus of the work is on derivation of simple,
near-optimal policies based on intuition from the T=2 solution and the
structure of the general problem. The proposed bit-allocation policies consist
of a linear combination of a delay-associated term and an opportunistic
(channel-aware) term. In addition, a variation of the problem in which the
entire packet must be transmitted in a single slot is studied, and a
channel-threshold policy is shown to be optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3337</identifier>
 <datestamp>2008-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3337</id><created>2008-07-21</created><authors><author><keyname>Hurley</keyname><forenames>Ted</forenames></author><author><keyname>McEvoy</keyname><forenames>Paul</forenames></author><author><keyname>Wenus</keyname><forenames>Jakub</forenames></author></authors><title>Algebraic constructions of LDPC codes with no short cycles</title><categories>math.RA cs.IT math.IT</categories><comments>13 pages, 8 figures in pdf format</comments><msc-class>94B60, 16S34</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algebraic group ring method for constructing codes with no short cycles in
the check matrix is derived. It is shown that the matrix of a group ring
element has no short cycles if and only if the collection of group differences
of this element has no repeats. When applied to elements in the group ring with
small support this gives a general method for constructing and analysing low
density parity check (LDPC) codes with no short cycles from group rings.
Examples of LDPC codes with no short cycles are constructed from group ring
elements and these are simulated and compared with known LDPC codes, including
those adopted for wireless standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3374</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3374</id><created>2008-07-21</created><updated>2010-09-05</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>The Dynamics of Internet Traffic: Self-Similarity, Self-Organization,
  and Complex Phenomena</title><categories>nlin.AO cs.NI nlin.CD</categories><comments>63 pages, 7 figures, 7 tables, submitted to Advances in Complex
  Systems</comments><journal-ref>Advances in Complex Systems, 14, 6 p. 905-949 (2011)</journal-ref><doi>10.1142/S0219525911003451</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Internet is the most complex system ever created in human history.
Therefore, its dynamics and traffic unsurprisingly take on a rich variety of
complex dynamics, self-organization, and other phenomena that have been
researched for years. This paper is a review of the complex dynamics of
Internet traffic. Departing from normal treatises, we will take a view from
both the network engineering and physics perspectives showing the strengths and
weaknesses as well as insights of both. In addition, many less covered
phenomena such as traffic oscillations, large-scale effects of worm traffic,
and comparisons of the Internet and biological models will be covered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3383</identifier>
 <datestamp>2009-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3383</id><created>2008-07-22</created><updated>2008-07-28</updated><authors><author><keyname>Li</keyname><forenames>An-Ping</forenames></author></authors><title>Recover plaintext attack to block ciphers</title><categories>cs.CR</categories><comments>there is a remark added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  we will present an estimation for the upper-bound of the amount of 16-bytes
plaintexts for English texts, which indicates that the block ciphers with block
length no more than 16-bytes will be subject to recover plaintext attacks in
the occasions of plaintext -known or plaintext-chosen attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3387</identifier>
 <datestamp>2008-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3387</id><created>2008-07-22</created><authors><author><keyname>Sumner</keyname><forenames>J. G.</forenames></author><author><keyname>Charleston</keyname><forenames>M. A.</forenames></author></authors><title>Phylogenetic estimation with partial likelihood tensors</title><categories>q-bio.QM cs.DS q-bio.PE</categories><comments>20 pages, 7 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an alternative method for calculating likelihoods in molecular
phylogenetics. Our method is based on partial likelihood tensors, which are
generalizations of partial likelihood vectors, as used in Felsenstein's
approach. Exploiting a lexicographic sorting and partial likelihood tensors, it
is possible to obtain significant computational savings. We show this on a
range of simulated data by enumerating all numerical calculations that are
required by our method and the standard approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3396</identifier>
 <datestamp>2008-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3396</id><created>2008-07-22</created><authors><author><keyname>Sivaramakrishnan</keyname><forenames>Kamakshi</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Universal Denoising of Discrete-time Continuous-Amplitude Signals</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>56 pages</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of reconstructing a discrete-time signal (sequence)
with continuous-valued components corrupted by a known memoryless channel. When
performance is measured using a per-symbol loss function satisfying mild
regularity conditions, we develop a sequence of denoisers that, although
independent of the distribution of the underlying `clean' sequence, is
universally optimal in the limit of large sequence length. This sequence of
denoisers is universal in the sense of performing as well as any sliding window
denoising scheme which may be optimized for the underlying clean signal. Our
results are initially developed in a ``semi-stochastic'' setting, where the
noiseless signal is an unknown individual sequence, and the only source of
randomness is due to the channel noise. It is subsequently shown that in the
fully stochastic setting, where the noiseless sequence is a stationary
stochastic process, our schemes universally attain optimum performance. The
proposed schemes draw from nonparametric density estimation techniques and are
practically implementable. We demonstrate efficacy of the proposed schemes in
denoising gray-scale images in the conventional additive white Gaussian noise
setting, with additional promising results for less conventional noise
distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3427</identifier>
 <datestamp>2008-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3427</id><created>2008-07-22</created><authors><author><keyname>Christodoulou</keyname><forenames>George</forenames><affiliation>Max-Planck-Institut f&#xfc;r Informatik, Saarbr&#xfc;cken, Germany</affiliation></author><author><keyname>Koutsoupias</keyname><forenames>Elias</forenames><affiliation>Department of Informatics, University of Athens</affiliation></author><author><keyname>Vidali</keyname><forenames>Angelina</forenames><affiliation>Department of Informatics, University of Athens</affiliation></author></authors><title>A characterization of 2-player mechanisms for scheduling</title><categories>cs.GT</categories><comments>20 pages, 4 figures, ESA'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the mechanism design problem of scheduling unrelated machines and we
completely characterize the decisive truthful mechanisms for two players when
the domain contains both positive and negative values. We show that the class
of truthful mechanisms is very limited: A decisive truthful mechanism
partitions the tasks into groups so that the tasks in each group are allocated
independently of the other groups. Tasks in a group of size at least two are
allocated by an affine minimizer and tasks in singleton groups by a
task-independent mechanism. This characterization is about all truthful
mechanisms, including those with unbounded approximation ratio.
  A direct consequence of this approach is that the approximation ratio of
mechanisms for two players is 2, even for two tasks. In fact, it follows that
for two players, VCG is the unique algorithm with optimal approximation 2.
  This characterization provides some support that any decisive truthful
mechanism (for 3 or more players) partitions the tasks into groups some of
which are allocated by affine minimizers, while the rest are allocated by a
threshold mechanism (in which a task is allocated to a player when it is below
a threshold value which depends only on the values of the other players). We
also show here that the class of threshold mechanisms is identical to the class
of additive mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3451</identifier>
 <datestamp>2009-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3451</id><created>2008-07-22</created><updated>2009-01-10</updated><authors><author><keyname>Payet</keyname><forenames>Etienne</forenames></author><author><keyname>Mesnard</keyname><forenames>Fred</forenames></author></authors><title>A Non-Termination Criterion for Binary Constraint Logic Programs</title><categories>cs.PL</categories><comments>32 pages. Long version of a paper accepted for publication in Theory
  and Practice of Logic Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On the one hand, termination analysis of logic programs is now a fairly
established research topic within the logic programming community. On the other
hand, non-termination analysis seems to remain a much less attractive subject.
If we divide this line of research into two kinds of approaches: dynamic versus
static analysis, this paper belongs to the latter. It proposes a criterion for
detecting non-terminating atomic queries with respect to binary CLP rules,
which strictly generalizes our previous works on this subject. We give a
generic operational definition and an implemented logical form of this
criterion. Then we show that the logical form is correct and complete with
respect to the operational definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3483</identifier>
 <datestamp>2008-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3483</id><created>2008-07-22</created><authors><author><keyname>Martin</keyname><forenames>Arnaud</forenames><affiliation>E3I2</affiliation></author></authors><title>Implementing general belief function framework with a practical
  codification for low complexity</title><categories>cs.AI</categories><comments>Advances and Applications of DSmT for Information Fusion, Florentin
  Smarandache &amp; Jean Dezert (Ed.) (2008) Pnd</comments><proxy>ccsd hal-00304125</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter, we propose a new practical codification of the elements of
the Venn diagram in order to easily manipulate the focal elements. In order to
reduce the complexity, the eventual constraints must be integrated in the
codification at the beginning. Hence, we only consider a reduced hyper power
set $D_r^\Theta$ that can be $2^\Theta$ or $D^\Theta$. We describe all the
steps of a general belief function framework. The step of decision is
particularly studied, indeed, when we can decide on intersections of the
singletons of the discernment space no actual decision functions are easily to
use. Hence, two approaches are proposed, an extension of previous one and an
approach based on the specificity of the elements on which to decide. The
principal goal of this chapter is to provide practical codes of a general
belief function framework for the researchers and users needing the belief
function theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3566</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3566</id><created>2008-07-22</created><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Stabilizer Quantum Codes: A Unified View based on Forney-style Factor
  Graphs</title><categories>quant-ph cs.IT math.IT</categories><comments>Proceedings 5th International Symposium on Turbo Codes and Related
  Topics, Lausanne, Switzerland, September 1-5, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum error-correction codes (QECCs) are a vital ingredient of quantum
computation and communication systems. In that context it is highly desirable
to design QECCs that can be represented by graphical models which possess a
structure that enables efficient and close-to-optimal iterative decoding. In
this paper we focus on stabilizer QECCs, a class of QECCs whose construction is
rendered non-trivial by the fact that the stabilizer label code, a code that is
associated with a stabilizer QECC, has to satisfy a certain self-orthogonality
condition. In order to design graphical models of stabilizer label codes that
satisfy this condition, we extend a duality result for Forney-style factor
graphs (FFGs) to the stabilizer label code framework. This allows us to
formulate a simple FFG design rule for constructing stabilizer label codes, a
design rule that unifies several earlier stabilizer label code constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3574</identifier>
 <datestamp>2008-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3574</id><created>2008-07-22</created><updated>2008-12-17</updated><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Mode Switching for MIMO Communication Based on Delay and Channel
  Quantization</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author as a major revision is made and a
new version is uploaded at arXiv:0812.3120
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3582</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3582</id><created>2008-07-22</created><authors><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Nguyen</keyname><forenames>Dung Viet</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Marcellin</keyname><forenames>Michael W.</forenames></author></authors><title>Error Correction Capability of Column-Weight-Three LDPC Codes: Part II</title><categories>cs.IT math.IT</categories><comments>7 pages, 7 figures, submitted to IEEE Transactions on Information
  Theory (July 2008)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relation between the girth and the error correction capability of
column-weight-three LDPC codes is investigated. Specifically, it is shown that
the Gallager A algorithm can correct $g/2-1$ errors in $g/2$ iterations on a
Tanner graph of girth $g \geq 10$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3590</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3590</id><created>2008-07-22</created><authors><author><keyname>Donoho</keyname><forenames>David L.</forenames></author><author><keyname>Tanner</keyname><forenames>Jared</forenames></author></authors><title>Counting the Faces of Randomly-Projected Hypercubes and Orthants, with
  Applications</title><categories>math.MG cs.IT math.IT math.OC math.PR</categories><comments>21 pages, 3 figures</comments><msc-class>52A22, 52B05, 52B11, 52B12, 62E20, 68P30, 68P25, 68W20, 68W40,
  94B20, 94B35, 94B65, 94B70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $A$ be an $n$ by $N$ real valued random matrix, and $\h$ denote the
$N$-dimensional hypercube. For numerous random matrix ensembles, the expected
number of $k$-dimensional faces of the random $n$-dimensional zonotope $A\h$
obeys the formula $E f_k(A\h) /f_k(\h) = 1-P_{N-n,N-k}$, where $P_{N-n,N-k}$ is
a fair-coin-tossing probability. The formula applies, for example, where the
columns of $A$ are drawn i.i.d. from an absolutely continuous symmetric
distribution. The formula exploits Wendel's Theorem\cite{We62}.
  Let $\po$ denote the positive orthant; the expected number of $k$-faces of
the random cone$A \po$ obeys $ {\cal E} f_k(A\po) /f_k(\po) = 1 - P_{N-n,N-k}$.
The formula applies to numerous matrix ensembles, including those with iid
random columns from an absolutely continuous, centrally symmetric distribution.
There is an asymptotically sharp threshold in the behavior of face counts of
the projected hypercube; thresholds known for projecting the simplex and the
cross-polytope, occur at very different locations. We briefly consider face
counts of the projected orthant when $A$ does not have mean zero; these do
behave similarly to those for the projected simplex. We consider non-random
projectors of the orthant; the 'best possible' $A$ is the one associated with
the first $n$ rows of the Fourier matrix.
  These geometric face-counting results have implications for signal
processing, information theory, inverse problems, and optimization. Most of
these flow in some way from the fact that face counting is related to
conditions for uniqueness of solutions of underdetermined systems of linear
equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3593</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3593</id><created>2008-07-22</created><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author></authors><title>An outer bound for 2-receiver discrete memoryless broadcast channels</title><categories>cs.IT math.IT</categories><comments>3 pages, a note</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An outer bound to the two-receiver discrete memoryless broadcast channel is
presented. We compare it to the known outer bounds and show that the outer
bound presented is at least as tight as the existing bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3600</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3600</id><created>2008-07-23</created><authors><author><keyname>Diaz</keyname><forenames>J.</forenames></author><author><keyname>Kirousis</keyname><forenames>L.</forenames></author><author><keyname>Mitsche</keyname><forenames>D.</forenames></author><author><keyname>Perez-Gimenez</keyname><forenames>X.</forenames></author></authors><title>A new upper bound for 3-SAT</title><categories>cs.DM</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that a randomly chosen 3-CNF formula over n variables with
clauses-to-variables ratio at least 4.4898 is, as n grows large, asymptotically
almost surely unsatisfiable. The previous best such bound, due to Dubois in
1999, was 4.506. The first such bound, independently discovered by many groups
of researchers since 1983, was 5.19. Several decreasing values between 5.19 and
4.506 were published in the years between. The probabilistic techniques we use
for the proof are, we believe, of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3622</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3622</id><created>2008-07-23</created><authors><author><keyname>Kallmeyer</keyname><forenames>Laura</forenames><affiliation>SFB 441</affiliation></author><author><keyname>Lichte</keyname><forenames>Timm</forenames><affiliation>SFB 441</affiliation></author><author><keyname>Maier</keyname><forenames>Wolfgang</forenames><affiliation>SFB 441</affiliation></author><author><keyname>Parmentier</keyname><forenames>Yannick</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Dellert</keyname><forenames>Johannes</forenames><affiliation>SFB 441</affiliation></author><author><keyname>Evang</keyname><forenames>Kilian</forenames><affiliation>SFB 441</affiliation></author></authors><title>TuLiPA: Towards a Multi-Formalism Parsing Environment for Grammar
  Engineering</title><categories>cs.CL</categories><comments>Dans 2nd Workshop on Grammar Engineering Across Frameworks, GEAF 2008
  (2008)</comments><proxy>ccsd inria-00304605</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an open-source parsing environment (Tuebingen
Linguistic Parsing Architecture, TuLiPA) which uses Range Concatenation Grammar
(RCG) as a pivot formalism, thus opening the way to the parsing of several
mildly context-sensitive formalisms. This environment currently supports
tree-based grammars (namely Tree-Adjoining Grammars, TAG) and Multi-Component
Tree-Adjoining Grammars with Tree Tuples (TT-MCTAG)) and allows computation not
only of syntactic structures, but also of the corresponding semantic
representations. It is used for the development of a tree-based grammar for
German.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3632</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3632</id><created>2008-07-23</created><authors><author><keyname>Bui</keyname><forenames>Alain</forenames></author><author><keyname>Sohier</keyname><forenames>Devan</forenames></author></authors><title>How to Compute Times of Random Walks based Distributed Algorithms</title><categories>cs.DC cs.DM</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random walk based distributed algorithms make use of a token that circulates
in the system according to a random walk scheme to achieve their goal. To study
their efficiency and compare it to one of the deterministic solutions, one is
led to compute certain quantities, namely the hitting times and the cover time.
Until now, only bounds on these quantities were defined. First, this paper
presents two generalizations of the notions of hitting and cover times to
weighted graphs. Indeed, the properties of random walks on symmetrically
weighted graphs provide interesting results on random walk based distributed
algorithms, such as local load balancing. Both of these generalization are
proposed to precisely represent the behaviour of these algorithms, and to take
into account what the weights represent. Then, we propose an algorithm to
compute the n^2 hitting times on a weighted graph of n vertices, which we
improve to obtain a O(n^3) complexity. This complexity is the lowest up to now.
This algorithm computes both of the generalizations that we propose for the
hitting times on a weighted graph. Finally, we provide the first algorithm to
compute the cover time (in both senses) of a graph. We improve it to achieve a
complexity of O(n^3 2^n). The algorithms that we present are all robust to a
topological change in a limited number of edges. This property allows us to use
them on dynamic graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3648</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3648</id><created>2008-07-23</created><updated>2010-02-18</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Ponse</keyname><forenames>A.</forenames></author></authors><title>Proposition Algebra with Projective Limits</title><categories>cs.LO</categories><comments>43 pages, 3 tables</comments><acm-class>F.3.2</acm-class><journal-ref>ACM Transactions on Computational Logic, 12 (3), Article 21, 2011</journal-ref><doi>10.1145/1929954.1929958</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential propositional logic deviates from ordinary propositional logic by
taking into account that during the sequential evaluation of a propositional
statement,atomic propositions may yield different Boolean values at repeated
occurrences. We introduce `free valuations' to capture this dynamics of a
propositional statement's environment. The resulting logic is phrased as an
equationally specified algebra rather than in the form of proof rules, and is
named `proposition algebra'. It is strictly more general than Boolean algebra
to the extent that the classical connectives fail to be expressively complete
in the sequential case. The four axioms for free valuation congruence are then
combined with other axioms in order define a few more valuation congruences
that gradually identify more propositional statements, up to static valuation
congruence (which is the setting of conventional propositional logic).
  Proposition algebra is developed in a fashion similar to the process algebra
ACP and the program algebra PGA, via an algebraic specification which has a
meaningful initial algebra for which a range of coarser congruences are
considered important as well. In addition infinite objects (that is
propositional statements, processes and programs respectively) are dealt with
by means of an inverse limit construction which allows the transfer of
knowledge concerning finite objects to facts about infinite ones while reducing
all facts about infinite objects to an infinity of facts about finite ones in
return.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3669</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3669</id><created>2008-07-23</created><authors><author><keyname>Dezert</keyname><forenames>Jean</forenames><affiliation>ONERA</affiliation></author><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author></authors><title>A new probabilistic transformation of belief mass assignment</title><categories>cs.AI</categories><proxy>ccsd hal-00304319</proxy><journal-ref>Fusion 2008 International Conference on Information Fusion,
  Cologne : Allemagne (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose in Dezert-Smarandache Theory (DSmT) framework, a
new probabilistic transformation, called DSmP, in order to build a subjective
probability measure from any basic belief assignment defined on any model of
the frame of discernment. Several examples are given to show how the DSmP
transformation works and we compare it to main existing transformations
proposed in the literature so far. We show the advantages of DSmP over
classical transformations in term of Probabilistic Information Content (PIC).
The direct extension of this transformation for dealing with qualitative belief
assignments is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3699</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3699</id><created>2008-07-23</created><authors><author><keyname>Arguello</keyname><forenames>Francisco</forenames></author></authors><title>Multiplication in Cyclotomic Rings and its Application to Finite Fields</title><categories>cs.DM</categories><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A representation of finite fields that has proved useful when implementing
finite field arithmetic in hardware is based on an isomorphism between subrings
and fields. In this paper, we present an unified formulation for multiplication
in cyclotomic rings and cyclotomic fields in that most arithmetic operations
are done on vectors. From this formulation we can generate optimized algorithms
for multiplication. For example, one of the proposed algorithms requires
approximately half the number of coordinate-level multiplications at the
expense of extra coordinate-level additions. Our method is then applied to the
finite fields GF(q^m) to further reduce the number of operations. We then
present optimized algorithms for multiplication in finite fields with type-I
and type-II optimal normal bases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3732</identifier>
 <datestamp>2008-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3732</id><created>2008-07-23</created><authors><author><keyname>Aubert</keyname><forenames>Alain</forenames><affiliation>LAHC</affiliation></author><author><keyname>Bochard</keyname><forenames>Nathalie</forenames><affiliation>LAHC</affiliation></author><author><keyname>Fresse</keyname><forenames>Virginie</forenames><affiliation>LAHC</affiliation></author></authors><title>An adaptive embedded architecture for real-time Particle Image
  Velocimetry algorithms</title><categories>cs.AR</categories><comments>14th European Signal Processing Conference - EUSIPCO 2006, Florence :
  Italie (2006)</comments><proxy>ccsd ujm-00124018</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Particle Image Velocimetry (PIV) is a method of im-aging and analysing fields
of flows. The PIV tech-niques compute and display all the motion vectors of the
field in a resulting image. Speeds more than thou-sand vectors per second can
be required, each speed being environment-dependent. Essence of this work is to
propose an adaptive FPGA-based system for real-time PIV algorithms. The
proposed structure is ge-neric so that this unique structure can be re-used for
any PIV applications that uses the cross-correlation technique. The major
structure remains unchanged, adaptations only concern the number of processing
operations. The required speed (corresponding to the number of vector per
second) is obtained thanks to a parallel processing strategy. The image
processing designer duplicates the processing modules to distrib-ute the
operations. The result is a FPGA-based archi-tecture, which is easily adapted
to algorithm specifica-tions without any hardware requirement. The design flow
is fast and reliable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3755</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3755</id><created>2008-07-23</created><authors><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Approximating Document Frequency with Term Count Values</title><categories>cs.IR cs.DL</categories><comments>11 pages, 6 figures, 4 tables</comments><acm-class>H.3.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For bounded datasets such as the TREC Web Track (WT10g) the computation of
term frequency (TF) and inverse document frequency (IDF) is not difficult.
However, when the corpus is the entire web, direct IDF calculation is
impossible and values must instead be estimated. Most available datasets
provide values for term count (TC) meaning the number of times a certain term
occurs in the entire corpus. Intuitively this value is different from document
frequency (DF), the number of documents (e.g., web pages) a certain term occurs
in. We conduct a comparison study between TC and DF values within the Web as
Corpus (WaC). We found a very strong correlation with Spearman's rho &gt;0.8
(p&lt;0.005) which makes us confident in claiming that for such recently created
corpora the TC and DF values can be used interchangeably to compute IDF values.
These results are useful for the generation of accurate lexical signatures
based on the TF-IDF scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3795</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3795</id><created>2008-07-24</created><authors><author><keyname>Spight</keyname><forenames>Marshall</forenames></author><author><keyname>Tropashko</keyname><forenames>Vadim</forenames></author></authors><title>Relational Lattice Axioms</title><categories>cs.DB</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relational lattice is a formal mathematical model for Relational algebra. It
reduces the set of six classic relational algebra operators to two: natural
join and inner union. We continue to investigate Relational lattice properties
with emphasis onto axiomatic definition. New results include additional axioms,
equational definition for set difference (more generally anti-join), and case
study demonstrating application of the relational lattice theory for query
transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3803</identifier>
 <datestamp>2013-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3803</id><created>2008-07-24</created><updated>2013-04-11</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Brun</keyname><forenames>Todd A.</forenames></author></authors><title>Quantum Convolutional Coding with Shared Entanglement: General Structure</title><categories>quant-ph cs.IT math.IT</categories><comments>23 pages, replaced with final published version</comments><report-no>CSI-08-07-02</report-no><journal-ref>Quantum Information Processing, Volume 9, Number 5, pages 509-540,
  September 2010</journal-ref><doi>10.1007/s11128-010-0179-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general theory of entanglement-assisted quantum convolutional
coding. The codes have a convolutional or memory structure, they assume that
the sender and receiver share noiseless entanglement prior to quantum
communication, and they are not restricted to possess the
Calderbank-Shor-Steane structure as in previous work. We provide two
significant advances for quantum convolutional coding theory. We first show how
to &quot;expand&quot; a given set of quantum convolutional generators. This expansion
step acts as a preprocessor for a polynomial symplectic Gram-Schmidt
orthogonalization procedure that simplifies the commutation relations of the
expanded generators to be the same as those of entangled Bell states (ebits)
and ancilla qubits. The above two steps produce a set of generators with
equivalent error-correcting properties to those of the original generators. We
then demonstrate how to perform online encoding and decoding for a stream of
information qubits, halves of ebits, and ancilla qubits. The upshot of our
theory is that the quantum code designer can engineer quantum convolutional
codes with desirable error-correcting properties without having to worry about
the commutation relations of these generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3806</identifier>
 <datestamp>2009-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3806</id><created>2008-07-24</created><updated>2009-04-06</updated><authors><author><keyname>Arikan</keyname><forenames>Erdal</forenames></author><author><keyname>Telatar</keyname><forenames>Emre</forenames></author></authors><title>On the Rate of Channel Polarization</title><categories>cs.IT math.IT</categories><comments>Some minor corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that for any binary-input discrete memoryless channel $W$ with
symmetric capacity $I(W)$ and any rate $R &lt;I(W)$, the probability of block
decoding error for polar coding under successive cancellation decoding
satisfies $P_e \le 2^{-N^\beta}$ for any $\beta&lt;\frac12$ when the block-length
$N$ is large enough.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3845</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3845</id><created>2008-07-24</created><authors><author><keyname>Reghizzi</keyname><forenames>Stefano Crespi</forenames></author></authors><title>Formal semantics of language and the Richard-Berry paradox</title><categories>cs.CL cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical logical antinomy known as Richard-Berry paradox is combined
with plausible assumptions about the size i.e. the descriptional complexity of
Turing machines formalizing certain sentences, to show that formalization of
language leads to contradiction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3865</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3865</id><created>2008-07-24</created><authors><author><keyname>Martin</keyname><forenames>Bruno</forenames><affiliation>I3S</affiliation></author><author><keyname>Sol&#xe9;</keyname><forenames>Patrick</forenames><affiliation>I3S</affiliation></author></authors><title>Pseudo-random Sequences Generated by Cellular Automata</title><categories>cs.DM</categories><proxy>ccsd hal-00305407</proxy><journal-ref>International Conference on Relations, Orders and Graphs:
  Interactions with Computer Science, Mahdia : Tunisie (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generation of pseudo random sequences by cellular automata, as well as by
hybrid cellular automata is surveyed. An application to the fast evaluation and
FPGA implementation of some classes of boolean functions is sketched out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3879</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3879</id><created>2008-07-24</created><authors><author><keyname>Di Pierro</keyname><forenames>Alessandra</forenames></author><author><keyname>Hankin</keyname><forenames>Chris</forenames></author><author><keyname>Wiklicky</keyname><forenames>Herbert</forenames></author></authors><title>Quantifying Timing Leaks and Cost Optimisation</title><categories>cs.CR cs.PL</categories><comments>16 pages, 2 figures, 4 tables. A shorter version is included in the
  proceedings of ICICS'08 - 10th International Conference on Information and
  Communications Security, 20-22 October, 2008 Birmingham, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new notion of security against timing attacks where the attacker
is able to simultaneously observe the execution time of a program and the
probability of the values of low variables. We then show how to measure the
security of a program with respect to this notion via a computable estimate of
the timing leakage and use this estimate for cost optimisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3908</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3908</id><created>2008-07-24</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>A Distributed Process Infrastructure for a Distributed Data Structure</title><categories>cs.AI cs.DL</categories><comments>written as a column for the Semantic Web and Information Systems
  Bulletin, AIS Special Interest Group on Semantic Web and Information Systems
  (SIGSEMIS), ISSN: 1556-2301</comments><report-no>LA-UR-08-04138</report-no><acm-class>I.2.4; C.1.4</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The Resource Description Framework (RDF) is continuing to grow outside the
bounds of its initial function as a metadata framework and into the domain of
general-purpose data modeling. This expansion has been facilitated by the
continued increase in the capacity and speed of RDF database repositories known
as triple-stores. High-end RDF triple-stores can hold and process on the order
of 10 billion triples. In an effort to provide a seamless integration of the
data contained in RDF repositories, the Linked Data community is providing
specifications for linking RDF data sets into a universal distributed graph
that can be traversed by both man and machine. While the seamless integration
of RDF data sets is important, at the scale of the data sets that currently
exist and will ultimately grow to become, the &quot;download and index&quot; philosophy
of the World Wide Web will not so easily map over to the Semantic Web. This
essay discusses the importance of adding a distributed RDF process
infrastructure to the current distributed RDF data structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3913</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3913</id><created>2008-07-24</created><authors><author><keyname>Mroueh</keyname><forenames>Lina</forenames></author><author><keyname>Rouquette-L&#xe9;veil</keyname><forenames>St&#xe9;phanie</forenames></author><author><keyname>Othman</keyname><forenames>Ghaya Rekaya-Ben</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>DMT of weighted Parallel Channels: Application to Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Symposium on Information
  Theory, Toronto, ON, Canada, July 6 - 11, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a broadcast channel with random packet arrival and transmission queues,
the stability of the system is achieved by maximizing a weighted sum rate
capacity with suitable weights that depend on the queue size. The weighted sum
rate capacity using Dirty Paper Coding (DPC) and Zero Forcing (ZF) is
asymptotically equivalent to the weighted sum capacity over parallel
single-channels. In this paper, we study the Diversity Multiplexing Tradeoff
(DMT) of the fading broadcast channel under a fixed weighted sum rate capacity
constraint. The DMT of both identical and different parallel weighted MISO
channels is first derived. Finally, we deduce the DMT of a broadcast channel
using DPC and ZF precoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3917</identifier>
 <datestamp>2009-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3917</id><created>2008-07-24</created><updated>2009-07-20</updated><authors><author><keyname>Arikan</keyname><forenames>Erdal</forenames></author></authors><title>Channel polarization: A method for constructing capacity-achieving codes
  for symmetric binary-input memoryless channels</title><categories>cs.IT math.IT</categories><comments>The version which appears in the IEEE Transactions on Information
  Theory, July 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is proposed, called channel polarization, to construct code
sequences that achieve the symmetric capacity $I(W)$ of any given binary-input
discrete memoryless channel (B-DMC) $W$. The symmetric capacity is the highest
rate achievable subject to using the input letters of the channel with equal
probability. Channel polarization refers to the fact that it is possible to
synthesize, out of $N$ independent copies of a given B-DMC $W$, a second set of
$N$ binary-input channels $\{W_N^{(i)}:1\le i\le N\}$ such that, as $N$ becomes
large, the fraction of indices $i$ for which $I(W_N^{(i)})$ is near 1
approaches $I(W)$ and the fraction for which $I(W_N^{(i)})$ is near 0
approaches $1-I(W)$. The polarized channels $\{W_N^{(i)}\}$ are
well-conditioned for channel coding: one need only send data at rate 1 through
those with capacity near 1 and at rate 0 through the remaining. Codes
constructed on the basis of this idea are called polar codes. The paper proves
that, given any B-DMC $W$ with $I(W)&gt;0$ and any target rate $R &lt; I(W)$, there
exists a sequence of polar codes $\{{\mathscr C}_n;n\ge 1\}$ such that
${\mathscr C}_n$ has block-length $N=2^n$, rate $\ge R$, and probability of
block error under successive cancellation decoding bounded as $P_{e}(N,R) \le
\bigoh(N^{-\frac14})$ independently of the code rate. This performance is
achievable by encoders and decoders with complexity $O(N\log N)$ for each.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3933</identifier>
 <datestamp>2008-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3933</id><created>2008-07-24</created><authors><author><keyname>Mou&#xeb;l</keyname><forenames>Fr&#xe9;d&#xe9;ric Le</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / CITI</affiliation></author><author><keyname>Ibrahim</keyname><forenames>Noha</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / CITI</affiliation></author><author><keyname>Fr&#xe9;not</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / CITI</affiliation></author></authors><title>Interface Matching and Combining Techniques for Services Integration</title><categories>cs.OS cs.SE</categories><proxy>ccsd inria-00305481</proxy><journal-ref>Dans 3er Congreso Nacional de Ciencias de la Computacion
  (CNCC'2005) (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of many highly dynamic environments, like pervasive
environments, introduces the possibility to use geographically close-related
services. Dynamically integrating and unintegrating these services in running
applications is a key challenge for this use. In this article, we classify
service integration issues according to interfaces exported by services and
internal combining techniques. We also propose a contextual integration
service, IntegServ, and an interface, Integrable, for developing services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3979</identifier>
 <datestamp>2008-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3979</id><created>2008-07-25</created><authors><author><keyname>Gabbrielli</keyname><forenames>Maurizio</forenames></author><author><keyname>Meo</keyname><forenames>Maria Chiara</forenames></author><author><keyname>Tacchella</keyname><forenames>Paolo</forenames></author></authors><title>Unfolding in CHR</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Program transformation is an appealing technique which allows to improve
run-time efficiency, space-consumption and more generally to optimize a given
program. Essentially it consists of a sequence of syntactic program
manipulations which preserves some kind of semantic equivalence. One of the
basic operations which is used by most program transformation systems is
unfolding which consists in the replacement of a procedure call by its
definition. While there is a large body of literature on transformation and
unfolding of sequential programs, very few papers have addressed this issue for
concurrent languages and, to the best of our knowledge, no other has considered
unfolding of CHR programs.
  This paper defines a correct unfolding system for CHR programs. We define an
unfolding rule, show its correctness and discuss some conditions which can be
used to delete an unfolded rule while preserving the program meaning. We prove
that confluence and termination properties are preserved by the above
transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3991</identifier>
 <datestamp>2008-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3991</id><created>2008-07-24</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author></authors><title>Codes Associated with Special Linear Groups and Power Moments of
  Multi-dimensional Kloosterman Sums</title><categories>math.NT cs.IT math.IT</categories><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct the binary linear codes $C(SL(n,q))$ associated
with finite special linear groups $SL(n,q)$, with both \emph{n,q} powers of
two. Then, via Pless power moment identity and utilizing our previous result on
the explicit expression of the Gauss sum for $SL(n,q)$, we obtain a recursive
formula for the power moments of multi-dimensional Kloosterman sums in terms of
the frequencies of weights in $C(SL(n,q))$. In particular, when $n=2$, this
gives a recursive formula for the power moments of Kloosterman sums. We
illustrate our results with some examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3996</identifier>
 <datestamp>2008-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3996</id><created>2008-07-25</created><authors><author><keyname>Zinoviev</keyname><forenames>D.</forenames></author></authors><title>Topology and Geometry of Online Social Networks</title><categories>cs.CY physics.soc-ph</categories><comments>6 pages, 11 figures, presented at WMCSI'08</comments><journal-ref>Proc. 12th World Multi-Conference on Systemics, Cybernetics and
  Informatics VI (2008) 138-143</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study certain geometric and topological properties of
online social networks using the concept of density and geometric vector
spaces. &quot;Moi Krug&quot; (&quot;My Circle&quot;), a Russian social network that promotes the
principle of the &quot;six degrees of separation&quot; and is positioning itself as a
vehicle for professionals and recruiters seeking each others' services, is used
as a test vehicle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4009</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4009</id><created>2008-07-25</created><authors><author><keyname>Cousseau</keyname><forenames>Florent</forenames></author><author><keyname>Mimura</keyname><forenames>Kazushi</forenames></author><author><keyname>Omori</keyname><forenames>Toshiaki</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Statistical mechanics of lossy compression for non-monotonic multilayer
  perceptrons</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.IT math.IT</categories><comments>29 pages, 7 figures</comments><journal-ref>Phys. Rev. E, 78, 021124 (2008)</journal-ref><doi>10.1103/PhysRevE.78.021124</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lossy data compression scheme for uniformly biased Boolean messages is
investigated via statistical mechanics techniques. We utilize tree-like
committee machine (committee tree) and tree-like parity machine (parity tree)
whose transfer functions are non-monotonic. The scheme performance at the
infinite code length limit is analyzed using the replica method. Both committee
and parity treelike networks are shown to saturate the Shannon bound. The AT
stability of the Replica Symmetric solution is analyzed, and the tuning of the
non-monotonic transfer function is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4052</identifier>
 <datestamp>2009-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4052</id><created>2008-07-25</created><updated>2008-12-09</updated><authors><author><keyname>Noack</keyname><forenames>Andreas</forenames></author></authors><title>Modularity clustering is force-directed layout</title><categories>cs.DM cs.CG physics.soc-ph</categories><comments>9 pages, 7 figures, see http://code.google.com/p/linloglayout/ for
  downloading the graph clustering and layout software</comments><acm-class>G.2.2; G.2.3; I.5.3</acm-class><journal-ref>Phys. Rev. E 79, 026102 (2009)</journal-ref><doi>10.1103/PhysRevE.79.026102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two natural and widely used representations for the community structure of
networks are clusterings, which partition the vertex set into disjoint subsets,
and layouts, which assign the vertices to positions in a metric space. This
paper unifies prominent characterizations of layout quality and clustering
quality, by showing that energy models of pairwise attraction and repulsion
subsume Newman and Girvan's modularity measure. Layouts with optimal energy are
relaxations of, and are thus consistent with, clusterings with optimal
modularity, which is of practical relevance because both representations are
complementary and often used together.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4073</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4073</id><created>2008-07-25</created><updated>2008-09-19</updated><authors><author><keyname>Rutten</keyname><forenames>J. J. M. M.</forenames></author></authors><title>Rational streams coalgebraically</title><categories>cs.LO</categories><acm-class>F.1.1; G.1.0</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (September
  19, 2008) lmcs:1164</journal-ref><doi>10.2168/LMCS-4(3:9)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study rational streams (over a field) from a coalgebraic perspective.
Exploiting the finality of the set of streams, we present an elementary and
uniform proof of the equivalence of four notions of representability of
rational streams: by finite dimensional linear systems; by finite stream
circuits; by finite weighted stream automata; and by finite dimensional
subsystems of the set of streams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4074</identifier>
 <datestamp>2008-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4074</id><created>2008-07-25</created><updated>2008-07-28</updated><authors><author><keyname>Das</keyname><forenames>Smarajit</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Low-delay, Low-PAPR, High-rate Non-square Complex Orthogonal Designs</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. 17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximal rate for non-square Complex Orthogonal Designs (CODs) with $n$
transmit antennas is ${1/2}+\frac{1}{n}$ if $n$ is even and
${1/2}+\frac{1}{n+1}$ if $n$ is odd, which are close to 1/2 for large values of
$n.$ A class of maximal rate non-square CODs have been constructed by Liang
(IEEE Trans. Inform. Theory, 2003) and Lu et. al. (IEEE Trans. Inform. Theory,
2005) have shown that the decoding delay of the codes given by Liang, can be
reduced by 50% when number of transmit antennas is a multiple of 4. Adams et.
al. (IEEE Trans. Inform. Theory, 2007) have shown that the designs of Liang are
of minimal-delay for $n$ equal to 1 and 3 modulo 4 and that of Lu et.al. are of
minimal delay when $n$ is a multiple of $4.$ However, these minimal delays are
large compared to the delays of the rate 1/2 non-square CODs constructed by
Tarokh et al (IEEE Trans. Inform. Theory, 1999) from rate-1 real orthogonal
designs (RODs). In this paper, we construct a class of rate-1/2 non-square CODs
for any $n$ with the decoding delay equal to 50% of that of the delay of the
rate-1/2 codes given by Tarokh et al. This is achieved by giving first a
general construction of rate-1 square Real Orthogonal Designs (RODs) which
includes as special cases the well known constructions of Adams, Lax and
Phillips and Geramita and Pullman, and then making use of it to obtain the
desired rate-1/2 non-square COD. For the case of 9 transmit antennas, our
rate-1/2 COD is shown to be of minimal-delay. The proposed construction results
in designs with zero entries which may have high Peak-to-Average Power Ratio
(PAPR) and it is shown that by appropriate postmultiplication, a design with no
zero entries can be obtained with no change in the code parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4111</identifier>
 <datestamp>2008-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4111</id><created>2008-07-25</created><authors><author><keyname>Dynes</keyname><forenames>J. F.</forenames></author><author><keyname>Yuan</keyname><forenames>Z. L.</forenames></author><author><keyname>Sharpe</keyname><forenames>A. W.</forenames></author><author><keyname>Shields</keyname><forenames>A. J.</forenames></author></authors><title>A High Speed, Post-Processing Free, Quantum Random Number Generator</title><categories>quant-ph cs.CR</categories><journal-ref>Applied Physics Letters Vol. 93 031109 (2008)</journal-ref><doi>10.1063/1.2961000</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A quantum random number generator (QRNG) based on gated single photon
detection of an InGaAs photodiode at GHz frequency is demonstrated. Owing to
the extremely long coherence time of each photon, each photons' wavefuntion
extends over many gating cycles of the photodiode. The collapse of the photon
wavefunction on random gating cycles as well as photon random arrival time
detection events are used to generate sequences of random bits at a rate of
4.01 megabits/s. Importantly, the random outputs are intrinsically bias-free
and require no post-processing procedure to pass random number statistical
tests, making this QRNG an extremely simple device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4128</identifier>
 <datestamp>2008-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4128</id><created>2008-07-25</created><authors><author><keyname>Das</keyname><forenames>Smarajit</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Square Complex Orthogonal Designs with Low PAPR and Signaling Complexity</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Wireless
  Communication. 10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space-Time Block Codes from square complex orthogonal designs (SCOD) have
been extensively studied and most of the existing SCODs contain large number of
zero. The zeros in the designs result in high peak-to-average power ratio
(PAPR) and also impose a severe constraint on hardware implementation of the
code when turning off some of the transmitting antennas whenever a zero is
transmitted. Recently, rate 1/2 SCODs with no zero entry have been reported for
8 transmit antennas. In this paper, SCODs with no zero entry for $2^a$ transmit
antennas whenever $a+1$ is a power of 2, are constructed which includes the 8
transmit antennas case as a special case. More generally, for arbitrary values
of $a$, explicit construction of $2^a\times 2^a$ rate $\frac{a+1}{2^a}$ SCODs
with the ratio of number of zero entries to the total number of entries equal
to $1-\frac{a+1}{2^a}2^{\lfloor log_2(\frac{2^a}{a+1}) \rfloor}$ is reported,
whereas for standard known constructions, the ratio is $1-\frac{a+1}{2^a}$. The
codes presented do not result in increased signaling complexity. Simulation
results show that the codes constructed in this paper outperform the codes
using the standard construction under peak power constraint while performing
the same under average power constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4132</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4132</id><created>2008-07-25</created><updated>2010-10-11</updated><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Mandrioli</keyname><forenames>Dino</forenames></author><author><keyname>Morzenti</keyname><forenames>Angelo</forenames></author><author><keyname>Rossi</keyname><forenames>Matteo</forenames></author></authors><title>Modeling Time in Computing: A Taxonomy and a Comparative Survey</title><categories>cs.GL</categories><comments>More typos fixed</comments><journal-ref>ACM Computing Surveys, 42(2):1--59, February 2010</journal-ref><doi>10.1145/1667062.1667063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing relevance of areas such as real-time and embedded systems,
pervasive computing, hybrid systems control, and biological and social systems
modeling is bringing a growing attention to the temporal aspects of computing,
not only in the computer science domain, but also in more traditional fields of
engineering.
  This article surveys various approaches to the formal modeling and analysis
of the temporal features of computer-based systems, with a level of detail that
is suitable also for non-specialists. In doing so, it provides a unifying
framework, rather than just a comprehensive list of formalisms.
  The paper first lays out some key dimensions along which the various
formalisms can be evaluated and compared. Then, a significant sample of
formalisms for time modeling in computing are presented and discussed according
to these dimensions. The adopted perspective is, to some extent, historical,
going from &quot;traditional&quot; models and formalisms to more modern ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4198</identifier>
 <datestamp>2009-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4198</id><created>2008-07-25</created><updated>2009-07-15</updated><authors><author><keyname>Vogel</keyname><forenames>Brian K.</forenames></author></authors><title>Positive factor networks: A graphical framework for modeling
  non-negative sequential data</title><categories>cs.LG</categories><comments>Minor editing of the abstract, introduction, and concluding sections
  to improve readability and remove redundant wording, based on feedback from a
  reviewer. No changes were made to the material presented nor to the results.
  Added an acknowledgment section to thank the reviewer. Corrected minor typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel graphical framework for modeling non-negative sequential
data with hierarchical structure. Our model corresponds to a network of coupled
non-negative matrix factorization (NMF) modules, which we refer to as a
positive factor network (PFN). The data model is linear, subject to
non-negativity constraints, so that observation data consisting of an additive
combination of individually representable observations is also representable by
the network. This is a desirable property for modeling problems in
computational auditory scene analysis, since distinct sound sources in the
environment are often well-modeled as combining additively in the corresponding
magnitude spectrogram. We propose inference and learning algorithms that
leverage existing NMF algorithms and that are straightforward to implement. We
present a target tracking example and provide results for synthetic observation
data which serve to illustrate the interesting properties of PFNs and motivate
their potential usefulness in applications such as music transcription, source
separation, and speech recognition. We show how a target process characterized
by a hierarchical state transition model can be represented as a PFN. Our
results illustrate that a PFN which is defined in terms of a single target
observation can then be used to effectively track the states of multiple
simultaneous targets. Our results show that the quality of the inferred target
states degrades gradually as the observation noise is increased. We also
present results for an example in which meaningful hierarchical features are
extracted from a spectrogram. Such a hierarchical representation could be
useful for music transcription and source separation applications. We also
propose a network for language modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4224</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4224</id><created>2008-07-26</created><authors><author><keyname>Kirwan</keyname><forenames>Edmund</forenames></author></authors><title>Encapsulation theory fundamentals</title><categories>cs.SE</categories><comments>33 pages, 35 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a theory of encapsulation, establishing a relationship
between encapsulation and information hiding through the concept of potential
structural complexity (P.S.C.), the maximum possible number of source code
dependencies that can exist between program units in a software system. The
P.S.C. of various, simple systems is examined in an attempt to demonstrate how
P.S.C. changes as program units are encapsulated among different configurations
of subsystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4229</identifier>
 <datestamp>2008-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4229</id><created>2008-07-26</created><updated>2008-12-01</updated><authors><author><keyname>Richard</keyname><forenames>Adrien</forenames></author></authors><title>Positive circuits and maximal number of fixed points in discrete
  dynamical systems</title><categories>cs.DM</categories><comments>13 pages</comments><acm-class>G.2.1; G.2.2; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Cartesian product X of n finite intervals of integers and a
map F from X to itself. As main result, we establish an upper bound on the
number of fixed points for F which only depends on X and on the topology of the
positive circuits of the interaction graph associated with F. The proof uses
and strongly generalizes a theorem of Richard and Comet which corresponds to a
discrete version of the Thomas' conjecture: if the interaction graph associated
with F has no positive circuit, then F has at most one fixed point. The
obtained upper bound on the number of fixed points also strongly generalizes
the one established by Aracena et al for a particular class of Boolean
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4234</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4234</id><created>2008-07-26</created><authors><author><keyname>Ioannidou</keyname><forenames>Kyriaki</forenames></author><author><keyname>Nikolopoulos</keyname><forenames>Stavros D.</forenames></author></authors><title>Linear Coloring and Linear Graphs</title><categories>cs.DM cs.DS</categories><comments>21 pages, 7 figures</comments><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the definition of linear coloring on simplicial complexes,
recently introduced in the context of algebraic topology \cite{Civan}, and the
framework through which it was studied, we introduce the linear coloring on
graphs. We provide an upper bound for the chromatic number $\chi(G)$, for any
graph $G$, and show that $G$ can be linearly colored in polynomial time by
proposing a simple linear coloring algorithm. Based on these results, we define
a new class of perfect graphs, which we call co-linear graphs, and study their
complement graphs, namely linear graphs. The linear coloring of a graph $G$ is
a vertex coloring such that two vertices can be assigned the same color, if
their corresponding clique sets are associated by the set inclusion relation (a
clique set of a vertex $u$ is the set of all maximal cliques containing $u$);
the linear chromatic number $\mathcal{\lambda}(G)$ of $G$ is the least integer
$k$ for which $G$ admits a linear coloring with $k$ colors. We show that linear
graphs are those graphs $G$ for which the linear chromatic number achieves its
theoretical lower bound in every induced subgraph of $G$. We prove inclusion
relations between these two classes of graphs and other subclasses of chordal
and co-chordal graphs, and also study the structure of the forbidden induced
subgraphs of the class of linear graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4247</identifier>
 <datestamp>2009-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4247</id><created>2008-07-26</created><updated>2009-06-04</updated><authors><author><keyname>Fernandez-Cordoba</keyname><forenames>Cristina</forenames></author><author><keyname>Pujol</keyname><forenames>Jaume</forenames></author><author><keyname>Villanueva</keyname><forenames>Merce</forenames></author></authors><title>Z2Z4-linear codes: rank and kernel</title><categories>cs.IT cs.DM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A code C is Z2Z4-additive if the set of coordinates can be partitioned into
two subsets X and Y such that the punctured code of C by deleting the
coordinates outside X (respectively, Y) is a binary linear code (respectively,
a quaternary linear code). In this paper, the rank and dimension of the kernel
for Z2Z4-linear codes, which are the corresponding binary codes of
Z2Z4-additive codes, are studied. The possible values of these two parameters
for Z2Z4-linear codes, giving lower and upper bounds, are established. For each
possible rank r between these bounds, the construction of a Z2Z4-linear code
with rank r is given. Equivalently, for each possible dimension of the kernel
k, the construction of a Z2Z4-linear code with dimension of the kernel k is
given. Finally, the bounds on the rank, once the kernel dimension is fixed, are
established and the construction of a Z2Z4-additive code for each possible pair
(r,k) is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4268</identifier>
 <datestamp>2009-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4268</id><created>2008-07-27</created><updated>2009-03-17</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Phase Diagrams of Network Traffic</title><categories>cs.NI</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn due to errors in the analysis of data with
Carrier Access Rate control and statistical methodologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4309</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4309</id><created>2008-07-27</created><authors><author><keyname>Sivadasan</keyname><forenames>Praveen</forenames></author><author><keyname>Lal</keyname><forenames>P. Sojan</forenames></author></authors><title>Array Based Java Source Code Obfuscation Using Classes with Restructured
  Arrays</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Array restructuring operations obscure arrays. Our work aims on java source
code obfuscation containing arrays. Our main proposal is Classes with
restructured array members and obscured member methods for setting, getting
array elements and to get the length of arrays. The class method definition
codes are obscured through index transformation and constant hiding. The
instantiated objects of these classes are used for source code writing. A tool
named JDATATRANS is developed for generating classes and to the best of our
knowledge this is the first tool available for array restructuring, on java
source codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4322</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4322</id><created>2008-07-27</created><authors><author><keyname>Kanter</keyname><forenames>Ido</forenames></author><author><keyname>Shental</keyname><forenames>Ori</forenames></author><author><keyname>Efraim</keyname><forenames>Hadar</forenames></author><author><keyname>Yacov</keyname><forenames>Nadav</forenames></author></authors><title>Carnot in the Information Age: Discrete Symmetric Channels</title><categories>cond-mat.stat-mech cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling communication channels as thermal systems results in Hamiltonians
which are an explicit function of the temperature. The first two authors have
recently generalized the second thermodynamic law to encompass systems with
temperature-dependent energy levels, $dQ=TdS+&lt;d\mathcal{E}/dT&gt;dT$, where
{$&lt;\cdot&gt;$} denotes averaging over the Boltzmann distribution, recomputing the
mutual information and other main properties of the popular Gaussian channel.
Here the mutual information for the binary symmetric channel as well as for the
discrete symmetric channel consisting of 4 input/output (I/O) symbols is
explicitly calculated using the generalized second law of thermodynamics. For
equiprobable I/O the mutual information of the examined channels has a very
simple form, -$\gamma U(\gamma)|_0^\beta$, where $U$ denotes the internal
energy of the channel. We prove that this simple form of the mutual information
governs the class of discrete memoryless symmetric communication channels with
equiprobable I/O symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4325</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4325</id><created>2008-07-28</created><authors><author><keyname>Perra</keyname><forenames>Nicola</forenames><affiliation>Dep of Physics, SLACS-CNR University of Cagliari Italy</affiliation><affiliation>Linkalab, Complex Systems Computational Lab. Cagliari, Italy</affiliation></author><author><keyname>Zlatic</keyname><forenames>Vinko</forenames><affiliation>Centre SMC CNR-INFM, Dip. Fisica, Universita' Sapienza Rome, Italy</affiliation><affiliation>Theor. Physics Div., Rudjer Boskovic Inst., Zagreb Croatia</affiliation></author><author><keyname>Chessa</keyname><forenames>Alessandro</forenames><affiliation>Dep of Physics, SLACS-CNR University of Cagliari Italy</affiliation><affiliation>Linkalab, Complex Systems Computational Lab. Cagliari, Italy</affiliation></author><author><keyname>Conti</keyname><forenames>Claudio</forenames><affiliation>Centre SOFT CNR-INFM, Dip. Fisica, Universita' Sapienza Rome, Italy</affiliation></author><author><keyname>Donato</keyname><forenames>Debora</forenames><affiliation>Yahoo! Research Barcelona Spain</affiliation></author><author><keyname>Caldarelli</keyname><forenames>Guido</forenames><affiliation>Centre SMC CNR-INFM, Dip. Fisica, Universita' Sapienza Rome, Italy</affiliation><affiliation>Linkalab, Complex Systems Computational Lab. Cagliari, Italy</affiliation></author></authors><title>Schroedinger-like PageRank equation and localization in the WWW</title><categories>physics.soc-ph cond-mat.stat-mech cs.IR physics.data-an</categories><comments>5 pages</comments><doi>10.1209/0295-5075/88/48002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The WorldWide Web is one of the most important communication systems we use
in our everyday life. Despite its central role, the growth and the development
of the WWW is not controlled by any central authority. This situation has
created a huge ensemble of connections whose complexity can be fruitfully
described and quantified by network theory. One important application that
allows to sort out the information present in these connections is given by the
PageRank alghorithm. Computation of this quantity is usually made iteratively
with a large use of computational time. In this paper we show that the PageRank
can be expressed in terms of a wave function obeying a Schroedinger-like
equation. In particular the topological disorder given by the unbalance of
outgoing and ingoing links between pages, induces wave function and potential
structuring. This allows to directly localize the pages with the largest score.
Through this new representation we can now compute the PageRank without
iterative techniques. For most of the cases of interest our method is faster
than the original one. Our results also clarify the role of topology in the
diffusion of information within complex networks. The whole approach opens the
possibility to novel techniques inspired by quantum physics for the analysis of
the WWW properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4326</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4326</id><created>2008-07-27</created><authors><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author><author><keyname>Sudakov</keyname><forenames>Benny</forenames></author><author><keyname>Vilenchik</keyname><forenames>Dan</forenames></author></authors><title>On the random satisfiable process</title><categories>math.CO cs.CC math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we suggest a new model for generating random satisfiable k-CNF
formulas. To generate such formulas -- randomly permute all 2^k\binom{n}{k}
possible clauses over the variables x_1, ..., x_n, and starting from the empty
formula, go over the clauses one by one, including each new clause as you go
along if after its addition the formula remains satisfiable. We study the
evolution of this process, namely the distribution over formulas obtained after
scanning through the first m clauses (in the random permutation's order).
  Random processes with conditioning on a certain property being respected are
widely studied in the context of graph properties. This study was pioneered by
Ruci\'nski and Wormald in 1992 for graphs with a fixed degree sequence, and
also by Erd\H{o}s, Suen, and Winkler in 1995 for triangle-free and bipartite
graphs. Since then many other graph properties were studied such as planarity
and H-freeness. Thus our model is a natural extension of this approach to the
satisfiability setting.
  Our main contribution is as follows. For m \geq cn, c=c(k) a sufficiently
large constant, we are able to characterize the structure of the solution space
of a typical formula in this distribution. Specifically, we show that typically
all satisfying assignments are essentially clustered in one cluster, and all
but e^{-\Omega(m/n)} n of the variables take the same value in all satisfying
assignments. We also describe a polynomial time algorithm that finds with high
probability a satisfying assignment for such formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4345</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4345</id><created>2008-07-27</created><authors><author><keyname>Prasetyo</keyname><forenames>Eri</forenames></author><author><keyname>R.</keyname><forenames>Wahyu K.</forenames></author><author><keyname>Prabowo</keyname><forenames>Bumi Prabu</forenames></author></authors><title>Avoider robot design to dim the fire with dt basic mini system</title><categories>cs.RO</categories><comments>5 pages, 5 figures, IES Conference</comments><journal-ref>9 th IES 2007, EEPIS ITS Surabaya</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Avoider robot is mean robot who is designed to avoid the block in around.
Except that, this robot is also added by an addition application to dim the
fire. This robot is made with ultrasonic sensor PING. This sensor is set on the
front, right and left from robot. This sensor is used robot to look for the
right street, so that robot can walk on. After the robot can look for the right
street, next accomplished the robot is looking for the fire in around. And the
next, dim the fire with fan. This robot is made with basic stamp 2
micro-controller. And that micro-controller can be found in dt-basic mini
system module. This robot is made with servo motor on the right and left side,
which is used to movement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4368</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4368</id><created>2008-07-28</created><authors><author><keyname>Papamichail</keyname><forenames>Dimitris</forenames></author><author><keyname>Papamichail</keyname><forenames>Georgios</forenames></author></authors><title>Improved Algorithms for Approximate String Matching (Extended Abstract)</title><categories>cs.DS</categories><comments>10 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The problem of approximate string matching is important in many different
areas such as computational biology, text processing and pattern recognition. A
great effort has been made to design efficient algorithms addressing several
variants of the problem, including comparison of two strings, approximate
pattern identification in a string or calculation of the longest common
subsequence that two strings share.
  We designed an output sensitive algorithm solving the edit distance problem
between two strings of lengths n and m respectively in time
O((s-|n-m|)min(m,n,s)+m+n) and linear space, where s is the edit distance
between the two strings. This worst-case time bound sets the quadratic factor
of the algorithm independent of the longest string length and improves existing
theoretical bounds for this problem. The implementation of our algorithm excels
also in practice, especially in cases where the two strings compared differ
significantly in length. Source code of our algorithm is available at
http://www.cs.miami.edu/\~dimitris/edit_distance
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4417</identifier>
 <datestamp>2009-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4417</id><created>2008-07-28</created><updated>2009-01-15</updated><authors><author><keyname>Sonntag</keyname><forenames>Daniel</forenames></author></authors><title>On Introspection, Metacognitive Control and Augmented Data Mining Live
  Cycles</title><categories>cs.AI</categories><comments>10 pages, 3 figures</comments><acm-class>I.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss metacognitive modelling as an enhancement to cognitive modelling
and computing. Metacognitive control mechanisms should enable AI systems to
self-reflect, reason about their actions, and to adapt to new situations. In
this respect, we propose implementation details of a knowledge taxonomy and an
augmented data mining life cycle which supports a live integration of obtained
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4450</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4450</id><created>2008-07-28</created><authors><author><keyname>Kominers</keyname><forenames>Paul M.</forenames></author><author><keyname>Kominers</keyname><forenames>Scott D.</forenames></author></authors><title>Candy-passing Games on General Graphs, I</title><categories>math.CO cs.DM</categories><comments>2 pages</comments><msc-class>05C35 (Primary); 37B15 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We undertake the first study of the candy-passing game on arbitrary connected
graphs. We obtain a general stabilization result which encompasses the first
author's results (arXiv:0709.2156) for candy-passing games on n-cycles with at
least 3n candies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4478</identifier>
 <datestamp>2008-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4478</id><created>2008-07-28</created><authors><author><keyname>Miravet</keyname><forenames>Carlos</forenames></author><author><keyname>Pascual</keyname><forenames>Luis</forenames></author><author><keyname>Krouch</keyname><forenames>Eloise</forenames></author><author><keyname>del Cura</keyname><forenames>Juan Manuel</forenames></author></authors><title>An Image-Based Sensor System for Autonomous Rendez-Vous with
  Uncooperative Satellites</title><categories>cs.CV cs.AI</categories><comments>12 pages, 13 figures. Presented in the 7th International ESA
  Conference on Guidance, Navigation &amp; Control Systems, Tralee, Ireland, 2008</comments><acm-class>I.4.3; I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper are described the image processing algorithms developed by
SENER, Ingenieria y Sistemas to cope with the problem of image-based,
autonomous rendez-vous (RV) with an orbiting satellite. The methods developed
have a direct application in the OLEV (Orbital Life Extension Extension
Vehicle) mission. OLEV is a commercial mission under development by a
consortium formed by Swedish Space Corporation, Kayser-Threde and SENER, aimed
to extend the operational life of geostationary telecommunication satellites by
supplying them control, navigation and guidance services. OLEV is planned to
use a set of cameras to determine the angular position and distance to the
client satellite during the complete phases of rendez-vous and docking, thus
enabling the operation with satellites not equipped with any specific
navigational aid to provide support during the approach. The ability to operate
with un-equipped client satellites significantly expands the range of
applicability of the system under development, compared to other competing
video technologies already tested in previous spatial missions, such as the
ones described here below.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4479</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4479</id><created>2008-07-28</created><authors><author><keyname>Ascasibar</keyname><forenames>Yago</forenames></author></authors><title>FiEstAS sampling -- a Monte Carlo algorithm for multidimensional
  numerical integration</title><categories>astro-ph cs.DS</categories><comments>18 pages, 3 figures, submitted to Comp. Phys. Comm</comments><doi>10.1016/j.cpc.2008.07.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new algorithm for Monte Carlo integration, based on
the Field Estimator for Arbitrary Spaces (FiEstAS). The algorithm is discussed
in detail, and its performance is evaluated in the context of Bayesian
analysis, with emphasis on multimodal distributions with strong parameter
degeneracies. Source code is available upon request.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4494</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4494</id><created>2008-07-28</created><updated>2011-05-25</updated><authors><author><keyname>McEwen</keyname><forenames>J. D.</forenames></author></authors><title>Fast, exact (but unstable) spin spherical harmonic transforms</title><categories>astro-ph cs.IT math.IT</categories><comments>15 pages, 5 figures, replaced to match version accepted by ARJP</comments><journal-ref>All Res.J.Phys.1:4-18,2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications data are measured or defined on a spherical manifold;
spherical harmonic transforms are then required to access the frequency content
of the data. We derive algorithms to perform forward and inverse spin spherical
harmonic transforms for functions of arbitrary spin number. These algorithms
involve recasting the spin transform on the two-sphere S^2 as a Fourier
transform on the two-torus T^2. Fast Fourier transforms are then used to
compute Fourier coefficients, which are related to spherical harmonic
coefficients through a linear transform. By recasting the problem as a Fourier
transform on the torus we appeal to the usual Shannon sampling theorem to
develop spherical harmonic transforms that are theoretically exact for
band-limited functions, thereby providing an alternative sampling theorem on
the sphere. The computational complexity of our forward and inverse spin
spherical harmonic transforms scale as O(L^3) for any arbitrary spin number,
where L is the harmonic band-limit of the spin function on the sphere.
Numerical experiments are performed and unfortunately the forward transform is
found to be unstable for band-limits above L~32. The instability is due to the
poorly conditioned linear system relating Fourier and spherical harmonic
coefficients. The inverse transform is expected to be stable, although it is
not possible to verify this hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4548</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4548</id><created>2008-07-28</created><authors><author><keyname>Simeone</keyname><forenames>O.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Gunduz</keyname><forenames>D.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. V.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Goldsmith</keyname><forenames>A.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>S.</forenames><affiliation>Shitz</affiliation></author></authors><title>Compound Multiple Access Channels with Partial Cooperation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-user discrete memoryless compound multiple access channel with a common
message and conferencing decoders is considered. The capacity region is
characterized in the special cases of physically degraded channels and
unidirectional cooperation, and achievable rate regions are provided for the
general case. The results are then extended to the corresponding Gaussian
model. In the Gaussian setup, the provided achievable rates are shown to lie
within some constant number of bits from the boundary of the capacity region in
several special cases. An alternative model, in which the encoders are
connected by conferencing links rather than having a common message, is studied
as well, and the capacity region for this model is also determined for the
cases of physically degraded channels and unidirectional cooperation. Numerical
results are also provided to obtain insights about the potential gains of
conferencing at the decoders and encoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4580</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4580</id><created>2008-07-29</created><authors><author><keyname>Kim</keyname><forenames>Yi-Reun</forenames></author><author><keyname>Whang</keyname><forenames>Kyu-Young</forenames></author><author><keyname>Kim</keyname><forenames>Min-Soo</forenames></author><author><keyname>Song</keyname><forenames>Il-Yeol</forenames></author></authors><title>A Logical Model and Data Placement Strategies for MEMS Storage Devices</title><categories>cs.DB</categories><comments>37 pages</comments><doi>10.1587/transinf.E92.D.2218</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MEMS storage devices are new non-volatile secondary storages that have
outstanding advantages over magnetic disks. MEMS storage devices, however, are
much different from magnetic disks in the structure and access characteristics.
They have thousands of heads called probe tips and provide the following two
major access facilities: (1) flexibility: freely selecting a set of probe tips
for accessing data, (2) parallelism: simultaneously reading and writing data
with the set of probe tips selected. Due to these characteristics, it is
nontrivial to find data placements that fully utilize the capability of MEMS
storage devices. In this paper, we propose a simple logical model called the
Region-Sector (RS) model that abstracts major characteristics affecting data
retrieval performance, such as flexibility and parallelism, from the physical
MEMS storage model. We also suggest heuristic data placement strategies based
on the RS model and derive new data placements for relational data and
two-dimensional spatial data by using those strategies. Experimental results
show that the proposed data placements improve the data retrieval performance
by up to 4.0 times for relational data and by up to 4.8 times for
two-dimensional spatial data of approximately 320 Mbytes compared with those of
existing data placements. Further, these improvements are expected to be more
marked as the database size grows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4581</identifier>
 <datestamp>2009-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4581</id><created>2008-07-29</created><updated>2009-03-30</updated><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Mishali</keyname><forenames>Moshe</forenames></author></authors><title>Robust Recovery of Signals From a Structured Union of Subspaces</title><categories>nlin.CG cs.IT math.IT nlin.SI</categories><comments>5 figures. 30 pages. This work has been submitted to the IEEE for
  possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional sampling theories consider the problem of reconstructing an
unknown signal $x$ from a series of samples. A prevalent assumption which often
guarantees recovery from the given measurements is that $x$ lies in a known
subspace. Recently, there has been growing interest in nonlinear but structured
signal models, in which $x$ lies in a union of subspaces. In this paper we
develop a general framework for robust and efficient recovery of such signals
from a given set of samples. More specifically, we treat the case in which $x$
lies in a sum of $k$ subspaces, chosen from a larger set of $m$ possibilities.
The samples are modelled as inner products with an arbitrary set of sampling
functions. To derive an efficient and robust recovery algorithm, we show that
our problem can be formulated as that of recovering a block-sparse vector whose
non-zero elements appear in fixed blocks. We then propose a mixed
$\ell_2/\ell_1$ program for block sparse recovery. Our main result is an
equivalence condition under which the proposed convex algorithm is guaranteed
to recover the original signal. This result relies on the notion of block
restricted isometry property (RIP), which is a generalization of the standard
RIP used extensively in the context of compressed sensing. Based on RIP we also
prove stability of our approach in the presence of noise and modelling errors.
  A special case of our framework is that of recovering multiple measurement
vectors (MMV) that share a joint sparsity pattern. Adapting our results to this
context leads to new MMV recovery methods as well as equivalence conditions
under which the entire set can be determined efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4582</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4582</id><created>2008-07-29</created><authors><author><keyname>Carroll</keyname><forenames>Douglas E.</forenames></author><author><keyname>Goel</keyname><forenames>Ashish</forenames></author></authors><title>Lower Bounds for Embedding into Distributions over Excluded Minor Graph
  Families</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was shown recently by Fakcharoenphol et al that arbitrary finite metrics
can be embedded into distributions over tree metrics with distortion O(log n).
It is also known that this bound is tight since there are expander graphs which
cannot be embedded into distributions over trees with better than Omega(log n)
distortion.
  We show that this same lower bound holds for embeddings into distributions
over any minor excluded family. Given a family of graphs F which excludes minor
M where |M|=k, we explicitly construct a family of graphs with treewidth-(k+1)
which cannot be embedded into a distribution over F with better than Omega(log
n) distortion. Thus, while these minor excluded families of graphs are more
expressive than trees, they do not provide asymptotically better approximations
in general. An important corollary of this is that graphs of treewidth-k cannot
be embedded into distributions over graphs of treewidth-(k-3) with distortion
less than Omega(log n).
  We also extend a result of Alon et al by showing that for any k, planar
graphs cannot be embedded into distributions over treewidth-k graphs with
better than Omega(log n) distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4609</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4609</id><created>2008-07-29</created><authors><author><keyname>Mutiara</keyname><forenames>A. B.</forenames></author></authors><title>Analisis Kinerja Sistem Cluster Terhadapa Aplikasi Simulasi Dinamika
  Molekular NAMD Memanfaatkan Pustaka CHARM++</title><categories>cs.DC</categories><comments>8 pages, 3 Figures (in Indonesian)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tingkat kompleksitas dari program simulasi dinamika molekular membutuhkan
mesin pemroses dengan kemampuan yang sangat besar. Mesin-mesin paralel terbukti
memiliki potensi untuk menjawab tantangan komputasi ini. Untuk memanfaatkan
potensi ini secara maksimal, diperlukan suatu program paralel dengan tingkat
efisiensi, efektifitas, skalabilitas, dan ekstensibilitas yang maksimal pula.
Program NAMD yang dibahas pada penulisan ini dianggap mampu untuk memenuhi
semua kriteria yang diinginkan. Program ini dirancang dengan
mengimplementasikan pustaka Charm++ untuk pembagian tugas perhitungan secara
paralel. NAMD memiliki sistem automatic load balancing secara periodik yang
cerdas, sehingga dapat memaksimalkan penggunaan kemampuan mesin yang tersedia.
Program ini juga dirancang secara modular, sehingga dapat dimodifikasi dan
ditambah dengan sangat mudah. NAMD menggunakan banyak kombinasi algoritma
perhitungan dan tehnik-tehnik numerik lainnya dalam melakukan tugasnya. NAMD
2.5 mengimplementasikan semua tehnik dan persamaan perhitungan yang digunakan
dalam dunia simulasi dinamika molekular saat ini. NAMD dapat berjalan diatas
berbagai mesin paralel termasuk arsitektur cluster, dengan hasil speedup yang
mengejutkan. Tulisan ini akan menjelaskan dan membuktikan kemampuan NAMD secara
paralel diatas lima buah mesin cluster. Penulisan ini juga akan memaparkan
kinerja NAMD pada beberapa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4618</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4618</id><created>2008-07-29</created><authors><author><keyname>Kuhn</keyname><forenames>Tobias</forenames></author></authors><title>AceWiki: A Natural and Expressive Semantic Wiki</title><categories>cs.HC cs.AI</categories><comments>To be published as: Proceedings of Semantic Web User Interaction at
  CHI 2008: Exploring HCI Challenges, CEUR Workshop Proceedings</comments><acm-class>H.5.2; I.2.4</acm-class><journal-ref>In Proceedings of the Fifth International Workshop on Semantic Web
  User Interaction (SWUI 2008), CEUR Workshop Proceedings, Volume 543, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present AceWiki, a prototype of a new kind of semantic wiki using the
controlled natural language Attempto Controlled English (ACE) for representing
its content. ACE is a subset of English with a restricted grammar and a formal
semantics. The use of ACE has two important advantages over existing semantic
wikis. First, we can improve the usability and achieve a shallow learning
curve. Second, ACE is more expressive than the formal languages of existing
semantic wikis. Our evaluation shows that people who are not familiar with the
formal foundations of the Semantic Web are able to deal with AceWiki after a
very short learning phase and without the help of an expert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4619</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4619</id><created>2008-07-29</created><authors><author><keyname>Shaiju</keyname><forenames>A. J.</forenames></author><author><keyname>Petersen</keyname><forenames>I. R.</forenames></author><author><keyname>James</keyname><forenames>M. R.</forenames></author></authors><title>Guaranteed Cost LQG Control of Uncertain Linear Quantum Stochastic
  Systems</title><categories>quant-ph cs.SY math.OC</categories><comments>15 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we formulate and solve a guaranteed cost control problem for a
class of uncertain linear stochastic quantum systems. For these quantum
systems, a connection with an associated classical (non-quantum) system is
first established. Using this connection, the desired guaranteed cost results
are established. The theory presented is illustrated using an example from
quantum optics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4620</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4620</id><created>2008-07-29</created><authors><author><keyname>Koch</keyname><forenames>Christoph</forenames></author></authors><title>A Compositional Query Algebra for Second-Order Logic and Uncertain
  Databases</title><categories>cs.DB cs.LO</categories><comments>22 pages, 1 figure</comments><acm-class>H.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  World-set algebra is a variable-free query language for uncertain databases.
It constitutes the core of the query language implemented in MayBMS, an
uncertain database system. This paper shows that world-set algebra captures
exactly second-order logic over finite structures, or equivalently, the
polynomial hierarchy. The proofs also imply that world-set algebra is closed
under composition, a previously open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4623</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4623</id><created>2008-07-29</created><authors><author><keyname>Kuhn</keyname><forenames>Tobias</forenames></author></authors><title>AceWiki: Collaborative Ontology Management in Controlled Natural
  Language</title><categories>cs.HC cs.AI</categories><acm-class>H.5.2; I.2.4</acm-class><journal-ref>In Proceedings of the 3rd Semantic Wiki Workshop, CEUR Workshop
  Proceedings, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AceWiki is a prototype that shows how a semantic wiki using controlled
natural language - Attempto Controlled English (ACE) in our case - can make
ontology management easy for everybody. Sentences in ACE can automatically be
translated into first-order logic, OWL, or SWRL. AceWiki integrates the OWL
reasoner Pellet and ensures that the ontology is always consistent. Previous
results have shown that people with no background in logic are able to add
formal knowledge to AceWiki without being instructed or trained in advance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4626</identifier>
 <datestamp>2008-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4626</id><created>2008-07-29</created><updated>2008-12-09</updated><authors><author><keyname>Khot</keyname><forenames>Subhash</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>Approximate kernel clustering</title><categories>cs.DS cs.CC math.FA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the kernel clustering problem we are given a large $n\times n$ positive
semi-definite matrix $A=(a_{ij})$ with $\sum_{i,j=1}^na_{ij}=0$ and a small
$k\times k$ positive semi-definite matrix $B=(b_{ij})$. The goal is to find a
partition $S_1,...,S_k$ of $\{1,... n\}$ which maximizes the quantity $$
\sum_{i,j=1}^k (\sum_{(i,j)\in S_i\times S_j}a_{ij})b_{ij}. $$ We study the
computational complexity of this generic clustering problem which originates in
the theory of machine learning. We design a constant factor polynomial time
approximation algorithm for this problem, answering a question posed by Song,
Smola, Gretton and Borgwardt. In some cases we manage to compute the sharp
approximation threshold for this problem assuming the Unique Games Conjecture
(UGC). In particular, when $B$ is the $3\times 3$ identity matrix the UGC
hardness threshold of this problem is exactly $\frac{16\pi}{27}$. We present
and study a geometric conjecture of independent interest which we show would
imply that the UGC threshold when $B$ is the $k\times k$ identity matrix is
$\frac{8\pi}{9}(1-\frac{1}{k})$ for every $k\ge 3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4655</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4655</id><created>2008-07-29</created><authors><author><keyname>Kominers</keyname><forenames>Paul M.</forenames></author><author><keyname>Kominers</keyname><forenames>Scott D.</forenames></author></authors><title>Candy-passing Games on General Graphs, II</title><categories>math.CO cs.DM</categories><comments>3 pages</comments><msc-class>05C35, 05C85, 68Q25 (Primary); 37B15, 68R10, 68Q80 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new proof that any candy-passing game on a graph G with at least
4|E(G)|-|V(G)| candies stabilizes. (This result was first proven in
arXiv:0807.4450.) Unlike the prior literature on candy-passing games, we use
methods from the general theory of chip-firing games which allow us to obtain a
polynomial bound on the number of rounds before stabilization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4656</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4656</id><created>2008-07-29</created><authors><author><keyname>Zhang</keyname><forenames>Ruifeng</forenames><affiliation>CITI, INRIA Rh&#xf4;ne-Alpes / CITI</affiliation></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames><affiliation>CITI, INRIA Rh&#xf4;ne-Alpes / CITI</affiliation></author><author><keyname>Jaffr&#xe8;s-Runser</keyname><forenames>Katia</forenames><affiliation>CITI, WNET</affiliation></author></authors><title>Energy-delay bounds analysis in wireless multi-hop networks with
  unreliable radio links</title><categories>cs.NI</categories><proxy>ccsd inria-00306697</proxy><report-no>RR-6598</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficiency and transmission delay are very important parameters for
wireless multi-hop networks. Previous works that study energy efficiency and
delay are based on the assumption of reliable links. However, the unreliability
of the channel is inevitable in wireless multi-hop networks. This paper
investigates the trade-off between the energy consumption and the end-to-end
delay of multi-hop communications in a wireless network using an unreliable
link model. It provides a closed form expression of the lower bound on the
energy-delay trade-off for different channel models (AWGN, Raleigh flat fading
and Nakagami block-fading) in a linear network. These analytical results are
also verified in 2-dimensional Poisson networks using simulations. The main
contribution of this work is the use of a probabilistic link model to define
the energy efficiency of the system and capture the energy-delay trade-offs.
Hence, it provides a more realistic lower bound on both the energy efficiency
and the energy-delay trade-off since it does not restrict the study to the set
of perfect links as proposed in earlier works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4671</identifier>
 <datestamp>2008-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4671</id><created>2008-07-29</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames><affiliation>Sogang University</affiliation></author></authors><title>Codes Associated with $O^+(2n,2^r)$ and Power Moments of Kloosterman
  Sums</title><categories>math.NT cs.IT math.IT</categories><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct three binary linear codes $C(SO^+(2,q))$,
$C(O^+(2,q))$, $C(SO^+(4,q))$, respectively associated with the orthogonal
groups $SO^+(2,q)$, $O^+(2,q)$, $SO^+(4,q)$, with $q$ powers of two. Then we
obtain recursive formulas for the power moments of Kloosterman and
2-dimensional Kloosterman sums in terms of the frequencies of weights in the
codes. This is done via Pless power moment identity and by utilizing the
explicit expressions of Gauss sums for the orthogonal groups. We emphasize
that, when the recursive formulas for the power moments of Kloosterman sums are
compared, the present one is computationally more effective than the previous
one constructed from the special linear group $SL(2,q)$. We illustrate our
results with some examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4680</identifier>
 <datestamp>2008-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4680</id><created>2008-07-29</created><updated>2008-10-19</updated><authors><author><keyname>Miguel</keyname><forenames>Sergio</forenames></author></authors><title>Hacia una teoria de unificacion para los comportamientos cognitivos</title><categories>cs.AI</categories><comments>63 pages, 4 figures, Spanish, mistakes erased</comments><acm-class>I.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Each cognitive science tries to understand a set of cognitive behaviors. The
structuring of knowledge of this nature's aspect is far from what it can be
expected about a science. Until now universal standard consistently describing
the set of cognitive behaviors has not been found, and there are many questions
about the cognitive behaviors for which only there are opinions of members of
the scientific community. This article has three proposals. The first proposal
is to raise to the scientific community the necessity of unified the cognitive
behaviors. The second proposal is claim the application of the Newton's
reasoning rules about nature of his book, Philosophiae Naturalis Principia
Mathematica, to the cognitive behaviors. The third is to propose a scientific
theory, currently developing, that follows the rules established by Newton to
make sense of nature, and could be the theory to explain all the cognitive
behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4701</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4701</id><created>2008-07-29</created><authors><author><keyname>Sparavigna</keyname><forenames>A.</forenames></author><author><keyname>Marazzato</keyname><forenames>R.</forenames></author></authors><title>An image processing analysis of skin textures</title><categories>cs.CV</categories><journal-ref>Skin Research and Technology, Volume 16 Issue 2, Pages 161 - 167,
  2010</journal-ref><doi>10.1111/j.1600-0846.2009.00413.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colour and coarseness of skin are visually different. When image processing
is involved in the skin analysis, it is important to quantitatively evaluate
such differences using texture features. In this paper, we discuss a texture
analysis and measurements based on a statistical approach to the pattern
recognition. Grain size and anisotropy are evaluated with proper diagrams. The
possibility to determine the presence of pattern defects is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4753</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4753</id><created>2008-07-30</created><authors><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Counterexamples to the maximal p-norm multiplicativity conjecture for
  all p &gt; 1</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>Merger of arXiv:0707.0402 and arXiv:0707.3291 containing new and
  improved analysis of counterexamples. 17 pages</comments><journal-ref>Comm. Math. Phys. 284(1):263-280, 2008.</journal-ref><doi>10.1007/s00220-008-0624-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For all p &gt; 1, we demonstrate the existence of quantum channels with
non-multiplicative maximal output p-norms. Equivalently, for all p &gt;1, the
minimum output Renyi entropy of order p of a quantum channel is not additive.
The violations found are large; in all cases, the minimum output Renyi entropy
of order p for a product channel need not be significantly greater than the
minimum output entropy of its individual factors. Since p=1 corresponds to the
von Neumann entropy, these counterexamples demonstrate that if the additivity
conjecture of quantum information theory is true, it cannot be proved as a
consequence of any channel-independent guarantee of maximal p-norm
multiplicativity. We also show that a class of channels previously studied in
the context of approximate encryption lead to counterexamples for all p &gt; 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4770</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4770</id><created>2008-07-29</created><updated>2010-01-18</updated><authors><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Liew</keyname><forenames>Soung-Chang</forenames></author></authors><title>Channel Coding and Decoding in a Relay System Operated with Physical
  layer Network Coding</title><categories>cs.NI cs.IT math.IT</categories><journal-ref>IEEE journal on selection area in communications, Jun. 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physical-layer Network Coding (PNC) can significantly improve the throughput
of wireless two way relay channel (TWRC) by allowing the two end nodes to
transmit messages to the relay simultaneously. To achieve reliable
communication, channel coding could be applied on top of PNC. This paper
investigates link-by-link channel-coded PNC, in which a critical process at the
relay is to transform the superimposed channel-coded packets received from the
two end nodes plus noise, Y3=X1+X2+W3, to the network-coded combination of the
source packets, S1 XOR S2 . This is in distinct to the traditional
multiple-access problem, in which the goal is to obtain S1 and S2 separately.
The transformation from Y3 to (S1 XOR S2) is referred to as the
Channel-decoding-Network-Coding process (CNC) in that it involves both channel
decoding and network coding operations. A contribution of this paper is the
insight that in designing CNC, we should first (i) channel-decode Y3 to the
superimposed source symbols S1+S2 before (ii) transforming S1+S2 to the
network-coded packets (S1 XOR S2) . Compared with previously proposed
strategies for CNC, this strategy reduces the channel-coding network-coding
mismatch. It is not obvious, however, that an efficient decoder for step (i)
exists. A second contribution of this paper is to provide an explicit
construction of such a decoder based on the use of the Repeat Accumulate (RA)
code. Specifically, we redesign the belief propagation algorithm of the RA code
for traditional point-to-point channel to suit the need of the PNC
multiple-access channel. Simulation results show that our new scheme
outperforms the previously proposed schemes significantly in terms of BER
without added complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4846</identifier>
 <datestamp>2009-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4846</id><created>2008-07-30</created><updated>2009-03-14</updated><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author></authors><title>Error-Correcting Codes in Projective Spaces via Rank-Metric Codes and
  Ferrers Diagrams</title><categories>cs.IT math.IT</categories><comments>Revised for IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coding in the projective space has received recently a lot of attention due
to its application in network coding. Reduced row echelon form of the linear
subspaces and Ferrers diagram can play a key role for solving coding problems
in the projective space. In this paper we propose a method to design
error-correcting codes in the projective space. We use a multilevel approach to
design our codes. First, we select a constant weight code. Each codeword
defines a skeleton of a basis for a subspace in reduced row echelon form. This
skeleton contains a Ferrers diagram on which we design a rank-metric code. Each
such rank-metric code is lifted to a constant dimension code. The union of
these codes is our final constant dimension code. In particular the codes
constructed recently by Koetter and Kschischang are a subset of our codes. The
rank-metric codes used for this construction form a new class of rank-metric
codes. We present a decoding algorithm to the constructed codes in the
projective space. The efficiency of the decoding depends on the efficiency of
the decoding for the constant weight codes and the rank-metric codes. Finally,
we use puncturing on our final constant dimension codes to obtain large codes
in the projective space which are not constant dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4881</identifier>
 <datestamp>2008-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4881</id><created>2008-07-23</created><authors><author><keyname>Gheryani</keyname><forenames>Mabruk</forenames></author><author><keyname>Wu</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Shayan</keyname><forenames>Yousef R.</forenames></author></authors><title>Capacity and Performance of Adaptive MIMO System Based on Beam-Nulling</title><categories>cs.IT math.IT</categories><comments>15 pages, 11 figures</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a scheme called &quot;beam-nulling&quot; for MIMO adaptation.
In the beam-nulling scheme, the eigenvector of the weakest subchannel is fed
back and then signals are sent over a generated subspace orthogonal to the
weakest subchannel. Theoretical analysis and numerical results show that the
capacity of beam-nulling is closed to the optimal water-filling at medium SNR.
Additionally, signal-to-interference-plus-noise ratio (SINR) of MMSE receiver
is derived for beam-nulling. Then the paper presents the associated average
bit-error rate (BER) of beam-nulling numerically which is verified by
simulation. Simulation results are also provided to compare beam-nulling with
beamforming. To improve performance further, beam-nulling is concatenated with
linear dispersion code. Simulation results are also provided to compare the
concatenated beam-nulling scheme with the beamforming scheme at the same data
rate. Additionally, the existing beamforming and new proposed beam-nulling can
be extended if more than one eigenvector is available at the transmitter. The
new extended schemes are called multi-dimensional (MD) beamforming and MD
beam-nulling. Theoretical analysis and numerical results in terms of capacity
are also provided to evaluate the new extended schemes. Simulation results show
that the MD scheme with LDC can outperform the MD scheme with STBC
significantly when the data rate is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4912</identifier>
 <datestamp>2008-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4912</id><created>2008-07-30</created><authors><author><keyname>Kienle</keyname><forenames>Holger M.</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Hausi A.</forenames></author></authors><title>Research Challenges in Management and Compliance of Policies on the Web</title><categories>cs.CY cs.SE</categories><comments>10 pages, 1 figure, 10th IEEE International Symposium on Web Site
  Evolution (WSE 2008), Beijing, China, http://wse2008.fbk.eu/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we argue that policies are an increasing concern for
organizations that are operating a web site. Examples of policies that are
relevant in the domain of the web address issues such as privacy of personal
data, accessibility for the disabled, user conduct, e-commerce, and
intellectual property. Web site policies--and the overarching concept of web
site governance--are cross-cutting concerns that have to be addressed and
implemented at different levels (e.g., policy documents, legal statements,
business processes, contracts, auditing, and software systems). For web sites,
policies are also reflected in the legal statements that the web site posts,
and in the behavior and features that the web site offers to its users. Both
policies and software tend to evolve independently, but at the same time they
both have to be kept in sync. This is a practical challenge for operators of
web sites that is poorly addressed right now and is, we believe, a promising
avenue for future research. In this paper, we discuss various challenges that
policy poses for web sites with an emphasis on privacy and data protection and
identify open issues for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4995</identifier>
 <datestamp>2008-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4995</id><created>2008-07-31</created><authors><author><keyname>Lee</keyname><forenames>Kwankyu</forenames></author><author><keyname>O'Sullivan</keyname><forenames>Michael E.</forenames></author></authors><title>Algebraic Soft-Decision Decoding of Hermitian Codes</title><categories>cs.IT math.IT</categories><comments>17 pages, submitted to IEEE Transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algebraic soft-decision decoder for Hermitian codes is presented. We apply
Koetter and Vardy's soft-decision decoding framework, now well established for
Reed-Solomon codes, to Hermitian codes. First we provide an algebraic
foundation for soft-decision decoding. Then we present an interpolation
algorithm finding the Q-polynomial that plays a key role in the decoding. With
some simulation results, we compare performances of the algebraic soft-decision
decoders for Hermitian codes and Reed-Solomon codes, favorable to the former.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.5091</identifier>
 <datestamp>2008-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.5091</id><created>2008-07-31</created><authors><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Willsky</keyname><forenames>Alan</forenames></author></authors><title>Message-passing for Maximum Weight Independent Set</title><categories>cs.AI cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the use of message-passing algorithms for the problem of
finding the max-weight independent set (MWIS) in a graph. First, we study the
performance of the classical loopy max-product belief propagation. We show that
each fixed point estimate of max-product can be mapped in a natural way to an
extreme point of the LP polytope associated with the MWIS problem. However,
this extreme point may not be the one that maximizes the value of node weights;
the particular extreme point at final convergence depends on the initialization
of max-product. We then show that if max-product is started from the natural
initialization of uninformative messages, it always solves the correct LP -- if
it converges. This result is obtained via a direct analysis of the iterative
algorithm, and cannot be obtained by looking only at fixed points.
  The tightness of the LP relaxation is thus necessary for max-product
optimality, but it is not sufficient. Motivated by this observation, we show
that a simple modification of max-product becomes gradient descent on (a
convexified version of) the dual of the LP, and converges to the dual optimum.
We also develop a message-passing algorithm that recovers the primal MWIS
solution from the output of the descent algorithm. We show that the MWIS
estimate obtained using these two algorithms in conjunction is correct when the
graph is bipartite and the MWIS is unique.
  Finally, we show that any problem of MAP estimation for probability
distributions over finite domains can be reduced to an MWIS problem. We believe
this reduction will yield new insights and algorithms for MAP estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.5111</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.5111</id><created>2008-07-31</created><updated>2008-09-22</updated><authors><author><keyname>Sarma</keyname><forenames>Atish Das</forenames></author><author><keyname>Deshpande</keyname><forenames>Amit</forenames></author><author><keyname>Kannan</keyname><forenames>Ravi</forenames></author></authors><title>Finding Dense Subgraphs in G(n,1/2)</title><categories>cs.DS</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the largest clique is a notoriously hard problem, even on random
graphs. It is known that the clique number of a random graph G(n,1/2) is almost
surely either k or k+1, where k = 2log n - 2log(log n) - 1. However, a simple
greedy algorithm finds a clique of size only (1+o(1))log n, with high
probability, and finding larger cliques -- that of size even (1+ epsilon)log n
-- in randomized polynomial time has been a long-standing open problem. In this
paper, we study the following generalization: given a random graph G(n,1/2),
find the largest subgraph with edge density at least (1-delta). We show that a
simple modification of the greedy algorithm finds a subset of 2log n vertices
whose induced subgraph has edge density at least 0.951, with high probability.
To complement this, we show that almost surely there is no subset of 2.784log n
vertices whose induced subgraph has edge density 0.951 or more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.5120</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.5120</id><created>2008-07-31</created><updated>2008-09-30</updated><authors><author><keyname>Dirnstorfer</keyname><forenames>Stefan</forenames></author><author><keyname>Grau</keyname><forenames>Andreas J.</forenames></author></authors><title>Accelerated Option Pricing in Multiple Scenarios</title><categories>cs.CE</categories><comments>17 pages: Page 17, References corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper covers a massive acceleration of Monte-Carlo based pricing method
for financial products and financial derivatives. The method is applicable in
risk management settings, where a financial product has to be priced under a
number of potential future scenarios. Instead of starting a separate nested
Monte Carlo simulation for each scenario under consideration, the new method
covers the utilization of very few representative nested simulations and
estimating the product prices at each scenario by a smoothing method based on
the state-space. This smoothing technique can be e.g. non-parametric regression
or kernel smoothing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0012</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0012</id><created>2008-07-31</created><authors><author><keyname>Caticha</keyname><forenames>Ariel</forenames></author></authors><title>Lectures on Probability, Entropy, and Statistical Physics</title><categories>physics.data-an cond-mat.stat-mech cs.IT math.IT math.ST physics.gen-ph stat.TH</categories><comments>170 pages. Invited lectures at MaxEnt 2008, the 28th International
  Workshop on Bayesian Inference and Maximum Entropy Methods in Science and
  Engineering (July 8-13, 2008, Boraceia Beach, Sao Paulo, Brazil)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These lectures deal with the problem of inductive inference, that is, the
problem of reasoning under conditions of incomplete information. Is there a
general method for handling uncertainty? Or, at least, are there rules that
could in principle be followed by an ideally rational mind when discussing
scientific matters? What makes one statement more plausible than another? How
much more plausible? And then, when new information is acquired how do we
change our minds? Or, to put it differently, are there rules for learning? Are
there rules for processing information that are objective and consistent? Are
they unique? And, come to think of it, what, after all, is information? It is
clear that data contains or conveys information, but what does this precisely
mean? Can information be conveyed in other ways? Is information physical? Can
we measure amounts of information? Do we need to? Our goal is to develop the
main tools for inductive inference--probability and entropy--from a thoroughly
Bayesian point of view and to illustrate their use in physics with examples
borrowed from the foundations of classical statistical physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0023</identifier>
 <datestamp>2008-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0023</id><created>2008-07-31</created><authors><author><keyname>Pataki</keyname><forenames>Gabor</forenames></author><author><keyname>Tural</keyname><forenames>Mustafa</forenames></author></authors><title>Branching proofs of infeasibility in low density subset sum problems</title><categories>cs.CC cs.CR math.CO math.OC</categories><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the subset sum problem has a polynomial time computable
certificate of infeasibility for all $a$ weight vectors with density at most
$1/(2n)$ and for almost all integer right hand sides. The certificate is
branching on a hyperplane, i.e. by a methodology dual to the one explored by
Lagarias and Odlyzko; Frieze; Furst and Kannan; and Coster et. al.
  The proof has two ingredients. We first prove that a vector that is near
parallel to $a$ is a suitable branching direction, regardless of the density.
Then we show that for a low density $a$ such a near parallel vector can be
computed using diophantine approximation, via a methodology introduced by Frank
and Tardos.
  We also show that there is a small number of long intervals whose disjoint
union covers the integer right hand sides, for which the infeasibility is
proven by branching on the above hyperplane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0036</identifier>
 <datestamp>2008-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0036</id><created>2008-07-31</created><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Kotecha</keyname><forenames>Jayesh H.</forenames></author><author><keyname>Sayeed</keyname><forenames>Akbar M.</forenames></author></authors><title>Why Does a Kronecker Model Result in Misleading Capacity Estimates?</title><categories>cs.IT math.IT</categories><comments>39 pages, 5 figures, under review with IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many recent works that study the performance of multi-input multi-output
(MIMO) systems in practice assume a Kronecker model where the variances of the
channel entries, upon decomposition on to the transmit and the receive
eigen-bases, admit a separable form. Measurement campaigns, however, show that
the Kronecker model results in poor estimates for capacity. Motivated by these
observations, a channel model that does not impose a separable structure has
been recently proposed and shown to fit the capacity of measured channels
better. In this work, we show that this recently proposed modeling framework
can be viewed as a natural consequence of channel decomposition on to its
canonical coordinates, the transmit and/or the receive eigen-bases. Using tools
from random matrix theory, we then establish the theoretical basis behind the
Kronecker mismatch at the low- and the high-SNR extremes: 1) Sparsity of the
dominant statistical degrees of freedom (DoF) in the true channel at the
low-SNR extreme, and 2) Non-regularity of the sparsity structure (disparities
in the distribution of the DoF across the rows and the columns) at the high-SNR
extreme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0037</identifier>
 <datestamp>2009-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0037</id><created>2008-07-31</created><updated>2009-07-13</updated><authors><author><keyname>Lo</keyname><forenames>Caleb K.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>An Energy-Based Comparison of Long-Hop and Short-Hop Routing in MIMO
  Networks</title><categories>cs.IT math.IT</categories><comments>27 pages, 12 figures, submitted to IEEE Transactions on Vehicular
  Technology in March 2009, revised in July 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of selecting either routes that consist of
long hops or routes that consist of short hops in a network of multiple-antenna
nodes, where each transmitting node employs spatial multiplexing. This
distance-dependent route selection problem is approached from the viewpoint of
energy efficiency, where a route is selected with the objective of minimizing
the transmission energy consumed while satisfying a target outage criterion at
the final destination. Deterministic line networks and two-dimensional random
networks are considered. It is shown that when 1) the number of hops traversed
between the source and destination grows large or 2) when the target success
probability approaches one or 3) when the number of transmit and/or receive
antennas grows large, short-hop routing requires less energy than long-hop
routing. It is also shown that if both routing strategies are subject to the
same delay constraint, long-hop routing requires less energy than short-hop
routing as the target success probability approaches one. In addition,
numerical analysis indicates that given loose outage constraints, only a small
number of transmit antennas are needed for short-hop routing to have its
maximum advantage over long-hop routing, while given stringent outage
constraints, the advantage of short-hop over long-hop routing always increases
with additional transmit antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0055</identifier>
 <datestamp>2008-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0055</id><created>2008-08-01</created><authors><author><keyname>Passalacqua</keyname><forenames>Olivier</forenames><affiliation>LISTIC</affiliation></author><author><keyname>Benoit</keyname><forenames>Eric</forenames><affiliation>LISTIC, LAMII</affiliation></author><author><keyname>Huget</keyname><forenames>Marc-Philippe</forenames><affiliation>LISTIC</affiliation></author><author><keyname>Moreaux</keyname><forenames>Patrice</forenames><affiliation>LISTIC</affiliation></author></authors><title>Integrating OPC Data into GSN Infrastructures</title><categories>cs.SE</categories><proxy>ccsd hal-00308566</proxy><journal-ref>IADIS International Conference APPLIED COMPUTING 2008, Algarve :
  Portugal (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and the implementation of an interface
software component between OLE for Process Control (OPC) formatted data and the
Global Sensor Network (GSN) framework for management of data from sensors. This
interface, named wrapper in the GSN context, communicates in Data Access mode
with an OPC server and converts the received data to the internal GSN format,
according to several temporal modes. This work is realized in the context of a
Ph.D. Thesis about the control of distributed information fusion systems. The
developed component allows the injection of OPC data, like measurements or
industrial processes states information, into a distributed information fusion
system deployed in a GSN framework. The component behaves as a client of the
OPC server. Developed in Java and based on the Opensaca Utgard, it can be
deployed on any computation node supporting a Java virtual machine. The
experiments show the component conformity according to the Data Access 2.05a
specification of the OPC standard and to the temporal modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0056</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0056</id><created>2008-08-01</created><authors><author><keyname>Diamant</keyname><forenames>Emanuel</forenames></author></authors><title>I'm sorry to say, but your understanding of image processing
  fundamentals is absolutely wrong</title><categories>cs.AI cs.CV cs.IR cs.RO q-bio.NC</categories><comments>To be published as chapter 5 in &quot;Frontiers in Brain, Vision and AI&quot;,
  I-TECH Publisher, Viena, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ongoing discussion whether modern vision systems have to be viewed as
visually-enabled cognitive systems or cognitively-enabled vision systems is
groundless, because perceptual and cognitive faculties of vision are separate
components of human (and consequently, artificial) information processing
system modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0059</identifier>
 <datestamp>2008-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0059</id><created>2008-08-01</created><authors><author><keyname>Santha</keyname><forenames>Miklos</forenames></author></authors><title>Quantum walk based search algorithms</title><categories>quant-ph cs.CC</categories><comments>16 pages, survey paper</comments><journal-ref>5th Theory and Applications of Models of Computation (TAMC08),
  Xian, April 2008, LNCS 4978, 31-46</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this survey paper we give an intuitive treatment of the discrete time
quantization of classical Markov chains. Grover search and the quantum walk
based search algorithms of Ambainis, Szegedy and Magniez et al. will be stated
as quantum analogues of classical search procedures. We present a rather
detailed description of a somewhat simplified version of the MNRS algorithm.
Finally, in the query complexity model, we show how quantum walks can be
applied to the following search problems: Element Distinctness, Matrix Product
Verification, Restricted Range Associativity, Triangle, and Group
Commutativity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0075</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0075</id><created>2008-08-01</created><updated>2009-05-29</updated><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Chai</keyname><forenames>Chin Choy</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Optimal Beamforming for Two-Way Multi-Antenna Relay Channel with
  Analogue Network Coding</title><categories>cs.IT math.IT</categories><comments>to appear in JSAC, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the wireless two-way relay channel (TWRC), where two
source nodes, S1 and S2, exchange information through an assisting relay node,
R. It is assumed that R receives the sum signal from S1 and S2 in one
time-slot, and then amplifies and forwards the received signal to both S1 and
S2 in the next time-slot. By applying the principle of analogue network (ANC),
each of S1 and S2 cancels the so-called &quot;self-interference&quot; in the received
signal from R and then decodes the desired message. Assuming that S1 and S2 are
each equipped with a single antenna and R with multi-antennas, this paper
analyzes the capacity region of an ANC-based TWRC with linear processing
(beamforming) at R. The capacity region contains all the achievable
bidirectional rate-pairs of S1 and S2 under the given transmit power
constraints at S1, S2, and R. We present the optimal relay beamforming
structure as well as an efficient algorithm to compute the optimal beamforming
matrix based on convex optimization techniques. Low-complexity suboptimal relay
beamforming schemes are also presented, and their achievable rates are compared
against the capacity with the optimal scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0103</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0103</id><created>2008-08-01</created><updated>2008-10-03</updated><authors><author><keyname>Henneken</keyname><forenames>Edwin A.</forenames></author><author><keyname>Kurtz</keyname><forenames>Michael J.</forenames></author><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Grant</keyname><forenames>Carolyn S.</forenames></author><author><keyname>Thompson</keyname><forenames>Donna</forenames></author><author><keyname>Bohlen</keyname><forenames>Elizabeth</forenames></author><author><keyname>Murray</keyname><forenames>Stephen S.</forenames></author></authors><title>Use of Astronomical Literature - A Report on Usage Patterns</title><categories>cs.DL astro-ph</categories><comments>12 pages, 8 figures, 2 tables. Accepted by Journal of Informetrics</comments><doi>10.1016/j.joi.2008.10.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a number of metrics for usage of the SAO/NASA
Astrophysics Data System (ADS). Since the ADS is used by the entire
astronomical community, these are indicative of how the astronomical literature
is used. We will show how the use of the ADS has changed both quantitatively
and qualitatively. We will also show that different types of users access the
system in different ways. Finally, we show how use of the ADS has evolved over
the years in various regions of the world.
  The ADS is funded by NASA Grant NNG06GG68G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0111</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0111</id><created>2008-08-01</created><updated>2010-09-03</updated><authors><author><keyname>Hartig</keyname><forenames>Florian</forenames></author><author><keyname>Drechsler</keyname><forenames>Martin</forenames></author></authors><title>Stay by thy neighbor? Social organization determines the efficiency of
  biodiversity markets with spatial incentives</title><categories>physics.soc-ph cs.GT</categories><comments>11 pages, 6 figures</comments><journal-ref>Ecological Complexity, 2010, 7, 91-99</journal-ref><doi>10.1016/j.ecocom.2009.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Market-based conservation instruments, such as payments, auctions or tradable
permits, are environmental policies that create financial incentives for
landowners to engage in voluntary conservation on their land. But what if
ecological processes operate across property boundaries and land use decisions
on one property influence ecosystem functions on neighboring sites? This paper
examines how to account for such spatial externalities when designing
market-based conservation instruments. We use an agent-based model to analyze
different spatial metrics and their implications on land use decisions in a
dynamic cost environment. The model contains a number of alternative submodels
which differ in incentive design and social interactions of agents, the latter
including coordinating as well as cooperating behavior of agents. We find that
incentive design and social interactions have a strong influence on the spatial
allocation and the costs of the conservation market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0112</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0112</id><created>2008-08-01</created><updated>2010-10-28</updated><authors><author><keyname>Yukalov</keyname><forenames>V. I.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author></authors><title>Mathematical Structure of Quantum Decision Theory</title><categories>cs.AI math-ph math.MP quant-ph</categories><comments>40 pages</comments><journal-ref>Advances in Complex Systems 13, 659-698 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most complex systems is the human brain whose formalized
functioning is characterized by decision theory. We present a &quot;Quantum Decision
Theory&quot; of decision making, based on the mathematical theory of separable
Hilbert spaces. This mathematical structure captures the effect of
superposition of composite prospects, including many incorporated intentions,
which allows us to explain a variety of interesting fallacies and anomalies
that have been reported to particularize the decision making of real human
beings. The theory describes entangled decision making, non-commutativity of
subsequent decisions, and intention interference of composite prospects. We
demonstrate how the violation of the Savage's sure-thing principle (disjunction
effect) can be explained as a result of the interference of intentions, when
making decisions under uncertainty. The conjunction fallacy is also explained
by the presence of the interference terms. We demonstrate that all known
anomalies and paradoxes, documented in the context of classical decision
theory, are reducible to just a few mathematical archetypes, all of which
finding straightforward explanations in the frame of the developed quantum
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0148</identifier>
 <datestamp>2008-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0148</id><created>2008-08-01</created><updated>2008-08-09</updated><authors><author><keyname>Biswal</keyname><forenames>Punyashloka</forenames></author><author><keyname>Lee</keyname><forenames>James R.</forenames></author><author><keyname>Rao</keyname><forenames>Satish</forenames></author></authors><title>Eigenvalue bounds, spectral partitioning, and metrical deformations via
  flows</title><categories>cs.DS cs.CG math.MG math.SP</categories><comments>Minor revisions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new method for upper bounding the second eigenvalue of the
Laplacian of graphs. Our approach uses multi-commodity flows to deform the
geometry of the graph; we embed the resulting metric into Euclidean space to
recover a bound on the Rayleigh quotient. Using this, we show that every
$n$-vertex graph of genus $g$ and maximum degree $d$ satisfies $\lambda_2(G) =
O((g+1)^3 d/n)$. This recovers the $O(d/n)$ bound of Spielman and Teng for
planar graphs, and compares to Kelner's bound of $O((g+1) poly(d)/n)$, but our
proof does not make use of conformal mappings or circle packings. We are thus
able to extend this to resolve positively a conjecture of Spielman and Teng, by
proving that $\lambda_2(G) = O(d h^6 \log h/n)$ whenever $G$ is $K_h$-minor
free. This shows, in particular, that spectral partitioning can be used to
recover $O(\sqrt{n})$-sized separators in bounded degree graphs that exclude a
fixed minor. We extend this further by obtaining nearly optimal bounds on
$\lambda_2$ for graphs which exclude small-depth minors in the sense of
Plotkin, Rao, and Smith. Consequently, we show that spectral algorithms find
small separators in a general class of geometric graphs.
  Moreover, while the standard &quot;sweep&quot; algorithm applied to the second
eigenvector may fail to find good quotient cuts in graphs of unbounded degree,
our approach produces a vector that works for arbitrary graphs. This yields an
alternate proof of the result of Alon, Seymour, and Thomas that every
excluded-minor family of graphs has $O(\sqrt{n})$-node balanced separators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0156</identifier>
 <datestamp>2009-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0156</id><created>2008-08-01</created><updated>2009-01-03</updated><authors><author><keyname>Amir</keyname><forenames>Yair</forenames></author><author><keyname>Bunn</keyname><forenames>Paul</forenames></author><author><keyname>Ostrovksy</keyname><forenames>Rafail</forenames></author></authors><title>Authenticated Adversarial Routing</title><categories>cs.CR cs.NI</categories><comments>Corrected typos. TCC '09 (to appear)</comments><acm-class>C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to demonstrate the feasibility of authenticated
throughput-efficient routing in an unreliable and dynamically changing
synchronous network in which the majority of malicious insiders try to destroy
and alter messages or disrupt communication in any way. More specifically, in
this paper we seek to answer the following question: Given a network in which
the majority of nodes are controlled by a malicious adversary and whose
topology is changing every round, is it possible to develop a protocol with
polynomially-bounded memory per processor that guarantees throughput-efficient
and correct end-to-end communication? We answer the question affirmatively for
extremely general corruption patterns: we only request that the topology of the
network and the corruption pattern of the adversary leaves at least one path
each round connecting the sender and receiver through honest nodes (though this
path may change at every round). Out construction works in the public-key
setting and enjoys bounded memory per processor (that does not depend on the
amount of traffic and is polynomial in the network size.) Our protocol achieves
optimal transfer rate with negligible decoding error. We stress that our
protocol assumes no knowledge of which nodes are corrupted nor which path is
reliable at any round, and is also fully distributed with nodes making
decisions locally, so that they need not know the topology of the network at
any time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0159</identifier>
 <datestamp>2008-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0159</id><created>2008-08-01</created><authors><author><keyname>Antal</keyname><forenames>T.</forenames></author><author><keyname>ben-Avraham</keyname><forenames>D.</forenames></author><author><keyname>Ben-Naim</keyname><forenames>E.</forenames></author><author><keyname>Krapivsky</keyname><forenames>P. L.</forenames></author></authors><title>Front Propagation with Rejuvenation in Flipping Processes</title><categories>cond-mat.stat-mech cs.DS math.PR</categories><comments>10 pages, 9 figures, 4 tables</comments><journal-ref>J. Phys. A 41, 465002 (2008)</journal-ref><doi>10.1088/1751-8113/41/46/465002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a directed flipping process that underlies the performance of the
random edge simplex algorithm. In this stochastic process, which takes place on
a one-dimensional lattice whose sites may be either occupied or vacant,
occupied sites become vacant at a constant rate and simultaneously cause all
sites to the right to change their state. This random process exhibits rich
phenomenology. First, there is a front, defined by the position of the
left-most occupied site, that propagates at a nontrivial velocity. Second, the
front involves a depletion zone with an excess of vacant sites. The total
excess D_k increases logarithmically, D_k ~ ln k, with the distance k from the
front. Third, the front exhibits rejuvenation -- young fronts are vigorous but
old fronts are sluggish. We investigate these phenomena using a quasi-static
approximation, direct solutions of small systems, and numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0163</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0163</id><created>2008-08-01</created><updated>2009-11-18</updated><authors><author><keyname>Batson</keyname><forenames>Joshua</forenames></author><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author><author><keyname>Srivastava</keyname><forenames>Nikhil</forenames></author></authors><title>Twice-Ramanujan Sparsifiers</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that every graph has a spectral sparsifier with a number of edges
linear in its number of vertices. As linear-sized spectral sparsifiers of
complete graphs are expanders, our sparsifiers of arbitrary graphs can be
viewed as generalizations of expander graphs.
  In particular, we prove that for every $d&gt;1$ and every undirected, weighted
graph $G=(V,E,w)$ on $n$ vertices, there exists a weighted graph
$H=(V,F,\tilde{w})$ with at most $\ceil{d(n-1)}$ edges such that for every $x
\in \R^{V}$, \[ x^{T}L_{G}x \leq x^{T}L_{H}x \leq
(\frac{d+1+2\sqrt{d}}{d+1-2\sqrt{d}})\cdot x^{T}L_{G}x \] where $L_{G}$ and
$L_{H}$ are the Laplacian matrices of $G$ and $H$, respectively. Thus, $H$
approximates $G$ spectrally at least as well as a Ramanujan expander with
$dn/2$ edges approximates the complete graph. We give an elementary
deterministic polynomial time algorithm for constructing $H$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0202</identifier>
 <datestamp>2008-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0202</id><created>2008-08-01</created><authors><author><keyname>Gao</keyname><forenames>Yong</forenames></author></authors><title>The Degree Distribution of Random k-Trees</title><categories>cs.DM cs.NI</categories><doi>10.1016/j.tcs.2008.10.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A power law degree distribution is established for a graph evolution model
based on the graph class of k-trees. This k-tree-based graph process can be
viewed as an idealized model that captures some characteristics of the
preferential attachment and copying mechanisms that existing evolving graph
processes fail to model due to technical obstacles. The result also serves as a
further cautionary note reinforcing the point of view that a power law degree
distribution should not be regarded as the only important characteristic of a
complex network, as has been previously argued.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0234</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0234</id><created>2008-08-02</created><authors><author><keyname>Sreeram</keyname><forenames>K.</forenames></author><author><keyname>Birenjith</keyname><forenames>S.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>DMT of Multi-hop Cooperative Networks - Part I: Basic Results</title><categories>cs.IT math.IT</categories><comments>This submission is Part-I of a two-part paper, which is a detailed
  version of the previous submission arXiv:0802.1888</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this two-part paper, the DMT of cooperative multi-hop networks is
examined. The focus is on single-source single-sink (ss-ss) multi-hop relay
networks having slow-fading links and relays that potentially possess multiple
antennas. The present paper examines the two end-points of the DMT of
full-duplex networks. In particular, the maximum achievable diversity of
arbitrary multi-terminal wireless networks is shown to be equal to the min-cut.
The maximum multiplexing gain of arbitrary full-duplex ss-ss networks is shown
to be equal to the min-cut rank, using a new connection to a deterministic
network. We also prove some basic results including a proof that the colored
noise encountered in AF protocols for cooperative networks can be treated as
white noise for DMT computations. The DMT of a parallel channel with
independent MIMO links is also computed here. As an application of these basic
results, we prove that a linear tradeoff between maximum diversity and maximum
multiplexing gain is achievable for full-duplex networks with single antenna
nodes. All protocols in this paper are explicit and rely only upon
amplify-and-forward (AF) relaying. Half duplex networks are studied, and
explicit codes for all protocols proposed in both parts, are provided in the
companion paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0235</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0235</id><created>2008-08-02</created><authors><author><keyname>Sreeram</keyname><forenames>K.</forenames></author><author><keyname>Birenjith</keyname><forenames>S.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>DMT of Multi-hop Cooperative Networks - Part II: Half-Duplex Networks
  with Full-Duplex Performance</title><categories>cs.IT math.IT</categories><comments>This submission is Part-II of a two-part paper, which is a detailed
  version of the previous submission arXiv:0802.1888</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider single-source single-sink (ss-ss) multi-hop relay networks, with
slow-fading links and single-antenna half-duplex relay nodes. In a companion
paper, we established some basic results which laid the foundation for the
results presented here. In the present paper, we consider two families of
networks of half-duplex networks. KPP networks may be viewed as the union of K
node-disjoint parallel relaying paths. Generalizations of these networks
include KPP(I) networks, which permit interference between paths and KPP(D)
networks, which possess a direct link between source and sink. We characterize
the DMT of these families of networks completely and show that they can achieve
the cut-set bound, thus proving that full-duplex performance can be obtained
even in the presence of the half-duplex constraint. We then consider layered
networks, and prove that a linear DMT between maximum diversity and maximum
multiplexing gain is achievable. All protocols in this paper are explicit and
use only amplify-and-forward relaying. We also construct codes that achieve the
optimal DMT for all the proposed schemes. Two key implications of the results
in the paper are that the half-duplex constraint does not entail any rate loss
for a large class of cooperative networks and that AF protocols are often
optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0247</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0247</id><created>2008-08-02</created><authors><author><keyname>Gligoroski</keyname><forenames>Danilo</forenames></author><author><keyname>Markovski</keyname><forenames>Smile</forenames></author><author><keyname>Knapskog</keyname><forenames>Svein Johan</forenames></author></authors><title>A Public Key Block Cipher Based on Multivariate Quadratic Quasigroups</title><categories>cs.CR</categories><comments>This is an extended and updated version of a paper &quot;Multivariate
  Quadratic Trapdoor Functions Based on Multivariate Quadratic Quasigroups&quot;,
  Proceedings of the American Conference On Applied Mathematics (MATH '08),
  Cambridge, Massachusetts, USA, March 24-26, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have designed a new class of public key algorithms based on quasigroup
string transformations using a specific class of quasigroups called
multivariate quadratic quasigroups (MQQ). Our public key algorithm is a
bijective mapping, it does not perform message expansions and can be used both
for encryption and signatures. The public key consist of n quadratic
polynomials with n variables where n=140, 160, ... . A particular
characteristic of our public key algorithm is that it is very fast and highly
parallelizable. More concretely, it has the speed of a typical modern symmetric
block cipher - the reason for the phrase &quot;A Public Key Block Cipher&quot; in the
title of this paper. Namely the reference C code for the 160-bit variant of the
algorithm performs decryption in less than 11,000 cycles (on Intel Core 2 Duo
-- using only one processor core), and around 6,000 cycles using two CPU cores
and OpenMP 2.0 library. However, implemented in Xilinx Virtex-5 FPGA that is
running on 249.4 MHz it achieves decryption throughput of 399 Mbps, and
implemented on four Xilinx Virtex-5 chips that are running on 276.7 MHz it
achieves encryption throughput of 44.27 Gbps. Compared to fastest RSA
implementations on similar FPGA platforms, MQQ algorithm is more than 10,000
times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0272</identifier>
 <datestamp>2009-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0272</id><created>2008-08-02</created><updated>2009-01-13</updated><authors><author><keyname>Lee</keyname><forenames>Ki-Moon</forenames></author><author><keyname>Radha</keyname><forenames>Hayder</forenames></author><author><keyname>Kim</keyname><forenames>Beom-Jin</forenames></author></authors><title>Kovalenko's Full-Rank Limit and Overhead as Lower Bounds for
  Error-Performances of LDPC and LT Codes over Binary Erasure Channels</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>A short version of this paper was presented at ISITA 2008, Auckland
  NZ. The first draft was submitted to IEEE Transactions on Information Theory,
  2008/06</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Kovalenko's full-rank limit as a tight lower bound for decoding
error probability of LDPC codes and LT codes over BEC. From the limit, we
derive a full-rank overhead as a lower bound for stable overheads for
successful maximum-likelihood decoding of the codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0284</identifier>
 <datestamp>2010-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0284</id><created>2008-08-02</created><updated>2010-03-31</updated><authors><author><keyname>Lebl</keyname><forenames>Jiri</forenames></author><author><keyname>Lichtblau</keyname><forenames>Daniel</forenames></author></authors><title>Uniqueness of certain polynomials constant on a line</title><categories>math.CV cs.CG math.NT</categories><comments>20 pages, latex; removed section 10 and address referee suggestions;
  accepted to Linear Algebra and its Applications</comments><msc-class>32H35, 68W30, 11C08, 05E99</msc-class><journal-ref>Linear Algebra and Its Applications 433 (2010) pp. 824-837</journal-ref><doi>10.1016/j.laa.2010.04.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a question with connections to linear algebra, real algebraic
geometry, combinatorics, and complex analysis. Let $p(x,y)$ be a polynomial of
degree $d$ with $N$ positive coefficients and no negative coefficients, such
that $p=1$ when $x+y=1$. A sharp estimate $d \leq 2N-3$ is known. In this paper
we study the $p$ for which equality holds. We prove some new results about the
form of these &quot;sharp&quot; polynomials. Using these new results and using two
independent computational methods we give a complete classification of these
polynomials up to $d=17$. The question is motivated by the problem of
classification of CR maps between spheres in different dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0291</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0291</id><created>2008-08-02</created><authors><author><keyname>Hadjiliadis</keyname><forenames>Olympia</forenames></author><author><keyname>Zhang</keyname><forenames>Hongzhong</forenames></author><author><keyname>Poor</keyname><forenames>H. V.</forenames></author></authors><title>One shot schemes for decentralized quickest change detection</title><categories>cs.IT math.IT</categories><comments>Proceedings of the Eleventh International Conference on Information
  Fusion, Cologne, Germany, June 30- July 3, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the problem of quickest detection with N distributed
sensors that receive continuous sequential observations from the environment.
These sensors employ cumulative sum (CUSUM) strategies and communicate to a
central fusion center by one shot schemes. One shot schemes are schemes in
which the sensors communicate with the fusion center only once, after which
they must signal a detection. The communication is clearly asynchronous and the
case is considered in which the fusion center employs a minimal strategy, which
means that it declares an alarm when the first communication takes place. It is
assumed that the observations received at the sensors are independent and that
the time points at which the appearance of a signal can take place are
different. It is shown that there is no loss of performance of one shot schemes
as compared to the centralized case in an extended Lorden min-max sense, since
the minimum of N CUSUMs is asymptotically optimal as the mean time between
false alarms increases without bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0298</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0298</id><created>2008-08-03</created><authors><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Pasechnik</keyname><forenames>Dmitrii V.</forenames></author></authors><title>Computing the nucleolus of weighted voting games</title><categories>cs.GT cs.DS</categories><comments>LaTeX, 12 pages, COMSOC-2008 workshop</comments><acm-class>G.1.6; I.2.8</acm-class><journal-ref>Proceedings of SODA 2009, pp. 327-335</journal-ref><doi>10.1145/1496770.1496807</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weighted voting games (WVG) are coalitional games in which an agent's
contribution to a coalition is given by his it weight, and a coalition wins if
its total weight meets or exceeds a given quota. These games model
decision-making in political bodies as well as collaboration and surplus
division in multiagent domains. The computational complexity of various
solution concepts for weighted voting games received a lot of attention in
recent years. In particular, Elkind et al.(2007) studied the complexity of
stability-related solution concepts in WVGs, namely, of the core, the least
core, and the nucleolus. While they have completely characterized the
algorithmic complexity of the core and the least core, for the nucleolus they
have only provided an NP-hardness result. In this paper, we solve an open
problem posed by Elkind et al. by showing that the nucleolus of WVGs, and, more
generally, k-vector weighted voting games with fixed k, can be computed in
pseudopolynomial time, i.e., there exists an algorithm that correctly computes
the nucleolus and runs in time polynomial in the number of players and the
maximum weight. In doing so, we propose a general framework for computing the
nucleolus, which may be applicable to a wider of class of games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0309</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0309</id><created>2008-08-03</created><authors><author><keyname>Jain</keyname><forenames>Chirag</forenames></author><author><keyname>Arora</keyname><forenames>Siddharth</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author></authors><title>A Reliable SVD based Watermarking Schem</title><categories>cs.MM</categories><comments>8 Pages, 7 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel scheme for watermarking of digital images based on
singular value decomposition (SVD), which makes use of the fact that the SVD
subspace preserves significant amount of information of an image, as compared
to its singular value matrix, Zhang and Li (2005). The principal components of
the watermark are embedded in the original image, leaving the detector with a
complimentary set of singular vectors for watermark extraction. The above step
invariably ensures that watermark extraction from the embedded watermark image,
using a modified matrix, is not possible, thereby removing a major drawback of
an earlier proposed algorithm by Liu and Tan (2002).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0347</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0347</id><created>2008-08-03</created><authors><author><keyname>Kienle</keyname><forenames>Holger M.</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Hausi A.</forenames></author></authors><title>Towards a Process for Developing Maintenance Tools in Academia</title><categories>cs.SE</categories><comments>10 pages, 2 figures, 15th Working Conference on Reverse Engineering
  (WCRE 2008), Antwerp, Belgium</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Building of tools--from simple prototypes to industrial-strength
applications--is a pervasive activity in academic research. When proposing a
new technique for software maintenance, effective tool support is typically
required to demonstrate the feasibility and effectiveness of the approach.
However, even though tool building is both pervasive and requiring significant
time and effort, it is still pursued in an ad hoc manner. In this paper, we
address these issues by proposing a dedicated development process for tool
building that takes the unique characteristics of an academic research
environment into account. We first identify process requirements based on a
review of the literature and our extensive tool building experience in the
domain of maintenance tools. We then outline a process framework based on work
products that accommodates the requirements while providing needed flexibility
for tailoring the process to account for specific tool building approaches and
project constraints. The work products are concrete milestones of the process,
tracking progress, rationalizing (design) decisions, and documenting the
current state of the tool building project. Thus, the work products provide
important input for strategic project decisions and rapid initiation of new
team members. Leveraging a dedicated tool building process promises tools that
are designed, build, and maintained in a more disciplined, predictable and
efficient manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0374</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0374</id><created>2008-08-03</created><authors><author><keyname>Prasetyo</keyname><forenames>Eri</forenames></author><author><keyname>Afandi</keyname><forenames>Hamzah</forenames></author><author><keyname>Ginhac</keyname><forenames>Nurul Huda Dominique</forenames></author><author><keyname>Paindavoine</keyname><forenames>Michel</forenames></author></authors><title>A 8 bits Pipeline Analog to Digital Converter Design for High Speed
  Camera Application</title><categories>cs.RO cs.CV</categories><comments>5 pages, 5 authors, conference</comments><journal-ref>EEPIS, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  - This paper describes a pipeline analog-to-digital converter is implemented
for high speed camera. In the pipeline ADC design, prime factor is designing
operational amplifier with high gain so ADC have been high speed. The other
advantage of pipeline is simple on concept, easy to implement in layout and
have flexibility to increase speed. We made design and simulation using Mentor
Graphics Software with 0.6 \mu m CMOS technology with a total power dissipation
of 75.47 mW. Circuit techniques used include a precise comparator, operational
amplifier and clock management. A switched capacitor is used to sample and
multiplying at each stage. Simulation a worst case DNL and INL of 0.75 LSB. The
design operates at 5 V dc. The ADC achieves a SNDR of 44.86 dB. keywords:
pipeline, switched capacitor, clock management
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0387</identifier>
 <datestamp>2008-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0387</id><created>2008-08-04</created><authors><author><keyname>Prasetyo</keyname><forenames>Eri</forenames></author><author><keyname>Ginhac</keyname><forenames>Dominique</forenames></author><author><keyname>Paindavoine</keyname><forenames>Michel</forenames></author></authors><title>Design and Implementation a 8 bits Pipeline Analog to Digital Converter
  in the Technology 0.6 \mu m CMOS Process</title><categories>cs.RO cs.CV</categories><comments>5 pages, Conference in Paris</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a 8 bits, 20 Msamples/s pipeline analog-to-digital
converter implemented in 0.6 \mu m CMOS technology with a total power
dissipation of 75.47 mW. Circuit techniques used include a precise comparator,
operational amplifier and clock management. A switched capacitor is used to
sample and multiplying at each stage. Simulation a worst case DNL and INL of
0.75 LSB. The design operate at 5 V dc. The ADC achieves a SNDR of 44.86 dB.
keywords : pipeline, switched capacitor, clock management
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0441</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0441</id><created>2008-08-04</created><updated>2008-08-27</updated><authors><author><keyname>Escardo</keyname><forenames>Martin</forenames></author></authors><title>Exhaustible sets in higher-type computation</title><categories>cs.LO</categories><acm-class>F.4.1; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (August 27,
  2008) lmcs:693</journal-ref><doi>10.2168/LMCS-4(3:3)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We say that a set is exhaustible if it admits algorithmic universal
quantification for continuous predicates in finite time, and searchable if
there is an algorithm that, given any continuous predicate, either selects an
element for which the predicate holds or else tells there is no example. The
Cantor space of infinite sequences of binary digits is known to be searchable.
Searchable sets are exhaustible, and we show that the converse also holds for
sets of hereditarily total elements in the hierarchy of continuous functionals;
moreover, a selection functional can be constructed uniformly from a
quantification functional. We prove that searchable sets are closed under
intersections with decidable sets, and under the formation of computable images
and of finite and countably infinite products. This is related to the fact,
established here, that exhaustible sets are topologically compact. We obtain a
complete description of exhaustible total sets by developing a computational
version of a topological Arzela--Ascoli type characterization of compact
subsets of function spaces. We also show that, in the non-empty case, they are
precisely the computable images of the Cantor space. The emphasis of this paper
is on the theory of exhaustible and searchable sets, but we also briefly sketch
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0469</identifier>
 <datestamp>2008-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0469</id><created>2008-08-04</created><updated>2008-08-31</updated><authors><author><keyname>Miller</keyname><forenames>Stephen D.</forenames></author><author><keyname>Venkatesan</keyname><forenames>Ramarathnam</forenames></author></authors><title>Non-degeneracy of Pollard Rho Collisions</title><categories>math.NT cs.CR cs.DM math.CO</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Pollard Rho algorithm is a widely used algorithm for solving discrete
logarithms on general cyclic groups, including elliptic curves. Recently the
first nontrivial runtime estimates were provided for it, culminating in a sharp
O(sqrt(n)) bound for the collision time on a cyclic group of order n. In this
paper we show that for n satisfying a mild arithmetic condition, the collisions
guaranteed by these results are nondegenerate with high probability: that is,
the Pollard Rho algorithm successfully finds the discrete logarithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0509</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0509</id><created>2008-08-04</created><authors><author><keyname>Bansal</keyname><forenames>Shweta</forenames></author><author><keyname>Khandelwal</keyname><forenames>Shashank</forenames></author><author><keyname>Meyers</keyname><forenames>Lauren Ancel</forenames></author></authors><title>Evolving Clustered Random Networks</title><categories>cs.DM physics.soc-ph</categories><journal-ref>BMC Bioinformatics, Vol 10: 405, 2009</journal-ref><doi>10.1186/1471-2105-10-405</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a Markov chain simulation method to generate simple connected
random graphs with a specified degree sequence and level of clustering. The
networks generated by our algorithm are random in all other respects and can
thus serve as generic models for studying the impacts of degree distributions
and clustering on dynamical processes as well as null models for detecting
other structural properties in empirical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0518</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0518</id><created>2008-08-04</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Petras</keyname><forenames>Vivien</forenames></author></authors><title>Building a terminology network for search: the KoMoHe project</title><categories>cs.DL cs.DB</categories><comments>5 pages, 2 figure, Dublin Core Conference 2008</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The paper reports about results on the GESIS-IZ project &quot;Competence Center
Modeling and Treatment of Semantic Heterogeneity&quot; (KoMoHe). KoMoHe supervised a
terminology mapping effort, in which 'cross-concordances' between major
controlled vocabularies were organized, created and managed. In this paper we
describe the establishment and implementation of cross-concordances for search
in a digital library (DL).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0521</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0521</id><created>2008-08-04</created><authors><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames></author><author><keyname>Moss</keyname><forenames>Lawrence S.</forenames></author></authors><title>Logics for the Relational Syllogistic</title><categories>cs.LO cs.CC cs.CL</categories><acm-class>F.4.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Aristotelian syllogistic cannot account for the validity of many
inferences involving relational facts. In this paper, we investigate the
prospects for providing a relational syllogistic. We identify several fragments
based on (a) whether negation is permitted on all nouns, including those in the
subject of a sentence; and (b) whether the subject noun phrase may contain a
relative clause. The logics we present are extensions of the classical
syllogistic, and we pay special attention to the question of whether reductio
ad absurdum is needed. Thus our main goal is to derive results on the existence
(or non-existence) of syllogistic proof systems for relational fragments. We
also determine the computational complexity of all our fragments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0540</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0540</id><created>2008-08-05</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Executable Set Theory and Arithmetic Encodings in Prolog</title><categories>cs.LO cs.DM cs.DS cs.MS cs.SC</categories><comments>Unpublished draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is organized as a self-contained literate Prolog program that
implements elements of an executable finite set theory with focus on
combinatorial generation and arithmetic encodings. The complete Prolog code is
available at http://logic.csci.unt.edu/tarau/research/2008/pHFS.zip . First,
ranking and unranking functions for some &quot;mathematically elegant&quot; data types in
the universe of Hereditarily Finite Sets with Urelements are provided,
resulting in arithmetic encodings for powersets, hypergraphs, ordinals and
choice functions. After implementing a digraph representation of Hereditarily
Finite Sets we define {\em decoration functions} that can recover well-founded
sets from encodings of their associated acyclic digraphs. We conclude with an
encoding of arbitrary digraphs and discuss a concept of duality induced by the
set membership relation. In the process, we uncover the surprising possibility
of internally sharing isomorphic objects, independently of their language level
types and meanings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0544</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0544</id><created>2008-08-04</created><authors><author><keyname>Kang</keyname><forenames>Jae Won</forenames></author><author><keyname>Whang</keyname><forenames>Younghoon</forenames></author><author><keyname>Park</keyname><forenames>Hyo Yol</forenames></author><author><keyname>Kim</keyname><forenames>Kwang Soon</forenames></author></authors><title>Generalized Cross-correlation Properties of Chu Sequences</title><categories>cs.IT math.IT</categories><comments>22 pages, 1figure, 1 table</comments><acm-class>E.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we analyze the cross-correlation properties for Chu sequences,
which provide information on the distribution of the maximum magnitudes of the
cross-correlation function. Furthermore, we can obtain the number of available
sequences for a given maximum magnitude of the cross-correlation function and
the sequence length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0548</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0548</id><created>2008-08-05</created><authors><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>How could the replica method improve accuracy of performance assessment
  of channel coding?</title><categories>cs.IT math.IT</categories><comments>13 pages, 1 figure, submitted to the International Workshop on
  Statistical-Mechanical Informatics (IW-SMI2008), Sendai</comments><doi>10.1088/1742-6596/143/1/012018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the relation between the techniques of statistical mechanics and
information theory for assessing the performance of channel coding. We base our
study on a framework developed by Gallager in {\em IEEE Trans. Inform. Theory}
{\bf 11}, 3 (1965), where the minimum decoding error probability is
upper-bounded by an average of a generalized Chernoff's bound over a code
ensemble. We show that the resulting bound in the framework can be directly
assessed by the replica method, which has been developed in statistical
mechanics of disordered systems, whereas in Gallager's original methodology
further replacement by another bound utilizing Jensen's inequality is
necessary. Our approach associates a seemingly {\em ad hoc} restriction with
respect to an adjustable parameter for optimizing the bound with a phase
transition between two replica symmetric solutions, and can improve the
accuracy of performance assessments of general code ensembles including low
density parity check codes, although its mathematical justification is still
open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0549</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0549</id><created>2008-08-05</created><updated>2010-02-26</updated><authors><author><keyname>Huang</keyname><forenames>Dong</forenames></author><author><keyname>Miao</keyname><forenames>Chunyan</forenames></author><author><keyname>Leung</keyname><forenames>Cyril</forenames></author><author><keyname>Shen</keyname><forenames>Zhiqi</forenames></author></authors><title>Resource Allocation of MU-OFDM Based Cognitive Radio Systems Under
  Partial Channel State Information</title><categories>cs.IT cs.NE math.CO math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to some errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0554</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0554</id><created>2008-08-05</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Ranking and Unranking of Hereditarily Finite Functions and Permutations</title><categories>cs.LO cs.MS</categories><comments>unpublished draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prolog's ability to return multiple answers on backtracking provides an
elegant mechanism to derive reversible encodings of combinatorial objects as
Natural Numbers i.e. {\em ranking} and {\em unranking} functions. Starting from
a generalization of Ackerman's encoding of Hereditarily Finite Sets with
Urelements and a novel tupling/untupling operation, we derive encodings for
Finite Functions and use them as building blocks for an executable theory of
{\em Hereditarily Finite Functions}. The more difficult problem of {\em
ranking} and {\em unranking} {\em Hereditarily Finite Permutations} is then
tackled using Lehmer codes and factoradics.
  The paper is organized as a self-contained literate Prolog program available
at \url{http://logic.csci.unt.edu/tarau/research/2008/pHFF.zip}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0555</identifier>
 <datestamp>2009-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0555</id><created>2008-08-05</created><updated>2009-02-03</updated><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Pairing Functions, Boolean Evaluation and Binary Decision Diagrams in
  Prolog</title><categories>cs.LO cs.SC</categories><comments>also in the informal proceedings of CICLOPS 2008 workshop at:
  http://clip.dia.fi.upm.es/Conferences/CICLOPS-2008/CICLOPS-2008-proceedings.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A &quot;pairing function&quot; J associates a unique natural number z to any two
natural numbers x,y such that for two &quot;unpairing functions&quot; K and L, the
equalities K(J(x,y))=x, L(J(x,y))=y and J(K(z),L(z))=z hold. Using pairing
functions on natural number representations of truth tables, we derive an
encoding for Binary Decision Diagrams with the unique property that its boolean
evaluation faithfully mimics its structural conversion to a a natural number
through recursive application of a matching pairing function. We then use this
result to derive {\em ranking} and {\em unranking} functions for BDDs and
reduced BDDs. The paper is organized as a self-contained literate Prolog
program, available at http://logic.csci.unt.edu/tarau/research/2008/pBDD.zip
  Keywords: logic programming and computational mathematics, pairing/unpairing
functions, encodings of boolean functions, binary decision diagrams, natural
number representations of truth tables
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0556</identifier>
 <datestamp>2008-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0556</id><created>2008-08-05</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Logic Engines as Interactors</title><categories>cs.PL cs.MA</categories><comments>unpublished draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new programming language construct, Interactors, supporting
the agent-oriented view that programming is a dialog between simple,
self-contained, autonomous building blocks.
  We define Interactors as an abstraction of answer generation and refinement
in Logic Engines resulting in expressive language extension and metaprogramming
patterns, including emulation of Prolog's dynamic database.
  A mapping between backtracking based answer generation in the callee and
&quot;forward&quot; recursion in the caller enables interaction between different
branches of the callee's search process and provides simplified design patterns
for algorithms involving combinatorial generation and infinite answer streams.
  Interactors extend language constructs like Ruby, Python and C#'s multiple
coroutining block returns through yield statements and they can emulate the
action of monadic constructs and catamorphisms in functional languages.
  Keywords: generalized iterators, logic engines, agent oriented programming
language constructs, interoperation with stateful objects, metaprogramming
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0558</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0558</id><created>2008-08-05</created><authors><author><keyname>Bhadra</keyname><forenames>Sandeep</forenames></author><author><keyname>Bodas</keyname><forenames>Shreeshankar</forenames></author><author><keyname>Shakkottai</keyname><forenames>Sanjay</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Communication Through Jamming over a Slotted ALOHA Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work derives bounds on the jamming capacity of a slotted ALOHA system. A
system with n legitimate users, each with a Bernoulli arrival process is
considered. Packets are temporarily stored at the corresponding user queues,
and a slotted ALOHA strategy is used for packet transmissions over the shared
channel. The scenario considered is that of a pair of illegitimate users that
jam legitimate transmissions in order to communicate over the slotted ALOHA
channel. Jamming leads to binary signaling between the illegitimate users, with
packet collisions due to legitimate users treated as (multiplicative) noise in
this channel. Further, the queueing dynamics at the legitimate users
stochastically couples the jamming strategy used by the illegitimate users and
the channel evolution.
  By considering various i.i.d. jamming strategies, achievable jamming rates
over the slotted ALOHA channel are derived. Further, an upper bound on the
jamming capacity over the class of all ergodic jamming policies is derived.
These bounds are shown to be tight in the limit where the offered system load
approaches unity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0584</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0584</id><created>2008-08-05</created><authors><author><keyname>De Martino</keyname><forenames>Daniele</forenames></author><author><keyname>Dall'Asta</keyname><forenames>Luca</forenames></author><author><keyname>Bianconi</keyname><forenames>Ginestra</forenames></author><author><keyname>Marsili</keyname><forenames>Matteo</forenames></author></authors><title>Congestion phenomena on complex networks</title><categories>physics.soc-ph cs.NI</categories><comments>4 pages, 4 figures, submitted to PRL</comments><doi>10.1103/PhysRevE.79.015101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a minimal model of traffic flows in complex networks containing the
most relevant features of real routing schemes, i.e. a trade--off strategy
between topological-based and traffic-based routing. The resulting collective
behavior, obtained analytically for the ensemble of uncorrelated networks, is
physically very rich and reproduces results recently observed in traffic
simulations on scale-free networks. We find that traffic control is useless in
homogeneous graphs but may improves global performance in inhomogeneous
networks, enlarging the free-flow region in parameter space. Traffic control
also introduces non-linear effects and, beyond a critical strength, may trigger
the appearance of a congested phase in a discontinuous manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0586</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0586</id><created>2008-08-05</created><authors><author><keyname>Leroy</keyname><forenames>Xavier</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Grall</keyname><forenames>Herv&#xe9;</forenames><affiliation>INRIA Rennes, LINA</affiliation></author></authors><title>Coinductive big-step operational semantics</title><categories>cs.PL</categories><proxy>ccsd inria-00309010</proxy><journal-ref>Information and Computation (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a call-by-value functional language as an example, this article
illustrates the use of coinductive definitions and proofs in big-step
operational semantics, enabling it to describe diverging evaluations in
addition to terminating evaluations. We formalize the connections between the
coinductive big-step semantics and the standard small-step semantics, proving
that both semantics are equivalent. We then study the use of coinductive
big-step semantics in proofs of type soundness and proofs of semantic
preservation for compilers. A methodological originality of this paper is that
all results have been proved using the Coq proof assistant. We explain the
proof-theoretic presentation of coinductive definitions and proofs offered by
Coq, and show that it facilitates the discovery and the presentation of the
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0596</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0596</id><created>2008-08-05</created><authors><author><keyname>Tal</keyname><forenames>Ido</forenames></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Roth</keyname><forenames>Ron M.</forenames></author></authors><title>On row-by-row coding for 2-D constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A constant-rate encoder--decoder pair is presented for a fairly large family
of two-dimensional (2-D) constraints. Encoding and decoding is done in a
row-by-row manner, and is sliding-block decodable.
  Essentially, the 2-D constraint is turned into a set of independent and
relatively simple one-dimensional (1-D) constraints; this is done by dividing
the array into fixed-width vertical strips. Each row in the strip is seen as a
symbol, and a graph presentation of the respective 1-D constraint is
constructed. The maxentropic stationary Markov chain on this graph is next
considered: a perturbed version of the corresponding probability distribution
on the edges of the graph is used in order to build an encoder which operates
in parallel on the strips. This perturbation is found by means of a network
flow, with upper and lower bounds on the flow through the edges.
  A key part of the encoder is an enumerative coder for constant-weight binary
words. A fast realization of this coder is shown, using floating-point
arithmetic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0634</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0634</id><created>2008-08-05</created><authors><author><keyname>Kuesters</keyname><forenames>Ralf</forenames></author><author><keyname>Truderung</keyname><forenames>Tomasz</forenames></author></authors><title>Reducing Protocol Analysis with XOR to the XOR-free Case in the Horn
  Theory Based Approach</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Horn theory based approach for cryptographic protocol analysis,
cryptographic protocols and (Dolev-Yao) intruders are modeled by Horn theories
and security analysis boils down to solving the derivation problem for Horn
theories. This approach and the tools based on this approach, including
ProVerif, have been very successful in the automatic analysis of cryptographic
protocols w.r.t. an unbounded number of sessions. However, dealing with the
algebraic properties of operators such as the exclusive OR (XOR) has been
problematic. In particular, ProVerif cannot deal with XOR. In this paper, we
show how to reduce the derivation problem for Horn theories with XOR to the
XOR-free case. Our reduction works for an expressive class of Horn theories. A
large class of intruder capabilities and protocols that employ the XOR operator
can be modeled by these theories. Our reduction allows us to carry out protocol
analysis by tools, such as ProVerif, that cannot deal with XOR, but are very
efficient in the XOR-free case. We implemented our reduction and, in
combination with ProVerif, applied it in the automatic analysis of several
protocols that use the XOR operator. In one case, we found a new attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0647</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0647</id><created>2008-08-05</created><authors><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author></authors><title>Model Checking Positive Equality-free FO: Boolean Structures and
  Digraphs of Size Three</title><categories>cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the model checking problem, for fixed structures A, over positive
equality-free first-order logic -- a natural generalisation of the non-uniform
quantified constraint satisfaction problem QCSP(A). We prove a complete
complexity classification for this problem when A ranges over 1.) boolean
structures and 2.) digraphs of size (less than or equal to) three. The former
class displays dichotomy between Logspace and Pspace-complete, while the latter
class displays tetrachotomy between Logspace, NP-complete, co-NP-complete and
Pspace-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0665</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0665</id><created>2008-08-05</created><authors><author><keyname>Fouard</keyname><forenames>C&#xe9;line</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Strand</keyname><forenames>Robin</forenames><affiliation>CBA</affiliation></author><author><keyname>Borgefors</keyname><forenames>Gunilla</forenames><affiliation>CBA</affiliation></author></authors><title>Weighted distance transforms generalized to modules and their
  computation on point lattices</title><categories>cs.DM</categories><proxy>ccsd hal-00308896</proxy><journal-ref>Pattern Recognition 40, 9 (2007) 2453--2474</journal-ref><doi>10.1016/j.patcog.2007.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the generalization of weighted distances to modules and
their computation through the chamfer algorithm on general point lattices. The
first part is dedicated to formalization of definitions and properties
(distance, metric, norm) of weighted distances on modules. It resumes tools
found in literature to express the weighted distance of any point of a module
and to compute optimal weights in the general case to get rotation invariant
distances. The second part of this paper proves that, for any point lattice,
the sequential two-scan chamfer algorithm produces correct distance maps.
Finally, the definitions and computation of weighted distances are applied to
the face-centered cubic (FCC) and body-centered cubic (BCC) grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0684</identifier>
 <datestamp>2008-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0684</id><created>2008-08-05</created><authors><author><keyname>Kavut</keyname><forenames>Selcuk</forenames></author><author><keyname>Yucel</keyname><forenames>Melek Diker</forenames></author></authors><title>9-variable Boolean Functions with Nonlinearity 242 in the Generalized
  Rotation Class</title><categories>cs.CR cs.IT math.IT</categories><comments>This work is based on (i) &quot;Generalized Rotation Symmetric and
  Dihedral Symmetric Boolean Functions - 9 variable Boolean Functions with
  Nonlinearity 242&quot;, AAECC-17 Symposium, LNCS Vol. 4851, pp. 321-329,
  Bangalore, India, 2007 and (ii) &quot;Random Permutations on Input Vectors of
  Boolean Functions&quot;, BFCA 2008, Copenhagen, Denmark, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2006, 9-variable Boolean functions having nonlinearity 241, which is
strictly greater than the bent concatenation bound of 240, have been discovered
in the class of Rotation Symmetric Boolean Functions (RSBFs) by Kavut, Maitra
and Yucel. To improve this nonlinearity result, we have firstly defined some
subsets of the n-variable Boolean functions as the &quot;generalized classes of
k-RSBFs and k-DSBFs (k-Dihedral Symmetric Boolean Functions)&quot;, where k is a
positive integer dividing n and k-RSBFs is a subset of l-RSBFs if k &lt; l.
Secondly, utilizing the steepest-descent like iterative heuristic search
algorithm used previously to identify the 9-variable RSBFs with nonlinearity
241, we have made a search within the classes of 3-RSBFs and 3-DSBFs. The
search has accomplished to find 9-variable Boolean functions with nonlinearity
242 in both of these classes. It should be emphasized that although the class
of 3-RSBFs contains functions with nonlinearity 242; 1-RSBFs or simply RSBFs,
which is a subset of 3-RSBFs, does not contain any. This result also shows that
the covering radius of the first order Reed-Muller code R(1, 9) is at least
equal to 242. Thirdly, motivated by the fact that RSBFs are invariant under a
special permutation of the input vector, we have classified all possible
permutations up to the linear equivalence of Boolean functions that are
invariant under those permutations. Specifically, for 9-variable Boolean
functions, 9! possible permutations are classified into 30 classes; and the
search algorithm identifies some of these classes as &quot;rich&quot;. The rich classes
yield new Boolean functions with nonlinearity 242 having different
autocorrelation spectra from those of the functions found in the generalized
3-RSBF and 3-DSBF classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0732</identifier>
 <datestamp>2008-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0732</id><created>2008-08-05</created><updated>2008-10-24</updated><authors><author><keyname>Pavlovic</keyname><forenames>Dusko</forenames></author></authors><title>Dynamics, robustness and fragility of trust</title><categories>cs.CR</categories><comments>17 pages; simplified the statement and the proof of the main theorem;
  FAST 2008</comments><acm-class>K.4.4; D.4.6; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trust is often conveyed through delegation, or through recommendation. This
makes the trust authorities, who process and publish trust recommendations,
into an attractive target for attacks and spoofing. In some recent empiric
studies, this was shown to lead to a remarkable phenomenon of *adverse
selection*: a greater percentage of unreliable or malicious web merchants were
found among those with certain types of trust certificates, then among those
without. While such findings can be attributed to a lack of diligence in trust
authorities, or even to conflicts of interest, our analysis of trust dynamics
suggests that public trust networks would probably remain vulnerable even if
trust authorities were perfectly diligent. The reason is that the process of
trust building, if trust is not breached too often, naturally leads to
power-law distributions: the rich get richer, the trusted attract more trust.
The evolutionary processes with such distributions, ubiquitous in nature, are
known to be robust with respect to random failures, but vulnerable to adaptive
attacks. We recommend some ways to decrease the vulnerability of trust
building, and suggest some ideas for exploration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0745</identifier>
 <datestamp>2009-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0745</id><created>2008-08-05</created><updated>2009-05-16</updated><authors><author><keyname>Lo</keyname><forenames>Caleb K.</forenames></author><author><keyname>Hasenbein</keyname><forenames>John J.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Relay-Assisted User Scheduling in Wireless Networks with Hybrid-ARQ</title><categories>cs.IT math.IT</categories><comments>14 pages, 5 figures, submitted to the IEEE Transactions on Vehicular
  Technology in October 2008, revised in March 2009 and May 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of relay-assisted user scheduling for downlink
wireless transmission. The base station or access point employs hybrid
automatic-repeat-request (HARQ) with the assistance of a set of fixed relays to
serve a set of mobile users. By minimizing a cost function of the queue lengths
at the base station and the number of retransmissions of the head-of-line
packet for each user, the base station can schedule an appropriate user in each
time slot and an appropriate transmitter to serve it. It is shown that a
priority-index policy is optimal for a linear cost function with packets
arriving according to a Poisson process and for an increasing convex cost
function where packets must be drained from the queues at the base station.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0753</identifier>
 <datestamp>2008-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0753</id><created>2008-08-05</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Ranking Catamorphisms and Unranking Anamorphisms on Hereditarily Finite
  Datatypes</title><categories>cs.SC cs.DM cs.DS</categories><comments>unpublished draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using specializations of unfold and fold on a generic tree data type we
derive unranking and ranking functions providing natural number encodings for
various Hereditarily Finite datatypes.
  In this context, we interpret unranking operations as instances of a generic
anamorphism and ranking operations as instances of the corresponding
catamorphism.
  Starting with Ackerman's Encoding from Hereditarily Finite Sets to Natural
Numbers we define pairings and tuple encodings that provide building blocks for
a theory of Hereditarily Finite Functions.
  The more difficult problem of ranking and unranking Hereditarily Finite
Permutations is then tackled using Lehmer codes and factoradics.
  The self-contained source code of the paper, as generated from a literate
Haskell program, is available at
\url{http://logic.csci.unt.edu/tarau/research/2008/fFUN.zip}.
  Keywords: ranking/unranking, pairing/tupling functions, Ackermann encoding,
hereditarily finite sets, hereditarily finite functions, permutations and
factoradics, computational mathematics, Haskell data representations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0754</identifier>
 <datestamp>2008-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0754</id><created>2008-08-05</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>A Functional Hitchhiker's Guide to Hereditarily Finite Sets, Ackermann
  Encodings and Pairing Functions</title><categories>cs.MS cs.DM cs.DS</categories><comments>unpublished draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is organized as a self-contained literate Haskell program that
implements elements of an executable finite set theory with focus on
combinatorial generation and arithmetic encodings. The code, tested under GHC
6.6.1, is available at http://logic.csci.unt.edu/tarau/research/2008/fSET.zip .
  We introduce ranking and unranking functions generalizing Ackermann's
encoding to the universe of Hereditarily Finite Sets with Urelements. Then we
build a lazy enumerator for Hereditarily Finite Sets with Urelements that
matches the unranking function provided by the inverse of Ackermann's encoding
and we describe functors between them resulting in arithmetic encodings for
powersets, hypergraphs, ordinals and choice functions. After implementing a
digraph representation of Hereditarily Finite Sets we define {\em decoration
functions} that can recover well-founded sets from encodings of their
associated acyclic digraphs. We conclude with an encoding of arbitrary digraphs
and discuss a concept of duality induced by the set membership relation.
  Keywords: hereditarily finite sets, ranking and unranking functions,
executable set theory, arithmetic encodings, Haskell data representations,
functional programming and computational mathematics
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0760</identifier>
 <datestamp>2008-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0760</id><created>2008-08-05</created><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Declarative Combinatorics: Boolean Functions, Circuit Synthesis and BDDs
  in Haskell</title><categories>cs.DS</categories><comments>unpublished draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe Haskell implementations of interesting combinatorial generation
algorithms with focus on boolean functions and logic circuit representations.
  First, a complete exact combinational logic circuit synthesizer is described
as a combination of catamorphisms and anamorphisms.
  Using pairing and unpairing functions on natural number representations of
truth tables, we derive an encoding for Binary Decision Diagrams (BDDs) with
the unique property that its boolean evaluation faithfully mimics its
structural conversion to a a natural number through recursive application of a
matching pairing function.
  We then use this result to derive ranking and unranking functions for BDDs
and reduced BDDs.
  Finally, a generalization of the encoding techniques to Multi-Terminal BDDs
is provided.
  The paper is organized as a self-contained literate Haskell program,
available at http://logic.csci.unt.edu/tarau/research/2008/fBDD.zip .
  Keywords: exact combinational logic synthesis, binary decision diagrams,
encodings of boolean functions, pairing/unpairing functions, ranking/unranking
functions for BDDs and MTBDDs, declarative combinatorics in Haskell
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0768</identifier>
 <datestamp>2008-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0768</id><created>2008-08-06</created><authors><author><keyname>Burgin</keyname><forenames>Mark</forenames></author></authors><title>Foundations of Information Theory</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information is the basic concept of information theory. However, there is no
definition of this concept that can encompass all uses of the term information
in information theories and beyond. Many question a possibility of such a
definition. However, foundations of information theory developed in the context
of the general theory of information made it possible to build such a relevant
and at the same time, encompassing definition. Foundations of information
theory are built in a form of ontological principles, which reflect basic
features of information and information processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0845</identifier>
 <datestamp>2008-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0845</id><created>2008-08-06</created><authors><author><keyname>Ma</keyname><forenames>Jian</forenames></author><author><keyname>Sun</keyname><forenames>Zengqi</forenames></author></authors><title>Mutual information is copula entropy</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that mutual information is actually negative copula entropy, based
on which a method for mutual information estimation is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0876</identifier>
 <datestamp>2008-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0876</id><created>2008-08-06</created><authors><author><keyname>Liu</keyname><forenames>Nan</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>Capacity Regions and Bounds for a Class of Z-interference Channels</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. on Information Theory. This material was
  presented in part at the IEEE International Symposium on Information Theory,
  Toronto, Canada, July 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a class of Z-interference channels for which we obtain a new upper
bound on the capacity region. The bound exploits a technique first introduced
by Korner and Marton. A channel in this class has the property that, for the
transmitter-receiver pair that suffers from interference, the conditional
output entropy at the receiver is invariant with respect to the transmitted
codewords. We compare the new capacity region upper bound with the
Han/Kobayashi achievable rate region for interference channels. This comparison
shows that our bound is tight in some cases, thereby yielding specific points
on the capacity region as well as sum capacity for certain Z-interference
channels. In particular, this result can be used as an alternate method to
obtain sum capacity of Gaussian Z-interference channels. We then apply an
additional restriction on our channel class: the transmitter-receiver pair that
suffers from interference achieves its maximum output entropy with a single
input distribution irrespective of the interference distribution. For these
channels we show that our new capacity region upper bound coincides with the
Han/Kobayashi achievable rate region, which is therefore capacity-achieving. In
particular, for these channels superposition encoding with partial decoding is
shown to be optimal and a single-letter characterization for the capacity
region is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0920</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0920</id><created>2008-08-06</created><authors><author><keyname>Arumugam</keyname><forenames>Mahesh</forenames></author></authors><title>A Distributed and Deterministic TDMA Algorithm for
  Write-All-With-Collision Model</title><categories>cs.OS cs.DC</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several self-stabilizing time division multiple access (TDMA) algorithms are
proposed for sensor networks. In addition to providing a collision-free
communication service, such algorithms enable the transformation of programs
written in abstract models considered in distributed computing literature into
a model consistent with sensor networks, i.e., write all with collision (WAC)
model. Existing TDMA slot assignment algorithms have one or more of the
following properties: (i) compute slots using a randomized algorithm, (ii)
assume that the topology is known upfront, and/or (iii) assign slots
sequentially. If these algorithms are used to transform abstract programs into
programs in WAC model then the transformed programs are probabilistically
correct, do not allow the addition of new nodes, and/or converge in a
sequential fashion. In this paper, we propose a self-stabilizing deterministic
TDMA algorithm where a sensor is aware of only its neighbors. We show that the
slots are assigned to the sensors in a concurrent fashion and starting from
arbitrary initial states, the algorithm converges to states where
collision-free communication among the sensors is restored. Moreover, this
algorithm facilitates the transformation of abstract programs into programs in
WAC model that are deterministically correct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0948</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0948</id><created>2008-08-06</created><authors><author><keyname>Kang</keyname><forenames>Wei</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Capacity of a Class of Diamond Channels</title><categories>cs.IT math.IT</categories><comments>15 pages, 3 figures, submitted to IEEE Trans. on Information Theory</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a special class of diamond channels which was introduced by Schein
in 2001. In this special class, each diamond channel consists of a transmitter,
a noisy relay, a noiseless relay and a receiver. We prove the capacity of this
class of diamond channels by providing an achievable scheme and a converse. The
capacity we show is strictly smaller than the cut-set bound. Our result also
shows the optimality of a combination of decode-and-forward (DAF) and
compress-and-forward (CAF) at the noisy relay node. This is the first example
where a combination of DAF and CAF is shown to be capacity achieving. Finally,
we note that there exists a duality between this diamond channel coding problem
and the Kaspi-Berger source coding problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0954</identifier>
 <datestamp>2009-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0954</id><created>2008-08-07</created><updated>2009-05-15</updated><authors><author><keyname>Kim</keyname><forenames>Sang Joon</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Mitran</keyname><forenames>Patrick</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Achievable rate regions for bi-directional relaying</title><categories>cs.IT math.IT</categories><comments>42 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a bi-directional relay channel, two nodes wish to exchange independent
messages over a shared wireless half-duplex channel with the help of a relay.
In this paper, we derive achievable rate regions for four new half-duplex
protocols and compare these to four existing half-duplex protocols and outer
bounds. In time, our protocols consist of either two or three phases. In the
two phase protocols, both users simultaneously transmit during the first phase
and the relay alone transmits during the second phase, while in the three phase
protocol the two users sequentially transmit followed by a transmission from
the relay. The relay may forward information in one of four manners; we outline
existing Amplify and Forward (AF), Decode and Forward (DF) and Compress and
Forward (CF) relaying schemes and introduce the novel Mixed Forward scheme. The
latter is a combination of CF in one direction and DF in the other. We derive
achievable rate regions for the CF and Mixed relaying schemes for the two and
three phase protocols. In the last part of this work we provide a comprehensive
treatment of 8 possible half-duplex bi-directional relaying protocols in
Gaussian noise, obtaining their respective achievable rate regions, outer
bounds, and their relative performance under different SNR and relay
geometries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0962</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0962</id><created>2008-08-07</created><authors><author><keyname>Ansari</keyname><forenames>Amin</forenames></author></authors><title>Verification of Peterson's Algorithm for Leader Election in a
  Unidirectional Asynchronous Ring Using NuSMV</title><categories>cs.LO cs.DC</categories><comments>11 pages, 6 figures</comments><acm-class>D.2.4; C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The finite intrinsic nature of the most distributed algorithms gives us this
ability to use model checking tools for verification of this type of
algorithms. In this paper, I attempt to use NuSMV as a model checking tool for
verifying necessary properties of Peterson's algorithm for leader election
problem in a unidirectional asynchronous ring topology. Peterson's algorithm
for an asynchronous ring supposes that each node in the ring has a unique ID
and also a queue for dealing with storage problem. By considering that the
queue can have any combination of values, a constructed model for a ring with
only four nodes will have more than a billion states. Although it seems that
model checking is not a feasible approach for this problem, I attempt to use
several effective limiting assumptions for hiring formal model checking
approach without losing the correct functionality of the Peterson's algorithm.
These enforced limiting assumptions target the degree of freedom in the model
checking process and significantly decrease the CPU time, memory usage and the
total number of page faults. By deploying these limitations, the number of
nodes can be increased from four to eight in the model checking process with
NuSMV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0973</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0973</id><created>2008-08-07</created><authors><author><keyname>Chemudugunta</keyname><forenames>Chaitanya</forenames></author><author><keyname>Smyth</keyname><forenames>Padhraic</forenames></author><author><keyname>Steyvers</keyname><forenames>Mark</forenames></author></authors><title>Text Modeling using Unsupervised Topic Models and Concept Hierarchies</title><categories>cs.AI cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical topic models provide a general data-driven framework for
automated discovery of high-level knowledge from large collections of text
documents. While topic models can potentially discover a broad range of themes
in a data set, the interpretability of the learned topics is not always ideal.
Human-defined concepts, on the other hand, tend to be semantically richer due
to careful selection of words to define concepts but they tend not to cover the
themes in a data set exhaustively. In this paper, we propose a probabilistic
framework to combine a hierarchy of human-defined semantic concepts with
statistical topic models to seek the best of both worlds. Experimental results
using two different sources of concept hierarchies and two collections of text
documents indicate that this combination leads to systematic improvements in
the quality of the associated language models as well as enabling new
techniques for inferring and visualizing the semantics of a document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0978</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0978</id><created>2008-08-07</created><authors><author><keyname>Scutari</keyname><forenames>Gesualdo</forenames></author><author><keyname>Palomar</keyname><forenames>Daniel P.</forenames></author><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author></authors><title>Cognitive MIMO Radio: A Competitive Optimality Design Based on Subspace
  Projections</title><categories>cs.IT cs.GT math.IT</categories><journal-ref>IEEE Signal Processing Magazine Special Issue on Signal Processing
  for Cognitive Radio Networks, November 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive MIMO Radio: A Competitive Optimality Design Based on Subspace
Projections
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0980</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0980</id><created>2008-08-07</created><authors><author><keyname>Dankelmann</keyname><forenames>Peter</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author></authors><title>On Complexity of Minimum Leaf Out-branching Problem</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a digraph $D$, the Minimum Leaf Out-Branching problem (MinLOB) is the
problem of finding in $D$ an out-branching with the minimum possible number of
leaves, i.e., vertices of out-degree 0. Gutin, Razgon and Kim (2008) proved
that MinLOB is polynomial time solvable for acyclic digraphs which are exactly
the digraphs of directed path-width (DAG-width, directed tree-width,
respectively) 0. We investigate how much one can extend this polynomiality
result. We prove that already for digraphs of directed path-width (directed
tree-width, DAG-width, respectively) 1, MinLOB is NP-hard. On the other hand,
we show that for digraphs of restricted directed tree-width (directed
path-width, DAG-width, respectively) and a fixed integer $k$, the problem of
checking whether there is an out-branching with at most $k$ leaves is
polynomial time solvable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0987</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0987</id><created>2008-08-07</created><authors><author><keyname>Wiczanowski</keyname><forenames>Marcin</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author></authors><title>A new graph perspective on max-min fairness in Gaussian parallel
  channels</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>41 pages, 8 figures. submitted to IEEE Transactions on Information
  Theory on August the 6th, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we are concerned with the problem of achieving max-min fairness
in Gaussian parallel channels with respect to a general performance function,
including channel capacity or decoding reliability as special cases. As our
central results, we characterize the laws which determine the value of the
achievable max-min fair performance as a function of channel sharing policy and
power allocation (to channels and users). In particular, we show that the
max-min fair performance behaves as a specialized version of the Lovasz
function, or Delsarte bound, of a certain graph induced by channel sharing
combinatorics. We also prove that, in addition to such graph, merely a certain
2-norm distance dependent on the allowable power allocations and used
performance functions, is sufficient for the characterization of max-min fair
performance up to some candidate interval. Our results show also a specific
role played by odd cycles in the graph induced by the channel sharing policy
and we present an interesting relation between max-min fairness in parallel
channels and optimal throughput in an associated interference channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1000</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1000</id><created>2008-08-07</created><updated>2010-03-07</updated><authors><author><keyname>Huang</keyname><forenames>Dong</forenames></author><author><keyname>Miao</keyname><forenames>Chunyan</forenames></author><author><keyname>Leung</keyname><forenames>Cyril</forenames></author></authors><title>Fitness Landscape Analysis for Dynamic Resource Allocation in Multiuser
  OFDM Based Cognitive Radio Systems</title><categories>cs.IT cs.NE math.CO math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1007</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1007</id><created>2008-08-07</created><authors><author><keyname>Bjelakovic</keyname><forenames>I.</forenames></author><author><keyname>Boche</keyname><forenames>H.</forenames></author><author><keyname>Noetzel</keyname><forenames>J.</forenames></author></authors><title>On Quantum Capacity of Compound Channels</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>16 pages, no figures</comments><doi>10.1103/PhysRevA.78.042331</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the issue of universal or robust communication over
quantum channels. Specifically, we consider memoryless communication scenario
with channel uncertainty which is an analog of compound channel in classical
information theory. We determine the quantum capacity of finite compound
channels and arbitrary compound channels with informed decoder. Our approach in
the finite case is based on the observation that perfect channel knowledge at
the decoder does not increase the capacity of finite quantum compound channels.
As a consequence we obtain coding theorem for finite quantum averaged channels,
the simplest class of channels with long-term memory. The extension of these
results to quantum compound channels with uninformed encoder and decoder, and
infinitely many constituents remains an open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1062</identifier>
 <datestamp>2008-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1062</id><created>2008-08-07</created><authors><author><keyname>Zhao</keyname><forenames>Qinglin</forenames></author><author><keyname>Liew</keyname><forenames>Soung C.</forenames></author></authors><title>Optimization of Location Management for PCS Networks with CTRW Mobility
  Model</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the design of the optimal locationupdate area (LA) of
the distance-based scheme for personal communication service (PCS) networks. We
focus on the optimization of two design parameters associated with the LA: 1)
initial position upon LA update; 2) distance threshold for triggering of LA
update. Based on the popular continuous-time random walk (CTRW) mobility model,
we propose a novel analytical framework that uses a diffusion equation to
minimize the location management cost. In this framework, a number of
measurable physical parameters, such as length of road section, angle between
road sections, and road section crossing time, can be integrated into the
system design. This framework allows us to easily evaluate the total cost under
general call arrival distributions and LA of different shapes. For the
particular case of circular LA and small Poisson call-arrival rate, we prove
the following: (1) When the drift is weak, the optimal initial position
approaches the center of the LA; when the drift is strong, it approaches the
boundary of the LA. (2) Comparing the optimal initial-position and
center-initial-position solutions (which is assumed in most prior work), when
the drift is weak, the optimal distance threshold and the minimum total cost
are roughly equal; when the drift is strong, the optimal distance threshold in
the later is about 1.260 times that in the former, and the minimum total cost
in the later is about 1.587 times that in the former. That is, optimizing on
initial position, which previous work did not consider, has the potential of
reducing the cost measure by 37%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1108</identifier>
 <datestamp>2008-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1108</id><created>2008-08-07</created><updated>2008-08-15</updated><authors><author><keyname>Bock</keyname><forenames>Nicolas</forenames></author><author><keyname>Rubensson</keyname><forenames>Emanuel H.</forenames></author><author><keyname>Sa&#x142;ek</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Niklasson</keyname><forenames>Anders M. N.</forenames></author><author><keyname>Challacombe</keyname><forenames>Matt</forenames></author></authors><title>Cache oblivious storage and access heuristics for blocked matrix-matrix
  multiplication</title><categories>cs.DS</categories><comments>Fixed typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate effects of ordering in blocked matrix--matrix multiplication.
We find that submatrices do not have to be stored contiguously in memory to
achieve near optimal performance. Instead it is the choice of execution order
of the submatrix multiplications that leads to a speedup of up to four times
for small block sizes. This is in contrast to results for single matrix
elements showing that contiguous memory allocation quickly becomes irrelevant
as the blocksize increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1119</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1119</id><created>2008-08-07</created><authors><author><keyname>Reddi</keyname><forenames>Seenu S.</forenames></author></authors><title>Graham's Schedules and the Number Partition Problem</title><categories>cs.CC cs.DM</categories><comments>6 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show the equivalence of the Number Partition Problem and the two processor
scheduling problem. We establish a priori bounds on the completion times for
the scheduling problem which are tighter than Graham's but almost on par with a
posteriori bounds of Coffman and Sethi. We conclude the paper with a
characterization of the asymptotic behavior of the scheduling problem which
relates to the spread of the processing times and the number of jobs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1125</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1125</id><created>2008-08-08</created><authors><author><keyname>David-Tabibi</keyname><forenames>Omid</forenames></author><author><keyname>Netanyahu</keyname><forenames>Nathan S.</forenames></author></authors><title>Verified Null-Move Pruning</title><categories>cs.AI</categories><comments>9 pages</comments><acm-class>I.2.8</acm-class><journal-ref>ICGA Journal, International Computer Games Association, Vol. 25,
  No. 3, pp. 153--161, September 2002</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we review standard null-move pruning and introduce our
extended version of it, which we call verified null-move pruning. In verified
null-move pruning, whenever the shallow null-move search indicates a fail-high,
instead of cutting off the search from the current node, the search is
continued with reduced depth.
  Our experiments with verified null-move pruning show that on average, it
constructs a smaller search tree with greater tactical strength in comparison
to standard null-move pruning. Moreover, unlike standard null-move pruning,
which fails badly in zugzwang positions, verified null-move pruning manages to
detect most zugzwangs and in such cases conducts a re-search to obtain the
correct result. In addition, verified null-move pruning is very easy to
implement, and any standard null-move pruning program can use verified
null-move pruning by modifying only a few lines of code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1128</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1128</id><created>2008-08-07</created><authors><author><keyname>Chan</keyname><forenames>Timothy M.</forenames></author><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author><author><keyname>Roditty</keyname><forenames>Liam</forenames></author></authors><title>Dynamic Connectivity: Connecting to Networks and Geometry</title><categories>cs.DS cs.CG</categories><comments>Full version of a paper to appear in FOCS 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic connectivity is a well-studied problem, but so far the most
compelling progress has been confined to the edge-update model: maintain an
understanding of connectivity in an undirected graph, subject to edge
insertions and deletions. In this paper, we study two more challenging, yet
equally fundamental problems.
  Subgraph connectivity asks to maintain an understanding of connectivity under
vertex updates: updates can turn vertices on and off, and queries refer to the
subgraph induced by &quot;on&quot; vertices. (For instance, this is closer to
applications in networks of routers, where node faults may occur.)
  We describe a data structure supporting vertex updates in O (m^{2/3})
amortized time, where m denotes the number of edges in the graph. This greatly
improves over the previous result [Chan, STOC'02], which required fast matrix
multiplication and had an update time of O(m^0.94). The new data structure is
also simpler.
  Geometric connectivity asks to maintain a dynamic set of n geometric objects,
and query connectivity in their intersection graph. (For instance, the
intersection graph of balls describes connectivity in a network of sensors with
bounded transmission radius.)
  Previously, nontrivial fully dynamic results were known only for special
cases like axis-parallel line segments and rectangles. We provide similarly
improved update times, O (n^{2/3}), for these special cases. Moreover, we show
how to obtain sublinear update bounds for virtually all families of geometric
objects which allow sublinear-time range queries, such as arbitrary 2D line
segments, d-dimensional simplices, and d-dimensional balls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1207</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1207</id><created>2008-08-08</created><authors><author><keyname>Bradler</keyname><forenames>Dirk</forenames></author><author><keyname>Kangasharju</keyname><forenames>Jussi</forenames></author><author><keyname>Muehlhaeuser</keyname><forenames>Max</forenames></author></authors><title>Optimally Efficient Prefix Search and Multicast in Structured P2P
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Searching in P2P networks is fundamental to all overlay networks.
  P2P networks based on Distributed Hash Tables (DHT) are optimized for single
key lookups, whereas unstructured networks offer more complex queries at the
cost of increased traffic and uncertain success rates. Our Distributed Tree
Construction (DTC) approach enables structured P2P networks to perform prefix
search, range queries, and multicast in an optimal way. It achieves this by
creating a spanning tree over the peers in the search area, using only
information available locally on each peer. Because DTC creates a spanning
tree, it can query all the peers in the search area with a minimal number of
messages. Furthermore, we show that the tree depth has the same upper bound as
a regular DHT lookup which in turn guarantees fast and responsive runtime
behavior. By placing objects with a region quadtree, we can perform a prefix
search or a range query in a freely selectable area of the DHT. Our DTC
algorithm is DHT-agnostic and works with most existing DHTs. We evaluate the
performance of DTC over several DHTs by comparing the performance to existing
application-level multicast solutions, we show that DTC sends 30-250% fewer
messages than common solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1211</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1211</id><created>2008-08-08</created><authors><author><keyname>Saba</keyname><forenames>Walid S.</forenames></author></authors><title>Commonsense Knowledge, Ontology and Ordinary Language</title><categories>cs.AI cs.CL</categories><comments>To appear in Int. J. Reasoning-based Intelligent Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over two decades ago a &quot;quite revolution&quot; overwhelmingly replaced
knowledgebased approaches in natural language processing (NLP) by quantitative
(e.g., statistical, corpus-based, machine learning) methods. Although it is our
firm belief that purely quantitative approaches cannot be the only paradigm for
NLP, dissatisfaction with purely engineering approaches to the construction of
large knowledge bases for NLP are somewhat justified. In this paper we hope to
demonstrate that both trends are partly misguided and that the time has come to
enrich logical semantics with an ontological structure that reflects our
commonsense view of the world and the way we talk about in ordinary language.
In this paper it will be demonstrated that assuming such an ontological
structure a number of challenges in the semantics of natural language (e.g.,
metonymy, intensionality, copredication, nominal compounds, etc.) can be
properly and uniformly addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1215</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1215</id><created>2008-08-08</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Weissman</keyname><forenames>Vicky</forenames></author></authors><title>A Formal Foundation for XrML</title><categories>cs.CR cs.LO</categories><acm-class>K.6.5; K.4.4; D.4.6; F.3; H.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XrML is becoming a popular language in industry for writing software
licenses. The semantics for XrML is implicitly given by an algorithm that
determines if a permission follows from a set of licenses. We focus on a
fragment of the language and use it to highlight some problematic aspects of
the algorithm. We then correct the problems, introduce formal semantics, and
show that our semantics captures the (corrected) algorithm. Next, we consider
the complexity of determining if a permission is implied by a set of XrML
licenses. We prove that the general problem is undecidable, but it is
polynomial-time computable for an expressive fragment of the language. We
extend XrML to capture a wider range of licenses by adding negation to the
language. Finally, we discuss the key differences between XrML and MPEG-21, an
international standard based on XrML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1246</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1246</id><created>2008-08-08</created><updated>2013-01-21</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Romulus</forenames></author><author><keyname>Andreica</keyname><forenames>Angela</forenames></author></authors><title>Minimum Dissatisfaction Personnel Scheduling</title><categories>cs.DS</categories><comments>Some of the algorithmic techniques presented in this paper were later
  used by the first author for developing solutions to several algorithmic
  contest tasks (see the attached zip archive for some examples)</comments><proxy>ccsd</proxy><journal-ref>ARA Congress, Boston : United States (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider two problems regarding the scheduling of available
personnel in order to perform a given quantity of work, which can be
arbitrarily decomposed into a sequence of activities. We are interested in
schedules which minimize the overall dissatisfaction, where each employee's
dissatisfaction is modeled as a time-dependent linear function. For the two
situations considered we provide a detailed mathematical analysis, as well as
efficient algorithms for determining optimal schedules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1247</identifier>
 <datestamp>2008-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1247</id><created>2008-08-08</created><authors><author><keyname>Briot</keyname><forenames>S&#xe9;bastien</forenames><affiliation>DGMA</affiliation></author><author><keyname>Bonev</keyname><forenames>Ilian</forenames><affiliation>GPA</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Arakelian</keyname><forenames>Vigen</forenames><affiliation>DGMA</affiliation></author></authors><title>Self-Motions of General 3-RPR Planar Parallel Robots</title><categories>cs.RO</categories><proxy>ccsd hal-00310393</proxy><journal-ref>International Journal of Robotics Research 27, 7 (2008) pp.
  855-866</journal-ref><doi>10.1177/0278364908092466</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the kinematic geometry of general 3-RPR planar parallel
robots with actuated base joints. These robots, while largely overlooked, have
simple direct kinematics and large singularity-free workspace. Furthermore,
their kinematic geometry is the same as that of a newly developed parallel
robot with SCARA-type motions. Starting from the direct and inverse kinematic
model, the expressions for the singularity loci of 3-RPR planar parallel robots
are determined. Then, the global behaviour at all singularities is
geometrically described by studying the degeneracy of the direct kinematic
model. Special cases of self-motions are then examined and the degree of
freedom gained in such special configurations is kinematically interpreted.
Finally, a practical example is discussed and experimental validations
performed on an actual robot prototype are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1343</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1343</id><created>2008-08-09</created><authors><author><keyname>Kienle</keyname><forenames>Holger M.</forenames></author><author><keyname>Lober</keyname><forenames>Andreas</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Hausi A.</forenames></author></authors><title>Policy and Legal Challenges of Virtual Worlds and Social Network Sites</title><categories>cs.CY</categories><comments>5 pages, 1 table, First International Workshop on Requirements
  Engineering and Law (RELAW 2008), Barcelona, Spain.
  http://www4.ncsu.edu/~tdbreaux/relaw/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses policy challenges of complex virtual environments such
as virtual worlds, social network sites, and massive multiplayer online games.
The complexity of these environments--apparent by the rich user interactions
and sophisticated user-generated content that they offer--poses unique
challenges for policy management and compliance. These challenges are also
impacting the life cycle of the software system that implements the virtual
environment. The goal of this paper is to identify and sketch important legal
and policy challenges of virtual environments and how they affect stakeholders
(i.e., operators, users, and lawmakers). Given the increasing significance of
virtual environments, we expect that tackling these challenges will become
increasingly important in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1354</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1354</id><created>2008-08-09</created><authors><author><keyname>Sadrzadeh</keyname><forenames>Mehrnoosh</forenames></author></authors><title>Ockham's razor and reasoning about information flow</title><categories>math.LO cs.LO</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is the minimal algebraic structure to reason about information flow? Do
we really need the full power of Boolean algebras with co-closure and de Morgan
dual operators? How much can we weaken and still be able to reason about
multi-agent scenarios in a tidy compositional way? This paper provides some
answers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1364</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1364</id><created>2008-08-09</created><authors><author><keyname>Kho&#xe1;t</keyname><forenames>Th&#xe2;n Quang</forenames></author></authors><title>On Bounded Integer Programming</title><categories>cs.CC cs.DM</categories><comments>The preliminary version of this paper appeared in Proceedings of the
  2008 IEEE International Conference on Research, Innovation &amp; Vision for the
  Future - RIVF, July 2008, pages 23-28, Ho Chi Minh city, Vietnam, entitled
  &quot;On the Bounded Integer Programming&quot;</comments><acm-class>G.1.6; F.1.3; F.2; G.2.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present an efficient reduction from the Bounded integer programming (BIP)
to the Subspace avoiding problem (SAP) in lattice theory. The reduction has
some special properties with some interesting consequences. The first is the
new upper time bound for BIP, $poly(\varphi)\cdot n^{n+o(n)}$ (where $n$ and
$\varphi$ are the dimension and the input size of the problem, respectively).
This is the best bound up to now for BIP. The second consequence is the proof
that #SAP, for some norms, is #P-hard under semi-reductions. It follows that
the counting version of the Generalized closest vector problem is also #P-hard
under semi-reductions. Furthermore, we also show that under some reasonable
assumptions, BIP is solvable in probabilistic time $2^{O(n)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1368</identifier>
 <datestamp>2008-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1368</id><created>2008-08-09</created><updated>2008-12-27</updated><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames><affiliation>University of Chicago</affiliation></author><author><keyname>Sochen</keyname><forenames>Nir</forenames><affiliation>Tel Aviv University</affiliation></author></authors><title>On some deterministic dictionaries supporting sparsity</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in the special issue on sparsity (Editors:
  Albert Cohen, Ronald DeVore, Michael Elad, Anna Gilbert) of the Journal of
  Fourier Analysis and Applications (2008). Key words: Sparsity, deterministic
  dictionaries, low coherence, Weil representation, commutative subgroups,
  eigenfunctions, explicit algorithm</comments><journal-ref>Special issue on sparsity, the Journal of Fourier Analysis and
  Applications, Vol. 14, 859-876, Dec. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new construction of an incoherent dictionary, referred to as
the oscillator dictionary, which is based on considerations in the
representation theory of finite groups. The oscillator dictionary consists of
order of p^5 unit vectors in a Hilbert space of dimension p, where p is an odd
prime, whose pairwise inner products have magnitude of at most 4/sqrt(p). An
explicit algorithm to construct a large portion of the oscillator dictionary is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1378</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1378</id><created>2008-08-09</created><authors><author><keyname>Eskander</keyname><forenames>George S.</forenames></author><author><keyname>Atiya</keyname><forenames>Amir F.</forenames></author></authors><title>A Novel Symbolic Type Neural Network Model- Application to River Flow
  Forecasting</title><categories>cs.NE cs.SC</categories><comments>Published in ICENCO2007, Cairo, December 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a new symbolic type neural tree network called
symbolic function network (SFN) that is based on using elementary functions to
model systems in a symbolic form. The proposed formulation permits feature
selection, functional selection, and flexible structure. We applied this model
on the River Flow forecasting problem. The results found to be superior in both
fitness and sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1400</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1400</id><created>2008-08-10</created><authors><author><keyname>Das</keyname><forenames>Smarajit</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Class of Maximal-Rate, Low-PAPR, Non-square Complex Orthogonal Designs</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communication, 25 pages, 5
  figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Space-time block codes (STBCs) from non-square complex orthogonal designs are
bandwidth efficient when compared with those from square real/complex
orthogonal designs. Though there exists rate-1 ROD for any number of transmit
antennas, rate-1 complex orthogonal designs (COD) does not exist for more than
2 transmit antennas. Liang (IEEE Trans. Inform. Theory, 2003) and Lu et al
(IEEE Trans. Inform. Theory, 2005) have constructed a class of maximal rate
non-square CODs where the rate is ${1/2}+\frac{1}{n}$ if number of transmit
antennas $n$ is even and ${1/2}+\frac{1}{n+1}$ if $n$ is odd. In this paper, we
present a simple construction for maximal rate non-square CODs obtained from
square CODs which resembles the construction of rate-1 non-square RODs from
square RODs. These designs are shown to be amenable for construction of a class
of generalized CODs (called Coordinate-Interleaved Scaled CODs) with low
peak-to-average power ratio (PAPR) having the same parameters as the maximal
rate codes. Simulation results indicate that these codes perform better than
the existing maximal rate codes under peak power constraint while performing
the same under average power constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1410</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1410</id><created>2008-08-10</created><authors><author><keyname>Bahar</keyname><forenames>H. B.</forenames></author><author><keyname>Aboutalebi</keyname><forenames>Ali</forenames></author></authors><title>Image Steganography, a New Approach for Transferring Security
  Information</title><categories>cs.CR</categories><comments>7 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Steganography is the art of hiding the fact that communication is taking
place, by hiding information in other information. Many different carrier file
formats can be used, but digital images are the most popular because of their
frequency on the Internet. For hiding secret information in images, there
exists a large variety of steganographic techniques some are more complex than
others and all of them have respective strong and weak points. Different
applications have different requirements of the steganography technique used.
For example, some applications may require absolute invisibility of the secret
information, while others require a larger secret message to be hidden. This
paper intends to give an overview of image steganography, its uses and
techniques. It also attempts to identify the requirements of a good
steganographic algorithm and briefly reflects on which steganographic
techniques are more suitable for which applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1417</identifier>
 <datestamp>2008-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1417</id><created>2008-08-10</created><updated>2008-12-30</updated><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames></author><author><keyname>Sochen</keyname><forenames>Nir</forenames></author></authors><title>The finite harmonic oscillator and its associated sequences</title><categories>cs.IT cs.CR cs.DM math-ph math.GR math.IT math.MP math.NT math.PR math.QA math.RT math.SG quant-ph</categories><comments>Published in the Proceedings of the National Academy of Sciences of
  the United States of America (Communicated by Joseph Bernstein, Tel Aviv
  University, Tel Aviv, Israel)</comments><journal-ref>PNAS, July 22, 2008 vol. 105 no. 29 9869-9873
  http://www.pnas.org/content/105/29/9869.abstract</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A system of functions (signals) on the finite line, called the oscillator
system, is described and studied. Applications of this system for discrete
radar and digital communication theory are explained.
  Keywords: Weil representation, commutative subgroups, eigenfunctions, random
behavior, deterministic construction
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1431</identifier>
 <datestamp>2008-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1431</id><created>2008-08-10</created><updated>2008-08-25</updated><authors><author><keyname>Gunther</keyname><forenames>Neil J.</forenames></author></authors><title>A General Theory of Computational Scalability Based on Rational
  Functions</title><categories>cs.PF cs.DC</categories><comments>14 pages, 5 figures; several typos corrected, 1 reference updated,
  page number reduced with 10 pt font</comments><acm-class>B.8; C.4; C.5.5; D.4.8; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The universal scalability law of computational capacity is a rational
function C_p = P(p)/Q(p) with P(p) a linear polynomial and Q(p) a second-degree
polynomial in the number of physical processors p, that has been long used for
statistical modeling and prediction of computer system performance. We prove
that C_p is equivalent to the synchronous throughput bound for a
machine-repairman with state-dependent service rate. Simpler rational
functions, such as Amdahl's law and Gustafson speedup, are corollaries of this
queue-theoretic bound. C_p is further shown to be both necessary and sufficient
for modeling all practical characteristics of computational scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1455</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1455</id><created>2008-08-11</created><authors><author><keyname>Oliver</keyname><forenames>Ian</forenames></author><author><keyname>Honkola</keyname><forenames>Jukka</forenames></author></authors><title>Personal Semantic Web Through A Space Based Computing Environment</title><categories>cs.NI cs.MA</categories><comments>14 pages, 6 figures. In proceedings: Middleware for the Semantic Web,
  Seconds IEEE Interntional Conference on Semantic Computing, Santa Clara, CA,
  USA, August 4-7, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Semantic Web through technologies such to support the canonical
representation information and presenting it to users in a method by which its
meaning can be understood or at least communi- cated and interpreted by all
parties. As the Semantic Web evolves into more of a computing platform rather
than an information platform more dynamic structures, interactions and
behaviours will evolve leading to systems which localise and personalise this
Dynamic Semantic Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1470</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1470</id><created>2008-08-11</created><authors><author><keyname>Sahoo</keyname><forenames>Sudhakar</forenames></author><author><keyname>Sahoo</keyname><forenames>Sanjaya</forenames></author><author><keyname>Nayak</keyname><forenames>Birendra Kumar</forenames></author><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author></authors><title>Encompression Using Two-dimensional Cellular Automata Rules</title><categories>cs.DM cs.CR</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the algebraic structure of some null boundary as
well as some periodic boundary 2-D Cellular Automata (CA) rules by introducing
a new matrix multiplication operation using only AND, OR instead of most
commonly used AND, EX-OR. This class includes any CA whose rule, when written
as an algebra, is a finite Abelean cyclic group in case of periodic boundary
and a finite commutative cyclic monoid in case of null boundary CA
respectively. The concept of 1-D Multiple Attractor Cellular Automata (MACA) is
extended to 2-D. Using the family of 2-D MACA and the finite Abelian cyclic
group, an efficient encompression algorithm is proposed for binary images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1495</identifier>
 <datestamp>2008-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1495</id><created>2008-08-11</created><updated>2008-12-30</updated><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames></author><author><keyname>Sochen</keyname><forenames>Nir</forenames></author></authors><title>The finite harmonic oscillator and its applications to sequences,
  communication and radar</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory
  (Communicated by Guang Gong, Department of Electrical and Computer
  Engineering, University of Waterloo, Waterloo, Ontario, CANADA)</comments><journal-ref>IEEE Transactions on Information Theory, vol. 54, no. 9, September
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel system, called the oscillator system, consisting of order of p^3
functions (signals) on the finite field F_p; with p an odd prime, is described
and studied. The new functions are proved to satisfy good auto-correlation,
cross-correlation and low peak-to-average power ratio properties. Moreover, the
oscillator system is closed under the operation of discrete Fourier transform.
Applications of the oscillator system for discrete radar and digital
communication theory are explained. Finally, an explicit algorithm to construct
the oscillator system is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1505</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1505</id><created>2008-08-11</created><authors><author><keyname>Abraham</keyname><forenames>Ittai</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>An Almost-Surely Terminating Polynomial Protocol for Asynchronous
  Byzantine Agreement with Optimal Resilience</title><categories>cs.DC</categories><acm-class>C.2.4; D.4.5; D.4.7; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an asynchronous system with private channels and $n$ processes, up
to $t$ of which may be faulty. We settle a longstanding open question by
providing a Byzantine agreement protocol that simultaneously achieves three
properties:
  1. (optimal) resilience: it works as long as $n&gt;3t$
  2. (almost-sure) termination: with probability one, all nonfaulty processes
terminate
  3. (polynomial) efficiency: the expected computation time, memory
consumption, message size, and number of messages sent are all polynomial in
$n$.
  Earlier protocols have achieved only two of these three properties. In
particular, the protocol of Bracha is not polynomially efficient, the protocol
of Feldman and Micali is not optimally resilient, and the protocol of Canetti
and Rabin does not have almost-sure termination. Our protocol utilizes a new
primitive called shunning (asynchronous) verifiable secret sharing (SVSS),
which ensures, roughly speaking, that either a secret is successfully shared or
a new faulty process is ignored from this point onwards by some nonfaulty
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1508</identifier>
 <datestamp>2008-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1508</id><created>2008-08-11</created><authors><author><keyname>Collavizza</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>I3S</affiliation></author><author><keyname>Rueher</keyname><forenames>Michel</forenames><affiliation>I3S</affiliation></author><author><keyname>Van Hentenryck</keyname><forenames>Pascal</forenames><affiliation>Brown University</affiliation></author></authors><title>Comparison between CPBPV, ESC/Java, CBMC, Blast, EUREKA and Why for
  Bounded Program Verification</title><categories>cs.SE cs.AI cs.LO</categories><proxy>ccsd hal-00274546</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report describes experimental results for a set of benchmarks on program
verification. It compares the capabilities of CPBVP &quot;Constraint Programming
framework for Bounded Program Verification&quot; [4] with the following frameworks:
ESC/Java, CBMC, Blast, EUREKA and Why.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1549</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1549</id><created>2008-08-11</created><updated>2008-11-19</updated><authors><author><keyname>Percus</keyname><forenames>Allon G.</forenames></author><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author><author><keyname>Goncalves</keyname><forenames>Bruno</forenames></author><author><keyname>Sumi</keyname><forenames>Robert Z.</forenames></author><author><keyname>Boettcher</keyname><forenames>Stefan</forenames></author></authors><title>The Peculiar Phase Structure of Random Graph Bisection</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC cs.DM</categories><comments>substantially revised section 2, changed figures 3, 4 and 6, made
  minor stylistic changes and added references</comments><report-no>LA-UR 08-5099</report-no><journal-ref>J. Math. Phys. 49, 125219 (2008)</journal-ref><doi>10.1063/1.3043666</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mincut graph bisection problem involves partitioning the n vertices of a
graph into disjoint subsets, each containing exactly n/2 vertices, while
minimizing the number of &quot;cut&quot; edges with an endpoint in each subset. When
considered over sparse random graphs, the phase structure of the graph
bisection problem displays certain familiar properties, but also some
surprises. It is known that when the mean degree is below the critical value of
2 log 2, the cutsize is zero with high probability. We study how the minimum
cutsize increases with mean degree above this critical threshold, finding a new
analytical upper bound that improves considerably upon previous bounds.
Combined with recent results on expander graphs, our bound suggests the unusual
scenario that random graph bisection is replica symmetric up to and beyond the
critical threshold, with a replica symmetry breaking transition possibly taking
place above the threshold. An intriguing algorithmic consequence is that
although the problem is NP-hard, we can find near-optimal cutsizes (whose ratio
to the optimal value approaches 1 asymptotically) in polynomial time for
typical instances near the phase transition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1599</identifier>
 <datestamp>2008-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1599</id><created>2008-08-11</created><authors><author><keyname>Kim</keyname><forenames>Jeong Han</forenames></author></authors><title>Finding cores of random 2-SAT formulae via Poisson cloning</title><categories>math.CO cs.CC math.PR</categories><msc-class>05C80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the random 2-SAT formula $F(n,p)$, let $F_C (n,p)$ be the formula left
after the pure literal algorithm applied to $F(n,p)$ stops. Using the recently
developed Poisson cloning model together with the cut-off line algorithm
(COLA), we completely analyze the structure of $F_{C} (n,p)$. In particular, it
is shown that, for $\gl:= p(2n-1) = 1+\gs $ with $\gs\gg n^{-1/3}$, the core of
$F(n,p)$ has $\thl^2 n +O((\thl n)^{1/2})$ variables and $\thl^2 \gl n+O((\thl
n))^{1/2}$ clauses, with high probability, where $\thl$ is the larger solution
of the equation $\th- (1-e^{-\thl \gl})=0$. We also estimate the probability of
$F(n,p)$ being satisfiable to obtain $$ \pr[ F_2(n, \sfrac{\gl}{2n-1}) is
satisfiable ] = \caseth{1-\frac{1+o(1)}{16\gs^3 n}}{if $\gl= 1-\gs$ with
$\gs\gg n^{-1/3}$}{}{}{e^{-\Theta(\gs^3n)}}{if $\gl=1+\gs$ with $\gs\gg
n^{-1/3}$,} $$ where $o(1)$ goes to 0 as $\gs$ goes to 0. This improves the
bounds of Bollob\'as et al. \cite{BBCKW}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1641</identifier>
 <datestamp>2008-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1641</id><created>2008-08-12</created><authors><author><keyname>Sahoo</keyname><forenames>Sudhakar</forenames></author><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author><author><keyname>Chakraborty</keyname><forenames>Mithun</forenames></author></authors><title>Characterization Of any Non-linear Boolean function Using A Set of
  Linear Operators</title><categories>cs.CC nlin.CG</categories><comments>12 pages, 4 figures, 2 table. Submitted for possible publication in
  the International Journal of Computer Mathematics and Applications, July 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Global dynamics of a non-linear Cellular Automata is, in general irregular,
asymmetric and unpredictable as opposed to that of a linear CA, which is highly
systematic and tractable. In the past efforts have been made to systematize
non-linear CA evolutions in the light of Boolean derivatives and Jacobian
Matrices. In this paper two different efforts have been made: first we try to
systematize non-linear CA evolution in the light of deviant states and
non-deviant states. For all the non-deviant states the nearest linear rule
matrix is applicable where as for the deviant states we have a set of other
matrices. Second using algebraic manipulation, an efficient algorithm is
proposed by which every Non-linear Boolean function can be characterized by a
sequence of binary matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1657</identifier>
 <datestamp>2009-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1657</id><created>2008-08-12</created><updated>2009-01-23</updated><authors><author><keyname>Allouche</keyname><forenames>Jean-Paul</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Periodicity, repetitions, and orbits of an automatic sequence</title><categories>cs.DM cs.FL</categories><comments>preliminary version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit a technique of S. Lehr on automata and use it to prove old and new
results in a simple way. We give a very simple proof of the 1986 theorem of
Honkala that it is decidable whether a given k-automatic sequence is ultimately
periodic. We prove that it is decidable whether a given k-automatic sequence is
overlap-free (or squareefree, or cubefree, etc.) We prove that the
lexicographically least sequence in the orbit closure of a k-automatic sequence
is k-automatic, and use this last result to show that several related
quantities, such as the critical exponent, irrationality measure, and
recurrence quotient for Sturmian words with slope alpha, have automatic
continued fraction expansions if alpha does.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1661</identifier>
 <datestamp>2008-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1661</id><created>2008-08-12</created><authors><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Medical robotics: where we come from, where we are and where we could go</title><categories>cs.RO</categories><proxy>ccsd hal-00310983</proxy><journal-ref>The Industrial Robot 35, 4 (2008) 289</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note presents a viewpoint about medical robotics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1671</identifier>
 <datestamp>2008-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1671</id><created>2008-08-12</created><authors><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Hartline</keyname><forenames>Jason</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author></authors><title>Algorithmic Pricing via Virtual Valuations</title><categories>cs.GT cs.DS</categories><comments>A preliminary version of this work appeared at the ACM EC'07
  conference. The current version contains improved results and simpler
  algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic pricing is the computational problem that sellers (e.g., in
supermarkets) face when trying to set prices for their items to maximize their
profit in the presence of a known demand. Guruswami et al. (2005) propose this
problem and give logarithmic approximations (in the number of consumers) when
each consumer's values for bundles are known precisely. Subsequently several
versions of the problem have been shown to have poly-logarithmic
inapproximability. This problem has direct ties to the important open question
of better understanding the Bayesian optimal mechanism in multi-parameter
settings; however, logarithmic approximations are inadequate for this purpose.
It is therefore of vital interest to consider special cases where constant
approximations are possible. We consider the unit-demand variant of this
problem. Here a consumer has a valuation for each different item and their
value for a set of items is simply the maximum value they have for any item in
the set. We assume that the preferences of the consumers are drawn from a
distribution, the standard assumption in economics; furthermore, the setting of
a specific set of customers with known preferences, which is employed in all
prior work in algorithmic pricing, is a special case of this general problem,
where there is a discrete Bayesian distribution for preferences specified by
picking one consumer uniformly from the given set of consumers. Our work
complements these existing works by considering the case where the consumer's
valuations for the different items are independent random variables. Our main
result is a constant approximation that makes use of an interesting connection
between this problem and the concept of virtual valuations from the
single-parameter Bayesian optimal mechanism design literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1721</identifier>
 <datestamp>2008-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1721</id><created>2008-08-12</created><authors><author><keyname>Fodor</keyname><forenames>Paul</forenames></author></authors><title>Initial Results on the F-logic to OWL Bi-directional Translation on a
  Tabled Prolog Engine</title><categories>cs.AI cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show our results on the bi-directional data exchange
between the F-logic language supported by the Flora2 system and the OWL
language. Most of the TBox and ABox axioms are translated preserving the
semantics between the two representations, such as: proper inclusion,
individual definition, functional properties, while some axioms and
restrictions require a change in the semantics, such as: numbered and qualified
cardinality restrictions. For the second case, we translate the OWL definite
style inference rules into F-logic style constraints. We also describe a set of
reasoning examples using the above translation, including the reasoning in
Flora2 of a variety of ABox queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1744</identifier>
 <datestamp>2008-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1744</id><created>2008-08-12</created><authors><author><keyname>Brodsky</keyname><forenames>Alex</forenames></author><author><keyname>Lindenberg</keyname><forenames>Scott</forenames></author></authors><title>Our Brothers' Keepers: Secure Routing with High Performance</title><categories>cs.DC cs.CR cs.NI</categories><comments>11 pages, 4 figures</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Trinity (Brodsky et al., 2007) spam classification system is based on a
distributed hash table that is implemented using a structured peer-to-peer
overlay. Such an overlay must be capable of processing hundreds of messages per
second, and must be able to route messages to their destination even in the
presence of failures and malicious peers that misroute packets or inject
fraudulent routing information into the system. Typically there is tension
between the requirements to route messages securely and efficiently in the
overlay.
  We describe a secure and efficient routing extension that we developed within
the I3 (Stoica et al. 2004) implementation of the Chord (Stoica et al. 2001)
overlay. Secure routing is accomplished through several complementary
approaches: First, peers in close proximity form overlapping groups that police
themselves to identify and mitigate fraudulent routing information. Second, a
form of random routing solves the problem of entire packet flows passing
through a malicious peer. Third, a message authentication mechanism links each
message to it sender, preventing spoofing. Fourth, each peer's identifier links
the peer to its network address, and at the same time uniformly distributes the
peers in the key-space.
  Lastly, we present our initial evaluation of the system, comprising a 255
peer overlay running on a local cluster. We describe our methodology and show
that the overhead of our secure implementation is quite reasonable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1753</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1753</id><created>2008-08-12</created><updated>2008-09-23</updated><authors><author><keyname>Krizhanovsky</keyname><forenames>A. A.</forenames></author></authors><title>Index wiki database: design and experiments</title><categories>cs.IR cs.CL</categories><comments>18 pages, 4 tables, 4 figures; FLINS'08, Corpus Linguistics'08,
  AIS/CAD'08; v2: table 3 changed</comments><acm-class>I.7.2; I.7.3; I.7.5; H.3.1; H.3.3</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  With the fantastic growth of Internet usage, information search in documents
of a special type called a &quot;wiki page&quot; that is written using a simple markup
language, has become an important problem. This paper describes the software
architectural model for indexing wiki texts in three languages (Russian,
English, and German) and the interaction between the software components (GATE,
Lemmatizer, and Synarcher). The inverted file index database was designed using
visual tool DBDesigner. The rules for parsing Wikipedia texts are illustrated
by examples. Two index databases of Russian Wikipedia (RW) and Simple English
Wikipedia (SEW) are built and compared. The size of RW is by order of magnitude
higher than SEW (number of words, lexemes), though the growth rate of number of
pages in SEW was found to be 14% higher than in Russian, and the rate of
acquisition of new words in SEW lexicon was 7% higher during a period of five
months (from September 2007 to February 2008). The Zipf's law was tested with
both Russian and Simple Wikipedias. The entire source code of the indexing
software and the generated index databases are freely available under GPL (GNU
General Public License).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1762</identifier>
 <datestamp>2008-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1762</id><created>2008-08-12</created><updated>2008-08-19</updated><authors><author><keyname>Shi</keyname><forenames>Yaoyun</forenames></author><author><keyname>Zhang</keyname><forenames>Zhiqiang</forenames></author></authors><title>Communication Complexities of XOR functions</title><categories>quant-ph cs.CC</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We call $F:\{0, 1\}^n\times \{0, 1\}^n\to\{0, 1\}$ a symmetric XOR function
if for a function $S:\{0, 1, ..., n\}\to\{0, 1\}$, $F(x, y)=S(|x\oplus y|)$,
for any $x, y\in\{0, 1\}^n$, where $|x\oplus y|$ is the Hamming weight of the
bit-wise XOR of $x$ and $y$.
  We show that for any such function, (a) the deterministic communication
complexity is always $\Theta(n)$ except for four simple functions that have a
constant complexity, and (b) up to a polylog factor, the error-bounded
randomized and quantum communication complexities are $\Theta(r_0+r_1)$, where
$r_0$ and $r_1$ are the minimum integers such that $r_0, r_1\leq n/2$ and
$S(k)=S(k+2)$ for all $k\in[r_0, n-r_1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1766</identifier>
 <datestamp>2008-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1766</id><created>2008-08-12</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>The Optimal Quantile Estimator for Compressed Counting</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Counting (CC) was recently proposed for very efficiently computing
the (approximate) $\alpha$th frequency moments of data streams, where $0&lt;\alpha
&lt;= 2$. Several estimators were reported including the geometric mean estimator,
the harmonic mean estimator, the optimal power estimator, etc. The geometric
mean estimator is particularly interesting for theoretical purposes. For
example, when $\alpha -&gt; 1$, the complexity of CC (using the geometric mean
estimator) is $O(1/\epsilon)$, breaking the well-known large-deviation bound
$O(1/\epsilon^2)$. The case $\alpha\approx 1$ has important applications, for
example, computing entropy of data streams.
  For practical purposes, this study proposes the optimal quantile estimator.
Compared with previous estimators, this estimator is computationally more
efficient and is also more accurate when $\alpha&gt; 1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1771</identifier>
 <datestamp>2008-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1771</id><created>2008-08-12</created><updated>2008-08-21</updated><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>A Very Efficient Scheme for Estimating Entropy of Data Streams Using
  Compressed Counting</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Counting (CC)} was recently proposed for approximating the
$\alpha$th frequency moments of data streams, for $0&lt;\alpha \leq 2$. Under the
relaxed strict-Turnstile model, CC dramatically improves the standard algorithm
based on symmetric stable random projections}, especially as $\alpha\to 1$. A
direct application of CC is to estimate the entropy, which is an important
summary statistic in Web/network measurement and often serves a crucial
&quot;feature&quot; for data mining. The R\'enyi entropy and the Tsallis entropy are
functions of the $\alpha$th frequency moments; and both approach the Shannon
entropy as $\alpha\to 1$. A recent theoretical work suggested using the
$\alpha$th frequency moment to approximate the Shannon entropy with
$\alpha=1+\delta$ and very small $|\delta|$ (e.g., $&lt;10^{-4}$).
  In this study, we experiment using CC to estimate frequency moments, R\'enyi
entropy, Tsallis entropy, and Shannon entropy, on real Web crawl data. We
demonstrate the variance-bias trade-off in estimating Shannon entropy and
provide practical recommendations. In particular, our experiments enable us to
draw some important conclusions:
  (1) As $\alpha\to 1$, CC dramatically improves {\em symmetric stable random
projections} in estimating frequency moments, R\'enyi entropy, Tsallis entropy,
and Shannon entropy. The improvements appear to approach &quot;infinity.&quot;
  (2) Using {\em symmetric stable random projections} and $\alpha = 1+\delta$
with very small $|\delta|$ does not provide a practical algorithm because the
required sample size is enormous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1787</identifier>
 <datestamp>2008-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1787</id><created>2008-08-13</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Grigorescu</keyname><forenames>Elena</forenames></author><author><keyname>Jung</keyname><forenames>Kyomin</forenames></author><author><keyname>Raskhodnikova</keyname><forenames>Sofya</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>Transitive-Closure Spanners</title><categories>cs.DS cs.CC</categories><comments>Extended abstract with appendices</comments><acm-class>F.2.2; G.2.2; G.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a directed graph G = (V,E) and an integer k&gt;=1, a
k-transitive-closure-spanner (k-TC-spanner) of G is a directed graph H = (V,
E_H) that has (1) the same transitive-closure as G and (2) diameter at most k.
These spanners were implicitly studied in access control, data structures, and
property testing, and properties of these spanners have been rediscovered over
the span of 20 years. The main goal in each of these applications is to obtain
the sparsest k-TC-spanners. We bring these diverse areas under the unifying
framework of TC-spanners.
  We initiate the study of approximability of the size of the sparsest
k-TC-spanner for a given directed graph. We completely resolve the
approximability of 2-TC-spanners, showing that it is Theta(log n) unless P =
NP. For k&gt;2, we present a polynomial-time algorithm that finds a k-TC-spanner
with size within O((n log n)^{1-1/k}) of the optimum. Our algorithmic
techniques also yield algorithms with the best-known approximation ratio for
well-studied problems on directed spanners when k&gt;3: DIRECTED k-SPANNER,
CLIENT/SERVER DIRECTED k-SPANNER, and k-DIAMETER SPANNING SUBGRAPH. For
constant k&gt;=3, we show that the size of the sparsest k-TC-spanner is hard to
approximate with 2^{log^{1-eps} n} ratio unless NP \subseteq DTIME(n^{polylog
n}}). Finally, we study the size of the sparsest k-TC-spanners for H-minor-free
graph families. Combining our constructions with our insight that 2-TC-spanners
can be used for designing property testers, we obtain a monotonicity tester
with O(log^2 n /eps) queries for any poset whose transitive reduction is an
H-minor free digraph, improving the Theta(sqrt(n) log n/eps)-queries required
of the tester due to Fischer et al (2002).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1802</identifier>
 <datestamp>2008-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1802</id><created>2008-08-13</created><authors><author><keyname>Grossman</keyname><forenames>Robert L.</forenames></author><author><keyname>Gu</keyname><forenames>Yunhong</forenames></author><author><keyname>Sabala</keyname><forenames>Michael</forenames></author><author><keyname>Zhang</keyname><forenames>Wanzhi</forenames></author></authors><title>Compute and Storage Clouds Using Wide Area High Performance Networks</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a cloud based infrastructure that we have developed that is
optimized for wide area, high performance networks and designed to support data
mining applications. The infrastructure consists of a storage cloud called
Sector and a compute cloud called Sphere. We describe two applications that we
have built using the cloud and some experimental studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1928</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1928</id><created>2008-08-13</created><updated>2008-12-12</updated><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author><author><keyname>Xu</keyname><forenames>Zhi</forenames></author></authors><title>Decision Problems For Convex Languages</title><categories>cs.CC cs.DM cs.FL</categories><comments>preliminary version. This version corrected one typo in Section
  2.1.1, line 4</comments><journal-ref>Proc. LATA 2009 Conference, LNICS #5457, pp. 247-258</journal-ref><doi>10.1007/978-3-642-00982-2_21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we examine decision problems associated with various classes of
convex languages, studied by Ang and Brzozowski (under the name &quot;continuous
languages&quot;). We show that we can decide whether a given language L is prefix-,
suffix-, factor-, or subword-convex in polynomial time if L is represented by a
DFA, but that the problem is PSPACE-hard if L is represented by an NFA. In the
case that a regular language is not convex, we prove tight upper bounds on the
length of the shortest words demonstrating this fact, in terms of the number of
states of an accepting DFA. Similar results are proved for some subclasses of
convex languages: the prefix-, suffix-, factor-, and subword-closed languages,
and the prefix-, suffix-, factor-, and subword-free languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2017</identifier>
 <datestamp>2008-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2017</id><created>2008-08-14</created><authors><author><keyname>Abraham</keyname><forenames>Ittai</forenames></author><author><keyname>Bartal</keyname><forenames>Yair</forenames></author><author><keyname>Neiman</keyname><forenames>Ofer</forenames></author></authors><title>Nearly Tight Low Stretch Spanning Trees</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that any graph $G$ with $n$ points has a distribution $\mathcal{T}$
over spanning trees such that for any edge $(u,v)$ the expected stretch $E_{T
\sim \mathcal{T}}[d_T(u,v)/d_G(u,v)]$ is bounded by $\tilde{O}(\log n)$. Our
result is obtained via a new approach of building ``highways'' between portals
and a new strong diameter probabilistic decomposition theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2045</identifier>
 <datestamp>2008-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2045</id><created>2008-08-14</created><authors><author><keyname>Pryor</keyname><forenames>Louise</forenames></author></authors><title>Correctness is not enough</title><categories>cs.SE cs.HC</categories><comments>6 Pages, 1 Table, 2 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2003 117-122
  ISBN 1 86166 199 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The usual aim of spreadsheet audit is to verify correctness. There are two
problems with this: first, it is often difficult to tell whether the
spreadsheets in question are correct, and second, even if they are, they may
still give the wrong results. These problems are explained in this paper, which
presents the key criteria for judging a spreadsheet and discusses how those
criteria can be achieved
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2059</identifier>
 <datestamp>2008-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2059</id><created>2008-08-14</created><authors><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Diversity-Multiplexing Tradeoffs in MIMO Relay Channels</title><categories>cs.IT math.IT</categories><comments>To appear at IEEE Global Communications Conf. (Globecom), New
  Orleans, LA, Nov. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multi-hop relay channel with multiple antenna terminals in a quasi-static
slow fading environment is considered. For both full-duplex and half-duplex
relays the fundamental diversity-multiplexing tradeoff (DMT) is analyzed. It is
shown that, while decode-and-forward (DF) relaying achieves the optimal DMT in
the full-duplex relay scenario, the dynamic decode-and-forward (DDF) protocol
is needed to achieve the optimal DMT if the relay is constrained to half-duplex
operation. For the latter case, static protocols are considered as well, and
the corresponding achievable DMT performance is characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2073</identifier>
 <datestamp>2008-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2073</id><created>2008-08-14</created><authors><author><keyname>Dimakis</keyname><forenames>A. G.</forenames></author><author><keyname>Wainwright</keyname><forenames>M. J.</forenames></author><author><keyname>Ramchandran</keyname><forenames>K.</forenames></author></authors><title>Lower Bounds on the Rate-Distortion Function of LDGM Codes</title><categories>cs.IT math.IT</categories><comments>22 Pages, Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent line of work has focused on the use of low-density generator matrix
(LDGM) codes for lossy source coding. In this paper, wedevelop a generic
technique for deriving lower bounds on the rate-distortion functions of binary
linear codes, with particular interest on the effect of bounded degrees. The
underlying ideas can be viewing as the source coding analog of the classical
result of Gallager, providing bounds for channel coding over the binary
symmetric channel using bounded degree LDPC codes. We illustrate this method
for different random ensembles of LDGM codes, including the check-regular
ensemble and bit-check-regular ensembles, by deriving explicit lower bounds on
their rate-distortion performance as a function of the degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2081</identifier>
 <datestamp>2008-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2081</id><created>2008-08-14</created><updated>2008-10-03</updated><authors><author><keyname>Ackermann</keyname><forenames>Heiner</forenames></author><author><keyname>Berenbrink</keyname><forenames>Petra</forenames></author><author><keyname>Fischer</keyname><forenames>Simon</forenames></author><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author></authors><title>Concurrent Imitation Dynamics in Congestion Games</title><categories>cs.GT</categories><comments>28 pages, 1 figure</comments><acm-class>F.2.2; G.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imitating successful behavior is a natural and frequently applied approach to
trust in when facing scenarios for which we have little or no experience upon
which we can base our decision. In this paper, we consider such behavior in
atomic congestion games. We propose to study concurrent imitation dynamics that
emerge when each player samples another player and possibly imitates this
agents' strategy if the anticipated latency gain is sufficiently large. Our
main focus is on convergence properties. Using a potential function argument,
we show that our dynamics converge in a monotonic fashion to stable states. In
such a state none of the players can improve its latency by imitating somebody
else. As our main result, we show rapid convergence to approximate equilibria.
At an approximate equilibrium only a small fraction of agents sustains a
latency significantly above or below average. In particular, imitation dynamics
behave like fully polynomial time approximation schemes (FPTAS). Fixing all
other parameters, the convergence time depends only in a logarithmic fashion on
the number of agents. Since imitation processes are not innovative they cannot
discover unused strategies. Furthermore, strategies may become extinct with
non-zero probability. For the case of singleton games, we show that the
probability of this event occurring is negligible. Additionally, we prove that
the social cost of a stable state reached by our dynamics is not much worse
than an optimal state in singleton congestion games with linear latency
function. Finally, we discuss how the protocol can be extended such that, in
the long run, dynamics converge to a Nash equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2083</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2083</id><created>2008-08-14</created><updated>2009-01-19</updated><authors><author><keyname>Kaser</keyname><forenames>Owen</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Aouiche</keyname><forenames>Kamel</forenames></author></authors><title>Histogram-Aware Sorting for Enhanced Word-Aligned Compression in Bitmap
  Indexes</title><categories>cs.DB</categories><comments>To appear in proceedings of DOLAP 2008</comments><acm-class>H.3.2; E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bitmap indexes must be compressed to reduce input/output costs and minimize
CPU usage. To accelerate logical operations (AND, OR, XOR) over bitmaps, we use
techniques based on run-length encoding (RLE), such as Word-Aligned Hybrid
(WAH) compression. These techniques are sensitive to the order of the rows: a
simple lexicographical sort can divide the index size by 9 and make indexes
several times faster. We investigate reordering heuristics based on computed
attribute-value histograms. Simply permuting the columns of the table based on
these histograms can increase the sorting efficiency by 40%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2089</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2089</id><created>2008-08-14</created><updated>2010-10-07</updated><authors><author><keyname>Liu</keyname><forenames>Jialing</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author></authors><title>Capacity-achieving Feedback Scheme for Gaussian Finite-State Markov
  Channels with Channel State Information</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory. 31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose capacity-achieving communication schemes for
Gaussian finite-state Markov channels (FSMCs) subject to an average channel
input power constraint, under the assumption that the transmitters can have
access to delayed noiseless output feedback as well as instantaneous or delayed
channel state information (CSI). We show that the proposed schemes reveals
connections between feedback communication and feedback control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2092</identifier>
 <datestamp>2008-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2092</id><created>2008-08-15</created><authors><author><keyname>Burnashev</keyname><forenames>Marat V.</forenames></author><author><keyname>Yamamoto</keyname><forenames>Hirosuke</forenames></author></authors><title>On zero-rate error exponent for BSC with noisy feedback</title><categories>cs.IT math.IT</categories><comments>23 Pages including 4 figures</comments><acm-class>H.1.1</acm-class><journal-ref>Problems of Information Transmission, vol. 44, no. 3, pp. 33-49,
  2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the information transmission a binary symmetric channel is used. There is
also another noisy binary symmetric channel (feedback channel), and the
transmitter observes without delay all the outputs of the forward channel via
that feedback channel. The transmission of a nonexponential number of messages
(i.e. the transmission rate equals zero) is considered. The achievable decoding
error exponent for such a combination of channels is investigated. It is shown
that if the crossover probability of the feedback channel is less than a
certain positive value, then the achievable error exponent is better than the
similar error exponent of the no-feedback channel.
  The transmission method described and the corresponding lower bound for the
error exponent can be strengthened, and also extended to the positive
transmission rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2181</identifier>
 <datestamp>2008-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2181</id><created>2008-08-15</created><updated>2008-08-16</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author></authors><title>Spectrum Sharing Between Cellular and Mobile Ad Hoc Networks:
  Transmission-Capacity Trade-Off</title><categories>cs.IT math.IT</categories><comments>23 pages, 7 figures, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sharing between wireless networks improves the efficiency of
spectrum usage, and thereby alleviates spectrum scarcity due to growing demands
for wireless broadband access. To improve the usual underutilization of the
cellular uplink spectrum, this paper studies spectrum sharing between a
cellular uplink and a mobile ad hoc networks. These networks access either all
frequency sub-channels or their disjoint sub-sets, called spectrum underlay and
spectrum overlay, respectively. Given these spectrum sharing methods, the
capacity trade-off between the coexisting networks is analyzed based on the
transmission capacity of a network with Poisson distributed transmitters. This
metric is defined as the maximum density of transmitters subject to an outage
constraint for a given signal-to-interference ratio (SIR). Using tools from
stochastic geometry, the transmission-capacity trade-off between the coexisting
networks is analyzed, where both spectrum overlay and underlay as well as
successive interference cancelation (SIC) are considered. In particular, for
small target outage probability, the transmission capacities of the coexisting
networks are proved to satisfy a linear equation, whose coefficients depend on
the spectrum sharing method and whether SIC is applied. This linear equation
shows that spectrum overlay is more efficient than spectrum underlay.
Furthermore, this result also provides insight into the effects of different
network parameters on transmission capacities, including link diversity gains,
transmission distances, and the base station density. In particular, SIC is
shown to increase transmission capacities of both coexisting networks by a
linear factor, which depends on the interference-power threshold for qualifying
canceled interferers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2220</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2220</id><created>2008-08-15</created><updated>2009-06-07</updated><authors><author><keyname>Calude</keyname><forenames>Cristian S.</forenames></author><author><keyname>Hay</keyname><forenames>Nicholas J.</forenames></author></authors><title>Every Computably Enumerable Random Real Is Provably Computably
  Enumerable Random</title><categories>cs.CC cs.LO math.LO</categories><comments>28 pages, minor update. Logic Journal of the IGPL, to appear in 2009</comments><report-no>CDMTCS Research Report 328, 2008</report-no><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that every computably enumerable (c.e.) random real is provable in
Peano Arithmetic (PA) to be c.e. random. A major step in the proof is to show
that the theorem stating that &quot;a real is c.e. and random iff it is the halting
probability of a universal prefix-free Turing machine&quot; can be proven in PA. Our
proof, which is simpler than the standard one, can also be used for the
original theorem.
  Our positive result can be contrasted with the case of computable functions,
where not every computable function is provably computable in PA, or even more
interestingly, with the fact that almost all random finite strings are not
provably random in PA.
  We also prove two negative results: a) there exists a universal machine whose
universality cannot be proved in PA, b) there exists a universal machine $U$
such that, based on $U$, PA cannot prove the randomness of its halting
probability.
  The paper also includes a sharper form of the Kraft-Chaitin Theorem, as well
as a formal proof of this theorem written with the proof assistant Isabelle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2222</identifier>
 <datestamp>2008-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2222</id><created>2008-08-15</created><authors><author><keyname>Andoni</keyname><forenames>Alexandr</forenames></author><author><keyname>McGregor</keyname><forenames>Andrew</forenames></author><author><keyname>Onak</keyname><forenames>Krzysztof</forenames></author><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author></authors><title>Better Bounds for Frequency Moments in Random-Order Streams</title><categories>cs.DS</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating frequency moments of data streams is a very well studied problem
and tight bounds are known on the amount of space that is necessary and
sufficient when the stream is adversarially ordered. Recently, motivated by
various practical considerations and applications in learning and statistics,
there has been growing interest into studying streams that are randomly
ordered. In the paper we improve the previous lower bounds on the space
required to estimate the frequency moments of a randomly ordered streams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2227</identifier>
 <datestamp>2008-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2227</id><created>2008-08-15</created><authors><author><keyname>Bhattacharya</keyname><forenames>C</forenames></author></authors><title>Higher Order Moments Generation by Mellin Transform for Compound Models
  of Clutter</title><categories>cs.CV</categories><comments>4pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The compound models of clutter statistics are found suitable to describe the
nonstationary nature of radar backscattering from high-resolution observations.
In this letter, we show that the properties of Mellin transform can be utilized
to generate higher order moments of simple and compound models of clutter
statistics in a compact manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2246</identifier>
 <datestamp>2008-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2246</id><created>2008-08-16</created><authors><author><keyname>Lauser</keyname><forenames>Boris</forenames></author><author><keyname>Johannsen</keyname><forenames>Gudrun</forenames></author><author><keyname>Caracciolo</keyname><forenames>Caterina</forenames></author><author><keyname>Keizer</keyname><forenames>Johannes</forenames></author><author><keyname>van Hage</keyname><forenames>Willem Robert</forenames></author><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>Comparing human and automatic thesaurus mapping approaches in the
  agricultural domain</title><categories>cs.DL</categories><comments>10 pages, Int'l Conf. on Dublin Core and Metadata Applications 2008</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Knowledge organization systems (KOS), like thesauri and other controlled
vocabularies, are used to provide subject access to information systems across
the web. Due to the heterogeneity of these systems, mapping between
vocabularies becomes crucial for retrieving relevant information. However,
mapping thesauri is a laborious task, and thus big efforts are being made to
automate the mapping process. This paper examines two mapping approaches
involving the agricultural thesaurus AGROVOC, one machine-created and one human
created. We are addressing the basic question &quot;What are the pros and cons of
human and automatic mapping and how can they complement each other?&quot; By
pointing out the difficulties in specific cases or groups of cases and grouping
the sample into simple and difficult types of mappings, we show the limitations
of current automatic methods and come up with some basic recommendations on
what approach to use when.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2296</identifier>
 <datestamp>2008-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2296</id><created>2008-08-17</created><authors><author><keyname>Laddomada</keyname><forenames>Massimiliano</forenames></author></authors><title>Fixed-Point Design of Generalized Comb Filters: A Statistical Approach</title><categories>cs.OH</categories><comments>10 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the problem of designing computationally
efficient Generalized Comb Filters (GCF). Basically, GCF filters are
anti-aliasing filters that guarantee superior performance in terms of
selectivity and quantization noise rejection compared to classical comb
filters, when used as decimation filters in multistage architectures. Upon
employing a partial polyphase (PP) architecture proposed in a companion paper,
we develop a sensitivity analysis in order to investigate the effects of the
coefficients' quantization on the frequency response of the designed filters.
We show that the sensitivity of the filter response to errors in the
coefficients is dependent on the particular split of the decimation factor
between the two sub-filters constituting the PP architecture. The sensitivity
analysis is then used for developing a fixed-point implementation of a sample
filter from the class of GCF filters, used as reference filter throughout the
paper. Finally, we present computer simulations in order to evaluate the
performance of the designed fixed-point filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2314</identifier>
 <datestamp>2008-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2314</id><created>2008-08-17</created><authors><author><keyname>Sridharan</keyname><forenames>Sriram</forenames></author><author><keyname>Jafarian</keyname><forenames>Amin</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Capacity of Symmetric K-User Gaussian Very Strong Interference Channels</title><categories>cs.IT math.IT</categories><comments>Accepted for publication at Globecom Communications Conference 2008,
  5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a symmetric K user Gaussian interference channel with K
transmitters and K receivers. A &quot;very strong&quot; interference regime is derived
for this channel setup. A &quot;very strong&quot; interference regime is one where the
capacity region of the interference channel is the same as the capacity region
of the channel with no interference. In this regime, the interference can be
perfectly canceled by all the receivers without incurring any rate penalties. A
&quot;very strong&quot; interference condition for an example symmetric K user
deterministic interference channel is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2325</identifier>
 <datestamp>2008-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2325</id><created>2008-08-17</created><authors><author><keyname>Neufeld</keyname><forenames>Michael</forenames></author><author><keyname>Partridge</keyname><forenames>Craig</forenames></author></authors><title>Networking in the Physical World</title><categories>cs.NI</categories><comments>13 pages, 4 figures</comments><acm-class>C.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose a network meta-architecture based on fundamental laws
of physics and a physical model of computation. This meta-architecture may be
used to frame discussions about novel network architectures as well as
cross-layer alterations to the canonical network stack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2417</identifier>
 <datestamp>2009-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2417</id><created>2008-08-18</created><updated>2009-07-03</updated><authors><author><keyname>Kao</keyname><forenames>Jui-Yi</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>On NFAs Where All States are Final, Initial, or Both</title><categories>cs.CC cs.FL</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine questions involving nondeterministic finite automata where all
states are final, initial, or both initial and final. First, we prove hardness
results for the nonuniversality and inequivalence problems for these NFAs.
Next, we characterize the languages accepted. Finally, we discuss some state
complexity problems involving such automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2428</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2428</id><created>2008-08-18</created><updated>2008-12-12</updated><authors><author><keyname>Davis</keyname><forenames>Philip M.</forenames></author></authors><title>Author-choice open access publishing in the biological and medical
  literature: a citation analysis</title><categories>cs.DL</categories><comments>citation changes; final manuscript</comments><journal-ref>JASIST, 60(1):3-8, 2008</journal-ref><doi>10.1002/asi.20965</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we analyze the citations to articles published in 11
biological and medical journals from 2003 to 2007 that employ author-choice
open access models. Controlling for known explanatory predictors of citations,
only 2 of the 11 journals show positive and significant open access effects.
Analyzing all journals together, we report a small but significant increase in
article citations of 17%. In addition, there is strong evidence to suggest that
the open access advantage is declining by about 7% per year, from 32% in 2004
to 11% in 2007.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2431</identifier>
 <datestamp>2008-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2431</id><created>2008-08-18</created><authors><author><keyname>Connes</keyname><forenames>Frederic</forenames></author></authors><title>A Simple E-Voting Protocol</title><categories>cs.CY</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an e-voting protocol that seems to allow citizens to verify that
their vote has been accurately taken into account while preserving its secrecy,
without requiring the use of a complex process. The main idea is to give each
voter a receipt on which her choice is mixed with the choices of other voters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2486</identifier>
 <datestamp>2008-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2486</id><created>2008-08-18</created><authors><author><keyname>Zubarev</keyname><forenames>Michail</forenames></author><author><keyname>Korzhik</keyname><forenames>Valery</forenames></author><author><keyname>Morales-Luna</keyname><forenames>Guillermo</forenames></author></authors><title>Wet Paper Coding for Watermarking of Binary Images</title><categories>cs.IT cs.CR math.IT</categories><acm-class>K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method to embed data in binary images, including scanned
text, figures, and signatures. Our method relies on the concept of wet paper
codes. The shuffling before embedding is used in order to equalize irregular
embedding capacity from diverse areas in the image. The hidden data can be
extracted without the original binary image. We illustrate some examples of
watermarked binary images after wet paper coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2515</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2515</id><created>2008-08-18</created><updated>2008-09-02</updated><authors><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author></authors><title>Provably efficient instanton search algorithm for LP decoding of LDPC
  codes over the BSC</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. 9 Pages, 4
  Figures; Dr. Bane Vasic added as an author; Changes made to the introduction
  and abstract; Acknowledgment section added; Some references added; Figures
  modified to make them more clear;</comments><report-no>LA-UR-08-05304</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Linear Programming (LP) decoding of a fixed Low-Density
Parity-Check (LDPC) code over the Binary Symmetric Channel (BSC). The LP
decoder fails when it outputs a pseudo-codeword which is not a codeword. We
design an efficient algorithm termed the Instanton Search Algorithm (ISA)
which, given a random input, generates a set of flips called the BSC-instanton.
We prove that: (a) the LP decoder fails for any set of flips with support
vector including an instanton; (b) for any input, the algorithm outputs an
instanton in the number of steps upper-bounded by twice the number of flips in
the input. Repeated sufficient number of times, the ISA outcomes the number of
unique instantons of different sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2530</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2530</id><created>2008-08-19</created><updated>2010-09-21</updated><authors><author><keyname>Jagabathula</keyname><forenames>Srikanth</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>Fair Scheduling in Networks Through Packet Election</title><categories>cs.IT math.IT</categories><comments>14 pages (double column), submitted to IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing a fair scheduling algorithm for
discrete-time constrained queuing networks. Each queue has dedicated exogenous
packet arrivals. There are constraints on which queues can be served
simultaneously. This model effectively describes important special instances
like network switches, interference in wireless networks, bandwidth sharing for
congestion control and traffic scheduling in road roundabouts. Fair scheduling
is required because it provides isolation to different traffic flows; isolation
makes the system more robust and enables providing quality of service. Existing
work on fairness for constrained networks concentrates on flow based fairness.
As a main result, we describe a notion of packet based fairness by establishing
an analogy with the ranked election problem: packets are voters, schedules are
candidates and each packet ranks the schedules based on its priorities. We then
obtain a scheduling algorithm that achieves the described notion of fairness by
drawing upon the seminal work of Goodman and Markowitz (1952). This yields the
familiar Maximum Weight (MW) style algorithm. As another important result we
prove that algorithm obtained is throughput optimal. There is no reason a
priori why this should be true, and the proof requires non-traditional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2543</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2543</id><created>2008-08-19</created><authors><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author></authors><title>A Refined Difference Field Theory for Symbolic Summation</title><categories>cs.SC math-ph math.CO math.MP</categories><comments>Uses elseart.cls and yjsco.sty</comments><report-no>SFB F013, J. Kepler University Linz. Technical report no. 2007-24</report-no><journal-ref>J. Symbolic Comput. 43(9), pp. 611-644. 2008</journal-ref><doi>10.1016/j.jsc.2008.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present a refined summation theory based on Karr's
difference field approach. The resulting algorithms find sum representations
with optimal nested depth. For instance, the algorithms have been applied
successively to evaluate Feynman integrals from Perturbative Quantum Field
Theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2544</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2544</id><created>2008-08-19</created><updated>2009-04-16</updated><authors><author><keyname>Bugeaud</keyname><forenames>Yann</forenames></author><author><keyname>Krieger</keyname><forenames>Dalia</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Morphic and Automatic Words: Maximal Blocks and Diophantine
  Approximation</title><categories>math.CO cs.FL</categories><comments>16 pages, 1 figure</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mb w$ be a morphic word over a finite alphabet $\Sigma$, and let
$\Delta$ be a nonempty subset of $\Sigma$. We study the behavior of maximal
blocks consisting only of letters from $\Delta$ in $\mb w$, and prove the
following: let $(i_k,j_k)$ denote the starting and ending positions,
respectively, of the $k$'th maximal $\Delta$-block in $\mb w$. Then
$\limsup_{k\to\infty} (j_k/i_k)$ is algebraic if $\mb w$ is morphic, and
rational if $\mb w$ is automatic. As a result, we show that the same conclusion
holds if $(i_k,j_k)$ are the starting and ending positions of the $k$'th
maximal zero block, and, more generally, of the $k$'th maximal $x$-block, where
$x$ is an arbitrary word. This enables us to draw conclusions about the
irrationality exponent of automatic and morphic numbers. In particular, we show
that the irrationality exponent of automatic (resp., morphic) numbers belonging
to a certain class that we define is rational (resp., algebraic).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2548</identifier>
 <datestamp>2009-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2548</id><created>2008-08-19</created><updated>2009-07-28</updated><authors><author><keyname>Kohda</keyname><forenames>Tohru</forenames></author><author><keyname>Hironaka</keyname><forenames>Satoshi</forenames></author><author><keyname>Aihara</keyname><forenames>Kazuyuki</forenames></author></authors><title>Negative Beta Encoder</title><categories>cs.IT math.IT</categories><comments>18 pages, 26 figures, submitted to IEEE Tran. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new class of analog-to-digital (A/D) and digital-to-analog (D/A) converters
using a flaky quantiser, called the $\beta$-encoder, has been shown to have
exponential bit rate accuracy while possessing a self-correction property for
fluctuations of the amplifier factor $\beta$ and the quantiser threshold $\nu$.
The probabilistic behavior of such a flaky quantiser is explained as the
deterministic dynamics of the multi-valued R\'enyi map. That is, a sample $x$
is always confined to a contracted subinterval while successive approximations
of $x$ are performed using $\beta$-expansion even if $\nu$ may vary at each
iteration. This viewpoint enables us to get the decoded sample, which is equal
to the midpoint of the subinterval, and its associated characteristic equation
for recovering $\beta$ which improves the quantisation error by more than
$3{dB}$ when $\beta&gt;1.5$. The invariant subinterval under the R\'enyi map shows
that $\nu$ should be set to around the midpoint of its associated greedy and
lazy values. %in terms of its quantisation MSE (mean square error).
Furthermore, a new A/D converter is introduced called the negative
$\beta$-encoder, which further improves the quantisation error of the
$\beta$-encoder. A two-state Markov chain describing the $\beta$-encoder
suggests that a negative eigenvalue of its associated transition probability
matrix reduces the quantisation error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2562</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2562</id><created>2008-08-19</created><authors><author><keyname>Zeng</keyname><forenames>Yonghong</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author></authors><title>Spectrum Sensing Algorithms for Cognitive Radio Based on Statistical
  Covariances</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing, i.e., detecting the presence of primary users in a licensed
spectrum, is a fundamental problem in cognitive radio. Since the statistical
covariances of received signal and noise are usually different, they can be
used to differentiate the case where the primary user's signal is present from
the case where there is only noise. In this paper, spectrum sensing algorithms
are proposed based on the sample covariance matrix calculated from a limited
number of received signal samples. Two test statistics are then extracted from
the sample covariance matrix. A decision on the signal presence is made by
comparing the two test statistics. Theoretical analysis for the proposed
algorithms is given. Detection probability and associated threshold are found
based on statistical theory. The methods do not need any information of the
signal, the channel and noise power a priori. Also, no synchronization is
needed. Simulations based on narrowband signals, captured digital television
(DTV) signals and multiple antenna signals are presented to verify the methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2584</identifier>
 <datestamp>2009-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2584</id><created>2008-08-19</created><updated>2009-01-20</updated><authors><author><keyname>Hou</keyname><forenames>Tie</forenames></author></authors><title>On Transformations of Load-Store Maurer Instruction Set Architecture</title><categories>cs.AR</categories><comments>14 pages, 6 figures; Corrected way of citing references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study how certain conditions can affect the transformations
on the states of the memory of a strict load-store Maurer ISA, when half of the
data memory serves as the part of the operating unit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2586</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2586</id><created>2008-08-19</created><authors><author><keyname>Poturalski</keyname><forenames>Marcin</forenames></author><author><keyname>Papadimitratos</keyname><forenames>Panos</forenames></author><author><keyname>Hubaux</keyname><forenames>Jean-Pierre</forenames></author></authors><title>Towards Provable Secure Neighbor Discovery in Wireless Networks</title><categories>cs.CR cs.NI</categories><acm-class>C.2.0</acm-class><journal-ref>ACM Computer and Communications Security Conference (CCS) Sixth
  Workshop on Formal Methods in Security Engineering (FMSE), pages 31{42,
  Alexan- dria, VA, USA, October 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless systems, neighbor discovery (ND) is a fundamental building block:
determining which devices are within direct radio communication is an enabler
for networking protocols and a wide range of applications. To thwart abuse of
ND and the resultant compromise of the dependent functionality of wireless
systems, numerous works proposed solutions to secure ND. Nonetheless, until
very recently, there has been no formal analysis of secure ND protocols. We
close this gap in \cite{asiaccs08}, but we concentrate primarily on the
derivation of an impossibility result for a class of protocols. In this paper,
we focus on reasoning about specific protocols. First, we contribute a number
of extensions and refinements on the framework of [24]. As we are particularly
concerned with the practicality of provably secure ND protocols, we investigate
availability and redefine accordingly the ND specification, and also consider
composability of ND with other protocols. Then, we propose and analyze two
secure ND protocols: We revisit one of the protocols analyzed in [24], and
introduce and prove correct a more elaborate challenge-response protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2591</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2591</id><created>2008-08-19</created><authors><author><keyname>Luo</keyname><forenames>Jun</forenames></author><author><keyname>Papadimitratos</keyname><forenames>Panos</forenames></author><author><keyname>Hubaux</keyname><forenames>Jean-Pierre</forenames></author></authors><title>GossiCrypt: Wireless Sensor Network Data Confidentiality Against
  Parasitic Adversaries</title><categories>cs.CR cs.NI</categories><journal-ref>Proceedings of the Fifth IEEE-CS Conference on Sensor, Mesh and Ad
  Hoc Communi- cations and Networks (IEEE SECON), pages 441{450, San Francisco,
  CA, USA, June 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource and cost constraints remain a challenge for wireless sensor network
security. In this paper, we propose a new approach to protect confidentiality
against a parasitic adversary, which seeks to exploit sensor networks by
obtaining measurements in an unauthorized way. Our low-complexity solution,
GossiCrypt, leverages on the large scale of sensor networks to protect
confidentiality efficiently and effectively. GossiCrypt protects data by
symmetric key encryption at their source nodes and re-encryption at a randomly
chosen subset of nodes en route to the sink. Furthermore, it employs key
refreshing to mitigate the physical compromise of cryptographic keys. We
validate GossiCrypt analytically and with simulations, showing it protects data
confidentiality with probability almost one. Moreover, compared with a system
that uses public-key data encryption, the energy consumption of GossiCrypt is
one to three orders of magnitude lower.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2596</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2596</id><created>2008-08-19</created><authors><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author></authors><title>Parameterized Telescoping Proves Algebraic Independence of Sums</title><categories>cs.SC math.CO math.NT</categories><comments>To appear in Annals of Combinatorics</comments><report-no>SFB F013, J. Kepler University Linz. Technical report no. 2006-40,
  2006</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Usually creative telescoping is used to derive recurrences for sums. In this
article we show that the non-existence of a creative telescoping solution, and
more generally, of a parameterized telescoping solution, proves algebraic
independence of certain types of sums. Combining this fact with
summation-theory shows transcendence of whole classes of sums. Moreover, this
result throws new light on the question why, e.g., Zeilberger's algorithm fails
to find a recurrence with minimal order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2602</identifier>
 <datestamp>2008-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2602</id><created>2008-08-19</created><updated>2008-08-20</updated><authors><author><keyname>Stukach</keyname><forenames>Nick</forenames></author></authors><title>Easily testable logical networks based on a 'widened long flip-flop'</title><categories>cs.AR</categories><comments>64 pages, including 35 figures and 10 tables</comments><acm-class>B.8; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article describes an attempt to solve at once three basic problems
arising at testing a complex digital equipment for defects: 1) the problem of
an exponential increasing of the complexity of testing the equipment with the
complexity of the equipment; 2) the problem of testing of the tester; 3) the
problem of a mutual masking of defects. The proposed solution is nothing more
than using certain limitations for connections between usual logical gates.
Arbitrary multiple stuck-at-faults are supposed as defects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2654</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2654</id><created>2008-08-19</created><authors><author><keyname>Papadimitratos</keyname><forenames>Panos</forenames></author><author><keyname>Hubaux</keyname><forenames>Jean-Pierre</forenames></author></authors><title>Report on the &quot;Secure Vehicular Communications: Results and Challenges
  Ahead&quot; Workshop</title><categories>cs.CR cs.NI</categories><journal-ref>ACM SIGMOBILE Mobile Computing and Communications Review (MC2R),
  12(2):53-64, April 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a report and a collection of abstracts from the Feb. 2008 Lausanne
Workshop on Secure Vehicular Communication Systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2659</identifier>
 <datestamp>2008-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2659</id><created>2008-08-19</created><authors><author><keyname>Krithivasan</keyname><forenames>Dinesh</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>Distributed Source Coding using Abelian Group Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider a distributed source coding problem with a joint
distortion criterion depending on the sources and the reconstruction. This
includes as a special case the problem of computing a function of the sources
to within some distortion and also the classic Slepian-Wolf problem,
Berger-Tung problem, Wyner-Ziv problem, Yeung-Berger problem and the
Ahlswede-Korner-Wyner problem. While the prevalent trend in information theory
has been to prove achievability results using Shannon's random coding
arguments, using structured random codes offer rate gains over unstructured
random codes for many problems. Motivated by this, we present a new achievable
rate-distortion region for this problem for discrete memoryless sources based
on &quot;good&quot; structured random nested codes built over abelian groups. We
demonstrate rate gains for this problem over traditional coding schemes using
random unstructured codes. For certain sources and distortion functions, the
new rate region is strictly bigger than the Berger-Tung rate region, which has
been the best known achievable rate region for this problem till now. Further,
there is no known unstructured random coding scheme that achieves these rate
gains. Achievable performance limits for single-user source coding using
abelian group codes are also obtained as parts of the proof of the main coding
theorem. As a corollary, we also prove that nested linear codes achieve the
Shannon rate-distortion bound in the single-user setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2662</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2662</id><created>2008-08-20</created><updated>2010-01-12</updated><authors><author><keyname>Drucker</keyname><forenames>Andrew</forenames></author></authors><title>Multitask Efficiencies in the Decision Tree Model</title><categories>cs.CC</categories><comments>Improved exposition based on conference version</comments><acm-class>F.1.1; F.1.3</acm-class><journal-ref>24th Annual IEEE Conference on Computational Complexity, 2009, p.
  286-297</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Direct Sum problems [KRW], one tries to show that for a given
computational model, the complexity of computing a collection of finite
functions on independent inputs is approximately the sum of their individual
complexities. In this paper, by contrast, we study the diversity of ways in
which the joint computational complexity can behave when all the functions are
evaluated on a common input. We focus on the deterministic decision tree model,
with depth as the complexity measure; in this model we prove a result to the
effect that the 'obvious' constraints on joint computational complexity are
essentially the only ones.
  The proof uses an intriguing new type of cryptographic data structure called
a `mystery bin' which we construct using a small polynomial separation between
deterministic and unambiguous query complexity shown by Savicky. We also pose a
variant of the Direct Sum Conjecture of [KRW] which, if proved for a single
family of functions, could yield an analogous result for models such as the
communication model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2666</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2666</id><created>2008-08-19</created><authors><author><keyname>Papadimitratos</keyname><forenames>Panos</forenames></author><author><keyname>Calandriello</keyname><forenames>Giorgio</forenames></author><author><keyname>Hubaux</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Lioy</keyname><forenames>Antonio</forenames></author></authors><title>Impact of Vehicular Communications Security on Transportation Safety</title><categories>cs.CR cs.NI</categories><journal-ref>IEEE Conference on Computer Communications (INFOCOM) Workshop on
  Mobile Networking for Vehicular Environments (MOVE), pp. 1-6, Phoenix, AZ,
  USA, April 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transportation safety, one of the main driving forces of the development of
vehicular communication (VC) systems, relies on high-rate safety messaging
(beaconing). At the same time, there is consensus among authorities, industry,
and academia on the need to secure VC systems. With specific proposals in the
literature, a critical question must be answered: can secure VC systems be
practical and satisfy the requirements of safety applications, in spite of the
significant communication and processing overhead and other restrictions
security and privacy-enhancing mechanisms impose? To answer this question, we
investigate in this paper the following three dimensions for secure and
privacy-enhancing VC schemes: the reliability of communication, the processing
overhead at each node, and the impact on a safety application. The results
indicate that with the appropriate system design, including sufficiently high
processing power, applications enabled by secure VC can be in practice as
effective as those enabled by unsecured VC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2668</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2668</id><created>2008-08-19</created><authors><author><keyname>Poturalski</keyname><forenames>Marcin</forenames></author><author><keyname>Papadimitratos</keyname><forenames>Panos</forenames></author><author><keyname>Hubaux</keyname><forenames>Jean-Pierre</forenames></author></authors><title>Secure Neighbor Discovery in Wireless Networks: Formal Investigation of
  Possibility</title><categories>cs.CR cs.NI</categories><acm-class>C.2.0</acm-class><journal-ref>ACM Symposium on Information, Computer and Communications Security
  (ASIACCS), pages 189{200, Tokyo, Japan, March 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless communication enables a broad spectrum of applications, ranging from
commodity to tactical systems. Neighbor discovery (ND), that is, determining
which devices are within direct radio communication, is a building block of
network protocols and applications, and its vulnerability can severely
compromise their functionalities. A number of proposals to secure ND have been
published, but none have analyzed the problem formally. In this paper, we
contribute such an analysis: We build a formal model capturing salient
characteristics of wireless systems, most notably obstacles and interference,
and we provide a specification of a basic variant of the ND problem. Then, we
derive an impossibility result for a general class of protocols we term
&quot;time-based protocols,&quot; to which many of the schemes in the literature belong.
We also identify the conditions under which the impossibility result is lifted.
Moreover, we explore a second class of protocols we term &quot;time- and
location-based protocols,&quot; and prove they can secure ND.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2669</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2669</id><created>2008-08-19</created><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Watrous</keyname><forenames>John</forenames></author></authors><title>Closed Timelike Curves Make Quantum and Classical Computing Equivalent</title><categories>quant-ph cs.CC</categories><comments>15 pages</comments><doi>10.1098/rspa.2008.0350</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While closed timelike curves (CTCs) are not known to exist, studying their
consequences has led to nontrivial insights in general relativity, quantum
information, and other areas. In this paper we show that if CTCs existed, then
quantum computers would be no more powerful than classical computers: both
would have the (extremely large) power of the complexity class PSPACE,
consisting of all problems solvable by a conventional computer using a
polynomial amount of memory. This solves an open problem proposed by one of us
in 2005, and gives an essentially complete understanding of computational
complexity in the presence of CTCs. Following the work of Deutsch, we treat a
CTC as simply a region of spacetime where a &quot;causal consistency&quot; condition is
imposed, meaning that Nature has to produce a (probabilistic or quantum)
fixed-point of some evolution operator. Our conclusion is then a consequence of
the following theorem: given any quantum circuit (not necessarily unitary), a
fixed-point of the circuit can be (implicitly) computed in polynomial space.
This theorem might have independent applications in quantum information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2670</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2670</id><created>2008-08-19</created><updated>2010-03-12</updated><authors><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Kuscsik</keyname><forenames>Zoltan</forenames></author><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Wakeling</keyname><forenames>Joseph R.</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Solving the apparent diversity-accuracy dilemma of recommender systems</title><categories>cs.IR physics.soc-ph</categories><comments>10 pages, 9 figures, 4 tables (final version with supporting
  information included)</comments><journal-ref>PNAS 107, 4511-4515, 2010</journal-ref><doi>10.1073/pnas.1000488107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems use data on past user preferences to predict possible
future likes and interests. A key challenge is that while the most useful
individual recommendations are to be found among diverse niche objects, the
most reliably accurate results are obtained by methods that recommend objects
based on user or object similarity. In this paper we introduce a new algorithm
specifically to address the challenge of diversity and show how it can be used
to resolve this apparent dilemma when combined in an elegant hybrid with an
accuracy-focused algorithm. By tuning the hybrid appropriately we are able to
obtain, without relying on any semantic or context-specific information,
simultaneous gains in both accuracy and diversity of recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2676</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2676</id><created>2008-08-19</created><authors><author><keyname>Haghani</keyname><forenames>P.</forenames></author><author><keyname>Papadimitratos</keyname><forenames>P.</forenames></author><author><keyname>Poturalski</keyname><forenames>M.</forenames></author><author><keyname>Aberer</keyname><forenames>K.</forenames></author><author><keyname>Hubaux</keyname><forenames>J. -P.</forenames></author></authors><title>Efficient and Robust Secure Aggregation for Sensor Networks</title><categories>cs.CR cs.NI</categories><journal-ref>IEEE ICNP Workshop on Secure Network Protocols (NPSec), pages 1{6,
  Beijing, China, October 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) rely on in-network aggregation for
efficiency, however, this comes at a price: A single adversary can severely
influence the outcome by contributing an arbitrary partial aggregate value.
Secure in-network aggregation can detect such manipulation. But as long as such
faults persist, no aggregation result can be obtained. In contrast, the
collection of individual sensor node values is robust and solves the problem of
availability, yet in an inefficient way. Our work seeks to bridge this gap in
secure data collection: We propose a system that enhances availability with an
efficiency close to that of in-network aggregation. To achieve this, our scheme
relies on costly operations to localize and exclude nodes that manipulate the
aggregation, but \emph{only} when a failure is detected. The detection of
aggregation disruptions and the removal of faulty nodes provides robustness. At
the same time, after removing faulty nodes, the WSN can enjoy low cost (secure)
aggregation. Thus, the high exclusion cost is amortized, and efficiency
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2703</identifier>
 <datestamp>2008-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2703</id><created>2008-08-20</created><authors><author><keyname>Martinez</keyname><forenames>Alfonso</forenames></author></authors><title>Low-Signal-Energy Asymptotics of Capacity and Mutual Information for the
  Discrete-Time Poisson Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first terms of the low-signal-energy asymptotics for the mutual
information in the discrete-time Poisson channel are derived and compared to an
asymptotic expression of the capacity. In the presence of non-zero additive
noise (either Poisson or geometric), the mutual information is concave at zero
signal-energy and the minimum energy per bit is not attained at zero capacity.
Fixed signal constellations which scale with the signal energy do not attain
the minimum energy per bit. The minimum energy per bit is zero when additive
Poisson noise is present and $\ew\log 2$ when additive geometric noise of mean
$\ew$ is present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2794</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2794</id><created>2008-08-20</created><authors><author><keyname>Baboulin</keyname><forenames>Marc</forenames></author><author><keyname>Buttari</keyname><forenames>Alfredo</forenames></author><author><keyname>Dongarra</keyname><forenames>Jack</forenames></author><author><keyname>Kurzak</keyname><forenames>Jakub</forenames></author><author><keyname>Langou</keyname><forenames>Julie</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author><author><keyname>Luszczek</keyname><forenames>Piotr</forenames></author><author><keyname>Tomov</keyname><forenames>Stanimire</forenames></author></authors><title>Accelerating Scientific Computations with Mixed Precision Algorithms</title><categories>cs.MS</categories><doi>10.1016/j.cpc.2008.11.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On modern architectures, the performance of 32-bit operations is often at
least twice as fast as the performance of 64-bit operations. By using a
combination of 32-bit and 64-bit floating point arithmetic, the performance of
many dense and sparse linear algebra algorithms can be significantly enhanced
while maintaining the 64-bit accuracy of the resulting solution. The approach
presented here can apply not only to conventional processors but also to other
technologies such as Field Programmable Gate Arrays (FPGA), Graphical
Processing Units (GPU), and the STI Cell BE processor. Results on modern
processor architectures and the STI Cell BE are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2801</identifier>
 <datestamp>2008-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2801</id><created>2008-08-20</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Papadimitriou</keyname><forenames>Christos H.</forenames></author></authors><title>Discretized Multinomial Distributions and Nash Equilibria in Anonymous
  Games</title><categories>cs.GT</categories><comments>In the 49th Annual IEEE Symposium on Foundations of Computer Science,
  FOCS 2008</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there is a polynomial-time approximation scheme for computing
Nash equilibria in anonymous games with any fixed number of strategies (a very
broad and important class of games), extending the two-strategy result of
Daskalakis and Papadimitriou 2007. The approximation guarantee follows from a
probabilistic result of more general interest: The distribution of the sum of n
independent unit vectors with values ranging over {e1, e2, ...,ek}, where ei is
the unit vector along dimension i of the k-dimensional Euclidean space, can be
approximated by the distribution of the sum of another set of independent unit
vectors whose probabilities of obtaining each value are multiples of 1/z for
some integer z, and so that the variational distance of the two distributions
is at most eps, where eps is bounded by an inverse polynomial in z and a
function of k, but with no dependence on n. Our probabilistic result specifies
the construction of a surprisingly sparse eps-cover -- under the total
variation distance -- of the set of distributions of sums of independent unit
vectors, which is of interest on its own right.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2827</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2827</id><created>2008-08-20</created><updated>2008-09-11</updated><authors><author><keyname>Lu</keyname><forenames>Louis Yu</forenames></author></authors><title>Fast Intrinsic Mode Decomposition and Filtering of Time Series Data</title><categories>cs.NA</categories><comments>Add filtering method and compare the results with different
  initialization</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intrinsic mode function (IMF) provides adaptive function bases for
nonlinear and non-stationary time series data. A fast convergent iterative
method is introduced in this paper to find the IMF components of the data, the
method is faster and more predictable than the Empirical Mode Decomposition
method devised by the author of Hilbert Huang Transform. The approach is to
iteratively adjust the control points on the data function corresponding to the
extrema of the refining IMF, the control points of the residue function are
calculated as the median of the straight line segments passing through the data
control points, the residue function is then constructed as the cubic spline
function of the median points. The initial residue function is simply
constructed as the straight line segments passing through the extrema of the
first derivative of the data function. The refining IMF is the difference
between the data function and the improved residue function. The IMF found
reveals all the riding waves in the whole data set. A new data filtering method
on frequency and amplitude of IMF is also presented with the similar approach
of finding the residue on the part to be filtered out. The program to
demonstrate the method is distributed under BSD open source license.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2833</identifier>
 <datestamp>2015-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2833</id><created>2008-08-20</created><updated>2010-11-04</updated><authors><author><keyname>Faigle</keyname><forenames>Ulrich</forenames></author><author><keyname>Sch&#xf6;nhuth</keyname><forenames>Alexander</forenames></author></authors><title>Efficient tests for equivalence of hidden Markov processes and quantum
  random walks</title><categories>cs.IT math.IT</categories><comments>16 pages, requires llncs.cls</comments><journal-ref>IEEE Transactions on Information Theory, 57(3), 1746-1753, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While two hidden Markov process (HMP) resp. quantum random walk (QRW)
parametrizations can differ from one another, the stochastic processes arising
from them can be equivalent. Here a polynomial-time algorithm is presented
which can determine equivalence of two HMP parametrizations $\cM_1,\cM_2$ resp.
two QRW parametrizations $\cQ_1,\cQ_2$ in time $O(|\S|\max(N_1,N_2)^{4})$,
where $N_1,N_2$ are the number of hidden states in $\cM_1,\cM_2$ resp. the
dimension of the state spaces associated with $\cQ_1,\cQ_2$, and $\S$ is the
set of output symbols. Previously available algorithms for testing equivalence
of HMPs were exponential in the number of hidden states. In case of QRWs,
algorithms for testing equivalence had not yet been presented. The core
subroutines of this algorithm can also be used to efficiently test hidden
Markov processes and quantum random walks for ergodicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2837</identifier>
 <datestamp>2008-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2837</id><created>2008-08-21</created><authors><author><keyname>Roth</keyname><forenames>Ron M.</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>List Decoding of Burst Errors</title><categories>cs.IT cs.DM math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, August 19, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalization of the Reiger bound is presented for the list decoding of
burst errors. It is then shown that Reed-Solomon codes attain this bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2904</identifier>
 <datestamp>2008-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2904</id><created>2008-08-21</created><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Investigation of the Zipf-plot of the extinct Meroitic language</title><categories>cs.CL</categories><comments>10 pages, 2 figures</comments><journal-ref>Glottometrics 15, 2007, 53-61</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ancient and extinct language Meroitic is investigated using Zipf's Law.
In particular, since Meroitic is still undeciphered, the Zipf law analysis
allows us to assess the quality of current texts and possible avenues for
future investigation using statistical techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2931</identifier>
 <datestamp>2008-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2931</id><created>2008-08-21</created><authors><author><keyname>Pustylnik</keyname><forenames>Gennady</forenames></author></authors><title>Spatial planning with constraints on translational distances between
  geometric objects</title><categories>cs.CG cs.RO</categories><comments>33 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main constraint on relative position of geometric objects, used in
spatial planning for computing the C-space maps (for example, in robotics, CAD,
and packaging), is the relative non-overlapping of objects. This is the
simplest constraint in which the minimum translational distance between objects
is greater than zero, or more generally, than some positive value. We present a
technique, based on the Minkowski operations, for generating the translational
C-space maps for spatial planning with more general and more complex
constraints on the relative position of geometric objects, such as constraints
on various types (not only on the minimum) of the translational distances
between objects. The developed technique can also be used, respectively, for
spatial planning with constraints on translational distances in a given
direction, and rotational distances between geometric objects, as well as for
spatial planning with given dynamic geometric situation of moving objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2953</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2953</id><created>2008-08-21</created><updated>2009-01-19</updated><authors><author><keyname>Tarau</keyname><forenames>Paul</forenames></author></authors><title>Declarative Combinatorics: Isomorphisms, Hylomorphisms and Hereditarily
  Finite Data Types in Haskell</title><categories>cs.PL cs.DS</categories><comments>unpublished draft, revision 3, added various new encodings, with
  focus on primes and multisets, now 104 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is an exploration in a functional programming framework of {\em
isomorphisms} between elementary data types (natural numbers, sets, multisets,
finite functions, permutations binary decision diagrams, graphs, hypergraphs,
parenthesis languages, dyadic rationals, primes, DNA sequences etc.) and their
extension to hereditarily finite universes through {\em hylomorphisms} derived
from {\em ranking/unranking} and {\em pairing/unpairing} operations.
  An embedded higher order {\em combinator language} provides any-to-any
encodings automatically.
  Besides applications to experimental mathematics, a few examples of ``free
algorithms'' obtained by transferring operations between data types are shown.
Other applications range from stream iterators on combinatorial objects to
self-delimiting codes, succinct data representations and generation of random
instances.
  The paper covers 59 data types and, through the use of the embedded
combinator language, provides 3540 distinct bijective transformations between
them.
  The self-contained source code of the paper, as generated from a literate
Haskell program, is available at
\url{http://logic.csci.unt.edu/tarau/research/2008/fISO.zip}.
  {\bf Keywords}: Haskell data representations, data type isomorphisms,
declarative combinatorics, computational mathematics, Ackermann encoding,
G\&quot;{o}del numberings, arithmetization, ranking/unranking, hereditarily finite
sets, functions and permutations, encodings of binary decision diagrams, dyadic
rationals, DNA encodings
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2964</identifier>
 <datestamp>2008-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2964</id><created>2008-08-21</created><authors><author><keyname>Morvai</keyname><forenames>Gusztav</forenames></author><author><keyname>Weiss</keyname><forenames>Benjamin</forenames></author></authors><title>Estimating the Lengths of Memory Words</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, Vol. 54, No. 8. (2008),
  pp. 3804-3807</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a stationary stochastic process $\{X_n\}$ with values in some set $A$, a
finite word $w \in A^K$ is called a memory word if the conditional probability
of $X_0$ given the past is constant on the cylinder set defined by
$X_{-K}^{-1}=w$. It is a called a minimal memory word if no proper suffix of
$w$ is also a memory word. For example in a $K$-step Markov processes all words
of length $K$ are memory words but not necessarily minimal. We consider the
problem of determining the lengths of the longest minimal memory words and the
shortest memory words of an unknown process $\{X_n\}$ based on sequentially
observing the outputs of a single sample $\{\xi_1,\xi_2,...\xi_n\}$. We will
give a universal estimator which converges almost surely to the length of the
longest minimal memory word and show that no such universal estimator exists
for the length of the shortest memory word. The alphabet $A$ may be finite or
countable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2984</identifier>
 <datestamp>2008-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2984</id><created>2008-08-21</created><authors><author><keyname>Destercke</keyname><forenames>S&#xe9;bastien</forenames><affiliation>IRSN, IRIT</affiliation></author><author><keyname>Guillaume</keyname><forenames>Serge</forenames><affiliation>ITAP</affiliation></author><author><keyname>Charnomordic</keyname><forenames>Brigitte</forenames><affiliation>ASB</affiliation></author></authors><title>Building an interpretable fuzzy rule base from data using Orthogonal
  Least Squares Application to a depollution problem</title><categories>cs.LG cs.AI</categories><comments>pre-print of final version published in Fuzzy Sets and Systems</comments><proxy>ccsd irsn-00311750</proxy><journal-ref>Fuzzy Sets and Systems 158, 18 (2007) 2078-2094</journal-ref><doi>10.1016/j.fss.2007.04.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many fields where human understanding plays a crucial role, such as
bioprocesses, the capacity of extracting knowledge from data is of critical
importance. Within this framework, fuzzy learning methods, if properly used,
can greatly help human experts. Amongst these methods, the aim of orthogonal
transformations, which have been proven to be mathematically robust, is to
build rules from a set of training data and to select the most important ones
by linear regression or rank revealing techniques. The OLS algorithm is a good
representative of those methods. However, it was originally designed so that it
only cared about numerical performance. Thus, we propose some modifications of
the original method to take interpretability into account. After recalling the
original algorithm, this paper presents the changes made to the original
method, then discusses some results obtained from benchmark problems. Finally,
the algorithm is applied to a real-world fault detection depollution problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3003</identifier>
 <datestamp>2008-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3003</id><created>2008-08-21</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames><affiliation>Sogang University</affiliation></author></authors><title>Codes Associated with Orthogonal Groups and Power Moments of Kloosterman
  Sums</title><categories>math.NT cs.IT math.IT</categories><msc-class>11T23; 20G40; 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct three binary linear codes $C(SO^{-}(2,q))$,
$C(O^{-}(2,q))$, $C(SO^{-}(4,q))$, respectively associated with the orthogonal
groups $SO^{-}(2,q)$, $O^{-}(2,q)$, $SO^{-}(4,q)$, with $q$ powers of two. Then
we obtain recursive formulas for the power moments of Kloosterman and
2-dimensional Kloosterman sums in terms of the frequencies of weights in the
codes. This is done via Pless power moment identity and by utilizing the
explicit expressions of Gauss sums for the orthogonal groups. We emphasize
that, when the recursive formulas for the power moments of Kloosterman sums are
compared, the present one is computationally more effective than the previous
one constructed from the special linear group $SL(2,q)$. We illustrate our
results with some examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3019</identifier>
 <datestamp>2008-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3019</id><created>2008-08-21</created><authors><author><keyname>Grossman</keyname><forenames>Robert L</forenames></author><author><keyname>Gu</keyname><forenames>Yunhong</forenames></author></authors><title>Data Mining Using High Performance Data Clouds: Experimental Studies
  Using Sector and Sphere</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the design and implementation of a high performance cloud that we
have used to archive, analyze and mine large distributed data sets. By a cloud,
we mean an infrastructure that provides resources and/or services over the
Internet. A storage cloud provides storage services, while a compute cloud
provides compute services. We describe the design of the Sector storage cloud
and how it provides the storage services required by the Sphere compute cloud.
We also describe the programming paradigm supported by the Sphere compute
cloud. Sector and Sphere are designed for analyzing large data sets using
computer clusters connected with wide area high performance networks (for
example, 10+ Gb/s). We describe a distributed data mining application that we
have developed using Sector and Sphere. Finally, we describe some experimental
studies comparing Sector/Sphere to Hadoop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3038</identifier>
 <datestamp>2011-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3038</id><created>2008-08-22</created><updated>2011-06-09</updated><authors><author><keyname>Schicho</keyname><forenames>Josef</forenames></author><author><keyname>Sevilla</keyname><forenames>David</forenames></author></authors><title>Tschirnhaus-Weierstrass curves</title><categories>math.AG cs.SC</categories><comments>v2: 10 pages, major revision due to errors in the main result. v1: 14
  pages, submitted to Mathematics of Computation</comments><msc-class>14H99 (Primary) 14Q05, 68W30 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the concept of Tschirnhaus-Weierstrass curve, named after the
Weierstrass form of an elliptic curve and Tschirnhaus transformations. Every
pointed curve has a Tschirnhaus-Weierstrass form, and this representation is
unique up to a scaling of variables. This is useful for computing isomorphisms
between curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3100</identifier>
 <datestamp>2008-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3100</id><created>2008-08-22</created><authors><author><keyname>Ivankov</keyname><forenames>Petr R.</forenames></author></authors><title>Optimizing Compiler for Engineering Problems</title><categories>cs.PF</categories><comments>6 pages, 1 figure</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New information technologies provide a lot of prospects for performance
improvement. One of them is &quot;Dynamic Source Code Generation and Compilation&quot;.
This article shows how this way provides high performance for engineering
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3109</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3109</id><created>2008-08-22</created><updated>2008-11-18</updated><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Christianto</keyname><forenames>V.</forenames></author></authors><title>n-ary Fuzzy Logic and Neutrosophic Logic Operators</title><categories>cs.AI</categories><comments>15 pages, 2 fuzzy and neutrosophic value tables, many diagrams</comments><acm-class>I.2.3</acm-class><journal-ref>Studies in Logic, Grammar and Rethoric [Belarus], 17 (30), pp.
  1-16, 2009.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend Knuth's 16 Boolean binary logic operators to fuzzy logic and
neutrosophic logic binary operators. Then we generalize them to n-ary fuzzy
logic and neutrosophic logic operators using the smarandache codification of
the Venn diagram and a defined vector neutrosophic law. In such way, new
operators in neutrosophic logic/set/probability are built.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3112</identifier>
 <datestamp>2012-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3112</id><created>2008-08-22</created><updated>2012-05-03</updated><authors><author><keyname>Cassaigne</keyname><forenames>Julien</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author></authors><title>On the decidability of semigroup freeness</title><categories>cs.DM</categories><comments>46 pages. 1 table. To appear in RAIRO</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the decidability of semigroup freeness. More precisely,
the freeness problem over a semigroup S is defined as: given a finite subset X
of S, decide whether each element of S has at most one factorization over X. To
date, the decidabilities of two freeness problems have been closely examined.
In 1953, Sardinas and Patterson proposed a now famous algorithm for the
freeness problem over the free monoid. In 1991, Klarner, Birget and Satterfield
proved the undecidability of the freeness problem over three-by-three integer
matrices. Both results led to the publication of many subsequent papers. The
aim of the present paper is three-fold: (i) to present general results
concerning freeness problems, (ii) to study the decidability of freeness
problems over various particular semigroups (special attention is devoted to
multiplicative matrix semigroups), and (iii) to propose precise, challenging
open questions in order to promote the study of the topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3145</identifier>
 <datestamp>2008-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3145</id><created>2008-08-22</created><authors><author><keyname>Avestimehr</keyname><forenames>Amir Salman</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Approximate capacity of the two-way relay channel: A deterministic
  approach</title><categories>cs.IT math.IT</categories><comments>7 pages, 8 figures, will be presented at 46. Allerton Conf. On Comm.,
  Control, and Computing 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the capacity of the full-duplex bidirectional (or two-way) relay
channel with two nodes and one relay. The channels in the forward direction are
assumed to be different (in general) than the channels in the backward
direction, i.e. channel reciprocity is not assumed. We use the recently
proposed deterministic approach to capture the essence of the problem and to
determine a good transmission and relay strategy for the Gaussian channel.
Depending on the ratio of the individual channel gains, we propose to use
either a simple amplify-and-forward or a particular superposition coding
strategy at the relay. We analyze the achievable rate region and show that the
scheme achieves to within 3 bits the cut-set bound for all values of channel
gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3166</identifier>
 <datestamp>2008-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3166</id><created>2008-08-23</created><authors><author><keyname>Mohaisen</keyname><forenames>Abedelaziz</forenames></author><author><keyname>Hong</keyname><forenames>Dowon</forenames></author></authors><title>Privacy Preserving Association Rule Mining Revisited</title><categories>cs.CR</categories><comments>15 pages, to appear in proceeding of WISA 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The privacy preserving data mining (PPDM) has been one of the most
interesting, yet challenging, research issues. In the PPDM, we seek to
outsource our data for data mining tasks to a third party while maintaining its
privacy. In this paper, we revise one of the recent PPDM schemes (i.e., FS)
which is designed for privacy preserving association rule mining (PP-ARM). Our
analysis shows some limitations of the FS scheme in term of its storage
requirements guaranteeing a reasonable privacy standard and the high
computation as well. On the other hand, we introduce a robust definition of
privacy that considers the average case privacy and motivates the study of a
weakness in the structure of FS (i.e., fake transactions filtering). In order
to overcome this limit, we introduce a hybrid scheme that considers both
privacy and resources guidelines. Experimental results show the efficiency of
our proposed scheme over the previously introduced one and opens directions for
further development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3196</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3196</id><created>2008-08-23</created><authors><author><keyname>Chakrabarti</keyname><forenames>Anindya S.</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Bikas K.</forenames></author></authors><title>Queue-length Variations In A Two-Restaurant Problem</title><categories>cs.GT q-fin.TR</categories><comments>7 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper attempts to find out numerically the distribution of the
queue-length ratio in the context of a model of preferential attachment. Here
we consider two restaurants only and a large number of customers (agents) who
come to these restaurants. Each day the same number of agents sequentially
arrives and decides which restaurant to enter. If all the agents literally
follow the crowd then there is no difference between this model and the famous
`P\'olya's Urn' model. But as agents alter their strategies different kind of
dynamics of the model is seen. It is seen from numerical results that the
existence of a distribution of the fixed points is quite robust and it is also
seen that in some cases the variations in the ratio of the queue-lengths follow
a power-law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3197</identifier>
 <datestamp>2008-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3197</id><created>2008-08-24</created><authors><author><keyname>Chen</keyname><forenames>Ming-Zhe</forenames></author></authors><title>On the Monotonicity of Work Function in k-Server Conjecture</title><categories>cs.DS</categories><comments>3 pages, corrected typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a mistake in work function algorithm of k-server
conjecture. That is, the monotonicity of the work function is not always true.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3203</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3203</id><created>2008-08-23</created><authors><author><keyname>Feigel</keyname><forenames>Alexander</forenames></author><author><keyname>Englander</keyname><forenames>Avraham</forenames></author><author><keyname>Engel</keyname><forenames>Assaf</forenames></author></authors><title>Sex is always well worth its two-fold cost</title><categories>q-bio.PE cs.GT physics.bio-ph</categories><comments>8 pages, 3 figures</comments><doi>10.1371/journal.pone.0006012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sex is considered as an evolutionary paradox, since its evolutionary
advantage does not necessarily overcome the two fold cost of sharing half of
one's offspring's genome with another member of the population. Here we
demonstrate that sexual reproduction can be evolutionary stable even when its
Darwinian fitness is twice as low when compared to the fitness of asexual
mutants. We also show that more than two sexes are always evolutionary
unstable. Our approach generalizes the evolutionary game theory to analyze
species whose members are able to sense the sexual state of their conspecifics
and to switch sexes consequently. The widespread emergence and maintenance of
sex follows therefore from its co-evolution with even more widespread
environmental sensing abilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3214</identifier>
 <datestamp>2008-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3214</id><created>2008-08-23</created><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames></author><author><keyname>Sochen</keyname><forenames>Nir</forenames></author></authors><title>The discrete Fourier transform: A canonical basis of eigenfunctions</title><categories>cs.IT cs.DM math.IT math.RT</categories><comments>To appear in the proceeding of the 2008 European Signal Processing
  Conference (EUSIPCO-2008), Lausanne, Switzerland; MSC classifications:
  Fourier transform, Weil representation, symmetries, eigenfunctions,
  oscillator transform, fast oscillator transform</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discrete Fourier transform (DFT) is an important operator which acts on
the Hilbert space of complex valued functions on the ring Z/NZ. In the case
where N=p is an odd prime number, we exhibit a canonical basis of eigenvectors
for the DFT. The transition matrix from the standard basis to the canonical
basis defines a novel transform which we call the &quot;discrete oscillator
transform&quot; (DOT for short). Finally, we describe a fast algorithm for computing
the DOT in certain cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3222</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3222</id><created>2008-08-23</created><updated>2008-09-03</updated><authors><author><keyname>Meek</keyname><forenames>Jerrald</forenames></author></authors><title>Analysis of the postulates produced by Karp's Theorem</title><categories>cs.CC</categories><comments>12 Pages;
  ftp://ftp%40micrognu%2Ecom:anon%40anon@ftp.micrognu.com/pnenp/conclusion.pdf</comments><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the final article in a series of four articles. Richard Karp has
proven that a deterministic polynomial time solution to K-SAT will result in a
deterministic polynomial time solution to all NP-Complete problems. However, it
is demonstrated that a deterministic polynomial time solution to any
NP-Complete problem does not necessarily produce a deterministic polynomial
time solution to all NP-Complete problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3230</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3230</id><created>2008-08-24</created><authors><author><keyname>Liu</keyname><forenames>Jialing</forenames></author><author><keyname>Yadav</keyname><forenames>Vikas</forenames></author><author><keyname>Sehgal</keyname><forenames>Hullas</forenames></author><author><keyname>Olson</keyname><forenames>Joshua M.</forenames></author><author><keyname>Liu</keyname><forenames>Haifeng</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author></authors><title>Phase Transitions on Fixed Connected Graphs and Random Graphs in the
  Presence of Noise</title><categories>math.OC cs.IT math.IT</categories><comments>15 pages, 3 figures. To appear in the IEEE Transactions on Automatic
  Control</comments><journal-ref>IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 53, NO. 8, 1817-1825,
  SEPTEMBER 2008</journal-ref><doi>10.1109/TAC.2008.929382</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the phase transition behavior emerging from the
interactions among multiple agents in the presence of noise. We propose a
simple discrete-time model in which a group of non-mobile agents form either a
fixed connected graph or a random graph process, and each agent, taking bipolar
value either +1 or -1, updates its value according to its previous value and
the noisy measurements of the values of the agents connected to it. We present
proofs for the occurrence of the following phase transition behavior: At a
noise level higher than some threshold, the system generates symmetric behavior
(vapor or melt of magnetization) or disagreement; whereas at a noise level
lower than the threshold, the system exhibits spontaneous symmetry breaking
(solid or magnetization) or consensus. The threshold is found analytically. The
phase transition occurs for any dimension. Finally, we demonstrate the phase
transition behavior and all analytic results using simulations. This result may
be found useful in the study of the collective behavior of complex systems
under communication constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3231</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3231</id><created>2008-08-24</created><updated>2011-10-23</updated><authors><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author><author><keyname>Zhang</keyname><forenames>Min-Ling</forenames></author><author><keyname>Huang</keyname><forenames>Sheng-Jun</forenames></author><author><keyname>Li</keyname><forenames>Yu-Feng</forenames></author></authors><title>Multi-Instance Multi-Label Learning</title><categories>cs.LG cs.AI</categories><comments>64 pages, 10 figures; Artificial Intelligence, 2011</comments><journal-ref>Artificial Intelligence, 2012, 176(1): 2291-2320</journal-ref><doi>10.1016/j.artint.2011.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose the MIML (Multi-Instance Multi-Label learning)
framework where an example is described by multiple instances and associated
with multiple class labels. Compared to traditional learning frameworks, the
MIML framework is more convenient and natural for representing complicated
objects which have multiple semantic meanings. To learn from MIML examples, we
propose the MimlBoost and MimlSvm algorithms based on a simple degeneration
strategy, and experiments show that solving problems involving complicated
objects with multiple semantic meanings in the MIML framework can lead to good
performance. Considering that the degeneration process may lose information, we
propose the D-MimlSvm algorithm which tackles MIML problems directly in a
regularization framework. Moreover, we show that even when we do not have
access to the real objects and thus cannot capture more information from real
objects by using the MIML representation, MIML is still useful. We propose the
InsDif and SubCod algorithms. InsDif works by transforming single-instances
into the MIML representation for learning, while SubCod works by transforming
single-label examples into the MIML representation for learning. Experiments
show that in some tasks they are able to achieve better performance than
learning the single-instances or single-label examples directly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3244</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3244</id><created>2008-08-24</created><authors><author><keyname>Kempner</keyname><forenames>Yulia</forenames></author><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author></authors><title>Duality between quasi-concave functions and monotone linkage functions</title><categories>math.CO cs.DM</categories><comments>12 pages, 2 figures</comments><msc-class>05B35 (Primary); 90C27 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A function $F$ defined on all subsets of a finite ground set $E$ is
quasi-concave if $F(X\cup Y)\geq\min\{F(X),F(Y)\}$ for all $X,Y\subset E$.
Quasi-concave functions arise in many fields of mathematics and computer
science such as social choice, theory of graph, data mining, clustering and
other fields.
  The maximization of quasi-concave function takes, in general, exponential
time. However, if a quasi-concave function is defined by associated monotone
linkage function then it can be optimized by the greedy type algorithm in a
polynomial time.
  Quasi-concave functions defined as minimum values of monotone linkage
functions were considered on antimatroids, where the correspondence between
quasi-concave and bottleneck functions was shown (Kempner &amp; Levit, 2003). The
goal of this paper is to analyze quasi-concave functions on different families
of sets and to investigate their relationships with monotone linkage functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3281</identifier>
 <datestamp>2008-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3281</id><created>2008-08-24</created><updated>2008-12-27</updated><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames><affiliation>University of Chicago</affiliation></author></authors><title>On the diagonalization of the discrete Fourier transform</title><categories>cs.IT cs.DM math.IT math.RT</categories><comments>Accepted for publication in the journal &quot;Applied and Computational
  Harmonic Analysis&quot;: Appl. Comput. Harmon. Anal. (2009),
  doi:10.1016/j.acha.2008.11.003. Key words: Discrete Fourier Transform, Weil
  Representation, Canonical Eigenvectors, Oscillator Transform, Fast Oscillator
  Transform</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discrete Fourier transform (DFT) is an important operator which acts on
the Hilbert space of complex valued functions on the ring Z/NZ. In the case
where N=p is an odd prime number, we exhibit a canonical basis of eigenvectors
for the DFT. The transition matrix from the standard basis to the canonical
basis defines a novel transform which we call the discrete oscillator transform
(DOT for short). Finally, we describe a fast algorithm for computing the
discrete oscillator transform in certain cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3292</identifier>
 <datestamp>2008-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3292</id><created>2008-08-24</created><authors><author><keyname>Ma</keyname><forenames>Yutao</forenames></author><author><keyname>He</keyname><forenames>Keqing</forenames></author><author><keyname>Liu</keyname><forenames>Jing</forenames></author></authors><title>Network Motifs in Object-Oriented Software Systems</title><categories>cs.SE</categories><comments>7 pages, 4 figures, 1 table, the revised version has been published
  by DCDIS-B special issue on software engineering and complex networks</comments><acm-class>D.2.8; K.6.3</acm-class><journal-ref>Dynamics of Continuous, Discrete and Impulsive Systems (Series B:
  Applications &amp; Algorithms), 2007, 14(S6): 166-172</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, software has become a complex piece of work that may be beyond our
control. Understanding how software evolves over time plays an important role
in controlling software development processes. Recently, a few researchers
found the quantitative evidence of structural duplication in software systems
or web applications, which is similar to the evolutionary trend found in
biological systems. To investigate the principles or rules of software
evolution, we introduce the relevant theories and methods of complex networks
into structural evolution and change of software systems. According to the
results of our experiment on network motifs, we find that the stability of a
motif shows positive correlation with its abundance and a motif with high Z
score tends to have stable structure. These findings imply that the evolution
of software systems is based on functional cloning as well as structural
duplication and tends to be structurally stable. So, the work presented in this
paper will be useful for the analysis of structural changes of software systems
in reverse engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3296</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3296</id><created>2008-08-24</created><updated>2008-08-26</updated><authors><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>Confirmation Bias and the Open Access Advantage: Some Methodological
  Suggestions for the Davis Citation Study</title><categories>cs.DL cs.DB</categories><comments>17 pages, 17 references, 1 table; comment on 0808.2428v1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Davis (2008) analyzes citations from 2004-2007 in 11 biomedical journals. 15%
of authors paid to make them Open Access (OA). The outcome is a significant OA
citation Advantage, but a small one (21%). The author infers that the OA
advantage has been shrinking yearly, but the data suggest the opposite. Further
analyses are necessary:
  (1) Not just author-choice (paid) OA but Free OA self-archiving needs to be
taken into account rather than being counted as non-OA.
  (2) proportion of OA articles per journal per year needs to be reported and
taken into account.
  (3) The Journal Impact Factor and the relation between the size of the OA
Advantage article 'citation-bracket' need to be taken into account.
  (4) The sample-size for the highest-impact, largest-sample journal analyzed,
PNAS, is restricted and excluded from some of the analyses. The full PNAS
dataset is needed.
  (5) The interaction between OA and time, 2004-2007, is based on retrospective
data from a June 2008 total cumulative citation count. The dates of both the
cited articles and the citing articles need to be taken into account.
  The author proposes that author self-selection bias for is the primary cause
of the observed OA Advantage, but this study does not test this or of any of
the other potential causal factors. The author suggests that paid OA is not
worth the cost, per extra citation. But with OA self-archiving both the OA and
the extra citations are free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3307</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3307</id><created>2008-08-25</created><updated>2008-09-20</updated><authors><author><keyname>Shikuma</keyname><forenames>Naokata</forenames></author><author><keyname>Igarashi</keyname><forenames>Atsushi</forenames></author></authors><title>Proving Noninterference by a Fully Complete Translation to the Simply
  Typed lambda-calculus</title><categories>cs.PL cs.CR</categories><comments>31 pages</comments><acm-class>D.3.1; F.3.2; F.3.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (September
  20, 2008) lmcs:683</journal-ref><doi>10.2168/LMCS-4(3:10)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tse and Zdancewic have formalized the notion of noninterference for Abadi et
al.'s DCC in terms of logical relations and given a proof of noninterference by
reduction to parametricity of System F. Unfortunately, their proof contains
errors in a key lemma that their translation from DCC to System F preserves the
logical relations defined for both calculi. In fact, we have found a
counterexample for it. In this article, instead of DCC, we prove
noninterference for sealing calculus, a new variant of DCC, by reduction to the
basic lemma of a logical relation for the simply typed lambda-calculus, using a
fully complete translation to the simply typed lambda-calculus. Full
completeness plays an important role in showing preservation of the two logical
relations through the translation. Also, we investigate relationship among
sealing calculus, DCC, and an extension of DCC by Tse and Zdancewic and show
that the first and the last of the three are equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3331</identifier>
 <datestamp>2008-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3331</id><created>2008-08-25</created><authors><author><keyname>Karagiorgos</keyname><forenames>Gregory</forenames></author><author><keyname>Poulakis</keyname><forenames>Dimitrios</forenames></author></authors><title>Efficient algorithms for the basis of finite Abelian groups</title><categories>cs.DS cs.CC</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a finite abelian group $G$ with $N$ elements. In this paper we
give a O(N) time algorithm for computing a basis of $G$. Furthermore, we obtain
an algorithm for computing a basis from a generating system of $G$ with $M$
elements having time complexity $O(M\sum_{p|N} e(p)\lceil
p^{1/2}\rceil^{\mu(p)})$, where $p$ runs over all the prime divisors of $N$,
and $p^{e(p)}$, $\mu(p)$ are the exponent and the number of cyclic groups which
are direct factors of the $p$-primary component of $G$, respectively. In case
where $G$ is a cyclic group having a generating system with $M$ elements, a
$O(MN^{\epsilon})$ time algorithm for the computation of a basis of $G$ is
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3386</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3386</id><created>2008-08-25</created><updated>2014-03-18</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>Linear Programming Formulation of the Boolean Satisfiability Problem</title><categories>cs.DM cs.CC</categories><comments>This paper has been withdrawn because Theorem 38 and Corollary 39 are
  in error. The modeling needs 9-dimensional z-variables instead of the
  8-dimensional variables defined in notations 24.1</comments><acm-class>F.2.2; G.1.6; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theorem 38 and Corollary 39 are in error. The modeling idea is sound, but it
needs 9-dimensional z-variables instead of the 8-dimensional variables defined
in notations 24.1.
  Examples of the correct model (with 9-index variables) are: (1) Diaby, M.,
&quot;Linear Programming Formulation of the Set Partitioning Problem,&quot; International
Journal of Operational Research 8:4 (August 2010) pp. 399-427; (2) Diaby, M.,
&quot;Linear Programming Formulation of the Vertex Coloring Problem,&quot; International
Journal of Mathematics in Operational Research 2:3 (May 2010) pp. 259-289; (3)
Diaby, M., &quot;The Traveling Salesman Problem: A Linear Programming Formulation,&quot;
WSEAS Transactions on Mathematics, 6:6 (June 2007) pp. 745-754.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3418</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3418</id><created>2008-08-26</created><authors><author><keyname>Amariucai</keyname><forenames>George T.</forenames></author><author><keyname>Wei</keyname><forenames>Shuangqing</forenames></author><author><keyname>Kannan</keyname><forenames>Rajgopal</forenames></author></authors><title>Jamming in Fixed-Rate Wireless Systems with Power Constraints - Part II:
  Parallel Slow Fading Channels</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the second part of a two-part paper that studies the problem of
jamming in a fixed-rate transmission system with fading. In the first part, we
studied the scenario with a fast fading channel, and found Nash equilibria of
mixed strategies for short term power constraints, and for average power
constraints with and without channel state information (CSI) feedback. We also
solved the equally important maximin and minimax problems with pure strategies.
Whenever we dealt with average power constraints, we decomposed the problem
into two levels of power control, which we solved individually. In this second
part of the paper, we study the scenario with a parallel, slow fading channel,
which usually models multi-carrier transmissions, such as OFDM. Although the
framework is similar as the one in Part I \cite{myself3}, dealing with the slow
fading requires more intricate techniques. Unlike in the fast fading scenario,
where the frames supporting the transmission of the codewords were equivalent
and completely characterized by the channel statistics, in our present scenario
the frames are unique, and characterized by a specific set of channel
realizations. This leads to more involved inter-frame power allocation
strategies, and in some cases even to the need for a third level of power
control. We also show that for parallel slow fading channels, the CSI feedback
helps in the battle against jamming, as evidenced by the significant
degradation to system performance when CSI is not sent back. We expect this
degradation to decrease as the number of parallel channels $M$ increases, until
it becomes marginal for $M\to \infty$ (which can be considered as the case in
Part I).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3431</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3431</id><created>2008-08-26</created><authors><author><keyname>Amariucai</keyname><forenames>George T.</forenames></author><author><keyname>Wei</keyname><forenames>Shuangqing</forenames></author></authors><title>Jamming in Fixed-Rate Wireless Systems with Power Constraints - Part I:
  Fast Fading Channels</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the first part of a two-part paper that studies the problem of
jamming in a fixed-rate transmission system with fading. Both transmitter and
jammer are subject to power constraints which can be enforced over each
codeword short-term / peak) or over all codewords (long-term / average), hence
generating different scenarios. All our jamming problems are formulated as
zero-sum games, having the probability of outage as pay-off function and power
control functions as strategies. The paper aims at providing a comprehensive
coverage of these problems, under fast and slow fading, peak and average power
constraints, pure and mixed strategies, with and without channel state
information (CSI) feedback. In this first part we study the fast fading
scenario. We first assume full CSI to be available to all parties. For peak
power constraints, a Nash equilibrium of pure strategies is found. For average
power constraints, both pure and mixed strategies are investigated. With pure
strategies, we derive the optimal power control functions for both intra-frame
and inter-frame power allocation. Maximin and minimax solutions are found and
shown to be different, which implies the non-existence of a saddle point. In
addition we provide alternative perspectives in obtaining the optimal
intra-frame power control functions under the long-term power constraints. With
mixed strategies, the Nash equilibrium is found by solving the generalized form
of an older problem dating back to Bell and Cover \cite{bell}. Finally, we
derive a Nash equilibrium of the game in which no CSI is fed back from the
receiver. We show that full channel state information brings only a very slight
improvement in the system's performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3453</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3453</id><created>2008-08-26</created><updated>2008-08-30</updated><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author><author><keyname>Z&#xe9;mor</keyname><forenames>Gilles</forenames></author></authors><title>Codes on hypergraphs</title><categories>cs.IT math.IT</categories><comments>16 pages</comments><journal-ref>Advances in Mathematics of Communications (AMC), Vol. 2, No 4,
  (2008) pp. 433 - 450.</journal-ref><doi>10.3934/amc.2008.2.433</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codes on hypergraphs are an extension of the well-studied family of codes on
bipartite graphs. Bilu and Hoory (2004) constructed an explicit family of codes
on regular t-partite hypergraphs whose minimum distance improves earlier
estimates of the distance of bipartite-graph codes. They also suggested a
decoding algorithm for such codes and estimated its error-correcting
capability.
  In this paper we study two aspects of hypergraph codes. First, we compute the
weight enumerators of several ensembles of such codes, establishing conditions
under which they attain the Gilbert-Varshamov bound and deriving estimates of
their distance. In particular, we show that this bound is attained by codes
constructed on a fixed bipartite graph with a large spectral gap.
  We also suggest a new decoding algorithm of hypergraph codes that corrects a
constant fraction of errors, improving upon the algorithm of Bilu and Hoory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3502</identifier>
 <datestamp>2009-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3502</id><created>2008-08-26</created><updated>2009-01-23</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>de Baynast</keyname><forenames>Alexandre</forenames></author></authors><title>Cooperative Protocols for Random Access Networks</title><categories>cs.IT math.IT</categories><comments>7 pages, presented at Allerton conference 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative communications have emerged as a significant concept to improve
reliability and throughput in wireless systems. On the other hand, WLANs based
on random access mechanism have become popular due to ease of deployment and
low cost. Since cooperation introduces extra transmissions among the
cooperating nodes and therefore increases the number of packet collisions, it
is not clear whether there is any benefit from using physical layer cooperation
under random access. In this paper, we develop new low complexity cooperative
protocols for random access that outperform the conventional non cooperative
scheme for a large range of signal-to-noise ratios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3504</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3504</id><created>2008-08-26</created><authors><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Fossorier</keyname><forenames>Marc</forenames></author></authors><title>On the Growth Rate of the Weight Distribution of Irregular
  Doubly-Generalized LDPC Codes</title><categories>cs.IT math.IT</categories><comments>10 pages, 1 figure, presented at the 46th Annual Allerton Conference
  on Communication, Control and Computing (this version includes additional
  appendix)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an expression for the asymptotic growth rate of the number of
small linear-weight codewords of irregular doubly-generalized LDPC (D-GLDPC)
codes is derived. The expression is compact and generalizes existing results
for LDPC and generalized LDPC (GLDPC) codes. Assuming that there exist check
and variable nodes with minimum distance 2, it is shown that the growth rate
depends only on these nodes. An important connection between this new result
and the stability condition of D-GLDPC codes over the BEC is highlighted. Such
a connection, previously observed for LDPC and GLDPC codes, is now extended to
the case of D-GLDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3511</identifier>
 <datestamp>2008-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3511</id><created>2008-08-26</created><updated>2008-08-27</updated><authors><author><keyname>Sastry</keyname><forenames>P. S.</forenames><affiliation>Indian Institute of Science</affiliation></author><author><keyname>Unnikrishnan</keyname><forenames>K. P.</forenames><affiliation>General Motors Research</affiliation></author></authors><title>Conditional probability based significance tests for sequential patterns
  in multi-neuronal spike trains</title><categories>q-bio.NC cond-mat.dis-nn cs.DB q-bio.QM stat.ME</categories><comments>35 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of detecting statistically significant
sequential patterns in multi-neuronal spike trains. These patterns are
characterized by ordered sequences of spikes from different neurons with
specific delays between spikes. We have previously proposed a data mining
scheme to efficiently discover such patterns which are frequent in the sense
that the count of non-overlapping occurrences of the pattern in the data stream
is above a threshold. Here we propose a method to determine the statistical
significance of these repeating patterns and to set the thresholds
automatically. The novelty of our approach is that we use a compound null
hypothesis that includes not only models of independent neurons but also models
where neurons have weak dependencies. The strength of interaction among the
neurons is represented in terms of certain pair-wise conditional probabilities.
We specify our null hypothesis by putting an upper bound on all such
conditional probabilities. We construct a probabilistic model that captures the
counting process and use this to calculate the mean and variance of the count
for any pattern. Using this we derive a test of significance for rejecting such
a null hypothesis. This also allows us to rank-order different significant
patterns. We illustrate the effectiveness of our approach using spike trains
generated from a non-homogeneous Poisson model with embedded dependencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3535</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3535</id><created>2008-08-26</created><authors><author><keyname>Raicu</keyname><forenames>Ioan</forenames></author><author><keyname>Zhao</keyname><forenames>Yong</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author></authors><title>Data Diffusion: Dynamic Resource Provision and Data-Aware Scheduling for
  Data Intensive Applications</title><categories>cs.DC</categories><comments>16 pages, 15 figures</comments><acm-class>C.2.4; D.1.3; D.4.2; D.4.7; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data intensive applications often involve the analysis of large datasets that
require large amounts of compute and storage resources. While dedicated compute
and/or storage farms offer good task/data throughput, they suffer low resource
utilization problem under varying workloads conditions. If we instead move such
data to distributed computing resources, then we incur expensive data transfer
cost. In this paper, we propose a data diffusion approach that combines dynamic
resource provisioning, on-demand data replication and caching, and data
locality-aware scheduling to achieve improved resource efficiency under varying
workloads. We define an abstract &quot;data diffusion model&quot; that takes into
consideration the workload characteristics, data accessing cost, application
throughput and resource utilization; we validate the model using a real-world
large-scale astronomy application. Our results show that data diffusion can
increase the performance index by as much as 34X, and improve application
response time by over 506X, while achieving near-optimal throughputs and
execution times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3536</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3536</id><created>2008-08-26</created><authors><author><keyname>Raicu</keyname><forenames>Ioan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhao</forenames></author><author><keyname>Wilde</keyname><forenames>Mike</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author></authors><title>Enabling Loosely-Coupled Serial Job Execution on the IBM BlueGene/P
  Supercomputer and the SiCortex SC5832</title><categories>cs.DC</categories><comments>13 pages, 18 figures</comments><acm-class>C.2.4; D.1.3; D.4.7; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work addresses the enabling of the execution of highly parallel
computations composed of loosely coupled serial jobs with no modifications to
the respective applications, on large-scale systems. This approach allows
new-and potentially far larger-classes of application to leverage systems such
as the IBM Blue Gene/P supercomputer and similar emerging petascale
architectures. We present here the challenges of I/O performance encountered in
making this model practical, and show results using both micro-benchmarks and
real applications on two large-scale systems, the BG/P and the SiCortex SC5832.
Our preliminary benchmarks show that we can scale to 4096 processors on the
Blue Gene/P and 5832 processors on the SiCortex with high efficiency, and can
achieve thousands of tasks/sec sustained execution rates for parallel workloads
of ordinary serial applications. We measured applications from two domains,
economic energy modeling and molecular dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3540</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3540</id><created>2008-08-26</created><updated>2008-08-27</updated><authors><author><keyname>Raicu</keyname><forenames>Ioan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhao</forenames></author><author><keyname>Wilde</keyname><forenames>Mike</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author><author><keyname>Beckman</keyname><forenames>Pete</forenames></author><author><keyname>Iskra</keyname><forenames>Kamil</forenames></author><author><keyname>Clifford</keyname><forenames>Ben</forenames></author></authors><title>Towards Loosely-Coupled Programming on Petascale Systems</title><categories>cs.DC</categories><comments>IEEE/ACM International Conference for High Performance Computing,
  Networking, Storage and Analysis (SuperComputing/SC) 2008</comments><acm-class>C.2.4; D.1.3; D.4.7; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have extended the Falkon lightweight task execution framework to make
loosely coupled programming on petascale systems a practical and useful
programming model. This work studies and measures the performance factors
involved in applying this approach to enable the use of petascale systems by a
broader user community, and with greater ease. Our work enables the execution
of highly parallel computations composed of loosely coupled serial jobs with no
modifications to the respective applications. This approach allows a new-and
potentially far larger-class of applications to leverage petascale systems,
such as the IBM Blue Gene/P supercomputer. We present the challenges of I/O
performance encountered in making this model practical, and show results using
both microbenchmarks and real applications from two domains: economic energy
modeling and molecular dynamics. Our benchmarks show that we can scale up to
160K processor-cores with high efficiency, and can achieve sustained execution
rates of thousands of tasks per second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3545</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3545</id><created>2008-08-26</created><authors><author><keyname>Zhao</keyname><forenames>Yong</forenames></author><author><keyname>Raicu</keyname><forenames>Ioan</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author></authors><title>Scientific Workflow Systems for 21st Century e-Science, New Bottle or
  New Wine?</title><categories>cs.SE cs.DC</categories><comments>IEEE Workshop on Scientific Workflows 2008</comments><acm-class>D.1.3; D.4.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advances in e-Sciences and the growing complexity of scientific
analyses, more and more scientists and researchers are relying on workflow
systems for process coordination, derivation automation, provenance tracking,
and bookkeeping. While workflow systems have been in use for decades, it is
unclear whether scientific workflows can or even should build on existing
workflow technologies, or they require fundamentally new approaches. In this
paper, we analyze the status and challenges of scientific workflows,
investigate both existing technologies and emerging languages, platforms and
systems, and identify the key challenges that must be addressed by workflow
systems for e-science in the 21st century.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3546</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3546</id><created>2008-08-26</created><authors><author><keyname>Raicu</keyname><forenames>Ioan</forenames></author><author><keyname>Zhao</keyname><forenames>Yong</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author><author><keyname>Szalay</keyname><forenames>Alex</forenames></author></authors><title>Accelerating Large-scale Data Exploration through Data Diffusion</title><categories>cs.DC</categories><comments>IEEE/ACM International Workshop on Data-Aware Distributed Computing
  2008</comments><acm-class>C.2.4; D.4.2; D.4.7; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-intensive applications often require exploratory analysis of large
datasets. If analysis is performed on distributed resources, data locality can
be crucial to high throughput and performance. We propose a &quot;data diffusion&quot;
approach that acquires compute and storage resources dynamically, replicates
data in response to demand, and schedules computations close to data. As demand
increases, more resources are acquired, thus allowing faster response to
subsequent requests that refer to the same data; when demand drops, resources
are released. This approach can provide the benefits of dedicated hardware
without the associated high costs, depending on workload and resource
characteristics. The approach is reminiscent of cooperative caching,
web-caching, and peer-to-peer storage systems, but addresses different
application demands. Other data-aware scheduling approaches assume dedicated
resources, which can be expensive and/or inefficient if load varies
significantly. To explore the feasibility of the data diffusion approach, we
have extended the Falkon resource provisioning and task scheduling system to
support data caching and data-aware scheduling. Performance results from both
micro-benchmarks and a large scale astronomy application demonstrate that our
approach improves performance relative to alternative approaches, as well as
provides improved scalability as aggregated I/O bandwidth scales linearly with
the number of data cache nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3548</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3548</id><created>2008-08-26</created><authors><author><keyname>Zhao</keyname><forenames>Yong</forenames></author><author><keyname>Raicu</keyname><forenames>Ioan</forenames></author><author><keyname>Foster</keyname><forenames>Ian</forenames></author><author><keyname>Hategan</keyname><forenames>Mihael</forenames></author><author><keyname>Nefedova</keyname><forenames>Veronika</forenames></author><author><keyname>Wilde</keyname><forenames>Mike</forenames></author></authors><title>Realizing Fast, Scalable and Reliable Scientific Computations in Grid
  Environments</title><categories>cs.DC cs.PL</categories><comments>Book chapter in Grid Computing Research Progress, ISBN:
  978-1-60456-404-4, Nova Publisher 2008</comments><acm-class>D.1.3; D.4.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The practical realization of managing and executing large scale scientific
computations efficiently and reliably is quite challenging. Scientific
computations often involve thousands or even millions of tasks operating on
large quantities of data, such data are often diversely structured and stored
in heterogeneous physical formats, and scientists must specify and run such
computations over extended periods on collections of compute, storage and
network resources that are heterogeneous, distributed and may change
constantly. We present the integration of several advanced systems: Swift,
Karajan, and Falkon, to address the challenges in running various large scale
scientific applications in Grid environments. Swift is a parallel programming
tool for rapid and reliable specification, execution, and management of
large-scale science and engineering workflows. Swift consists of a simple
scripting language called SwiftScript and a powerful runtime system that is
based on the CoG Karajan workflow engine and integrates the Falkon light-weight
task execution service that uses multi-level scheduling and a streamlined
dispatcher. We showcase the scalability, performance and reliability of the
integrated system using application examples drawn from astronomy, cognitive
neuroscience and molecular dynamics, which all comprise large number of
fine-grained jobs. We show that Swift is able to represent dynamic workflows
whose structures can only be determined during runtime and reduce largely the
code size of various workflow representations using SwiftScript; schedule the
execution of hundreds of thousands of parallel computations via the Karajan
engine; and achieve up to 90% reduction in execution time when compared to
traditional batch schedulers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3558</identifier>
 <datestamp>2008-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3558</id><created>2008-08-26</created><authors><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Yeo</keyname><forenames>Chee Shin</forenames></author><author><keyname>Venugopal</keyname><forenames>Srikumar</forenames></author></authors><title>Market-Oriented Cloud Computing: Vision, Hype, and Reality for
  Delivering IT Services as Computing Utilities</title><categories>cs.DC</categories><comments>9 pages; GRIDS Lab Technical Report, Aug 2008</comments><acm-class>C.2.4</acm-class><journal-ref>Proceedings of the 10th IEEE International Conference on High
  Performance Computing and Communications (HPCC-08, IEEE CS Press, Los
  Alamitos, CA, USA), Sept. 25-27, 2008, Dalian, China</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This keynote paper: presents a 21st century vision of computing; identifies
various computing paradigms promising to deliver the vision of computing
utilities; defines Cloud computing and provides the architecture for creating
market-oriented Clouds by leveraging technologies such as VMs; provides
thoughts on market-based resource management strategies that encompass both
customer-driven service management and computational risk management to sustain
SLA-oriented resource allocation; presents some representative Cloud platforms
especially those developed in industries along with our current work towards
realising market-oriented resource allocation of Clouds by leveraging the 3rd
generation Aneka enterprise Grid technology; reveals our early thoughts on
interconnecting Clouds for dynamically creating an atmospheric computing
environment along with pointers to future community research; and concludes
with the need for convergence of competing IT paradigms for delivering our 21st
century vision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3563</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3563</id><created>2008-08-26</created><authors><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>What It Feels Like To Hear Voices: Fond Memories of Julian Jaynes</title><categories>cs.CL</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Julian Jaynes's profound humanitarian convictions not only prevented him from
going to war, but would have prevented him from ever kicking a dog. Yet
according to his theory, not only are language-less dogs unconscious, but so
too were the speaking/hearing Greeks in the Bicameral Era, when they heard
gods' voices telling them what to do rather than thinking for themselves. I
argue that to be conscious is to be able to feel, and that all mammals (and
probably lower vertebrates and invertebrates too) feel, hence are conscious.
Julian Jaynes's brilliant analysis of our concepts of consciousness
nevertheless keeps inspiring ever more inquiry and insights into the age-old
mind/body problem and its relation to cognition and language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3569</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3569</id><created>2008-08-26</created><updated>2008-09-01</updated><authors><author><keyname>Dror</keyname><forenames>Itiel</forenames></author><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>Offloading Cognition onto Cognitive Technology</title><categories>cs.MA cs.CL</categories><comments>To Appear in: Itiel E. Dror &amp; Stevan Harnad (Eds) Cognition
  Distributed: How Cognitive Technology Extends Our Minds. Amsterdam: John
  Benjamins</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;Cognizing&quot; (e.g., thinking, understanding, and knowing) is a mental state.
Systems without mental states, such as cognitive technology, can sometimes
contribute to human cognition, but that does not make them cognizers. Cognizers
can offload some of their cognitive functions onto cognitive technology,
thereby extending their performance capacity beyond the limits of their own
brain power. Language itself is a form of cognitive technology that allows
cognizers to offload some of their cognitive functions onto the brains of other
cognizers. Language also extends cognizers' individual and joint performance
powers, distributing the load through interactive and collaborative cognition.
Reading, writing, print, telecommunications and computing further extend
cognizers' capacities. And now the web, with its network of cognizers, digital
databases and software agents, all accessible anytime, anywhere, has become our
'Cognitive Commons,' in which distributed cognizers and cognitive technology
can interoperate globally with a speed, scope and degree of interactivity
inconceivable through local individual cognition alone. And as with language,
the cognitive tool par excellence, such technological changes are not merely
instrumental and quantitative: they can have profound effects on how we think
and encode information, on how we communicate with one another, on our mental
states, and on our very nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3572</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3572</id><created>2008-08-26</created><updated>2009-12-09</updated><authors><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author><author><keyname>Cevher</keyname><forenames>Volkan</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Hegde</keyname><forenames>Chinmay</forenames></author></authors><title>Model-Based Compressive Sensing</title><categories>cs.IT math.IT</categories><comments>20 pages, 10 figures. Typo corrected in grant number. To appear in
  IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) is an alternative to Shannon/Nyquist sampling for
the acquisition of sparse or compressible signals that can be well approximated
by just K &lt;&lt; N elements from an N-dimensional basis. Instead of taking periodic
samples, CS measures inner products with M &lt; N random vectors and then recovers
the signal via a sparsity-seeking optimization or greedy algorithm. Standard CS
dictates that robust signal recovery is possible from M = O(K log(N/K))
measurements. It is possible to substantially decrease M without sacrificing
robustness by leveraging more realistic signal models that go beyond simple
sparsity and compressibility by including structural dependencies between the
values and locations of the signal coefficients. This paper introduces a
model-based CS theory that parallels the conventional theory and provides
concrete guidelines on how to create model-based recovery algorithms with
provable performance guarantees. A highlight is the introduction of a new class
of structured compressible signals along with a new sufficient condition for
robust structured compressible signal recovery that we dub the restricted
amplification property, which is the natural counterpart to the restricted
isometry property of conventional CS. Two examples integrate two relevant
signal models - wavelet trees and block sparsity - into two state-of-the-art CS
recovery algorithms and prove that they offer robust recovery from just M=O(K)
measurements. Extensive numerical simulations demonstrate the validity and
applicability of our new theory and algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3574</identifier>
 <datestamp>2008-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3574</id><created>2008-08-26</created><authors><author><keyname>D'Hondt</keyname><forenames>Ellie</forenames></author><author><keyname>Sadrzadeh</keyname><forenames>Mehrnoosh</forenames></author></authors><title>Classical Knowledge for Quantum Security</title><categories>cs.CR cs.LO quant-ph</categories><comments>extended abstract, 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a decision procedure for analysing security of quantum
cryptographic protocols, combining a classical algebraic rewrite system for
knowledge with an operational semantics for quantum distributed computing. As a
test case, we use our procedure to reason about security properties of a
recently developed quantum secret sharing protocol that uses graph states. We
analyze three different scenarios based on the safety assumptions of the
classical and quantum channels and discover the path of an attack in the
presence of an adversary. The epistemic analysis that leads to this and similar
types of attacks is purely based on our classical notion of knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3616</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3616</id><created>2008-08-26</created><updated>2009-03-30</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Constructing word similarities in Meroitic as an aid to decipherment</title><categories>cs.CL</categories><comments>10 pages; 2 figures; to appear in British Museum studies in Ancient
  Egypt and Sudan</comments><journal-ref>British Museum Studies in Ancient Egypt and Sudan, 12, 1-10 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meroitic is the still undeciphered language of the ancient civilization of
Kush. Over the years, various techniques for decipherment such as finding a
bilingual text or cognates from modern or other ancient languages in the Sudan
and surrounding areas has not been successful. Using techniques borrowed from
information theory and natural language statistics, similar words are paired
and attempts are made to use currently defined words to extract at least
partial meaning from unknown words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3651</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3651</id><created>2008-08-27</created><updated>2008-11-18</updated><authors><author><keyname>Zhang</keyname><forenames>Lijun</forenames></author><author><keyname>Hermanns</keyname><forenames>Holger</forenames></author><author><keyname>Eisenbrand</keyname><forenames>Friedrich</forenames></author><author><keyname>Jansen</keyname><forenames>David N.</forenames></author></authors><title>Flow Faster: Efficient Decision Algorithms for Probabilistic Simulations</title><categories>cs.LO</categories><comments>LMCS</comments><acm-class>F.2.1; F.3.1; G.2.2; G.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (November
  11, 2008) lmcs:989</journal-ref><doi>10.2168/LMCS-4(4:6)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Strong and weak simulation relations have been proposed for Markov chains,
while strong simulation and strong probabilistic simulation relations have been
proposed for probabilistic automata. However, decision algorithms for strong
and weak simulation over Markov chains, and for strong simulation over
probabilistic automata are not efficient, which makes it as yet unclear whether
they can be used as effectively as their non-probabilistic counterparts. This
paper presents drastically improved algorithms to decide whether some
(discrete- or continuous-time) Markov chain strongly or weakly simulates
another, or whether a probabilistic automaton strongly simulates another. The
key innovation is the use of parametric maximum flow techniques to amortize
computations. We also present a novel algorithm for deciding strong
probabilistic simulation preorders on probabilistic automata, which has
polynomial complexity via a reduction to an LP problem. When extending the
algorithms for probabilistic automata to their continuous-time counterpart, we
retain the same complexity for both strong and strong probabilistic
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3689</identifier>
 <datestamp>2008-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3689</id><created>2008-08-27</created><updated>2008-08-28</updated><authors><author><keyname>Kang</keyname><forenames>Xin</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Nallanathan</keyname><forenames>Arumugam</forenames></author><author><keyname>Garg</keyname><forenames>Hari Krishna</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Optimal Power Allocation for Fading Channels in Cognitive Radio
  Networks: Ergodic Capacity and Outage Capacity</title><categories>cs.IT math.IT</categories><comments>26 pages, 9 figures, to appear in IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cognitive radio network (CRN) is formed by either allowing the secondary
users (SUs) in a secondary communication network (SCN) to opportunistically
operate in the frequency bands originally allocated to a primary communication
network (PCN) or by allowing SCN to coexist with the primary users (PUs) in PCN
as long as the interference caused by SCN to each PU is properly regulated. In
this paper, we consider the latter case, known as spectrum sharing, and study
the optimal power allocation strategies to achieve the ergodic capacity and the
outage capacity of the SU fading channel under different types of power
constraints and fading channel models. In particular, besides the interference
power constraint at PU, the transmit power constraint of SU is also considered.
Since the transmit power and the interference power can be limited either by a
peak or an average constraint, various combinations of power constraints are
studied. It is shown that there is a capacity gain for SU under the average
over the peak transmit/interference power constraint. It is also shown that
fading for the channel between SU transmitter and PU receiver is usually a
beneficial factor for enhancing the SU channel capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3693</identifier>
 <datestamp>2008-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3693</id><created>2008-08-27</created><authors><author><keyname>Grehant</keyname><forenames>Xavier</forenames></author><author><keyname>Dana</keyname><forenames>J. M.</forenames></author></authors><title>Providing Virtual Execution Environments: A Twofold Illustration</title><categories>cs.DC</categories><comments>openlab Technical Documents and Publications</comments><acm-class>C.0; D.2.9; D.4.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Platform virtualization helps solving major grid computing challenges: share
resource with flexible, user-controlled and custom execution environments and
in the meanwhile, isolate failures and malicious code. Grid resource management
tools will evolve to embrace support for virtual resource.
  We present two open source projects that transparently supply virtual
execution environments. Tycoon has been developed at HP Labs to optimise
resource usage in creating an economy where users bid to access virtual
machines and compete for CPU cycles. SmartDomains provides a peer-to-peer layer
that automates virtual machines deployment using a description language and
deployment engine from HP Labs. These projects demonstrate both client-server
and peer-to-peer approaches to virtual resource management. The first case
makes extensive use of virtual machines features for dynamic resource
allocation. The second translates virtual machines capabilities into a
sophisticated language where resource management components can be plugged in
configurations and architectures defined at deployment time.
  We propose to share our experience at CERN openlab developing SmartDomains
and deploying Tycoon to give an illustrative introduction to emerging research
in virtual resource management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3694</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3694</id><created>2008-08-27</created><updated>2009-05-13</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Studying Geometric Graph Properties of Road Networks Through an
  Algorithmic Lens</title><categories>cs.CG</categories><comments>Expanded version of paper appearing at ACM GIS 2008</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies real-world road networks from an algorithmic perspective,
focusing on empirical studies that yield useful properties of road networks
that can be exploited in the design of fast algorithms that deal with
geographic data. Unlike previous approaches, our study is not based on the
assumption that road networks are planar graphs. Indeed, based on the a number
of experiments we have performed on the road networks of the 50 United States
and District of Columbia, we provide strong empirical evidence that road
networks are quite non-planar. Our approach therefore instead is directed at
finding algorithmically-motivated properties of road networks as non-planar
geometric graphs, focusing on alternative properties of road networks that can
still lead to efficient algorithms for such problems as shortest paths and
Voronoi diagrams. In particular, we study road networks as multiscale-dispersed
graphs, which is a concept we formalize in terms of disk neighborhood systems.
This approach allows us to develop fast algorithms for road networks without
making any additional assumptions about the distribution of edge weights. In
fact, our algorithms can allow for non-metric weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3712</identifier>
 <datestamp>2008-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3712</id><created>2008-08-27</created><updated>2008-12-10</updated><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author></authors><title>Critique du rapport signal \`a bruit en communications num\'eriques --
  Questioning the signal to noise ratio in digital communications</title><categories>cs.IT math.IT math.PR math.RA</categories><proxy>ccsd inria-00311719</proxy><journal-ref>ARIMA (Revue africaine d'informatique et de Math\'ematiques
  appliqu\'ees) 9 (2008) 419-429</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The signal to noise ratio, which plays such an important r\^ole in
information theory, is shown to become pointless for digital communications
where the demodulation is achieved via new fast estimation techniques.
Operational calculus, differential algebra, noncommutative algebra and
nonstandard analysis are the main mathematical tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3717</identifier>
 <datestamp>2008-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3717</id><created>2008-08-27</created><authors><author><keyname>van Reijswoud</keyname><forenames>Victor</forenames></author><author><keyname>de Jager</keyname><forenames>Arjan</forenames></author></authors><title>Free and Open Source Software for Development</title><categories>cs.GL</categories><comments>113 pages, ISBN 978-88-7699-131-8 (Printed edition), ISBN
  978-88-7699-132-5 (Electronic edition), printed edition available at
  http://www.amazon.com/ and on http://stores.lulu.com/polimetrica</comments><journal-ref>&quot;Publishing studies&quot; book series, edited by Giandomenico Sica,
  ISSN 1973-6061 (Printed edition), ISSN 1973-6053 (Electronic edition)</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Development organizations and International Non-Governmental Organizations
have been emphasizing the high potential of Free and Open Source Software for
the Less Developed Countries. Cost reduction, less vendor dependency and
increased potential for local capacity development have been their main
arguments. In spite of its advantages, Free and Open Source Software is not
widely adopted at the African continent. In this book the authors will explore
the grounds on with these expectations are based. Where do they come from and
is there evidence to support these expectations? Over the past years several
projects have been initiated and some good results have been achieved, but at
the same time many challenges were encountered. What lessons can be drawn from
these experiences and do these experiences contain enough evidence to support
the high expectations? Several projects and their achievements will be
considered. In the final part of the book the future of Free and Open Source
Software for Development will be explored. Special attention is given to the
African continent since here challenges are highest. What is the role of Free
and open Source Software for Development and how do we need to position and
explore the potential? What are the threats? The book aims at professionals
that are engaged in the design and implementation of ICT for Development
(ICT4D) projects and want to improve their understanding of the role Free and
Open Source Software can play.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3726</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3726</id><created>2008-08-27</created><updated>2009-10-14</updated><authors><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Highly accurate recommendation algorithm based on high-order
  similarities</title><categories>physics.data-an cs.IR</categories><journal-ref>Physica A 389, 881-886 (2010)</journal-ref><doi>10.1016/j.physa.2009.10.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this Letter, we introduce a modified collaborative filtering (MCF)
algorithm, which has remarkably higher accuracy than the standard collaborative
filtering. In the MCF, instead of the standard Pearson coefficient, the
user-user similarities are obtained by a diffusion process. Furthermore, by
considering the second order similarities, we design an effective algorithm
that depresses the influence of mainstream preferences. The corresponding
algorithmic accuracy, measured by the ranking score, is further improved by
24.9% in the optimal case. In addition, two significant criteria of algorithmic
performance, diversity and popularity, are also taken into account. Numerical
results show that the algorithm based on second order similarity can outperform
the MCF simultaneously in all three criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3746</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3746</id><created>2008-08-27</created><updated>2008-10-21</updated><authors><author><keyname>V'yugin</keyname><forenames>Vladimir V.</forenames></author></authors><title>A game-theoretic version of Oakes' example for randomized forecasting</title><categories>cs.LG cs.GT</categories><comments>9 pages</comments><acm-class>I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the game-theoretic framework for probability, Vovk and Shafer. have
shown that it is always possible, using randomization, to make sequential
probability forecasts that pass any countable set of well-behaved statistical
tests. This result generalizes work by other authors, who consider only tests
of calbration.
  We complement this result with a lower bound. We show that Vovk and Shafer's
result is valid only when the forecasts are computed with unrestrictedly
increasing degree of accuracy.
  When some level of discreteness is fixed, we present a game-theoretic
generalization of Oakes' example for randomized forecasting that is a test
failing any given method of deferministic forecasting; originally, this example
was presented for deterministic calibration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3747</identifier>
 <datestamp>2009-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3747</id><created>2008-08-27</created><updated>2009-01-19</updated><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>De Pellegrini</keyname><forenames>Francesco</forenames></author></authors><title>Forward Correction and Fountain codes in Delay Tolerant Networks</title><categories>cs.NI cs.PF</categories><comments>10 pages - typos fixes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delay tolerant Ad-hoc Networks make use of mobility of relay nodes to
compensate for lack of permanent connectivity and thus enable communication
between nodes that are out of range of each other. To decrease delivery delay,
the information that needs to be delivered is replicated in the network. Our
objective in this paper is to study replication mechanisms that include coding
in order to improve the probability of successful delivery within a given time
limit. We propose an analytical approach that allows to quantify tradeoffs
between resources and performance measures (energy and delay). We study the
effect of coding on the performance of the network while optimizing parameters
that govern routing. Our results, based on fluid approximations, are compared
to simulations which validate the model
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3756</identifier>
 <datestamp>2009-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3756</id><created>2008-08-27</created><updated>2009-01-09</updated><authors><author><keyname>Wang</keyname><forenames>Zheng</forenames></author><author><keyname>Luo</keyname><forenames>Jie</forenames></author></authors><title>Approaching Blokh-Zyablov Error Exponent with Linear-Time
  Encodable/Decodable Codes</title><categories>cs.IT cs.CC math.IT</categories><comments>Submitted to IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Guruswami and Indyk showed in [1] that Forney's error exponent can be
achieved with linear coding complexity over binary symmetric channels. This
paper extends this conclusion to general discrete-time memoryless channels and
shows that Forney's and Blokh-Zyablov error exponents can be arbitrarily
approached by one-level and multi-level concatenated codes with linear
encoding/decoding complexity. The key result is a revision to Forney's general
minimum distance decoding algorithm, which enables a low complexity integration
of Guruswami-Indyk's outer codes into the concatenated coding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3881</identifier>
 <datestamp>2009-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3881</id><created>2008-08-28</created><updated>2009-07-15</updated><authors><author><keyname>Bonsma</keyname><forenames>Paul</forenames></author><author><keyname>Breuer</keyname><forenames>Felix</forenames></author></authors><title>Counting Hexagonal Patches and Independent Sets in Circle Graphs</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hexagonal patch is a plane graph in which inner faces have length 6, inner
vertices have degree 3, and boundary vertices have degree 2 or 3. We consider
the following counting problem: given a sequence of twos and threes, how many
hexagonal patches exist with this degree sequence along the outer face? This
problem is motivated by the study of benzenoid hydrocarbons and fullerenes in
computational chemistry. We give the first polynomial time algorithm for this
problem. We show that it can be reduced to counting maximum independent sets in
circle graphs, and give a simple and fast algorithm for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3884</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3884</id><created>2008-08-28</created><updated>2010-08-23</updated><authors><author><keyname>Beyersdorff</keyname><forenames>Olaf</forenames></author><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>Thomas</keyname><forenames>Michael</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>The Complexity of Reasoning for Fragments of Default Logic</title><categories>cs.CC cs.LO</categories><comments>Corrected version</comments><acm-class>F.2.2; F.4.1; I.2.3; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Default logic was introduced by Reiter in 1980. In 1992, Gottlob classified
the complexity of the extension existence problem for propositional default
logic as $\SigmaPtwo$-complete, and the complexity of the credulous and
skeptical reasoning problem as SigmaP2-complete, resp. PiP2-complete.
Additionally, he investigated restrictions on the default rules, i.e.,
semi-normal default rules. Selman made in 1992 a similar approach with
disjunction-free and unary default rules. In this paper we systematically
restrict the set of allowed propositional connectives. We give a complete
complexity classification for all sets of Boolean functions in the meaning of
Post's lattice for all three common decision problems for propositional default
logic. We show that the complexity is a hexachotomy (SigmaP2-, DeltaP2-, NP-,
P-, NL-complete, trivial) for the extension existence problem, while for the
credulous and skeptical reasoning problem we obtain similar classifications
without trivial cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3889</identifier>
 <datestamp>2008-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3889</id><created>2008-08-28</created><authors><author><keyname>Benitez</keyname><forenames>M. T. Carrasco</forenames></author></authors><title>Open architecture for multilingual parallel texts</title><categories>cs.CL</categories><comments>22 pages - for comments to the author and follow-ups go to
  http://dragoman.org/par</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Multilingual parallel texts (abbreviated to parallel texts) are linguistic
versions of the same content (&quot;translations&quot;); e.g., the Maastricht Treaty in
English and Spanish are parallel texts. This document is about creating an open
architecture for the whole Authoring, Translation and Publishing Chain
(ATP-chain) for the processing of parallel texts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3892</identifier>
 <datestamp>2008-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3892</id><created>2008-08-28</created><updated>2008-10-13</updated><authors><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author></authors><title>Essential arity gap of Boolean functions</title><categories>cs.DM</categories><comments>12 pages, J. of Computing, Serdika, IMI, BAS, Sofia</comments><acm-class>G.2.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We investigate the Boolean functions with essential arity gap 2. We use Full
Conjunctive Normal Forms instead of Zhegalkin's polynomials, which allow us to
simplify the proofs and to obtain several combinatorial results, concerning the
Boolean functions with a given arity gap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3928</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3928</id><created>2008-08-28</created><updated>2008-09-25</updated><authors><author><keyname>Werner</keyname><forenames>Benjamin</forenames></author></authors><title>On the strength of proof-irrelevant type theories</title><categories>cs.LO</categories><comments>20 pages, Logical Methods in Computer Science, Long version of IJCAR
  2006 paper</comments><acm-class>F.4.1; F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (September
  26, 2008) lmcs:1142</journal-ref><doi>10.2168/LMCS-4(3:13)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a type theory with some proof-irrelevance built into the
conversion rule. We argue that this feature is useful when type theory is used
as the logical formalism underlying a theorem prover. We also show a close
relation with the subset types of the theory of PVS. We show that in these
theories, because of the additional extentionality, the axiom of choice implies
the decidability of equality, that is, almost classical logic. Finally we
describe a simple set-theoretic semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3937</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3937</id><created>2008-08-28</created><authors><author><keyname>Bredel</keyname><forenames>Michael</forenames></author><author><keyname>Fidler</keyname><forenames>Markus</forenames></author></authors><title>Understanding Fairness and its Impact on Quality of Service in IEEE
  802.11</title><categories>cs.NI cs.PF</categories><journal-ref>IEEE INFOCOM 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Distributed Coordination Function (DCF) aims at fair and efficient medium
access in IEEE 802.11. In face of its success, it is remarkable that there is
little consensus on the actual degree of fairness achieved, particularly
bearing its impact on quality of service in mind. In this paper we provide an
accurate model for the fairness of the DCF. Given M greedy stations we assume
fairness if a tagged station contributes a share of 1/M to the overall number
of packets transmitted. We derive the probability distribution of fairness
deviations and support our analytical results by an extensive set of
measurements. We find a closed-form expression for the improvement of long-term
over short-term fairness. Regarding the random countdown values we quantify the
significance of their distribution whereas we discover that fairness is largely
insensitive to the distribution parameters. Based on our findings we view the
DCF as emulating an ideal fair queuing system to quantify the deviations from a
fair rate allocation. We deduce a stochastic service curve model for the DCF to
predict packet delays in IEEE 802.11. We show how a station can estimate its
fair bandwidth share from passive measurements of its traffic arrivals and
departures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3959</identifier>
 <datestamp>2008-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3959</id><created>2008-08-28</created><authors><author><keyname>Erez</keyname><forenames>Uri</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author></authors><title>A Simple Extension of the $\modulo$-$\Lambda$ Transformation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple lemma is derived that allows to transform a general scalar
(non-Gaussian, non-additive) continuous-alphabet channel as well as a general
multiple-access channel into a modulo-additive noise channel. While in general
the transformation is information lossy, it allows to leverage linear coding
techniques and capacity results derived for networks comprised of additive
Gaussian nodes to more general networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3971</identifier>
 <datestamp>2008-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3971</id><created>2008-08-28</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Runhua</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Ghosh</keyname><forenames>Arunabha</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Networked MIMO with Clustered Linear Precoding</title><categories>cs.IT math.IT</categories><comments>27 pages, submitted to IEEE Transaction on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A clustered base transceiver station (BTS) coordination strategy is proposed
for a large cellular MIMO network, which includes full intra-cluster
coordination to enhance the sum rate and limited inter-cluster coordination to
reduce interference for the cluster edge users. Multi-cell block
diagonalization is used to coordinate the transmissions across multiple BTSs in
the same cluster. To satisfy per-BTS power constraints, three combined precoder
and power allocation algorithms are proposed with different performance and
complexity tradeoffs. For inter-cluster coordination, the coordination area is
chosen to balance fairness for edge users and the achievable sum rate. It is
shown that a small cluster size (about 7 cells) is sufficient to obtain most of
the sum rate benefits from clustered coordination while greatly relieving
channel feedback requirement. Simulations show that the proposed coordination
strategy efficiently reduces interference and provides a considerable sum rate
gain for cellular MIMO networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3990</identifier>
 <datestamp>2008-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3990</id><created>2008-08-28</created><updated>2008-09-17</updated><authors><author><keyname>S&#xfc;zen</keyname><forenames>Mehmet</forenames></author><author><keyname>S&#xfc;zen</keyname><forenames>Ziya</forenames></author></authors><title>Adaptive Dynamic Congestion Avoidance with Master Equation</title><categories>cs.NI</categories><comments>7 pages, 2 figure, technical report</comments><acm-class>C.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an adaptive variant of Random Early Detection (RED)
gateway queue management for packet-switched networks via a discrete state
analog of the non-stationary Master Equation i.e. Markov process. The
computation of average queue size, which appeared in the original RED
algorithm, is altered by introducing a probability $P(l,t)$, which defines the
probability of having $l$ number of packets in the queue at the given time $t$,
and depends upon the previous state of the queue. This brings the advantage of
eliminating a free parameter: queue weight, completely. Computation of
transition rates and probabilities are carried out on the fly, and determined
by the algorithm automatically. Simulations with unstructured packets
illustrate the method, the performance of the adaptive variant of RED
algorithm, and the comparison with the standard RED.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4050</identifier>
 <datestamp>2011-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4050</id><created>2008-08-29</created><updated>2009-05-20</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author></authors><title>Optimizing the double description method for normal surface enumeration</title><categories>math.GT cs.CG math.CO</categories><comments>27 pages, 12 figures; v2: Removed the 3^n bound from Section 3.3,
  fixed the projective equation in Lemma 4.4, clarified &quot;most triangulations&quot;
  in the introduction to section 5; v3: replace -ise with -ize for Mathematics
  of Computation (note that this changes the title of the paper)</comments><msc-class>52B55 (Primary) 57N10, 57N35 (Secondary)</msc-class><journal-ref>Mathematics of Computation 79 (2010), no. 269, 453-484</journal-ref><doi>10.1090/S0025-5718-09-02282-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many key algorithms in 3-manifold topology involve the enumeration of normal
surfaces, which is based upon the double description method for finding the
vertices of a convex polytope. Typically we are only interested in a small
subset of these vertices, thus opening the way for substantial optimization.
Here we give an account of the vertex enumeration problem as it applies to
normal surfaces, and present new optimizations that yield strong improvements
in both running time and memory consumption. The resulting algorithms are
tested using the freely available software package Regina.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4060</identifier>
 <datestamp>2008-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4060</id><created>2008-08-29</created><authors><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author><author><keyname>Margasinski</keyname><forenames>Igor</forenames></author><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Cabaj</keyname><forenames>Krzysztof</forenames></author><author><keyname>Radziszewski</keyname><forenames>Pawel</forenames></author></authors><title>TrustMAS: Trusted Communication Platform for Multi-Agent Systems</title><categories>cs.CR cs.MA</categories><comments>18 pages, 7 figures, accepted to The 3rd International Symposium on
  Information Security (IS'08), Monterrey, Mexico, November 10-11, 2008
  (Proceedings will be published by Springer LNCS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents TrustMAS - Trusted Communication Platform for Multi-Agent
Systems, which provides trust and anonymity for mobile agents. The platform
includes anonymous technique based on random-walk algorithm for providing
general purpose anonymous communication for agents. All agents, which take part
in the proposed platform, benefit from trust and anonymity that is provided for
their interactions. Moreover, in TrustMAS there are StegAgents (SA) that are
able to perform various steganographic communication. To achieve that goal, SAs
may use methods in different layers of TCP/IP model or specialized middleware
enabling steganography that allows hidden communication through all layers of
mentioned model. In TrustMAS steganographic channels are used to exchange
routing tables between StegAgents. Thus all StegAgents in TrustMAS with their
ability to exchange information by using hidden channels form distributed
steganographic router (Stegrouter).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4079</identifier>
 <datestamp>2008-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4079</id><created>2008-08-29</created><updated>2008-10-14</updated><authors><author><keyname>Azad</keyname><forenames>Amar Prakash</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>El-Azouzi</keyname><forenames>R.</forenames></author></authors><title>From Altruism to Non-Cooperation in Routing Games</title><categories>cs.GT cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the routing in the network shared by several users. Each
user seeks to optimize either its own performance or some combination between
its own performance and that of other users, by controlling the routing of its
given flow demand. We parameterize the degree of cooperation which allows to
cover the fully non-cooperative behavior, the fully cooperative behavior, and
even more, the fully altruistic behavior, all these as special cases of the
parameter's choice. A large part of the work consists in exploring the impact
of the degree of cooperation on the equilibrium. Our first finding is to
identify multiple Nash equilibria with cooperative behavior that do not occur
in the non-cooperative case under the same conditions (cost, demand and
topology). We then identify Braess like paradox (in which adding capacity or
adding a link to a network results in worse performance to all users) and study
the impact of the degree of cooperation on it. We identify another type of
paradox in cooperation scenario. We identify that when we increase the degree
of cooperation of a user while other users keep unchanged their degree of
cooperation, leads to an improvement in performance of that user. We then
pursue the exploration and carry it on to the setting of Mixed equilibrium
(i.e. some users are non atomic-they have infinitesimally small demand, and
other have finite fixed demand). We finally obtain some theoretical results
that show that for low degree of cooperation the equilibrium is unique,
confirming the results of our numerical study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4100</identifier>
 <datestamp>2008-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4100</id><created>2008-08-29</created><authors><author><keyname>Lavall&#xe9;e</keyname><forenames>Sylvain</forenames></author><author><keyname>Reutenauer</keyname><forenames>Christophe</forenames></author><author><keyname>Retakh</keyname><forenames>Vladimir</forenames></author><author><keyname>Perrin</keyname><forenames>Dominique</forenames></author></authors><title>Codes and Noncommutative Stochastic Matrices</title><categories>math.RA cs.IT math.IT</categories><comments>24 pages, Latex</comments><msc-class>16K40, 15A51, 94A45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a matrix over a skew field fixing the column (1,...,1)^t, we give
formulas for a row vector fixed by this matrix. The same techniques are applied
to give noncommutative extensions of probabilistic properties of codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4104</identifier>
 <datestamp>2008-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4104</id><created>2008-08-29</created><authors><author><keyname>Schatzmann</keyname><forenames>Dominik</forenames></author><author><keyname>Burkhart</keyname><forenames>Martin</forenames></author><author><keyname>Spyropoulos</keyname><forenames>Thrasyvoulos</forenames></author></authors><title>Flow-level Characteristics of Spam and Ham</title><categories>cs.NI</categories><report-no>TIK-Report No. 291</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite a large amount of effort devoted in the past years trying to limit
unsolicited mail, spam is still a major global concern. Content-analysis
techniques and blacklists, the most popular methods used to identify and block
spam, are beginning to lose their edge in the battle. We argue here that one
not only needs to look into the network-related characteristics of spam
traffic, as has been recently suggested, but also to look deeper into the
network core, in order to counter the increasing sophistication of spam-ing
methods. Yet, at the same time, local knowledge available at a given server can
often be irreplaceable in identifying specific spammers. To this end, in this
paper we show how the local intelligence of mail servers can be gathered and
correlated pas- sively at the ISP-level providing valuable network-wide
information. Specifically, we use first a large network flow trace from a
medium size, national ISP, to demonstrate that the pre-filtering decisions of
individual mail servers can be tracked and combined at the flow level. Then, we
argue that such aggregated knowledge not only can allow ISPs to develop and
evaluate powerful new methods for fighting spam, but also to monitor remotely
what their own servers are doing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4111</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4111</id><created>2008-08-29</created><updated>2010-04-03</updated><authors><author><keyname>Bavaud</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Relative Entropy and Statistics</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>31 pages. 2 figures.</comments><journal-ref>Bavaud F. (2009) Information Theory, Relative Entropy and
  Statistics. In: Sommaruga G. (editor): Formal Theories of Information.
  Lecture Notes in Computer Science 5363, Springer, pp. 54-78</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formalising the confrontation of opinions (models) to observations (data) is
the task of Inferential Statistics. Information Theory provides us with a basic
functional, the relative entropy (or Kullback-Leibler divergence), an
asymmetrical measure of dissimilarity between the empirical and the theoretical
distributions. The formal properties of the relative entropy turn out to be
able to capture every aspect of Inferential Statistics, as illustrated here,
for simplicity, on dices (= i.i.d. process with finitely many outcomes):
refutability (strict or probabilistic): the asymmetry data / models; small
deviations: rejecting a single hypothesis; competition between hypotheses and
model selection; maximum likelihood: model inference and its limits; maximum
entropy: reconstructing partially observed data; EM-algorithm; flow data and
gravity modelling; determining the order of a Markov chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4122</identifier>
 <datestamp>2009-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4122</id><created>2008-08-29</created><updated>2009-03-05</updated><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>Swapping Lemmas for Regular and Context-Free Languages</title><categories>cs.CC cs.CL cs.FL</categories><comments>Version 2: minor chages associated with typos; slight changes of
  title, abstract, and introduction (letter size, 13 pages, 4 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In formal language theory, one of the most fundamental tools, known as
pumping lemmas, is extremely useful for regular and context-free languages.
However, there are natural properties for which the pumping lemmas are of
little use. One of such examples concerns a notion of advice, which depends
only on the size of an underlying input. A standard pumping lemma encounters
difficulty in proving that a given language is not regular in the presence of
advice. We develop its substitution, called a swapping lemma for regular
languages, to demonstrate the non-regularity of a target language with advice.
For context-free languages, we also present a similar form of swapping lemma,
which serves as a technical tool to show that certain languages are not
context-free with advice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4133</identifier>
 <datestamp>2008-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4133</id><created>2008-08-29</created><authors><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author><author><keyname>Shkatov</keyname><forenames>Dmitry</forenames></author></authors><title>Tableau-based decision procedure for the multi-agent epistemic logic
  with operators of common and distributed knowledge</title><categories>cs.LO cs.MA</categories><comments>To appear in the Proceedings of the 6th IEEE Conference on Software
  Engineering and Formal Methods (SEFM 2008)</comments><acm-class>F.4.1; I.2.4; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an incremental-tableau-based decision procedure for the
multi-agent epistemic logic MAEL(CD) (aka S5_n (CD)), whose language contains
operators of individual knowledge for a finite set Ag of agents, as well as
operators of distributed and common knowledge among all agents in Ag. Our
tableau procedure works in (deterministic) exponential time, thus establishing
an upper bound for MAEL(CD)-satisfiability that matches the (implicit)
lower-bound known from earlier results, which implies ExpTime-completeness of
MAEL(CD)-satisfiability. Therefore, our procedure provides a complexity-optimal
algorithm for checking MAEL(CD)-satisfiability, which, however, in most cases
is much more efficient. We prove soundness and completeness of the procedure,
and illustrate it with an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4134</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4134</id><created>2008-08-29</created><updated>2010-07-20</updated><authors><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Spectral Sparsification of Graphs</title><categories>cs.DS cs.DM</categories><comments>This revision addresses comments of the referees. In particular, we
  have completely re-written the proof of the main graph partitioning theorem
  in section 8</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new notion of graph sparsificaiton based on spectral
similarity of graph Laplacians: spectral sparsification requires that the
Laplacian quadratic form of the sparsifier approximate that of the original.
This is equivalent to saying that the Laplacian of the sparsifier is a good
preconditioner for the Laplacian of the original. We prove that every graph has
a spectral sparsifier of nearly linear size. Moreover, we present an algorithm
that produces spectral sparsifiers in time $\softO{m}$, where $m$ is the number
of edges in the original graph. This construction is a key component of a
nearly-linear time algorithm for solving linear equations in
diagonally-dominant matrcies. Our sparsification algorithm makes use of a
nearly-linear time algorithm for graph partitioning that satisfies a strong
guarantee: if the partition it outputs is very unbalanced, then the larger part
is contained in a subgraph of high conductance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4135</identifier>
 <datestamp>2008-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4135</id><created>2008-08-29</created><updated>2008-08-31</updated><authors><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Achieving the Empirical Capacity Using Feedback Part I: Memoryless
  Additive Models</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of universal communications over an unknown channel
with an instantaneous noiseless feedback, and show how rates corresponding to
the empirical behavior of the channel can be attained, although no rate can be
guaranteed in advance. First, we consider a discrete modulo-additive channel
with alphabet $\mathcal{X}$, where the noise sequence $Z^n$ is arbitrary and
unknown and may causally depend on the transmitted and received sequences and
on the encoder's message, possibly in an adversarial fashion. Although the
classical capacity of this channel is zero, we show that rates approaching the
empirical capacity $\log|\mathcal{X}|-H_{emp}(Z^n)$ can be universally
attained, where $H_{emp}(Z^n)$ is the empirical entropy of $Z^n$. For the more
general setting where the channel can map its input to an output in an
arbitrary unknown fashion subject only to causality, we model the empirical
channel actions as the modulo-addition of a realized noise sequence, and show
that the same result applies if common randomness is available. The results are
proved constructively, by providing a simple sequential transmission scheme
approaching the empirical capacity. In part II of this work we demonstrate how
even higher rates can be attained by using more elaborate models for channel
actions, and by utilizing possible empirical dependencies in its behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4146</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4146</id><created>2008-08-29</created><updated>2010-03-17</updated><authors><author><keyname>Ganti</keyname><forenames>RadhaKrishna</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Dynamic Connectivity in ALOHA Ad Hoc Networks</title><categories>cs.IT cs.NI math.IT math.PR</categories><comments>Submitted to IEEE Transactions on Information Theory.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a wireless network the set of transmitting nodes changes frequently
because of the MAC scheduler and the traffic load. Previously, connectivity in
wireless networks was analyzed using static geometric graphs, and as we show
leads to an overly constrained design criterion. The dynamic nature of the
transmitting set introduces additional randomness in a wireless system that
improves the connectivity, and this additional randomness is not captured by a
static connectivity graph. In this paper, we consider an ad hoc network with
half-duplex radios that uses multihop routing and slotted ALOHA for the MAC
contention and introduce a random dynamic multi-digraph to model its
connectivity. We first provide analytical results about the degree distribution
of the graph. Next, defining the path formation time as the minimum time
required for a causal path to form between the source and destination on the
dynamic graph, we derive the distributional properties of the connection delay
using techniques from first-passage percolation and epidemic processes. We
consider the giant component of the network formed when communication is
noise-limited (by neglecting interference). Then, in the presence of
interference, we prove that the delay scales linearly with the
source-destination distance on this giant component. We also provide simulation
results to support the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4156</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4156</id><created>2008-08-29</created><updated>2010-05-07</updated><authors><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Rate-Distortion via Markov Chain Monte Carlo</title><categories>cs.IT math.IT</categories><comments>35 pages, 16 figures, Submitted to IEEE Transactions on Information
  Theory</comments><msc-class>68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an approach to lossy source coding, utilizing ideas from Gibbs
sampling, simulated annealing, and Markov Chain Monte Carlo (MCMC). The idea is
to sample a reconstruction sequence from a Boltzmann distribution associated
with an energy function that incorporates the distortion between the source and
reconstruction, the compressibility of the reconstruction, and the point sought
on the rate-distortion curve. To sample from this distribution, we use a `heat
bath algorithm': Starting from an initial candidate reconstruction (say the
original source sequence), at every iteration, an index i is chosen and the
i-th sequence component is replaced by drawing from the conditional probability
distribution for that component given all the rest. At the end of this process,
the encoder conveys the reconstruction to the decoder using universal lossless
compression. The complexity of each iteration is independent of the sequence
length and only linearly dependent on a certain context parameter (which grows
sub-logarithmically with the sequence length). We show that the proposed
algorithms achieve optimum rate-distortion performance in the limits of large
number of iterations, and sequence length, when employed on any stationary
ergodic source. Experimentation shows promising initial results. Employing our
lossy compressors on noisy data, with appropriately chosen distortion measure
and level, followed by a simple de-randomization operation, results in a family
of denoisers that compares favorably (both theoretically and in practice) with
other MCMC-based schemes, and with the Discrete Universal Denoiser (DUDE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4160</identifier>
 <datestamp>2008-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4160</id><created>2008-08-29</created><authors><author><keyname>Tseng</keyname><forenames>Chih-Yuan</forenames></author><author><keyname>Caticha</keyname><forenames>Ariel</forenames></author></authors><title>Using Relative Entropy to Find Optimal Approximations: an Application to
  Simple Fluids</title><categories>cond-mat.stat-mech cs.IT math.IT math.PR physics.data-an</categories><comments>5 figures, accepted for publication in Physica A, 2008</comments><journal-ref>Physica A387, 6759 (2008)</journal-ref><doi>10.1016/j.physa.2008.08.035</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a maximum relative entropy formalism to generate optimal
approximations to probability distributions. The central results consist in (a)
justifying the use of relative entropy as the uniquely natural criterion to
select a preferred approximation from within a family of trial parameterized
distributions, and (b) to obtain the optimal approximation by marginalizing
over parameters using the method of maximum entropy and information geometry.
As an illustration we apply our method to simple fluids. The &quot;exact&quot; canonical
distribution is approximated by that of a fluid of hard spheres. The proposed
method first determines the preferred value of the hard-sphere diameter, and
then obtains an optimal hard-sphere approximation by a suitably weighed average
over different hard-sphere diameters. This leads to a considerable improvement
in accounting for the soft-core nature of the interatomic potential. As a
numerical demonstration, the radial distribution function and the equation of
state for a Lennard-Jones fluid (argon) are compared with results from
molecular dynamics simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0009</identifier>
 <datestamp>2012-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0009</id><created>2008-08-29</created><updated>2012-05-18</updated><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author><author><keyname>Ramanan</keyname><forenames>Kavita</forenames></author></authors><title>Distributed Parameter Estimation in Sensor Networks: Nonlinear
  Observation Models and Imperfect Communication</title><categories>cs.MA cs.IT math.IT</categories><comments>IEEE Transactions On Information Theory, Vol. 58, No. 6, June 2012</comments><doi>10.1109/TIT.2012.219450</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies distributed static parameter (vector) estimation in sensor
networks with nonlinear observation models and noisy inter-sensor
communication. It introduces \emph{separably estimable} observation models that
generalize the observability condition in linear centralized estimation to
nonlinear distributed estimation. It studies two distributed estimation
algorithms in separably estimable models, the $\mathcal{NU}$ (with its linear
counterpart $\mathcal{LU}$) and the $\mathcal{NLU}$. Their update rule combines
a \emph{consensus} step (where each sensor updates the state by weight
averaging it with its neighbors' states) and an \emph{innovation} step (where
each sensor processes its local current observation.) This makes the three
algorithms of the \textit{consensus + innovations} type, very different from
traditional consensus. The paper proves consistency (all sensors reach
consensus almost surely and converge to the true parameter value,) efficiency,
and asymptotic unbiasedness. For $\mathcal{LU}$ and $\mathcal{NU}$, it proves
asymptotic normality and provides convergence rate guarantees. The three
algorithms are characterized by appropriately chosen decaying weight sequences.
Algorithms $\mathcal{LU}$ and $\mathcal{NU}$ are analyzed in the framework of
stochastic approximation theory; algorithm $\mathcal{NLU}$ exhibits mixed
time-scale behavior and biased perturbations, and its analysis requires a
different approach that is developed in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0016</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0016</id><created>2008-08-29</created><updated>2010-03-30</updated><authors><author><keyname>Weber</keyname><forenames>Steven</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>An overview of the transmission capacity of wireless networks</title><categories>cs.IT math.IT</categories><comments>Submitted August 13, 2009 to IEEE Transactions on Communications.
  Revisions submitted December 14, 2009 and February 26, 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper surveys and unifies a number of recent contributions that have
collectively developed a metric for decentralized wireless network analysis
known as transmission capacity. Although it is notoriously difficult to derive
general end-to-end capacity results for multi-terminal or \adhoc networks, the
transmission capacity (TC) framework allows for quantification of achievable
single-hop rates by focusing on a simplified physical/MAC-layer model. By using
stochastic geometry to quantify the multi-user interference in the network, the
relationship between the optimal spatial density and success probability of
transmissions in the network can be determined, and expressed -- often fairly
simply -- in terms of the key network parameters. The basic model and
analytical tools are first discussed and applied to a simple network with path
loss only and we present tight upper and lower bounds on transmission capacity
(via lower and upper bounds on outage probability). We then introduce random
channels (fading/shadowing) and give TC and outage approximations for an
arbitrary channel distribution, as well as exact results for the special cases
of Rayleigh and Nakagami fading. We then apply these results to show how TC can
be used to better understand scheduling, power control, and the deployment of
multiple antennas in a decentralized network. The paper closes by discussing
shortcomings in the model as well as future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0024</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0024</id><created>2008-08-29</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Pass</keyname><forenames>Rafael</forenames></author></authors><title>Game Theory with Costly Computation</title><categories>cs.GT cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a general game-theoretic framework for reasoning about strategic
agents performing possibly costly computation. In this framework, many
traditional game-theoretic results (such as the existence of a Nash
equilibrium) no longer hold. Nevertheless, we can use the framework to provide
psychologically appealing explanations to observed behavior in well-studied
games (such as finitely repeated prisoner's dilemma and rock-paper-scissors).
Furthermore, we provide natural conditions on games sufficient to guarantee
that equilibria exist. As an application of this framework, we consider a
notion of game-theoretic implementation of mediators in computational games. We
show that a special case of this notion is equivalent to a variant of the
traditional cryptographic definition of protocol security; this result shows
that, when taking computation into account, the two approaches used for dealing
with &quot;deviating&quot; players in two different communities -- Nash equilibrium in
game theory and zero-knowledge &quot;simulation&quot; in cryptography -- are intimately
related.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0032</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0032</id><created>2008-08-29</created><authors><author><keyname>Lin</keyname><forenames>D. D.</forenames></author><author><keyname>Lim</keyname><forenames>T. J.</forenames></author></authors><title>A Variational Inference Framework for Soft-In-Soft-Out Detection in
  Multiple Access Channels</title><categories>cs.IT cs.LG math.IT</categories><comments>Submitted to Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a unified framework for deriving and studying soft-in-soft-out
(SISO) detection in interference channels using the concept of variational
inference. The proposed framework may be used in multiple-access interference
(MAI), inter-symbol interference (ISI), and multiple-input multiple-outpu
(MIMO) channels. Without loss of generality, we will focus our attention on
turbo multiuser detection, to facilitate a more concrete discussion. It is
shown that, with some loss of optimality, variational inference avoids the
exponential complexity of a posteriori probability (APP) detection by
optimizing a closely-related, but much more manageable, objective function
called variational free energy. In addition to its systematic appeal, there are
several other advantages to this viewpoint. First of all, it provides unified
and rigorous justifications for numerous detectors that were proposed on
radically different grounds, and facilitates convenient joint detection and
decoding (utilizing the turbo principle) when error-control codes are
incorporated. Secondly, efficient joint parameter estimation and data detection
is possible via the variational expectation maximization (EM) algorithm, such
that the detrimental effect of inaccurate channel knowledge at the receiver may
be dealt with systematically. We are also able to extend BPSK-based SISO
detection schemes to arbitrary square QAM constellations in a rigorous manner
using a variational argument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0060</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0060</id><created>2008-08-30</created><updated>2008-09-25</updated><authors><author><keyname>Jurdzinski</keyname><forenames>Marcin</forenames></author><author><keyname>Laroussinie</keyname><forenames>Francois</forenames></author><author><keyname>Sproston</keyname><forenames>Jeremy</forenames></author></authors><title>Model Checking Probabilistic Timed Automata with One or Two Clocks</title><categories>cs.LO</categories><acm-class>D.2.4; F.4.1; G.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (September
  26, 2008) lmcs:988</journal-ref><doi>10.2168/LMCS-4(3:11)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic timed automata are an extension of timed automata with discrete
probability distributions. We consider model-checking algorithms for the
subclasses of probabilistic timed automata which have one or two clocks.
Firstly, we show that PCTL probabilistic model-checking problems (such as
determining whether a set of target states can be reached with probability at
least 0.99 regardless of how nondeterminism is resolved) are PTIME-complete for
one-clock probabilistic timed automata, and are EXPTIME-complete for
probabilistic timed automata with two clocks. Secondly, we show that, for
one-clock probabilistic timed automata, the model-checking problem for the
probabilistic timed temporal logic PCTL is EXPTIME-complete. However, the
model-checking problem for the subclass of PCTL which does not permit both
punctual timing bounds, which require the occurrence of an event at an exact
time point, and comparisons with probability bounds other than 0 or 1, is
PTIME-complete for one-clock probabilistic timed automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0062</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0062</id><created>2008-08-30</created><authors><author><keyname>Ahmad</keyname><forenames>Sk. Safique</forenames></author><author><keyname>Rajan</keyname><forenames>Nagalinga</forenames></author><author><keyname>Raha</keyname><forenames>Soumyendu</forenames></author></authors><title>The Stochastic Logarithmic Norm for Stability Analysis of Stochastic
  Differential Equations</title><categories>cs.NA</categories><comments>19 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  To analyze the stability of It\^o stochastic differential equations with
multiplicative noise, we introduce the stochastic logarithmic norm. The
logarithmic norm was originally introduced by G. Dahlquist in 1958 as a tool to
study the growth of solutions to ordinary differential equations and for
estimating the error growth in discretization methods for their approximate
solutions. We extend the concept to the stability analysis of It\^o stochastic
differential equations with multiplicative noise. Stability estimates for
linear It\^o SDEs using the one, two and $\infty$-norms in the $l$-th mean,
where $1 \leq l &lt; \infty $, are derived and the application of the stochastic
logarithmic norm is illustrated with examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0063</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0063</id><created>2008-08-30</created><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Fousse</keyname><forenames>Laurent</forenames><affiliation>LJK</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Simultaneous Modular Reduction and Kronecker Substitution for Small
  Finite Fields</title><categories>cs.SC math.NT</categories><proxy>ccsd hal-00315772</proxy><doi>10.1016/j.jsc.2010.08.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms to perform modular polynomial multiplication or modular
dot product efficiently in a single machine word. We pack polynomials into
integers and perform several modular operations with machine integer or
floating point arithmetic. The modular polynomials are converted into integers
using Kronecker substitution (evaluation at a sufficiently large integer). With
some control on the sizes and degrees, arithmetic operations on the polynomials
can be performed directly with machine integers or floating point numbers and
the number of conversions can be reduced. We also present efficient ways to
recover the modular values of the coefficients. This leads to practical gains
of quite large constant factors for polynomial multiplication, prime field
linear algebra and small extension field arithmetic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0070</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0070</id><created>2008-08-30</created><authors><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author><author><keyname>Stojanovic</keyname><forenames>Milica</forenames></author></authors><title>Underwater Acoustic Networks: Channel Models and Network Coding based
  Lower Bound to Transmission Power for Multicast</title><categories>cs.IT math.IT</categories><comments>12 pages, 10 figures, 2 Tables, Accepted to Journal on Selected Areas
  in Communications (Underwater Communications and Wireless Networks)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is two-fold. First, to establish a tractable model for
the underwater acoustic channel useful for network optimization in terms of
convexity. Second, to propose a network coding based lower bound for
transmission power in underwater acoustic networks, and compare this bound to
the performance of several network layer schemes. The underwater acoustic
channel is characterized by a path loss that depends strongly on transmission
distance and signal frequency. The exact relationship among power, transmission
band, distance and capacity for the Gaussian noise scenario is a complicated
one. We provide a closed-form approximate model for 1) transmission power and
2) optimal frequency band to use, as functions of distance and capacity. The
model is obtained through numerical evaluation of analytical results that take
into account physical models of acoustic propagation loss and ambient noise.
Network coding is applied to determine a lower bound to transmission power for
a multicast scenario, for a variety of multicast data rates and transmission
distances of interest for practical systems, exploiting physical properties of
the underwater acoustic channel. The results quantify the performance gap in
transmission power between a variety of routing and network coding schemes and
the network coding based lower bound. We illustrate results numerically for
different network scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0073</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0073</id><created>2008-08-30</created><updated>2010-07-22</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Languages recognized with unbounded error by quantum finite automata</title><categories>quant-ph cs.CC</categories><comments>This paper has been superseded by arXiv:1007.3624</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been superseded by arXiv:1007.3624
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0091</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0091</id><created>2008-08-30</created><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Nogin</keyname><forenames>Dmitry</forenames></author></authors><title>A functional view of upper bounds on codes</title><categories>cs.IT math.IT</categories><comments>10 pages</comments><journal-ref>&quot; Coding and Cryptography,&quot; Proceedings of the First International
  Workshop, Wuyi Mountain, Fujian, China, 11 - 15 June 2007, edited by Yongqing
  Li et al., World Scientific, 2008, pp. 15--24</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional and linear-algebraic approaches to the Delsarte problem of upper
bounds on codes are discussed. We show that Christoffel-Darboux kernels and
Levenshtein polynomials related to them arise as stationary points of the
moment functionals of some distributions. We also show that they can be derived
as eigenfunctions of the Jacobi operator. This motivates the choice of
polynomials used to derive linear programming upper bounds on codes in
homogeneous spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0099</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0099</id><created>2008-08-31</created><authors><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Degrees of Freedom of the $K$ User $M \times N$ MIMO Interference
  Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide innerbound and outerbound for the total number of degrees of
freedom of the $K$ user multiple input multiple output (MIMO) Gaussian
interference channel with $M$ antennas at each transmitter and $N$ antennas at
each receiver if the channel coefficients are time-varying and drawn from a
continuous distribution. The bounds are tight when the ratio
$\frac{\max(M,N)}{\min(M,N)}=R$ is equal to an integer. For this case, we show
that the total number of degrees of freedom is equal to $\min(M,N)K$ if $K \leq
R$ and $\min(M,N)\frac{R}{R+1}K$ if $K &gt; R$. Achievability is based on
interference alignment. We also provide examples where using interference
alignment combined with zero forcing can achieve more degrees of freedom than
merely zero forcing for some MIMO interference channels with constant channel
coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0103</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0103</id><created>2008-08-31</created><authors><author><keyname>Manin</keyname><forenames>Dmitrii Y.</forenames></author></authors><title>On the nature of long-range letter correlations in texts</title><categories>cs.CL cs.IT math.IT</categories><comments>14 pages, 5 figures, unpublished</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The origin of long-range letter correlations in natural texts is studied
using random walk analysis and Jensen?Shannon divergence. It is concluded that
they result from slow variations in letter frequency distribution, which are a
consequence of slow variations in lexical composition within the text. These
correlations are preserved by random letter shuffling within a moving window.
As such, they do reflect structural properties of the text, but in a very
indirect manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0116</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0116</id><created>2008-08-31</created><authors><author><keyname>Martin</keyname><forenames>David J.</forenames></author><author><keyname>Gehrke</keyname><forenames>Johannes</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Toward Expressive and Scalable Sponsored Search Auctions</title><categories>cs.DB</categories><comments>10 pages, 13 figures, ICDE 2008</comments><acm-class>K.4.4</acm-class><journal-ref>David J. Martin, Johannes Gehrke, and Joseph Y. Halpern. Toward
  Expressive and Scalable Sponsored Search Auctions. In Proceedings of the 24th
  IEEE International Conference on Data Engineering, pages 237--246. April 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet search results are a growing and highly profitable advertising
platform. Search providers auction advertising slots to advertisers on their
search result pages. Due to the high volume of searches and the users' low
tolerance for search result latency, it is imperative to resolve these auctions
fast. Current approaches restrict the expressiveness of bids in order to
achieve fast winner determination, which is the problem of allocating slots to
advertisers so as to maximize the expected revenue given the advertisers' bids.
The goal of our work is to permit more expressive bidding, thus allowing
advertisers to achieve complex advertising goals, while still providing fast
and scalable techniques for winner determination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0124</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0124</id><created>2008-08-31</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames><affiliation>National Research Council of Canada</affiliation></author></authors><title>A Uniform Approach to Analogies, Synonyms, Antonyms, and Associations</title><categories>cs.CL cs.IR cs.LG</categories><comments>related work available at http://purl.org/peter.turney/</comments><report-no>NRC 50398</report-no><acm-class>H.3.1; I.2.6; I.2.7</acm-class><journal-ref>Proceedings of the 22nd International Conference on Computational
  Linguistics (Coling 2008), August 2008, Manchester, UK, Pages 905-912</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recognizing analogies, synonyms, antonyms, and associations appear to be four
distinct tasks, requiring distinct NLP algorithms. In the past, the four tasks
have been treated independently, using a wide variety of algorithms. These four
semantic classes, however, are a tiny sample of the full range of semantic
phenomena, and we cannot afford to create ad hoc algorithms for each semantic
phenomenon; we need to seek a unified approach. We propose to subsume a broad
range of phenomena under analogies. To limit the scope of this paper, we
restrict our attention to the subsumption of synonyms, antonyms, and
associations. We introduce a supervised corpus-based machine learning algorithm
for classifying analogous word pairs, and we show that it can solve
multiple-choice SAT analogy questions, TOEFL synonym questions, ESL
synonym-antonym questions, and similar-associated-both questions from cognitive
psychology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0158</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0158</id><created>2008-08-31</created><authors><author><keyname>Ni</keyname><forenames>Jian</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author></authors><title>Network Tomography Based on Additive Metrics</title><categories>cs.NI cs.IT math.IT</categories><comments>35 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference of the network structure (e.g., routing topology) and dynamics
(e.g., link performance) is an essential component in many network design and
management tasks. In this paper we propose a new, general framework for
analyzing and designing routing topology and link performance inference
algorithms using ideas and tools from phylogenetic inference in evolutionary
biology. The framework is applicable to a variety of measurement techniques.
Based on the framework we introduce and develop several polynomial-time
distance-based inference algorithms with provable performance. We provide
sufficient conditions for the correctness of the algorithms. We show that the
algorithms are consistent (return correct topology and link performance with an
increasing sample size) and robust (can tolerate a certain level of measurement
errors). In addition, we establish certain optimality properties of the
algorithms (i.e., they achieve the optimal $l_\infty$-radius) and demonstrate
their effectiveness via model simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0159</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0159</id><created>2008-09-01</created><authors><author><keyname>Elbassioni</keyname><forenames>K.</forenames></author><author><keyname>Matijevic</keyname><forenames>D.</forenames></author><author><keyname>Mestre</keyname><forenames>J.</forenames></author><author><keyname>Severdija</keyname><forenames>D.</forenames></author></authors><title>Improved Approximations for Guarding 1.5-Dimensional Terrains</title><categories>cs.CG</categories><comments>10 pages, 1 Postscript figure, uses geometry.sty</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a 4-approximation algorithm for the problem of placing a fewest
guards on a 1.5D terrain so that every point of the terrain is seen by at least
one guard. This improves on the currently best approximation factor of 5. Our
method is based on rounding the linear programming relaxation of the
corresponding covering problem. Besides the simplicity of the analysis, which
mainly relies on decomposing the constraint matrix of the LP into totally
balanced matrices, our algorithm, unlike previous work, generalizes to the
weighted and partial versions of the basic problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0188</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0188</id><created>2008-09-01</created><authors><author><keyname>Berman</keyname><forenames>Piotr</forenames></author><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author></authors><title>Approximating Transitivity in Directed Networks</title><categories>cs.CC cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of computing a minimum equivalent digraph (also known as
the problem of computing a strong transitive reduction) and its maximum
objective function variant, with two types of extensions. First, we allow to
declare a set $D\subset E$ and require that a valid solution $A$ satisfies
$D\subset A$ (it is sometimes called transitive reduction problem). In the
second extension (called $p$-ary transitive reduction), we have integer edge
labeling and we view two paths as equivalent if they have the same beginning,
ending and the sum of labels modulo $p$. A solution $A\subseteq E$ is valid if
it gives an equivalent path for every original path. For all problems we
establish the following: polynomial time minimization of $|A|$ within ratio
1.5, maximization of $|E-A|$ within ratio 2, MAX-SNP hardness even of the
length of simple cycles is limited to 5. Furthermore, we believe that the
combinatorial technique behind the approximation algorithm for the minimization
version might be of interest to other graph connectivity problems as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0195</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0195</id><created>2008-09-01</created><updated>2008-11-07</updated><authors><author><keyname>Coppola</keyname><forenames>Paolo</forenames></author><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Della Rocca</keyname><forenames>Simona Ronchi</forenames></author></authors><title>Light Logics and the Call-by-Value Lambda Calculus</title><categories>cs.LO</categories><comments>28 pages</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (November
  7, 2008) lmcs:820</journal-ref><doi>10.2168/LMCS-4(4:5)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The so-called light logics have been introduced as logical systems enjoying
quite remarkable normalization properties. Designing a type assignment system
for pure lambda calculus from these logics, however, is problematic. In this
paper we show that shifting from usual call-by-name to call-by-value lambda
calculus allows regaining strong connections with the underlying logic. This
will be done in the context of Elementary Affine Logic (EAL), designing a type
system in natural deduction style assigning EAL formulae to lambda terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0199</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0199</id><created>2008-09-01</created><authors><author><keyname>Wright</keyname><forenames>John</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Dense Error Correction via L1-Minimization</title><categories>cs.IT math.IT</categories><comments>40 pages, 9 figures</comments><report-no>UILU-ENG-08-2210, DC 237</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of recovering a non-negative sparse signal $\x
\in \Re^n$ from highly corrupted linear measurements $\y = A\x + \e \in \Re^m$,
where $\e$ is an unknown error vector whose nonzero entries may be unbounded.
Motivated by an observation from face recognition in computer vision, this
paper proves that for highly correlated (and possibly overcomplete)
dictionaries $A$, any non-negative, sufficiently sparse signal $\x$ can be
recovered by solving an $\ell^1$-minimization problem: $\min \|\x\|_1 +
\|\e\|_1 \quad {subject to} \quad \y = A\x + \e.$ More precisely, if the
fraction $\rho$ of errors is bounded away from one and the support of $\x$
grows sublinearly in the dimension $m$ of the observation, then as $m$ goes to
infinity, the above $\ell^1$-minimization succeeds for all signals $\x$ and
almost all sign-and-support patterns of $\e$. This result suggests that
accurate recovery of sparse signals is possible and computationally feasible
even with nearly 100% of the observations corrupted. The proof relies on a
careful characterization of the faces of a convex polytope spanned together by
the standard crosspolytope and a set of iid Gaussian vectors with nonzero mean
and small variance, which we call the ``cross-and-bouquet'' model. Simulations
and experimental results corroborate the findings, and suggest extensions to
the result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0216</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0216</id><created>2008-09-01</created><authors><author><keyname>Sanadhya</keyname><forenames>Somitra Kumar</forenames></author><author><keyname>Sarkar</keyname><forenames>Palash</forenames></author></authors><title>Colliding Message Pairs for 23 and 24-step SHA-512</title><categories>cs.CR</categories><comments>2 pages, 2 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Indesteege et al. [1] had described attacks against 23 and 24-step
SHA-512 at SAC '08. Their attacks are based on the differential path by Nikolic
and Biryukov [2]. The reported complexities are $2^{44.9}$ and $2^{53}$ calls
to the respective step reduced SHA-512 hash function. They provided colliding
message pairs for 23-step SHA-512 but did not provide a colliding message pair
for 24-step SHA-512. In this note we provide a colliding message pair for
23-step SHA-512 and the first colliding message pair for 24-step SHA-512. Our
attacks use the differential path first described by Sanadhya and Sarkar at
ACISP '08 [3]. The complexities of our attacks are $2^{16.5}$ and $2^{34.5}$
calls to the respective step reduced SHA-512 hash function. Complete details of
the attacks will be provided in an extended version of this note.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0257</identifier>
 <datestamp>2008-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0257</id><created>2008-09-01</created><updated>2008-09-20</updated><authors><author><keyname>Cai</keyname><forenames>Xuan</forenames></author></authors><title>Linear Kernelizations for Restricted 3-Hitting Set Problems</title><categories>cs.CC</categories><comments>12 pages</comments><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3-\textsc{Hitting Set} problem is also called the \textsc{Vertex Cover}
problem on 3-uniform hypergraphs. In this paper, we address kernelizations of
the \textsc{Vertex Cover} problem on 3-uniform hypergraphs. We show that this
problem admits a linear kernel in three classes of 3-uniform hypergraphs. We
also obtain lower and upper bounds on the kernel size for them by the
parametric duality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0259</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0259</id><created>2008-09-01</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>On Duality between Local Maximum Stable Sets of a Graph and its
  Line-Graph</title><categories>math.CO cs.DM</categories><comments>7 pages; 7 figures</comments><msc-class>05C69 (Primary) 05C70 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  G is a Koenig-Egervary graph provided alpha(G)+ mu(G)=|V(G)|, where mu(G) is
the size of a maximum matching and alpha(G) is the cardinality of a maximum
stable set. S is a local maximum stable set of G if S is a maximum stable set
of the closed neighborhood of S. Nemhauser and Trotter Jr. proved that any
local maximum stable set is a subset of a maximum stable set of G. In this
paper we demonstrate that if S is a local maximum stable set, the subgraph H
induced by the closed neighborhood of S is a Koenig-Egervary graph, and M is a
maximum matching in H, then M is a local maximum stable set in the line graph
of G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0271</identifier>
 <datestamp>2008-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0271</id><created>2008-09-01</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>Randomised Variable Neighbourhood Search for Multi Objective
  Optimisation</title><categories>cs.AI</categories><journal-ref>Proceedings of the 4th EU/ME Workshop: Design and Evaluation of
  Advanced Hybrid Meta-Heuristics, November 4--5, Nottingham, United Kingdom,
  pp. 34-42</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various local search approaches have recently been applied to machine
scheduling problems under multiple objectives. Their foremost consideration is
the identification of the set of Pareto optimal alternatives. An important
aspect of successfully solving these problems lies in the definition of an
appropriate neighbourhood structure. Unclear in this context remains, how
interdependencies within the fitness landscape affect the resolution of the
problem.
  The paper presents a study of neighbourhood search operators for multiple
objective flow shop scheduling. Experiments have been carried out with twelve
different combinations of criteria. To derive exact conclusions, small problem
instances, for which the optimal solutions are known, have been chosen.
Statistical tests show that no single neighbourhood operator is able to equally
identify all Pareto optimal alternatives. Significant improvements however have
been obtained by hybridising the solution algorithm using a randomised variable
neighbourhood search technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0352</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0352</id><created>2008-09-02</created><updated>2010-07-14</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Instruction sequences and non-uniform complexity theory</title><categories>cs.CC</categories><comments>31 pages; 31 pages, improvements of several proof outlines; 33 pages,
  presentation of section 7 improved</comments><report-no>PRG0812</report-no><acm-class>F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop theory concerning non-uniform complexity in a setting in which the
notion of single-pass instruction sequence considered in program algebra is the
central notion. We define counterparts of the complexity classes P/poly and
NP/poly and formulate a counterpart of the complexity theoretic conjecture that
NP is not included in P/poly. In addition, we define a notion of completeness
for the counterpart of NP/poly using a non-uniform reducibility relation and
formulate complexity hypotheses which concern restrictions on the instruction
sequences used for computation. We think that the theory developed opens up an
additional way of investigating issues concerning non-uniform complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0355</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0355</id><created>2008-09-02</created><authors><author><keyname>Imai</keyname><forenames>Katsunobu</forenames><affiliation>I3S, IEC</affiliation></author><author><keyname>Martin</keyname><forenames>Bruno</forenames><affiliation>I3S</affiliation></author></authors><title>Simulations between triangular and hexagonal number-conserving cellular
  automata</title><categories>cs.DM</categories><comments>11 pages; International Workshop on Natural Computing, Yokohama :
  Japon (2008)</comments><proxy>ccsd hal-00315932</proxy><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number-conserving cellular automaton is a cellular automaton whose states
are integers and whose transition function keeps the sum of all cells constant
throughout its evolution. It can be seen as a kind of modelization of the
physical conservation laws of mass or energy. In this paper, we first propose a
necessary condition for triangular and hexagonal cellular automata to be
number-conserving. The local transition function is expressed by the sum of
arity two functions which can be regarded as 'flows' of numbers. The
sufficiency is obtained through general results on number-conserving cellular
automata. Then, using the previous flow functions, we can construct effective
number-conserving simulations between hexagonal cellular automata and
triangular cellular automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0360</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0360</id><created>2008-09-02</created><updated>2008-09-22</updated><authors><author><keyname>Bonatti</keyname><forenames>Piero A.</forenames></author><author><keyname>Lutz</keyname><forenames>Carsten</forenames></author><author><keyname>Murano</keyname><forenames>Aniello</forenames></author><author><keyname>Vardi</keyname><forenames>Moshe Y.</forenames></author></authors><title>The Complexity of Enriched Mu-Calculi</title><categories>cs.LO cs.CL</categories><comments>A preliminary version of this paper appears in the Proceedings of the
  33rd International Colloquium on Automata, Languages and Programming (ICALP),
  2006. This paper has been selected for a special issue in LMCS</comments><acm-class>F.3.1; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 3 (September
  22, 2008) lmcs:993</journal-ref><doi>10.2168/LMCS-4(3:11)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fully enriched &amp;mu;-calculus is the extension of the propositional
&amp;mu;-calculus with inverse programs, graded modalities, and nominals. While
satisfiability in several expressive fragments of the fully enriched
&amp;mu;-calculus is known to be decidable and ExpTime-complete, it has recently
been proved that the full calculus is undecidable. In this paper, we study the
fragments of the fully enriched &amp;mu;-calculus that are obtained by dropping at
least one of the additional constructs. We show that, in all fragments obtained
in this way, satisfiability is decidable and ExpTime-complete. Thus, we
identify a family of decidable logics that are maximal (and incomparable) in
expressive power. Our results are obtained by introducing two new automata
models, showing that their emptiness problems are ExpTime-complete, and then
reducing satisfiability in the relevant logics to these problems. The automata
models we introduce are two-way graded alternating parity automata over
infinite trees (2GAPTs) and fully enriched automata (FEAs) over infinite
forests. The former are a common generalization of two incomparable automata
models from the literature. The latter extend alternating automata in a similar
way as the fully enriched &amp;mu;-calculus extends the standard &amp;mu;-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0400</identifier>
 <datestamp>2009-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0400</id><created>2008-09-02</created><updated>2009-03-21</updated><authors><author><keyname>Cai</keyname><forenames>Xuan</forenames></author></authors><title>Canonical Coin Systems for Change-Making Problems</title><categories>cs.DS cs.DM</categories><comments>7 pages</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Change-Making Problem is to represent a given value with the fewest coins
under a given coin system. As a variation of the knapsack problem, it is known
to be NP-hard. Nevertheless, in most real money systems, the greedy algorithm
yields optimal solutions. In this paper, we study what type of coin systems
that guarantee the optimality of the greedy algorithm. We provide new proofs
for a sufficient and necessary condition for the so-called \emph{canonical}
coin systems with four or five types of coins, and a sufficient condition for
non-canonical coin systems, respectively. Moreover, we present an $O(m^2)$
algorithm that decides whether a tight coin system is canonical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0406</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0406</id><created>2008-09-02</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>Foundations of the Pareto Iterated Local Search Metaheuristic</title><categories>cs.AI</categories><comments>Proceedings of the 18th International Conference on Multiple Criteria
  Decision Making, Chania, Greece, June 19-23, 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes the proposition and application of a local search
metaheuristic for multi-objective optimization problems. It is based on two
main principles of heuristic search, intensification through variable
neighborhoods, and diversification through perturbations and successive
iterations in favorable regions of the search space. The concept is
successfully tested on permutation flow shop scheduling problems under multiple
objectives. While the obtained results are encouraging in terms of their
quality, another positive attribute of the approach is its' simplicity as it
does require the setting of only very few parameters. The implementation of the
Pareto Iterated Local Search metaheuristic is based on the MOOPPS computer
system of local search heuristics for multi-objective scheduling which has been
awarded the European Academic Software Award 2002 in Ronneby, Sweden
(http://www.easa-award.net/, http://www.bth.se/llab/easa_2002.nsf)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0410</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0410</id><created>2008-09-02</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>A Computational Study of Genetic Crossover Operators for Multi-Objective
  Vehicle Routing Problem with Soft Time Windows</title><categories>cs.AI</categories><journal-ref>Habenicht, W. et al. (eds.): Multi-Criteria- und Fuzzy Systeme in
  Theorie und Praxis-Loesungsansaetze fuer Entscheidungsprobleme mit komplexen
  Zielsystemen, 2003, ISBN 3-8244-7864-1, pp. 191-207</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article describes an investigation of the effectiveness of genetic
algorithms for multi-objective combinatorial optimization (MOCO) by presenting
an application for the vehicle routing problem with soft time windows. The work
is motivated by the question, if and how the problem structure influences the
effectiveness of different configurations of the genetic algorithm.
Computational results are presented for different classes of vehicle routing
problems, varying in their coverage with time windows, time window size,
distribution and number of customers. The results are compared with a simple,
but effective local search approach for multi-objective combinatorial
optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0416</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0416</id><created>2008-09-02</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>Genetic Algorithms for multiple objective vehicle routing</title><categories>cs.AI</categories><journal-ref>Proceedings of the Metaheuristics International Conference
  MIC'2001, Porto, Portugal, pp. 349-353</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The talk describes a general approach of a genetic algorithm for multiple
objective optimization problems. A particular dominance relation between the
individuals of the population is used to define a fitness operator, enabling
the genetic algorithm to adress even problems with efficient, but
convex-dominated alternatives. The algorithm is implemented in a multilingual
computer program, solving vehicle routing problems with time windows under
multiple objectives. The graphical user interface of the program shows the
progress of the genetic algorithm and the main parameters of the approach can
be easily modified. In addition to that, the program provides powerful decision
support to the decision maker. The software has proved it's excellence at the
finals of the European Academic Software Award EASA, held at the Keble college/
University of Oxford/ Great Britain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0417</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0417</id><created>2008-09-02</created><updated>2009-05-20</updated><authors><author><keyname>Mukherjee</keyname><forenames>Satyam</forenames></author><author><keyname>Gupte</keyname><forenames>Neelima</forenames></author></authors><title>Queue-length synchronization in a communication networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.NI</categories><comments>13 Pages, 15 figures</comments><journal-ref>Phys. Rev. E Vol. 79, 056105 (2009)</journal-ref><doi>10.1103/PhysRevE.79.056105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study synchronization in the context of network traffic on a $2-d$
communication network with local clustering and geographic separations. The
network consists of nodes and randomly distributed hubs where the top five hubs
ranked according to their coefficient of betweenness centrality (CBC) are
connected by random assortative and gradient mechanisms. For multiple message
traffic, messages can trap at the high CBC hubs, and congestion can build up on
the network with long queues at the congested hubs. The queue lengths are seen
to synchronize in the congested phase. Both complete and phase synchronization
is seen, between pairs of hubs. In the decongested phase, the pairs start
clearing, and synchronization is lost. A cascading master-slave relation is
seen between the hubs, with the slower hubs (which are slow to decongest)
driving the faster ones. These are usually the hubs of high CBC. Similar
results are seen for traffic of constant density. Total synchronization between
the hubs of high CBC is also seen in the congested regime. Similar behavior is
seen for traffic on a network constructed using the Waxman random topology
generator. We also demonstrate the existence of phase synchronization in real
Internet traffic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0444</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0444</id><created>2008-09-02</created><updated>2008-09-02</updated><authors><author><keyname>Gambs</keyname><forenames>S&#xe9;bastien</forenames></author></authors><title>Quantum classification</title><categories>quant-ph cs.LG</categories><comments>Preliminary version, comments are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum classification is defined as the task of predicting the associated
class of an unknown quantum state drawn from an ensemble of pure states given a
finite number of copies of this state. By recasting the state discrimination
problem within the framework of Machine Learning (ML), we can use the notion of
learning reduction coming from classical ML to solve different variants of the
classification task, such as the weighted binary and the multiclass versions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0448</identifier>
 <datestamp>2008-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0448</id><created>2008-09-02</created><authors><author><keyname>Engle</keyname><forenames>Eric</forenames></author></authors><title>The Stock Market as a Game: An Agent Based Approach to Trading in Stocks</title><categories>q-fin.TR cs.AI cs.GT</categories><comments>21 pages and accompanying program</comments><acm-class>H.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Just as war is sometimes fallaciously represented as a zero sum game -- when
in fact war is a negative sum game - stock market trading, a positive sum game
over time, is often erroneously represented as a zero sum game. This is called
the &quot;zero sum fallacy&quot; -- the erroneous belief that one trader in a stock
market exchange can only improve their position provided some other trader's
position deteriorates. However, a positive sum game in absolute terms can be
recast as a zero sum game in relative terms. Similarly it appears that negative
sum games in absolute terms have been recast as zero sum games in relative
terms: otherwise, why would zero sum games be used to represent situations of
war? Such recasting may have heuristic or pedagogic interest but recasting must
be clearly explicited or risks generating confusion.
  Keywords: Game theory, stock trading and agent based AI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0458</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0458</id><created>2008-09-02</created><authors><author><keyname>Engle</keyname><forenames>Eric</forenames></author></authors><title>Agent Models of Political Interactions</title><categories>cs.AI cs.GT</categories><comments>22 pages</comments><acm-class>H.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Looks at state interactions from an agent based AI perspective to see state
interactions as an example of emergent intelligent behavior. Exposes basic
principles of game theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0460</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0460</id><created>2008-09-02</created><authors><author><keyname>Agrawal</keyname><forenames>Shipra</forenames></author><author><keyname>Saberi</keyname><forenames>Amin</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>Stochastic Combinatorial Optimization under Probabilistic Constraints</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present approximation algorithms for combinatorial
optimization problems under probabilistic constraints. Specifically, we focus
on stochastic variants of two important combinatorial optimization problems:
the k-center problem and the set cover problem, with uncertainty characterized
by a probability distribution over set of points or elements to be covered. We
consider these problems under adaptive and non-adaptive settings, and present
efficient approximation algorithms for the case when underlying distribution is
a product distribution. In contrast to the expected cost model prevalent in
stochastic optimization literature, our problem definitions support
restrictions on the probability distributions of the total costs, via
incorporating constraints that bound the probability with which the incurred
costs may exceed a given threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0461</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0461</id><created>2008-09-02</created><authors><author><keyname>Engle</keyname><forenames>Eric</forenames></author></authors><title>The Semiotic Machine</title><categories>cs.HC</categories><comments>28 pages</comments><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A semiotic model of the user interface in human-computer interaction.
Algorithmic sign, semotics, algorithmic art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0490</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0490</id><created>2008-09-02</created><updated>2011-05-09</updated><authors><author><keyname>Gorban</keyname><forenames>A. N.</forenames></author><author><keyname>Zinovyev</keyname><forenames>A. Y.</forenames></author></authors><title>Principal Graphs and Manifolds</title><categories>cs.LG cs.NE stat.ML</categories><comments>36 pages, 6 figures, minor corrections</comments><journal-ref>Handbook of Research on Machine Learning Applications and Trends:
  Algorithms, Methods and Techniques, Ch. 2, Information Science Reference,
  2009. 28-59</journal-ref><doi>10.4018/978-1-60566-766-9</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In many physical, statistical, biological and other investigations it is
desirable to approximate a system of points by objects of lower dimension
and/or complexity. For this purpose, Karl Pearson invented principal component
analysis in 1901 and found 'lines and planes of closest fit to system of
points'. The famous k-means algorithm solves the approximation problem too, but
by finite sets instead of lines and planes. This chapter gives a brief
practical introduction into the methods of construction of general principal
objects, i.e. objects embedded in the 'middle' of the multidimensional data
set. As a basis, the unifying framework of mean squared distance approximation
of finite datasets is selected. Principal graphs and manifolds are constructed
as generalisations of principal components and k-means principal points. For
this purpose, the family of expectation/maximisation algorithms with nearest
generalisations is presented. Construction of principal graphs with controlled
complexity is based on the graph grammar approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0494</identifier>
 <datestamp>2008-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0494</id><created>2008-09-02</created><authors><author><keyname>Guillaume</keyname><forenames>Bruno</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Perrier</keyname><forenames>Guy</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Interaction Grammars</title><categories>cs.LO</categories><proxy>ccsd inria-00288376</proxy><report-no>RR-6621</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interaction Grammar (IG) is a grammatical formalism based on the notion of
polarity. Polarities express the resource sensitivity of natural languages by
modelling the distinction between saturated and unsaturated syntactic
structures. Syntactic composition is represented as a chemical reaction guided
by the saturation of polarities. It is expressed in a model-theoretic framework
where grammars are constraint systems using the notion of tree description and
parsing appears as a process of building tree description models satisfying
criteria of saturation and minimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0519</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0519</id><created>2008-09-02</created><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author></authors><title>Complexity of comparison of influence of players in simple games</title><categories>cs.GT</categories><comments>Latex, 13 pages, COMSOC-2008: 2nd International Workshop on
  Computational Social Choice</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coalitional voting games appear in different forms in multi-agent systems,
social choice and threshold logic. In this paper, the complexity of comparison
of influence between players in coalitional voting games is characterized. The
possible representations of simple games considered are simple games
represented by winning coalitions, minimal winning coalitions, weighted voting
game or a multiple weighted voting game. The influence of players is gauged
from the viewpoint of basic player types, desirability relations and classical
power indices such as Shapley-Shubik index, Banzhaf index, Holler index,
Deegan-Packel index and Chow parameters. Among other results, it is shown that
for a simple game represented by minimal winning coalitions, although it is
easy to verify whether a player has zero or one voting power, computing the
Banzhaf value of the player is #P-complete. Moreover, it is proved that
multiple weighted voting games are the only representations for which it is
NP-hard to verify whether the game is linear or not. For a simple game with a
set W^m of minimal winning coalitions and n players, a O(n.|W^m|+(n^2)log(n))
algorithm is presented which returns `no' if the game is non-linear and returns
the strict desirability ordering otherwise. The complexity of transforming
simple games into compact representations is also examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0522</identifier>
 <datestamp>2013-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0522</id><created>2008-09-02</created><authors><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>The first-mover advantage in scientific publication</title><categories>physics.soc-ph cs.DL cs.SI</categories><comments>7 pages, 3 figures</comments><journal-ref>Europhys. Lett. 86, 68001 (2009)</journal-ref><doi>10.1209/0295-5075/86/68001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical models of the scientific citation process predict a strong
&quot;first-mover&quot; effect under which the first papers in a field will, essentially
regardless of content, receive citations at a rate enormously higher than
papers published later. Moreover papers are expected to retain this advantage
in perpetuity -- they should receive more citations indefinitely, no matter how
many other papers are published after them. We test this conjecture against
data from a selection of fields and in several cases find a first-mover effect
of a magnitude similar to that predicted by the theory. Were we wearing our
cynical hat today, we might say that the scientist who wants to become famous
is better off -- by a wide margin -- writing a modest paper in next year's
hottest field than an outstanding paper in this year's. On the other hand,
there are some papers, albeit only a small fraction, that buck the trend and
attract significantly more citations than theory predicts despite having
relatively late publication dates. We suggest that papers of this kind, though
they often receive comparatively few citations overall, are probably worthy of
our attention.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0524</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0524</id><created>2008-09-02</created><authors><author><keyname>Engle</keyname><forenames>Eric</forenames></author></authors><title>Computer Art in the Former Soviet Bloc</title><categories>cs.MM cs.CY</categories><comments>28 pages</comments><acm-class>J.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Documents early computer art in the Soviet bloc and describes Marxist art
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0533</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0533</id><created>2008-09-03</created><updated>2009-03-16</updated><authors><author><keyname>Ren</keyname><forenames>Wei</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>Power Control in Cognitive Radio Networks: How to Cross a Multi-Lane
  Highway</title><categories>cs.NI</categories><comments>20 pages, 10 figures, to appear in IEEE Journal on Selected Areas in
  Communications (JSAC): Special Issue on Stochastic Geometry and Random Graphs
  for Wireless Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider power control in cognitive radio networks where secondary users
identify and exploit instantaneous and local spectrum opportunities without
causing unacceptable interference to primary users. We qualitatively
characterize the impact of the transmission power of secondary users on the
occurrence of spectrum opportunities and the reliability of opportunity
detection. Based on a Poisson model of the primary network, we quantify these
impacts by showing that (i) the probability of spectrum opportunity decreases
exponentially with respect to the transmission power of secondary users, where
the exponential decay constant is given by the traffic load of primary users;
(ii) reliable opportunity detection is achieved in the two extreme regimes in
terms of the ratio between the transmission power of secondary users and that
of primary users. Such analytical characterizations allow us to study power
control for optimal transport throughput under constraints on the interference
to primary users. Furthermore, we reveal the difference between detecting
primary signals and detecting spectrum opportunities, and demonstrate the
complex relationship between physical layer spectrum sensing and MAC layer
throughput. The dependency of this PHY-MAC interaction on the application type
and the use of handshake signaling such as RTS/CTS is illustrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0536</identifier>
 <datestamp>2009-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0536</id><created>2008-09-03</created><updated>2009-01-05</updated><authors><author><keyname>Xia</keyname><forenames>Minghua</forenames></author><author><keyname>Wen</keyname><forenames>Wenkun</forenames></author><author><keyname>Kim</keyname><forenames>Soo-Chang</forenames></author></authors><title>How to Fully Exploit the Degrees of Freedom in the Downlink of MISO
  Systems With Opportunistic Beamforming</title><categories>cs.IT math.IT</categories><comments>v2, revised Jan. 5, 2009. Few typo and error corrections, better
  clarification</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The opportunistic beamforming in the downlink of multiple-input single-output
(MISO) systems forms $N$ transmit beams, usually, no more than the number of
transmit antennas $N_t$. However, the degrees of freedom in this downlink is as
large as $N_t^2$. That is, at most $N_t^2$ rather than only $N_t$ users can be
simultaneously transmitted and thus the scheduling latency can be significantly
reduced. In this paper, we focus on the opportunistic beamforming schemes with
$N_t&lt;N\le N_t^2$ transmit beams in the downlink of MISO systems over Rayleigh
fading channels. We first show how to design the beamforming matrices with
maximum number of transmit beams as well as least correlation between any pair
of them as possible, through Fourier, Grassmannian, and mutually unbiased bases
(MUB) based constructions in practice. Then, we analyze their system throughput
by exploiting the asymptotic theory of extreme order statistics. Finally, our
simulation results show the Grassmannian-based beamforming achieves the maximum
throughput in all cases with $N_t=2$, 3, 4. However, if we want to exploit
overall $N_t^2$ degrees of freedom, we shall resort to the Fourier and
MUB-based constructions in the cases with $N_t=3$, 4, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0539</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0539</id><created>2008-09-02</created><updated>2011-02-17</updated><authors><author><keyname>Santipach</keyname><forenames>Wiroonsak</forenames></author></authors><title>Signature Quantization in Fading CDMA With Limited Feedback</title><categories>cs.IT math.IT</categories><journal-ref>IEEE TRANSACTIONS ON COMMUNICATIONS, VOL. 59, NO. 2, PP. 569-577
  FEBRUARY 2011</journal-ref><doi>10.1109/TCOMM.2011.122110.090476</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we analyze the performance of a signature quantization scheme
for reverse-link Direct Sequence (DS)- Code Division Multiple Access (CDMA).
Assuming perfect estimates of the channel and interference covariance, the
receiver selects the signature that minimizes interference power or maximizes
signal-to-interference plus noise ratio (SINR) for a desired user from a
signature codebook. The codebook index corresponding to the optimal signature
is then relayed to the user with a finite number of bits via a feedback
channel. Here we are interested in the performance of a Random Vector
Quantization (RVQ) codebook, which contains independent isotropically
distributed vectors. Assuming arbitrary transmit power allocation, we consider
additive white Gaussian noise (AWGN) channel first with no fading and
subsequently, with multipath fading. We derive the corresponding SINR in a
large system limit at the output of matched filter and linear minimum mean
squared error (MMSE) receiver. Numerical examples show that the derived large
system results give a good approximation to the performance of finite-size
system and that the MMSE receiver achieves close to a single-user performance
with only one feedback bit per signature element.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0545</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0545</id><created>2008-09-03</created><authors><author><keyname>Hassen</keyname><forenames>S. Z. Sayed</forenames></author><author><keyname>Heurs</keyname><forenames>M.</forenames></author><author><keyname>Huntington</keyname><forenames>E. H.</forenames></author><author><keyname>Petersen</keyname><forenames>I. R.</forenames></author></authors><title>Frequency Locking of an Optical Cavity using LQG Integral Control</title><categories>quant-ph cs.SY</categories><comments>18 pages, 9 figures</comments><journal-ref>Journal of Physics B: Atomic, Molecular and Optical Physics, vol.
  42, 175501, 2009</journal-ref><doi>10.1088/0953-4075/42/17/175501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the application of integral Linear Quadratic Gaussian
(LQG) optimal control theory to a problem of cavity locking in quantum optics.
The cavity locking problem involves controlling the error between the laser
frequency and the resonant frequency of the cavity. A model for the cavity
system, which comprises a piezo-electric actuator and an optical cavity is
experimentally determined using a subspace identification method. An LQG
controller which includes integral action is synthesized to stabilize the
frequency of the cavity to the laser frequency and to reject low frequency
noise. The controller is successfully implemented in the laboratory using a
dSpace DSP board.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0600</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0600</id><created>2008-09-03</created><updated>2009-06-16</updated><authors><author><keyname>Srikanth</keyname><forenames>R.</forenames></author></authors><title>No-signaling, intractability and entanglement</title><categories>quant-ph cs.CC</categories><comments>19 pages, 2 figures, revtex4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of deriving the no-signaling condition from the
assumption that, as seen from a complexity theoretic perspective, the universe
is not an exponential place. A fact that disallows such a derivation is the
existence of {\em polynomial superluminal} gates, hypothetical primitive
operations that enable superluminal signaling but not the efficient solution of
intractable problems. It therefore follows, if this assumption is a basic
principle of physics, either that it must be supplemented with additional
assumptions to prohibit such gates, or, improbably, that no-signaling is not a
universal condition. Yet, a gate of this kind is possibly implicit, though not
recognized as such, in a decade-old quantum optical experiment involving
position-momentum entangled photons. Here we describe a feasible modified
version experiment that appears to explicitly demonstrate the action of this
gate. Some obvious counter-claims are shown to be invalid. We believe that the
unexpected possibility of polynomial superluminal operations arises because
some practically measured quantum optical quantities are not describable as
standard quantum mechanical observables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0610</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0610</id><created>2008-09-03</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author><author><keyname>Wenger</keyname><forenames>Wolf</forenames></author></authors><title>A framework for the interactive resolution of multi-objective vehicle
  routing problems</title><categories>cs.AI</categories><comments>Proceedings of the 7th EU/ME Workshop: Adaptive, Self-Adaptive, and
  Multi-Level Metaheuristics, Malaga, Spain, November 16-17, 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents a framework for the resolution of rich vehicle routing
problems which are difficult to address with standard optimization techniques.
We use local search on the basis on variable neighborhood search for the
construction of the solutions, but embed the techniques in a flexible framework
that allows the consideration of complex side constraints of the problem such
as time windows, multiple depots, heterogeneous fleets, and, in particular,
multiple optimization criteria. In order to identify a compromise alternative
that meets the requirements of the decision maker, an interactive procedure is
integrated in the resolution of the problem, allowing the modification of the
preference information articulated by the decision maker. The framework is
prototypically implemented in a computer system. First results of test runs on
multiple depot vehicle routing problems with time windows are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0635</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0635</id><created>2008-09-03</created><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Low ML-Decoding Complexity, Large Coding Gain, Full-Rate, Full-Diversity
  STBCs for 2 X 2 and 4 X 2 MIMO Systems</title><categories>cs.IT math.IT</categories><comments>28 pages, 5 figures, 3 tables, submitted to IEEE Journal of Selected
  Topics in Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper (Part of the content of this manuscript has been accepted for
presentation in IEEE Globecom 2008, to be held in New Orleans) deals with low
maximum likelihood (ML) decoding complexity, full-rate and full-diversity
space-time block codes (STBCs), which also offer large coding gain, for the 2
transmit antenna, 2 receive antenna ($2\times 2$) and the 4 transmit antenna, 2
receive antenna ($4\times 2$) MIMO systems. Presently, the best known STBC for
the $2\times2$ system is the Golden code and that for the $4\times2$ system is
the DjABBA code. Following the approach by Biglieri, Hong and Viterbo, a new
STBC is presented in this paper for the $2\times 2$ system. This code matches
the Golden code in performance and ML-decoding complexity for square QAM
constellations while it has lower ML-decoding complexity with the same
performance for non-rectangular QAM constellations. This code is also shown to
be \emph{information-lossless} and \emph{diversity-multiplexing gain} (DMG)
tradeoff optimal. This design procedure is then extended to the $4\times 2$
system and a code, which outperforms the DjABBA code for QAM constellations
with lower ML-decoding complexity, is presented. So far, the Golden code has
been reported to have an ML-decoding complexity of the order of $M^4$ for
square QAM of size $M$. In this paper, a scheme that reduces its ML-decoding
complexity to $M^2\sqrt{M}$ is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0662</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0662</id><created>2008-09-03</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author><author><keyname>Petrovic</keyname><forenames>Sanja</forenames></author></authors><title>Improving Local Search for Fuzzy Scheduling Problems</title><categories>cs.AI</categories><journal-ref>Proceedings of the Post Graduate Research Conference in
  Electronics, Photonics, Communications &amp; Networks and Computing Science PREP
  2004, University of Hertfordshire, Great Britain, pp. 146-147</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of fuzzy set theory and fuzzy logic into scheduling is a
rather new aspect with growing importance for manufacturing applications,
resulting in various unsolved aspects. In the current paper, we investigate an
improved local search technique for fuzzy scheduling problems with fitness
plateaus, using a multi criteria formulation of the problem. We especially
address the problem of changing job priorities over time as studied at the
Sherwood Press Ltd, a Nottingham based printing company, who is a collaborator
on the project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0676</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0676</id><created>2008-09-03</created><authors><author><keyname>Thippireddy</keyname><forenames>Suresh B.</forenames></author></authors><title>Binary Random Sequences Obtained From Decimal Sequences</title><categories>cs.CR</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a twist to the generation of binary random sequences by
starting with decimal sequences. Rather than representing the prime reciprocal
sequence directly in base 2, we first right the prime reciprocal in base 10 and
then convert it into the binary form. The autocorrelation and cross-correlation
properties of these binary random (BRD) sequences are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0680</identifier>
 <datestamp>2008-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0680</id><created>2008-09-03</created><authors><author><keyname>Fodor</keyname><forenames>Paul</forenames></author><author><keyname>Lally</keyname><forenames>Adam</forenames></author><author><keyname>Ferrucci</keyname><forenames>David</forenames></author></authors><title>The Prolog Interface to the Unstructured Information Management
  Architecture</title><categories>cs.SE cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe the design and implementation of the Prolog
interface to the Unstructured Information Management Architecture (UIMA) and
some of its applications in natural language processing. The UIMA Prolog
interface translates unstructured data and the UIMA Common Analysis Structure
(CAS) into a Prolog knowledge base, over which, the developers write rules and
use resolution theorem proving to search and generate new annotations over the
unstructured data. These rules can explore all the previous UIMA annotations
(such as, the syntactic structure, parsing statistics) and external Prolog
knowledge bases (such as, Prolog WordNet and Extended WordNet) to implement a
variety of tasks for the natural language analysis. We also describe
applications of this logic programming interface in question analysis (such as,
focus detection, answer-type and other constraints detection), shallow parsing
(such as, relations in the syntactic structure), and answer selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0686</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0686</id><created>2008-09-03</created><updated>2010-06-08</updated><authors><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Yukich</keyname><forenames>Joseph E.</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>Energy Scaling Laws for Distributed Inference in Random Fusion Networks</title><categories>cs.IT cs.NI math.IT math.ST stat.TH</categories><comments>IEEE JSAC on Stochastic Geometry and Random Graphs for Wireless
  Networks</comments><journal-ref>vol. 27, no. 7, pp.1203-1217, Sept. 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The energy scaling laws of multihop data fusion networks for distributed
inference are considered. The fusion network consists of randomly located
sensors distributed i.i.d. according to a general spatial distribution in an
expanding region. Among the class of data fusion schemes that enable optimal
inference at the fusion center for Markov random field (MRF) hypotheses, the
scheme with minimum average energy consumption is bounded below by average
energy of fusion along the minimum spanning tree, and above by a suboptimal
scheme, referred to as Data Fusion for Markov Random Fields (DFMRF). Scaling
laws are derived for the optimal and suboptimal fusion policies. It is shown
that the average asymptotic energy of the DFMRF scheme is finite for a class of
MRF models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0689</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0689</id><created>2008-09-03</created><authors><author><keyname>K&#xf6;ppe</keyname><forenames>Matthias</forenames></author><author><keyname>Ryan</keyname><forenames>Christopher Thomas</forenames></author><author><keyname>Queyranne</keyname><forenames>Maurice</forenames></author></authors><title>Rational Generating Functions and Integer Programming Games</title><categories>cs.GT math.CO</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the computational complexity of computing pure Nash equilibria for
a new class of strategic games called integer programming games with difference
of piecewise linear convex payoffs. Integer programming games are games where
players' action sets are integer points inside of polytopes. Using recent
results from the study of short rational generating functions for encoding sets
of integer points pioneered by Alexander Barvinok, we present efficient
algorithms for enumerating all pure Nash equilibria, and other computations of
interest, such as the pure price of anarchy, and pure threat point, when the
dimension and number of &quot;convex&quot; linear pieces in the payoff functions are
fixed. Sequential games where a leader is followed by competing followers (a
Stackelberg--Nash setting) are also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0692</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0692</id><created>2008-09-03</created><authors><author><keyname>Stanek</keyname><forenames>Krzysztof Zbigniew</forenames></author></authors><title>How long should an astronomical paper be to increase its Impact?</title><categories>astro-ph cs.DL physics.soc-ph</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Naively, one would expect longer papers to have larger impact (i.e., to be
cited more). I tested this expectation by selecting all (~30,000) refereed
papers from A&amp;A, AJ, ApJ and MNRAS published between 2000 and 2004. These
particular years were chosen so papers analyzed would not be too &quot;fresh&quot;, but
at the same time length of each article could be obtained via ADS. I find that
indeed longer papers published in these four major astronomy journals are on
average cited more, with a median number of citations increasing from 6 for
articles 2-3 pages long to about 50 for articles ~50 pages long. I do however
observe a significant &quot;Letters effect&quot;, i.e. ApJ and A&amp;A articles 4 pages long
are cited more than articles 5-10 pages long. Also, the very few longest (&gt;80
pages) papers are actually cited less than somewhat shorter papers. For
individual journals, median citations per paper increase from 11 for ~9,300 A&amp;A
papers to 14 for ~5,300 MNRAS papers, 16 for ~2,550 AJ papers, and 20 for
~12,850 ApJ papers (including ApJ Letters and Supplement). I conclude with some
semi-humorous career advice, directed especially at first-year graduate
students.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0723</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0723</id><created>2008-09-03</created><authors><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>A Simple Mechanism for Focused Web-harvesting</title><categories>cs.IR cs.CY</categories><comments>6 pages, 4 figures, Proceeding of the International Conference on
  Advanced Computational Intelligence and Its Applications 2008</comments><report-no>FISIKALIPI-08079</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focused web-harvesting is deployed to realize an automated and
comprehensive index databases as an alternative way for virtual topical data
integration. The web-harvesting has been implemented and extended by not only
specifying the targeted URLs, but also predefining human-edited harvesting
parameters to improve the speed and accuracy. The harvesting parameter set
comprises three main components. First, the depth-scale of being harvested
final pages containing desired information counted from the first page at the
targeted URLs. Secondly, the focus-point number to determine the exact box
containing relevant information. Lastly, the combination of keywords to
recognize encountered hyperlinks of relevant images or full-texts embedded in
those final pages. All parameters are accessible and fully customizable for
each target by the administrators of participating institutions over an
integrated web interface. A real implementation to the Indonesian Scientific
Index which covers all scientific information across Indonesia is also briefly
introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0727</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0727</id><created>2008-09-03</created><authors><author><keyname>Firmansyah</keyname><forenames>I.</forenames></author><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Hermanto</keyname><forenames>B.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>Microcontroller-based System for Modular Networked Robot</title><categories>cs.RO cs.CY</categories><comments>6 pages, 5 figures, Proceeding of the 2008 International Conference
  on Advanced Computational Intelligence and Its Applications</comments><report-no>FISIKALIPI-08077</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A prototype of modular networked robot for autonomous monitoring works with
full control over web through wireless connection has been developed. The robot
is equipped with a particular set of built-in analyzing tools and appropriate
censors, depending on its main purposes, to enable self-independent and
real-time data acquisition and processing. The paper is focused on the
microcontroller-based system to realize the modularity. The whole system is
divided into three modules : main unit, data acquisition and data processing,
while the analyzed results and all aspects of control and monitoring systems
are fully accessible over an integrated web-interface. This concept leads to
some unique features : enhancing flexibility due to enabling partial
replacement of the modules according to user needs, easy access over web for
remote users, and low development and maintenance cost due to software
dominated components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0728</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0728</id><created>2008-09-03</created><authors><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>A Spectrum-Shaping Perspective on Cognitive Radio</title><categories>cs.IT math.IT</categories><comments>To appear in DySPAN'08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new perspective on cognitive radio is presented, where the pre-existent
legacy service is either uncoded or coded and a pair of cognitive transceivers
need be appropriately deployed to coexist with the legacy service. The basic
idea underlying the new perspective is to exploit the fact that, typically, the
legacy channel is not fully loaded by the legacy service, thus leaving a
non-negligible margin to accommodate the cognitive transmission. The
exploitation of such a load margin is optimized by shaping the spectrum of the
transmitted cognitive signal. It is shown that non-trivial coexistence of
legacy and cognitive systems is possible even without sharing the legacy
message with the cognitive transmitter. Surprisingly, the optimized cognitive
transmitter is no longer limited by its interference power at the legacy
receiver, and can always transmit at its full available device power.
Analytical development and numerical illustration are presented, in particular
focusing on the logarithmic growth rate, {\it i.e.}, the prelog coefficient, of
cognitive transmission in the high-power regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0733</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0733</id><created>2008-09-03</created><updated>2009-03-06</updated><authors><author><keyname>Harada</keyname><forenames>Masaaki</forenames></author><author><keyname>Munemasa</keyname><forenames>Akihiro</forenames></author></authors><title>There exists no self-dual [24,12,10] code over F5</title><categories>math.CO cs.IT math.IT</categories><comments>To appear in Designs, Codes and Cryptogr</comments><msc-class>94B05</msc-class><journal-ref>Designs, Codes and Cryptogr. 52 (2009), 125-127</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-dual codes over F5 exist for all even lengths. The smallest length for
which the largest minimum weight among self-dual codes has not been determined
is 24, and the largest minimum weight is either 9 or 10. In this note, we show
that there exists no self-dual [24,12,10] code over F5, using the
classification of 24-dimensional odd unimodular lattices due to Borcherds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0737</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0737</id><created>2008-09-03</created><updated>2011-05-09</updated><authors><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author><author><keyname>Kusuma</keyname><forenames>Julius</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author></authors><title>Malleable Coding with Fixed Reuse</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cloud computing, storage area networks, remote backup storage, and similar
settings, stored data is modified with updates from new versions. Representing
information and modifying the representation are both expensive. Therefore it
is desirable for the data to not only be compressed but to also be easily
modified during updates. A malleable coding scheme considers both compression
efficiency and ease of alteration, promoting codeword reuse. We examine the
trade-off between compression efficiency and malleability cost-the difficulty
of synchronizing compressed versions-measured as the length of a reused prefix
portion. Through a coding theorem, the region of achievable rates and
malleability is expressed as a single-letter optimization. Relationships to
common information problems are also described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0745</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0745</id><created>2008-09-04</created><updated>2009-08-10</updated><authors><author><keyname>Saab</keyname><forenames>Rayan</forenames></author><author><keyname>Yilmaz</keyname><forenames>Ozgur</forenames></author></authors><title>Sparse Recovery by Non-convex Optimization -- Instance Optimality</title><categories>cs.IT math.IT</categories><comments>32 pages, 4 figures v2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we address the theoretical properties of $\Delta_p$, a class of
compressed sensing decoders that rely on $\ell^p$ minimization with 0&lt;p&lt;1 to
recover estimates of sparse and compressible signals from incomplete and
inaccurate measurements. In particular, we extend the results of Candes,
Romberg and Tao, and Wojtaszczyk regarding the decoder $\Delta_1$, based on
$\ell^1$ minimization, to $\Delta_p$ with 0&lt;p&lt;1. Our results are two-fold.
First, we show that under certain sufficient conditions that are weaker than
the analogous sufficient conditions for $\Delta_1$ the decoders $\Delta_p$ are
robust to noise and stable in the sense that they are (2,p) instance optimal
for a large class of encoders. Second, we extend the results of Wojtaszczyk to
show that, like $\Delta_1$, the decoders $\Delta_p$ are (2,2) instance optimal
in probability provided the measurement matrix is drawn from an appropriate
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0753</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0753</id><created>2008-09-04</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>Proposition of the Interactive Pareto Iterated Local Search Procedure -
  Elements and Initial Experiments</title><categories>cs.AI cs.HC</categories><journal-ref>The Fourth International Conference on Evolutionary
  Multi-Criterion Optimization: Late Breaking Papers, Matsushima, Japan, March
  2007, pp. 19-23</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents an approach to interactively solve multi-objective
optimization problems. While the identification of efficient solutions is
supported by computational intelligence techniques on the basis of local
search, the search is directed by partial preference information obtained from
the decision maker.
  An application of the approach to biobjective portfolio optimization, modeled
as the well-known knapsack problem, is reported, and experimental results are
reported for benchmark instances taken from the literature. In brief, we obtain
encouraging results that show the applicability of the approach to the
described problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0755</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0755</id><created>2008-09-04</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>Bin Packing Under Multiple Objectives - a Heuristic Approximation
  Approach</title><categories>cs.AI</categories><journal-ref>The Fourth International Conference on Evolutionary
  Multi-Criterion Optimization: Late Breaking Papers, Matsushima, Japan, March
  2007, pp. 53-56</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article proposes a heuristic approximation approach to the bin packing
problem under multiple objectives. In addition to the traditional objective of
minimizing the number of bins, the heterogeneousness of the elements in each
bin is minimized, leading to a biobjective formulation of the problem with a
tradeoff between the number of bins and their heterogeneousness. An extension
of the Best-Fit approximation algorithm is presented to solve the problem.
Experimental investigations have been carried out on benchmark instances of
different size, ranging from 100 to 1000 items. Encouraging results have been
obtained, showing the applicability of the heuristic approach to the described
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0757</identifier>
 <datestamp>2008-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0757</id><created>2008-09-04</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>An application of the Threshold Accepting metaheuristic for curriculum
  based course timetabling</title><categories>cs.AI</categories><journal-ref>Proceedings of the 7th International Conference on the Practice
  and Theory of Automated Timetabling PATAT 2008, August 19-22, Montreal,
  Canada</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents a local search approach for the solution of timetabling
problems in general, with a particular implementation for competition track 3
of the International Timetabling Competition 2007 (ITC 2007). The heuristic
search procedure is based on Threshold Accepting to overcome local optima. A
stochastic neighborhood is proposed and implemented, randomly removing and
reassigning events from the current solution.
  The overall concept has been incrementally obtained from a series of
experiments, which we describe in each (sub)section of the paper. In result, we
successfully derived a potential candidate solution approach for the finals of
track 3 of the ITC 2007.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0788</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0788</id><created>2008-09-04</created><updated>2012-02-03</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Chen</keyname><forenames>Hubie</forenames></author></authors><title>Peek Arc Consistency</title><categories>cs.AI cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies peek arc consistency, a reasoning technique that extends
the well-known arc consistency technique for constraint satisfaction. In
contrast to other more costly extensions of arc consistency that have been
studied in the literature, peek arc consistency requires only linear space and
quadratic time and can be parallelized in a straightforward way such that it
runs in linear time with a linear number of processors. We demonstrate that for
various constraint languages, peek arc consistency gives a polynomial-time
decision procedure for the constraint satisfaction problem. We also present an
algebraic characterization of those constraint languages that can be solved by
peek arc consistency, and study the robustness of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0833</identifier>
 <datestamp>2008-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0833</id><created>2008-09-04</created><authors><author><keyname>Mathieu</keyname><forenames>Fabien</forenames><affiliation>INRIA Rocquencourt, FT R&amp;D, INRIA Rocquencourt</affiliation></author><author><keyname>Postelnicu</keyname><forenames>Gheorghe</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Reynier</keyname><forenames>Julien</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>The stable configuration in acyclic preference-based systems</title><categories>cs.NI</categories><proxy>ccsd inria-00318621</proxy><report-no>RR-6628</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acyclic preferences recently appeared as an elegant way to model many
distributed systems. An acyclic instance admits a unique stable configuration,
which can reveal the performance of the system. In this paper, we give the
statistical properties of the stable configuration for three classes of acyclic
preferences: node-based preferences, distance-based preferences, and random
acyclic systems. Using random overlay graphs, we prove using mean-field and
fluid-limit techniques that these systems have an asymptotically continuous
independent rank distribution for a proper scaling, and the analytical solution
is compared to simulations. These results provide a theoretical ground for
validating the performance of bandwidth-based or proximity-based unstructured
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0835</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0835</id><created>2008-09-04</created><updated>2010-03-13</updated><authors><author><keyname>Bringmann</keyname><forenames>Karl</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author></authors><title>Approximating the volume of unions and intersections of high-dimensional
  geometric objects</title><categories>cs.CG cs.NE</categories><comments>16 pages, To appear in Computational Geometry - Theory and
  Applications</comments><journal-ref>Computational Geometry: Theory and Applications, Vol. 43, No. 6-7,
  pages 601-610, 2010</journal-ref><doi>10.1016/j.comgeo.2010.03.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the computation of the volume of the union of high-dimensional
geometric objects. While showing that this problem is #P-hard already for very
simple bodies (i.e., axis-parallel boxes), we give a fast FPRAS for all objects
where one can: (1) test whether a given point lies inside the object, (2)
sample a point uniformly, (3) calculate the volume of the object in polynomial
time. All three oracles can be weak, that is, just approximate. This implies
that Klee's measure problem and the hypervolume indicator can be approximated
efficiently even though they are #P-hard and hence cannot be solved exactly in
time polynomial in the number of dimensions unless P=NP. Our algorithm also
allows to approximate efficiently the volume of the union of convex bodies
given by weak membership oracles.
  For the analogous problem of the intersection of high-dimensional geometric
objects we prove #P-hardness for boxes and show that there is no multiplicative
polynomial-time $2^{d^{1-\epsilon}}$-approximation for certain boxes unless
NP=BPP, but give a simple additive polynomial-time $\epsilon$-approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0840</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0840</id><created>2008-09-04</created><updated>2009-02-09</updated><authors><author><keyname>Chekanov</keyname><forenames>S.</forenames></author></authors><title>HEP data analysis using jHepWork and Java</title><categories>cs.CE hep-ex hep-ph</categories><comments>5 pages, Proceedings of the HERA-LHC workshops (2007-2008), DESY-CERN</comments><report-no>ANL-HEP-CP-08-53</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A role of Java in high-energy physics and recent progress in development of a
platform-independent data-analysis framework, jHepWork, is discussed. The
framework produces professional graphics and has many libraries for data
manipulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0853</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0853</id><created>2008-09-04</created><updated>2009-04-22</updated><authors><author><keyname>Nguyen</keyname><forenames>XuanLong</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>Estimating divergence functionals and the likelihood ratio by convex
  risk minimization</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>28 pages</comments><journal-ref>IEEE Transactions on Information Theory, 56(11), 5847--5861, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop and analyze $M$-estimation methods for divergence functionals and
the likelihood ratios of two probability distributions. Our method is based on
a non-asymptotic variational characterization of $f$-divergences, which allows
the problem of estimating divergences to be tackled via convex empirical risk
optimization. The resulting estimators are simple to implement, requiring only
the solution of standard convex programs. We present an analysis of consistency
and convergence for these estimators. Given conditions only on the ratios of
densities, we show that our estimators can achieve optimal minimax rates for
the likelihood ratio and the divergence functionals in certain regimes. We
derive an efficient optimization algorithm for computing our estimates, and
illustrate their convergence behavior and practical viability by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0874</identifier>
 <datestamp>2008-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0874</id><created>2008-09-04</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>Between the Information Economy and Student Recruitment: Present
  Conjuncture and Future Prospects</title><categories>cs.CY cs.GL</categories><comments>18 pages, 4 figures</comments><acm-class>K.0; K.1; K.3.0; K.4.3; K.7.0</acm-class><journal-ref>CEPIS UPGRADE, vol. IX, no. 5, pp. 56-64, Oct. 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In university programs and curricula, in general we react to the need to meet
market needs. We respond to market stimulus, or at least try to do so. Consider
now an inverted view. Consider our data and perspectives in university programs
as reflecting and indeed presaging economic trends. In this article I pursue
this line of thinking. I show how various past events fit very well into this
new view. I provide explanation for why some technology trends happened as they
did, and why some current developments are important now.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0884</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0884</id><created>2008-09-04</created><authors><author><keyname>Risch</keyname><forenames>John S.</forenames></author></authors><title>On the role of metaphor in information visualization</title><categories>cs.HC cs.GR</categories><comments>20 pages, with figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of metaphor, in particular graphical (or visual) metaphor, is
central to the field of information visualization. Information graphics and
interactive information visualization systems employ a variety of metaphorical
devices to make abstract, complex, voluminous, or otherwise
difficult-to-comprehend information understandable in graphical terms. This
paper explores the use of metaphor in information visualization, advancing the
theory previously argued by Johnson, Lakoff, Tversky et al. that many
information graphics are metaphorically understood in terms of cognitively
entrenched spatial patterns known as image schemas. These patterns serve to
structure and constrain abstract reasoning processes via metaphorical
projection operations that are grounded in everyday perceptual experiences with
phenomena such as containment, movement, and force dynamics. Building on
previous research, I argue that information graphics promote comprehension of
their target information through the use of graphical patterns that invoke
these preexisting schematic structures. I further theorize that the degree of
structural alignment of a particular graphic with one or more corresponding
image schemas accounts for its perceived degree of intuitiveness. Accordingly,
image schema theory can provide a powerful explanatory and predictive framework
for visualization research. I review relevant theories of analogy and metaphor,
and discuss the image schematic properties of several common types of
information graphic. I conclude with the proposal that the inventory of image
schemas culled from linguistic studies can serve as the basis for an inventory
of design elements suitable for developing intuitive and effective new
information visualization techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0908</identifier>
 <datestamp>2009-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0908</id><created>2008-09-04</created><updated>2009-03-02</updated><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author></authors><title>Reduced Complexity Demodulation and Equalization Scheme for Differential
  Impulse Radio UWB Systems with ISI</title><categories>cs.IT math.IT</categories><comments>Camera ready version. Several typos in the previous version have been
  fixed</comments><journal-ref>Proceeding of the IEEE Sarnoff Symposium, Princeton NJ, March 30 -
  April 1, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the demodulation and equalization problem of
differential Impulse Radio (IR) Ultra-WideBand (UWB) Systems with
Inter-Symbol-Interference (ISI). The differential IR UWB systems have been
extensively discussed recently. The advantage of differential IR UWB systems
include simple receiver frontend structure. One challenge in the demodulation
and equalization of such systems with ISI is that the systems have a rather
complex model. The input and output signals of the systems follow a
second-order Volterra model. Furthermore, the noise at the output is data
dependent. In this paper, we propose a reduced-complexity joint demodulation
and equalization algorithm. The algorithm is based on reformulating the nearest
neighborhood decoding problem into a mixed quadratic programming and utilizing
a semi-definite relaxation. The numerical results show that the proposed
demodulation and equalization algorithm has low computational complexity, and
at the same time, has almost the same error probability performance compared
with the maximal likelihood decoding algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0916</identifier>
 <datestamp>2015-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0916</id><created>2008-09-04</created><updated>2008-09-23</updated><authors><author><keyname>Turitsyn</keyname><forenames>Konstantin S.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Vucelja</keyname><forenames>Marija</forenames></author></authors><title>Irreversible Monte Carlo Algorithms for Efficient Sampling</title><categories>cond-mat.stat-mech cs.IT math.IT math.PR stat.AP</categories><comments>4 pages, 2 figures</comments><doi>10.1016/j.physd.2010.10.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Equilibrium systems evolve according to Detailed Balance (DB). This principe
guided development of the Monte-Carlo sampling techniques, of which
Metropolis-Hastings (MH) algorithm is the famous representative. It is also
known that DB is sufficient but not necessary. We construct irreversible
deformation of a given reversible algorithm capable of dramatic improvement of
sampling from known distribution. Our transformation modifies transition rates
keeping the structure of transitions intact. To illustrate the general scheme
we design an Irreversible version of Metropolis-Hastings (IMH) and test it on
example of a spin cluster. Standard MH for the model suffers from the critical
slowdown, while IMH is free from critical slowdown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0918</identifier>
 <datestamp>2008-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0918</id><created>2008-09-04</created><authors><author><keyname>Anthapadmanabhan</keyname><forenames>N. Prasanth</forenames></author><author><keyname>Makowski</keyname><forenames>Armand M.</forenames></author></authors><title>Intersecting random graphs and networks with multiple adjacency
  constraints: A simple example</title><categories>cs.IT math.IT math.PR</categories><comments>Submitted to IEEE JSAC issue on Stochastic Geometry and Random Graphs
  for Wireless Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When studying networks using random graph models, one is sometimes faced with
situations where the notion of adjacency between nodes reflects multiple
constraints. Traditional random graph models are insufficient to handle such
situations.
  A simple idea to account for multiple constraints consists in taking the
intersection of random graphs. In this paper we initiate the study of random
graphs so obtained through a simple example. We examine the intersection of an
Erdos-Renyi graph and of one-dimensional geometric random graphs. We
investigate the zero-one laws for the property that there are no isolated
nodes. When the geometric component is defined on the unit circle, a full
zero-one law is established and we determine its critical scaling. When the
geometric component lies in the unit interval, there is a gap in that the
obtained zero and one laws are found to express deviations from different
critical scalings. In particular, the first moment method requires a larger
critical scaling than in the unit circle case in order to obtain the one law.
This discrepancy is somewhat surprising given that the zero-one laws for the
absence of isolated nodes are identical in the geometric random graphs on both
the unit interval and unit circle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0922</identifier>
 <datestamp>2009-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0922</id><created>2008-09-04</created><updated>2009-11-30</updated><authors><author><keyname>Horbach</keyname><forenames>Matthias</forenames></author><author><keyname>Weidenbach</keyname><forenames>Christoph</forenames></author></authors><title>Superposition for Fixed Domains</title><categories>cs.AI cs.LO</categories><comments>34 pages; to appear in ACM Transactions on Computational Logic</comments><acm-class>I.2.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superposition is an established decision procedure for a variety of
first-order logic theories represented by sets of clauses. A satisfiable
theory, saturated by superposition, implicitly defines a minimal term-generated
model for the theory. Proving universal properties with respect to a saturated
theory directly leads to a modification of the minimal model's term-generated
domain, as new Skolem functions are introduced. For many applications, this is
not desired.
  Therefore, we propose the first superposition calculus that can explicitly
represent existentially quantified variables and can thus compute with respect
to a given domain. This calculus is sound and refutationally complete in the
limit for a first-order fixed domain semantics. For saturated Horn theories and
classes of positive formulas, we can even employ the calculus to prove
properties of the minimal model itself, going beyond the scope of known
superposition-based approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0949</identifier>
 <datestamp>2009-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0949</id><created>2008-09-05</created><updated>2009-05-07</updated><authors><author><keyname>Baer</keyname><forenames>Michael B.</forenames></author></authors><title>Efficient Implementation of the Generalized Tunstall Code Generation
  Algorithm</title><categories>cs.IT cs.DS math.IT</categories><comments>5 pages, 5 figures, accepted to ISIT 2009</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method is presented for constructing a Tunstall code that is linear time in
the number of output items. This is an improvement on the state of the art for
non-Bernoulli sources, including Markov sources, which require a (suboptimal)
generalization of Tunstall's algorithm proposed by Savari and analytically
examined by Tabus and Rissanen. In general, if n is the total number of output
leaves across all Tunstall trees, s is the number of trees (states), and D is
the number of leaves of each internal node, then this method takes O((1+(log
s)/D) n) time and O(n) space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0961</identifier>
 <datestamp>2008-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0961</id><created>2008-09-05</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>MOOPPS: An Optimization System for Multi Objective Scheduling</title><categories>cs.AI cs.HC</categories><journal-ref>Proceedings of the Metaheuristics International Conference MIC
  2005, Vienna, Austria, pp. 403-408</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current paper, we present an optimization system solving multi
objective production scheduling problems (MOOPPS). The identification of Pareto
optimal alternatives or at least a close approximation of them is possible by a
set of implemented metaheuristics. Necessary control parameters can easily be
adjusted by the decision maker as the whole software is fully menu driven. This
allows the comparison of different metaheuristic algorithms for the considered
problem instances. Results are visualized by a graphical user interface showing
the distribution of solutions in outcome space as well as their corresponding
Gantt chart representation.
  The identification of a most preferred solution from the set of efficient
solutions is supported by a module based on the aspiration interactive method
(AIM). The decision maker successively defines aspiration levels until a single
solution is chosen.
  After successfully competing in the finals in Ronneby, Sweden, the MOOPPS
software has been awarded the European Academic Software Award 2002
(http://www.bth.se/llab/easa_2002.nsf)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1017</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1017</id><created>2008-09-05</created><authors><author><keyname>Grunwald</keyname><forenames>Peter</forenames></author></authors><title>Entropy Concentration and the Empirical Coding Game</title><categories>cs.IT cs.LG math.IT math.ST stat.ME stat.TH</categories><comments>A somewhat modified version of this paper was published in Statistica
  Neerlandica 62(3), pages 374-392, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a characterization of Maximum Entropy/Minimum Relative Entropy
inference by providing two `strong entropy concentration' theorems. These
theorems unify and generalize Jaynes' `concentration phenomenon' and Van
Campenhout and Cover's `conditional limit theorem'. The theorems characterize
exactly in what sense a prior distribution Q conditioned on a given constraint,
and the distribution P, minimizing the relative entropy D(P ||Q) over all
distributions satisfying the constraint, are `close' to each other. We then
apply our theorems to establish the relationship between entropy concentration
and a game-theoretic characterization of Maximum Entropy Inference due to
Topsoe and others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1019</identifier>
 <datestamp>2008-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1019</id><created>2008-09-05</created><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>Moving and resizing of the screen objects</title><categories>cs.HC</categories><comments>17 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The shape and size of the objects, which we see on the screen, when the
application is running, are defined at the design time. By using some sort of
adaptive interface, developers give users a chance to resize these objects or
on rare occasion even change, but all these changes are predetermined by a
developer; user can't go out of the designer's scenario. Making each and all
elements moveable / resizable and giving users the full control of these
processes, changes the whole idea of applications; programs become user-driven
and significantly increase the effectiveness of users' work. This article is
about the instrument to turn any screen object into moveable / resizable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1039</identifier>
 <datestamp>2008-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1039</id><created>2008-09-05</created><authors><author><keyname>Kittipiyakul</keyname><forenames>Somsak</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author><author><keyname>Javidi</keyname><forenames>Tara</forenames></author></authors><title>High-SNR Analysis of Outage-Limited Communications with Bursty and
  Delay-Limited Information</title><categories>cs.IT math.IT</categories><comments>16 pages, 5 figures, to appear in IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work analyzes the high-SNR asymptotic error performance of
outage-limited communications with fading, where the number of bits that arrive
at the transmitter during any time slot is random but the delivery of bits at
the receiver must adhere to a strict delay limitation. Specifically, bit errors
are caused by erroneous decoding at the receiver or violation of the strict
delay constraint. Under certain scaling of the statistics of the bit-arrival
process with SNR, this paper shows that the optimal decay behavior of the
asymptotic total probability of bit error depends on how fast the burstiness of
the source scales down with SNR. If the source burstiness scales down too
slowly, the total probability of error is asymptotically dominated by
delay-violation events. On the other hand, if the source burstiness scales down
too quickly, the total probability of error is asymptotically dominated by
channel-error events. However, at the proper scaling, where the burstiness
scales linearly with 1/sqrt(log SNR) and at the optimal coding duration and
transmission rate, the occurrences of channel errors and delay-violation errors
are asymptotically balanced. In this latter case, the optimal exponent of the
total probability of error reveals a tradeoff that addresses the question of
how much of the allowable time and rate should be used for gaining reliability
over the channel and how much for accommodating the burstiness with delay
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1043</identifier>
 <datestamp>2008-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1043</id><created>2008-09-05</created><authors><author><keyname>Dalai</keyname><forenames>Marco</forenames></author><author><keyname>Leonardi</keyname><forenames>Riccardo</forenames></author></authors><title>On Unique Decodability</title><categories>cs.IT math.IT</categories><comments>Accepted for publication, IEEE Transactions on Information Theory</comments><msc-class>94A45; 94A29; 94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a revisitation of the topic of unique decodability
and of some fundamental theorems of lossless coding. It is widely believed
that, for any discrete source X, every &quot;uniquely decodable&quot; block code
satisfies E[l(X_1 X_2 ... X_n)]&gt;= H(X_1,X_2,...,X_n), where X_1, X_2,...,X_n
are the first n symbols of the source, E[l(X_1 X_2 ... X_n)] is the expected
length of the code for those symbols and H(X_1,X_2,...,X_n) is their joint
entropy. We show that, for certain sources with memory, the above inequality
only holds when a limiting definition of &quot;uniquely decodable code&quot; is
considered. In particular, the above inequality is usually assumed to hold for
any &quot;practical code&quot; due to a debatable application of McMillan's theorem to
sources with memory. We thus propose a clarification of the topic, also
providing an extended version of McMillan's theorem to be used for Markovian
sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1053</identifier>
 <datestamp>2009-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1053</id><created>2008-09-05</created><updated>2009-07-10</updated><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>An impossibility result for process discrimination</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><proxy>ccsd inria-00319076</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two series of binary observations $x_1,x_1,...$ and $y_1,y_2,...$ are
presented: at each time $n\in\N$ we are given $x_n$ and $y_n$. It is assumed
that the sequences are generated independently of each other by two
B-processes. We are interested in the question of whether the sequences
represent a typical realization of two different processes or of the same one.
We demonstrate that this is impossible to decide, in the sense that every
discrimination procedure is bound to err with non-negligible frequency when
presented with sequences from some B-processes. This contrasts earlier positive
results on B-processes, in particular those showing that there are consistent
$\bar d$-distance estimates for this class of processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1061</identifier>
 <datestamp>2008-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1061</id><created>2008-09-05</created><authors><author><keyname>Laddomada</keyname><forenames>M.</forenames></author><author><keyname>Mesiti</keyname><forenames>F.</forenames></author><author><keyname>Mondin</keyname><forenames>M.</forenames></author><author><keyname>Daneshgaran</keyname><forenames>F.</forenames></author></authors><title>A Novel Proportional Fairness Criterion for Throughput Allocation in
  Multirate IEEE 802.11</title><categories>cs.NI</categories><comments>Submitted to IEEE Transaction on Wireless Communications, September
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on multirate IEEE 802.11 Wireless LAN employing the
mandatory Distributed Coordination Function (DCF) option. Its aim is threefold.
Upon starting from the multi-dimensional Markovian state transition model
proposed by Malone \textit{et.al.} for characterizing the behavior of the IEEE
802.11 protocol at the Medium Access Control layer, it presents an extension
accounting for packet transmission failures due to channel errors. Second, it
establishes the conditions under which a network constituted by $N$ stations,
each station transmitting with its own bit rate, $R^{(s)}_d$, and packet rate,
$\lambda_s$, can be assumed loaded. Finally, it proposes a modified
Proportional Fairness (PF) criterion, suitable for mitigating the \textit{rate
anomaly} problem of multirate loaded IEEE 802.11 Wireless LANs, employing the
mandatory DCF option. Compared to the widely adopted assumption of saturated
network, the proposed fairness criterion can be applied to general loaded
networks.
  The throughput allocation resulting from the proposed algorithm is able to
greatly increase the aggregate throughput of the DCF, while ensuring fairness
levels among the stations of the same order as the ones guaranteed by the
classical PF criterion.
  Simulation results are presented for some sample scenarios, confirming the
effectiveness of the proposed criterion for optimized throughput allocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1077</identifier>
 <datestamp>2008-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1077</id><created>2008-09-05</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author><author><keyname>Wenger</keyname><forenames>Wolf</forenames></author></authors><title>Variable Neighborhood Search for the University Lecturer-Student
  Assignment Problem</title><categories>cs.AI</categories><comments>Proceedings of the 18th Mini Euro Conference on Variable Neighborhood
  Search, November 23-25, 2005, Puerto de La Cruz, Tenerife, Spain, ISBN
  84-689-5679-1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a study of local search heuristics in general and variable
neighborhood search in particular for the resolution of an assignment problem
studied in the practical work of universities. Here, students have to be
assigned to scientific topics which are proposed and supported by members of
staff. The problem involves the optimization under given preferences of
students which may be expressed when applying for certain topics.
  It is possible to observe that variable neighborhood search leads to superior
results for the tested problem instances. One instance is taken from an actual
case, while others have been generated based on the real world data to support
the analysis with a deeper analysis.
  An extension of the problem has been formulated by integrating a second
objective function that simultaneously balances the workload of the members of
staff while maximizing utility of the students. The algorithmic approach has
been prototypically implemented in a computer system. One important aspect in
this context is the application of the research work to problems of other
scientific institutions, and therefore the provision of decision support
functionalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1132</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1132</id><created>2008-09-06</created><authors><author><keyname>Berten</keyname><forenames>Vandy</forenames></author><author><keyname>Chang</keyname><forenames>Chi-Ju</forenames></author><author><keyname>Kuo</keyname><forenames>Tei-Wei</forenames></author></authors><title>Managing Varying Worst Case Execution Times on DVS Platforms</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficient real-time task scheduling attracted a lot of attention in
the past decade. Most of the time, deterministic execution lengths for tasks
were considered, but this model fits less and less with the reality, especially
with the increasing number of multimedia applications. It's why a lot of
research is starting to consider stochastic models, where execution times are
only known stochastically. However, authors consider that they have a pretty
much precise knowledge about the properties of the system, especially regarding
to the worst case execution time (or worst case execution cycles, WCEC).
  In this work, we try to relax this hypothesis, and assume that the WCEC can
vary. We propose miscellaneous methods to react to such a situation, and give
many simulation results attesting that with a small effort, we can provide very
good results, allowing to keep a low deadline miss rate as well as an energy
consumption similar to clairvoyant algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1138</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1138</id><created>2008-09-06</created><authors><author><keyname>Feigel</keyname><forenames>Alexander</forenames></author><author><keyname>Englander</keyname><forenames>Avraham</forenames></author><author><keyname>Engel</keyname><forenames>Assaf</forenames></author></authors><title>Derivation of evolutionary payoffs from observable behavior</title><categories>q-bio.PE cs.GT physics.soc-ph</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interpretation of animal behavior, especially as cooperative or selfish, is a
challenge for evolutionary theory. Strategy of a competition should follow from
corresponding Darwinian payoffs for the available behavioral options. The
payoffs and decision making processes, however, are difficult to observe and
quantify. Here we present a general method for the derivation of evolutionary
payoffs from observable statistics of interactions. The method is applied to
combat of male bowl and doily spiders, to predator inspection by sticklebacks
and to territorial defense by lions, demonstrating animal behavior as a new
type of game theoretical equilibrium. Games animals play may be derived
unequivocally from their observable behavior, the reconstruction, however, can
be subjected to fundamental limitations due to our inability to observe all
information exchange mechanisms (communication).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1171</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1171</id><created>2008-09-06</created><authors><author><keyname>Luo</keyname><forenames>Cheng-Wei</forenames></author><author><keyname>Liu</keyname><forenames>Hsiao-Fei</forenames></author><author><keyname>Chen</keyname><forenames>Peng-An</forenames></author><author><keyname>Chao</keyname><forenames>Kun-Mao</forenames></author></authors><title>Minkowski Sum Selection and Finding</title><categories>cs.DS cs.CG</categories><comments>23 pages, 10 figures, accepted by ISAAC 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the \textsc{Minkowski Sum Selection} problem with linear objective
functions, we obtain the following results: (1) optimal $O(n\log n)$ time
algorithms for $\lambda=1$; (2) $O(n\log^2 n)$ time deterministic algorithms
and expected $O(n\log n)$ time randomized algorithms for any fixed $\lambda&gt;1$.
For the \textsc{Minkowski Sum Finding} problem with linear objective functions
or objective functions of the form
  $f(x,y)=\frac{by}{ax}$, we construct optimal $O(n\log n)$ time algorithms for
any fixed $\lambda\geq 1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1177</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1177</id><created>2008-09-06</created><authors><author><keyname>Karbowski</keyname><forenames>Andrzej</forenames></author></authors><title>Amdahl's and Gustafson-Barsis laws revisited</title><categories>cs.DC cs.GT cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a simple derivation of the Gustafson-Barsis law from the
Amdahl's law. In the computer literature these two laws describing the speedup
limits of parallel applications are derived separately. It is shown, that
treating the time of the execution of the sequential part of the application as
a constant, in few lines the Gustafson-Barsis law can be obtained from the
Amdahl's law and that the popular claim, that Gustafson-Barsis law overthrows
Amdahl's law is a mistake.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1181</identifier>
 <datestamp>2009-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1181</id><created>2008-09-06</created><updated>2009-01-16</updated><authors><author><keyname>Gu</keyname><forenames>Yunhong</forenames></author><author><keyname>Grossman</keyname><forenames>Robert L</forenames></author></authors><title>Sector and Sphere: Towards Simplified Storage and Processing of Large
  Scale Distributed Data</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing has demonstrated that processing very large datasets over
commodity clusters can be done simply given the right programming model and
infrastructure. In this paper, we describe the design and implementation of the
Sector storage cloud and the Sphere compute cloud. In contrast to existing
storage and compute clouds, Sector can manage data not only within a data
center, but also across geographically distributed data centers. Similarly, the
Sphere compute cloud supports User Defined Functions (UDF) over data both
within a data center and across data centers. As a special case, MapReduce
style programming can be implemented in Sphere by using a Map UDF followed by a
Reduce UDF. We describe some experimental studies comparing Sector/Sphere and
Hadoop using the Terasort Benchmark. In these studies, Sector is about twice as
fast as Hadoop. Sector/Sphere is open source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1205</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1205</id><created>2008-09-06</created><updated>2009-07-07</updated><authors><author><keyname>Xie</keyname><forenames>Liang-Liang</forenames></author></authors><title>On Information-Theoretic Scaling Laws for Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the analysis of the hierarchical scheme, the potential influence of the
pre-constant in deriving scaling laws is exposed. It is found that a modified
hierarchical scheme can achieve a throughput arbitrarily times higher than the
original one, although it is still diminishingly small compared to the linear
scaling. The study demonstrates the essential importance of the throughput
formula itself, rather than the scaling laws consequently derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1208</identifier>
 <datestamp>2009-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1208</id><created>2008-09-08</created><updated>2009-06-03</updated><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Bounds on the Capacity of the Relay Channel with States at the Source</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1226</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1226</id><created>2008-09-07</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author></authors><title>Applications of Universal Source Coding to Statistical Analysis of Time
  Series</title><categories>cs.IT cs.AI math.IT math.ST stat.TH</categories><comments>accepted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how universal codes can be used for solving some of the most
important statistical problems for time series. By definition, a universal code
(or a universal lossless data compressor) can compress any sequence generated
by a stationary and ergodic source asymptotically to the Shannon entropy,
which, in turn, is the best achievable ratio for lossless data compressors.
  We consider finite-alphabet and real-valued time series and the following
problems: estimation of the limiting probabilities for finite-alphabet time
series and estimation of the density for real-valued time series, the on-line
prediction, regression, classification (or problems with side information) for
both types of the time series and the following problems of hypothesis testing:
goodness-of-fit testing, or identity testing, and testing of serial
independence. It is important to note that all problems are considered in the
framework of classical mathematical statistics and, on the other hand, everyday
methods of data compression (or archivers) can be used as a tool for the
estimation and testing. It turns out, that quite often the suggested methods
and tests are more powerful than known ones when they are applied in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1236</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1236</id><created>2008-09-07</created><updated>2010-01-17</updated><authors><author><keyname>Ganty</keyname><forenames>Pierre</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author><author><keyname>Monmege</keyname><forenames>Benjamin</forenames></author></authors><title>Bounded Underapproximations</title><categories>cs.LO</categories><comments>30 pages, 2 figures, v4 added complexity results, various
  improvements</comments><journal-ref>Formal Methods in System Design 40(2) (2012) 206-231</journal-ref><doi>10.1007/s10703-011-0136-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a new and constructive proof of the following language-theoretic
result: for every context-free language L, there is a bounded context-free
language L' included in L which has the same Parikh (commutative) image as L.
Bounded languages, introduced by Ginsburg and Spanier, are subsets of regular
languages of the form w1*w2*...wk* for some finite words w1,...,wk. In
particular bounded subsets of context-free languages have nice structural and
decidability properties. Our proof proceeds in two parts. First, using Newton's
iterations on the language semiring, we construct a context-free subset Ls of L
that can be represented as a sequence of substitutions on a linear language and
has the same Parikh image as L. Second, we inductively construct a
Parikh-equivalent bounded context-free subset of Ls.
  We show two applications of this result in model checking: to
underapproximate the reachable state space of multithreaded procedural programs
and to underapproximate the reachable state space of recursive counter
programs. The bounded language constructed above provides a decidable
underapproximation for the original problems. By iterating the construction, we
get a semi-algorithm for the original problems that constructs a sequence of
underapproximations such that no two underapproximations of the sequence can be
compared. This provides a progress guarantee: every word w in L is in some
underapproximation of the sequence. In addition, we show that our approach
subsumes context-bounded reachability for multithreaded programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1241</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1241</id><created>2008-09-08</created><updated>2012-12-04</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>A New Framework of Multistage Estimation</title><categories>math.ST cs.LG math.PR stat.ME stat.TH</categories><comments>254 pages, no figure; added more references; main results appeared in
  Proceedings of SPIE, Orlando, Florida, USA, April 2010 and 2011</comments><doi>10.1103/PhysRevE.79.026307</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have established a unified framework of multistage
parameter estimation. We demonstrate that a wide variety of statistical
problems such as fixed-sample-size interval estimation, point estimation with
error control, bounded-width confidence intervals, interval estimation
following hypothesis testing, construction of confidence sequences, can be cast
into the general framework of constructing sequential random intervals with
prescribed coverage probabilities. We have developed exact methods for the
construction of such sequential random intervals in the context of multistage
sampling. In particular, we have established inclusion principle and coverage
tuning techniques to control and adjust the coverage probabilities of
sequential random intervals. We have obtained concrete sampling schemes which
are unprecedentedly efficient in terms of sampling effort as compared to
existing procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1252</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1252</id><created>2008-09-07</created><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Rocha</keyname><forenames>Valdemar Cardoso da</forenames><suffix>Jr.</suffix></author><author><keyname>Pimentel</keyname><forenames>Cecilio</forenames></author></authors><title>Maximum Entropy Rate of Markov Sources for Systems With Non-regular
  Constraints</title><categories>cs.IT math.IT</categories><comments>5 pages, to presented at the ISITA 2008 in Auckland, NZ</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the concept of discrete noiseless channels, it was shown by Shannon in
A Mathematical Theory of Communication that the ultimate performance of an
encoder for a constrained system is limited by the combinatorial capacity of
the system if the constraints define a regular language. In the present work,
it is shown that this is not an inherent property of regularity but holds in
general. To show this, constrained systems are described by generating
functions and random walks on trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1257</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1257</id><created>2008-09-07</created><authors><author><keyname>Daubechies</keyname><forenames>I.</forenames></author><author><keyname>G&#xfc;nt&#xfc;rk</keyname><forenames>C. S.</forenames></author><author><keyname>Wang</keyname><forenames>Y.</forenames></author><author><keyname>Yilmaz</keyname><forenames>&#xd6;.</forenames></author></authors><title>The Golden Ratio Encoder</title><categories>cs.IT math.IT</categories><comments>24 pages, 9 figures</comments><msc-class>41A99, 94C99</msc-class><doi>10.1109/TIT.2010.2059750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel Nyquist-rate analog-to-digital (A/D) conversion
algorithm which achieves exponential accuracy in the bit-rate despite using
imperfect components. The proposed algorithm is based on a robust
implementation of a beta-encoder where the value of the base beta is equal to
golden mean. It was previously shown that beta-encoders can be implemented in
such a way that their exponential accuracy is robust against threshold offsets
in the quantizer element. This paper extends this result by allowing for
imperfect analog multipliers with imprecise gain values as well. A formal
computational model for algorithmic encoders and a general test bed for
evaluating their robustness is also proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1258</identifier>
 <datestamp>2008-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1258</id><created>2008-09-07</created><updated>2008-12-21</updated><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author></authors><title>Network Protection Codes Against Link Failures Using Network Coding</title><categories>cs.IT cs.NI math.IT</categories><journal-ref>Proc. of IEEE Globecom 08, New Orleans, LA, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protecting against link failures in communication networks is essential to
increase robustness, accessibility, and reliability of data transmission.
Recently, network coding has been proposed as a solution to provide agile and
cost efficient network protection against link failures, which does not require
data rerouting, or packet retransmission. To achieve this, separate paths have
to be provisioned to carry encoded packets, hence requiring either the addition
of extra links, or reserving some of the resources for this purpose. In this
paper, we propose network protection codes against a single link failure using
network coding, where a separate path using reserved links is not needed. In
this case portions of the link capacities are used to carry the encoded
packets.
  The scheme is extended to protect against multiple link failures and can be
implemented at an overlay layer. Although this leads to reducing the network
capacity, the network capacity reduction is asymptotically small in most cases
of practical interest. We demonstrate that such network protection codes are
equivalent to error correcting codes for erasure channels. Finally, we study
the encoding and decoding operations of such codes over the binary field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1264</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1264</id><created>2008-09-07</created><authors><author><keyname>Baer</keyname><forenames>Michael</forenames></author></authors><title>Tight Bounds on Minimum Maximum Pointwise Redundancy</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, presented at ISIT 2008</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new lower and upper bounds for the optimal compression of
binary prefix codes in terms of the most probable input symbol, where
compression efficiency is determined by the nonlinear codeword length objective
of minimizing maximum pointwise redundancy. This objective relates to both
universal modeling and Shannon coding, and these bounds are tight throughout
the interval. The upper bounds also apply to a related objective, that of dth
exponential redundancy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1270</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1270</id><created>2008-09-08</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Predictive Hypothesis Identification</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While statistics focusses on hypothesis testing and on estimating (properties
of) the true sampling distribution, in machine learning the performance of
learning algorithms on future data is the primary issue. In this paper we
bridge the gap with a general principle (PHI) that identifies hypotheses with
best predictive performance. This includes predictive point and interval
estimation, simple and composite hypothesis testing, (mixture) model selection,
and others as special cases. For concrete instantiations we will recover
well-known methods, variations thereof, and new ones. PHI nicely justifies,
reconciles, and blends (a reparametrization invariant variation of) MAP, ML,
MDL, and moment estimation. One particular feature of PHI is that it can
genuinely deal with nested hypotheses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1300</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1300</id><created>2008-09-08</created><authors><author><keyname>Sayir</keyname><forenames>Jossy</forenames></author></authors><title>What makes a good role model</title><categories>cs.IT math.IT</categories><comments>This paper is dedicated to Jim Massey on the occasion of his 75th
  birthday. Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The role model strategy is introduced as a method for designing an estimator
by approaching the output of a superior estimator that has better input
observations. This strategy is shown to yield the optimal Bayesian estimator
when a Markov condition is fulfilled. Two examples involving simple channels
are given to illustrate its use. The strategy is combined with time averaging
to construct a statistical model by numerically solving a convex program. The
role model strategy was developed in the context of low complexity decoder
design for iterative decoding. Potential applications outside the field of
communications are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1318</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1318</id><created>2008-09-08</created><authors><author><keyname>Al-saggaf</keyname><forenames>Alawi A.</forenames></author><author><keyname>Acharya</keyname><forenames>H. S.</forenames></author></authors><title>A Fuzzy Commitment Scheme</title><categories>cs.CR</categories><comments>4 pages, IEEE International Conference on Advances in Computer Vision
  and Information Technology 28-30 November 2007 - India</comments><acm-class>D.4.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper attempt has been made to explain a fuzzy commitment scheme. In the
conventional Commitment schemes, both committed string m and valid opening key
are required to enable the sender to prove the commitment. However there could
be many instances where the transmission involves noise or minor errors arising
purely because of the factors over which neither the sender nor the receiver
have any control. The fuzzy commitment scheme presented in this paper is to
accept the opening key that is close to the original one in suitable distance
metric, but not necessarily identical. The concept itself is illustrated with
the help of simple situation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1330</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1330</id><created>2008-09-08</created><authors><author><keyname>Maierbacher</keyname><forenames>G.</forenames></author><author><keyname>Barros</keyname><forenames>J.</forenames></author></authors><title>Low-Complexity Coding and Source-Optimized Clustering for Large-Scale
  Sensor Networks</title><categories>cs.IT math.IT</categories><comments>26 pages</comments><acm-class>E.4; H.1.1; E.1; G.3; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the distributed source coding problem in which correlated data
picked up by scattered sensors has to be encoded separately and transmitted to
a common receiver, subject to a rate-distortion constraint. Although
near-tooptimal solutions based on Turbo and LDPC codes exist for this problem,
in most cases the proposed techniques do not scale to networks of hundreds of
sensors. We present a scalable solution based on the following key elements:
(a) distortion-optimized index assignments for low-complexity distributed
quantization, (b) source-optimized hierarchical clustering based on the
Kullback-Leibler distance and (c) sum-product decoding on specific factor
graphs exploiting the correlation of the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1344</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1344</id><created>2008-09-08</created><updated>2010-01-21</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>The Balanced Unicast and Multicast Capacity Regions of Large Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>37 pages, 7 figures, to appear in IEEE Transactions on Information
  Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 56, pp. 2249-2271,
  May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the question of determining the scaling of the $n^2$-dimensional
balanced unicast and the $n 2^n$-dimensional balanced multicast capacity
regions of a wireless network with $n$ nodes placed uniformly at random in a
square region of area $n$ and communicating over Gaussian fading channels. We
identify this scaling of both the balanced unicast and multicast capacity
regions in terms of $\Theta(n)$, out of $2^n$ total possible, cuts. These cuts
only depend on the geometry of the locations of the source nodes and their
destination nodes and the traffic demands between them, and thus can be readily
evaluated. Our results are constructive and provide optimal (in the scaling
sense) communication schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1348</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1348</id><created>2008-09-08</created><authors><author><keyname>Hehn</keyname><forenames>Thorsten</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author><author><keyname>Laendner</keyname><forenames>Stefan</forenames></author></authors><title>MBBP for improved iterative channel decoding in 802.16e WiMAX systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to IEEE ICC 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the application of multiple-bases belief-propagation, an optimized
iterative decoding method, to a set of rate-1/2 LDPC codes from the IEEE
802.16e WiMAX standard. The presented approach allows for improved decoding
performance when signaling over the AWGN channel. As all required operations
for this method can be run in parallel, the decoding delay of this method and
standard belief-propagation decoding are equal. The obtained results are
compared to the performance of LDPC codes optimized with the progressive
edge-growth algorithm and to bounds from information theory. It will be shown
that the discussed method mitigates the gap to the well-known random coding
bound by about 20 percent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1366</identifier>
 <datestamp>2008-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1366</id><created>2008-09-08</created><authors><author><keyname>Lima</keyname><forenames>Lu&#xed;sa</forenames></author><author><keyname>Vilela</keyname><forenames>Jo&#xe3;o P.</forenames></author><author><keyname>Oliveira</keyname><forenames>Paulo F.</forenames></author><author><keyname>Barros</keyname><forenames>Jo&#xe3;o</forenames></author></authors><title>Network Coding Security: Attacks and Countermeasures</title><categories>cs.CR cs.IT cs.NI math.IT</categories><comments>8 pages, 4 figures</comments><acm-class>C.2.1; C.2.2; E.3; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By allowing intermediate nodes to perform non-trivial operations on packets,
such as mixing data from multiple streams, network coding breaks with the
ruling store and forward networking paradigm and opens a myriad of challenging
security questions. Following a brief overview of emerging network coding
protocols, we provide a taxonomy of their security vulnerabilities, which
highlights the differences between attack scenarios in which network coding is
particularly vulnerable and other relevant cases in which the intrinsic
properties of network coding allow for stronger and more efficient security
solutions than classical routing. Furthermore, we give practical examples where
network coding can be combined with classical cryptography both for secure
communication and secret key distribution. Throughout the paper we identify a
number of research challenges deemed relevant towards the applicability of
secure network coding in practical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1379</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1379</id><created>2008-09-08</created><updated>2009-01-30</updated><authors><author><keyname>Costa</keyname><forenames>Rui A.</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>A Max-Flow Min-Cut Theorem with Applications in Small Worlds and Dual
  Radio Networks</title><categories>cs.IT cs.DM math.IT</categories><comments>22 pages, 4 figures, Submitted to JSAC Special Issue on Stochastic
  Geometry and Random Graphs for Wireless Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intrigued by the capacity of random networks, we start by proving a max-flow
min-cut theorem that is applicable to any random graph obeying a suitably
defined independence-in-cut property. We then show that this property is
satisfied by relevant classes, including small world topologies, which are
pervasive in both man-made and natural networks, and wireless networks of dual
devices, which exploit multiple radio interfaces to enhance the connectivity of
the network. In both cases, we are able to apply our theorem and derive
max-flow min-cut bounds for network information flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1398</identifier>
 <datestamp>2010-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1398</id><created>2008-09-08</created><updated>2010-04-29</updated><authors><author><keyname>Mungan</keyname><forenames>Muhittin</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose J.</forenames></author></authors><title>Stability of Maximum likelihood based clustering methods: exploring the
  backbone of classifications (Who is keeping you in that community?)</title><categories>physics.soc-ph cond-mat.stat-mech cs.IT math.IT physics.comp-ph physics.data-an</categories><comments>19 pages, 9 figures</comments><journal-ref>J. Stat. Mech. (2010) P04028</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Components of complex systems are often classified according to the way they
interact with each other. In graph theory such groups are known as clusters or
communities. Many different techniques have been recently proposed to detect
them, some of which involve inference methods using either Bayesian or Maximum
Likelihood approaches. In this article, we study a statistical model designed
for detecting clusters based on connection similarity. The basic assumption of
the model is that the graph was generated by a certain grouping of the nodes
and an Expectation Maximization algorithm is employed to infer that grouping.
We show that the method admits further development to yield a stability
analysis of the groupings that quantifies the extent to which each node
influences its neighbors group membership. Our approach naturally allows for
the identification of the key elements responsible for the grouping and their
resilience to changes in the network. Given the generality of the assumptions
underlying the statistical model, such nodes are likely to play special roles
in the original system. We illustrate this point by analyzing several empirical
networks for which further information about the properties of the nodes is
available. The search and identification of stabilizing nodes constitutes thus
a novel technique to characterize the relevance of nodes in complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1409</identifier>
 <datestamp>2008-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1409</id><created>2008-09-08</created><authors><author><keyname>Sinha</keyname><forenames>Anshuman</forenames></author><author><keyname>Nandela</keyname><forenames>Haritha</forenames></author><author><keyname>Balakrishna</keyname><forenames>Vijaya</forenames></author></authors><title>Domain Specific Software Architecture for Design Center Automation</title><categories>cs.SE</categories><comments>158 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domain specific software architecture aims at software reuse through
construction of domain architecture reference model. The constructed reference
model presents a set of individual components and their interaction points.
When starting on a new large software project, the design engineer starts with
pre-constructed model, which can be easily browsed and picks up opportunities
of use in the new solution design. This report discusses application of domain
reference design methods by deriving domain specific reference architecture for
a product ordering system in a design center. The product in this case is
instock and special order blinds from different manufacturers in a large supply
store. The development of mature domain specific reference software
architecture for this domain is not the objective of this report. However, this
report would like to capture the method used in one such process and that is
the primary concern of this report. This report lists subjective details of
such a process applied to the domain of ordering custom and instock blinds from
a large home construction and goods supply store. This report also describes
the detailed process of derivation of knowledge models, unified knowledge
models and the reference architecture for this domain. However, this domain
model is only partially complete which may not be used for any real
applications. This report is a result of a course project undertaken while
studying this methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1437</identifier>
 <datestamp>2008-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1437</id><created>2008-09-09</created><authors><author><keyname>Georgatos</keyname><forenames>Fotis</forenames></author></authors><title>How applicable is Python as first computer language for teaching
  programming in a pre-university educational environment, from a teacher's
  point of view?</title><categories>cs.PL cs.CY</categories><comments>135 pages, 20 tables, 10 figures (incl. evolution of computer
  languages)</comments><acm-class>D.3; K.3.2; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This project report attempts to evaluate the educational properties of the
Python computer language, in practice. This is done by examining computer
language evolution history, related scientific background work, the existing
educational research on computer languages and Python's experimental
application in higher secondary education in Greece, during first half of year
2002. This Thesis Report was delivered in advance of a thesis defense for a
Masters/Doctorandus (MSc/Drs) title with the Amstel Institute/Universiteit van
Amsterdam, during the same year.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1465</identifier>
 <datestamp>2008-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1465</id><created>2008-09-08</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Probabilistic Systems with LimSup and LimInf Objectives</title><categories>cs.GT cs.LO</categories><comments>The paper will appear in ILC proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give polynomial-time algorithms for computing the values of Markov
decision processes (MDPs) with limsup and liminf objectives. A real-valued
reward is assigned to each state, and the value of an infinite path in the MDP
is the limsup (resp. liminf) of all rewards along the path. The value of an MDP
is the maximal expected value of an infinite path that can be achieved by
resolving the decisions of the MDP. Using our result on MDPs, we show that
turn-based stochastic games with limsup and liminf objectives can be solved in
NP \cap coNP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1476</identifier>
 <datestamp>2008-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1476</id><created>2008-09-08</created><authors><author><keyname>Feng</keyname><forenames>Yong</forenames></author><author><keyname>Zhang</keyname><forenames>Jingzhong</forenames></author><author><keyname>Qin</keyname><forenames>Xiaolin</forenames></author><author><keyname>Yuan</keyname><forenames>Xun</forenames></author></authors><title>Obtaining Exact Interpolation Multivariate Polynomial by Approximation</title><categories>cs.SC cs.CG</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In some fields such as Mathematics Mechanization, automated reasoning and
Trustworthy Computing etc., exact results are needed. Symbolic computations are
used to obtain the exact results. Symbolic computations are of high complexity.
In order to improve the situation, exactly interpolating methods are often
proposed for the exact results and approximate interpolating methods for the
approximate ones. In this paper, we study how to obtain exact interpolation
polynomial with rational coefficients by approximate interpolating methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1489</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1489</id><created>2008-09-09</created><authors><author><keyname>Flor&#xe9;en</keyname><forenames>Patrik</forenames></author><author><keyname>Kaasinen</keyname><forenames>Joel</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Suomela</keyname><forenames>Jukka</forenames></author></authors><title>An optimal local approximation algorithm for max-min linear programs</title><categories>cs.DC</categories><comments>16 pages, 3 figures</comments><doi>10.1145/1583991.1584058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a local algorithm (constant-time distributed algorithm) for
approximating max-min LPs. The objective is to maximise $\omega$ subject to $Ax
\le 1$, $Cx \ge \omega 1$, and $x \ge 0$ for nonnegative matrices $A$ and $C$.
The approximation ratio of our algorithm is the best possible for any local
algorithm; there is a matching unconditional lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1493</identifier>
 <datestamp>2008-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1493</id><created>2008-09-09</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Exploring Large Feature Spaces with Hierarchical Multiple Kernel
  Learning</title><categories>cs.LG stat.ML</categories><proxy>ccsd hal-00319660</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For supervised and unsupervised learning, positive definite kernels allow to
use large and potentially infinite dimensional feature spaces with a
computational cost that only depends on the number of observations. This is
usually done through the penalization of predictor functions by Euclidean or
Hilbertian norms. In this paper, we explore penalizing by sparsity-inducing
norms such as the l1-norm or the block l1-norm. We assume that the kernel
decomposes into a large sum of individual basis kernels which can be embedded
in a directed acyclic graph; we show that it is then possible to perform kernel
selection through a hierarchical multiple kernel learning framework, in
polynomial time in the number of selected kernels. This framework is naturally
applied to non linear variable selection; our extensive simulations on
synthetic datasets and datasets from the UCI repository show that efficiently
exploring the large feature space through sparsity-inducing norms leads to
state-of-the-art predictive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1522</identifier>
 <datestamp>2008-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1522</id><created>2008-09-09</created><authors><author><keyname>Cohen</keyname><forenames>Gerard</forenames></author><author><keyname>Fachini</keyname><forenames>Emanuela</forenames></author><author><keyname>Korner</keyname><forenames>Janos</forenames></author></authors><title>On the permutation capacity of digraphs</title><categories>math.CO cs.IT math.IT</categories><comments>11 pages, no figures</comments><msc-class>05D05; 05C69: 05C69; 94A24</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend several results of the third author and C. Malvenuto on
graph-different permutations to the case of directed graphs and introduce new
open problems. Permutation capacity is a natural extension of Sperner capacity
from finite directed graphs to infinite digraphs. Our subject is combinatorial
in nature, but can be equally regarded as zero-error information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1551</identifier>
 <datestamp>2009-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1551</id><created>2008-09-09</created><updated>2009-02-19</updated><authors><author><keyname>Staworko</keyname><forenames>Slawomir</forenames></author><author><keyname>Chomicki</keyname><forenames>Jan</forenames></author></authors><title>Consistent Query Answers in the Presence of Universal Constraints</title><categories>cs.DB</categories><comments>Submitted to Information Systems</comments><report-no>UB CSE TR 2008-15</report-no><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The framework of consistent query answers and repairs has been introduced to
alleviate the impact of inconsistent data on the answers to a query. A repair
is a minimally different consistent instance and an answer is consistent if it
is present in every repair. In this article we study the complexity of
consistent query answers and repair checking in the presence of universal
constraints.
  We propose an extended version of the conflict hypergraph which allows to
capture all repairs w.r.t. a set of universal constraints. We show that repair
checking is in PTIME for the class of full tuple-generating dependencies and
denial constraints, and we present a polynomial repair algorithm. This
algorithm is sound, i.e. always produces a repair, but also complete, i.e.
every repair can be constructed. Next, we present a polynomial-time algorithm
computing consistent answers to ground quantifier-free queries in the presence
of denial constraints, join dependencies, and acyclic full-tuple generating
dependencies. Finally, we show that extending the class of constraints leads to
intractability. For arbitrary full tuple-generating dependencies consistent
query answering becomes coNP-complete. For arbitrary universal constraints
consistent query answering is \Pi_2^p-complete and repair checking
coNP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1552</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1552</id><created>2008-09-08</created><updated>2010-06-03</updated><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author><author><keyname>Spitters</keyname><forenames>Bas</forenames></author></authors><title>A computer verified, monadic, functional implementation of the integral</title><categories>cs.LO cs.NA</categories><journal-ref>Theoretical Computer Science, Volume 411, Issue 37, 7 August 2010,
  Pages 3386-3402</journal-ref><doi>10.1016/j.tcs.2010.05.031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a computer verified exact monadic functional implementation of the
Riemann integral in type theory. Together with previous work by O'Connor, this
may be seen as the beginning of the realization of Bishop's vision to use
constructive mathematics as a programming language for exact analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1570</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1570</id><created>2008-09-09</created><authors><author><keyname>Bradley</keyname><forenames>Patrick Erik</forenames></author></authors><title>Mumford dendrograms and discrete p-adic symmetries</title><categories>cs.DM math-ph math.MP q-bio.GN</categories><comments>14 pages, 6 figures</comments><journal-ref>p-Adic Numbers, Ultrametric Analysis and Applications, Vol. 1, No.
  2 (2009), 118-127</journal-ref><doi>10.1134/S2070046609020034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we present an effective encoding of dendrograms by embedding
them into the Bruhat-Tits trees associated to $p$-adic number fields. As an
application, we show how strings over a finite alphabet can be encoded in
cyclotomic extensions of $\mathbb{Q}_p$ and discuss $p$-adic DNA encoding. The
application leads to fast $p$-adic agglomerative hierarchic algorithms similar
to the ones recently used e.g. by A. Khrennikov and others. From the viewpoint
of $p$-adic geometry, to encode a dendrogram $X$ in a $p$-adic field $K$ means
to fix a set $S$ of $K$-rational punctures on the $p$-adic projective line
$\mathbb{P}^1$. To $\mathbb{P}^1\setminus S$ is associated in a natural way a
subtree inside the Bruhat-Tits tree which recovers $X$, a method first used by
F. Kato in 1999 in the classification of discrete subgroups of
$\textrm{PGL}_2(K)$.
  Next, we show how the $p$-adic moduli space $\mathfrak{M}_{0,n}$ of
$\mathbb{P}^1$ with $n$ punctures can be applied to the study of time series of
dendrograms and those symmetries arising from hyperbolic actions on
$\mathbb{P}^1$. In this way, we can associate to certain classes of dynamical
systems a Mumford curve, i.e. a $p$-adic algebraic curve with totally
degenerate reduction modulo $p$.
  Finally, we indicate some of our results in the study of general discrete
actions on $\mathbb{P}^1$, and their relation to $p$-adic Hurwitz spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1590</identifier>
 <datestamp>2012-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1590</id><created>2008-09-09</created><authors><author><keyname>Argyriou</keyname><forenames>Andreas</forenames></author><author><keyname>Micchelli</keyname><forenames>Charles</forenames></author><author><keyname>Pontil</keyname><forenames>Massimiliano</forenames></author></authors><title>When is there a representer theorem? Vector versus matrix regularizers</title><categories>cs.LG</categories><comments>22 pages 2 figures</comments><acm-class>G.1.1; G.1.2; G.1.6; G.1.10; G.3; I.2.6</acm-class><journal-ref>Journal of Machine Learning Research, 10:2507-2529, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general class of regularization methods which learn a vector of
parameters on the basis of linear measurements. It is well known that if the
regularizer is a nondecreasing function of the inner product then the learned
vector is a linear combination of the input data. This result, known as the
{\em representer theorem}, is at the basis of kernel-based methods in machine
learning. In this paper, we prove the necessity of the above condition, thereby
completing the characterization of kernel methods based on regularization. We
further extend our analysis to regularization methods which learn a matrix, a
problem which is motivated by the application to multi-task learning. In this
context, we study a more general representer theorem, which holds for a larger
class of regularizers. We provide a necessary and sufficient condition for
these class of matrix regularizers and highlight them with some concrete
examples of practical importance. Our analysis uses basic principles from
matrix theory, especially the useful notion of matrix nondecreasing function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1593</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1593</id><created>2008-09-09</created><updated>2011-07-11</updated><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author></authors><title>Constructing Perfect Steganographic Systems</title><categories>cs.CR cs.IT math.IT</categories><journal-ref>Information and Computation, 2011, Vol. 209, No. 9, pp. 1223-1230</journal-ref><doi>10.1016/j.ic.2011.06.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose steganographic systems for the case when covertexts (containers)
are generated by a finite-memory source with possibly unknown statistics. The
probability distributions of covertexts with and without hidden information are
the same; this means that the proposed stegosystems are perfectly secure, i.e.
an observer cannot determine whether hidden information is being transmitted.
The speed of transmission of hidden information can be made arbitrary close to
the theoretical limit - the Shannon entropy of the source of covertexts. An
interesting feature of the suggested stegosystems is that they do not require
any (secret or public) key.
  At the same time, we outline some principled computational limitations on
steganography. We show that there are such sources of covertexts, that any
stegosystem that has linear (in the length of the covertext) speed of
transmission of hidden text must have an exponential Kolmogorov complexity.
This shows, in particular, that some assumptions on the sources of covertext
are necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1618</identifier>
 <datestamp>2008-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1618</id><created>2008-09-09</created><authors><author><keyname>Pereira</keyname><forenames>Antonio</forenames></author></authors><title>ECOLANG - Communications Language for Ecological Simulations Network</title><categories>cs.AI cs.MA</categories><comments>16 pages, language specification description</comments><report-no>TR-LIACC-FEUP-AMCP 01.1</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes the communication language used in one multiagent
system environment for ecological simulations, based on EcoDynamo simulator
application linked with several intelligent agents and visualisation
applications, and extends the initial definition of the language. The agents
actions and perceptions are translated into messages exchanged with the
simulator application and other agents. The concepts and definitions used
follow the BNF notation (Backus et al. 1960) and is inspired in the Coach
Unilang language (Reis and Lau 2002).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1644</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1644</id><created>2008-09-09</created><authors><author><keyname>Kaliszyk</keyname><forenames>Cezary</forenames></author><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>Computing with Classical Real Numbers</title><categories>cs.LO</categories><journal-ref>Journal of Formalized Reasoning, 2(1):27-39, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are two incompatible Coq libraries that have a theory of the real
numbers; the Coq standard library gives an axiomatic treatment of classical
real numbers, while the CoRN library from Nijmegen defines constructively valid
real numbers. Unfortunately, this means results about one structure cannot
easily be used in the other structure. We present a way interfacing these two
libraries by showing that their real number structures are isomorphic assuming
the classical axioms already present in the standard library reals. This allows
us to use O'Connor's decision procedure for solving ground inequalities present
in CoRN to solve inequalities about the reals from the Coq standard library,
and it allows theorems from the Coq standard library to apply to problem about
the CoRN reals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1659</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1659</id><created>2008-09-09</created><authors><author><keyname>Bardsley</keyname><forenames>Scott</forenames></author><author><keyname>Thomas</keyname><forenames>Theodosios</forenames></author><author><keyname>Morris</keyname><forenames>R. Paul</forenames></author></authors><title>A Tiered Security System for Mobile Devices</title><categories>cs.CR</categories><comments>10 pages, 2 figures</comments><acm-class>C.2.8.d; J.9; K.6.5.e; K.6.m.b</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have designed a tiered security system for mobile devices where each
security tier holds user-defined security triggers and actions. It has a
friendly interface that allows users to easily define and configure the
different circumstances and actions they need according to context. The system
can be set up and activated from any browser or directly on the mobile device
itself. When the security system is operated from a Web site or server, its
configuration can be readily shared across multiple devices. When operated
directly from the mobile device, no server is needed for activation. Many
different types of security circumstances and actions can be set up and
employed from its tiers. Security circumstances can range from temporary
misplacement of a mobile device at home to malicious theft in a hostile region.
Security actions can range from ringing a simple alarm to automatically
erasing, overwriting, and re-erasing drives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1681</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1681</id><created>2008-09-09</created><authors><author><keyname>Laufer</keyname><forenames>Rafael</forenames></author><author><keyname>Kleinrock</keyname><forenames>Leonard</forenames></author></authors><title>Multirate Anypath Routing in Wireless Mesh Networks</title><categories>cs.NI cs.DS</categories><comments>13 pages, 8 figures</comments><report-no>UCLA-CSD-TR080025</report-no><journal-ref>IEEE INFOCOM 2009</journal-ref><doi>10.1109/INFCOM.2009.5061904</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new routing paradigm that generalizes
opportunistic routing in wireless mesh networks. In multirate anypath routing,
each node uses both a set of next hops and a selected transmission rate to
reach a destination. Using this rate, a packet is broadcast to the nodes in the
set and one of them forwards the packet on to the destination. To date, there
is no theory capable of jointly optimizing both the set of next hops and the
transmission rate used by each node. We bridge this gap by introducing a
polynomial-time algorithm to this problem and provide the proof of its
optimality. The proposed algorithm runs in the same running time as regular
shortest-path algorithms and is therefore suitable for deployment in link-state
routing protocols. We conducted experiments in a 802.11b testbed network, and
our results show that multirate anypath routing performs on average 80% and up
to 6.4 times better than anypath routing with a fixed rate of 11 Mbps. If the
rate is fixed at 1 Mbps instead, performance improves by up to one order of
magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1686</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1686</id><created>2008-09-09</created><authors><author><keyname>Pereira</keyname><forenames>Antonio</forenames><affiliation>UFP, Porto, Portugal</affiliation><affiliation>FEUP, Porto, Portugal</affiliation></author><author><keyname>Duarte</keyname><forenames>Pedro</forenames><affiliation>UFP, Porto, Portugal</affiliation></author><author><keyname>Reis</keyname><forenames>Luis Paulo</forenames><affiliation>FEUP, Porto, Portugal</affiliation></author></authors><title>Agent-based Ecological Model Calibration - on the Edge of a New Approach</title><categories>cs.AI cs.MA</categories><comments>7 pages, 6 figures, Proceedings of the International Conference on
  Knowledge Engineering and Decision Support, pp. 107-113, ISEP, Porto,
  Portugal, July 2004</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to present a new approach to ecological model
calibration -- an agent-based software. This agent works on three stages: 1- It
builds a matrix that synthesizes the inter-variable relationships; 2- It
analyses the steady-state sensitivity of different variables to different
parameters; 3- It runs the model iteratively and measures model lack of fit,
adequacy and reliability. Stage 3 continues until some convergence criteria are
attained. At each iteration, the agent knows from stages 1 and 2, which
parameters are most likely to produce the desired shift on predicted results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1687</identifier>
 <datestamp>2009-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1687</id><created>2008-09-09</created><updated>2009-03-13</updated><authors><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Hadani</keyname><forenames>Ronny</forenames><affiliation>University of Chicago</affiliation></author></authors><title>Incoherent dictionaries and the statistical restricted isometry property</title><categories>cs.IT cs.DM math.IT math.PR</categories><comments>Key words: Incoherent dictionaries, statistical version of Candes -
  Tao RIP, Semi-Circle law, deterministic constructions, Heisenberg-Weil
  representation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we present a statistical version of the Candes-Tao restricted
isometry property (SRIP for short) which holds in general for any incoherent
dictionary which is a disjoint union of orthonormal bases. In addition, under
appropriate normalization, the eigenvalues of the associated Gram matrix
fluctuate around 1 according to the Wigner semicircle distribution. The result
is then applied to various dictionaries that arise naturally in the setting of
finite harmonic analysis, giving, in particular, a better understanding on a
remark of Applebaum-Howard-Searle-Calderbank concerning RIP for the Heisenberg
dictionary of chirp like functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1710</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1710</id><created>2008-09-10</created><authors><author><keyname>Diwan</keyname><forenames>Ajit A.</forenames></author><author><keyname>Kenkre</keyname><forenames>Sreyash</forenames></author><author><keyname>Vishwanathan</keyname><forenames>Sundar</forenames></author></authors><title>Circumference, Chromatic Number and Online Coloring</title><categories>cs.DM</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Erd\&quot;os conjectured that if $G$ is a triangle free graph of chromatic number
at least $k\geq 3$, then it contains an odd cycle of length at least
$k^{2-o(1)}$ \cite{sudakovverstraete, verstraete}. Nothing better than a linear
bound (\cite{gyarfas}, Problem 5.1.55 in \cite{West}) was so far known. We make
progress on this conjecture by showing that $G$ contains an odd cycle of length
at least $O(k\log\log k)$. Erd\&quot;os' conjecture is known to hold for graphs with
girth at least 5. We show that if a girth 4 graph is $C_5$ free, then Erd\&quot;os'
conjecture holds. When the number of vertices is not too large we can prove
better bounds on $\chi$. We also give bounds on the chromatic number of graphs
with at most $r$ cycles of length $1\bmod k$, or at most $s$ cycles of length
$2\bmod k$, or no cycles of length $3\bmod k$. Our techniques essentially
consist of using a depth first search tree to decompose the graph into ordered
paths, which are then fed to an online coloring algorithm. Using this technique
we give simple proofs of some old results, and also obtain several simpler
results. We also obtain a lower bound on the number of colors an online
coloring algorithm needs to use on triangle free graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1715</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1715</id><created>2008-09-10</created><authors><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author><author><keyname>R&#xf6;glin</keyname><forenames>Heiko</forenames></author></authors><title>Improved Smoothed Analysis of the k-Means Method</title><categories>cs.DS</categories><comments>To be presented at the 20th ACM-SIAM Symposium on Discrete Algorithms
  (SODA 2009)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-means method is a widely used clustering algorithm. One of its
distinguished features is its speed in practice. Its worst-case running-time,
however, is exponential, leaving a gap between practical and theoretical
performance. Arthur and Vassilvitskii (FOCS 2006) aimed at closing this gap,
and they proved a bound of $\poly(n^k, \sigma^{-1})$ on the smoothed
running-time of the k-means method, where n is the number of data points and
$\sigma$ is the standard deviation of the Gaussian perturbation. This bound,
though better than the worst-case bound, is still much larger than the
running-time observed in practice.
  We improve the smoothed analysis of the k-means method by showing two upper
bounds on the expected running-time of k-means. First, we prove that the
expected running-time is bounded by a polynomial in $n^{\sqrt k}$ and
$\sigma^{-1}$. Second, we prove an upper bound of $k^{kd} \cdot \poly(n,
\sigma^{-1})$, where d is the dimension of the data space. The polynomial is
independent of k and d, and we obtain a polynomial bound for the expected
running-time for $k, d \in O(\sqrt{\log n/\log \log n})$.
  Finally, we show that k-means runs in smoothed polynomial time for
one-dimensional instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1790</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1790</id><created>2008-09-10</created><authors><author><keyname>Cheung</keyname><forenames>Donny</forenames></author><author><keyname>Perez-Delgado</keyname><forenames>Carlos A.</forenames></author></authors><title>Cellular Automata as a Model of Physical Systems</title><categories>cs.DM</categories><comments>To appear in the Proceedings of AUTOMATA 2007</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular Automata (CA), as they are presented in the literature, are abstract
mathematical models of computation. In this pa- per we present an alternate
approach: using the CA as a model or theory of physical systems and devices.
While this approach abstracts away all details of the underlying physical
system, it remains faithful to the fact that there is an underlying physical
reality which it describes. This imposes certain restrictions on the types of
computations a CA can physically carry out, and the resources it needs to do
so. In this paper we explore these and other consequences of our
reformalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1802</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1802</id><created>2008-09-10</created><authors><author><keyname>Brouwer</keyname><forenames>William</forenames></author><author><keyname>Kataria</keyname><forenames>Saurabh</forenames></author><author><keyname>Das</keyname><forenames>Sujatha</forenames></author><author><keyname>Mitra</keyname><forenames>Prasenjit</forenames></author><author><keyname>Giles</keyname><forenames>C. L.</forenames></author></authors><title>Automatic Identification and Data Extraction from 2-Dimensional Plots in
  Digital Documents</title><categories>cs.CV</categories><comments>4 pages, 3 figures, 5 tables, accepted for publication in Joint
  Conference on Digital Libraries 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most search engines index the textual content of documents in digital
libraries. However, scholarly articles frequently report important findings in
figures for visual impact and the contents of these figures are not indexed.
These contents are often invaluable to the researcher in various fields, for
the purposes of direct comparison with their own work. Therefore, searching for
figures and extracting figure data are important problems. To the best of our
knowledge, there exists no tool to automatically extract data from figures in
digital documents. If we can extract data from these images automatically and
store them in a database, an end-user can query and combine data from multiple
digital documents simultaneously and efficiently. We propose a framework based
on image analysis and machine learning to extract information from 2-D plot
images and store them in a database. The proposed algorithm identifies a 2-D
plot and extracts the axis labels, legend and the data points from the 2-D
plot. We also segregate overlapping shapes that correspond to different data
points. We demonstrate performance of individual algorithms, using a
combination of generated and real-life images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1806</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1806</id><created>2008-09-10</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Graph Operations that are Good for Greedoids</title><categories>math.CO cs.DM</categories><comments>8 pages, 4 figures</comments><msc-class>05C69 (Primary) 05B35, 90C27 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  S is a local maximum stable set of a graph G, if the set S is a maximum
stable set of the subgraph induced by its closed neighborhood. In (Levit,
Mandrescu, 2002) we have proved that the family of all local maximum stable
sets is a greedoid for every forest. The cases of bipartite graphs and
triangle-free graphs were analyzed in (Levit, Mandrescu, 2004) and (Levit,
Mandrescu, 2007), respectively. In this paper we give necessary and sufficient
conditions for the family of all local maximum stable sets of a graph G to form
a greedoid, where G is: (a) the disjoint union of a family of graphs; (b) the
Zykov sum of a family of graphs, or (c) the corona X*{H_1,H_2,...,H_n} obtained
by joining each vertex k of a graph X to all the vertices of a graph H_k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1810</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1810</id><created>2008-09-10</created><authors><author><keyname>Cruz</keyname><forenames>Felipe A.</forenames></author><author><keyname>Barba</keyname><forenames>L. A.</forenames></author></authors><title>Characterization of the errors of the FMM in particle simulations</title><categories>cs.DS physics.comp-ph</categories><comments>34 pages, 38 images</comments><journal-ref>Int. J. Num. Meth. Engrg., 79(13):1577-1604 (2009)</journal-ref><doi>10.1002/nme.2611</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Fast Multipole Method (FMM) offers an acceleration for pairwise
interaction calculation, known as $N$-body problems, from $\mathcal{O}(N^2)$ to
$\mathcal{O}(N)$ with $N$ particles. This has brought dramatic increase in the
capability of particle simulations in many application areas, such as
electrostatics, particle formulations of fluid mechanics, and others. Although
the literature on the subject provides theoretical error bounds for the FMM
approximation, there are not many reports of the measured errors in a suite of
computational experiments. We have performed such an experimental
investigation, and summarized the results of about 1000 calculations using the
FMM algorithm, to characterize the accuracy of the method in relation with the
different parameters available to the user. In addition to the more standard
diagnostic of the maximum error, we supply illustrations of the spatial
distribution of the errors, which offers visual evidence of all the
contributing factors to the overall approximation accuracy: multipole
expansion, local expansion, hierarchical spatial decomposition (interaction
lists, local domain, far domain). This presentation is a contribution to any
researcher wishing to incorporate the FMM acceleration to their application
code, as it aids in understanding where accuracy is gained or compromised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1812</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1812</id><created>2008-09-10</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>LIP</affiliation></author><author><keyname>Lecomte</keyname><forenames>Dominique</forenames><affiliation>UMR 7586</affiliation></author></authors><title>Topological Complexity of omega-Powers : Extended Abstract</title><categories>cs.LO cs.CC math.LO</categories><proxy>ccsd ensl-00319447</proxy><report-no>LIP Research Report RR 2008-27</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is an extended abstract presenting new results on the topological
complexity of omega-powers (which are included in a paper &quot;Classical and
effective descriptive complexities of omega-powers&quot; available from
arXiv:0708.4176) and reflecting also some open questions which were discussed
during the Dagstuhl seminar on &quot;Topological and Game-Theoretic Aspects of
Infinite Computations&quot; 29.06.08 - 04.07.08.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1836</identifier>
 <datestamp>2008-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1836</id><created>2008-09-10</created><authors><author><keyname>Faben</keyname><forenames>John</forenames></author></authors><title>The complexity of counting solutions to Generalised Satisfiability
  Problems modulo k</title><categories>cs.CC</categories><acm-class>F.2.2; F.4.1; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalised Satisfiability Problems (or Boolean Constraint Satisfaction
Problems), introduced by Schaefer in 1978, are a general class of problem which
allow the systematic study of the complexity of satisfiability problems with
different types of constraints. In 1979, Valiant introduced the complexity
class parity P, the problem of counting the number of solutions to NP problems
modulo two. Others have since considered the question of counting modulo other
integers.
  We give a dichotomy theorem for the complexity of counting the number of
solutions to Generalised Satisfiability Problems modulo integers. This follows
from an earlier result of Creignou and Hermann which gave a counting dichotomy
for these types of problem, and the dichotomy itself is almost identical.
Specifically, counting the number of solutions to a Generalised Satisfiability
Problem can be done in polynomial time if all the relations are affine.
Otherwise, except for one special case with k = 2, it is #_kP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1895</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1895</id><created>2008-09-10</created><authors><author><keyname>Azar</keyname><forenames>Yossi</forenames></author><author><keyname>Birnbaum</keyname><forenames>Benjamin</forenames></author><author><keyname>Karlin</keyname><forenames>Anna R.</forenames></author><author><keyname>Nguyen</keyname><forenames>C. Thach</forenames></author></authors><title>Thinking Twice about Second-Price Ad Auctions</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has addressed the algorithmic problem of allocating advertisement
space for keywords in sponsored search auctions so as to maximize revenue, most
of which assume that pricing is done via a first-price auction. This does not
realistically model the Generalized Second Price (GSP) auction used in
practice, in which bidders pay the next-highest bid for keywords that they are
allocated. Towards the goal of more realistically modeling these auctions, we
introduce the Second-Price Ad Auctions problem, in which bidders' payments are
determined by the GSP mechanism. We show that the complexity of the
Second-Price Ad Auctions problem is quite different than that of the more
studied First-Price Ad Auctions problem. First, unlike the first-price variant,
for which small constant-factor approximations are known, it is NP-hard to
approximate the Second-Price Ad Auctions problem to any non-trivial factor,
even when the bids are small compared to the budgets. Second, this discrepancy
extends even to the 0-1 special case that we call the Second-Price Matching
problem (2PM). Offline 2PM is APX-hard, and for online 2PM there is no
deterministic algorithm achieving a non-trivial competitive ratio and no
randomized algorithm achieving a competitive ratio better than 2. This
contrasts with the results for the analogous special case in the first-price
model, the standard bipartite matching problem, which is solvable in polynomial
time and which has deterministic and randomized online algorithms achieving
better competitive ratios. On the positive side, we provide a 2-approximation
for offline 2PM and a 5.083-competitive randomized algorithm for online 2PM.
The latter result makes use of a new generalization of a result on the
performance of the &quot;Ranking&quot; algorithm for online bipartite matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1900</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1900</id><created>2008-09-10</created><authors><author><keyname>Ermis</keyname><forenames>E.</forenames></author><author><keyname>Saligrama</keyname><forenames>V.</forenames></author></authors><title>Distributed Detection in Sensor Networks with Limited Range Multi-Modal
  Sensors</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-object detection problem over a sensor network (SNET)
with limited range multi-modal sensors. Limited range sensing environment
arises in a sensing field prone to signal attenuation and path losses. The
general problem complements the widely considered decentralized detection
problem where all sensors observe the same object. In this paper we develop a
distributed detection approach based on recent development of the false
discovery rate (FDR) and the associated BH test procedure. The BH procedure is
based on rank ordering of scalar test statistics. We first develop scalar test
statistics for multidimensional data to handle multi-modal sensor observations
and establish its optimality in terms of the BH procedure. We then propose a
distributed algorithm in the ideal case of infinite attenuation for
identification of sensors that are in the immediate vicinity of an object. We
demonstrate communication message scalability to large SNETs by showing that
the upper bound on the communication message complexity scales linearly with
the number of sensors that are in the vicinity of objects and is independent of
the total number of sensors in the SNET. This brings forth an important
principle for evaluating the performance of an SNET, namely, the need for
scalability of communications and performance with respect to the number of
objects or events in an SNET irrespective of the network size. We then account
for finite attenuation by modeling sensor observations as corrupted by
uncertain interference arising from distant objects and developing robust
extensions to our idealized distributed scheme. The robustness properties
ensure that both the error performance and communication message complexity
degrade gracefully with interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1902</identifier>
 <datestamp>2009-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1902</id><created>2008-09-10</created><updated>2009-09-08</updated><authors><author><keyname>Mendel</keyname><forenames>Manor</forenames></author><author><keyname>Schwob</keyname><forenames>Chaya</forenames></author></authors><title>Fast C-K-R Partitions of Sparse Graphs</title><categories>cs.DS</categories><comments>15 pages, title changed, a small error in the running time was fixed.
  Many errors in English were eliminated</comments><acm-class>F.2; E.1</acm-class><journal-ref>Chicago J. Theoretical Comp. Sci., 2009(2), 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present fast algorithms for constructing probabilistic embeddings and
approximate distance oracles in sparse graphs. The main ingredient is a fast
algorithm for sampling the probabilistic partitions of Calinescu, Karloff, and
Rabani in sparse graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1906</identifier>
 <datestamp>2008-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1906</id><created>2008-09-10</created><updated>2008-10-19</updated><authors><author><keyname>Kintali</keyname><forenames>Shiva</forenames></author></authors><title>Betweenness Centrality : Algorithms and Lower Bounds</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most fundamental problems in large scale network analysis is to
determine the importance of a particular node in a network. Betweenness
centrality is the most widely used metric to measure the importance of a node
in a network. In this paper, we present a randomized parallel algorithm and an
algebraic method for computing betweenness centrality of all nodes in a
network. We prove that any path-comparison based algorithm cannot compute
betweenness in less than O(nm) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1910</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1910</id><created>2008-09-10</created><authors><author><keyname>Altug</keyname><forenames>Yucel</forenames></author><author><keyname>Mihcak</keyname><forenames>M. Kivanc</forenames></author><author><keyname>Ozyesil</keyname><forenames>Onur</forenames></author><author><keyname>Monga</keyname><forenames>Vishal</forenames></author></authors><title>Reliable Communications with Asymmetric Codebooks: An Information
  Theoretic Analysis of Robust Signal Hashing</title><categories>cs.IT math.IT</categories><comments>24 pages, 3 figures, submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a generalization of the traditional point-to-point to
communication setup, which is named as &quot;reliable communications with asymmetric
codebooks&quot;, is proposed. Under the assumption of independent identically
distributed (i.i.d) encoder codewords, it is proven that the operational
capacity of the system is equal to the information capacity of the system,
which is given by $\max_{p(x)} I(U;Y)$, where $X, U$ and $Y$ denote the
individual random elements of encoder codewords, decoder codewords and decoder
inputs. The capacity result is derived in the &quot;binary symmetric&quot; case (which is
an analogous formulation of the traditional &quot;binary symmetric channel&quot; for our
case), as a function of the system parameters. A conceptually insightful
inference is made by attributing the difference from the classical Shannon-type
capacity of binary symmetric channel to the {\em gap} due to the codebook
asymmetry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1916</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1916</id><created>2008-09-11</created><authors><author><keyname>Jeon</keyname><forenames>Sung-eok</forenames></author><author><keyname>Ji</keyname><forenames>Chunayi</forenames></author></authors><title>Randomized Distributed Configuration Management of Wireless Networks:
  Multi-layer Markov Random Fields and Near-Optimality</title><categories>cs.DC cs.AI</categories><comments>15 pages, revised and submitted to IEEE Trans. on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed configuration management is imperative for wireless
infrastructureless networks where each node adjusts locally its physical and
logical configuration through information exchange with neighbors. Two issues
remain open. The first is the optimality. The second is the complexity. We
study these issues through modeling, analysis, and randomized distributed
algorithms. Modeling defines the optimality. We first derive a global
probabilistic model for a network configuration which characterizes jointly the
statistical spatial dependence of a physical- and a logical-configuration. We
then show that a local model which approximates the global model is a two-layer
Markov Random Field or a random bond model. The complexity of the local model
is the communication range among nodes. The local model is near-optimal when
the approximation error to the global model is within a given error bound. We
analyze the trade-off between an approximation error and complexity, and derive
sufficient conditions on the near-optimality of the local model. We validate
the model, the analysis and the randomized distributed algorithms also through
simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1949</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1949</id><created>2008-09-11</created><updated>2011-05-14</updated><authors><author><keyname>Wendzel</keyname><forenames>Steffen</forenames></author></authors><title>Protocol Channels</title><categories>cs.CR</categories><comments>2 pages</comments><acm-class>K.6.5; D.4.6</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Covert channel techniques are used by attackers to transfer data in a way
prohibited by the security policy. There are two main categories of covert
channels: timing channels and storage channels. This paper introduces a new
storage channel technique called a protocol channel. A protocol channel
switches one of at least two protocols to send a bit combination to a
destination. The main goal of a protocol channel is that packets containing
covert information look equal to all other packets within a network, what makes
a protocol channel hard to detect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1963</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1963</id><created>2008-09-11</created><authors><author><keyname>Mahboubi</keyname><forenames>Hadj</forenames><affiliation>ERIC</affiliation></author><author><keyname>Aouiche</keyname><forenames>Kamel</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>Materialized View Selection by Query Clustering in XML Data Warehouses</title><categories>cs.DB</categories><proxy>ccsd hal-00320632</proxy><journal-ref>4th International Multiconference on Computer Science and
  Information Technology (CSIT 06), Amman : Jordanie (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML data warehouses form an interesting basis for decision-support
applications that exploit complex data. However, native XML database management
systems currently bear limited performances and it is necessary to design
strategies to optimize them. In this paper, we propose an automatic strategy
for the selection of XML materialized views that exploits a data mining
technique, more precisely the clustering of the query workload. To validate our
strategy, we implemented an XML warehouse modeled along the XCube
specifications. We executed a workload of XQuery decision-support queries on
this warehouse, with and without using our strategy. Our experimental results
demonstrate its efficiency, even when queries are complex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1965</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1965</id><created>2008-09-11</created><authors><author><keyname>Azefack</keyname><forenames>St&#xe9;phane</forenames><affiliation>ERIC</affiliation></author><author><keyname>Aouiche</keyname><forenames>Kamel</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>Dynamic index selection in data warehouses</title><categories>cs.DB</categories><proxy>ccsd hal-00320640</proxy><journal-ref>4th International Conference on Innovations in Information
  Technology (Innovations 07), Dubai : \'Emirats arabes unis (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analytical queries defined on data warehouses are complex and use several
join operations that are very costly, especially when run on very large data
volumes. To improve response times, data warehouse administrators casually use
indexing techniques. This task is nevertheless complex and fastidious. In this
paper, we present an automatic, dynamic index selection method for data
warehouses that is based on incremental frequent itemset mining from a given
query workload. The main advantage of this approach is that it helps update the
set of selected indexes when workload evolves instead of recreating it from
scratch. Preliminary experimental results illustrate the efficiency of this
approach, both in terms of performance enhancement and overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1971</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1971</id><created>2008-09-11</created><authors><author><keyname>Ralaivao</keyname><forenames>Jean-Christian</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>Knowledge and Metadata Integration for Warehousing Complex Data</title><categories>cs.DB</categories><comments>6th International Conference on Information Systems Technology and
  its Applications (ISTA 07), Kharkiv : Ukraine (2007)</comments><proxy>ccsd hal-00320661</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the ever-growing availability of so-called complex data, especially on
the Web, decision-support systems such as data warehouses must store and
process data that are not only numerical or symbolic. Warehousing and analyzing
such data requires the joint exploitation of metadata and domain-related
knowledge, which must thereby be integrated. In this paper, we survey the types
of knowledge and metadata that are needed for managing complex data, discuss
the issue of knowledge and metadata integration, and propose a CWM-compliant
integration solution that we incorporate into an XML complex data warehousing
framework we previously designed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1981</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1981</id><created>2008-09-11</created><authors><author><keyname>Mahboubi</keyname><forenames>Hadj</forenames><affiliation>ERIC</affiliation></author><author><keyname>Aouiche</keyname><forenames>Kamel</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>A Join Index for XML Data Warehouses</title><categories>cs.DB</categories><comments>2008 International Conference on Information Resources Management
  (Conf-IRM 08), Niagra Falls : Canada (2008)</comments><proxy>ccsd hal-00320669</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML data warehouses form an interesting basis for decision-support
applications that exploit complex data. However, native-XML database management
systems (DBMSs) currently bear limited performances and it is necessary to
research for ways to optimize them. In this paper, we propose a new join index
that is specifically adapted to the multidimensional architecture of XML
warehouses. It eliminates join operations while preserving the information
contained in the original warehouse. A theoretical study and experimental
results demonstrate the efficiency of our join index. They also show that
native XML DBMSs can compete with XML-compatible, relational DBMSs when
warehousing and analyzing XML data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1989</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1989</id><created>2008-09-11</created><authors><author><keyname>Gast</keyname><forenames>Nicolas</forenames></author><author><keyname>Gaujal</keyname><forenames>Bruno</forenames></author></authors><title>Distributing Labels on Infinite Trees</title><categories>cs.DM</categories><comments>30 pages, use pgf/tikz</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sturmian words are infinite binary words with many equivalent definitions:
They have a minimal factor complexity among all aperiodic sequences; they are
balanced sequences (the labels 0 and 1 are as evenly distributed as possible)
and they can be constructed using a mechanical definition. All this properties
make them good candidates for being extremal points in scheduling problems over
two processors. In this paper, we consider the problem of generalizing Sturmian
words to trees. The problem is to evenly distribute labels 0 and 1 over
infinite trees. We show that (strongly) balanced trees exist and can also be
constructed using a mechanical process as long as the tree is irrational. Such
trees also have a minimal factor complexity. Therefore they bring the hope that
extremal scheduling properties of Sturmian words can be extended to such trees,
as least partially. Such possible extensions are illustrated by one such
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2032</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2032</id><created>2008-09-11</created><authors><author><keyname>Mokhov</keyname><forenames>O. I.</forenames></author></authors><title>On consistency of determinants on cubic lattices</title><categories>nlin.SI cs.DM math.CO</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a modified condition of consistency on cubic lattices for some
special classes of two-dimensional discrete equations and prove that the
discrete nonlinear equations defined by determinants of matrices of orders N &gt;
2 are consistent on cubic lattices in this sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2061</identifier>
 <datestamp>2009-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2061</id><created>2008-09-11</created><updated>2009-01-15</updated><authors><author><keyname>Adams</keyname><forenames>Robin</forenames></author><author><keyname>Luo</keyname><forenames>Zhaohui</forenames></author></authors><title>Weyl's Predicative Classical Mathematics as a Logic-Enriched Type Theory</title><categories>cs.LO</categories><comments>31 pages, 6 figures. Accepted for publication in ACM TOCL. v2:
  Corrected a broken citation in v1. v3: Final version, revised after referees'
  comments</comments><acm-class>F.4.1</acm-class><journal-ref>ACM TOCL 11(2), 2010</journal-ref><doi>10.1145/1656242.1656246</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a logic-enriched type theory LTTW that corresponds closely to
the predicative system of foundations presented by Hermann Weyl in Das
Kontinuum. We formalise many results from that book in LTTW, including Weyl's
definition of the cardinality of a set and several results from real analysis,
using the proof assistant Plastic that implements the logical framework LF.
This case study shows how type theory can be used to represent a
non-constructive foundation for mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2075</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2075</id><created>2008-09-11</created><updated>2008-09-12</updated><authors><author><keyname>Fakcharoenphol</keyname><forenames>Jittat</forenames></author><author><keyname>Kijsirikul</keyname><forenames>Boonserm</forenames></author></authors><title>Low congestion online routing and an improved mistake bound for online
  prediction of graph labeling</title><categories>cs.DS cs.DM cs.LG</categories><comments>5 pages</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show a connection between a certain online low-congestion
routing problem and an online prediction of graph labeling. More specifically,
we prove that if there exists a routing scheme that guarantees a congestion of
$\alpha$ on any edge, there exists an online prediction algorithm with mistake
bound $\alpha$ times the cut size, which is the size of the cut induced by the
label partitioning of graph vertices. With previous known bound of $O(\log n)$
for $\alpha$ for the routing problem on trees with $n$ vertices, we obtain an
improved prediction algorithm for graphs with high effective resistance.
  In contrast to previous approaches that move the graph problem into problems
in vector space using graph Laplacian and rely on the analysis of the
perceptron algorithm, our proof are purely combinatorial. Further more, our
approach directly generalizes to the case where labels are not binary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2083</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2083</id><created>2008-09-11</created><updated>2009-02-13</updated><authors><author><keyname>Baldoni</keyname><forenames>Velleda</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>Berline</keyname><forenames>Nicole</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>De Loera</keyname><forenames>Jesus</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>K&#xf6;ppe</keyname><forenames>Matthias</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>Vergne</keyname><forenames>Mich&#xe8;le</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author></authors><title>How to Integrate a Polynomial over a Simplex</title><categories>math.MG cs.CC cs.SC</categories><comments>Tables added with new experimental results. References added</comments><proxy>ccsd hal-00320882</proxy><journal-ref>Mathematics of Computation 80, 273 (2011) 297-325</journal-ref><doi>10.1090/S0025-5718-2010-02378-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper settles the computational complexity of the problem of integrating
a polynomial function f over a rational simplex. We prove that the problem is
NP-hard for arbitrary polynomials via a generalization of a theorem of Motzkin
and Straus. On the other hand, if the polynomial depends only on a fixed number
of variables, while its degree and the dimension of the simplex are allowed to
vary, we prove that integration can be done in polynomial time. As a
consequence, for polynomials of fixed total degree, there is a polynomial time
algorithm as well. We conclude the article with extensions to other polytopes,
discussion of other available methods and experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2085</identifier>
 <datestamp>2008-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2085</id><created>2008-09-11</created><authors><author><keyname>Jacob</keyname><forenames>Laurent</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Vert</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Clustered Multi-Task Learning: A Convex Formulation</title><categories>cs.LG</categories><proxy>ccsd hal-00320573</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multi-task learning several related tasks are considered simultaneously,
with the hope that by an appropriate sharing of information across tasks, each
task may benefit from the others. In the context of learning linear functions
for supervised classification or regression, this can be achieved by including
a priori information about the weight vectors associated with the tasks, and
how they are expected to be related to each other. In this paper, we assume
that tasks are clustered into groups, which are unknown beforehand, and that
tasks within a group have similar weight vectors. We design a new spectral norm
that encodes this a priori assumption, without the prior knowledge of the
partition of tasks into groups, resulting in a new convex optimization
formulation for multi-task learning. We show in simulations on synthetic
examples and on the IEDB MHC-I binding dataset, that our approach outperforms
well-known convex methods for multi-task learning, as well as related non
convex methods dedicated to the same problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2093</identifier>
 <datestamp>2008-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2093</id><created>2008-09-11</created><authors><author><keyname>Lee</keyname><forenames>Troy</forenames></author><author><keyname>Shraibman</keyname><forenames>Adi</forenames></author></authors><title>An approximation algorithm for approximation rank</title><categories>cs.CC</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the strongest techniques available for showing lower bounds on quantum
communication complexity is the logarithm of the approximation rank of the
communication matrix--the minimum rank of a matrix which is entrywise close to
the communication matrix. This technique has two main drawbacks: it is
difficult to compute, and it is not known to lower bound quantum communication
complexity with entanglement.
  Linial and Shraibman recently introduced a norm, called gamma_2^{alpha}, to
quantum communication complexity, showing that it can be used to lower bound
communication with entanglement. Here the parameter alpha is a measure of
approximation which is related to the allowable error probability of the
protocol. This bound can be written as a semidefinite program and gives bounds
at least as large as many techniques in the literature, although it is smaller
than the corresponding alpha-approximation rank, rk_alpha. We show that in fact
log gamma_2^{alpha}(A)$ and log rk_{alpha}(A)$ agree up to small factors. As
corollaries we obtain a constant factor polynomial time approximation algorithm
to the logarithm of approximate rank, and that the logarithm of approximation
rank is a lower bound for quantum communication complexity with entanglement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2097</identifier>
 <datestamp>2008-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2097</id><created>2008-09-11</created><authors><author><keyname>Liu</keyname><forenames>Hsiao-Fei</forenames></author><author><keyname>Chen</keyname><forenames>Peng-An</forenames></author><author><keyname>Chao</keyname><forenames>Kun-Mao</forenames></author></authors><title>Algorithms for Locating Constrained Optimal Intervals</title><categories>cs.DS</categories><comments>An earlier version of the second part of this work appeared in
  Proceedings of the 18th International Symposium on Algorithms and
  Computation, Japan, 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we obtain the following new results.
  1. Given a sequence $D=((h_1,s_1), (h_2,s_2) ..., (h_n,s_n))$ of number
pairs, where $s_i&gt;0$ for all $i$, and a number $L_h$, we propose an O(n)-time
algorithm for finding an index interval $[i,j]$ that maximizes
$\frac{\sum_{k=i}^{j} h_k}{\sum_{k=i}^{j} s_k}$ subject to $\sum_{k=i}^{j} h_k
\geq L_h$.
  2. Given a sequence $D=((h_1,s_1), (h_2,s_2) ..., (h_n,s_n))$ of number
pairs, where $s_i=1$ for all $i$, and an integer $L_s$ with $1\leq L_s\leq n$,
we propose an $O(n\frac{T(L_s^{1/2})}{L_s^{1/2}})$-time algorithm for finding
an index interval $[i,j]$ that maximizes $\frac{\sum_{k=i}^{j}
h_k}{\sqrt{\sum_{k=i}^{j} s_k}}$ subject to $\sum_{k=i}^{j} s_k \geq L_s$,
where $T(n')$ is the time required to solve the all-pairs shortest paths
problem on a graph of $n'$ nodes. By the latest result of Chan \cite{Chan},
$T(n')=O(n'^3 \frac{(\log\log n')^3}{(\log n')^2})$, so our algorithm runs in
subquadratic time $O(nL_s\frac{(\log\log L_s)^3}{(\log L_s)^2})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2136</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2136</id><created>2008-09-12</created><updated>2009-12-16</updated><authors><author><keyname>Enumula</keyname><forenames>Prabodh K.</forenames></author><author><keyname>Rao</keyname><forenames>Shrisha</forenames></author></authors><title>The Potluck Problem</title><categories>cs.GT cs.MA</categories><comments>9 pages. Economics Letters, to appear</comments><acm-class>I.2.11; I.6.1</acm-class><journal-ref>Economics Letters 107 (1), pp. 10--12, April 2010</journal-ref><doi>10.1016/j.econlet.2009.12.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the Potluck Problem as a model for the behavior of
independent producers and consumers under standard economic assumptions, as a
problem of resource allocation in a multi-agent system in which there is no
explicit communication among the agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2147</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2147</id><created>2008-09-12</created><updated>2009-12-08</updated><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author></authors><title>Investigation on Multiuser Diversity in Spectrum Sharing Based Cognitive
  Radio Networks</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Communication Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new form of multiuser diversity, named \emph{multiuser interference
diversity}, is investigated for opportunistic communications in cognitive radio
(CR) networks by exploiting the mutual interference between the CR and the
existing primary radio (PR) links. The multiuser diversity gain and ergodic
throughput are analyzed for different types of CR networks and compared against
those in the conventional networks without the PR link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2148</identifier>
 <datestamp>2009-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2148</id><created>2008-09-12</created><updated>2009-08-03</updated><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author></authors><title>Cognitive Beamforming Made Practical: Effective Interference Channel and
  Learning-Throughput Tradeoff</title><categories>cs.IT math.IT</categories><comments>Accepted in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the transmit strategy for a secondary link or the
so-called cognitive radio (CR) link under opportunistic spectrum sharing with
an existing primary radio (PR) link. It is assumed that the CR transmitter is
equipped with multi-antennas, whereby transmit precoding and power control can
be jointly deployed to balance between avoiding interference at the PR
terminals and optimizing performance of the CR link. This operation is named as
cognitive beamforming (CB). Unlike prior study on CB that assumes perfect
knowledge of the channels over which the CR transmitter interferes with the PR
terminals, this paper proposes a practical CB scheme utilizing a new idea of
effective interference channel (EIC), which can be efficiently estimated at the
CR transmitter from its observed PR signals. Somehow surprisingly, this paper
shows that the learning-based CB scheme with the EIC improves the CR channel
capacity against the conventional scheme even with the exact CR-to-PR channel
knowledge, when the PR link is equipped with multi-antennas but only
communicates over a subspace of the total available spatial dimensions.
Moreover, this paper presents algorithms for the CR to estimate the EIC over a
finite learning time. Due to channel estimation errors, the proposed CB scheme
causes leakage interference at the PR terminals, which leads to an interesting
learning-throughput tradeoff phenomenon for the CR, pertinent to its time
allocation between channel learning and data transmission. This paper derives
the optimal channel learning time to maximize the effective throughput of the
CR link, subject to the CR transmit power constraint and the interference power
constraints for the PR terminals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2152</identifier>
 <datestamp>2008-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2152</id><created>2008-09-12</created><authors><author><keyname>Costa</keyname><forenames>Rui A.</forenames></author><author><keyname>Munaretto</keyname><forenames>Daniele</forenames></author><author><keyname>Widmer</keyname><forenames>Joerg</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author></authors><title>Informed Network Coding for Minimum Decoding Delay</title><categories>cs.IT math.IT</categories><comments>Proc. of the IEEE International Conference on Mobile Ad-hoc and
  Sensor Systems (IEEE MASS 2008), Atlanta, USA, September 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding is a highly efficient data dissemination mechanism for
wireless networks. Since network coded information can only be recovered after
delivering a sufficient number of coded packets, the resulting decoding delay
can become problematic for delay-sensitive applications such as real-time media
streaming. Motivated by this observation, we consider several algorithms that
minimize the decoding delay and analyze their performance by means of
simulation. The algorithms differ both in the required information about the
state of the neighbors' buffers and in the way this knowledge is used to decide
which packets to combine through coding operations. Our results show that a
greedy algorithm, whose encodings maximize the number of nodes at which a coded
packet is immediately decodable significantly outperforms existing network
coding protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2168</identifier>
 <datestamp>2010-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2168</id><created>2008-09-12</created><authors><author><keyname>Saini</keyname><forenames>Megha</forenames></author><author><keyname>Rao</keyname><forenames>Shrisha</forenames></author></authors><title>Fairness in Combinatorial Auctioning Systems</title><categories>cs.GT cs.MA</categories><comments>18 pages; AAAI Spring Symposium on Game Theoretic and Decision
  Theoretic Agents, Stanford University, CA, March 2007</comments><acm-class>I.2.11; J.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the Multi-Agent Systems that is widely used by various government
agencies, buyers and sellers in a market economy, in such a manner so as to
attain optimized resource allocation, is the Combinatorial Auctioning System
(CAS). We study another important aspect of resource allocations in CAS, namely
fairness. We present two important notions of fairness in CAS, extended
fairness and basic fairness. We give an algorithm that works by incorporating a
metric to ensure fairness in a CAS that uses the Vickrey-Clark-Groves (VCG)
mechanism, and uses an algorithm of Sandholm to achieve optimality.
Mathematical formulations are given to represent measures of extended fairness
and basic fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2214</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2214</id><created>2008-09-12</created><authors><author><keyname>Legay</keyname><forenames>Axel</forenames></author><author><keyname>Wolper</keyname><forenames>Pierre</forenames></author></authors><title>On (Omega-)Regular Model Checking</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Checking infinite-state systems is frequently done by encoding infinite sets
of states as regular languages. Computing such a regular representation of,
say, the set of reachable states of a system requires acceleration techniques
that can finitely compute the effect of an unbounded number of transitions.
Among the acceleration techniques that have been proposed, one finds both
specific and generic techniques. Specific techniques exploit the particular
type of system being analyzed, e.g. a system manipulating queues or integers,
whereas generic techniques only assume that the transition relation is
represented by a finite-state transducer, which has to be iterated. In this
paper, we investigate the possibility of using generic techniques in cases
where only specific techniques have been exploited so far. Finding that
existing generic techniques are often not applicable in cases easily handled by
specific techniques, we have developed a new approach to iterating transducers.
This new approach builds on earlier work, but exploits a number of new
conceptual and algorithmic ideas, often induced with the help of experiments,
that give it a broad scope, as well as good performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2226</identifier>
 <datestamp>2008-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2226</id><created>2008-09-12</created><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Mandayam</keyname><forenames>Narayan B.</forenames></author></authors><title>Relay vs. User Cooperation in Time-Duplexed Multiaccess Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Wireless Communications, August
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of user-cooperation in a multi-access network is compared to
that of using a wireless relay. Using the total transmit and processing power
consumed at all nodes as a cost metric, the outage probabilities achieved by
dynamic decode-and-forward (DDF) and amplify-and-forward (AF) are compared for
the two networks. A geometry-inclusive high signal-to-noise ratio (SNR) outage
analysis in conjunction with area-averaged numerical simulations shows that
user and relay cooperation achieve a maximum diversity of K and 2 respectively
for a K-user multiaccess network under both DDF and AF. However, when
accounting for energy costs of processing and communication, relay cooperation
can be more energy efficient than user cooperation, i.e., relay cooperation
achieves coding (SNR) gains, particularly in the low SNR regime, that override
the diversity advantage of user cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2315</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2315</id><created>2008-09-13</created><authors><author><keyname>Abualrub</keyname><forenames>Taher</forenames></author><author><keyname>Ghrayeb</keyname><forenames>Ali</forenames></author><author><keyname>Aydin</keyname><forenames>Nuh</forenames></author><author><keyname>Siap</keyname><forenames>Irfan</forenames></author></authors><title>On the Construction of Skew Quasi-Cyclic Codes</title><categories>cs.IT cs.DM math.IT math.RA</categories><comments>12 pages. submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a special type of quasi-cyclic (QC) codes called skew
QC codes. This set of codes is constructed using a non-commutative ring called
the skew polynomial rings $F[x;\theta ]$. After a brief description of the skew
polynomial ring $F[x;\theta ]$ it is shown that skew QC codes are left
submodules of the ring $R_{s}^{l}=(F[x;\theta ]/(x^{s}-1))^{l}.$ The notions of
generator and parity-check polynomials are given. We also introduce the notion
of similar polynomials in the ring $F[x;\theta ]$ and show that parity-check
polynomials for skew QC codes are unique up to similarity. Our search results
lead to the construction of several new codes with Hamming distances exceeding
the Hamming distances of the previously best known linear codes with comparable
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2319</identifier>
 <datestamp>2009-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2319</id><created>2008-09-15</created><updated>2009-01-30</updated><authors><author><keyname>Datta</keyname><forenames>Samir</forenames></author><author><keyname>Limaye</keyname><forenames>Nutan</forenames></author><author><keyname>Nimbhorkar</keyname><forenames>Prajakta</forenames></author><author><keyname>Thierauf</keyname><forenames>Thomas</forenames></author><author><keyname>Wagner</keyname><forenames>Fabian</forenames></author></authors><title>A Log-space Algorithm for Canonization of Planar Graphs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph Isomorphism is the prime example of a computational problem with a wide
difference between the best known lower and upper bounds on its complexity. We
bridge this gap for a natural and important special case, planar graph
isomorphism, by presenting an upper bound that matches the known logspace
hardness [Lindell'92]. In fact, we show the formally stronger result that
planar graph canonization is in logspace. This improves the previously known
upper bound of AC1 [MillerReif'91].
  Our algorithm first constructs the biconnected component tree of a connected
planar graph and then refines each biconnected component into a triconnected
component tree. The next step is to logspace reduce the biconnected planar
graph isomorphism and canonization problems to those for 3-connected planar
graphs, which are known to be in logspace by [DattaLimayeNimbhorkar'08]. This
is achieved by using the above decomposition, and by making significant
modifications to Lindell's algorithm for tree canonization, along with changes
in the space complexity analysis.
  The reduction from the connected case to the biconnected case requires
further new ideas, including a non-trivial case analysis and a group theoretic
lemma to bound the number of automorphisms of a colored 3-connected planar
graph. This lemma is crucial for the reduction to work in logspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2322</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2322</id><created>2008-09-13</created><authors><author><keyname>Veerayya</keyname><forenames>Mallapur</forenames></author></authors><title>An Energy-Aware On-Demand Routing Protocol for Ad-Hoc Wireless Networks</title><categories>cs.NI</categories><comments>65 pages, Master's Thesis, Department of Elecrical Engineering, IIT
  Bombay</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An ad-hoc wireless network is a collection of nodes that come together to
dynamically create a network, with no fixed infrastructure or centralized
administration. An ad-hoc network is characterized by energy constrained nodes,
bandwidth constrained links and dynamic topology. With the growing use of
wireless networks (including ad-hoc networks) for real-time applications, such
as voice, video, and real-time data, the need for Quality of Service (QoS)
guarantees in terms of delay, bandwidth, and packet loss is becoming
increasingly important. Providing QoS in ad-hoc networks is a challenging task
because of dynamic nature of network topology and imprecise state information.
Hence, it is important to have a dynamic routing protocol with fast re-routing
capability, which also provides stable route during the life-time of the flows.
  In this thesis, we have proposed a novel, energy aware, stable routing
protocol named, Stability-based QoS-capable Ad-hoc On-demand Distance Vector
(SQ-AODV), which is an enhancement of the well-known Ad-hoc On-demand Distance
Vector (AODV) routing protocol for ad-hoc wireless networks. SQ-AODV utilizes a
cross-layer design approach in which information about the residual energy of a
node is used for route selection and maintenance. An important feature of
SQ-AODV protocol is that it uses only local information and requires no
additional communication or co-operation between the network nodes. SQ-AODV
possesses a make-before-break re-routing capability that enables near-zero
packet drops and is compatible with the basic AODV data formats and operation,
making it easy to adopt in ad-hoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2350</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2350</id><created>2008-09-13</created><authors><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>Stojanovic</keyname><forenames>Milica</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Random Linear Network Coding For Time Division Duplexing: When To Stop
  Talking And Start Listening</title><categories>cs.IT math.IT</categories><comments>9 pages, 9 figures, Submitted to INFOCOM'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new random linear network coding scheme for reliable communications for
time division duplexing channels is proposed. The setup assumes a packet
erasure channel and that nodes cannot transmit and receive information
simultaneously. The sender transmits coded data packets back-to-back before
stopping to wait for the receiver to acknowledge (ACK) the number of degrees of
freedom, if any, that are required to decode correctly the information. We
provide an analysis of this problem to show that there is an optimal number of
coded data packets, in terms of mean completion time, to be sent before
stopping to listen. This number depends on the latency, probabilities of packet
erasure and ACK erasure, and the number of degrees of freedom that the receiver
requires to decode the data. This scheme is optimal in terms of the mean time
to complete the transmission of a fixed number of data packets. We show that
its performance is very close to that of a full duplex system, while
transmitting a different number of coded packets can cause large degradation in
performance, especially if latency is high. Also, we study the throughput
performance of our scheme and compare it to existing half-duplex Go-back-N and
Selective Repeat ARQ schemes. Numerical results, obtained for different
latencies, show that our scheme has similar performance to the Selective Repeat
in most cases and considerable performance gain when latency and packet error
probability is high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2386</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2386</id><created>2008-09-14</created><updated>2012-04-15</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Dalmau</keyname><forenames>Victor</forenames></author></authors><title>Datalog and Constraint Satisfaction with Infinite Templates</title><categories>cs.LO cs.CC</categories><comments>28 pages. This is an extended long version of a conference paper that
  appeared at STACS'06. In the third version in the arxiv we have revised the
  presentation again and added a section that relates our results to
  formalizations of CSPs using relation algebras</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  On finite structures, there is a well-known connection between the expressive
power of Datalog, finite variable logics, the existential pebble game, and
bounded hypertree duality. We study this connection for infinite structures.
This has applications for constraint satisfaction with infinite templates. If
the template Gamma is omega-categorical, we present various equivalent
characterizations of those Gamma such that the constraint satisfaction problem
(CSP) for Gamma can be solved by a Datalog program. We also show that
CSP(Gamma) can be solved in polynomial time for arbitrary omega-categorical
structures Gamma if the input is restricted to instances of bounded treewidth.
Finally, we characterize those omega-categorical templates whose CSP has
Datalog width 1, and those whose CSP has strict Datalog width k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2394</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2394</id><created>2008-09-14</created><authors><author><keyname>Krivine</keyname><forenames>Jean-Louis</forenames><affiliation>PPS</affiliation></author></authors><title>Structures de r\'ealisabilit\'e, RAM et ultrafiltre sur N</title><categories>cs.LO</categories><comments>34 p</comments><proxy>ccsd hal-00321410</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to transform into programs the proofs in classical Analysis which
use the existence of an ultrafilter on the integers. The method mixes the
classical realizability introduced by the author, with the &quot;forcing&quot; of P.
Cohen. The programs we obtain, use read and write instructions in random access
memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2421</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2421</id><created>2008-09-14</created><updated>2011-04-18</updated><authors><author><keyname>Sarmiento</keyname><forenames>Juan Ojeda</forenames></author></authors><title>Electricity Demand and Energy Consumption Management System</title><categories>cs.AI cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This project describes the electricity demand and energy consumption
management system and its application to Southern Peru smelter. It is composed
of an hourly demand-forecasting module and of a simulation component for a
plant electrical system. The first module was done using dynamic neural
networks with backpropagation training algorithm; it is used to predict the
electric power demanded every hour, with an error percentage below of 1%. This
information allows efficient management of energy peak demands before this
happen, distributing the raise of electric load to other hours or improving
those equipments that increase the demand. The simulation module is based in
advanced estimation techniques, such as: parametric estimation, neural network
modeling, statistic regression and previously developed models, which simulates
the electric behavior of the smelter plant. These modules facilitate
electricity demand and consumption proper planning, because they allow knowing
the behavior of the hourly demand and the consumption patterns of the plant,
including the bill components, but also energy deficiencies and opportunities
for improvement, based on analysis of information about equipments, processes
and production plans, as well as maintenance programs. Finally the results of
its application in Southern Peru smelter are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2423</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2423</id><created>2008-09-14</created><updated>2008-11-13</updated><authors><author><keyname>Sousbie</keyname><forenames>T.</forenames></author><author><keyname>Colombi</keyname><forenames>S.</forenames></author><author><keyname>Pichon</keyname><forenames>C.</forenames></author></authors><title>The fully connected N-dimensional skeleton: probing the evolution of the
  cosmic web</title><categories>astro-ph cs.CG physics.comp-ph</categories><comments>Accepted for publication in MNRAS</comments><journal-ref>Mon.Not.Roy.Astron.Soc.393:457,2009</journal-ref><doi>10.1111/j.1365-2966.2008.14244.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method to compute the full hierarchy of the critical subsets of a density
field is presented. It is based on a watershed technique and uses a probability
propagation scheme to improve the quality of the segmentation by circumventing
the discreteness of the sampling. It can be applied within spaces of arbitrary
dimensions and geometry. This recursive segmentation of space yields, for a
$d$-dimensional space, a $d-1$ succession of $n$-dimensional subspaces that
fully characterize the topology of the density field. The final 1D manifold of
the hierarchy is the fully connected network of the primary critical lines of
the field : the skeleton. It corresponds to the subset of lines linking maxima
to saddle points, and provides a definition of the filaments that compose the
cosmic web as a precise physical object, which makes it possible to compute any
of its properties such as its length, curvature, connectivity etc... When the
skeleton extraction is applied to initial conditions of cosmological N-body
simulations and their present day non linear counterparts, it is shown that the
time evolution of the cosmic web, as traced by the skeleton, is well accounted
for by the Zel'dovich approximation. Comparing this skeleton to the initial
skeleton undergoing the Zel'dovich mapping shows that two effects are competing
during the formation of the cosmic web: a general dilation of the larger
filaments that is captured by a simple deformation of the skeleton of the
initial conditions on the one hand, and the shrinking, fusion and disappearance
of the more numerous smaller filaments on the other hand. Other applications of
the N dimensional skeleton and its peak patch hierarchy are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2443</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2443</id><created>2008-09-15</created><authors><author><keyname>Panda</keyname><forenames>B. S.</forenames></author><author><keyname>Pradhan</keyname><forenames>D.</forenames></author></authors><title>NP-Completeness of Hamiltonian Cycle Problem on Rooted Directed Path
  Graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hamiltonian cycle problem is to decide whether a given graph has a
Hamiltonian cycle. Bertossi and Bonuccelli (1986, Information Processing
Letters, 23, 195-200) proved that the Hamiltonian Cycle Problem is NP-Complete
even for undirected path graphs and left the Hamiltonian cycle problem open for
directed path graphs. Narasimhan (1989, Information Processing Letters, 32,
167-170) proved that the Hamiltonian Cycle Problem is NP-Complete even for
directed path graphs and left the Hamiltonian cycle problem open for rooted
directed path graphs. In this paper we resolve this open problem by proving
that the Hamiltonian Cycle Problem is also NP-Complete for rooted directed path
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2446</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2446</id><created>2008-09-15</created><updated>2009-09-16</updated><authors><author><keyname>Mohammed</keyname><forenames>Saif K.</forenames></author><author><keyname>Zaki</keyname><forenames>Ahmed</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>High-Rate Space-Time Coded Large MIMO Systems: Low-Complexity Detection
  and Channel Estimation</title><categories>cs.IT math.IT</categories><comments>v3: Performance/complexity comparison of the proposed scheme with
  other large-MIMO architectures/detectors has been added (Sec. IV-D). The
  paper has been accepted for publication in IEEE Journal of Selected Topics in
  Signal Processing (JSTSP): Spl. Iss. on Managing Complexity in Multiuser MIMO
  Systems. v2: Section V on Channel Estimation is updated</comments><doi>10.1109/JSTSP.2009.2035862</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a low-complexity algorithm for detection in
high-rate, non-orthogonal space-time block coded (STBC) large-MIMO systems that
achieve high spectral efficiencies of the order of tens of bps/Hz. We also
present a training-based iterative detection/channel estimation scheme for such
large STBC MIMO systems. Our simulation results show that excellent bit error
rate and nearness-to-capacity performance are achieved by the proposed
multistage likelihood ascent search (M-LAS) detector in conjunction with the
proposed iterative detection/channel estimation scheme at low complexities. The
fact that we could show such good results for large STBCs like 16x16 and 32x32
STBCs from Cyclic Division Algebras (CDA) operating at spectral efficiencies in
excess of 20 bps/Hz (even after accounting for the overheads meant for pilot
based training for channel estimation and turbo coding) establishes the
effectiveness of the proposed detector and channel estimator. We decode perfect
codes of large dimensions using the proposed detector. With the feasibility of
such a low-complexity detection/channel estimation scheme, large-MIMO systems
with tens of antennas operating at several tens of bps/Hz spectral efficiencies
can become practical, enabling interesting high data rate wireless
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2489</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2489</id><created>2008-09-15</created><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames></author><author><keyname>Husfeldt</keyname><forenames>Thore</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author></authors><title>The fast intersection transform with applications to counting paths</title><categories>cs.DS cs.DM</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for evaluating a linear ``intersection transform'' of
a function defined on the lattice of subsets of an $n$-element set. In
particular, the algorithm constructs an arithmetic circuit for evaluating the
transform in ``down-closure time'' relative to the support of the function and
the evaluation domain. As an application, we develop an algorithm that, given
as input a digraph with $n$ vertices and bounded integer weights at the edges,
counts paths by weight and given length $0\leq\ell\leq n-1$ in time
$O^*(\exp(n\cdot H(\ell/(2n))))$, where $H(p)=-p\log p-(1-p)\log(1-p)$, and the
notation $O^*(\cdot)$ suppresses a factor polynomial in $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2508</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2508</id><created>2008-09-15</created><updated>2008-09-16</updated><authors><author><keyname>Mohimani</keyname><forenames>Hossein</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Massoud</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>A fast approach for overcomplete sparse decomposition based on smoothed
  L0 norm</title><categories>cs.IT math.IT</categories><comments>Accepted in IEEE Transactions on Signal Processing. For MATLAB codes,
  see (http://ee.sharif.ir/~SLzero). File replaced, because Fig. 5 was missing
  erroneously</comments><doi>10.1109/TSP.2008.2007606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a fast algorithm for overcomplete sparse decomposition, called
SL0, is proposed. The algorithm is essentially a method for obtaining sparse
solutions of underdetermined systems of linear equations, and its applications
include underdetermined Sparse Component Analysis (SCA), atomic decomposition
on overcomplete dictionaries, compressed sensing, and decoding real field
codes. Contrary to previous methods, which usually solve this problem by
minimizing the L1 norm using Linear Programming (LP) techniques, our algorithm
tries to directly minimize the L0 norm. It is experimentally shown that the
proposed algorithm is about two to three orders of magnitude faster than the
state-of-the-art interior-point LP solvers, while providing the same (or
better) accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2525</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2525</id><created>2008-09-15</created><authors><author><keyname>Grabisch</keyname><forenames>Michel</forenames><affiliation>CES</affiliation></author><author><keyname>Miranda</keyname><forenames>Pedro</forenames></author></authors><title>On the vertices of the k-addiive core</title><categories>cs.DM cs.GT</categories><proxy>ccsd hal-00321625</proxy><journal-ref>Discrete Mathematics (2008) 5204-5217</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The core of a game $v$ on $N$, which is the set of additive games $\phi$
dominating $v$ such that $\phi(N)=v(N)$, is a central notion in cooperative
game theory, decision making and in combinatorics, where it is related to
submodular functions, matroids and the greedy algorithm. In many cases however,
the core is empty, and alternative solutions have to be found. We define the
$k$-additive core by replacing additive games by $k$-additive games in the
definition of the core, where $k$-additive games are those games whose M\&quot;obius
transform vanishes for subsets of more than $k$ elements. For a sufficiently
high value of $k$, the $k$-additive core is nonempty, and is a convex closed
polyhedron. Our aim is to establish results similar to the classical results of
Shapley and Ichiishi on the core of convex games (corresponds to Edmonds'
theorem for the greedy algorithm), which characterize the vertices of the core.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2532</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2532</id><created>2008-09-15</created><authors><author><keyname>Poder</keyname><forenames>Tanel</forenames></author><author><keyname>Gunther</keyname><forenames>Neil J.</forenames></author></authors><title>Multidimensional Visualization of Oracle Performance Using Barry007</title><categories>cs.PF cs.DB</categories><comments>To appear in the Proc. CMG International Conference, Las Vegas,
  Nevada, December 2008</comments><acm-class>B.8; C.4; D.4.8; H.2.4; H.2.7; H.3.4; H.5.1; K.8.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most generic performance tools display only system-level performance data
using 2-dimensional plots or diagrams and this limits the informational detail
that can be displayed. Moreover, a modern relational database system, like
Oracle, can concurrently serve thousands of client processes with different
workload characteristics, so that generic performance-data displays inevitably
hide important information. Drawing on our previous work, this paper
demonstrates the application of Barry007 multidimensional visualization to the
analysis of Oracle end-user, session-level, performance data, showing both
collective trends and individual performance anomalies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2541</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2541</id><created>2008-09-15</created><authors><author><keyname>Holtman</keyname><forenames>Jim</forenames></author><author><keyname>Gunther</keyname><forenames>Neil J.</forenames></author></authors><title>Getting in the Zone for Successful Scalability</title><categories>cs.PF cs.DC</categories><comments>14 pages, 15 figures. To appear in Proc. CMG International
  Conference, Las Vegas, Nevada, December 2008</comments><acm-class>B.8; C.4; C.5.5; D.4.8; F.1.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The universal scalability law (USL) is an analytic model used to quantify
application scaling. It is universal because it subsumes Amdahl's law and
Gustafson linearized scaling as special cases. Using simulation, we show: (i)
that the USL is equivalent to synchronous queueing in a load-dependent machine
repairman model and (ii) how USL, Amdahl's law, and Gustafson scaling can be
regarded as boundaries defining three scalability zones. Typical throughput
measurements lie across all three zones. Simulation scenarios provide deeper
insight into queueing effects and thus provide a clearer indication of which
application features should be tuned to get into the optimal performance zone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2546</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2546</id><created>2008-09-15</created><authors><author><keyname>Antunes</keyname><forenames>Luis</forenames><affiliation>Univ. Porto</affiliation></author><author><keyname>Matos</keyname><forenames>Armando</forenames><affiliation>Univ. Porto</affiliation></author><author><keyname>Souto</keyname><forenames>Andre</forenames><affiliation>Univ. Porto</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul</forenames><affiliation>CWI and Univ. Amsterdam</affiliation></author></authors><title>Depth as Randomness Deficiency</title><categories>cs.CC cs.IT math.IT</categories><comments>Lates, 15 pages, no figures. Theory of Computing Systems, To appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Depth of an object concerns a tradeoff between computation time and excess of
program length over the shortest program length required to obtain the object.
It gives an unconditional lower bound on the computation time from a given
program in absence of auxiliary information. Variants known as logical depth
and computational depth are expressed in Kolmogorov complexity theory.
  We derive quantitative relation between logical depth and computational depth
and unify the different depth notions by relating them to A. Kolmogorov and L.
Levin's fruitful notion of randomness deficiency. Subsequently, we revisit the
computational depth of infinite strings, introducing the notion of super deep
sequences and relate it with other approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2553</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2553</id><created>2008-09-15</created><authors><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI and Univ. Amsterdam</affiliation></author><author><keyname>Balbach</keyname><forenames>Frank J.</forenames><affiliation>Univ. Waterloo</affiliation></author><author><keyname>Cilibrasi</keyname><forenames>Rudi L.</forenames><affiliation>CWI</affiliation></author><author><keyname>Li</keyname><forenames>Ming</forenames><affiliation>Univ. Waterloo</affiliation></author></authors><title>Normalized Information Distance</title><categories>cs.IR cs.AI</categories><comments>33 pages, 12 figures, pdf, in: Normalized information distance, in:
  Information Theory and Statistical Learning, Eds. M. Dehmer, F.
  Emmert-Streib, Springer-Verlag, New-York, To appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The normalized information distance is a universal distance measure for
objects of all kinds. It is based on Kolmogorov complexity and thus
uncomputable, but there are ways to utilize it. First, compression algorithms
can be used to approximate the Kolmogorov complexity if the objects have a
string representation. Second, for names and abstract concepts, page count
statistics from the World Wide Web can be used. These practical realizations of
the normalized information distance can then be applied to machine learning
tasks, expecially clustering, to perform feature-free and parameter-free data
mining. This chapter discusses the theoretical foundations of the normalized
information distance and both practical realizations. It presents numerous
examples of successful real-world applications based on these distance
measures, ranging from bioinformatics to music clustering to machine
translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2554</identifier>
 <datestamp>2008-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2554</id><created>2008-09-15</created><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Tangwongsan</keyname><forenames>Kanat</forenames></author></authors><title>Simpler Analyses of Local Search Algorithms for Facility Location</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study local search algorithms for metric instances of facility location
problems: the uncapacitated facility location problem (UFL), as well as
uncapacitated versions of the $k$-median, $k$-center and $k$-means problems.
All these problems admit natural local search heuristics: for example, in the
UFL problem the natural moves are to open a new facility, close an existing
facility, and to swap a closed facility for an open one; in $k$-medians, we are
allowed only swap moves. The local-search algorithm for $k$-median was analyzed
by Arya et al. (SIAM J. Comput. 33(3):544-562, 2004), who used a clever
``coupling'' argument to show that local optima had cost at most constant times
the global optimum. They also used this argument to show that the local search
algorithm for UFL was 3-approximation; their techniques have since been applied
to other facility location problems.
  In this paper, we give a proof of the $k$-median result which avoids this
coupling argument. These arguments can be used in other settings where the Arya
et al. arguments have been used. We also show that for the problem of opening
$k$ facilities $F$ to minimize the objective function $\Phi_p(F) = \big(\sum_{j
\in V} d(j, F)^p\big)^{1/p}$, the natural swap-based local-search algorithm is
a $\Theta(p)$-approximation. This implies constant-factor approximations for
$k$-medians (when $p=1$), and $k$-means (when $p = 2$), and an $O(\log
n)$-approximation algorithm for the $k$-center problem (which is essentially $p
= \log n$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2639</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2639</id><created>2008-09-16</created><authors><author><keyname>Wu</keyname><forenames>Yiyue</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Code diversity in multiple antenna wireless communication</title><categories>cs.IT math.IT</categories><comments>9 pages</comments><doi>10.1109/JSTSP.2009.2035861</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard approach to the design of individual space-time codes is based
on optimizing diversity and coding gains. This geometric approach leads to
remarkable examples, such as perfect space-time block codes, for which the
complexity of Maximum Likelihood (ML) decoding is considerable. Code diversity
is an alternative and complementary approach where a small number of feedback
bits are used to select from a family of space-time codes. Different codes lead
to different induced channels at the receiver, where Channel State Information
(CSI) is used to instruct the transmitter how to choose the code. This method
of feedback provides gains associated with beamforming while minimizing the
number of feedback bits. It complements the standard approach to code design by
taking advantage of different (possibly equivalent) realizations of a
particular code design. Feedback can be combined with sub-optimal low
complexity decoding of the component codes to match ML decoding performance of
any individual code in the family. It can also be combined with ML decoding of
the component codes to improve performance beyond ML decoding performance of
any individual code. One method of implementing code diversity is the use of
feedback to adapt the phase of a transmitted signal as shown for 4 by 4
Quasi-Orthogonal Space-Time Block Code (QOSTBC) and multi-user detection using
the Alamouti code. Code diversity implemented by selecting from equivalent
variants is used to improve ML decoding performance of the Golden code. This
paper introduces a family of full rate circulant codes which can be linearly
decoded by fourier decomposition of circulant matrices within the code
diversity framework. A 3 by 3 circulant code is shown to outperform the
Alamouti code at the same transmission rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2651</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2651</id><created>2008-09-16</created><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Putnam</keyname><forenames>Brian</forenames></author><author><keyname>Roy</keyname><forenames>Sasanka</forenames></author></authors><title>Largest Empty Circle Centered on a Query Line</title><categories>cs.CG</categories><comments>18 pages, 13 figures</comments><doi>10.1016/j.jda.2009.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Largest Empty Circle problem seeks the largest circle centered within the
convex hull of a set $P$ of $n$ points in $\mathbb{R}^2$ and devoid of points
from $P$. In this paper, we introduce a query version of this well-studied
problem. In our query version, we are required to preprocess $P$ so that when
given a query line $Q$, we can quickly compute the largest empty circle
centered at some point on $Q$ and within the convex hull of $P$.
  We present solutions for two special cases and the general case; all our
queries run in $O(\log n)$ time. We restrict the query line to be horizontal in
the first special case, which we preprocess in $O(n \alpha(n) \log n)$ time and
space, where $\alpha(n)$ is the slow growing inverse of the Ackermann's
function. When the query line is restricted to pass through a fixed point, the
second special case, our preprocessing takes $O(n \alpha(n)^{O(\alpha(n))} \log
n)$ time and space. We use insights from the two special cases to solve the
general version of the problem with preprocessing time and space in $O(n^3 \log
n)$ and $O(n^3)$ respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2680</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2680</id><created>2008-09-16</created><authors><author><keyname>Bagdasaryan</keyname><forenames>Armen</forenames></author></authors><title>Mathematical Tool of Discrete Dynamic Modeling of Complex Systems in
  Control Loop</title><categories>cs.MA cs.CE</categories><comments>9 pages, paper presented at the American Conference on Applied
  Mathematics (MATH'08), Harvard University; published in book Recent Advances
  on Applied Mathematics, WSEAS Press, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a method of discrete modeling and analysis of
multi-level dynamics of complex large-scale hierarchical dynamic systems
subject to external dynamic control mechanism. In a model each state describes
parallel dynamics and simultaneous trends of changes in system parameters. The
essence of the approach is in analysis of system state dynamics while it is in
the control loop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2686</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2686</id><created>2008-09-16</created><authors><author><keyname>Boussa&#xef;d</keyname><forenames>Omar</forenames><affiliation>ERIC</affiliation></author><author><keyname>Bentayeb</keyname><forenames>Fadila</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>An MAS-Based ETL Approach for Complex Data</title><categories>cs.DB</categories><comments>in 10th ISPE International Conference on Concurrent Engineering:
  Research and Applications (CE 03), Madeira : Portugal (2003)</comments><proxy>ccsd hal-00321977</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a data warehousing process, the phase of data integration is crucial. Many
methods for data integration have been published in the literature. However,
with the development of the Internet, the availability of various types of data
(images, texts, sounds, videos, databases...) has increased, and structuring
such data is a difficult task. We name these data, which may be structured or
unstructured, &quot;complex data&quot;. In this paper, we propose a new approach for
complex data integration, based on a Multi-Agent System (MAS), in association
to a data warehousing approach. Our objective is to take advantage of the MAS
to perform the integration phase for complex data. We indeed consider the
different tasks of the data integration process as services offered by agents.
To validate this approach, we have actually developed an MAS for complex data
integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2687</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2687</id><created>2008-09-16</created><authors><author><keyname>Aouiche</keyname><forenames>Kamel</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author><author><keyname>Gruenwald</keyname><forenames>Le</forenames></author></authors><title>Frequent itemsets mining for database auto-administration</title><categories>cs.DB</categories><comments>in 7th International Database Engineering and Application Symposium
  (IDEAS 03), Hong-Kong : Chine (2003)</comments><proxy>ccsd hal-00321980</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the wide development of databases in general and data warehouses in
particular, it is important to reduce the tasks that a database administrator
must perform manually. The aim of auto-administrative systems is to
administrate and adapt themselves automatically without loss (or even with a
gain) in performance. The idea of using data mining techniques to extract
useful knowledge for administration from the data themselves has existed for
some years. However, little research has been achieved. This idea nevertheless
remains a very promising approach, notably in the field of data warehousing,
where queries are very heterogeneous and cannot be interpreted easily. The aim
of this study is to search for a way of extracting useful knowledge from stored
data themselves to automatically apply performance optimization techniques, and
more particularly indexing techniques. We have designed a tool that extracts
frequent itemsets from a given workload to compute an index configuration that
helps optimizing data access time. The experiments we performed showed that the
index configurations generated by our tool allowed performance gains of 15% to
25% on a test database and a test data warehouse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2688</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2688</id><created>2008-09-16</created><authors><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author><author><keyname>Olivier</keyname><forenames>Emerson</forenames><affiliation>ERIC</affiliation></author></authors><title>A Complex Data Warehouse for Personalized, Anticipative Medicine</title><categories>cs.DB</categories><comments>in 17th Information Resources Management Association International
  Conference (IRMA 06), Wahsington, DC : \'Etats-Unis d'Am\'erique (2006)</comments><proxy>ccsd hal-00321989</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing use of new technologies, healthcare is nowadays undergoing
significant changes. Information-based medicine has to exploit medical
decision-support systems and requires the analysis of various, heterogeneous
data, such as patient records, medical images, biological analysis results,
etc. In this paper, we present the design of the complex data warehouse
relating to high-level athletes. It is original in two ways. First, it is aimed
at storing complex medical data. Second, it is designed to allow innovative and
quite different kinds of analyses to support: (1) personalized and anticipative
medicine (in opposition to curative medicine) for well-identified patients; (2)
broad-band statistical studies over a given population of patients.
Furthermore, the system includes data relating to several medical fields. It is
also designed to be evolutionary to take into account future advances in
medical research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2691</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2691</id><created>2008-09-16</created><authors><author><keyname>Hachicha</keyname><forenames>Marouane</forenames><affiliation>ERIC</affiliation></author><author><keyname>Mahboubi</keyname><forenames>Hadj</forenames><affiliation>ERIC</affiliation></author><author><keyname>Darmont</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>ERIC</affiliation></author></authors><title>Expressing OLAP operators with the TAX XML algebra</title><categories>cs.DB</categories><comments>in 3rd International Workshop on Database Technologies for Handling
  XML Information on the Web (DataX-EDBT 08), Nantes : France (2008)</comments><proxy>ccsd hal-00321993</proxy><acm-class>H.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rise of XML as a standard for representing business data, XML data
warehouses appear as suitable solutions for Web-based decision-support
applications. In this context, it is necessary to allow OLAP analyses over XML
data cubes (XOLAP). Thus, XQuery extensions are needed. To help define a formal
framework and allow much-needed performance optimizations on analytical queries
expressed in XQuery, having an algebra at one's disposal is desirable. However,
XOLAP approaches and algebras from the literature still largely rely on the
relational model and/or only feature a small number of OLAP operators. In
opposition, we propose in this paper to express a broad set of OLAP operators
with the TAX XML algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2696</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2696</id><created>2008-09-16</created><authors><author><keyname>Schommer</keyname><forenames>Christoph</forenames></author></authors><title>An Unified Definition of Data Mining</title><categories>cs.SC cs.CY</categories><comments>7 pages, 3 figures</comments><acm-class>H.2.8; K.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since many years, theoretical concepts of Data Mining have been developed and
improved. Data Mining has become applied to many academic and industrial
situations, and recently, soundings of public opinion about privacy have been
carried out. However, a consistent and standardized definition is still
missing, and the initial explanation given by Frawley et al. has pragmatically
often changed over the years. Furthermore, alternative terms like Knowledge
Discovery have been conjured and forged, and a necessity of a Data Warehouse
has been endeavoured to persuade the users. In this work, we pick up current
definitions and introduce an unified definition that covers existing attempted
explanations. For this, we appeal to the natural original of chemical states of
aggregation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2730</identifier>
 <datestamp>2009-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2730</id><created>2008-09-16</created><updated>2009-01-22</updated><authors><author><keyname>Mei</keyname><forenames>Alessandro</forenames><affiliation>Department of Computer Science, Sapienza University of Rome, Italy</affiliation></author><author><keyname>Stefa</keyname><forenames>Julinda</forenames><affiliation>Department of Computer Science, Sapienza University of Rome, Italy</affiliation></author></authors><title>SWIM: A Simple Model to Generate Small Mobile Worlds</title><categories>cs.DC cs.NI</categories><comments>Accepted for publication in IEEE INFOCOM 09, Rio de Janeiro, Brazil,
  April 2009</comments><acm-class>C.2; C.2.1; C.2.2; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents small world in motion (SWIM), a new mobility model for
ad-hoc networking. SWIM is relatively simple, is easily tuned by setting just a
few parameters, and generates traces that look real--synthetic traces have the
same statistical properties of real traces. SWIM shows experimentally and
theoretically the presence of the power law and exponential decay dichotomy of
inter-contact time, and, most importantly, our experiments show that it can
predict very accurately the performance of forwarding protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2754</identifier>
 <datestamp>2008-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2754</id><created>2008-09-16</created><updated>2008-09-17</updated><authors><author><keyname>Grunwald</keyname><forenames>Peter D.</forenames><affiliation>CWI</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI and Univ. Amsterdam</affiliation></author></authors><title>Algorithmic information theory</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>37 pages, 2 figures, pdf, in: Philosophy of Information, P. Adriaans
  and J. van Benthem, Eds., A volume in Handbook of the philosophy of science,
  D. Gabbay, P. Thagard, and J. Woods, Eds., Elsevier, 2008. In version 1 of
  September 16 the refs are missing. Corrected in version 2 of September 17</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce algorithmic information theory, also known as the theory of
Kolmogorov complexity. We explain the main concepts of this quantitative
approach to defining `information'. We discuss the extent to which Kolmogorov's
and Shannon's information theory have a common purpose, and where they are
fundamentally different. We indicate how recent developments within the theory
allow one to formally distinguish between `structural' (meaningful) and
`random' information as measured by the Kolmogorov structure function, which
leads to a mathematical formalization of Occam's razor in inductive inference.
We end by discussing some of the philosophical implications of the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2768</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2768</id><created>2008-09-16</created><updated>2008-10-15</updated><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Hubs and Clusters in the Evolving U. S. Internal Migration Network</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>38 pages, 16 figures, 2 tables. Additional analyses of the 1995-2000
  migration data and new figures are presented in Secs. V.C and V.D. To examine
  the four (searchable) master dendrograms (the first two [cardinal and
  ordinal] based on the doubly-stochastic table, and the next two, on its
  square), one must download the source</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most nations of the world periodically publish N x N origin-destination
tables, recording the number of people who lived in geographic subdivision i at
time t and j at t+1. We have developed and widely applied to such national
tables and other analogous (weighted, directed) socioeconomic networks, a
two-stage--double-standardization and (strong component) hierarchical
clustering--procedure. Previous applications of this methodology and related
analytical issues are discussed. Its use is illustrated in a large-scale study,
employing recorded United States internal migration flows between the 3,000+
county-level units of the nation for the periods 1965-1970 and 1995-2000.
Prominent, important features--such as ''cosmopolitan hubs'' and ``functional
regions''--are extracted from master dendrograms. The extent to which such
characteristics have varied over the intervening thirty years is evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2792</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2792</id><created>2008-09-16</created><updated>2009-06-24</updated><authors><author><keyname>Luss</keyname><forenames>Ronny</forenames></author><author><keyname>d'Aspremont</keyname><forenames>Alexandre</forenames></author></authors><title>Predicting Abnormal Returns From News Using Text Classification</title><categories>cs.LG cs.AI</categories><comments>Larger data sets, results on time of day effect, and use of delta
  hedged covered call options to trade on daily predictions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how text from news articles can be used to predict intraday price
movements of financial assets using support vector machines. Multiple kernel
learning is used to combine equity returns with text as predictive features to
increase classification performance and we develop an analytic center cutting
plane method to solve the kernel learning problem efficiently. We observe that
while the direction of returns is not predictable using either text or returns,
their size is, with text features producing significantly better performance
than historical returns alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2818</identifier>
 <datestamp>2008-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2818</id><created>2008-09-16</created><authors><author><keyname>Schommer</keyname><forenames>Christoph</forenames></author></authors><title>A Simple Framework to Typify Social Bibliographic Communities</title><categories>cs.DL cs.CG</categories><comments>14 pages, 12 figures</comments><acm-class>H.3.1; H.3.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social Communities in bibliographic databases exist since many years,
researchers share common research interests, and work and publish together. A
social community may vary in type and size, being fully connected between
participating members or even more expressed by a consortium of small and
individual members who play individual roles in it. In this work, we focus on
social communities inside the bibliographic database DBLP and characterize
communities through a simple typifying description model. Generally, we
understand a publication as a transaction between the associated authors. The
idea therefore is to concern with directed associative relationships among
them, to decompose each pattern to its fundamental structure, and to describe
the communities by expressive attributes. Finally, we argue that the
decomposition supports the management of discovered structures towards the use
of adaptive-incremental mind-maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2835</identifier>
 <datestamp>2009-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2835</id><created>2008-09-16</created><authors><author><keyname>Grokop</keyname><forenames>Leonard</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Fundamental Constraints on Multicast Capacity Regions</title><categories>cs.IT math.IT</categories><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much of the existing work on the broadcast channel focuses only on the
sending of private messages. In this work we examine the scenario where the
sender also wishes to transmit common messages to subsets of receivers. For an
L user broadcast channel there are 2L - 1 subsets of receivers and
correspondingly 2L - 1 independent messages. The set of achievable rates for
this channel is a 2L - 1 dimensional region. There are fundamental constraints
on the geometry of this region. For example, observe that if the transmitter is
able to simultaneously send L rate-one private messages, error-free to all
receivers, then by sending the same information in each message, it must be
able to send a single rate-one common message, error-free to all receivers.
This swapping of private and common messages illustrates that for any broadcast
channel, the inclusion of a point R* in the achievable rate region implies the
achievability of a set of other points that are not merely component-wise less
than R*. We formerly define this set and characterize it for L = 2 and L = 3.
Whereas for L = 2 all the points in the set arise only from operations relating
to swapping private and common messages, for L = 3 a form of network coding is
required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2840</identifier>
 <datestamp>2008-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2840</id><created>2008-09-16</created><authors><author><keyname>Grokop</keyname><forenames>Leonard</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Spectrum Sharing between Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of two wireless networks operating on the same
(presumably unlicensed) frequency band. Pairs within a given network cooperate
to schedule transmissions, but between networks there is competition for
spectrum. To make the problem tractable, we assume transmissions are scheduled
according to a random access protocol where each network chooses an access
probability for its users. A game between the two networks is defined. We
characterize the Nash Equilibrium behavior of the system. Three regimes are
identified; one in which both networks simultaneously schedule all
transmissions; one in which the denser network schedules all transmissions and
the sparser only schedules a fraction; and one in which both networks schedule
only a fraction of their transmissions. The regime of operation depends on the
pathloss exponent $\alpha$, the latter regime being desirable, but attainable
only for $\alpha&gt;4$. This suggests that in certain environments, rival wireless
networks may end up naturally cooperating. To substantiate our analytical
results, we simulate a system where networks iteratively optimize their access
probabilities in a greedy manner. We also discuss a distributed scheduling
protocol that employs carrier sensing, and demonstrate via simulations, that
again a near cooperative equilibrium exists for sufficiently large $\alpha$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2851</identifier>
 <datestamp>2008-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2851</id><created>2008-09-17</created><updated>2008-10-21</updated><authors><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Magudamudi</keyname><forenames>Manoranjan</forenames></author></authors><title>Correlation of Expert and Search Engine Rankings</title><categories>cs.DL</categories><comments>10 pages, 5 figures (figures 3-5 corrected in version 2)</comments><acm-class>H.3.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous research it has been shown that link-based web page metrics can
be used to predict experts' assessment of quality. We are interested in a
related question: do expert rankings of real-world entities correlate with
search engine rankings of corresponding web resources? For example, each year
US News &amp; World Report publishes a list of (among others) top 50 graduate
business schools. Does their expert ranking correlate with the search engine
ranking of the URLs of those business schools? To answer this question we
conducted 9 experiments using 8 expert rankings on a range of academic,
athletic, financial and popular culture topics. We compared the expert rankings
with the rankings in Google, Live Search (formerly MSN) and Yahoo (with list
lengths of 10, 25, and 50). In 57 search engine vs. expert comparisons, only 1
strong and 4 moderate correlations were statistically significant. In 42
inter-search engine comparisons, only 2 strong and 4 moderate correlations were
statistically significant. The correlations appeared to decrease with the size
of the lists: the 3 strong correlations were for lists of 10, the 8 moderate
correlations were for lists of 25, and no correlations were found for lists of
50.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2858</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2858</id><created>2008-09-17</created><updated>2008-09-17</updated><authors><author><keyname>Bessy</keyname><forenames>Stephane</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author><author><keyname>Perez</keyname><forenames>Anthony</forenames></author></authors><title>Polynomial kernels for 3-leaf power graph modification problems</title><categories>cs.DM cs.DS</categories><comments>Submitted</comments><acm-class>F.2; G.2.1; G.2.2</acm-class><doi>10.1007/978-3-642-10217-2_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph G=(V,E) is a 3-leaf power iff there exists a tree T whose leaves are
V and such that (u,v) is an edge iff u and v are at distance at most 3 in T.
The 3-leaf power graph edge modification problems, i.e. edition (also known as
the closest 3-leaf power), completion and edge-deletion, are FTP when
parameterized by the size of the edge set modification. However polynomial
kernel was known for none of these three problems. For each of them, we provide
cubic kernels that can be computed in linear time for each of these problems.
We thereby answer an open problem first mentioned by Dom, Guo, Huffner and
Niedermeier (2005).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2884</identifier>
 <datestamp>2008-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2884</id><created>2008-09-17</created><authors><author><keyname>Das</keyname><forenames>Bidu Prakash</forenames></author><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author></authors><title>On an algorithm that generates an interesting maximal set P(n) of the
  naturals for any n greater than or equal to 2</title><categories>cs.DM</categories><comments>There are some problems with the page numbering. I could not remove
  the unwanted page numbers! please read the pages one after another as they
  come. There are 11 pages in all</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper considers the problem of finding the largest possible set P(n), a
subset of the set N of the natural numbers, with the property that a number is
in P(n) if and only if it is a sum of n distinct naturals all in P(n) or none
in P(n). Here largest is in the set theoretic sense and n is greater than or
equal to 2. We call P(n) a maximal set obeying this property. For small n say 2
or 3, it is possible to develop P(n) intuitively but we strongly felt the
necessity of an algorithm for any n greater than or equal to 2. Now P(n) shall
invariably be a infinite set so we define another set Q(n) such that
Q(n)=N-P(n), prove that Q(n) is finite and, since P(n) is automatically known
if Q(n) is known, design an algorithm of worst case O(1) complexity which
generates Q(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2931</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2931</id><created>2008-09-17</created><authors><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author><author><keyname>Jayaprakasam</keyname><forenames>ArunKumar</forenames></author></authors><title>An Efficient Algorithm for Cooperative Spectrum Sensing in Cognitive
  Radio Networks</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of Spectrum Sensing in Cognitive Radio Systems. We
have developed a distributed algorithm that the Secondary users can run to
sense the channel cooperatively. It is based on sequential detection algorithms
which optimally use the past observations. We use the algorithm on secondary
users with energy detectors although it can be used with matched filter and
other spectrum sensing algorithms also. The algorithm provides very low
detection delays and also consumes little energy. Furthermore it causes low
interference to the primary users. We compare this algorithm to several
recently proposed algorithms and show that it detects changes in spectrum
faster than these algorithms and uses significantly less energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2956</identifier>
 <datestamp>2008-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2956</id><created>2008-09-17</created><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Carmi</keyname><forenames>Paz</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author><author><keyname>Xu</keyname><forenames>Daming</forenames></author></authors><title>Communication-Efficient Construction of the Plane Localized Delaunay
  Graph</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $V$ be a finite set of points in the plane. We present a 2-local
algorithm that constructs a plane $\frac{4 \pi \sqrt{3}}{9}$-spanner of the
unit-disk graph $\UDG(V)$. This algorithm makes only one round of communication
and each point of $V$ broadcasts at most 5 messages. This improves the
previously best message-bound of 11 by Ara\'{u}jo and Rodrigues (Fast localized
Delaunay triangulation, Lecture Notes in Computer Science, volume 3544, 2004).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2957</identifier>
 <datestamp>2008-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2957</id><created>2008-09-17</created><authors><author><keyname>Elizalde</keyname><forenames>Sergi</forenames></author><author><keyname>Winkler</keyname><forenames>Peter</forenames></author></authors><title>Sorting by Placement and Shift</title><categories>math.CO cs.DM cs.DS</categories><comments>13 pages, 4 figures, Proceedings of SODA 2009</comments><msc-class>68W40 (Primary); 68R05, 05A05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sorting situations where the final destination of each item is known, it
is natural to repeatedly choose items and place them where they belong,
allowing the intervening items to shift by one to make room. (In fact, a
special case of this algorithm is commonly used to hand-sort files.) However,
it is not obvious that this algorithm necessarily terminates.
  We show that in fact the algorithm terminates after at most $2^{n-1}-1$ steps
in the worst case (confirming a conjecture of L. Larson), and that there are
super-exponentially many permutations for which this exact bound can be
achieved. The proof involves a curious symmetrical binary representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2965</identifier>
 <datestamp>2009-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2965</id><created>2008-09-17</created><updated>2009-08-11</updated><authors><author><keyname>Daylight</keyname><forenames>E. G.</forenames><affiliation>Univ. Amsterdam</affiliation></author><author><keyname>Koolen</keyname><forenames>W. M.</forenames><affiliation>CWI</affiliation></author><author><keyname>Vitanyi</keyname><forenames>P. M. B.</forenames><affiliation>CWI and Univ Amsterdam</affiliation></author></authors><title>On Time-Bounded Incompressibility of Compressible Strings and Sequences</title><categories>cs.CC cs.IT math.IT</categories><comments>9 pages, LaTeX, no figures, submitted to Information Processing
  Letters. Changed and added a Barzdins-like lemma for infinite sequences with
  different quantification oreder, a fixed constant, and uncountably many
  sequences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For every total recursive time bound $t$, a constant fraction of all
compressible (low Kolmogorov complexity) strings is $t$-bounded incompressible
(high time-bounded Kolmogorov complexity); there are uncountably many infinite
sequences of which every initial segment of length $n$ is compressible to $\log
n$ yet $t$-bounded incompressible below ${1/4}n - \log n$; and there are
countable infinitely many recursive infinite sequence of which every initial
segment is similarly $t$-bounded incompressible. These results are related to,
but different from, Barzdins's lemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2968</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2968</id><created>2008-09-17</created><updated>2009-06-23</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Bounds on Covering Codes with the Rank Metric</title><categories>cs.IT math.IT</categories><comments>8 pages, 1 table, extended version with all the proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate geometrical properties of the rank metric space
and covering properties of rank metric codes. We first establish an analytical
expression for the intersection of two balls with rank radii, and then derive
an upper bound on the volume of the union of multiple balls with rank radii.
Using these geometrical properties, we derive both upper and lower bounds on
the minimum cardinality of a code with a given rank covering radius. The
geometrical properties and bounds proposed in this paper are significant to the
design, decoding, and performance analysis of rank metric codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2970</identifier>
 <datestamp>2008-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2970</id><created>2008-09-17</created><authors><author><keyname>Yuster</keyname><forenames>Raphael</forenames></author></authors><title>Single source shortest paths in $H$-minor free graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for the Single Source Shortest Paths (SSSP) problem
in \emph{$H$-minor free} graphs. For every fixed $H$, if $G$ is a graph with
$n$ vertices having integer edge lengths and $s$ is a designated source vertex
of $G$, the algorithm runs in $\tilde{O}(n^{\sqrt{11.5}-2} \log L) \le
O(n^{1.392} \log L)$ time, where $L$ is the absolute value of the smallest edge
length. The algorithm computes shortest paths and the distances from $s$ to all
vertices of the graph, or else provides a certificate that $G$ is not $H$-minor
free. Our result improves an earlier $O(n^{1.5} \log L)$ time algorithm for
this problem, which follows from a general SSSP algorithm of Goldberg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2978</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2978</id><created>2008-09-17</created><updated>2010-06-09</updated><authors><author><keyname>Wilkening</keyname><forenames>Jon</forenames></author><author><keyname>Yu</keyname><forenames>Jia</forenames></author></authors><title>A local construction of the Smith normal form of a matrix polynomial</title><categories>cs.SC</categories><comments>26 pages, 6 figures; introduction expanded, 10 references added, two
  additional tests performed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for computing a Smith form with multipliers of a
regular matrix polynomial over a field. This algorithm differs from previous
ones in that it computes a local Smith form for each irreducible factor in the
determinant separately and then combines them into a global Smith form, whereas
other algorithms apply a sequence of unimodular row and column operations to
the original matrix. The performance of the algorithm in exact arithmetic is
reported for several test cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2995</identifier>
 <datestamp>2009-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2995</id><created>2008-09-17</created><updated>2009-02-08</updated><authors><author><keyname>Boguna</keyname><forenames>Marian</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author></authors><title>Navigating ultrasmall worlds in ultrashort time</title><categories>cond-mat.dis-nn cs.NI physics.soc-ph</categories><comments>4 pages, 2 figures</comments><journal-ref>Phys. Rev. Lett. 102, 058701 (2009)</journal-ref><doi>10.1103/PhysRevLett.102.058701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random scale-free networks are ultrasmall worlds. The average length of the
shortest paths in networks of size N scales as lnlnN. Here we show that these
ultrasmall worlds can be navigated in ultrashort time. Greedy routing on
scale-free networks embedded in metric spaces finds paths with the average
length scaling also as lnlnN. Greedy routing uses only local information to
navigate a network. Nevertheless, it finds asymptotically the shortest paths, a
direct computation of which requires global topology knowledge. Our findings
imply that the peculiar structure of complex networks ensures that the lack of
global topological awareness has asymptotically no impact on the length of
communication paths. These results have important consequences for
communication systems such as the Internet, where maintaining knowledge of
current topology is a major scalability bottleneck.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3009</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3009</id><created>2008-09-17</created><authors><author><keyname>Hodnigg</keyname><forenames>Karin</forenames></author><author><keyname>Mittermeir</keyname><forenames>Roland T.</forenames></author></authors><title>Metrics-Based Spreadsheet Visualization: Support for Focused Maintenance</title><categories>cs.SE cs.HC</categories><comments>16 Pages, 7 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 79-94
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Legacy spreadsheets are both, an asset, and an enduring problem concerning
spreadsheets in business. To make spreadsheets stay alive and remain correct,
comprehension of a given spreadsheet is highly important. Visualization
techniques should ease the complex and mindblowing challenges of finding
structures in a huge set of spreadsheet cells for building an adequate mental
model of spreadsheet programs. Since spreadsheet programs are as diverse as the
purpose they are serving and as inhomogeneous as their programmers, to find an
appropriate representation or visualization technique for every spreadsheet
program seems futile. We thus propose different visualization and
representation methods that may ease spreadsheet comprehension but should not
be applied with all kind of spreadsheet programs. Therefore, this paper
proposes to use (complexity) measures as indicators for proper visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3010</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3010</id><created>2008-09-17</created><authors><author><keyname>Metcalf-Burton</keyname><forenames>Jessica Ruth</forenames></author></authors><title>Improved Upper Bounds for the Information Rates of the Secret Sharing
  Schemes Induced by the Vamos Matroid</title><categories>cs.CR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An access structure specifying the qualified sets of a secret sharing scheme
must have information rate less than or equal to one. The Vamos matroid induces
two non-isomorphic access structures V1 and V6, which were shown by Marti-Farre
and Padro to have information rates of at least 3/4. Beimel, Livne, and Padro
showed that the information rates of V1 and V6 are bounded above by 10/11 and
9/10 respectively. Here we improve those upper bounds to 19/21 for V1 and 17/19
for V6.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3016</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3016</id><created>2008-09-17</created><authors><author><keyname>Perry</keyname><forenames>Eric</forenames></author></authors><title>Automating Spreadsheet Discovery &amp; Risk Assessment</title><categories>cs.SE cs.HC</categories><comments>7 Pages, 6 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 61-67
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There have been many articles and mishaps published about the risks of
uncontrolled spreadsheets in today's business environment, including
non-compliance, operational risk, errors, and fraud all leading to significant
loss events. Spreadsheets fall into the realm of end user developed
applications and are often absent the proper safeguards and controls an IT
organization would enforce for enterprise applications. There is also an
overall lack of software programming discipline enforced in how spreadsheets
are developed. However, before an organization can apply proper controls and
discipline to critical spreadsheets, an accurate and living inventory of
spreadsheets across the enterprise must be created, and all critical
spreadsheets must be identified. As such, this paper proposes an automated
approach to the initial stages of the spreadsheet management lifecycle -
discovery, inventory and risk assessment. Without the use of technology, these
phases are often treated as a one-off project. By leveraging technology, they
become a sustainable business process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3023</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3023</id><created>2008-09-17</created><authors><author><keyname>Bagchi</keyname><forenames>Atish</forenames></author><author><keyname>Wells</keyname><forenames>Charles</forenames></author></authors><title>Graph-based Logic and Sketches</title><categories>math.CT cs.IT math.IT math.LO</categories><comments>PDFLaTeX with xy-pic. 112 pages, 182 diagrams</comments><msc-class>18C30 (Primary) 68Q55, 03C95 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the basic ideas of forms (a generalization of Ehresmann's
sketches) and their theories and models, more explicitly than in previous
expositions. Forms provide the ability to specify mathematical structures and
data types in any appropriate category, including many types of structures
(e.g. function spaces) that cannot be specified by sketches. We also outline a
new kind of formal logic (based on graphs instead of strings of symbols) that
gives an intrinsically categorial definition of assertion and proof for each
type of form. This formal logic is new to this monograph. The relationship
between multisorted equational logic and finite product theories is worked out
in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3027</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3027</id><created>2008-09-17</created><authors><author><keyname>Mannila</keyname><forenames>Heikki</forenames></author><author><keyname>Terzi</keyname><forenames>Evimaria</forenames></author></authors><title>Finding links and initiators: a graph reconstruction problem</title><categories>cs.AI cs.DB physics.soc-ph</categories><acm-class>H.2.8</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Consider a 0-1 observation matrix M, where rows correspond to entities and
columns correspond to signals; a value of 1 (or 0) in cell (i,j) of M indicates
that signal j has been observed (or not observed) in entity i. Given such a
matrix we study the problem of inferring the underlying directed links between
entities (rows) and finding which entries in the matrix are initiators.
  We formally define this problem and propose an MCMC framework for estimating
the links and the initiators given the matrix of observations M. We also show
how this framework can be extended to incorporate a temporal aspect; instead of
considering a single observation matrix M we consider a sequence of observation
matrices M1,..., Mt over time.
  We show the connection between our problem and several problems studied in
the field of social-network analysis. We apply our method to paleontological
and ecological data and show that our algorithms work well in practice and give
reasonable results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3030</identifier>
 <datestamp>2008-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3030</id><created>2008-09-17</created><authors><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Romero</keyname><forenames>Daniel M.</forenames></author><author><keyname>Wu</keyname><forenames>Fang</forenames></author></authors><title>Crowdsourcing, Attention and Productivity</title><categories>cs.CY physics.soc-ph</categories><acm-class>H.1; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tragedy of the digital commons does not prevent the copious voluntary
production of content that one witnesses in the web. We show through an
analysis of a massive data set from \texttt{YouTube} that the productivity
exhibited in crowdsourcing exhibits a strong positive dependence on attention,
measured by the number of downloads. Conversely, a lack of attention leads to a
decrease in the number of videos uploaded and the consequent drop in
productivity, which in many cases asymptotes to no uploads whatsoever.
Moreover, uploaders compare themselves to others when having low productivity
and to themselves when exceeding a threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3035</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3035</id><created>2008-09-17</created><authors><author><keyname>Grokop</keyname><forenames>Leonard</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author><author><keyname>Yates</keyname><forenames>Roy D.</forenames></author></authors><title>Interference Alignment for Line-of-Sight Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fully connected K-user interference channel is studied in a multipath
environment with bandwidth W. We show that when each link consists of D
physical paths, the total spectral efficiency can grow {\it linearly} with K.
This result holds not merely in the limit of large transmit power P, but for
any fixed P, and is therefore a stronger characterization than degrees of
freedom. It is achieved via a form of interference alignment in the time
domain. A caveat of this result is that W must grow with K, a phenomenon we
refer to as {\it bandwidth scaling}. Our insight comes from examining channels
with single path links (D=1), which we refer to as line-of-sight (LOS) links.
For such channels we build a time-indexed interference graph and associate the
communication problem with finding its maximal independent set. This graph has
a stationarity property that we exploit to solve the problem efficiently via
dynamic programming. Additionally, the interference graph enables us to
demonstrate the necessity of bandwidth scaling for any scheme operating over
LOS interference channels. Bandwidth scaling is then shown to also be a
necessary ingredient for interference alignment in the K-user interference
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3044</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3044</id><created>2008-09-18</created><authors><author><keyname>Rakotomanga</keyname><forenames>Novona</forenames><affiliation>GPA</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Kinetostatic Performance of a Planar Parallel Mechanism with Variable
  Actuation</title><categories>cs.RO</categories><comments>Published in: Advances in Robot Kinematics, France (2008)</comments><proxy>ccsd hal-00322760</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with a new planar parallel mechanism with variable actuation
and its kinetostatic performance. A drawback of parallel mechanisms is the non
homogeneity of kinetostatic performance within their workspace. The common
approach to solve this problem is the introduction of actuation redundancy,
that involves force control algorithms. Another approach, highlighted in this
paper, is to select the actuated joint in each limb with regard to the pose of
the end-effector. First, the architecture of the mechanism and two kinetostatic
performance indices are described. Then, the actuating modes of the mechanism
are compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3083</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3083</id><created>2008-09-18</created><authors><author><keyname>Mairal</keyname><forenames>Julien</forenames><affiliation>WILLOW</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>WILLOW</affiliation></author><author><keyname>Ponce</keyname><forenames>Jean</forenames><affiliation>WILLOW, LIENS</affiliation></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames><affiliation>WILLOW, VGG</affiliation></author><author><keyname>Zisserman</keyname><forenames>Andrew</forenames><affiliation>WILLOW, VGG</affiliation></author></authors><title>Supervised Dictionary Learning</title><categories>cs.CV</categories><proxy>ccsd inria-00322431</proxy><report-no>RR-6652</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is now well established that sparse signal models are well suited to
restoration tasks and can effectively be learned from audio, image, and video
data. Recent research has been aimed at learning discriminative sparse models
instead of purely reconstructive ones. This paper proposes a new step in that
direction, with a novel sparse representation for signals belonging to
different classes in terms of a shared dictionary and multiple class-decision
functions. The linear variant of the proposed model admits a simple
probabilistic interpretation, while its most general variant admits an
interpretation in terms of kernels. An optimization framework for learning all
the components of the proposed model is presented, along with experimental
results on standard handwritten digit and texture classification tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3091</identifier>
 <datestamp>2009-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3091</id><created>2008-09-18</created><updated>2009-09-07</updated><authors><author><keyname>Coucheney</keyname><forenames>Pierre</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Touati</keyname><forenames>Corinne</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Gaujal</keyname><forenames>Bruno</forenames><affiliation>INRIA Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>A Distributed Algorithm for Fair and Efficient User-Network Association
  in Multi-Technology Wireless Networks</title><categories>cs.GT</categories><proxy>ccsd inria-00322403</proxy><report-no>RR-6653</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent mobile equipment (as well as the norm IEEE 802.21) now offers the
possibility for users to switch from one technology to another (vertical
handover). This allows flexibility in resource assignments and, consequently,
increases the potential throughput allocated to each user. In this paper, we
design a fully distributed algorithm based on trial and error mechanisms that
exploits the benefits of vertical handover by finding fair and efficient
assignment schemes. On the one hand, mobiles gradually update the fraction of
data packets they send to each network based on the rewards they receive from
the stations. On the other hand, network stations send rewards to each mobile
that represent the impact each mobile has on the cell throughput. This reward
function is closely related to the concept of marginal cost in the pricing
literature. Both the station and the mobile algorithms are simple enough to be
implemented in current standard equipment. Based on tools from evolutionary
games, potential games and replicator dynamics, we analytically show the
convergence of the algorithm to solutions that are efficient and fair in terms
of throughput. Moreover, we show that after convergence, each user is connected
to a single network cell which avoids costly repeated vertical handovers.
Several simple heuristics based on this algorithm are proposed to achieve fast
convergence. Indeed, for implementation purposes, the number of iterations
should remain in the order of a few tens. We also compare, for different loads,
the quality of their solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3140</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3140</id><created>2008-09-18</created><authors><author><keyname>Gottlob</keyname><forenames>Georg</forenames></author><author><keyname>Pichler</keyname><forenames>Reinhard</forenames></author><author><keyname>Wei</keyname><forenames>Fang</forenames></author></authors><title>Monadic Datalog over Finite Structures with Bounded Treewidth</title><categories>cs.DB cs.CC cs.LO</categories><acm-class>F.2.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bounded treewidth and Monadic Second Order (MSO) logic have proved to be key
concepts in establishing fixed-parameter tractability results. Indeed, by
Courcelle's Theorem we know: Any property of finite structures, which is
expressible by an MSO sentence, can be decided in linear time (data complexity)
if the structures have bounded treewidth.
  In principle, Courcelle's Theorem can be applied directly to construct
concrete algorithms by transforming the MSO evaluation problem into a tree
language recognition problem. The latter can then be solved via a finite tree
automaton (FTA). However, this approach has turned out to be problematical,
since even relatively simple MSO formulae may lead to a ``state explosion'' of
the FTA.
  In this work we propose monadic datalog (i.e., datalog where all intentional
predicate symbols are unary) as an alternative method to tackle this class of
fixed-parameter tractable problems. We show that if some property of finite
structures is expressible in MSO then this property can also be expressed by
means of a monadic datalog program over the structure plus the tree
decomposition.
  Moreover, we show that the resulting fragment of datalog can be evaluated in
linear time (both w.r.t. the program size and w.r.t. the data size). This new
approach is put to work by devising new algorithms for the 3-Colorability
problem of graphs and for the PRIMALITY problem of relational schemas (i.e.,
testing if some attribute in a relational schema is part of a key). We also
report on experimental results with a prototype implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3159</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3159</id><created>2008-09-18</created><authors><author><keyname>Bagayoko</keyname><forenames>Abdoulaye</forenames></author><author><keyname>Tortelier</keyname><forenames>Patrick</forenames></author></authors><title>A Geometrical Description of the SINR Region of the Gaussian
  Interference Channel: the two and three-user case</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE ICC 2009, 5 pages</comments><report-no>1569150569</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of computing the achievable rates for two
(and three) users sharing a same frequency band without coordination and thus
interfering with each other. It is thus primarily related to the field of
cognitive radio studies as we look for the achievable increase in the spectrum
use efficiency. It is also strongly related to the long standing problem of the
capacity region of a Gaussian interference channel (GIC) because of the
assumption of no user coordination (and the underlying assumption that all
signals and interferences are Gaussian). We give a geometrical description of
the SINR region for the two-user and three-user channels. This geometric
approach provides a closed-form expression of the capacity region of the
two-user interference channel and an insightful of known optimal power
allocation scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3170</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3170</id><created>2008-09-18</created><updated>2012-12-04</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>A New Framework of Multistage Hypothesis Tests</title><categories>math.ST cs.LG math.PR stat.ME stat.TH</categories><comments>77 pages, no figure; added more references; in Proceedings of SPIE
  Conferences, Orlando, Florida, April 5-10, 2010 and April 25-29, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have established a general framework of multistage
hypothesis tests which applies to arbitrarily many mutually exclusive and
exhaustive composite hypotheses. Within the new framework, we have constructed
specific multistage tests which rigorously control the risk of committing
decision errors and are more efficient than previous tests in terms of average
sample number and the number of sampling operations. Without truncation, the
sample numbers of our testing plans are absolutely bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3179</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3179</id><created>2008-09-18</created><authors><author><keyname>Ur-Rehman</keyname><forenames>Raza</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Kinematic and Dynamic Analyses of the Orthoglide 5-axis</title><categories>cs.RO</categories><proxy>ccsd hal-00322702</proxy><journal-ref>Congress on Mechatronics, Le Grand-Bornand : France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the kinematic and dynamic analyses of the Orthoglide
5-axis, a five-degree-of-freedom manipulator. It is derived from two
manipulators: i) the Orthoglide 3-axis; a three dof translational manipulator
and ii) the Agile eye; a parallel spherical wrist. First, the kinematic and
dynamic models of the Orthoglide 5-axis are developed. The geometric and
inertial parameters of the manipulator are determined by means of a CAD
software. Then, the required motors performances are evaluated for some test
trajectories. Finally, the motors are selected in the catalogue from the
previous results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3180</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3180</id><created>2008-09-18</created><authors><author><keyname>Kanaan</keyname><forenames>Daniel</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Singularity Analysis of Limited-dof Parallel Manipulators using
  Grassmann-Cayley Algebra</title><categories>cs.RO</categories><proxy>ccsd hal-00322720</proxy><journal-ref>11th International Symposium on Advances in Robot Kinematics,
  France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper characterizes geometrically the singularities of limited DOF
parallel manipulators. The geometric conditions associated with the dependency
of six Pl\&quot;ucker vector of lines (finite and infinite) constituting the rows of
the inverse Jacobian matrix are formulated using Grassmann-Cayley algebra.
Manipulators under consideration do not need to have a passive spherical joint
somewhere in each leg. This study is illustrated with three example robots
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3181</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3181</id><created>2008-09-18</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author></authors><title>Framework for Dynamic Evaluation of Muscle Fatigue in Manual Handling
  Work</title><categories>cs.RO</categories><comments>International Conference On Industrial Technology, Chengdu : Chine
  (2008)</comments><proxy>ccsd hal-00322749</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Muscle fatigue is defined as the point at which the muscle is no longer able
to sustain the required force or work output level. The overexertion of muscle
force and muscle fatigue can induce acute pain and chronic pain in human body.
When muscle fatigue is accumulated, the functional disability can be resulted
as musculoskeletal disorders (MSD). There are several posture exposure analysis
methods useful for rating the MSD risks, but they are mainly based on static
postures. Even in some fatigue evaluation methods, muscle fatigue evaluation is
only available for static postures, but not suitable for dynamic working
process. Meanwhile, some existing muscle fatigue models based on physiological
models cannot be easily used in industrial ergonomic evaluations. The external
dynamic load is definitely the most important factor resulting muscle fatigue,
thus we propose a new fatigue model under a framework for evaluating fatigue in
dynamic working processes. Under this framework, virtual reality system is
taken to generate virtual working environment, which can be interacted with the
work with haptic interfaces and optical motion capture system. The motion
information and load information are collected and further processed to
evaluate the overall work load of the worker based on dynamic muscle fatigue
models and other work evaluation criterions and to give new information to
characterize the penibility of the task in design process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3182</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3182</id><created>2008-09-18</created><authors><author><keyname>Ben-Horin</keyname><forenames>Patricia</forenames><affiliation>Technion</affiliation></author><author><keyname>Shoham</keyname><forenames>Moshe</forenames><affiliation>Technion</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>SINGULAB - A Graphical user Interface for the Singularity Analysis of
  Parallel Robots based on Grassmann-Cayley Algebra</title><categories>cs.RO</categories><comments>Advances in Robot Kinematics, Batz sur Mer : France (2008)</comments><proxy>ccsd hal-00322730</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents SinguLab, a graphical user interface for the singularity
analysis of parallel robots. The algorithm is based on Grassmann-Cayley
algebra. The proposed tool is interactive and introduces the designer to the
singularity analysis performed by this method, showing all the stages along the
procedure and eventually showing the solution algebraically and graphically,
allowing as well the singularity verification of different robot poses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3187</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3187</id><created>2008-09-18</created><authors><author><keyname>Borogovac</keyname><forenames>T.</forenames></author><author><keyname>Alexander</keyname><forenames>F. J.</forenames></author><author><keyname>Vakili</keyname><forenames>P.</forenames></author></authors><title>A Control Variate Approach for Improving Efficiency of Ensemble Monte
  Carlo</title><categories>cs.CE cond-mat.stat-mech stat.CO</categories><comments>15 pages, 2 ps figures, elsart.cls</comments><report-no>LA-UR-08-05399</report-no><acm-class>G.3; J.2; I.6.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new approach to control variates for improving
computational efficiency of Ensemble Monte Carlo. We present the approach using
simulation of paths of a time-dependent nonlinear stochastic equation. The core
idea is to extract information at one or more nominal model parameters and use
this information to gain estimation efficiency at neighboring parameters. This
idea is the basis of a general strategy, called DataBase Monte Carlo (DBMC),
for improving efficiency of Monte Carlo. In this paper we describe how this
strategy can be implemented using the variance reduction technique of Control
Variates (CV). We show that, once an initial setup cost for extracting
information is incurred, this approach can lead to significant gains in
computational efficiency. The initial setup cost is justified in projects that
require a large number of estimations or in those that are to be performed
under real-time constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3204</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3204</id><created>2008-09-18</created><authors><author><keyname>J&#xe4;rvisalo</keyname><forenames>Matti</forenames></author><author><keyname>Oikarinen</keyname><forenames>Emilia</forenames></author></authors><title>Extended ASP tableaux and rule redundancy in normal logic programs</title><categories>cs.AI</categories><comments>27 pages, 5 figures, 1 table</comments><journal-ref>Theory and Practice of Logic Programming, 8(5-6):691-716, 2008</journal-ref><doi>10.1017/S1471068408003578</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an extended tableau calculus for answer set programming (ASP).
The proof system is based on the ASP tableaux defined in [Gebser&amp;Schaub, ICLP
2006], with an added extension rule. We investigate the power of Extended ASP
Tableaux both theoretically and empirically. We study the relationship of
Extended ASP Tableaux with the Extended Resolution proof system defined by
Tseitin for sets of clauses, and separate Extended ASP Tableaux from ASP
Tableaux by giving a polynomial-length proof for a family of normal logic
programs P_n for which ASP Tableaux has exponential-length minimal proofs with
respect to n. Additionally, Extended ASP Tableaux imply interesting insight
into the effect of program simplification on the lengths of proofs in ASP.
Closely related to Extended ASP Tableaux, we empirically investigate the effect
of redundant rules on the efficiency of ASP solving.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3214</identifier>
 <datestamp>2008-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3214</id><created>2008-09-18</created><updated>2008-10-25</updated><authors><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author><author><keyname>Solanki</keyname><forenames>Sandeep Singh</forenames></author><author><keyname>Roy</keyname><forenames>Sayan</forenames></author><author><keyname>Chauhan</keyname><forenames>Shivee</forenames></author><author><keyname>Tripathy</keyname><forenames>Sanjaya Shankar</forenames></author><author><keyname>Mahto</keyname><forenames>Kartik</forenames></author></authors><title>A Statistical Approach to Modeling Indian Classical Music Performance</title><categories>cs.SD stat.AP</categories><comments>24 pages,11 figures;a replacement paper is being uploaded because the
  the nyas swars of Yaman were not correctly given;some typos have been
  corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A raga is a melodic structure with fixed notes and a set of rules
characterizing a certain mood endorsed through performance. By a vadi swar is
meant that note which plays the most significant role in expressing the raga. A
samvadi swar similarly is the second most significant note. However, the
determination of their significance has an element of subjectivity and hence we
are motivated to find some truths through an objective analysis. The paper
proposes a probabilistic method of note detection and demonstrates how the
relative frequency (relative number of occurrences of the pitch) of the more
important notes stabilize far more quickly than that of others. In addition, a
count for distinct transitory and similar looking non-transitory (fundamental)
frequency movements (but possibly embedding distinct emotions!) between the
notes is also taken depicting the varnalankars or musical ornaments decorating
the notes and note sequences as rendered by the artist. They reflect certain
structural properties of the ragas. Several case studies are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3232</identifier>
 <datestamp>2008-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3232</id><created>2008-09-18</created><authors><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>A Local Clustering Algorithm for Massive Graphs and its Application to
  Nearly-Linear Time Graph Partitioning</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the design of local algorithms for massive graphs. A local algorithm
is one that finds a solution containing or near a given vertex without looking
at the whole graph. We present a local clustering algorithm. Our algorithm
finds a good cluster--a subset of vertices whose internal connections are
significantly richer than its external connections--near a given vertex. The
running time of our algorithm, when it finds a non-empty local cluster, is
nearly linear in the size of the cluster it outputs.
  Our clustering algorithm could be a useful primitive for handling massive
graphs, such as social networks and web-graphs. As an application of this
clustering algorithm, we present a partitioning algorithm that finds an
approximate sparsest cut with nearly optimal balance. Our algorithm takes time
nearly linear in the number edges of the graph.
  Using the partitioning algorithm of this paper, we have designed a
nearly-linear time algorithm for constructing spectral sparsifiers of graphs,
which we in turn use in a nearly-linear time algorithm for solving linear
systems in symmetric, diagonally-dominant matrices. The linear system solver
also leads to a nearly linear-time algorithm for approximating the
second-smallest eigenvalue and corresponding eigenvector of the Laplacian
matrix of a graph. These other results are presented in two companion papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3250</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3250</id><created>2008-09-18</created><authors><author><keyname>Kutuzov</keyname><forenames>Andrey</forenames></author></authors><title>Using descriptive mark-up to formalize translation quality assessment</title><categories>cs.CL</categories><comments>9 pages</comments><journal-ref>Published in Russian in 'Translation industry and information
  supply in international business activities: materials of international
  conference' - Perm, 2008, pp. 90-101</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The paper deals with using descriptive mark-up to emphasize translation
mistakes. The author postulates the necessity to develop a standard and formal
XML-based way of describing translation mistakes. It is considered to be
important for achieving impersonal translation quality assessment. Marked-up
translations can be used in corpus translation studies; moreover, automatic
translation assessment based on marked-up mistakes is possible. The paper
concludes with setting up guidelines for further activity within the described
field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3273</identifier>
 <datestamp>2009-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3273</id><created>2008-09-18</created><updated>2009-02-09</updated><authors><author><keyname>Pirandola</keyname><forenames>Stefano</forenames></author><author><keyname>Garcia-Patron</keyname><forenames>Raul</forenames></author><author><keyname>Braunstein</keyname><forenames>Samuel L.</forenames></author><author><keyname>Lloyd</keyname><forenames>Seth</forenames></author></authors><title>Direct and Reverse Secret-Key Capacities of a Quantum Channel</title><categories>quant-ph cs.CR cs.IT math.IT physics.optics</categories><comments>4 pages, 5 figures, REVteX</comments><journal-ref>Phys. Rev. Lett. 102, 050503 (2009)</journal-ref><doi>10.1103/PhysRevLett.102.050503</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the direct and reverse secret-key capacities of a memoryless
quantum channel as the optimal rates that entanglement-based quantum key
distribution protocols can reach by using a single forward classical
communication (direct reconciliation) or a single feedback classical
communication (reverse reconciliation). In particular, the reverse secret-key
capacity can be positive for antidegradable channels, where no forward strategy
is known to be secure. This property is explicitly shown in the continuous
variable framework by considering arbitrary one-mode Gaussian channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3276</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3276</id><created>2008-09-18</created><updated>2008-09-22</updated><authors><author><keyname>Sun</keyname><forenames>Zheng</forenames></author><author><keyname>Xu</keyname><forenames>Wenjun</forenames></author><author><keyname>He</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Niu</keyname><forenames>Kai</forenames></author></authors><title>Criteria on Utility Designing of Convex Optimization in FDMA Networks</title><categories>cs.NI</categories><comments>published in workshop of ICC '08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the network utility maximization problem in
FDMA systems. We summarize with a suite of criteria on designing utility
functions so as to achieve the global optimization convex. After proposing the
general form of the utility functions, we present examples of commonly used
utility function forms that are consistent with the criteria proposed in this
paper, which include the well-known proportional fairness function and the
sigmoidal-like functions. In the second part of this paper, we use numerical
results to demonstrate a case study based on the criteria mentioned above,
which deals with the subcarrier scheduling problem with dynamic rate allocation
in FDMA system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3279</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3279</id><created>2008-09-18</created><authors><author><keyname>Sun</keyname><forenames>Zheng</forenames></author></authors><title>Distributed Spiral Optimization in Wireless Sensor Networks without
  Fusion Centers</title><categories>cs.NI</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed spiral algorithm for distributed optimization in WSN is
proposed. By forming a spiral-shape message passing scheme among clusters,
without loss of estimation accuracy and convergence speed, the algorithm is
proved to converge with a lower total transport cost than the distributed
in-cluster algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3280</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3280</id><created>2008-09-18</created><authors><author><keyname>Sun</keyname><forenames>Zheng</forenames></author><author><keyname>He</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Wang</keyname><forenames>Ruochen</forenames></author><author><keyname>Niu</keyname><forenames>Kai</forenames></author></authors><title>A Heuristic Scheduling Scheme in Multiuser OFDMA Networks</title><categories>cs.NI</categories><comments>published in VTC Fall '08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional heterogeneous-traffic scheduling schemes utilize zero-delay
constraint for real-time services, which aims to minimize the average packet
delay among real-time users. However, in light or moderate load networks this
strategy is unnecessary and leads to low data throughput for non-real-time
users. In this paper, we propose a heuristic scheduling scheme to solve this
problem. The scheme measures and assigns scheduling priorities to both
real-time and non-real-time users, and schedules the radio resources for the
two user classes simultaneously. Simulation results show that the proposed
scheme efficiently handles the heterogeneous-traffic scheduling with diverse
QoS requirements and alleviates the unfairness between real-time and
non-real-time services under various traffic loads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3283</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3283</id><created>2008-09-18</created><updated>2008-09-22</updated><authors><author><keyname>Sun</keyname><forenames>Zheng</forenames></author><author><keyname>Xu</keyname><forenames>Wenjun</forenames></author><author><keyname>He</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Niu</keyname><forenames>Kai</forenames></author></authors><title>Performance Comparison of Cooperative and Distributed Spectrum Sensing
  in Cognitive Radio</title><categories>cs.NI</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we compare the performances of cooperative and distributed
spectrum sensing in wireless sensor networks. After introducing the basic
problem, we describe two strategies: 1) a cooperative sensing strategy, which
takes advantage of cooperation diversity gain to increase probability of
detection and 2) a distributed sensing strategy, which by passing the results
in an inter-node manner increases energy efficiency and fairness among nodes.
Then, we compare the performances of the strategies in terms of three criteria:
agility, energy efficiency, and robustness against SNR changes, and summarize
the comparison. It shows that: 1) the non-cooperative strategy has the best
fairness of energy consumption, 2) the cooperative strategy leads to the best
agility, and 3) the distributed strategy leads to the lowest energy consumption
and the best robustness against SNR changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3285</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3285</id><created>2008-09-18</created><authors><author><keyname>Sun</keyname><forenames>Zheng</forenames></author><author><keyname>Huang</keyname><forenames>Xiaohong</forenames></author><author><keyname>Ma</keyname><forenames>Yan</forenames></author></authors><title>Load Balancing Strategies to Solve Flowshop Scheduling on Parallel
  Computing</title><categories>cs.NI</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper first presents a parallel solution for the Flowshop Scheduling
Problem in parallel environment, and then proposes a novel load balancing
strategy. The proposed Proportional Fairness Strategy (PFS) takes computational
performance of computing process sets into account, and assigns additional load
to computing nodes proportionally to their evaluated performance. In order to
efficiently utilize the power of parallel resource, we also discuss the data
structure used in communications among computational nodes and design an
optimized data transfer strategy. This data transfer strategy combined with the
proposed load balancing strategy have been implemented and tested on a super
computer consisted of 86 CPUs using MPI as the middleware. The results show
that the proposed PFS achieves better performance in terms of computing time
than the existing Adaptive Contracting Within Neighborhood Strategy. We also
show that the combination of both the Proportional Fairness Strategy and the
proposed data transferring strategy achieves additional 13~15% improvement in
efficiency of parallelism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3352</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3352</id><created>2008-09-19</created><authors><author><keyname>Kuehn</keyname><forenames>Steffen</forenames></author></authors><title>Generalized Prediction Intervals for Arbitrary Distributed
  High-Dimensional Data</title><categories>cs.CV cs.AI cs.LG</categories><comments>13 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper generalizes the traditional statistical concept of prediction
intervals for arbitrary probability density functions in high-dimensional
feature spaces by introducing significance level distributions, which provides
interval-independent probabilities for continuous random variables. The
advantage of the transformation of a probability density function into a
significance level distribution is that it enables one-class classification or
outlier detection in a direct manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3357</identifier>
 <datestamp>2008-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3357</id><created>2008-09-19</created><authors><author><keyname>Ruj</keyname><forenames>Sushmita</forenames></author><author><keyname>Roy</keyname><forenames>Bimal</forenames></author></authors><title>More on Combinatorial Batch Codes</title><categories>cs.CR cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paterson, Stinson and Wei \cite{PSW} introduced Combinatorial batch codes,
which are combinatorial description of Batch code. Batch codes were first
presented by Ishai, Kushilevita, Ostrovsky and Sahai \cite{IKOS} in STOC'04. In
this paper we answer some of the questions put forward by Paterson, Stinson and
Wei and give some results for the general case $t&gt;1$ which were not studied by
the authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3365</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3365</id><created>2008-09-19</created><updated>2008-09-30</updated><authors><author><keyname>Luzzi</keyname><forenames>Laura</forenames></author><author><keyname>Othman</keyname><forenames>Ghaya Rekaya-Ben</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Algebraic reduction for space-time codes based on quaternion algebras</title><categories>cs.IT math.IT</categories><comments>29 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a new right preprocessing method for the decoding
of 2x2 algebraic STBCs, called algebraic reduction, which exploits the
multiplicative structure of the code. The principle of the new reduction is to
absorb part of the channel into the code, by approximating the channel matrix
with an element of the maximal order of the algebra. We prove that algebraic
reduction attains the receive diversity when followed by a simple ZF detection.
Simulation results for the Golden Code show that using MMSE-GDFE left
preprocessing, algebraic reduction with simple ZF detection has a loss of only
$3 \dB$ with respect to ML decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3370</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3370</id><created>2008-09-19</created><authors><author><keyname>Martinez</keyname><forenames>Alfonso</forenames></author></authors><title>Achievability of the Rate ${1/2}\log(1+\es)$ in the Discrete-Time
  Poisson Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple lower bound to the capacity of the discrete-time Poisson channel
with average energy $\es$ is derived. The rate ${1/2}\log(1+\es)$ is shown to
be the generalized mutual information of a modified minimum-distance decoder,
when the input follows a gamma distribution of parameter 1/2 and mean $\es$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3384</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3384</id><created>2008-09-19</created><authors><author><keyname>Bonev</keyname><forenames>Ilian</forenames><affiliation>GPA</affiliation></author><author><keyname>Briot</keyname><forenames>S&#xe9;bastien</forenames><affiliation>GPA</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Changing Assembly Modes without Passing Parallel Singularities in
  Non-Cuspidal 3-R\underline{P}R Planar Parallel Robots</title><categories>cs.RO</categories><comments>2nd International Workshop on Fundamental Issues and Future Research
  Directions for Parallel Mechanisms and Manipulators, Montpellier : France
  (2008)</comments><proxy>ccsd hal-00323101</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper demonstrates that any general 3-DOF three-legged planar parallel
robot with extensible legs can change assembly modes without passing through
parallel singularities (configurations where the mobile platform loses its
stiffness). While the results are purely theoretical, this paper questions the
very definition of parallel singularities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3415</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3415</id><created>2008-09-19</created><authors><author><keyname>Aidouni</keyname><forenames>Frederic</forenames></author><author><keyname>Latapy</keyname><forenames>Matthieu</forenames></author><author><keyname>Magnien</keyname><forenames>Clemence</forenames></author></authors><title>Ten weeks in the life of an eDonkey server</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a capture of the queries managed by an eDonkey server
during almost 10 weeks, leading to the observation of almost 9 billion messages
involving almost 90 million users and more than 275 million distinct files.
Acquisition and management of such data raises several challenges, which we
discuss as well as the solutions we developed. We obtain a very rich dataset,
orders of magnitude larger than previously avalaible ones, which we provide for
public use. We finally present basic analysis of the obtained data, which
already gives evidence of non-trivial features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3447</identifier>
 <datestamp>2008-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3447</id><created>2008-09-19</created><authors><author><keyname>Tungare</keyname><forenames>Manas</forenames></author><author><keyname>Perez-Quinones</keyname><forenames>Manuel</forenames></author><author><keyname>Sams</keyname><forenames>Alyssa</forenames></author></authors><title>An Exploratory Study of Calendar Use</title><categories>cs.HC cs.IR</categories><acm-class>H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we report on findings from an ethnographic study of how people
use their calendars for personal information management (PIM). Our participants
were faculty, staff and students who were not required to use or contribute to
any specific calendaring solution, but chose to do so anyway. The study was
conducted in three parts: first, an initial survey provided broad insights into
how calendars were used; second, this was followed up with personal interviews
of a few participants which were transcribed and content-analyzed; and third,
examples of calendar artifacts were collected to inform our analysis. Findings
from our study include the use of multiple reminder alarms, the reliance on
paper calendars even among regular users of electronic calendars, and wide use
of calendars for reporting and life-archival purposes. We conclude the paper
with a discussion of what these imply for designers of interactive calendar
systems and future work in PIM research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3479</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3479</id><created>2008-09-19</created><updated>2008-11-20</updated><authors><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Fermions and Loops on Graphs. I. Loop Calculus for Determinant</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC cs.IT hep-th math.IT</categories><comments>11 pages, 1 figure; misprints corrected</comments><report-no>LA-UR-08-05537</report-no><journal-ref>J.Stat.Mech.0812:P12011,2008</journal-ref><doi>10.1088/1742-5468/2008/12/P12011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is the first in the series devoted to evaluation of the partition
function in statistical models on graphs with loops in terms of the
Berezin/fermion integrals. The paper focuses on a representation of the
determinant of a square matrix in terms of a finite series, where each term
corresponds to a loop on the graph. The representation is based on a fermion
version of the Loop Calculus, previously introduced by the authors for
graphical models with finite alphabets. Our construction contains two levels.
First, we represent the determinant in terms of an integral over anti-commuting
Grassman variables, with some reparametrization/gauge freedom hidden in the
formulation. Second, we show that a special choice of the gauge, called BP
(Bethe-Peierls or Belief Propagation) gauge, yields the desired loop
representation. The set of gauge-fixing BP conditions is equivalent to the
Gaussian BP equations, discussed in the past as efficient (linear scaling)
heuristics for estimating the covariance of a sparse positive matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3481</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3481</id><created>2008-09-19</created><updated>2008-11-20</updated><authors><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Fermions and Loops on Graphs. II. Monomer-Dimer Model as Series of
  Determinants</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC cs.IT hep-th math.IT</categories><comments>11 pages, 2 figures; misprints corrected</comments><report-no>LA-UR-08-05678</report-no><journal-ref>J.Stat.Mech.0812:P12012,2008</journal-ref><doi>10.1088/1742-5468/2008/12/P12012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue the discussion of the fermion models on graphs that started in
the first paper of the series. Here we introduce a Graphical Gauge Model (GGM)
and show that : (a) it can be stated as an average/sum of a determinant defined
on the graph over $\mathbb{Z}_{2}$ (binary) gauge field; (b) it is equivalent
to the Monomer-Dimer (MD) model on the graph; (c) the partition function of the
model allows an explicit expression in terms of a series over disjoint directed
cycles, where each term is a product of local contributions along the cycle and
the determinant of a matrix defined on the remainder of the graph (excluding
the cycle). We also establish a relation between the MD model on the graph and
the determinant series, discussed in the first paper, however, considered using
simple non-Belief-Propagation choice of the gauge. We conclude with a
discussion of possible analytic and algorithmic consequences of these results,
as well as related questions and challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3485</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3485</id><created>2008-09-20</created><authors><author><keyname>Firouzi</keyname><forenames>Hamed</forenames></author><author><keyname>Babaie-Zadeh</keyname><forenames>Massoud</forenames></author><author><keyname>Ghasemian</keyname><forenames>Aria</forenames></author><author><keyname>Jutten</keyname><forenames>Christian</forenames></author></authors><title>A First Step to Convolutive Sparse Representation</title><categories>cs.MM cs.OH</categories><comments>4 Pages-In Proceeding of ICASSP 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper an extension of the sparse decomposition problem is considered
and an algorithm for solving it is presented. In this extension, it is known
that one of the shifted versions of a signal s (not necessarily the original
signal itself) has a sparse representation on an overcomplete dictionary, and
we are looking for the sparsest representation among the representations of all
the shifted versions of s. Then, the proposed algorithm finds simultaneously
the amount of the required shift, and the sparse representation. Experimental
results emphasize on the performance of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3503</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3503</id><created>2008-09-20</created><authors><author><keyname>Sivadasan</keyname><forenames>Praveen</forenames></author><author><keyname>Lal</keyname><forenames>P Sojan</forenames></author><author><keyname>Sivadasan</keyname><forenames>Naveen</forenames></author></authors><title>JDATATRANS for Array Obfuscation in Java Source Code to Defeat Reverse
  Engineering from Decompiled Codes</title><categories>cs.CR</categories><comments>Manuscript submitted to ACM COMPUTE 2009 Conference,Bangalore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software obfuscation or obscuring a software is an approach to defeat the
practice of reverse engineering a software for using its functionality
illegally in the development of another software. Java applications are more
amenable to reverse engineering and re-engineering attacks through methods such
as decompilation because Java class files store the program in a semi complied
form called 'byte' codes. The existing obfuscation systems obfuscate the Java
class files. Obfuscated source code produce obfuscated byte codes and hence two
level obfuscation (source code and byte code level) of the program makes it
more resilient to reverse engineering attacks. But source code obfuscation is
much more difficult due to richer set of programming constructs and the scope
of the different variables used in the program and only very little progress
has been made on this front. Hence programmers resort to adhoc manual ways of
obscuring their program which makes it difficult for its maintenance and
usability. To address this issue partially, we developed a user friendly tool
JDATATRANS to obfuscate Java source code by obscuring the array usages. Using
various array restructuring techniques such as 'array splitting', 'array
folding' and 'array flattening', in addition to constant hiding, our system
obfuscate the input Java source code and produce an obfuscated Java source code
that is functionally equivalent to the input program. We also perform a number
of experiments to measure the potency, resilience and cost incurred by our
tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3527</identifier>
 <datestamp>2012-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3527</id><created>2008-09-20</created><updated>2012-12-23</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Angela</forenames></author><author><keyname>Andreica</keyname><forenames>Romulus</forenames></author></authors><title>Inferring Company Structure from Limited Available Information</title><categories>cs.DS</categories><comments>Some of the algorithmic techniques presented in this paper were used
  as part of the solutions for some of the tasks proposed in several
  programming contests in which the first author participated (see the related
  materials for several such tasks and their solutions)</comments><proxy>ccsd</proxy><journal-ref>International Symposium on Social Development and Economic
  Performance, Satu Mare : Romania (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present several algorithmic techniques for inferring the
structure of a company when only a limited amount of information is available.
We consider problems with two types of inputs: the number of pairs of employees
with a given property and restricted information about the hierarchical
structure of the company. We provide dynamic programming and greedy algorithms
for these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3528</identifier>
 <datestamp>2013-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3528</id><created>2008-09-20</created><updated>2013-01-30</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Cristina Teodora</forenames></author><author><keyname>Andreica</keyname><forenames>Madalina Ecaterina</forenames></author></authors><title>Locating Restricted Facilities on Binary Maps</title><categories>cs.DS</categories><comments>The algorithmic techniques presented in this paper were used by the
  first author in the implementation of solutions to various algorithmic
  contest tasks (see the attached zip archive for some examples)</comments><proxy>ccsd</proxy><journal-ref>International Symposium on Social Development and Economic
  Performance, Satu Mare : Romania (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider several facility location problems with
applications to cost and social welfare optimization, when the area map is
encoded as a binary (0,1) mxn matrix. We present algorithmic solutions for all
the problems. Some cases are too particular to be used in practical situations,
but they are at least a starting point for more generic solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3540</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3540</id><created>2008-09-22</created><authors><author><keyname>Ford</keyname><forenames>David</forenames></author></authors><title>A Note on the Equivalence of Gibbs Free Energy and Information Theoretic
  Capacity</title><categories>cond-mat.stat-mech cs.IT math.IT</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimization of Gibbs free energy is based on the changes in work and
free energy that occur in a physical or chemical system. The maximization of
mutual information, the capacity, of a noisy channel is determined based on the
marginal probabilities and conditional entropies associated with a
communications system. As different as the procedures might first appear,
through the exploration of a simple, &quot;dual use&quot; Ising model, it is seen that
the two concepts are in fact the same. In particular, the case of a binary
symmetric channel is calculated in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3542</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3542</id><created>2008-09-20</created><authors><author><keyname>Voras</keyname><forenames>Ivan</forenames></author><author><keyname>Basch</keyname><forenames>Danko</forenames></author><author><keyname>Zagar</keyname><forenames>Mario</forenames></author></authors><title>A High Performance Memory Database for Web Application Caches</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the architecture and characteristics of a memory database
intended to be used as a cache engine for web applications. Primary goals of
this database are speed and efficiency while running on SMP systems with
several CPU cores (four and more). A secondary goal is the support for simple
metadata structures associated with cached data that can aid in efficient use
of the cache. Due to these goals, some data structures and algorithms normally
associated with this field of computing needed to be adapted to the new
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3546</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3546</id><created>2008-09-20</created><updated>2010-04-27</updated><authors><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Universal Secure Network Coding via Rank-Metric Codes</title><categories>cs.IT cs.CR math.IT</categories><comments>12 pages, 1 figure, substantially rewritten and improved. Submitted
  to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of securing a network coding communication system against an
eavesdropper adversary is considered. The network implements linear network
coding to deliver n packets from source to each receiver, and the adversary can
eavesdrop on \mu arbitrarily chosen links. The objective is to provide reliable
communication to all receivers, while guaranteeing that the source information
remains information-theoretically secure from the adversary. A coding scheme is
proposed that can achieve the maximum possible rate of n-\mu packets. The
scheme, which is based on rank-metric codes, has the distinctive property of
being universal: it can be applied on top of any communication network without
requiring knowledge of or any modifications on the underlying network code. The
only requirement of the scheme is that the packet length be at least n, which
is shown to be strictly necessary for universal communication at the maximum
rate. A further scenario is considered where the adversary is allowed not only
to eavesdrop but also to inject up to t erroneous packets into the network, and
the network may suffer from a rank deficiency of at most \rho. In this case,
the proposed scheme can be extended to achieve the rate of n-\rho-2t-\mu
packets. This rate is shown to be optimal under the assumption of zero-error
communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3554</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3554</id><created>2008-09-21</created><authors><author><keyname>Bresler</keyname><forenames>Guy</forenames></author><author><keyname>Parekh</keyname><forenames>Abhay</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>The Approximate Capacity of the Many-to-One and One-to-Many Gaussian
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>45 pages, 16 figures. Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Etkin, Tse, and Wang found the capacity region of the two-user
Gaussian interference channel to within one bit/s/Hz. A natural goal is to
apply this approach to the Gaussian interference channel with an arbitrary
number of users. We make progress towards this goal by finding the capacity
region of the many-to-one and one-to-many Gaussian interference channels to
within a constant number of bits. The result makes use of a deterministic model
to provide insight into the Gaussian channel. The deterministic model makes
explicit the dimension of signal scale. A central theme emerges: the use of
lattice codes for alignment of interfering signals on the signal scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3565</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3565</id><created>2008-09-21</created><updated>2008-11-23</updated><authors><author><keyname>Vanetik</keyname><forenames>N.</forenames></author></authors><title>On fractionality of the path packing problem</title><categories>cs.DM</categories><comments>18 pages, 5 figures in .eps format, 2 latex files, main file is
  kc13.tex Resubmission due to incorrectly specified CS type of the article; no
  changes to the context have been made</comments><acm-class>G.2.2; F.2.2</acm-class><doi>10.1007/s10878-011-9405-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study fractional multiflows in undirected graphs. A
fractional multiflow in a graph G with a node subset T, called terminals, is a
collection of weighted paths with ends in T such that the total weights of
paths traversing each edge does not exceed 1. Well-known fractional path
packing problem consists of maximizing the total weight of paths with ends in a
subset S of TxT over all fractional multiflows. Together, G,T and S form a
network. A network is an Eulerian network if all nodes in N\T have even
degrees.
  A term &quot;fractionality&quot; was defined for the fractional path packing problem by
A. Karzanov as the smallest natural number D so that there exists a solution to
the problem that becomes integer-valued when multiplied by D. A. Karzanov has
defined the class of Eulerian networks in terms of T and S, outside which D is
infinite and proved that whithin this class D can be 1,2 or 4. He conjectured
that D should be 1 or 2 for this class of networks. In this paper we prove this
conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3571</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3571</id><created>2008-09-21</created><authors><author><keyname>Flood</keyname><forenames>Derek</forenames></author><author><keyname>Daid</keyname><forenames>Kevin Mc</forenames></author><author><keyname>Caffery</keyname><forenames>Fergal Mc</forenames></author><author><keyname>Bishop</keyname><forenames>Brian</forenames></author></authors><title>Evaluation of an Intelligent Assistive Technology for Voice Navigation
  of Spreadsheets</title><categories>cs.HC</categories><comments>10 Pages, 2 Colour Figures, 4 Tables</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 69-78
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An integral part of spreadsheet auditing is navigation. For sufferers of
Repetitive Strain Injury who need to use voice recognition technology this
navigation can be highly problematic. To counter this the authors have
developed an intelligent voice navigation system, iVoice, which replicates
common spreadsheet auditing behaviours through simple voice commands. This
paper outlines the iVoice system and summarizes the results of a study to
evaluate iVoice when compared to a leading voice recognition technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3574</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3574</id><created>2008-09-21</created><authors><author><keyname>Ipsilandis</keyname><forenames>Pandelis G.</forenames></author></authors><title>Spreadsheet modelling for solving combinatorial problems: The vendor
  selection problem</title><categories>cs.SE cs.HC</categories><comments>13 Pages, 8 Colour Figures, 1 Table</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 95-107
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets have grown up and became very powerful and easy to use tools in
applying analytical techniques for solving business problems. Operations
managers, production managers, planners and schedulers can work with them in
developing solid and practical Do-It-Yourself Decision Support Systems. Small
and Medium size organizations, can apply OR methodologies without the presence
of specialized software and trained personnel, which in many cases cannot
afford anyway. This paper examines an efficient approach in solving
combinatorial programming problems with the use of spreadsheets. A practical
application, which demonstrates the approach, concerns the development of a
spreadsheet-based DSS for the Multi Item Procurement Problem with Fixed Vendor
Cost. The DSS has been build using exclusively standard spreadsheet feature and
can solve real problems of substantial size. The benefits and limitations of
the approach are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3577</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3577</id><created>2008-09-21</created><updated>2010-01-13</updated><authors><author><keyname>Mohamed</keyname><forenames>Han&#xe8;ne</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author></authors><title>Dynamic tree algorithms</title><categories>math.PR cs.DS</categories><comments>Published in at http://dx.doi.org/10.1214/09-AAP617 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>ccsd inria-00323350</proxy><report-no>IMS-AAP-AAP617</report-no><msc-class>68W40, 60K20 (Primary), 90B15 (Secondary)</msc-class><journal-ref>Annals of Applied Probability 2010, Vol. 20, No. 1, 26-51</journal-ref><doi>10.1214/09-AAP617</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a general tree algorithm processing a random flow of arrivals
is analyzed. Capetanakis--Tsybakov--Mikhailov's protocol in the context of
communication networks with random access is an example of such an algorithm.
In computer science, this corresponds to a trie structure with a dynamic input.
Mathematically, it is related to a stopped branching process with exogeneous
arrivals (immigration). Under quite general assumptions on the distribution of
the number of arrivals and on the branching procedure, it is shown that there
exists a positive constant $\lambda_c$ so that if the arrival rate is smaller
than $\lambda_c$, then the algorithm is stable under the flow of requests, that
is, that the total size of an associated tree is integrable. At the same time,
a gap in the earlier proofs of stability in the literature is fixed. When the
arrivals are Poisson, an explicit characterization of $\lambda_c$ is given.
Under the stability condition, the asymptotic behavior of the average size of a
tree starting with a large number of individuals is analyzed. The results are
obtained with the help of a probabilistic rewriting of the functional equations
describing the dynamics of the system. The proofs use extensively this
stochastic background throughout the paper. In this analysis, two basic limit
theorems play a key role: the renewal theorem and the convergence to
equilibrium of an auto-regressive process with a moving average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3584</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3584</id><created>2008-09-21</created><authors><author><keyname>Paine</keyname><forenames>Jocelyn</forenames></author></authors><title>Spreadsheet Components For All</title><categories>cs.SE cs.HC</categories><comments>19 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 109-127
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have prototyped a &quot;spreadsheet component repository&quot; Web site, from which
users can copy &quot;components&quot; into their own Excel or Google spreadsheets.
Components are collections of cells containing formulae: in real life, they
would do useful calculations that many practitioners find hard to program, and
would be rigorously tested and documented. Crucially, the user can tell the
repository which cells in their spreadsheet to use for a componen's inputs and
outputs. The repository will then reshape the component to fit. A single
component can therefore be used in many different sizes and shapes of
spreadsheet. We hope to set up a spreadsheet equivalent of the high-quality
numerical subroutine libraries that revolutionised scientific computing, but
where instead of subroutines, the library contains such components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3586</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3586</id><created>2008-09-21</created><authors><author><keyname>Grossman</keyname><forenames>Thomas A.</forenames></author></authors><title>A Primer on Spreadsheet Analytics</title><categories>cs.SE cs.HC</categories><comments>12 Pages, 8 Colour Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 129-140
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides guidance to an analyst who wants to extract insight from
a spreadsheet model. It discusses the terminology of spreadsheet analytics, how
to prepare a spreadsheet model for analysis, and a hierarchy of analytical
techniques. These techniques include sensitivity analysis, tornado charts,and
backsolving (or goal-seeking). This paper presents native-Excel approaches for
automating these techniques, and discusses add-ins that are even more
efficient. Spreadsheet optimization and spreadsheet Monte Carlo simulation are
briefly discussed. The paper concludes by calling for empirical research, and
describing desired features spreadsheet sensitivity analysis and spreadsheet
optimization add-ins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3587</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3587</id><created>2008-09-21</created><authors><author><keyname>Bishop</keyname><forenames>Brian</forenames></author><author><keyname>McDaid</keyname><forenames>Kevin</forenames></author></authors><title>Spreadsheet End-User Behaviour Analysis</title><categories>cs.SE cs.HC</categories><comments>12 Pages, 13 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 141-152
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To aid the development of spreadsheet debugging tools, a knowledge of
end-users natural behaviour within the Excel environment would be advantageous.
This paper details the design and application of a novel data acquisition tool,
which can be used for the unobtrusive recording of end-users mouse, keyboard
and Excel specific actions during the debugging of Excel spreadsheets. A
debugging experiment was conducted using this data acquisition tool, and based
on analysis of end-users performance and behaviour data, the authors developed
a &quot;spreadsheet cell coverage feedback&quot; debugging tool. Results from the
debugging experiment are presented in terms of enduser debugging performance
and behaviour, and the outcomes of an evaluation experiment with the debugging
tool are detailed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3595</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3595</id><created>2008-09-21</created><authors><author><keyname>Chambers</keyname><forenames>Jamie</forenames></author><author><keyname>Hamill</keyname><forenames>John</forenames></author></authors><title>Controlling End User Computing Applications - a case study</title><categories>cs.HC</categories><comments>9 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 153-161
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report the results of a project to control the use of end user computing
tools for business critical applications in a banking environment. Several
workstreams were employed in order to bring about a cultural change within the
bank towards the use of spreadsheets and other end-user tools, covering policy
development, awareness and skills training, inventory monitoring, user
licensing, key risk metrics and mitigation approaches. The outcomes of these
activities are discussed, and conclusions are drawn as to the need for
appropriate organisational models to guide the use of these tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3597</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3597</id><created>2008-09-21</created><authors><author><keyname>Alliy</keyname><forenames>Mbwana</forenames></author><author><keyname>Brown</keyname><forenames>Patty</forenames></author></authors><title>Spreadsheets: Aiming the Accountant's Hammer to Hit the Nail on the Head</title><categories>cs.HC</categories><comments>8 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 163-170
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accounting and Finance (A&amp;F) Professionals are arguably the most loyal and
concentrated population of spreadsheet users. The work that they perform in
spreadsheets has the most significant impact on financial data and business
processes within global organizations today. Spreadsheets offer the flexibility
and ease of use of a desktop application, combined with the power to perform
complex data analysis. They are also the lowest cost business IT tool when
stacked up against other functional tools. As a result, spreadsheets are used
to support critical business processes in most organizations. In fact, research
indicates that over half of financial management reporting is performed with
spreadsheets by an accounting and finance professional. A disparity exists in
the business world between the importance of spreadsheets on financial data
(created by A&amp;F Professionals) and the resources devoted to: The development
and oversight of global spreadsheet standards; A recognized and accredited
certification in spreadsheet proficiency; Corporate sponsored and required
training; Awareness of emerging technologies as it relates to spreadsheet use.
This management paper focuses on the current topics relevant to the largest
user group (A&amp;F Professionals) of the most widely used financial software
application, spreadsheets, also known as the accountant's hammer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3600</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3600</id><created>2008-09-21</created><authors><author><keyname>Wang</keyname><forenames>Zheng</forenames></author><author><keyname>Karande</keyname><forenames>Shirish</forenames></author><author><keyname>Sadjadpour</keyname><forenames>Hamid R.</forenames></author><author><keyname>Garcia-Luna-Aceves</keyname><forenames>J. J.</forenames></author></authors><title>On the Capacity Improvement of Multicast Traffic with Network Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the contribution of network coding (NC) in improving
the multicast capacity of random wireless ad hoc networks when nodes are
endowed with multi-packet transmission (MPT) and multi-packet reception (MPR)
capabilities. We show that a per session throughput capacity of
$\Theta(nT^{3}(n))$, where $n$ is the total number of nodes and T(n) is the
communication range, can be achieved as a tight bound when each session
contains a constant number of sinks. Surprisingly, an identical order capacity
can be achieved when nodes have only MPR and MPT capabilities. This result
proves that NC does not contribute to the order capacity of multicast traffic
in wireless ad hoc networks when MPR and MPT are used in the network. The
result is in sharp contrast to the general belief (conjecture) that NC improves
the order capacity of multicast. Furthermore, if the communication range is
selected to guarantee the connectivity in the network, i.e., $T(n)\ge
\Theta(\sqrt{\log n/n})$, then the combination of MPR and MPT achieves a
throughput capacity of $\Theta(\frac{\log^{{3/2}} n}{\sqrt{n}})$ which provides
an order capacity gain of $\Theta(\log^2 n)$ compared to the point-to-point
multicast capacity with the same number of destinations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3609</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3609</id><created>2008-09-21</created><authors><author><keyname>O'Beirne</keyname><forenames>Patrick</forenames></author></authors><title>Information and Data Quality in Spreadsheets</title><categories>cs.SE cs.HC</categories><comments>15 Pages, 3 Tables, 1 Figure</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 171-185
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quality of the data in spreadsheets is less discussed than the structural
integrity of the formulas. Yet it is an area of great interest to the owners
and users of the spreadsheet. This paper provides an overview of Information
Quality (IQ) and Data Quality (DQ) with specific reference to how data is
sourced, structured, and presented in spreadsheets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3612</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3612</id><created>2008-09-21</created><authors><author><keyname>Blondel</keyname><forenames>Francois-Marie</forenames></author><author><keyname>Bruillard</keyname><forenames>Eric</forenames></author><author><keyname>Tort</keyname><forenames>Francoise</forenames></author></authors><title>Overview and main results of the DidaTab project</title><categories>cs.HC</categories><comments>12 Pages, 5 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 187-198
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The DidaTab project (Didactics of Spreadsheet, teaching and learning
spreadsheets) is a three year project (2005-2007) funded by the French Ministry
of Research and dedicated to the study of personal and classroom uses of
spreadsheets in the French context, focussing on the processes of appropriation
and uses by secondary school students. In this paper, we present an overview of
the project, briefly report the studies performed in the framework of the
DidaTab project, and give the main results we obtained. We then explore the new
research tracks we intend to develop, more in connection with EuSpRIG. Our main
result is that the use of spreadsheet during secondary education (grade 6 to
12) is rather sparse for school work (and even more seldom at home) and that
student competencies are weak. Curricula have to be reviewed to include more
training of dynamics tabular tools (including databases queries) in order to
ensure sufficient mastery of computer tools that have became necessary in many
educational activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3613</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3613</id><created>2008-09-21</created><authors><author><keyname>Panko</keyname><forenames>Raymond R.</forenames></author></authors><title>Revisiting the Panko-Halverson Taxonomy of Spreadsheet Errors</title><categories>cs.SE cs.HC</categories><comments>22 Pages, 17 Figures</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2008 199-220
  ISBN 978-905617-69-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to revisit the Panko-Halverson taxonomy of
spreadsheet errors and suggest revisions. There are several reasons for doing
so: First, the taxonomy has been widely used. Therefore, it should have
scrutiny; Second, the taxonomy has not been widely available in its original
form and most users refer to secondary sources. Consequently, they often equate
the taxonomy with the simplified extracts used in particular experiments or
field studies; Third, perhaps as a consequence, most users use only a fraction
of the taxonomy. In particular, they tend not to use the taxonomy's life-cycle
dimension; Fourth, the taxonomy has been tested against spreadsheets in
experiments and spreadsheets in operational use. It is time to review how it
has fared in these tests; Fifth, the taxonomy was based on the types of
spreadsheet errors that were known to the authors in the mid-1990s. Subsequent
experience has shown that the taxonomy needs to be extended for situations
beyond those original experiences; Sixth, the omission category in the taxonomy
has proven to be too narrow. Although this paper will focus on the
Panko-Halverson taxonomy, this does not mean that that it is the only possible
error taxonomy or even the best error taxonomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3614</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3614</id><created>2008-09-22</created><authors><author><keyname>Volkov</keyname><forenames>Sergey</forenames></author></authors><title>Improved Monotone Circuit Depth Upper Bound for Directed Graph
  Reachability</title><categories>cs.CC</categories><comments>preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the directed graph reachability problem (transitive closure)
can be solved by monotone fan-in 2 boolean circuits of depth (1/2+o(1))(log
n)^2, where n is the number of nodes. This improves the previous known upper
bound (1+o(1))(log n)^2. The proof is non-constructive, but we give a
constructive proof of the upper bound (7/8+o(1))(log n)^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3618</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3618</id><created>2008-09-21</created><authors><author><keyname>McAuley</keyname><forenames>Julian J.</forenames></author><author><keyname>Caetano</keyname><forenames>Tiberio S.</forenames></author><author><keyname>Smola</keyname><forenames>Alexander J.</forenames></author></authors><title>Robust Near-Isometric Matching via Structured Learning of Graphical
  Models</title><categories>cs.CV cs.LG</categories><comments>11 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models for near-rigid shape matching are typically based on distance-related
features, in order to infer matches that are consistent with the isometric
assumption. However, real shapes from image datasets, even when expected to be
related by &quot;almost isometric&quot; transformations, are actually subject not only to
noise but also, to some limited degree, to variations in appearance and scale.
In this paper, we introduce a graphical model that parameterises appearance,
distance, and angle features and we learn all of the involved parameters via
structured prediction. The outcome is a model for near-rigid shape matching
which is robust in the sense that it is able to capture the possibly limited
but still important scale and appearance variations. Our experimental results
reveal substantial improvements upon recent successful models, while
maintaining similar running times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3646</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3646</id><created>2008-09-22</created><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Golovach</keyname><forenames>Petr A.</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Approximating acyclicity parameters of sparse hypergraphs</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notions of hypertree width and generalized hypertree width were
introduced by Gottlob, Leone, and Scarcello in order to extend the concept of
hypergraph acyclicity. These notions were further generalized by Grohe and
Marx, who introduced the fractional hypertree width of a hypergraph. All these
width parameters on hypergraphs are useful for extending tractability of many
problems in database theory and artificial intelligence. In this paper, we
study the approximability of (generalized, fractional) hyper treewidth of
sparse hypergraphs where the criterion of sparsity reflects the sparsity of
their incidence graphs. Our first step is to prove that the (generalized,
fractional) hypertree width of a hypergraph H is constant-factor sandwiched by
the treewidth of its incidence graph, when the incidence graph belongs to some
apex-minor-free graph class. This determines the combinatorial borderline above
which the notion of (generalized, fractional) hypertree width becomes
essentially more general than treewidth, justifying that way its functionality
as a hypergraph acyclicity measure. While for more general sparse families of
hypergraphs treewidth of incidence graphs and all hypertree width parameters
may differ arbitrarily, there are sparse families where a constant factor
approximation algorithm is possible. In particular, we give a constant factor
approximation polynomial time algorithm for (generalized, fractional) hypertree
width on hypergraphs whose incidence graphs belong to some H-minor-free graph
class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3650</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3650</id><created>2008-09-22</created><updated>2009-09-23</updated><authors><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames></author><author><keyname>Tourneret</keyname><forenames>Jean-Yves</forenames></author></authors><title>Hierarchical Bayesian sparse image reconstruction with application to
  MRFM</title><categories>physics.data-an cs.IT math.IT stat.ME</categories><comments>v2: final version; IEEE Trans. Image Processing, 2009</comments><journal-ref>IEEE Trans. Image Processing, vol. 18, no. 9, pp. 2059-2070, Sept.
  2009</journal-ref><doi>10.1109/TIP.2009.2024067</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a hierarchical Bayesian model to reconstruct sparse
images when the observations are obtained from linear transformations and
corrupted by an additive white Gaussian noise. Our hierarchical Bayes model is
well suited to such naturally sparse image applications as it seamlessly
accounts for properties such as sparsity and positivity of the image via
appropriate Bayes priors. We propose a prior that is based on a weighted
mixture of a positive exponential distribution and a mass at zero. The prior
has hyperparameters that are tuned automatically by marginalization over the
hierarchical Bayesian model. To overcome the complexity of the posterior
distribution, a Gibbs sampling strategy is proposed. The Gibbs samples can be
used to estimate the image to be recovered, e.g. by maximizing the estimated
posterior distribution. In our fully Bayesian approach the posteriors of all
the parameters are available. Thus our algorithm provides more information than
other previously proposed sparse reconstruction methods that only give a point
estimate. The performance of our hierarchical Bayesian sparse reconstruction
method is illustrated on synthetic and real data collected from a tobacco virus
sample using a prototype MRFM instrument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3688</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3688</id><created>2008-09-22</created><authors><author><keyname>Bagdasaryan</keyname><forenames>Armen</forenames></author></authors><title>Mathematical and computer tools of discrete dynamic modeling and
  analysis of complex systems in control loop</title><categories>cs.CE cs.MA</categories><comments>14 pages, 15 figures</comments><journal-ref>Int J Mathematical Models and Methods in Applied Sciences, vol. 2,
  issue 1, 2008, pp. 82-95</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method of discrete modeling and analysis of multilevel dynamics
of complex large-scale hierarchical dynamic systems subject to external dynamic
control mechanism. Architectural model of information system supporting
simulation and analysis of dynamic processes and development scenarios
(strategies) of complex large-scale hierarchical systems is also proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3690</identifier>
 <datestamp>2008-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3690</id><created>2008-09-22</created><authors><author><keyname>K&#xfc;hn</keyname><forenames>Steffen</forenames></author><author><keyname>G&#xfc;hmann</keyname><forenames>Clemens</forenames></author></authors><title>Modeling and Control with Local Linearizing Nadaraya Watson Regression</title><categories>cs.CV</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Black box models of technical systems are purely descriptive. They do not
explain why a system works the way it does. Thus, black box models are
insufficient for some problems. But there are numerous applications, for
example, in control engineering, for which a black box model is absolutely
sufficient. In this article, we describe a general stochastic framework with
which such models can be built easily and fully automated by observation.
Furthermore, we give a practical example and show how this framework can be
used to model and control a motorcar powertrain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3731</identifier>
 <datestamp>2009-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3731</id><created>2008-09-22</created><updated>2009-07-23</updated><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Uncertainty Relations for Shift-Invariant Analog Signals</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Trans. on Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past several years have witnessed a surge of research investigating
various aspects of sparse representations and compressed sensing. Most of this
work has focused on the finite-dimensional setting in which the goal is to
decompose a finite-length vector into a given finite dictionary. Underlying
many of these results is the conceptual notion of an uncertainty principle: a
signal cannot be sparsely represented in two different bases. Here, we extend
these ideas and results to the analog, infinite-dimensional setting by
considering signals that lie in a finitely-generated shift-invariant (SI)
space. This class of signals is rich enough to include many interesting special
cases such as multiband signals and splines. By adapting the notion of
coherence defined for finite dictionaries to infinite SI representations, we
develop an uncertainty principle similar in spirit to its finite counterpart.
We demonstrate tightness of our bound by considering a bandlimited lowpass
train that achieves the uncertainty principle. Building upon these results and
similar work in the finite setting, we show how to find a sparse decomposition
in an overcomplete dictionary by solving a convex optimization problem. The
distinguishing feature of our approach is the fact that even though the problem
is defined over an infinite domain with infinitely many variables and
constraints, under certain conditions on the dictionary spectrum our algorithm
can find the sparsest representation by solving a finite-dimensional problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3908</identifier>
 <datestamp>2008-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3908</id><created>2008-09-23</created><authors><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author><author><keyname>Mukherji</keyname><forenames>Utpal</forenames></author><author><keyname>Joseph</keyname><forenames>Vinay</forenames></author><author><keyname>Gupta</keyname><forenames>Shrey</forenames></author></authors><title>Optimal Energy Management Policies for Energy Harvesting Sensor Nodes</title><categories>cs.NI</categories><comments>Submitted to the IEEE Transactions on Wireless Communications; 22
  pages with 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a sensor node with an energy harvesting source. The generated energy
can be stored in a buffer. The sensor node periodically senses a random field
and generates a packet. These packets are stored in a queue and transmitted
using the energy available at that time. We obtain energy management policies
that are throughput optimal, i.e., the data queue stays stable for the largest
possible data rate. Next we obtain energy management policies which minimize
the mean delay in the queue.We also compare performance of several easily
implementable sub-optimal energy management policies. A greedy policy is
identified which, in low SNR regime, is throughput optimal and also minimizes
mean delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3935</identifier>
 <datestamp>2009-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3935</id><created>2008-09-23</created><updated>2009-03-22</updated><authors><author><keyname>Sitharam</keyname><forenames>Meera</forenames></author><author><keyname>Gao</keyname><forenames>Heping</forenames></author></authors><title>Characterizing graphs with convex and connected configuration spaces</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define and study exact, efficient representations of realization spaces
Euclidean Distance Constraint Systems (EDCS), which includes Linkages and
Frameworks. Each representation corresponds to a choice of Cayley parameters
and yields a different parametrized configuration space. Significantly, we give
purely graph-theoretic, forbidden minor characterizations that capture (i) the
class of graphs that always admit efficient configuration spaces and (ii) the
possible choices of representation parameters that yield efficient
configuration spaces for a given graph. In addition, our results are tight: we
show counterexamples to obvious extensions. This is the first step in a
systematic and graded program of combinatorial characterizations of efficient
configuration spaces. We discuss several future theoretical and applied
research directions. Some of our proofs employ an unusual interplay of (a)
classical analytic results related to positive semi-definiteness of Euclidean
distance matrices, with (b) recent forbidden minor characterizations and
algorithms related to the notion of d-realizability of EDCS. We further
introduce a novel type of restricted edge contraction or reduction to a graph
minor, a &quot;trick&quot; that we anticipate will be useful in other situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3942</identifier>
 <datestamp>2008-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3942</id><created>2008-09-23</created><authors><author><keyname>Hoogvorst</keyname><forenames>Philippe</forenames></author><author><keyname>Guilley</keyname><forenames>Sylvain</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Sumanta</forenames></author><author><keyname>Danger</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Beyrouthy</keyname><forenames>Taha</forenames></author><author><keyname>Fesquet</keyname><forenames>Laurent</forenames></author></authors><title>A Reconfigurable Programmable Logic Block for a Multi-Style Asynchronous
  FPGA resistant to Side-Channel Attacks</title><categories>cs.CR cs.OH</categories><comments>29 pages</comments><acm-class>D.4.6; B.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Side-channel attacks are efficient attacks against cryptographic devices.
They use only quantities observable from outside, such as the duration and the
power consumption. Attacks against synchronous devices using electric
observations are facilitated by the fact that all transitions occur
simultaneously with some global clock signal. Asynchronous control remove this
synchronization and therefore makes it more difficult for the attacker to
insulate \emph{interesting intervals}. In addition the coding of data in an
asynchronous circuit is inherently more difficult to attack. This article
describes the Programmable Logic Block of an asynchronous FPGA resistant
against \emph{side-channel attacks}. Additionally it can implement different
styles of asynchronous control and of data representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3960</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3960</id><created>2008-09-23</created><updated>2009-06-30</updated><authors><author><keyname>Bengtson</keyname><forenames>Jesper</forenames></author><author><keyname>Parrow</keyname><forenames>Joachim</forenames></author></authors><title>Formalising the pi-calculus using nominal logic</title><categories>cs.LO</categories><comments>36 pages, 3 figures</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (June 30,
  2009) lmcs:832</journal-ref><doi>10.2168/LMCS-5(2:16)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formalise the pi-calculus using the nominal datatype package, based on
ideas from the nominal logic by Pitts et al., and demonstrate an implementation
in Isabelle/HOL. The purpose is to derive powerful induction rules for the
semantics in order to conduct machine checkable proofs, closely following the
intuitive arguments found in manual proofs. In this way we have covered many of
the standard theorems of bisimulation equivalence and congruence, both late and
early, and both strong and weak in a uniform manner. We thus provide one of the
most extensive formalisations of a process calculus ever done inside a theorem
prover.
  A significant gain in our formulation is that agents are identified up to
alpha-equivalence, thereby greatly reducing the arguments about bound names.
This is a normal strategy for manual proofs about the pi-calculus, but that
kind of hand waving has previously been difficult to incorporate smoothly in an
interactive theorem prover. We show how the nominal logic formalism and its
support in Isabelle accomplishes this and thus significantly reduces the tedium
of conducting completely formal proofs. This improves on previous work using
weak higher order abstract syntax since we do not need extra assumptions to
filter out exotic terms and can keep all arguments within a familiar
first-order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3994</identifier>
 <datestamp>2010-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3994</id><created>2008-09-23</created><updated>2010-01-23</updated><authors><author><keyname>Steiner</keyname><forenames>Wolfgang</forenames><affiliation>LIAFA</affiliation></author></authors><title>Regularities of the distribution of abstract van der Corput sequences</title><categories>math.NT cs.DM</categories><proxy>ccsd hal-00323846</proxy><msc-class>11K38, 11K31, 11K16, 37B10, 68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarly to $\beta$-adic van der Corput sequences, abstract van der Corput
sequences can be defined for abstract numeration systems. Under some
assumptions, these sequences are low discrepancy sequences. The discrepancy
function is computed explicitely, and a characterization of bounded remainder
sets of the form $[0,y)$ is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4017</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4017</id><created>2008-09-23</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>de Alfaro</keyname><forenames>Luca</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Termination Criteria for Solving Concurrent Safety and Reachability
  Games</title><categories>cs.GT cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider concurrent games played on graphs. At every round of a game, each
player simultaneously and independently selects a move; the moves jointly
determine the transition to a successor state. Two basic objectives are the
safety objective to stay forever in a given set of states, and its dual, the
reachability objective to reach a given set of states. We present in this paper
a strategy improvement algorithm for computing the value of a concurrent safety
game, that is, the maximal probability with which player~1 can enforce the
safety objective. The algorithm yields a sequence of player-1 strategies which
ensure probabilities of winning that converge monotonically to the value of the
safety game.
  Our result is significant because the strategy improvement algorithm
provides, for the first time, a way to approximate the value of a concurrent
safety game from below. Since a value iteration algorithm, or a strategy
improvement algorithm for reachability games, can be used to approximate the
same value from above, the combination of both algorithms yields a method for
computing a converging sequence of upper and lower bounds for the values of
concurrent reachability and safety games. Previous methods could approximate
the values of these games only from one direction, and as no rates of
convergence are known, they did not provide a practical way to solve these
games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4019</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4019</id><created>2008-09-23</created><updated>2010-02-22</updated><authors><author><keyname>Cui</keyname><forenames>Shengshan</forenames><affiliation>Shitz</affiliation></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Somekh</keyname><forenames>Oren</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Throughput Scaling of Wireless Networks With Random Connections</title><categories>cs.IT math.IT</categories><comments>13 pages, 4 figures, To appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the throughput scaling laws of ad hoc wireless networks in
the limit of a large number of nodes. A random connections model is assumed in
which the channel connections between the nodes are drawn independently from a
common distribution. Transmitting nodes are subject to an on-off strategy, and
receiving nodes employ conventional single-user decoding. The following results
are proven:
  1) For a class of connection models with finite mean and variance, the
throughput scaling is upper-bounded by $O(n^{1/3})$ for single-hop schemes, and
$O(n^{1/2})$ for two-hop (and multihop) schemes.
  2) The $\Theta (n^{1/2})$ throughput scaling is achievable for a specific
connection model by a two-hop opportunistic relaying scheme, which employs
full, but only local channel state information (CSI) at the receivers, and
partial CSI at the transmitters.
  3) By relaxing the constraints of finite mean and variance of the connection
model, linear throughput scaling $\Theta (n)$ is achievable with Pareto-type
fading models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4058</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4058</id><created>2008-09-24</created><authors><author><keyname>Godrich</keyname><forenames>Hana</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames></author><author><keyname>Blum</keyname><forenames>Rick S.</forenames></author></authors><title>Target Localization Accuracy Gain in MIMO Radar Based Systems</title><categories>cs.IT math.IT</categories><comments>36 pages, 5 figures, submitted to IEEE Transaction on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analysis of target localization accuracy, attainable
by the use of MIMO (Multiple-Input Multiple-Output) radar systems, configured
with multiple transmit and receive sensors, widely distributed over a given
area. The Cramer-Rao lower bound (CRLB) for target localization accuracy is
developed for both coherent and non-coherent processing. Coherent processing
requires a common phase reference for all transmit and receive sensors. The
CRLB is shown to be inversely proportional to the signal effective bandwidth in
the non-coherent case, but is approximately inversely proportional to the
carrier frequency in the coherent case. We further prove that optimization over
the sensors' positions lowers the CRLB by a factor equal to the product of the
number of transmitting and receiving sensors. The best linear unbiased
estimator (BLUE) is derived for the MIMO target localization problem. The
BLUE's utility is in providing a closed form localization estimate that
facilitates the analysis of the relations between sensors locations, target
location, and localization accuracy. Geometric dilution of precision (GDOP)
contours are used to map the relative performance accuracy for a given layout
of radars over a given geographic area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4059</identifier>
 <datestamp>2008-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4059</id><created>2008-09-23</created><updated>2008-10-07</updated><authors><author><keyname>Koepsell</keyname><forenames>Kilian</forenames></author><author><keyname>Sommer</keyname><forenames>Friedrich T.</forenames></author></authors><title>Information transmission in oscillatory neural activity</title><categories>q-bio.NC cs.IT math.IT q-bio.QM</categories><comments>18 pages, 8 figures, to appear in Biological Cybernetics</comments><journal-ref>Biological Cybernetics (2008) 99:403-416</journal-ref><doi>10.1007/s00422-008-0273-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Periodic neural activity not locked to the stimulus or to motor responses is
usually ignored. Here, we present new tools for modeling and quantifying the
information transmission based on periodic neural activity that occurs with
quasi-random phase relative to the stimulus. We propose a model to reproduce
characteristic features of oscillatory spike trains, such as histograms of
inter-spike intervals and phase locking of spikes to an oscillatory influence.
The proposed model is based on an inhomogeneous Gamma process governed by a
density function that is a product of the usual stimulus-dependent rate and a
quasi-periodic function. Further, we present an analysis method generalizing
the direct method (Rieke et al, 1999; Brenner et al, 2000) to assess the
information content in such data. We demonstrate these tools on recordings from
relay cells in the lateral geniculate nucleus of the cat.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4082</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4082</id><created>2008-09-24</created><authors><author><keyname>Berten</keyname><forenames>Vandy</forenames></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author></authors><title>Multiprocessor Global Scheduling on Frame-Based DVFS Systems</title><categories>cs.OS</categories><acm-class>D.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this ongoing work, we are interested in multiprocessor energy efficient
systems, where task durations are not known in advance, but are know
stochastically. More precisely, we consider global scheduling algorithms for
frame-based multiprocessor stochastic DVFS (Dynamic Voltage and Frequency
Scaling) systems. Moreover, we consider processors with a discrete set of
available frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4086</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4086</id><created>2008-09-24</created><updated>2011-01-07</updated><authors><author><keyname>Cybenko</keyname><forenames>George</forenames></author><author><keyname>Crespi</keyname><forenames>Valentino</forenames></author></authors><title>Learning Hidden Markov Models using Non-Negative Matrix Factorization</title><categories>cs.LG cs.AI cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory in September
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Baum-Welsh algorithm together with its derivatives and variations has
been the main technique for learning Hidden Markov Models (HMM) from
observational data. We present an HMM learning algorithm based on the
non-negative matrix factorization (NMF) of higher order Markovian statistics
that is structurally different from the Baum-Welsh and its associated
approaches. The described algorithm supports estimation of the number of
recurrent states of an HMM and iterates the non-negative matrix factorization
(NMF) algorithm to improve the learned HMM parameters. Numerical examples are
provided as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4093</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4093</id><created>2008-09-24</created><updated>2011-07-27</updated><authors><author><keyname>Vega-Paez</keyname><forenames>Ignacio</forenames></author><author><keyname>Ortega</keyname><forenames>Jose Angel</forenames></author><author><keyname>Pulido</keyname><forenames>Georgina G.</forenames></author></authors><title>Perspective Drawing of Surfaces with Line Hidden Line Elimination,
  Dibujando Superficies En Perspectiva Con Eliminacion De Lineas Ocultas</title><categories>cs.GR cs.CG</categories><report-no>IBP-TR2008-08</report-no><journal-ref>Proceedings in Technical Memory, XI Congreso Nacional de
  Ingenieria Electromecanica y de Sistemas, pp. 136-144, Mexico, DF., Nov 2009</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  An efficient computer algorithm is described for the perspective drawing of a
wide class of surfaces. The class includes surfaces corresponding lo
single-valued, continuous functions which are defined over rectangular domains.
The algorithm automatically computes and eliminates hidden lines. The number of
computations in the algorithm grows linearly with the number of sample points
on the surface to be drawn. An analysis of the algorithm is presented, and
extensions lo certain multi-valued functions are indicated. The algorithm is
implemented and tested on .Net 2.0 platform that left interactive use. Running
times are found lo be exceedingly efficient for visualization, where
interaction on-line and view-point control, enables effective and rapid
examination of a surfaces from many perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4101</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4101</id><created>2008-09-24</created><authors><author><keyname>Zhang</keyname><forenames>Lan</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Xin</keyname><forenames>Yan</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>On Gaussian MIMO BC-MAC Duality With Multiple Transmit Covariance
  Constraints</title><categories>cs.IT math.IT</categories><comments>36 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Owing to the structure of the Gaussian multiple-input multiple-output (MIMO)
broadcast channel (BC), associated optimization problems such as capacity
region computation and beamforming optimization are typically non-convex, and
cannot be solved directly. One feasible approach to these problems is to
transform them into their dual multiple access channel (MAC) problems, which
are easier to deal with due to their convexity properties. The conventional
BC-MAC duality is established via BC-MAC signal transformation, and has been
successfully applied to solve beamforming optimization,
signal-to-interference-plus-noise ratio (SINR) balancing, and capacity region
computation. However, this conventional duality approach is applicable only to
the case, in which the base station (BS) of the BC is subject to a single sum
power constraint. An alternative approach is minimax duality, established by Yu
in the framework of Lagrange duality, which can be applied to solve the
per-antenna power constraint problem. This paper extends the conventional
BC-MAC duality to the general linear constraint case, and thereby establishes a
general BC-MAC duality. This new duality is applied to solve the capacity
computation and beamforming optimization for the MIMO and multiple-input
single-output (MISO) BC, respectively, with multiple linear constraints.
Moreover, the relationship between this new general BC-MAC duality and minimax
duality is also presented. It is shown that the general BC-MAC duality offers
more flexibility in solving BC optimization problems relative to minimax
duality. Numerical results are provided to illustrate the effectiveness of the
proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4107</identifier>
 <datestamp>2010-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4107</id><created>2008-09-24</created><authors><author><keyname>Laprie</keyname><forenames>Jean-Claude</forenames><affiliation>LAAS</affiliation></author><author><keyname>Kanoun</keyname><forenames>Karama</forenames><affiliation>LAAS</affiliation></author><author><keyname>Kaaniche</keyname><forenames>Mohamed</forenames><affiliation>LAAS</affiliation></author></authors><title>Modelling interdependencies between the electricity and information
  infrastructures</title><categories>cs.DC</categories><proxy>ccsd hal-00323999</proxy><journal-ref>26th International Conference on Computer Safety, Reliability and
  Security, SAFECOMP-2007, Nurenberg : Allemagne (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to provide qualitative models characterizing
interdependencies related failures of two critical infrastructures: the
electricity infrastructure and the associated information infrastructure. The
interdependencies of these two infrastructures are increasing due to a growing
connection of the power grid networks to the global information infrastructure,
as a consequence of market deregulation and opening. These interdependencies
increase the risk of failures. We focus on cascading, escalating and
common-cause failures, which correspond to the main causes of failures due to
interdependencies. We address failures in the electricity infrastructure, in
combination with accidental failures in the information infrastructure, then we
show briefly how malicious attacks in the information infrastructure can be
addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4108</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4108</id><created>2008-09-24</created><authors><author><keyname>Rugina</keyname><forenames>Ana E.</forenames><affiliation>LAAS</affiliation></author><author><keyname>Kanoun</keyname><forenames>Karama</forenames><affiliation>LAAS</affiliation></author><author><keyname>Kaaniche</keyname><forenames>Mohamed</forenames><affiliation>LAAS</affiliation></author></authors><title>The ADAPT Tool: From AADL Architectural Models to Stochastic Petri Nets
  through Model Transformation</title><categories>cs.SE</categories><comments>6 pages</comments><proxy>ccsd hal-00323969</proxy><journal-ref>7th European Dependable Computing Conference (EDCC), Kaunas :
  Lituanie (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ADAPT is a tool that aims at easing the task of evaluating dependability
measures in the context of modern model driven engineering processes based on
AADL (Architecture Analysis and Design Language). Hence, its input is an AADL
architectural model annotated with dependability-related information. Its
output is a dependability evaluation model in the form of a Generalized
Stochastic Petri Net (GSPN). The latter can be processed by existing
dependability evaluation tools, to compute quantitative measures such as
reliability, availability, etc.. ADAPT interfaces OSATE (the Open Source AADL
Tool Environment) on the AADL side and SURF-2, on the dependability evaluation
side. In addition, ADAPT provides the GSPN in XML/XMI format, which represents
a gateway to other dependability evaluation tools, as the processing techniques
for XML files allow it to be easily converted to a tool-specific GSPN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4109</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4109</id><created>2008-09-24</created><authors><author><keyname>Rugina</keyname><forenames>Ana-Elena</forenames><affiliation>LAAS</affiliation></author><author><keyname>Feiler</keyname><forenames>Peter H.</forenames><affiliation>CMU-SEI</affiliation></author><author><keyname>Kanoun</keyname><forenames>Karama</forenames><affiliation>LAAS</affiliation></author><author><keyname>Kaaniche</keyname><forenames>Mohamed</forenames><affiliation>LAAS</affiliation></author></authors><title>Software dependability modeling using an industry-standard architecture
  description language</title><categories>cs.SE</categories><proxy>ccsd hal-00323983</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performing dependability evaluation along with other analyses at
architectural level allows both making architectural tradeoffs and predicting
the effects of architectural decisions on the dependability of an application.
This paper gives guidelines for building architectural dependability models for
software systems using the AADL (Architecture Analysis and Design Language). It
presents reusable modeling patterns for fault-tolerant applications and shows
how the presented patterns can be used in the context of a subsystem of a
real-life application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4115</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4115</id><created>2008-09-24</created><updated>2008-10-21</updated><authors><author><keyname>Baldan</keyname><forenames>Paolo</forenames></author><author><keyname>Corradini</keyname><forenames>Andrea</forenames></author><author><keyname>Ehrig</keyname><forenames>Hartmut</forenames></author><author><keyname>Heckel</keyname><forenames>Reiko</forenames></author><author><keyname>K&#xf6;nig</keyname><forenames>Barbara</forenames></author></authors><title>Bisimilarity and Behaviour-Preserving Reconfigurations of Open Petri
  Nets</title><categories>cs.LO</categories><comments>To appear in &quot;Logical Methods in Computer Science&quot;, 41 pages</comments><acm-class>F.4.1, D.2.2, D.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 4, Issue 4 (October
  21, 2008) lmcs:1165</journal-ref><doi>10.2168/LMCS-4(4:3)2008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for the specification of behaviour-preserving
reconfigurations of systems modelled as Petri nets. The framework is based on
open nets, a mild generalisation of ordinary Place/Transition nets suited to
model open systems which might interact with the surrounding environment and
endowed with a colimit-based composition operation. We show that natural
notions of bisimilarity over open nets are congruences with respect to the
composition operation. The considered behavioural equivalences differ for the
choice of the observations, which can be single firings or parallel steps.
Additionally, we consider weak forms of such equivalences, arising in the
presence of unobservable actions. We also provide an up-to technique for
facilitating bisimilarity proofs. The theory is used to identify suitable
classes of reconfiguration rules (in the double-pushout approach to rewriting)
whose application preserves the observational semantics of the net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4149</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4149</id><created>2008-09-24</created><authors><author><keyname>Bahramgiri</keyname><forenames>Hossein</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author></authors><title>Block Network Error Control Codes and Syndrome-based Complete Maximum
  Likelihood Decoding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, network error control coding is studied for robust and
efficient multicast in a directed acyclic network with imperfect links. The
block network error control coding framework, BNEC, is presented and the
capability of the scheme to correct a mixture of symbol errors and packet
erasures and to detect symbol errors is studied. The idea of syndrome-based
decoding and error detection is introduced for BNEC, which removes the effect
of input data and hence decreases the complexity. Next, an efficient
three-stage syndrome-based BNEC decoding scheme for network error correction is
proposed, in which prior to finding the error values, the position of the edge
errors are identified based on the error spaces at the receivers. In addition
to bounded-distance decoding schemes for error correction up to the refined
Singleton bound, a complete decoding scheme for BNEC is also introduced.
Specifically, it is shown that using the proposed syndrome-based complete
decoding, a network error correcting code with redundancy order d for receiver
t, can correct d-1 random additive errors with a probability sufficiently close
to 1, if the field size is sufficiently large. Also, a complete maximum
likelihood decoding scheme for BNEC is proposed. As the probability of error in
different network edges is not equal in general, and given the equivalency of
certain edge errors within the network at a particular receiver, the number of
edge errors, assessed in the refined Singleton bound, is not a sufficient
statistic for ML decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4183</identifier>
 <datestamp>2008-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4183</id><created>2008-09-24</created><authors><author><keyname>Avoine</keyname><forenames>Gildas</forenames></author><author><keyname>Tchamkerten</keyname><forenames>Aslan</forenames></author></authors><title>An Asymptotically Optimal RFID Authentication Protocol Against Relay
  Attacks</title><categories>cs.CR cs.IT math.IT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relay attacks are a major concern for RFID systems: during an authentication
process an adversary transparently relays messages between a verifier and a
remote legitimate prover.
  We present an authentication protocol suited for RFID systems. Our solution
is the first that prevents relay attacks without degrading the authentication
security level: it minimizes the probability that the verifier accepts a fake
proof of identity, whether or not a relay attack occurs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4194</identifier>
 <datestamp>2008-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4194</id><created>2008-09-24</created><updated>2008-12-08</updated><authors><author><keyname>Kovacs</keyname><forenames>Benedek</forenames></author></authors><title>Rate based call gapping with priorities and fairness between traffic
  classes</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new rate based call gapping method. The main advantage
is that it provides maximal throughput, priority handling and fairness for
traffic classes without queues, unlike Token Bucket which provides only the
first two or Weighted Fair Queuing that uses queues. The Token Bucket is used
for call gapping because it has good throughput characteristics. For this
reason we present a mixture of the two methods keeping the good properties of
both. A mathematical model has been developed to support our proposal. It
defines the three requirements and proves theorems about if they are satisfied
with the different call gapping mechanisms. Simulation, numerical results and
statistical discussion are also presented to underpin the findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4296</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4296</id><created>2008-09-24</created><authors><author><keyname>Rutishauser</keyname><forenames>Ueli</forenames></author><author><keyname>Douglas</keyname><forenames>Rodney J.</forenames></author></authors><title>State dependent computation using coupled recurrent networks</title><categories>q-bio.NC cs.NE</categories><comments>32 pages, 10 figures. Neural computation (in press)</comments><journal-ref>Neural computation, 21(2):478-509, 2009</journal-ref><doi>10.1162/neco.2008.03-08-734</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although conditional branching between possible behavioural states is a
hallmark of intelligent behavior, very little is known about the neuronal
mechanisms that support this processing. In a step toward solving this problem
we demonstrate by theoretical analysis and simulation how networks of richly
inter-connected neurons, such as those observed in the superficial layers of
the neocortex, can embed reliable robust finite state machines. We show how a
multi-stable neuronal network containing a number of states can be created very
simply, by coupling two recurrent networks whose synaptic weights have been
configured for soft winner-take-all (sWTA) performance. These two sWTAs have
simple, homogenous locally recurrent connectivity except for a small fraction
of recurrent cross-connections between them, which are used to embed the
required states. This coupling between the maps allows the network to continue
to express the current state even after the input that elicted that state is
withdrawn. In addition, a small number of 'transition neurons' implement the
necessary input-driven transitions between the embedded states. We provide
simple rules to systematically design and construct neuronal state machines of
this kind. The significance of our finding is that it offers a method whereby
the cortex could construct networks supporting a broad range of sophisticated
processing by applying only small specializations to the same generic neuronal
circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4316</identifier>
 <datestamp>2008-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4316</id><created>2008-09-24</created><authors><author><keyname>Sridharan</keyname><forenames>Sriram</forenames><affiliation>Shitz</affiliation></author><author><keyname>Jafarian</keyname><forenames>Amin</forenames><affiliation>Shitz</affiliation></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames><affiliation>Shitz</affiliation></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>A Layered Lattice Coding Scheme for a Class of Three User Gaussian
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies a class of three user Gaussian interference channels. A new
layered lattice coding scheme is introduced as a transmission strategy. The use
of lattice codes allows for an &quot;alignment&quot; of the interference observed at each
receiver. The layered lattice coding is shown to achieve more than one degree
of freedom for a class of interference channels and also achieves rates which
are better than the rates obtained using the Han-Kobayashi coding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4317</identifier>
 <datestamp>2012-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4317</id><created>2008-09-24</created><updated>2010-12-23</updated><authors><author><keyname>Choi</keyname><forenames>Byung-Soo</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author></authors><title>On the Effect of Quantum Interaction Distance on Quantum Addition
  Circuits</title><categories>quant-ph cs.AR</categories><comments>accepted for ACM Journal on Emerging Technologies in Computing
  Systems</comments><acm-class>C.1.m; B.2.0; B.m</acm-class><doi>10.1145/2000502.2000504</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the theoretical limits of the effect of the quantum
interaction distance on the speed of exact quantum addition circuits. For this
study, we exploit graph embedding for quantum circuit analysis. We study a
logical mapping of qubits and gates of any $\Omega(\log n)$-depth quantum adder
circuit for two $n$-qubit registers onto a practical architecture, which limits
interaction distance to the nearest neighbors only and supports only one- and
two-qubit logical gates. Unfortunately, on the chosen $k$-dimensional practical
architecture, we prove that the depth lower bound of any exact quantum addition
circuits is no longer $\Omega(\log {n})$, but $\Omega(\sqrt[k]{n})$. This
result, the first application of graph embedding to quantum circuits and
devices, provides a new tool for compiler development, emphasizes the impact of
quantum computer architecture on performance, and acts as a cautionary note
when evaluating the time performance of quantum algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4325</identifier>
 <datestamp>2009-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4325</id><created>2008-09-25</created><updated>2009-12-26</updated><authors><author><keyname>Ma</keyname><forenames>Liangping</forenames></author></authors><title>On the Unicast Capacity of Stationary Multi-channel Multi-radio Wireless
  Networks: Separability and Multi-channel Routing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first result is on the separability of the unicast capacity of stationary
multi-channel multi-radio wireless networks, i.e., whether the capacity of such
a network is equal to the sum of the capacities of the corresponding
single-channel single-radio wireless networks. For both the Arbitrary Network
model and the Random Network model, given a channel assignment, the
separability property does not always hold. However, if the number of radio
interfaces at each node is equal to the number of channels, the separability
property holds. The second result is on the impact of multi-channel routing
(i.e., routing a bit through multiple channels as opposed to through a single
channel) on the network capacity. For both network models, the network
capacities conditioned on a channel assignment under the two routing schemes
are not always equal, but if again the number of radio interfaces at each node
is equal to the number of channels, the two routing schemes yield equal network
capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4326</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4326</id><created>2008-09-25</created><updated>2010-09-01</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames><affiliation>Institute of Science and Technology, Vienna, Austria</affiliation></author><author><keyname>de Alfaro</keyname><forenames>Luca</forenames><affiliation>University of California, Santa Cruz, USA</affiliation></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames><affiliation>University of California, Los Angeles, USA</affiliation></author><author><keyname>Raman</keyname><forenames>Vishwanath</forenames><affiliation>University of California, Santa Cruz, USA</affiliation></author></authors><title>Algorithms for Game Metrics</title><categories>cs.GT</categories><comments>27 pages. Full version of the paper accepted at FSTTCS 2008</comments><proxy>LMCS</proxy><acm-class>F.4.1, F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (September
  1, 2010) lmcs:783</journal-ref><doi>10.2168/LMCS-6(3:13)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulation and bisimulation metrics for stochastic systems provide a
quantitative generalization of the classical simulation and bisimulation
relations. These metrics capture the similarity of states with respect to
quantitative specifications written in the quantitative {\mu}-calculus and
related probabilistic logics. We first show that the metrics provide a bound
for the difference in long-run average and discounted average behavior across
states, indicating that the metrics can be used both in system verification,
and in performance evaluation. For turn-based games and MDPs, we provide a
polynomial-time algorithm for the computation of the one-step metric distance
between states. The algorithm is based on linear programming; it improves on
the previous known exponential-time algorithm based on a reduction to the
theory of reals. We then present PSPACE algorithms for both the decision
problem and the problem of approximating the metric distance between two
states, matching the best known algorithms for Markov chains. For the
bisimulation kernel of the metric our algorithm works in time O(n^4) for both
turn-based games and MDPs; improving the previously best known O(n^9\cdot
log(n)) time algorithm for MDPs. For a concurrent game G, we show that
computing the exact distance between states is at least as hard as computing
the value of concurrent reachability games and the square-root-sum problem in
computational geometry. We show that checking whether the metric distance is
bounded by a rational r, can be done via a reduction to the theory of real
closed fields, involving a formula with three quantifier alternations, yielding
O(|G|^O(|G|^5)) time complexity, improving the previously known reduction,
which yielded O(|G|^O(|G|^7)) time complexity. These algorithms can be iterated
to approximate the metrics using binary search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4332</identifier>
 <datestamp>2009-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4332</id><created>2008-09-25</created><updated>2009-03-17</updated><authors><author><keyname>Li</keyname><forenames>Kang</forenames></author><author><keyname>Ma</keyname><forenames>Hui</forenames></author><author><keyname>Zhou</keyname><forenames>Haijun</forenames></author></authors><title>From one solution of a 3-satisfiability formula to a solution cluster:
  Frozen variables and entropy</title><categories>cond-mat.dis-nn cs.CC</categories><comments>13 pages, 6 figures. Final version as published in PRE</comments><journal-ref>Physical Review E 79, 031102 (2009)</journal-ref><doi>10.1103/PhysRevE.79.031102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A solution to a 3-satisfiability (3-SAT) formula can be expanded into a
cluster, all other solutions of which are reachable from this one through a
sequence of single-spin flips. Some variables in the solution cluster are
frozen to the same spin values by one of two different mechanisms: frozen-core
formation and long-range frustrations. While frozen cores are identified by a
local whitening algorithm, long-range frustrations are very difficult to trace,
and they make an entropic belief-propagation (BP) algorithm fail to converge.
For BP to reach a fixed point the spin values of a tiny fraction of variables
(chosen according to the whitening algorithm) are externally fixed during the
iteration. From the calculated entropy values, we infer that, for a large
random 3-SAT formula with constraint density close to the satisfiability
threshold, the solutions obtained by the survey-propagation or the walksat
algorithm belong neither to the most dominating clusters of the formula nor to
the most abundant clusters. This work indicates that a single solution cluster
of a random 3-SAT formula may have further community structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4342</identifier>
 <datestamp>2008-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4342</id><created>2008-09-25</created><authors><author><keyname>Kai</keyname><forenames>Caihong</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Towards a More Accurate Carrier Sensing Model for CSMA Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work calls into question a substantial body of past work on CSMA
wireless networks. In the majority of studies on CSMA wireless networks, a
contention graph is used to model the carrier sensing relationships (CS) among
links. This is a 0-1 model in which two links can either sense each other
completely or not. In real experiments, we observed that this is generally not
the case: the CS relationship between the links are often probabilistic and can
vary dynamically over time. This is the case even if the distance between the
links is fixed and there is no drastic change in the environment. Furthermore,
this partial carrier sensing relationship is prevalent and occurs over a wide
range of distances between the links. This observation is not consistent with
the 0-1 contention graph and implies that many results and conclusions drawn
from previous theoretical studies need to be re-examined. This paper
establishes a more accurate CS model with the objective of laying down a
foundation for future theoretical studies that reflect reality. Towards that
end, we set up detailed experiments to investigate the partial carrier sensing
phenomenon. We discuss the implications and the use of our partial carrier
sensing model in network analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4395</identifier>
 <datestamp>2008-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4395</id><created>2008-09-25</created><authors><author><keyname>Ball</keyname><forenames>Rudi</forenames></author></authors><title>Content Sharing for Mobile Devices</title><categories>cs.DC cs.NI</categories><comments>98 page, Masters Dissertation, 64 figures, September 2007</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The miniaturisation of computing devices has seen computing devices become
increasingly pervasive in society. With this increased pervasiveness, the
technologies of small computing devices have also improved. Mobile devices are
now capable of capturing various forms of multimedia and able to communicate
wirelessly using increasing numbers of communication techniques. The owners and
creators of local content are motivated to share this content in ever
increasing volume; the conclusion has been that social networks sites are
seeing a revolution in the sharing of information between communities of
people. As load on centralised systems increases, we present a novel
decentralised peer-to-peer approach dubbed the Market Contact Protocol (MCP) to
achieve cost effective, scalable and efficient content sharing using
opportunistic networking (pocket switched networking), incentive,
context-awareness, social contact and mobile devices. Within the report we
describe how the MCP is simulated with a superimposed geographic framework on
top of the JiST (Java in Simulation Time) framework to evaluate and measure its
capability to share content between massively mobile peers. The MCP is shown in
conclusion to be a powerful means by which to share content in a massively
mobile ad-hoc environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4398</identifier>
 <datestamp>2008-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4398</id><created>2008-09-25</created><authors><author><keyname>Schuetz</keyname><forenames>Philipp</forenames></author><author><keyname>Caflisch</keyname><forenames>Amedeo</forenames></author></authors><title>Multistep greedy algorithm identifies community structure in real-world
  and computer-generated networks</title><categories>cs.DS cond-mat.dis-nn physics.soc-ph q-bio.MN q-bio.QM</categories><comments>17 pages, 2 figures</comments><journal-ref>Phys. Rev. E 78, 026112 (2008)</journal-ref><doi>10.1103/PhysRevE.78.026112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have recently introduced a multistep extension of the greedy algorithm for
modularity optimization. The extension is based on the idea that merging l
pairs of communities (l&gt;1) at each iteration prevents premature condensation
into few large communities. Here, an empirical formula is presented for the
choice of the step width l that generates partitions with (close to) optimal
modularity for 17 real-world and 1100 computer-generated networks. Furthermore,
an in-depth analysis of the communities of two real-world networks (the
metabolic network of the bacterium E. coli and the graph of coappearing words
in the titles of papers coauthored by Martin Karplus) provides evidence that
the partition obtained by the multistep greedy algorithm is superior to the one
generated by the original greedy algorithm not only with respect to modularity
but also according to objective criteria. In other words, the multistep
extension of the greedy algorithm reduces the danger of getting trapped in
local optima of modularity and generates more reasonable partitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4484</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4484</id><created>2008-09-25</created><updated>2008-09-28</updated><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Llull and Copeland Voting Computationally Resist Bribery and Control</title><categories>cs.GT cs.CC cs.MA</categories><comments>This 2008/9/28 version is the same as both the 2008/9/25 version at
  arxiv.org and the 2008/9/25 revision of URCS TR-2008-933, except the present
  version corrects a minor typo in the penultimate paragraph of Section 3</comments><report-no>URCS-TR-2008-933</report-no><acm-class>I.2.11; F.2.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The only systems previously known to be resistant to all the standard control
types were highly artificial election systems created by hybridization. We
study a parameterized version of Copeland voting, denoted by Copeland^\alpha,
where the parameter \alpha is a rational number between 0 and 1 that specifies
how ties are valued in the pairwise comparisons of candidates. We prove that
Copeland^{0.5}, the system commonly referred to as &quot;Copeland voting,&quot; provides
full resistance to constructive control, and we prove the same for
Copeland^\alpha, for all rational \alpha, 0 &lt; \alpha &lt; 1. Copeland voting is
the first natural election system proven to have full resistance to
constructive control. We also prove that both Copeland^1 (Llull elections) and
Copeland^0 are resistant to all standard types of constructive control other
than one variant of addition of candidates. Moreover, we show that for each
rational \alpha, 0 \leq \alpha \leq 1, Copeland^\alpha voting is fully
resistant to bribery attacks, and we establish fixed-parameter tractability of
bounded-case control for Copeland^\alpha. We also study Copeland^\alpha
elections under more flexible models such as microbribery and extended control
and we integrate the potential irrationality of voter preferences into many of
our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4501</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4501</id><created>2008-09-25</created><authors><author><keyname>Yu</keyname><forenames>Guoshen</forenames></author><author><keyname>Slotine</keyname><forenames>Jean-Jacques</forenames></author></authors><title>Audio Classification from Time-Frequency Texture</title><categories>cs.CV cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-frequency representations of audio signals often resemble texture
images. This paper derives a simple audio classification algorithm based on
treating sound spectrograms as texture images. The algorithm is inspired by an
earlier visual classification scheme particularly efficient at classifying
textures. While solely based on time-frequency texture features, the algorithm
achieves surprisingly good performance in musical instrument classification
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4529</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4529</id><created>2008-09-26</created><authors><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author><author><keyname>Su</keyname><forenames>Chao-Cheng</forenames></author><author><keyname>Jalden</keyname><forenames>Joakim</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-Hui</forenames></author><author><keyname>Chi</keyname><forenames>Chong-Yung</forenames></author></authors><title>The Equivalence of Semidefinite Relaxation MIMO Detectors for
  Higher-Order QAM</title><categories>cs.IT math.IT math.OC</categories><comments>Submitted to IEEE Journal of Selected Topics in Signal Processing,
  Aug 2008</comments><doi>10.1109/JSTSP.2009.2035798</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multi-input-multi-output (MIMO) detection, semidefinite relaxation (SDR)
has been shown to be an efficient high-performance approach. Developed
initially for BPSK and QPSK, SDR has been found to be capable of providing
near-optimal performance (for those constellations). This has stimulated a
number of recent research endeavors that aim to apply SDR to the high-order QAM
cases. These independently developed SDRs are different in concept and
structure, and presently no serious analysis has been given to compare these
methods. This paper analyzes the relationship of three such SDR methods, namely
the polynomial-inspired SDR (PI-SDR) by Wiesel et al., the bound-constrained
SDR (BC-SDR) by Sidiropoulos and Luo, and the virtually-antipodal SDR (VA-SDR)
by Mao et al. The result that we have proven is somehow unexpected: the three
SDRs are equivalent. Simply speaking, we show that solving any one SDR is
equivalent to solving the other SDRs. This paper also discusses some
implications arising from the SDR equivalence, and provides simulation results
to verify our theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4530</identifier>
 <datestamp>2009-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4530</id><created>2008-09-26</created><updated>2009-05-09</updated><authors><author><keyname>Medelyan</keyname><forenames>Olena</forenames></author><author><keyname>Milne</keyname><forenames>David</forenames></author><author><keyname>Legg</keyname><forenames>Catherine</forenames></author><author><keyname>Witten</keyname><forenames>Ian H.</forenames></author></authors><title>Mining Meaning from Wikipedia</title><categories>cs.AI cs.CL cs.IR</categories><comments>An extensive survey of re-using information in Wikipedia in natural
  language processing, information retrieval and extraction and ontology
  building. Accepted for publication in International Journal of Human-Computer
  Studies</comments><report-no>ISSN 1177-777X</report-no><acm-class>I.2.6; I.2.7; H.3.1; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wikipedia is a goldmine of information; not just for its many readers, but
also for the growing community of researchers who recognize it as a resource of
exceptional scale and utility. It represents a vast investment of manual effort
and judgment: a huge, constantly evolving tapestry of concepts and relations
that is being applied to a host of tasks.
  This article provides a comprehensive description of this work. It focuses on
research that extracts and makes use of the concepts, relations, facts and
descriptions found in Wikipedia, and organizes the work into four broad
categories: applying Wikipedia to natural language processing; using it to
facilitate information retrieval and information extraction; and as a resource
for ontology building. The article addresses how Wikipedia is being used as is,
how it is being improved and adapted, and how it is being combined with other
structures to create entirely new resources. We identify the research groups
and individuals involved, and how their work has developed in the last few
years. We provide a comprehensive list of the open-source software they have
produced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4576</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4576</id><created>2008-09-26</created><authors><author><keyname>Lacan</keyname><forenames>Jerome</forenames></author><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author></authors><title>On-the-Fly Coding to Enable Full Reliability Without Retransmission</title><categories>cs.NI</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new reliability algorithm specifically useful when
retransmission is either problematic or not possible. In case of multimedia or
multicast communications and in the context of the Delay Tolerant Networking
(DTN), the classical retransmission schemes can be counterproductive in terms
of data transfer performance or not possible when the acknowledgment path is
not always available. Indeed, over long delay links, packets retransmission has
a meaning of cost and must be minimized.In this paper, we detail a novel
reliability mechanism with an implicit acknowledgment strategy that could be
used either within these new DTN proposals, for multimedia traffic or in the
context of multicast transport protocols. This proposal is based on a new
on-the-fly erasure coding concept specifically designed to operate efficient
reliable transfer over bi-directional links. This proposal, named Tetrys,
allows to unify a full reliability with an error correction scheme. In this
paper, we model the performance of this proposal and demonstrate with a
prototype, that we can achieve a full reliability without acknowledgment path
confirmation. Indeed, the main findings are that Tetrys is not sensitive to the
loss of acknowledgments while ensuring a faster data availability to the
application compared to other traditional acknowledgment schemes. Finally, we
pave the first step of the integration of such algorithm inside a congestion
controlled protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4577</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4577</id><created>2008-09-26</created><authors><author><keyname>Golin</keyname><forenames>Mordecai</forenames></author><author><keyname>Xu</keyname><forenames>Xiaoming</forenames></author><author><keyname>Yu</keyname><forenames>Jiajin</forenames></author></authors><title>A Generic Top-Down Dynamic-Programming Approach to Prefix-Free Coding</title><categories>cs.DS cs.IT math.IT</categories><acm-class>E.1; E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a probability distribution over a set of n words to be transmitted, the
Huffman Coding problem is to find a minimal-cost prefix free code for
transmitting those words. The basic Huffman coding problem can be solved in O(n
log n) time but variations are more difficult. One of the standard techniques
for solving these variations utilizes a top-down dynamic programming approach.
In this paper we show that this approach is amenable to dynamic programming
speedup techniques, permitting a speedup of an order of magnitude for many
algorithms in the literature for such variations as mixed radix, reserved
length and one-ended coding. These speedups are immediate implications of a
general structural property that permits batching together the calculation of
many DP entries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4582</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4582</id><created>2008-09-26</created><authors><author><keyname>Oikarinen</keyname><forenames>Emilia</forenames></author><author><keyname>Janhunen</keyname><forenames>Tomi</forenames></author></authors><title>Achieving compositionality of the stable model semantics for Smodels
  programs</title><categories>cs.AI</categories><comments>44 pages, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a Gaifman-Shapiro-style module architecture is tailored to the
case of Smodels programs under the stable model semantics. The composition of
Smodels program modules is suitably limited by module conditions which ensure
the compatibility of the module system with stable models. Hence the semantics
of an entire Smodels program depends directly on stable models assigned to its
modules. This result is formalized as a module theorem which truly strengthens
Lifschitz and Turner's splitting-set theorem for the class of Smodels programs.
To streamline generalizations in the future, the module theorem is first proved
for normal programs and then extended to cover Smodels programs using a
translation from the latter class of programs to the former class. Moreover,
the respective notion of module-level equivalence, namely modular equivalence,
is shown to be a proper congruence relation: it is preserved under
substitutions of modules that are modularly equivalent. Principles for program
decomposition are also addressed. The strongly connected components of the
respective dependency graph can be exploited in order to extract a module
structure when there is no explicit a priori knowledge about the modules of a
program. The paper includes a practical demonstration of tools that have been
developed for automated (de)composition of Smodels programs.
  To appear in Theory and Practice of Logic Programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4622</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4622</id><created>2008-09-26</created><authors><author><keyname>Fix</keyname><forenames>J&#xe9;r&#xe9;my</forenames><affiliation>INRIA Lorraine - Loria</affiliation></author><author><keyname>Rougier</keyname><forenames>Nicolas P.</forenames><affiliation>INRIA Lorraine - Loria, University of Colorado, Boulder</affiliation></author><author><keyname>Alexandre</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lorraine - Loria</affiliation></author></authors><title>A computational approach to the covert and overt deployment of spatial
  attention</title><categories>cs.NE</categories><proxy>ccsd inria-00325181</proxy><journal-ref>Dans NeuroComp 2008 : 2i\`eme Conf\'erence Fran\c{c}aise de
  Neurosciences Computationnelles (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popular computational models of visual attention tend to neglect the
influence of saccadic eye movements whereas it has been shown that the primates
perform on average three of them per seconds and that the neural substrate for
the deployment of attention and the execution of an eye movement might
considerably overlap. Here we propose a computational model in which the
deployment of attention with or without a subsequent eye movement emerges from
local, distributed and numerical computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4632</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4632</id><created>2008-09-26</created><authors><author><keyname>Veeramachaneni</keyname><forenames>Sriharsha</forenames></author><author><keyname>Kondadadi</keyname><forenames>Ravikumar</forenames></author></authors><title>Surrogate Learning - An Approach for Semi-Supervised Classification</title><categories>cs.LG</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the task of learning a classifier from the feature space
$\mathcal{X}$ to the set of classes $\mathcal{Y} = \{0, 1\}$, when the features
can be partitioned into class-conditionally independent feature sets
$\mathcal{X}_1$ and $\mathcal{X}_2$. We show the surprising fact that the
class-conditional independence can be used to represent the original learning
task in terms of 1) learning a classifier from $\mathcal{X}_2$ to
$\mathcal{X}_1$ and 2) learning the class-conditional distribution of the
feature set $\mathcal{X}_1$. This fact can be exploited for semi-supervised
learning because the former task can be accomplished purely from unlabeled
samples. We present experimental evaluation of the idea in two real world
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4635</identifier>
 <datestamp>2008-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4635</id><created>2008-09-26</created><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>van der Zwaag</keyname><forenames>Mark B.</forenames></author></authors><title>Mechanistic Behavior of Single-Pass Instruction Sequences</title><categories>cs.PL cs.LO</categories><comments>12 pages</comments><acm-class>D.1.4; F.3.2; F.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Earlier work on program and thread algebra detailed the functional,
observable behavior of programs under execution. In this article we add the
modeling of unobservable, mechanistic processing, in particular processing due
to jump instructions. We model mechanistic processing preceding some further
behavior as a delay of that behavior; we borrow a unary delay operator from
discrete time process algebra. We define a mechanistic improvement ordering on
threads and observe that some threads do not have an optimal implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4668</identifier>
 <datestamp>2009-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4668</id><created>2008-09-26</created><authors><author><keyname>Orlicki</keyname><forenames>Jose Ignacio</forenames><affiliation>CoreLabs, ITBA</affiliation></author><author><keyname>Fierens</keyname><forenames>Pablo Ignacio</forenames><affiliation>ITBA</affiliation></author><author><keyname>Alvarez-Hamelin</keyname><forenames>Jos&#xe9; Ignacio</forenames><affiliation>ITBA, CONICET</affiliation></author></authors><title>Faceted Ranking of Egos in Collaborative Tagging Systems</title><categories>cs.IR</categories><proxy>ccsd hal-00325248</proxy><journal-ref>WEBIST 2009, Lisboa : Portugal (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimedia uploaded content is tagged and recommended by users of
collaborative systems, resulting in informal classifications also known as
folksonomies. Faceted web ranking has been proved a reasonable alternative to a
single ranking which does not take into account a personalized context. In this
paper we analyze the online computation of rankings of users associated to
facets made up of multiple tags. Possible applications are user reputation
evaluation (ego-ranking) and improvement of content quality in case of
retrieval. We propose a solution based on PageRank as centrality measure: (i) a
ranking for each tag is computed offline on the basis of the corresponding
tag-dependent subgraph; (ii) a faceted order is generated by merging rankings
corresponding to all the tags in the facet. The fundamental assumption,
validated by empirical observations, is that step (i) is scalable. We also
present algorithms for part (ii) having time complexity O(k), where k is the
number of tags in the facet, well suited to online computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4743</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4743</id><created>2008-09-27</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author></authors><title>The Imaginary Sliding Window As a New Data Structure for Adaptive
  Algorithms</title><categories>cs.IT cs.DS math.IT</categories><comments>Published in: Problems of information transmission,1996,v.32,#2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The scheme of the sliding window is known in Information Theory, Computer
Science, the problem of predicting and in stastistics. Let a source with
unknown statistics generate some word $... x_{-1}x_{0}x_{1}x_{2}...$ in some
alphabet $A$. For every moment $t, t=... $ $-1, 0, 1, ...$, one stores the word
(&quot;window&quot;) $ x_{t-w} x_{t-w+1}... x_{t-1}$ where $w$,$w \geq 1$, is called
&quot;window length&quot;. In the theory of universal coding, the code of the $x_{t}$
depends on source ststistics estimated by the window, in the problem of
predicting, each letter $x_{t}$ is predicted using information of the window,
etc. After that the letter $x_{t}$ is included in the window on the right,
while $x_{t-w}$ is removed from the window. It is the sliding window scheme.
This scheme has two merits: it allows one i) to estimate the source statistics
quite precisely and ii) to adapt the code in case of a change in the source'
statistics. However this scheme has a defect, namely, the necessity to store
the window (i.e. the word $x_{t-w}... x_{t-1})$ which needs a large memory size
for large $w$. A new scheme named &quot;the Imaginary Sliding Window (ISW)&quot; is
constructed. The gist of this scheme is that not the last element $x_{t-w}$ but
rather a random one is removed from the window. This allows one to retain both
merits of the sliding window as well as the possibility of not storing the
window and thus significantly decreasing the memory size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4747</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4747</id><created>2008-09-27</created><updated>2012-01-28</updated><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>On parsimonious edge-colouring of graphs with maximum degree three</title><categories>cs.DM</categories><comments>Revised version submitted to Graphs and Combinatorics</comments><proxy>ccsd</proxy><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a graph $G$ of maximum degree $\Delta$ let $\gamma$ denote the largest
fraction of edges that can be $\Delta$ edge-coloured. Albertson and Haas showed
that $\gamma \geq 13/15$ when $G$ is cubic . We show here that this result can
be extended to graphs with maximum degree 3 with the exception of a graph on 5
vertices. Moreover, there are exactly two graphs with maximum degree 3 (one
being obviously the Petersen graph) for which $\gamma = 13/15$. This extends a
result given by Steffen. These results are obtained by using structural
properties of the so called $\delta$-minimum edge colourings for graphs with
maximum degree 3. Keywords : Cubic graph; Edge-colouring
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4784</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4784</id><created>2008-09-27</created><authors><author><keyname>Reis</keyname><forenames>Luis Paulo</forenames></author><author><keyname>Barteneva</keyname><forenames>Daria</forenames></author><author><keyname>Lau</keyname><forenames>Nuno</forenames></author></authors><title>A Computational Study on Emotions and Temperament in Multi-Agent Systems</title><categories>cs.AI cs.MA cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in neurosciences and psychology have provided evidence that
affective phenomena pervade intelligence at many levels, being inseparable from
the cognitionaction loop. Perception, attention, memory, learning,
decisionmaking, adaptation, communication and social interaction are some of
the aspects influenced by them. This work draws its inspirations from
neurobiology, psychophysics and sociology to approach the problem of building
autonomous robots capable of interacting with each other and building
strategies based on temperamental decision mechanism. Modelling emotions is a
relatively recent focus in artificial intelligence and cognitive modelling.
Such models can ideally inform our understanding of human behavior. We may see
the development of computational models of emotion as a core research focus
that will facilitate advances in the large array of computational systems that
model, interpret or influence human behavior. We propose a model based on a
scalable, flexible and modular approach to emotion which allows runtime
evaluation between emotional quality and performance. The results achieved
showed that the strategies based on temperamental decision mechanism strongly
influence the system performance and there are evident dependency between
emotional state of the agents and their temperamental type, as well as the
dependency between the team performance and the temperamental configuration of
the team members, and this enable us to conclude that the modular approach to
emotional programming based on temperamental theory is the good choice to
develop computational mind models for emotional behavioral Multi-Agent systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4792</identifier>
 <datestamp>2009-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4792</id><created>2008-09-28</created><updated>2009-03-08</updated><authors><author><keyname>Hansen</keyname><forenames>Thomas Dueholm</forenames></author><author><keyname>Telelis</keyname><forenames>Orestis A.</forenames></author></authors><title>On Pure and (approximate) Strong Equilibria of Facility Location Games</title><categories>cs.GT</categories><comments>19 pages, 5 figures, 2 tables, partially appeared in WINE 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study social cost losses in Facility Location games, where $n$ selfish
agents install facilities over a network and connect to them, so as to forward
their local demand (expressed by a non-negative weight per agent). Agents using
the same facility share fairly its installation cost, but every agent pays
individually a (weighted) connection cost to the chosen location. We study the
Price of Stability (PoS) of pure Nash equilibria and the Price of Anarchy of
strong equilibria (SPoA), that generalize pure equilibria by being resilient to
coalitional deviations. A special case of recently studied network design
games, Facility Location merits separate study as a classic model with numerous
applications and individual characteristics: our analysis for unweighted agents
on metric networks reveals constant upper and lower bounds for the PoS, while
an $O(\ln n)$ upper bound implied by previous work is tight for non-metric
networks. Strong equilibria do not always exist, even for the unweighted metric
case. We show that $e$-approximate strong equilibria exist ($e=2.718...$). The
SPoA is generally upper bounded by $O(\ln W)$ ($W$ is the sum of agents'
weights), which becomes tight $\Theta(\ln n)$ for unweighted agents. For the
unweighted metric case we prove a constant upper bound. We point out several
challenging open questions that arise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4794</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4794</id><created>2008-09-27</created><authors><author><keyname>Smith</keyname><forenames>Adam</forenames></author></authors><title>Efficient, Differentially Private Point Estimators</title><categories>cs.CR cs.DS</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a recent notion of privacy for statistical databases
that provides rigorous, meaningful confidentiality guarantees, even in the
presence of an attacker with access to arbitrary side information.
  We show that for a large class of parametric probability models, one can
construct a differentially private estimator whose distribution converges to
that of the maximum likelihood estimator. In particular, it is efficient and
asymptotically unbiased. This result provides (further) compelling evidence
that rigorous notions of privacy in statistical databases can be consistent
with statistically valid inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4804</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4804</id><created>2008-09-27</created><authors><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>On the Secure Degrees of Freedom of Wireless X Networks</title><categories>cs.IT math.IT</categories><comments>To appear in Proceedings of 46th Annual Allerton Conference on
  Communication, Control and Computing, Sept. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work showed that the X network with M transmitters, N receivers has
MN/(M+N-1) degrees of freedom. In this work we study the degrees of freedom of
the X network with secrecy constraints, i.e. the X network where some/all
messages are confidential. We consider the $M \times N$ network where all
messages are secured and show that N(M-1)/(M+N-1) degrees of freedom can be
achieved. Secondly, we show that if messages from only M-1 transmitters are
confidential, then MN/(M+N-1) degrees of freedom can be achieved meaning that
there is no loss of degrees of freedom because of secrecy constraints. We also
consider the achievable secure degrees of freedom under a more conservative
secrecy constraint. We require that messages from any subset of transmitters
are secure even if other transmitters are compromised, i.e., messages from the
compromised transmitter are revealed to the unintended receivers. We also study
the achievable secure degrees of freedom of the K user Gaussian interference
channel under two different secrecy constraints where 1/2 secure degrees of
freedom per message can be achieved. The achievable scheme in all cases is
based on random binning combined with interference alignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4807</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4807</id><created>2008-09-27</created><authors><author><keyname>Dong</keyname><forenames>Lun</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Secure Wireless Communications via Cooperation</title><categories>cs.IT math.IT</categories><comments>7 pages, 5 figures, appeared in 2008 Allerton Conference on
  Communication, Control, and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The feasibility of physical-layer-based security approaches for wireless
communications in the presence of one or more eavesdroppers is hampered by
channel conditions. In this paper, cooperation is investigated as an approach
to overcome this problem and improve the performance of secure communications.
In particular, a decode-and-forward (DF) based cooperative protocol is
considered, and the objective is to design the system for secrecy capacity
maximization or transmit power minimization. System design for the DF-based
cooperative protocol is first studied by assuming the availability of global
channel state information (CSI). For the case of one eavesdropper, an iterative
scheme is proposed to obtain the optimal solution for the problem of transmit
power minimization. For the case of multiple eavesdroppers, the problem of
secrecy capacity maximization or transmit power minimization is in general
intractable. Suboptimal system design is proposed by adding an additional
constraint, i.e., the complete nulling of signals at all eavesdroppers, which
yields simple closed-form solutions for the aforementioned two problems. Then,
the impact of imperfect CSI of eavesdroppers on system design is studied, in
which the ergodic secrecy capacity is of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4812</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4812</id><created>2008-09-27</created><authors><author><keyname>Feron</keyname><forenames>Eric</forenames></author><author><keyname>Alegre</keyname><forenames>Fernando</forenames></author></authors><title>Control software analysis, Part I Open-loop properties</title><categories>cs.SE</categories><comments>20 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the digital world enters further into everyday life, questions are raised
about the increasing challenges brought by the interaction of real-time
software with physical devices. Many accidents and incidents encountered in
areas as diverse as medical systems, transportation systems or weapon systems
are ultimately attributed to &quot;software failures&quot;. Since real-time software that
interacts with physical systems might as well be called control software, the
long litany of accidents due to real-time software failures might be taken as
an equally long list of opportunities for control systems engineering. In this
paper, we are interested only in run-time errors in those pieces of software
that are a direct implementation of control system specifications: For
well-defined and well-understood control architectures such as those present in
standard textbooks on digital control systems, the current state of theoretical
computer science is well-equipped enough to address and analyze control
algorithms. It appears that a central element to these analyses is Lyapunov
stability theory, which translate into invariant theory in computer
implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4821</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4821</id><created>2008-09-28</created><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>On Fan Raspaud Conjecture</title><categories>cs.DM</categories><proxy>ccsd hal-00325258</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A conjecture of Fan and Raspaud [3] asserts that every bridgeless cubic graph
con-tains three perfect matchings with empty intersection. Kaiser and Raspaud
[6] sug-gested a possible approach to this problem based on the concept of a
balanced join in an embedded graph. We give here some new results concerning
this conjecture and prove that a minimum counterexample must have at least 32
vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4822</identifier>
 <datestamp>2009-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4822</id><created>2008-09-28</created><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>On normal odd partitions in cubic graphs</title><categories>cs.DM</categories><proxy>ccsd hal-00325250</proxy><journal-ref>Discussiones Mathematicae Graph Theory 29, 2 (2009) 293-312</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A normal partition of the edges of a cubic graph is a partition into trails
(no repeated edge) such that each vertex is the end vertex of exactly one trail
of the partition. We investigate this notion and give some results and
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4834</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4834</id><created>2008-09-28</created><authors><author><keyname>Torres</keyname><forenames>Jose</forenames></author><author><keyname>Reis</keyname><forenames>Luis Paulo</forenames></author></authors><title>Relevance Feedback in Conceptual Image Retrieval: A User Evaluation</title><categories>cs.IR</categories><comments>15 Pages, 20 References</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Visual Object Information Retrieval (VOIR) system described in this paper
implements an image retrieval approach that combines two layers, the conceptual
and the visual layer. It uses terms from a textual thesaurus to represent the
conceptual information and also works with image regions, the visual
information. The terms are related with the image regions through a weighted
association enabling the execution of concept-level queries. VOIR uses
region-based relevance feedback to improve the quality of the results in each
query session and to discover new associations between text and image. This
paper describes a user-centred and task-oriented comparative evaluation of VOIR
which was undertaken considering three distinct versions of VOIR: a full-fledge
version; one supporting relevance feedback only at image level; and a third
version not supporting relevance feedback at all. The evaluation performed
showed the usefulness of region based relevance feedback in the context of VOIR
prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4839</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4839</id><created>2008-09-28</created><updated>2009-11-07</updated><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>M\'acajov\'a and \v{S}koviera Conjecture on Cubic Graphs</title><categories>cs.DM</categories><proxy>ccsd hal-00325255</proxy><journal-ref>Discussionnes Mathematicae on Graph Theory 30, 2 (2010) xxx-yyy</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A conjecture of M\'a\u{c}ajov\'a and \u{S}koviera asserts that every
bridgeless cubic graph has two perfect matchings whose intersection does not
contain any odd edge cut. We prove this conjecture for graphs with few vertices
and we give a stronger result for traceable graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4882</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4882</id><created>2008-09-28</created><authors><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author></authors><title>Multi-Armed Bandits in Metric Spaces</title><categories>cs.DS cs.LG</categories><comments>16 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multi-armed bandit problem, an online algorithm chooses from a set of
strategies in a sequence of trials so as to maximize the total payoff of the
chosen strategies. While the performance of bandit algorithms with a small
finite strategy set is quite well understood, bandit problems with large
strategy sets are still a topic of very active investigation, motivated by
practical applications such as online auctions and web advertisement. The goal
of such research is to identify broad and natural classes of strategy sets and
payoff functions which enable the design of efficient solutions. In this work
we study a very general setting for the multi-armed bandit problem in which the
strategies form a metric space, and the payoff function satisfies a Lipschitz
condition with respect to the metric. We refer to this problem as the
&quot;Lipschitz MAB problem&quot;. We present a complete solution for the multi-armed
problem in this setting. That is, for every metric space (L,X) we define an
isometry invariant which bounds from below the performance of Lipschitz MAB
algorithms for X, and we present an algorithm which comes arbitrarily close to
meeting this bound. Furthermore, our technique gives even better results for
benign payoff functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4883</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4883</id><created>2008-09-29</created><updated>2010-05-08</updated><authors><author><keyname>Saligrama</keyname><forenames>V.</forenames></author><author><keyname>Zhao</keyname><forenames>M.</forenames></author></authors><title>Thresholded Basis Pursuit: An LP Algorithm for Achieving Optimal Support
  Recovery for Sparse and Approximately Sparse Signals from Noisy Random
  Measurements</title><categories>cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a linear programming solution for sign pattern
recovery of a sparse signal from noisy random projections of the signal. We
consider two types of noise models, input noise, where noise enters before the
random projection; and output noise, where noise enters after the random
projection. Sign pattern recovery involves the estimation of sign pattern of a
sparse signal. Our idea is to pretend that no noise exists and solve the
noiseless $\ell_1$ problem, namely, $\min \|\beta\|_1 ~ s.t. ~ y=G \beta$ and
quantizing the resulting solution. We show that the quantized solution
perfectly reconstructs the sign pattern of a sufficiently sparse signal.
Specifically, we show that the sign pattern of an arbitrary k-sparse,
n-dimensional signal $x$ can be recovered with $SNR=\Omega(\log n)$ and
measurements scaling as $m= \Omega(k \log{n/k})$ for all sparsity levels $k$
satisfying $0&lt; k \leq \alpha n$, where $\alpha$ is a sufficiently small
positive constant. Surprisingly, this bound matches the optimal
\emph{Max-Likelihood} performance bounds in terms of $SNR$, required number of
measurements, and admissible sparsity level in an order-wise sense. In contrast
to our results, previous results based on LASSO and Max-Correlation techniques
either assume significantly larger $SNR$, sublinear sparsity levels or
restrictive assumptions on signal sets. Our proof technique is based on noisy
perturbation of the noiseless $\ell_1$ problem, in that, we estimate the
maximum admissible noise level before sign pattern recovery fails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4916</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4916</id><created>2008-09-29</created><authors><author><keyname>Schommer</keyname><forenames>Christoph</forenames></author></authors><title>16 Propositions to Reconsider the Organization of a Scientific Workshop</title><categories>cs.CY cs.GL</categories><comments>5 pages</comments><acm-class>K.4.0; A.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Participating a scientific workshop is nowadays often an adventure because
the number of participants do seldom exceed the number of talks. A half-day
workshop is mostly finished at lunchtime, speakers are sometimes not present
and unexcused, and a strict progression of the workshop offers little air for
discussion. And when talks are re-scheduled on short notice in case that a
speech is dropped out, attaining guests definitely wonder why the presenter is
talking about something that does not match the previously announced talk. In
this respect, we believe that the organization of a workshop in the classical
sense must be reconsidered. It is not enough of compelling the presenters to
pay the registration fee only and to let the participants being impassive or
taken away mentally. With this work, we address several propositions to become
implemented in the future workshop organization. With that, we hope to
contribute to the identification of scientific workshops as a place of
interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4917</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4917</id><created>2008-09-29</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Ma</keyname><forenames>Longhua</forenames></author><author><keyname>Zhao</keyname><forenames>Wenhong</forenames></author><author><keyname>Sun</keyname><forenames>Youxian</forenames></author><author><keyname>Dong</keyname><forenames>Jinxiang</forenames></author></authors><title>Enhanced Energy-Aware Feedback Scheduling of Embedded Control Systems</title><categories>cs.OH</categories><comments>to appear in Journal of Computers</comments><acm-class>C.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic voltage scaling (DVS) is one of the most effective techniques for
reducing energy consumption in embedded and real-time systems. However,
traditional DVS algorithms have inherent limitations on their capability in
energy saving since they rarely take into account the actual application
requirements and often exploit fixed timing constraints of real-time tasks.
Taking advantage of application adaptation, an enhanced energy-aware feedback
scheduling (EEAFS) scheme is proposed, which integrates feedback scheduling
with DVS. To achieve further reduction in energy consumption over pure DVS
while not jeopardizing the quality of control, the sampling period of each
control loop is adapted to its actual control performance, thus exploring
flexible timing constraints on control tasks. Extensive simulation results are
given to demonstrate the effectiveness of EEAFS under different scenarios.
Compared with the optimal pure DVS scheme, EEAFS saves much more energy while
yielding comparable control performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4920</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4920</id><created>2008-09-29</created><authors><author><keyname>Ma</keyname><forenames>Longhua</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Peng</keyname><forenames>Zhe</forenames></author></authors><title>Integrated Design and Implementation of Embedded Control Systems with
  Scilab</title><categories>cs.OH</categories><comments>15 pages, 14 figures; Open Access at
  http://www.mdpi.org/sensors/papers/s8095501.pdf</comments><acm-class>C.3</acm-class><journal-ref>Sensors, 8(9): 5501-5515, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Embedded systems are playing an increasingly important role in control
engineering. Despite their popularity, embedded systems are generally subject
to resource constraints and it is therefore difficult to build complex control
systems on embedded platforms. Traditionally, the design and implementation of
control systems are often separated, which causes the development of embedded
control systems to be highly time-consuming and costly. To address these
problems, this paper presents a low-cost, reusable, reconfigurable platform
that enables integrated design and implementation of embedded control systems.
To minimize the cost, free and open source software packages such as Linux and
Scilab are used. Scilab is ported to the embedded ARM-Linux system. The drivers
for interfacing Scilab with several communication protocols including serial,
Ethernet, and Modbus are developed. Experiments are conducted to test the
developed embedded platform. The use of Scilab enables implementation of
complex control algorithms on embedded platforms. With the developed platform,
it is possible to perform all phases of the development cycle of embedded
control systems in a unified environment, thus facilitating the reduction of
development time and cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4924</identifier>
 <datestamp>2008-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4924</id><created>2008-09-29</created><authors><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Ma</keyname><forenames>Longhua</forenames></author><author><keyname>Peng</keyname><forenames>Chen</forenames></author><author><keyname>Sun</keyname><forenames>Youxian</forenames></author><author><keyname>Dong</keyname><forenames>Jinxiang</forenames></author></authors><title>Cross-Layer Adaptive Feedback Scheduling of Wireless Control Systems</title><categories>cs.NI</categories><comments>17 pages, 12 figures; Open Access at
  http://www.mdpi.org/sensors/papers/s8074265.pdf</comments><acm-class>C.2.1; C.3</acm-class><journal-ref>Sensors, 8(7): 4265-4281, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a trend towards using wireless technologies in networked control
systems. However, the adverse properties of the radio channels make it
difficult to design and implement control systems in wireless environments. To
attack the uncertainty in available communication resources in wireless control
systems closed over WLAN, a cross-layer adaptive feedback scheduling (CLAFS)
scheme is developed, which takes advantage of the co-design of control and
wireless communications. By exploiting cross-layer design, CLAFS adjusts the
sampling periods of control systems at the application layer based on
information about deadline miss ratio and transmission rate from the physical
layer. Within the framework of feedback scheduling, the control performance is
maximized through controlling the deadline miss ratio. Key design parameters of
the feedback scheduler are adapted to dynamic changes in the channel condition.
An event-driven invocation mechanism for the feedback scheduler is also
developed. Simulation results show that the proposed approach is efficient in
dealing with channel capacity variations and noise interference, thus providing
an enabling technology for control over WLAN.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="4000" completeListSize="102538">1122234|5001</resumptionToken>
</ListRecords>
</OAI-PMH>
